id,project,branch,change_id,subject,status,created,updated,submitted,reviewers,revisions,total_comment_count,number,current_revision,discussion_messages_count,reviewers_count,revisions_count,owner_account_id,owner_name,owner_username,is_owner_bot,commit_message,git_command,changed_files,files_count,commit_id,topic,added_lines,deleted_lines,insertions,deletions
openstack%2Freleases~master~I85089d82d13c324628b761eaf931bad6904f7c61,openstack/releases,master,I85089d82d13c324628b761eaf931bad6904f7c61,"release automation, 4",MERGED,2016-08-29 21:54:27.000000000,2016-08-29 22:25:46.000000000,2016-08-29 22:04:44.000000000,"[{'_account_id': 3}, {'_account_id': 2472}]","[{'number': 1, 'created': '2016-08-29 21:54:27.000000000', 'files': ['deliverables/_independent/release-test.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/05148fe80ec3cf03e3c0929476faf1862eb7361f', 'message': 'release automation, 4\n\nChange-Id: I85089d82d13c324628b761eaf931bad6904f7c61\n'}]",0,362464,05148fe80ec3cf03e3c0929476faf1862eb7361f,7,2,1,2472,,,0,"release automation, 4

Change-Id: I85089d82d13c324628b761eaf931bad6904f7c61
",git fetch https://review.opendev.org/openstack/releases refs/changes/64/362464/1 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/_independent/release-test.yaml'],1,05148fe80ec3cf03e3c0929476faf1862eb7361f,release-automation,--- launchpad: oslo.config team: Release Management send-announcements-to: doug@doughellmann.com releases: - version: 0.0.5 projects: - repo: openstack/release-test hash: ecda79f509fe2d9c1e69e121721dc988933a0fcd ,,9,0
openstack%2Fdevstack-gate~master~I6721f614c56298f9c9b476044705fa5fab6d63fc,openstack/devstack-gate,master,I6721f614c56298f9c9b476044705fa5fab6d63fc,"Revert ""Use ntp-wait instead of ntpdate to set time""",MERGED,2016-08-19 20:18:29.000000000,2016-08-29 22:17:19.000000000,2016-08-29 22:17:19.000000000,"[{'_account_id': 1}, {'_account_id': 3}, {'_account_id': 4146}, {'_account_id': 5263}, {'_account_id': 7353}]","[{'number': 1, 'created': '2016-08-19 20:18:29.000000000', 'files': ['functions.sh'], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/ed81ff26a970a34fb2751f56da322d7f2c0ab61c', 'message': 'Revert ""Use ntp-wait instead of ntpdate to set time""\n\nThis reverts commit aaa0890e4f1b47f1d455aa333aa4cdb1bb978e18.\n\nTurns out using ntp-wait does not always result in a stepped clock like\nwe want. Go back to the old ntpdate setup.\n\nDepends-On: Ib3fd4afe5a89d8a799cc15c57254aaf11b6aa3e5\nChange-Id: I6721f614c56298f9c9b476044705fa5fab6d63fc\n'}]",0,358105,ed81ff26a970a34fb2751f56da322d7f2c0ab61c,14,5,1,4146,,,0,"Revert ""Use ntp-wait instead of ntpdate to set time""

This reverts commit aaa0890e4f1b47f1d455aa333aa4cdb1bb978e18.

Turns out using ntp-wait does not always result in a stepped clock like
we want. Go back to the old ntpdate setup.

Depends-On: Ib3fd4afe5a89d8a799cc15c57254aaf11b6aa3e5
Change-Id: I6721f614c56298f9c9b476044705fa5fab6d63fc
",git fetch https://review.opendev.org/openstack/devstack-gate refs/changes/05/358105/1 && git format-patch -1 --stdout FETCH_HEAD,['functions.sh'],1,ed81ff26a970a34fb2751f56da322d7f2c0ab61c,revert-ntpwait," if is_fedora; then local ntp_service='ntpd' elif uses_debs; then local ntp_service='ntp' else echo ""Unsupported platform, can't determine ntp service"" exit 1 fi local default_ntp_server=$( grep ^server /etc/ntp.conf | head -1 | awk '{print $2}') local ntp_server=${NTP_SERVER:-$default_ntp_server} sudo service $ntp_service stop sudo /usr/sbin/ntpdate $ntp_server sudo service $ntp_service start", sudo /usr/sbin/ntp-wait -v -n 100,14,1
openstack%2Fopenstack-ansible~master~I66d7c15a43a70237b35d8ba7325d24e3b7206208,openstack/openstack-ansible,master,I66d7c15a43a70237b35d8ba7325d24e3b7206208,Fix deprecation warning for undefined variables,MERGED,2016-08-26 18:21:50.000000000,2016-08-29 21:58:13.000000000,2016-08-29 21:58:13.000000000,"[{'_account_id': 3}, {'_account_id': 6816}, {'_account_id': 7353}, {'_account_id': 14805}]","[{'number': 1, 'created': '2016-08-26 18:21:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/e58afbaee78bcd1bac27730f383daedc3a8f9150', 'message': ""Fix deprecation warning for undefined variables\n\nProvide a default empty variable for 'bootstrap_host_data_disk_device'.\nTasks which make use of this variable within with_items lists have been\nupdated to evaluate that it has been set before executing.\n\n'with_' clauses are evaluated before 'when' clauses. In Ansible 1.9\ntasks are silently skipped when a variable within a 'with_' clause is\nundefined, Ansible 2 provides a deprecation warning.\n\nChange-Id: I66d7c15a43a70237b35d8ba7325d24e3b7206208\n""}, {'number': 2, 'created': '2016-08-26 18:40:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/1a29babf8cdb4724e99ab9a1dc0114b0006f307e', 'message': ""Fix deprecation warning for undefined variables\n\nProvide a default empty variable for 'bootstrap_host_data_disk_device'.\nTasks which make use of this variable within with_items lists have been\nupdated to evaluate that it has been set before executing.\n\n'with_' clauses are evaluated before 'when' clauses. In Ansible 1.9\ntasks are silently skipped when a variable within a 'with_' clause is\nundefined, Ansible 2 provides a deprecation warning.\n\nChange-Id: I66d7c15a43a70237b35d8ba7325d24e3b7206208\n""}, {'number': 3, 'created': '2016-08-29 17:28:22.000000000', 'files': ['tests/roles/bootstrap-host/tasks/check-requirements.yml', 'tests/roles/bootstrap-host/tasks/prepare_data_disk.yml', 'tests/roles/bootstrap-host/tasks/main.yml', 'tests/roles/bootstrap-host/defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/58e9c8db6e35eef1c24ec8ac6016651d6d110338', 'message': ""Fix deprecation warning for undefined variables\n\nProvide a default empty variable for 'bootstrap_host_data_disk_device'.\nTasks which make use of this variable within with_items lists have been\nupdated to evaluate that it has been set before executing.\n\n'with_' clauses are evaluated before 'when' clauses. In Ansible 1.9\ntasks are silently skipped when a variable within a 'with_' clause is\nundefined, Ansible 2 provides a deprecation warning.\n\nChange-Id: I66d7c15a43a70237b35d8ba7325d24e3b7206208\n""}]",0,361407,58e9c8db6e35eef1c24ec8ac6016651d6d110338,22,4,3,14805,,,0,"Fix deprecation warning for undefined variables

Provide a default empty variable for 'bootstrap_host_data_disk_device'.
Tasks which make use of this variable within with_items lists have been
updated to evaluate that it has been set before executing.

'with_' clauses are evaluated before 'when' clauses. In Ansible 1.9
tasks are silently skipped when a variable within a 'with_' clause is
undefined, Ansible 2 provides a deprecation warning.

Change-Id: I66d7c15a43a70237b35d8ba7325d24e3b7206208
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/07/361407/1 && git format-patch -1 --stdout FETCH_HEAD,"['tests/roles/bootstrap-host/tasks/prepare_data_disk.yml', 'tests/roles/bootstrap-host/defaults/main.yml']",2,e58afbaee78bcd1bac27730f383daedc3a8f9150,bp/ansible-2-1-support,bootstrap_host_data_disk_device: null,#bootstrap_host_data_disk_device: vdb,15,7
openstack%2Fmurano~master~Ia94cf24bcf517af7db57117f86c7b802423f81df,openstack/murano,master,Ia94cf24bcf517af7db57117f86c7b802423f81df,Update app dev framework with multi-region support,MERGED,2016-08-29 18:40:46.000000000,2016-08-29 21:57:50.000000000,2016-08-29 21:57:50.000000000,"[{'_account_id': 3}, {'_account_id': 7225}, {'_account_id': 7821}, {'_account_id': 15168}, {'_account_id': 20364}]","[{'number': 1, 'created': '2016-08-29 18:40:46.000000000', 'files': ['meta/io.murano.applications/Classes/component.yaml'], 'web_link': 'https://opendev.org/openstack/murano/commit/077a3c364b1e9799d51f208b16b0b2afc4127286', 'message': ""Update app dev framework with multi-region support\n\nWhen security rules were applied they were were\napplied to the environment's Heat stack. Now they\nare applied to each region's stack application\ninstances belong in.\n\nChange-Id: Ia94cf24bcf517af7db57117f86c7b802423f81df\n""}]",0,362316,077a3c364b1e9799d51f208b16b0b2afc4127286,10,5,1,7226,,,0,"Update app dev framework with multi-region support

When security rules were applied they were were
applied to the environment's Heat stack. Now they
are applied to each region's stack application
instances belong in.

Change-Id: Ia94cf24bcf517af7db57117f86c7b802423f81df
",git fetch https://review.opendev.org/openstack/murano refs/changes/16/362316/1 && git format-patch -1 --stdout FETCH_HEAD,['meta/io.murano.applications/Classes/component.yaml'],1,077a3c364b1e9799d51f208b16b0b2afc4127286,362284," - If: $sr Then: - $regions: $servers.select($.getRegion()).distinct() - $regions.pselect($this._configureSecurityGroup($, $sr)) _configureSecurityGroup: Usage: Static Arguments: - region: Contract: $.class(std:CloudRegion).notNull() - rules: Contract: - FromPort: $.int().notNull() ToPort: $.int().notNull() IpProtocol: $.string().notNull() External: $.bool().notNull() Ethertype: $.string().check($ in list(null, 'IPv4', 'IPv6')) Body: - $region.securityGroupManager.addGroupIngress($rules) - $region.stack.push()", - $env: $this.find(std:Environment) - If: $sr and $env Then: - $env.securityGroupManager.addGroupIngress($sr) - $env.stack.push(),19,4
openstack%2Fneutron~master~Ifa58601be97c150536d416415728eda7714f6030,openstack/neutron,master,Ifa58601be97c150536d416415728eda7714f6030,Move dscv and ca_certs to config section service_clients,ABANDONED,2016-08-19 07:07:00.000000000,2016-08-29 21:57:20.000000000,,"[{'_account_id': 3}, {'_account_id': 5170}, {'_account_id': 8410}, {'_account_id': 9845}, {'_account_id': 15752}, {'_account_id': 16376}, {'_account_id': 20190}]","[{'number': 1, 'created': '2016-08-19 07:07:00.000000000', 'files': ['neutron/tests/tempest/api/clients.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/a01e85dedeb3ec8fd661669f76831c21b59f5dae', 'message': 'Move dscv and ca_certs to config section service_clients\n\ndscv and ca_certs has been moved to section servic_clients\nin tempest\n\nChange-Id: Ifa58601be97c150536d416415728eda7714f6030\n'}]",0,357642,a01e85dedeb3ec8fd661669f76831c21b59f5dae,9,7,1,20190,,,0,"Move dscv and ca_certs to config section service_clients

dscv and ca_certs has been moved to section servic_clients
in tempest

Change-Id: Ifa58601be97c150536d416415728eda7714f6030
",git fetch https://review.opendev.org/openstack/neutron refs/changes/42/357642/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/tests/tempest/api/clients.py'],1,a01e85dedeb3ec8fd661669f76831c21b59f5dae,change_item_section_in_config," CONF.service_clients.disable_ssl_certificate_validation, 'ca_certs': CONF.service_clients.ca_certificates_file,"," CONF.identity.disable_ssl_certificate_validation, 'ca_certs': CONF.identity.ca_certificates_file,",2,2
openstack%2Fglance~master~I9ea635368994a9f89bb4f19a82104499e5174b46,openstack/glance,master,I9ea635368994a9f89bb4f19a82104499e5174b46,"Remove ""Services which consume this"" section",MERGED,2016-08-19 20:48:40.000000000,2016-08-29 21:55:53.000000000,2016-08-29 21:55:53.000000000,"[{'_account_id': 3}, {'_account_id': 2537}, {'_account_id': 5314}, {'_account_id': 8158}, {'_account_id': 21722}, {'_account_id': 22448}, {'_account_id': 22834}]","[{'number': 1, 'created': '2016-08-19 20:48:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/a75f302cbc9d824bcb4ef7067154d63748fc5826', 'message': 'Remove ""Services which consume this"" section\n\nIn the first few improvements to the help text of configuration\noptions, the section ""Services which consume this"" was included\nto clearly indicate which services consume a particular\nconfiguration option. However, this is redundant information as\nall glance services have their configuration files. And, the very\nfact that a configuration option appears in a certain file\nindicates that the corresponding service potentially consumes it.\n\nChange-Id: I9ea635368994a9f89bb4f19a82104499e5174b46\nPartial-Bug: #1570946\n'}, {'number': 2, 'created': '2016-08-29 19:31:22.000000000', 'files': ['glance/api/versions.py', 'glance/api/glare/versions.py', 'glance/image_cache/__init__.py', 'glance/api/middleware/context.py', 'glance/image_cache/drivers/sqlite.py', 'glance/scrubber.py'], 'web_link': 'https://opendev.org/openstack/glance/commit/3ff3debc1427ba0da4c60ac8ff9ef66bbdfe1f6a', 'message': 'Remove ""Services which consume this"" section\n\nIn the first few improvements to the help text of configuration\noptions, the section ""Services which consume this"" was included\nto clearly indicate which services consume a particular\nconfiguration option. However, this is redundant information as\nall glance services have their configuration files. And, the very\nfact that a configuration option appears in a certain file\nindicates that the corresponding service potentially consumes it.\n\nHence, in this patch we drop the redundant section from the help text\nof configuration options it appears in. The configuration options\nthat are impacted are:\n* public_endpoint (glance/api/glare/versions.py)\n* owner_is_tenant (glance/api/middleware/context.py)\n* admin_role (glance/api/middleware/context.py)\n* allow_anonymous_access (glance/api/middleware/context.py)\n* max_request_id_length (glance/api/middleware/context.py)\n* public_endpoint (glance/api/versions.py)\n* image_cache_driver (glance/image_cache/__init__.py)\n* image_cache_max_size (glance/image_cache/__init__.py)\n* image_cache_stall_time (glance/image_cache/__init__.py)\n* image_cache_dir (glance/image_cache/__init__.py)\n* image_cache_sqlite_db (glance/image_cache/drivers/sqlite.py)\n* admin_role (glance/scrubber.py)\n\nChange-Id: I9ea635368994a9f89bb4f19a82104499e5174b46\nPartial-Bug: #1570946\n'}]",1,358113,3ff3debc1427ba0da4c60ac8ff9ef66bbdfe1f6a,13,7,2,8158,,,0,"Remove ""Services which consume this"" section

In the first few improvements to the help text of configuration
options, the section ""Services which consume this"" was included
to clearly indicate which services consume a particular
configuration option. However, this is redundant information as
all glance services have their configuration files. And, the very
fact that a configuration option appears in a certain file
indicates that the corresponding service potentially consumes it.

Hence, in this patch we drop the redundant section from the help text
of configuration options it appears in. The configuration options
that are impacted are:
* public_endpoint (glance/api/glare/versions.py)
* owner_is_tenant (glance/api/middleware/context.py)
* admin_role (glance/api/middleware/context.py)
* allow_anonymous_access (glance/api/middleware/context.py)
* max_request_id_length (glance/api/middleware/context.py)
* public_endpoint (glance/api/versions.py)
* image_cache_driver (glance/image_cache/__init__.py)
* image_cache_max_size (glance/image_cache/__init__.py)
* image_cache_stall_time (glance/image_cache/__init__.py)
* image_cache_dir (glance/image_cache/__init__.py)
* image_cache_sqlite_db (glance/image_cache/drivers/sqlite.py)
* admin_role (glance/scrubber.py)

Change-Id: I9ea635368994a9f89bb4f19a82104499e5174b46
Partial-Bug: #1570946
",git fetch https://review.opendev.org/openstack/glance refs/changes/13/358113/1 && git format-patch -1 --stdout FETCH_HEAD,"['glance/api/versions.py', 'glance/api/glare/versions.py', 'glance/image_cache/__init__.py', 'glance/api/middleware/context.py', 'glance/image_cache/drivers/sqlite.py', 'glance/scrubber.py']",6,a75f302cbc9d824bcb4ef7067154d63748fc5826,remove-service-consumption-section,,Services which consume this: * glance-api * glare-api * glance-registry * glance-scrubber ,0,48
openstack%2Fnetworking-ovn~master~I101395f09b502ec271994351a28c7fcab960dc54,openstack/networking-ovn,master,I101395f09b502ec271994351a28c7fcab960dc54,Force config drive when OVN native services are enabled,ABANDONED,2016-08-26 22:05:31.000000000,2016-08-29 21:55:16.000000000,,"[{'_account_id': 3}, {'_account_id': 8410}]","[{'number': 1, 'created': '2016-08-26 22:05:31.000000000', 'files': ['devstack/override-defaults'], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/fd62e9defdbd9d6528ae88feec104125bd4ccdf9', 'message': ""Force config drive when OVN native services are enabled\n\nOVN native services don't provide metadata support so config drive\nis needed to provide configuration (such as SSH keys) to instances.\nPrior to [1] and [2], this was the default in DevStack and in the\nDevStack gate.\n\n[1] https://review.openstack.org/#/c/357443/\n[2] https://review.openstack.org/#/c/357446/\n\nChange-Id: I101395f09b502ec271994351a28c7fcab960dc54\n""}]",0,361485,fd62e9defdbd9d6528ae88feec104125bd4ccdf9,4,2,1,8410,,,0,"Force config drive when OVN native services are enabled

OVN native services don't provide metadata support so config drive
is needed to provide configuration (such as SSH keys) to instances.
Prior to [1] and [2], this was the default in DevStack and in the
DevStack gate.

[1] https://review.openstack.org/#/c/357443/
[2] https://review.openstack.org/#/c/357446/

Change-Id: I101395f09b502ec271994351a28c7fcab960dc54
",git fetch https://review.opendev.org/openstack/networking-ovn refs/changes/85/361485/1 && git format-patch -1 --stdout FETCH_HEAD,['devstack/override-defaults'],1,fd62e9defdbd9d6528ae88feec104125bd4ccdf9,config-drive,"# Force config drive whenever OVN native services are enabled. Currently, # OVN native services do not provide metadata support. if [[ ""$OVN_NATIVE_DHCP"" == ""True"" || ""$OVN_L3_MODE"" == ""True"" ]]; then FORCE_CONFIG_DRIVE=${FORCE_CONFIG_DRIVE:-""True""} fi ",,6,0
openstack%2Fneutron~master~Ied714bf23bcedfface757de1f93827e30cbde59e,openstack/neutron,master,Ied714bf23bcedfface757de1f93827e30cbde59e,Fix ipam_driver config help,MERGED,2016-08-29 11:21:18.000000000,2016-08-29 21:53:43.000000000,2016-08-29 20:55:35.000000000,"[{'_account_id': 3}, {'_account_id': 1131}, {'_account_id': 1653}, {'_account_id': 5170}, {'_account_id': 7448}, {'_account_id': 9732}, {'_account_id': 10385}, {'_account_id': 14611}, {'_account_id': 15752}, {'_account_id': 16376}, {'_account_id': 20363}]","[{'number': 1, 'created': '2016-08-29 11:21:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/6b96bc672afa9a4908115e618ece98fbee4b67f0', 'message': ""Fix ipam_driver config help\n\nCommit I1d633810bd16f1bec7bbca57522e9ad3f7745ea2 changed the default ipam\ndriver from none to 'internal', but the config help was not updated.\n\nChange-Id: Ied714bf23bcedfface757de1f93827e30cbde59e\n""}, {'number': 2, 'created': '2016-08-29 11:45:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/7fb0f63d6ac72f44f5605a51f40526f084289dae', 'message': ""Fix ipam_driver config help\n\nCommit I1d633810bd16f1bec7bbca57522e9ad3f7745ea2 changed the default ipam\ndriver from none to 'internal', but the config help was not updated.\n\nChange-Id: Ied714bf23bcedfface757de1f93827e30cbde59e\n""}, {'number': 3, 'created': '2016-08-29 16:21:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/8947cff6197093ff550a395203dca53e298d4c05', 'message': ""Fix ipam_driver config help\n\nCommit I1d633810bd16f1bec7bbca57522e9ad3f7745ea2 changed the default ipam\ndriver from none to 'internal', but the config help was not updated.\n\nChange-Id: Ied714bf23bcedfface757de1f93827e30cbde59e\n""}, {'number': 4, 'created': '2016-08-29 16:28:12.000000000', 'files': ['neutron/conf/common.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/e4d4c72f8aacf07e98fc0e2a83214081f62bac53', 'message': ""Fix ipam_driver config help\n\nCommit I1d633810bd16f1bec7bbca57522e9ad3f7745ea2 changed the default ipam\ndriver from none to 'internal', but the config help was not updated.\n\nChange-Id: Ied714bf23bcedfface757de1f93827e30cbde59e\n""}]",3,362028,e4d4c72f8aacf07e98fc0e2a83214081f62bac53,31,11,4,20363,,,0,"Fix ipam_driver config help

Commit I1d633810bd16f1bec7bbca57522e9ad3f7745ea2 changed the default ipam
driver from none to 'internal', but the config help was not updated.

Change-Id: Ied714bf23bcedfface757de1f93827e30cbde59e
",git fetch https://review.opendev.org/openstack/neutron refs/changes/28/362028/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/conf/common.py'],1,6b96bc672afa9a4908115e618ece98fbee4b67f0,ipam_driver_def," ""If ipam_driver is not set, no IPAM driver is used. "" ""By default, the reference implementation of Neutron "" ""IPAM driver is used."")),"," ""If ipam_driver is not set (default behavior), no IPAM "" ""driver is used. In order to use the reference "" ""implementation of Neutron IPAM driver, "" ""use 'internal'."")),",3,4
openstack%2Fkeystone~master~I86dfbd2c1f7fed199c612dd1456358e559da3fad,openstack/keystone,master,I86dfbd2c1f7fed199c612dd1456358e559da3fad,Add a feature support matrix for identity sources,MERGED,2016-08-29 13:30:17.000000000,2016-08-29 21:53:37.000000000,2016-08-29 21:53:37.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 6482}, {'_account_id': 8119}, {'_account_id': 17860}]","[{'number': 1, 'created': '2016-08-29 13:30:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/36f8f3e5fa9b4354162384a349b157070df139e3', 'message': 'Add a feature support matrix for identity sources\n\nThis introduces the various ways you can configure keystone to\nauthenticate users, and provides a little compare/contrast to help\npeople understand how each solution behaves at a high level before\ndiving deeper.\n\nThis patch covers:\n\n- SQL\n- LDAP (considering that all write operations are deprecated)\n- External authentication (REMOTE_USER)\n- OAuth 1.0a\n- OpenID Connect\n- SAMLv2\n\nChange-Id: I86dfbd2c1f7fed199c612dd1456358e559da3fad\n'}, {'number': 2, 'created': '2016-08-29 13:46:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/9e7d88a19ae369355c3ccfc17fc6f161443fa451', 'message': 'Add a feature support matrix for identity sources\n\nThis introduces the various ways you can configure keystone to\nauthenticate users, and provides a little compare/contrast to help\npeople understand how each solution behaves at a high level before\ndiving deeper.\n\nThis patch covers:\n\n- SQL\n- LDAP (considering that all write operations are deprecated)\n- External authentication (REMOTE_USER)\n- OAuth 1.0a\n- OpenID Connect\n- SAMLv2\n\nChange-Id: I86dfbd2c1f7fed199c612dd1456358e559da3fad\n'}, {'number': 3, 'created': '2016-08-29 15:17:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/fa056e2e44500251321506a28ace412c828ce190', 'message': 'Add a feature support matrix for identity sources\n\nThis introduces the various ways you can configure keystone to\nauthenticate users, and provides a little compare/contrast to help\npeople understand how each solution behaves at a high level before\ndiving deeper.\n\nThis patch covers:\n\n- SQL\n- LDAP (considering that all write operations are deprecated)\n- External authentication (REMOTE_USER)\n- OAuth 1.0a\n- OpenID Connect\n- SAMLv2\n\nChange-Id: I86dfbd2c1f7fed199c612dd1456358e559da3fad\n'}, {'number': 4, 'created': '2016-08-29 18:56:56.000000000', 'files': ['doc/source/configuration.rst', 'doc/source/identity-support-matrix.ini'], 'web_link': 'https://opendev.org/openstack/keystone/commit/428a6e0faa4a2ab667bec9eeb9649fc90c44618b', 'message': 'Add a feature support matrix for identity sources\n\nThis introduces the various ways you can configure keystone to\nauthenticate users, and provides a little compare/contrast to help\npeople understand how each solution behaves at a high level before\ndiving deeper.\n\nThis patch covers:\n\n- SQL\n- LDAP (considering that all write operations are deprecated)\n- External authentication (REMOTE_USER)\n- OAuth 1.0a\n- OpenID Connect\n- SAMLv2\n\nChange-Id: I86dfbd2c1f7fed199c612dd1456358e559da3fad\n'}]",8,362113,428a6e0faa4a2ab667bec9eeb9649fc90c44618b,19,5,4,4,,,0,"Add a feature support matrix for identity sources

This introduces the various ways you can configure keystone to
authenticate users, and provides a little compare/contrast to help
people understand how each solution behaves at a high level before
diving deeper.

This patch covers:

- SQL
- LDAP (considering that all write operations are deprecated)
- External authentication (REMOTE_USER)
- OAuth 1.0a
- OpenID Connect
- SAMLv2

Change-Id: I86dfbd2c1f7fed199c612dd1456358e559da3fad
",git fetch https://review.opendev.org/openstack/keystone refs/changes/13/362113/4 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/configuration.rst', 'doc/source/identity-support-matrix.ini']",2,36f8f3e5fa9b4354162384a349b157070df139e3,,"# Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. # This file contains a specification of what feature capabilities each driver # is able to support. Feature capabilities include what API operations are # supported, what backend behaviors features can be used and what aspects of # the driver implementation can be configured. The capabilities can be # considered to be structured into nested groups, but in this file they have # been flattened for ease of representation. The section names represent the # group structure. At the top level there are the following groups defined: # # - operation: Public API operations. # - feature: Features of the driver. # # When considering which capabilities should be marked as mandatory, consider # the following guiding principles. # # The 'status' field takes possible values: # # - mandatory: Unconditionally required to be implemented. # - optional: Optional to support, but nice to have. # - choice(group): At least one of the options within the named group # must be implemented. # - conditional(cond): Required, if the referenced condition is met. # # The value against each 'driver-impl-XXXX' entry refers to the level of the # implementation of the feature in that driver: # # - complete: Fully implemented, expected to work at all times. # - partial: Implemented, but with caveats about when it will work. # For example, some configurations or hardware or guest OS may not # support it. # - missing: Not implemented at all. # # In the case of the driver being marked as 'partial', then # 'driver-notes-XXX' entry should be used to explain the caveats around the # implementation. # # The 'cli' field takes a list of client commands, separated by semicolon. # These CLi commands are related to that feature. # Example: # cli=openstack domain list;openstack domain show <domain> # [targets] # List of driver implementations for which we are going to track the status of # features. This list only covers drivers that are in tree. Out of tree # drivers should maintain their own equivalent document, and merge it with this # when their code merges into core. sql=SQL ldap=LDAP oauth1=OAuth v1.0a external=REMOTE_USER oidc=OpenID Connect samlv2=SAML v2 [feature.local_authentication] title=Local authentication status=optional notes=Authenticate with keystone by providing credentials directly to keystone. sql=complete ldap=complete oauth1=complete external=missing oidc=missing samlv2=missing [feature.external_authentication] title=External authentication status=optional notes=Authenticate with keystone by providing credentials to an external system that keystone trusts (as with federation). sql=missing ldap=missing oauth1=missing external=complete oidc=complete samlv2=complete [feature.identity_crud] title=Identity management status=optional notes=Create, update, enable/disable, and delete users via Keystone's HTTP API. sql=complete ldap=partial oauth1=complete external=missing oidc=missing samlv2=missing [feature.pci_controls] title=PCI-DSS controls status=optional notes=Configure keystone to enforce PCI-DSS compliant security controls. sql=complete ldap=unknown oauth1=missing external=unknown oidc=unknown samlv2=unknown [feature.auditing] title=Auditing status=mandatory notes=Audit authentication flows using PyCADF. sql=complete ldap=complete oauth1=missing external=missing oidc=missing samlv2=complete ",,137,0
openstack%2Fpython-ironicclient~master~I6a655b9f136d0214b6e9bb868f411ba948557ac3,openstack/python-ironicclient,master,I6a655b9f136d0214b6e9bb868f411ba948557ac3,Add openstack baremetal chassis commands,MERGED,2016-07-22 05:31:38.000000000,2016-08-29 21:53:16.000000000,2016-08-29 21:53:16.000000000,"[{'_account_id': 3}, {'_account_id': 6618}, {'_account_id': 10239}, {'_account_id': 10342}, {'_account_id': 13636}, {'_account_id': 14525}, {'_account_id': 14614}]","[{'number': 1, 'created': '2016-07-22 05:31:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/158268c51855516fede11b7b74fd2490453852e1', 'message': 'Add openstack baremetal chassis commands\n\nThis extends the OpenStackClient plugin with new commands related\nto the chassis:\n\n  * openstack baremetal chassis create\n  * openstack baremetal chassis delete\n  * openstack baremetal chassis list\n  * openstack baremetal chassis set\n  * openstack baremetal chassis show\n  * openstack baremetal chassis unset\n\nChange-Id: I6a655b9f136d0214b6e9bb868f411ba948557ac3\nPartial-Bug: 1526479\n'}, {'number': 2, 'created': '2016-08-18 19:13:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/1508441662cc2372af882ef8dcc8c0d79c9b2f84', 'message': 'Add openstack baremetal chassis commands\n\nThis extends the OpenStackClient plugin with new commands related\nto the chassis:\n\n  * openstack baremetal chassis create\n  * openstack baremetal chassis delete\n  * openstack baremetal chassis list\n  * openstack baremetal chassis set\n  * openstack baremetal chassis show\n  * openstack baremetal chassis unset\n\nChange-Id: I6a655b9f136d0214b6e9bb868f411ba948557ac3\nPartial-Bug: 1526479\n'}, {'number': 3, 'created': '2016-08-25 16:36:29.000000000', 'files': ['ironicclient/tests/unit/osc/v1/fakes.py', 'ironicclient/osc/v1/baremetal_chassis.py', 'ironicclient/tests/unit/osc/v1/test_baremetal_chassis.py', 'releasenotes/notes/osc-baremetal-chassis-332ef4d453c52a58.yaml', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/dd755102e86f10b5df26d3b7a56dfe68a9581b1f', 'message': 'Add openstack baremetal chassis commands\n\nThis extends the OpenStackClient plugin with new commands related\nto the chassis:\n\n  * openstack baremetal chassis create\n  * openstack baremetal chassis delete\n  * openstack baremetal chassis list\n  * openstack baremetal chassis set\n  * openstack baremetal chassis show\n  * openstack baremetal chassis unset\n\nChange-Id: I6a655b9f136d0214b6e9bb868f411ba948557ac3\nPartial-Bug: 1526479\n'}]",15,345815,dd755102e86f10b5df26d3b7a56dfe68a9581b1f,34,7,3,6618,,,0,"Add openstack baremetal chassis commands

This extends the OpenStackClient plugin with new commands related
to the chassis:

  * openstack baremetal chassis create
  * openstack baremetal chassis delete
  * openstack baremetal chassis list
  * openstack baremetal chassis set
  * openstack baremetal chassis show
  * openstack baremetal chassis unset

Change-Id: I6a655b9f136d0214b6e9bb868f411ba948557ac3
Partial-Bug: 1526479
",git fetch https://review.opendev.org/openstack/python-ironicclient refs/changes/15/345815/1 && git format-patch -1 --stdout FETCH_HEAD,"['ironicclient/osc/v1/baremetal_chassis.py', 'ironicclient/tests/unit/osc/v1/fakes.py', 'ironicclient/tests/unit/osc/v1/test_baremetal_chassis.py', 'releasenotes/notes/osc-baremetal-chassis-332ef4d453c52a58.yaml', 'setup.cfg']",5,158268c51855516fede11b7b74fd2490453852e1,bug/1526479, baremetal_chassis_create = ironicclient.osc.v1.baremetal_chassis:CreateBaremetalChassis baremetal_chassis_delete = ironicclient.osc.v1.baremetal_chassis:DeleteBaremetalChassis baremetal_chassis_list = ironicclient.osc.v1.baremetal_chassis:ListBaremetalChassis baremetal_chassis_set = ironicclient.osc.v1.baremetal_chassis:SetBaremetalChassis baremetal_chassis_show = ironicclient.osc.v1.baremetal_chassis:ShowBaremetalChassis baremetal_chassis_unset = ironicclient.osc.v1.baremetal_chassis:UnsetBaremetalChassis,,908,0
openstack%2Fkolla-kubernetes~master~Id95c2f0d891882a6cc91a8248156c998a204a294,openstack/kolla-kubernetes,master,Id95c2f0d891882a6cc91a8248156c998a204a294,"Deployment, Readiness, Safe Shutdown, & Scaling for glance",MERGED,2016-08-12 18:31:02.000000000,2016-08-29 21:52:38.000000000,2016-08-29 21:52:38.000000000,"[{'_account_id': 3}, {'_account_id': 9237}, {'_account_id': 10419}, {'_account_id': 19384}, {'_account_id': 22143}]","[{'number': 1, 'created': '2016-08-12 18:31:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-kubernetes/commit/ec2b7504d259eb2f7b8289be29b9f17403ca9353', 'message': 'WIP - Deployment, Safe Shutdown, & Scaling for glance-api\n\nThis patch switches glance-api over to use the k8s deployment type.\nIt also puts an haproxy in front of it so it can safely be drained\nto perform rolling upgrades/node migrations and scale down. Lastly,\nit removes an unneeded volume when ceph direct access is configured.\n\nChange-Id: Id95c2f0d891882a6cc91a8248156c998a204a294\n'}, {'number': 2, 'created': '2016-08-12 18:41:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-kubernetes/commit/0ba81d39d20db137f14bad482114c163b13f845d', 'message': 'WIP - Deployment, Safe Shutdown, & Scaling for glance-api\n\nThis patch switches glance-api over to use the k8s deployment type.\nIt also puts an haproxy in front of it so it can safely be drained\nto perform rolling upgrades/node migrations and scale down. Lastly,\nit removes an unneeded volume when ceph direct access is configured.\n\nChange-Id: Id95c2f0d891882a6cc91a8248156c998a204a294\n'}, {'number': 3, 'created': '2016-08-12 18:42:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-kubernetes/commit/a95c19c2ed063c0aecb28d0a4952e7bd5fc7bd1e', 'message': 'WIP - Deployment, Safe Shutdown, & Scaling for glance-api\n\nThis patch switches glance-api over to use the k8s deployment type.\nIt also puts an haproxy in front of it so it can safely be drained\nto perform rolling upgrades/node migrations and scale down. Lastly,\nit removes an unneeded volume when ceph direct access is configured.\n\nChange-Id: Id95c2f0d891882a6cc91a8248156c998a204a294\n'}, {'number': 4, 'created': '2016-08-12 18:43:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-kubernetes/commit/e5808ba72a61954be25fbd8da563102475fad198', 'message': 'WIP - Deployment, Safe Shutdown, & Scaling for glance-api\n\nThis patch switches glance-api over to use the k8s deployment type.\nIt also puts an haproxy in front of it so it can safely be drained\nto perform rolling upgrades/node migrations and scale down. Lastly,\nit removes an unneeded volume when ceph direct access is configured.\n\nChange-Id: Id95c2f0d891882a6cc91a8248156c998a204a294\n'}, {'number': 5, 'created': '2016-08-17 18:21:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-kubernetes/commit/bed5c997ff12bcb6dae7de8223c7dc72f7078d56', 'message': 'WIP - Deployment, Safe Shutdown, & Scaling for glance-api\n\nThis patch switches glance-api over to use the k8s deployment type.\nIt also puts an haproxy in front of it so it can safely be drained\nto perform rolling upgrades/node migrations and scale down. Lastly,\nit removes an unneeded volume when ceph direct access is configured.\n\nChange-Id: Id95c2f0d891882a6cc91a8248156c998a204a294\n'}, {'number': 6, 'created': '2016-08-17 18:23:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-kubernetes/commit/65ed5797929c62beb0904460fa88864f3a6d72df', 'message': 'WIP - Deployment, Safe Shutdown, & Scaling for glance-api\n\nThis patch switches glance-api over to use the k8s deployment type.\nIt also puts an haproxy in front of it so it can safely be drained\nto perform rolling upgrades/node migrations and scale down. Lastly,\nit removes an unneeded volume when ceph direct access is configured.\n\nChange-Id: Id95c2f0d891882a6cc91a8248156c998a204a294\n'}, {'number': 7, 'created': '2016-08-17 18:52:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-kubernetes/commit/3dcc062bb61f25a61dd2d6ebb15a6a99249146bf', 'message': 'WIP - Deployment, Safe Shutdown, & Scaling for glance-api\n\nThis patch switches glance-api over to use the k8s deployment type.\nIt also puts an haproxy in front of it so it can safely be drained\nto perform rolling upgrades/node migrations and scale down. Lastly,\nit removes an unneeded volume when ceph direct access is configured.\n\nChange-Id: Id95c2f0d891882a6cc91a8248156c998a204a294\n'}, {'number': 8, 'created': '2016-08-17 19:29:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-kubernetes/commit/d748521872ef058156fd08b7463dade680b0f130', 'message': 'WIP - Deployment, Safe Shutdown, & Scaling for glance-api\n\nThis patch switches glance-api over to use the k8s deployment type.\nIt also puts an haproxy in front of it so it can safely be drained\nto perform rolling upgrades/node migrations and scale down. Lastly,\nit removes an unneeded volume when ceph direct access is configured.\n\nChange-Id: Id95c2f0d891882a6cc91a8248156c998a204a294\n'}, {'number': 9, 'created': '2016-08-17 22:14:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-kubernetes/commit/85758bc6afb024b3410dc837ec10398cff4a7a68', 'message': 'Deployment, Readiness, Safe Shutdown, & Scaling for glance-api\n\nThis patch switches glance-api over to use the k8s deployment type.\nIt also puts an haproxy in front of it so it can safely be drained\nto perform rolling upgrades/node migrations and scale down. It\nblocks access until the service is up via readiness probe. Lastly,\nit removes an unneeded volume when ceph direct access is configured.\n\nChange-Id: Id95c2f0d891882a6cc91a8248156c998a204a294\n'}, {'number': 10, 'created': '2016-08-18 18:21:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-kubernetes/commit/33ef84453a0347e2ed4fbb3c0c89f1cdb510e404', 'message': 'Deployment, Readiness, Safe Shutdown, & Scaling for glance-api\n\nThis patch switches glance-api over to use the k8s deployment type.\nIt also puts an haproxy in front of it so it can safely be drained\nto perform rolling upgrades/node migrations and scale down. It\nblocks access until the service is up via readiness probe. Lastly,\nit removes an unneeded volume when ceph direct access is configured.\n\nChange-Id: Id95c2f0d891882a6cc91a8248156c998a204a294\n'}, {'number': 11, 'created': '2016-08-18 21:03:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-kubernetes/commit/a481b07f92d8a75287ae117370dcf8366efcffa4', 'message': 'Deployment, Readiness, Safe Shutdown, & Scaling for glance-api\n\nThis patch switches glance-api over to use the k8s deployment type.\nIt also puts an haproxy in front of it so it can safely be drained\nto perform rolling upgrades/node migrations and scale down. It\nblocks access until the service is up via readiness probe. Lastly,\nit removes an unneeded volume when ceph direct access is configured.\n\nChange-Id: Id95c2f0d891882a6cc91a8248156c998a204a294\n'}, {'number': 12, 'created': '2016-08-23 16:20:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-kubernetes/commit/59302f0d02a8437ad89981932bcf9331bc732cb7', 'message': 'Deployment, Readiness, Safe Shutdown, & Scaling for glance\n\nThis patch switches glance over to use the k8s deployment type.\nIt also puts an haproxy in front of it so it can safely be drained\nto perform rolling upgrades/node migrations and scale down. It\nblocks access until the service is up via readiness probe. Lastly,\nit removes an unneeded volume when ceph direct access is configured.\n\nChange-Id: Id95c2f0d891882a6cc91a8248156c998a204a294\n'}, {'number': 13, 'created': '2016-08-23 18:27:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-kubernetes/commit/10276ffd752808afbfe22cd2b195aa2717d4c9da', 'message': 'Deployment, Readiness, Safe Shutdown, & Scaling for glance\n\nThis patch switches glance over to use the k8s deployment type.\nIt also puts an haproxy in front of it so it can safely be drained\nto perform rolling upgrades/node migrations and scale down. It\nblocks access until the service is up via readiness probe. Lastly,\nit removes an unneeded volume when ceph direct access is configured.\nIt also makes the glance services externally available.\n\nChange-Id: Id95c2f0d891882a6cc91a8248156c998a204a294\n'}, {'number': 14, 'created': '2016-08-24 00:22:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-kubernetes/commit/d0377fcd7b5d9c6ba5efe240c523dec0ae1af4e1', 'message': 'Deployment, Readiness, Safe Shutdown, & Scaling for glance\n\nThis patch switches glance over to use the k8s deployment type.\nIt also puts an haproxy in front of it so it can safely be drained\nto perform rolling upgrades/node migrations and scale down. It\nblocks access until the service is up via readiness probe. Lastly,\nit removes an unneeded volume when ceph direct access is configured.\nIt also makes the glance services externally available.\n\nChange-Id: Id95c2f0d891882a6cc91a8248156c998a204a294\n'}, {'number': 15, 'created': '2016-08-24 18:30:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-kubernetes/commit/62066ca376851563f16ee110e3827af73cae0bef', 'message': 'Deployment, Readiness, Safe Shutdown, & Scaling for glance\n\nThis patch switches glance over to use the k8s deployment type.\nIt also puts an haproxy in front of it so it can safely be drained\nto perform rolling upgrades/node migrations and scale down. It\nblocks access until the service is up via readiness probe. Lastly,\nit removes an unneeded volume when ceph direct access is configured.\nIt also makes the glance services externally available.\n\nChange-Id: Id95c2f0d891882a6cc91a8248156c998a204a294\n'}, {'number': 16, 'created': '2016-08-24 19:58:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-kubernetes/commit/cc559afc797444a630027dea9653be498f414f9b', 'message': 'Deployment, Readiness, Safe Shutdown, & Scaling for glance\n\nThis patch switches glance over to use the k8s deployment type.\nIt also puts an haproxy in front of it so it can safely be drained\nto perform rolling upgrades/node migrations and scale down. It\nblocks access until the service is up via readiness probe. Lastly,\nit removes an unneeded volume when ceph direct access is configured.\nIt also makes the glance services externally available.\n\nPartially-Implements: blueprint deployments\nPartially-Implements: blueprint kolla-kubernetes-service-exposure\nPartially-Implements: blueprint api-termination\n\nChange-Id: Id95c2f0d891882a6cc91a8248156c998a204a294\n'}, {'number': 17, 'created': '2016-08-25 16:12:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-kubernetes/commit/0d5fa7f541b9d33298105498ead3501bd69aff7a', 'message': 'Deployment, Readiness, Safe Shutdown, & Scaling for glance\n\nThis patch switches glance over to use the k8s deployment type.\nIt also puts an haproxy in front of it so it can safely be drained\nto perform rolling upgrades/node migrations and scale down. It\nblocks access until the service is up via readiness probe. Lastly,\nit removes an unneeded volume when ceph direct access is configured.\nIt also makes the glance services externally available.\n\nPartially-Implements: blueprint deployments\nPartially-Implements: blueprint kolla-kubernetes-service-exposure\nPartially-Implements: blueprint api-termination\n\nChange-Id: Id95c2f0d891882a6cc91a8248156c998a204a294\n'}, {'number': 18, 'created': '2016-08-25 22:29:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-kubernetes/commit/c0d9056e9bd4b46886d2d979025c987ff1443e2b', 'message': 'Deployment, Readiness, Safe Shutdown, & Scaling for glance\n\nThis patch switches glance over to use the k8s deployment type.\nIt also puts an haproxy in front of it so it can safely be drained\nto perform rolling upgrades/node migrations and scale down. It\nblocks access until the service is up via readiness probe. Lastly,\nit removes an unneeded volume when ceph direct access is configured.\nIt also makes the glance services externally available.\n\nPartially-Implements: blueprint deployments\nPartially-Implements: blueprint kolla-kubernetes-service-exposure\nPartially-Implements: blueprint api-termination\n\nChange-Id: Id95c2f0d891882a6cc91a8248156c998a204a294\n'}, {'number': 19, 'created': '2016-08-25 22:36:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-kubernetes/commit/0cf8c011b9a841def8402b4aa0c4fedfd1905932', 'message': 'Deployment, Readiness, Safe Shutdown, & Scaling for glance\n\nThis patch switches glance over to use the k8s deployment type.\nIt also puts an haproxy in front of it so it can safely be drained\nto perform rolling upgrades/node migrations and scale down. It\nblocks access until the service is up via readiness probe. Lastly,\nit removes an unneeded volume when ceph direct access is configured.\nIt also makes the glance services externally available.\n\nPartially-Implements: blueprint deployments\nPartially-Implements: blueprint kolla-kubernetes-service-exposure\nPartially-Implements: blueprint api-termination\n\nChange-Id: Id95c2f0d891882a6cc91a8248156c998a204a294\n'}, {'number': 20, 'created': '2016-08-29 19:04:15.000000000', 'files': ['services/common/api-haproxy-configmap.yml.j2', 'services/glance/glance-api-pod.yml.j2', 'services/glance/glance-bootstrap-job.yml.j2', 'services/glance/glance-registry-pod.yml.j2', 'kolla_kubernetes/service_resources.py', 'services/glance/glance-registry-service.yml.j2', 'etc/kolla-kubernetes/service_resources.yml', 'services/glance/glance-api-service.yml.j2'], 'web_link': 'https://opendev.org/openstack/kolla-kubernetes/commit/6fa5b0273d2d6b8c63e7ba6011fe3cb782ca7186', 'message': 'Deployment, Readiness, Safe Shutdown, & Scaling for glance\n\nThis patch switches glance over to use the k8s deployment type.\nIt also puts an haproxy in front of it so it can safely be drained\nto perform rolling upgrades/node migrations and scale down. It\nblocks access until the service is up via readiness probe. Lastly,\nit removes an unneeded volume when ceph direct access is configured.\nIt also makes the glance services externally available.\n\nWe need to add more haproxy support in the cli as a follow up.\n\nPartially-Implements: blueprint deployments\nPartially-Implements: blueprint kolla-kubernetes-service-exposure\nPartially-Implements: blueprint api-termination\n\nChange-Id: Id95c2f0d891882a6cc91a8248156c998a204a294\n'}]",21,354895,6fa5b0273d2d6b8c63e7ba6011fe3cb782ca7186,70,5,20,9237,,,0,"Deployment, Readiness, Safe Shutdown, & Scaling for glance

This patch switches glance over to use the k8s deployment type.
It also puts an haproxy in front of it so it can safely be drained
to perform rolling upgrades/node migrations and scale down. It
blocks access until the service is up via readiness probe. Lastly,
it removes an unneeded volume when ceph direct access is configured.
It also makes the glance services externally available.

We need to add more haproxy support in the cli as a follow up.

Partially-Implements: blueprint deployments
Partially-Implements: blueprint kolla-kubernetes-service-exposure
Partially-Implements: blueprint api-termination

Change-Id: Id95c2f0d891882a6cc91a8248156c998a204a294
",git fetch https://review.opendev.org/openstack/kolla-kubernetes refs/changes/95/354895/17 && git format-patch -1 --stdout FETCH_HEAD,"['services/glance/glance-api-pod.yml.j2', 'kolla_kubernetes/service_resources.py', 'etc/kolla-kubernetes/service_resources.yml']",3,ec2b7504d259eb2f7b8289be29b9f17403ca9353,bp/deployments, - name: glance-api-haproxy-configmap template: services/glance/glance-api-haproxy-configmap.yml.j2,,57,10
openstack%2Fironic-python-agent~stable%2Fmitaka~Ib5c0c57cafdb6ffd7456e61f3b1bb5fa57520e5a,openstack/ironic-python-agent,stable/mitaka,Ib5c0c57cafdb6ffd7456e61f3b1bb5fa57520e5a,Enforce upper-constraints when building ramdisks,MERGED,2016-08-25 21:13:16.000000000,2016-08-29 21:45:40.000000000,2016-08-29 21:45:40.000000000,"[{'_account_id': 3}, {'_account_id': 2889}, {'_account_id': 7080}, {'_account_id': 10343}, {'_account_id': 14760}]","[{'number': 1, 'created': '2016-08-25 21:13:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/00dfd54eb4f3d572545a355e9e5d2bb8a3890a25', 'message': 'Enforce upper-constraints when building ramdisks\n\nCurrently, building ramdisks installs ironic-python-agent without any\nupper-constraints. This causes the package to be installed with newer,\nuntested dependencies.\n\nThis commits introduces a tool to generate a local upper-constraints\nfile based on predefined strategies (below). Additionally, the fallback\nto the openstack/requirements uses the URL defined in tox.ini instead of\nredefining it. This prevents having to keep track of two separate\nvariables when releasing.\n\nupper-constraints lookup strategies (in order):\n\n  * UPPER_CONSTRAINTS_FILE points to a local file\n  * UPPER_CONSTRAINTS_FILE points to a URL\n  * /opt/stack/new/requirements/upper-constraints.txt\n  * upper-constraints.txt from openstack/requirements git repository\n\nPartial-bug: #1616554\nChange-Id: Ib5c0c57cafdb6ffd7456e61f3b1bb5fa57520e5a\nCherry-picked-from: f7ead01f12ce799a29e46b50be936ff3d812f904\n'}, {'number': 2, 'created': '2016-08-25 23:43:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/b5345db8c3e6bf3944e5cd9d061f1493841ff3cf', 'message': 'Enforce upper-constraints when building ramdisks\n\nCurrently, building ramdisks installs ironic-python-agent without any\nupper-constraints. This causes the package to be installed with newer,\nuntested dependencies.\n\nThis commits introduces a tool to generate a local upper-constraints\nfile based on predefined strategies (below). Additionally, the fallback\nto the openstack/requirements uses the URL defined in tox.ini instead of\nredefining it. This prevents having to keep track of two separate\nvariables when releasing.\n\nupper-constraints lookup strategies (in order):\n\n  * UPPER_CONSTRAINTS_FILE points to a local file\n  * UPPER_CONSTRAINTS_FILE points to a URL\n  * /opt/stack/new/requirements/upper-constraints.txt\n  * upper-constraints.txt from openstack/requirements git repository\n\nPartial-bug: #1616554\nChange-Id: Ib5c0c57cafdb6ffd7456e61f3b1bb5fa57520e5a\nCherry-picked-from: f7ead01f12ce799a29e46b50be936ff3d812f904\n'}, {'number': 3, 'created': '2016-08-26 12:32:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/2a37f90d2cd6e895c6620fa4caf002f090c1f482', 'message': 'Enforce upper-constraints when building ramdisks\n\nCurrently, building ramdisks installs ironic-python-agent without any\nupper-constraints. This causes the package to be installed with newer,\nuntested dependencies.\n\nThis commits introduces a tool to generate a local upper-constraints\nfile based on predefined strategies (below). Additionally, the fallback\nto the openstack/requirements uses the URL defined in tox.ini instead of\nredefining it. This prevents having to keep track of two separate\nvariables when releasing.\n\nupper-constraints lookup strategies (in order):\n\n  * UPPER_CONSTRAINTS_FILE points to a local file\n  * UPPER_CONSTRAINTS_FILE points to a URL\n  * /opt/stack/new/requirements/upper-constraints.txt\n  * upper-constraints.txt from openstack/requirements git repository\n\nPartial-bug: #1616554\nChange-Id: Ib5c0c57cafdb6ffd7456e61f3b1bb5fa57520e5a\n(cherry picked from commit f7ead01f12ce799a29e46b50be936ff3d812f904)\n'}, {'number': 4, 'created': '2016-08-26 12:35:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/114b64b5b4d5c9976579fa4d046d88f0b417a782', 'message': 'Enforce upper-constraints when building ramdisks\n\nCurrently, building ramdisks installs ironic-python-agent without any\nupper-constraints. This causes the package to be installed with newer,\nuntested dependencies.\n\nThis commits introduces a tool to generate a local upper-constraints\nfile based on predefined strategies (below). Additionally, the fallback\nto the openstack/requirements uses the URL defined in tox.ini instead of\nredefining it. This prevents having to keep track of two separate\nvariables when releasing.\n\nupper-constraints lookup strategies (in order):\n\n  * UPPER_CONSTRAINTS_FILE points to a local file\n  * UPPER_CONSTRAINTS_FILE points to a URL\n  * /opt/stack/new/requirements/upper-constraints.txt\n  * upper-constraints.txt from openstack/requirements git repository\n\nPartial-bug: #1616554\nChange-Id: Ib5c0c57cafdb6ffd7456e61f3b1bb5fa57520e5a\n(cherry picked from commit f7ead01f12ce799a29e46b50be936ff3d812f904)\n'}, {'number': 5, 'created': '2016-08-26 15:17:00.000000000', 'files': ['imagebuild/common/extract_upper_constraints_from_tox_ini.sh', 'imagebuild/common/generate_upper_constraints.sh', 'Dockerfile', '.gitignore', 'imagebuild/tinyipa/build-tinyipa.sh', 'imagebuild/coreos/docker_build.bash', 'imagebuild/tinyipa/finalise-tinyipa.sh'], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/0a8abdd462f9a6acc3571a95147c19752416f14e', 'message': 'Enforce upper-constraints when building ramdisks\n\nCurrently, building ramdisks installs ironic-python-agent without any\nupper-constraints. This causes the package to be installed with newer,\nuntested dependencies.\n\nThis commits introduces a tool to generate a local upper-constraints\nfile based on predefined strategies (below). Additionally, the fallback\nto the openstack/requirements uses the URL defined in tox.ini instead of\nredefining it. This prevents having to keep track of two separate\nvariables when releasing.\n\nupper-constraints lookup strategies (in order):\n\n  * UPPER_CONSTRAINTS_FILE points to a local file\n  * UPPER_CONSTRAINTS_FILE points to a URL\n  * /opt/stack/new/requirements/upper-constraints.txt\n  * upper-constraints.txt from openstack/requirements git repository\n\nPartial-bug: #1616554\nChange-Id: Ib5c0c57cafdb6ffd7456e61f3b1bb5fa57520e5a\n(cherry picked from commit a0ca6ce157b8a84f282d8abbdd27c75f48d991ff)\n'}]",1,360795,0a8abdd462f9a6acc3571a95147c19752416f14e,20,5,5,7080,,,0,"Enforce upper-constraints when building ramdisks

Currently, building ramdisks installs ironic-python-agent without any
upper-constraints. This causes the package to be installed with newer,
untested dependencies.

This commits introduces a tool to generate a local upper-constraints
file based on predefined strategies (below). Additionally, the fallback
to the openstack/requirements uses the URL defined in tox.ini instead of
redefining it. This prevents having to keep track of two separate
variables when releasing.

upper-constraints lookup strategies (in order):

  * UPPER_CONSTRAINTS_FILE points to a local file
  * UPPER_CONSTRAINTS_FILE points to a URL
  * /opt/stack/new/requirements/upper-constraints.txt
  * upper-constraints.txt from openstack/requirements git repository

Partial-bug: #1616554
Change-Id: Ib5c0c57cafdb6ffd7456e61f3b1bb5fa57520e5a
(cherry picked from commit a0ca6ce157b8a84f282d8abbdd27c75f48d991ff)
",git fetch https://review.opendev.org/openstack/ironic-python-agent refs/changes/95/360795/4 && git format-patch -1 --stdout FETCH_HEAD,"['imagebuild/common/extract_upper_constraints_from_tox_ini.sh', 'imagebuild/common/generate_upper_constraints.sh', 'Dockerfile', '.gitignore', 'imagebuild/tinyipa/build-tinyipa.sh', 'imagebuild/coreos/docker_build.bash', 'imagebuild/tinyipa/finalise-tinyipa.sh']",7,00dfd54eb4f3d572545a355e9e5d2bb8a3890a25,bug/1616554, cp -a $BUILDDIR/tmp/upper-constraints.txt $FINALDIR/tmp/upper-constraints.txt $CHROOT_CMD python /tmp/get-pip.py -c /tmp/upper-constraints.txt --no-wheel --no-index --find-links=file:///tmp/wheelhouse ironic_python_agent rm -rf $FINALDIR/tmp/upper-constraints.txt, $CHROOT_CMD python /tmp/get-pip.py --no-wheel --no-index --find-links=file:///tmp/wheelhouse ironic_python_agent,108,8
openstack%2Fopenstack-ansible-rabbitmq_server~master~Ie349528929398f53a9d87e7fc02e0c95c9d6d4f1,openstack/openstack-ansible-rabbitmq_server,master,Ie349528929398f53a9d87e7fc02e0c95c9d6d4f1,"Add collect_statistics_interval, rates_mode in rabbitmq.config template",MERGED,2016-08-29 17:38:15.000000000,2016-08-29 21:43:47.000000000,2016-08-29 19:13:39.000000000,"[{'_account_id': 3}, {'_account_id': 7353}, {'_account_id': 14805}, {'_account_id': 16197}]","[{'number': 1, 'created': '2016-08-29 17:38:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-rabbitmq_server/commit/ca2479f5a35bad4c4aeded68f878ffd5296be3f2', 'message': 'Add collect_statistics_interval, rates_mode in rabbitmq.config template\n\n1. Add collect_statistics_interval and rates_mode configurations in\nrabbitmq.config template which enables to define custom value for\nthose fields.\n2. Variables to be defined in /etc/openstack_deploy/user_variables.yml\nfor updating the collect_statistics_interval,rates_mode default values,\nrabbitmq_collect_statistics_interval: 30000\nrabbitmq_management_rates_mode: none\n\nChange-Id: Ie349528929398f53a9d87e7fc02e0c95c9d6d4f1\nCloses-bug: 1617516\n'}, {'number': 2, 'created': '2016-08-29 18:02:42.000000000', 'files': ['templates/rabbitmq.config.j2', 'defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-rabbitmq_server/commit/9ccc0ee3f113963de78548ceca756491023d4f05', 'message': 'Add collect_statistics_interval, rates_mode in rabbitmq.config template\n\n1. Add collect_statistics_interval and rates_mode configurations in\nrabbitmq.config template which enables to define custom value for\nthose fields.\n2. Add collect_statistics_interval and rates_mode defaults in\ndefaults/main.yml\n\nChange-Id: Ie349528929398f53a9d87e7fc02e0c95c9d6d4f1\nCloses-bug: 1617516\n'}]",3,362297,9ccc0ee3f113963de78548ceca756491023d4f05,13,4,2,16027,,,0,"Add collect_statistics_interval, rates_mode in rabbitmq.config template

1. Add collect_statistics_interval and rates_mode configurations in
rabbitmq.config template which enables to define custom value for
those fields.
2. Add collect_statistics_interval and rates_mode defaults in
defaults/main.yml

Change-Id: Ie349528929398f53a9d87e7fc02e0c95c9d6d4f1
Closes-bug: 1617516
",git fetch https://review.opendev.org/openstack/openstack-ansible-rabbitmq_server refs/changes/97/362297/1 && git format-patch -1 --stdout FETCH_HEAD,['templates/rabbitmq.config.j2'],1,ca2479f5a35bad4c4aeded68f878ffd5296be3f2,bug/1617516," {collect_statistics_interval, {{ rabbitmq_collect_statistics_interval | default(5000) }} }, ]}, {rabbitmq_management, [{rates_mode, {{ rabbitmq_management_rates_mode | default('basic') }} }] }", ]},3,1
openstack%2Fkeystone~master~I36c4bdb73dedfb896325165f5e14a7e1baf36511,openstack/keystone,master,I36c4bdb73dedfb896325165f5e14a7e1baf36511,Fix cache invalidation,ABANDONED,2016-06-09 19:02:15.000000000,2016-08-29 21:41:23.000000000,,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 2903}, {'_account_id': 5046}, {'_account_id': 6482}, {'_account_id': 6486}, {'_account_id': 7156}, {'_account_id': 7725}, {'_account_id': 13055}, {'_account_id': 13478}]","[{'number': 1, 'created': '2016-06-09 19:02:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/7e05b2942bde2137a5510e69d2b3b33a89161954', 'message': 'Fix cache invalidation\n\nThe last argument passed to setattr() was evaluated before being\npassed. It resulted in setters and deleters not being set to\nrequired attributes, leaving us without cross-process cache\ninvalidation.\n\nPass object with descriptors instead instead.\n\nCloses-Bug: 1590779\nChange-Id: I36c4bdb73dedfb896325165f5e14a7e1baf36511\n'}, {'number': 2, 'created': '2016-06-09 19:03:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/e1e8d8e2eb12838cf59b8c2b800c2eed6917f1db', 'message': 'Fix cache invalidation\n\nThe last argument passed to setattr() was evaluated before being\npassed. It resulted in setters and deleters not being set to\nrequired attributes, leaving us without cross-process cache\ninvalidation.\n\nPass object with descriptors instead instead.\n\nCloses-Bug: 1590779\nChange-Id: I36c4bdb73dedfb896325165f5e14a7e1baf36511\n'}, {'number': 3, 'created': '2016-06-09 19:11:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/abdd240ff205c83d578e1e5ec71aa6b5c6e4ca27', 'message': 'Fix cache invalidation\n\nThe last argument passed to setattr() was evaluated before being\npassed. It resulted in setters and deleters not being set to\nrequired attributes, leaving us without cross-process cache\ninvalidation.\n\nPass object with descriptors instead instead.\n\nCloses-Bug: 1590779\nChange-Id: I36c4bdb73dedfb896325165f5e14a7e1baf36511\n'}, {'number': 4, 'created': '2016-06-09 19:15:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/aaf338570fe5feaec4ad25ff8a0ae84dc535a726', 'message': 'Fix cache invalidation\n\nThe last argument passed to setattr() was evaluated before being\npassed. It resulted in setters and deleters not being set to\nrequired attributes, leaving us without cross-process cache\ninvalidation.\n\nPass object with descriptors instead instead.\n\nCloses-Bug: 1590779\nChange-Id: I36c4bdb73dedfb896325165f5e14a7e1baf36511\n'}, {'number': 5, 'created': '2016-06-09 20:07:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/1903e9fed6e3e1cc6e1b5e13ade7d434bf3bdd35', 'message': 'Fix cache invalidation\n\nThe last argument passed to setattr() was evaluated before being\npassed. It resulted in setters and deleters not being set to\nrequired attributes, leaving us without cross-process cache\ninvalidation.\n\nPass object with descriptors instead instead.\n\nCloses-Bug: 1590779\nChange-Id: I36c4bdb73dedfb896325165f5e14a7e1baf36511\n'}, {'number': 6, 'created': '2016-06-09 20:57:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/b257b96db194754d24364421d7f0de041f70821d', 'message': 'Fix cache invalidation\n\nThe last argument passed to setattr() was evaluated before being\npassed. It resulted in setters and deleters not being set to\nrequired attributes, leaving us without cross-process cache\ninvalidation.\n\nPass object with descriptors instead instead.\n\nCloses-Bug: 1590779\nChange-Id: I36c4bdb73dedfb896325165f5e14a7e1baf36511\n'}, {'number': 7, 'created': '2016-06-09 22:44:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/bdba65e055928d339cb9fcca61af58f0b88f680f', 'message': 'Fix cache invalidation\n\nThe last argument passed to setattr() was evaluated before being\npassed. It resulted in setters and deleters not being set to\nrequired attributes, leaving us without cross-process cache\ninvalidation.\n\nPass object with descriptors instead instead.\n\nCloses-Bug: 1590779\nChange-Id: I36c4bdb73dedfb896325165f5e14a7e1baf36511\n'}, {'number': 8, 'created': '2016-07-05 16:26:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/cfbd706c5bf6726ed4a3c2fd1aa36626cd3fe956', 'message': 'Fix cache invalidation\n\nThe last argument passed to setattr() was evaluated before being\npassed. It resulted in setters and deleters not being set to\nrequired attributes, leaving us without cross-process cache\ninvalidation.\n\nPass object with descriptors instead instead.\n\nCloses-Bug: 1590779\nChange-Id: I36c4bdb73dedfb896325165f5e14a7e1baf36511\n'}, {'number': 9, 'created': '2016-07-18 16:01:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/d2bb927c081da8bff78ce571ed82b18dd27a79dc', 'message': 'Fix cache invalidation\n\nThe last argument passed to setattr() was evaluated before being\npassed. It resulted in setters and deleters not being set to\nrequired attributes, leaving us without cross-process cache\ninvalidation.\n\nPass object with descriptors instead instead.\n\nCloses-Bug: 1590779\nChange-Id: I36c4bdb73dedfb896325165f5e14a7e1baf36511\n'}, {'number': 10, 'created': '2016-07-18 17:06:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/9f6fcdd4a09470d51fd881783e7f51ee8749fb0e', 'message': 'Fix cache invalidation\n\nThe last argument passed to setattr() was evaluated before being\npassed. It resulted in setters and deleters not being set to\nrequired attributes, leaving us without cross-process cache\ninvalidation.\n\nPass object with descriptors instead instead.\n\nCloses-Bug: 1590779\nChange-Id: I36c4bdb73dedfb896325165f5e14a7e1baf36511\n'}, {'number': 11, 'created': '2016-07-28 13:19:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/e9fa90afec47f4f2428f5f674e819f25fb68aded', 'message': 'Fix cache invalidation\n\nThe last argument passed to setattr() was evaluated before being\npassed. It resulted in setters and deleters not being set to\nrequired attributes, leaving us without cross-process cache\ninvalidation.\n\nPass object with descriptors instead instead.\n\nCloses-Bug: 1590779\nChange-Id: I36c4bdb73dedfb896325165f5e14a7e1baf36511\n'}, {'number': 12, 'created': '2016-07-28 13:21:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/1569705a5df783eb653b2afe0b5417f22b6859bf', 'message': 'Fix cache invalidation\n\nThe last argument passed to setattr() was evaluated before being\npassed. It resulted in setters and deleters not being set to\nrequired attributes, leaving us without cross-process cache\ninvalidation.\n\nPass object with descriptors instead instead.\n\nCloses-Bug: 1590779\nChange-Id: I36c4bdb73dedfb896325165f5e14a7e1baf36511\n'}, {'number': 13, 'created': '2016-07-28 23:22:08.000000000', 'files': ['keystone/tests/unit/common/test_utils.py', 'keystone/token/provider.py', 'keystone/identity/core.py', 'keystone/assignment/core.py', 'keystone/catalog/core.py', 'keystone/common/cache/core.py', 'keystone/server/backends.py', 'keystone/revoke/core.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/639b1c378f8881dac6c4b7615d039ee0838ad1fc', 'message': 'Fix cache invalidation\n\nThe last argument passed to setattr() was evaluated before being\npassed. It resulted in setters and deleters not being set to\nrequired attributes, leaving us without cross-process cache\ninvalidation.\n\nPass object with descriptors instead instead.\n\nCloses-Bug: 1590779\nChange-Id: I36c4bdb73dedfb896325165f5e14a7e1baf36511\n'}]",20,327885,639b1c378f8881dac6c4b7615d039ee0838ad1fc,46,10,13,13478,,,0,"Fix cache invalidation

The last argument passed to setattr() was evaluated before being
passed. It resulted in setters and deleters not being set to
required attributes, leaving us without cross-process cache
invalidation.

Pass object with descriptors instead instead.

Closes-Bug: 1590779
Change-Id: I36c4bdb73dedfb896325165f5e14a7e1baf36511
",git fetch https://review.opendev.org/openstack/keystone refs/changes/85/327885/1 && git format-patch -1 --stdout FETCH_HEAD,['keystone/common/cache/core.py'],1,7e05b2942bde2137a5510e69d2b3b33a89161954,bug/1590779,"# TODO(morganfainberg): Move this logic up into oslo.cache directly # so we can handle region-wide invalidations or alternatively propose # a fix to dogpile.cache to make region-wide invalidates possible to # work across distributed processes. class Invalidated(object): def __init__(self, region, region_name, invalidate_type): self.invalidate_type = invalidate_type self.region = region self.region_name = region_name self.region_key = '_RegionExpiration.%(type)s.%(region_name)s' % { 'type': invalidate_type, 'region_name': region_name} def __get__(self, obj, objtype=None): invalidated = self.region.backend.get(self.hard_region_key) if invalidated is not api.NO_VALUE: return invalidated.payload return None def __set__(self, obj, value): self.region.set(self.region_key, value) def __delete__(self, obj): self.region.delete(self.region_key) setattr(region, '_hard_invalidated', Invalidated(region, region_name, 'hard')) setattr(region, '_soft_invalidated', Invalidated(region, region_name, 'soft'))"," invalidator = _RegionInvalidator(region=region, region_name=region_name) setattr(region, '_hard_invalidated', invalidator.hard_invalidated) setattr(region, '_soft_invalidated', invalidator.soft_invalidated)",28,3
openstack%2Fproject-config~master~I9d0c7e12ffbe2afc32a2acad0ce9f0d4e1da4499,openstack/project-config,master,I9d0c7e12ffbe2afc32a2acad0ce9f0d4e1da4499,tripleo: align CI scenarios with Puppet CI,MERGED,2016-08-26 19:25:16.000000000,2016-08-29 21:40:22.000000000,2016-08-29 21:40:22.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 6609}]","[{'number': 1, 'created': '2016-08-26 19:25:16.000000000', 'files': ['jenkins/jobs/projects.yaml', 'zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/e4dee739ccbf00dd3849ba4898b1419b735d57fc', 'message': 'tripleo: align CI scenarios with Puppet CI\n\nTripleO has the desire to cover more OpenStack services testing in the\nCI but we also care of saving CI resources.\n\nPuppet CI had the same challenge and we created scenarios, with a\nspecific set of services deployed by each scenario.\n\nTripleO investigated this way and we successfully reproduce the same\nmechanism in our CI.\n\nNow, we would like to align the scenarios from Puppet CI to bring\nconsistency and re-use the feedback from Puppet community.\n\nThis patch is a starter to reproduce Puppet CI:\nhttps://github.com/openstack/puppet-openstack-integration#description\n\n- scenario001 will be a Telemetry scenario with Aodh, Ceilometer and\n  Gnocchi with the rest of compute services.\n- scenario002 will just deploy Cinder with the rest of compute services.\n- scenario003 was scenario001 and will continue to test Sahara with the\n  rest of compute services.\n\nMore consistency, more coverage, without wasting CI resources.\n\nChange-Id: I9d0c7e12ffbe2afc32a2acad0ce9f0d4e1da4499\n'}]",0,361433,e4dee739ccbf00dd3849ba4898b1419b735d57fc,7,3,1,3153,,,0,"tripleo: align CI scenarios with Puppet CI

TripleO has the desire to cover more OpenStack services testing in the
CI but we also care of saving CI resources.

Puppet CI had the same challenge and we created scenarios, with a
specific set of services deployed by each scenario.

TripleO investigated this way and we successfully reproduce the same
mechanism in our CI.

Now, we would like to align the scenarios from Puppet CI to bring
consistency and re-use the feedback from Puppet community.

This patch is a starter to reproduce Puppet CI:
https://github.com/openstack/puppet-openstack-integration#description

- scenario001 will be a Telemetry scenario with Aodh, Ceilometer and
  Gnocchi with the rest of compute services.
- scenario002 will just deploy Cinder with the rest of compute services.
- scenario003 was scenario001 and will continue to test Sahara with the
  rest of compute services.

More consistency, more coverage, without wasting CI resources.

Change-Id: I9d0c7e12ffbe2afc32a2acad0ce9f0d4e1da4499
",git fetch https://review.opendev.org/openstack/project-config refs/changes/33/361433/1 && git format-patch -1 --stdout FETCH_HEAD,"['jenkins/jobs/projects.yaml', 'zuul/layout.yaml']",2,e4dee739ccbf00dd3849ba4898b1419b735d57fc,tripleo/scenarios, - gate-tripleo-ci-centos-7-scenario002-multinode-nv - gate-tripleo-ci-centos-7-scenario003-multinode-nv - ^puppet/services/aodh.*$ - ^manifests/profile/base/aodh.*$ - ^puppet/services/ceilometer.*$ - ^manifests/profile/base/ceilometer.*$ - ^puppet/services/gnocchi.*$ - ^manifests/profile/base/gnocchi.*$ - name : ^gate-tripleo-ci-centos-7-scenario002-multinode.*$ files: - ^puppet/services/cinder.*$ - ^manifests/profile/base/cinder.*$ - name : ^gate-tripleo-ci-centos-7-scenario003-multinode.*$ files:,,30,0
openstack%2Fcinder~master~I423f239a1ac7cd3f3699bb523eece5425cfb005d,openstack/cinder,master,I423f239a1ac7cd3f3699bb523eece5425cfb005d,VMware: Fix upload to image with glance v2,MERGED,2016-07-28 09:55:28.000000000,2016-08-29 21:30:20.000000000,2016-08-28 21:44:15.000000000,"[{'_account_id': 3}, {'_account_id': 6491}, {'_account_id': 9008}, {'_account_id': 11904}, {'_account_id': 16419}, {'_account_id': 21976}, {'_account_id': 22025}]","[{'number': 1, 'created': '2016-07-28 09:55:28.000000000', 'files': ['cinder/tests/unit/volume/drivers/vmware/test_vmware_vmdk.py', 'cinder/volume/drivers/vmware/vmdk.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/4e8f83c540409ece41c857821835df3f21cdfee4', 'message': ""VMware: Fix upload to image with glance v2\n\ncopy_volume_to_image uses an oslo.vmware API which expects a kwarg\n'is_public' that should be set to 'is_public' in the image meta-data.\nGlance v2 replaced 'is_public' with 'visibility' in the image meta-\ndata and therefore upload volume to image fails with KeyError.\n\nChange I9f379f6ada91141da79fd75fbc4a1550a8a06db6 made is_public\noptional in the oslo.vmware API, and hence we do not need to pass it.\nThis patch removes 'is_public' kwarg in the oslo.vmware API call to\nfix the upload error.\n\nCloses-bug: #1596939\nChange-Id: I423f239a1ac7cd3f3699bb523eece5425cfb005d\n""}]",2,348206,4e8f83c540409ece41c857821835df3f21cdfee4,60,7,1,9171,,,0,"VMware: Fix upload to image with glance v2

copy_volume_to_image uses an oslo.vmware API which expects a kwarg
'is_public' that should be set to 'is_public' in the image meta-data.
Glance v2 replaced 'is_public' with 'visibility' in the image meta-
data and therefore upload volume to image fails with KeyError.

Change I9f379f6ada91141da79fd75fbc4a1550a8a06db6 made is_public
optional in the oslo.vmware API, and hence we do not need to pass it.
This patch removes 'is_public' kwarg in the oslo.vmware API call to
fix the upload error.

Closes-bug: #1596939
Change-Id: I423f239a1ac7cd3f3699bb523eece5425cfb005d
",git fetch https://review.opendev.org/openstack/cinder refs/changes/06/348206/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/tests/unit/volume/drivers/vmware/test_vmware_vmdk.py', 'cinder/volume/drivers/vmware/vmdk.py']",2,4e8f83c540409ece41c857821835df3f21cdfee4,bug/1596939, image_version=1)," image_version=1, is_public=image_meta['is_public'])",2,4
openstack%2Fnetworking-ovn~master~I5d36ca94926b12912dc81ec710851e678a0ea470,openstack/networking-ovn,master,I5d36ca94926b12912dc81ec710851e678a0ea470,DNM: Test conventional with native DHCP support,ABANDONED,2016-08-25 20:34:00.000000000,2016-08-29 21:26:49.000000000,,"[{'_account_id': 3}, {'_account_id': 8410}]","[{'number': 1, 'created': '2016-08-25 20:34:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/e0f45fa609d689deb86153bfe091ad452cf0f0b4', 'message': 'DNM: Test conventional with native DHCP support\n\nDo not merge test of conventional with native DHCP support.\n\nChange-Id: I5d36ca94926b12912dc81ec710851e678a0ea470\n'}, {'number': 2, 'created': '2016-08-29 14:47:59.000000000', 'files': ['devstack/devstackgaterc'], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/996f11d6023626eb14585b8b0a50069a470adddc', 'message': 'DNM: Test conventional with native DHCP support\n\nDo not merge test of conventional with native DHCP support.\n\nChange-Id: I5d36ca94926b12912dc81ec710851e678a0ea470\n'}]",0,360777,996f11d6023626eb14585b8b0a50069a470adddc,12,2,2,8410,,,0,"DNM: Test conventional with native DHCP support

Do not merge test of conventional with native DHCP support.

Change-Id: I5d36ca94926b12912dc81ec710851e678a0ea470
",git fetch https://review.opendev.org/openstack/networking-ovn refs/changes/77/360777/2 && git format-patch -1 --stdout FETCH_HEAD,['devstack/devstackgaterc'],1,e0f45fa609d689deb86153bfe091ad452cf0f0b4,dhcp,"export DEVSTACK_LOCAL_CONFIG+=$'\n'""OVN_NATIVE_DHCP=True""","export DEVSTACK_LOCAL_CONFIG+=$'\n'""OVN_NATIVE_DHCP=False""",1,1
openstack%2Ftripleo-heat-templates~master~I68e9c0eee4851706440b1ad0f47a5f8f87c16786,openstack/tripleo-heat-templates,master,I68e9c0eee4851706440b1ad0f47a5f8f87c16786,Enable IPv4/IPv6 dual-stack Public API endpoints,ABANDONED,2016-03-07 11:26:22.000000000,2016-08-29 21:23:35.000000000,,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 12398}, {'_account_id': 21909}]","[{'number': 1, 'created': '2016-03-07 11:26:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/564e3da7a2b4e581d0a7ff8334ead0c6b751edde', 'message': '[WIP] Enable IPv4/IPv6 dual-stack Public API endpoints\n\nThis change adds the option to create two External networks. This\nallows one main External network with IPv6 addresses and allows a\nsecondary External network with IPv4 addresses. Both of the IPs from\nthese two networks will be fed to os-net-config to be added to the\nsame interface.\n\nChanges to the loadbalancer.pp module in puppet-tripleo will allow\nfor dual-stack configuration of the endpoints if the PublicVIP and\nKeystoneAdminVIP are an array containing two IP addresses.\n\nNOTE: This is a work in progress\nTODO: Refactor Public VIP and Keystone Public API VIP  puppet\n      hieradata outputs to be arrays containing both the IPv6\n      and IPv4 addresses.\n\nChange-Id: I68e9c0eee4851706440b1ad0f47a5f8f87c16786\n'}, {'number': 2, 'created': '2016-03-07 11:27:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/c1214e9c5f807d02abcdc23a27e9eaae8bf4ccfc', 'message': '[WIP] Enable IPv4/IPv6 dual-stack Public API endpoints\n\nThis change adds the option to create two External networks. This\nallows one main External network with IPv6 addresses and allows a\nsecondary External network with IPv4 addresses. Both of the IPs from\nthese two networks will be fed to os-net-config to be added to the\nsame interface.\n\nChanges to the loadbalancer.pp module in puppet-tripleo will allow\nfor dual-stack configuration of the endpoints if the PublicVIP and\nKeystoneAdminVIP are an array containing two IP addresses.\n\nNOTE: This is a work in progress\nTODO: Refactor Public VIP and Keystone Public API VIP  puppet\n      hieradata outputs to be arrays containing both the IPv6\n      and IPv4 addresses.\n\nChange-Id: I68e9c0eee4851706440b1ad0f47a5f8f87c16786\n'}, {'number': 3, 'created': '2016-03-08 02:04:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/cc79e56f91a309c0f0936587692777370051cd15', 'message': '[WIP] Enable IPv4/IPv6 dual-stack Public API endpoints\n\nThis change adds the option to create two External networks. This\nallows one main External network with IPv6 addresses and allows a\nsecondary External network with IPv4 addresses. Both of the IPs from\nthese two networks will be fed to os-net-config to be added to the\nsame interface. This change only adds ports on the second external\nnetwork to the controllers, for use by HAProxy.\n\nChanges to the loadbalancer.pp module in puppet-tripleo will allow\nfor dual-stack configuration of the endpoints using the PublicVIP\nand KeystoneAdminVIP as an array containing two IP addresses.\n\nNOTE: This is a work in progress\n\nChange-Id: I68e9c0eee4851706440b1ad0f47a5f8f87c16786\n'}, {'number': 4, 'created': '2016-03-08 04:27:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/3e3213e761d7de2ae10da653666b4f26cc208570', 'message': '[WIP] Enable IPv4/IPv6 dual-stack Public API endpoints\n\nThis change adds the option to create two External networks. This\nallows one main External network with IPv6 addresses and allows a\nsecondary External network with IPv4 addresses. Both of the IPs from\nthese two networks will be fed to os-net-config to be added to the\nsame interface. This change only adds ports on the second external\nnetwork to the controllers, for use by HAProxy.\n\nChanges to the loadbalancer.pp module in puppet-tripleo will allow\nfor dual-stack configuration of the endpoints using the PublicVIP\nand KeystoneAdminVIP as an array containing two IP addresses.\n\nNOTE: This is a work in progress\n\nChange-Id: I68e9c0eee4851706440b1ad0f47a5f8f87c16786\n'}, {'number': 5, 'created': '2016-03-08 17:14:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/e2a50521b44965432e430d655cb3096c0e210476', 'message': '[WIP] Enable IPv4/IPv6 dual-stack Public API endpoints\n\nThis change adds the option to create two External networks. This\nallows one main External network with IPv6 addresses and allows a\nsecondary External network with IPv4 addresses. Both of the IPs from\nthese two networks will be fed to os-net-config to be added to the\nsame interface. This change only adds ports on the second external\nnetwork to the controllers, for use by HAProxy.\n\nChanges to the loadbalancer.pp module in puppet-tripleo will allow\nfor dual-stack configuration of the endpoints using the PublicVIP\nand KeystoneAdminVIP as an array containing two IP addresses.\n\nNOTE: This is a work in progress\n\nChange-Id: I68e9c0eee4851706440b1ad0f47a5f8f87c16786\nDepends-On: I003b6d7d171652654745861d4231882f9e0d373e\n'}, {'number': 6, 'created': '2016-03-14 23:31:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/24d4da71dfd76482121c9f23b5e2d5031cb877bf', 'message': '[WIP] Enable IPv4/IPv6 dual-stack Public API endpoints\n\nThis change adds the option to create two External networks. This\nallows one main External network with IPv6 addresses and allows a\nsecondary External network with IPv4 addresses. Both of the IPs from\nthese two networks will be fed to os-net-config to be added to the\nsame interface. This change only adds ports on the second external\nnetwork to the controllers, for use by HAProxy.\n\nChanges to the loadbalancer.pp module in puppet-tripleo will allow\nfor dual-stack configuration of the endpoints using the PublicVIP\nand KeystoneAdminVIP as an array containing two IP addresses.\n\nNOTE: This is a work in progress\n\nChange-Id: I68e9c0eee4851706440b1ad0f47a5f8f87c16786\nDepends-On: I003b6d7d171652654745861d4231882f9e0d373e\n'}, {'number': 7, 'created': '2016-06-17 19:03:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/98e622e23593f78c6a79536f11c61ee7eada4442', 'message': '[WIP] Enable IPv4/IPv6 dual-stack Public API endpoints\n\nThis change adds the option to create two External networks. This\nallows one main External network with IPv6 addresses and allows a\nsecondary External network with IPv4 addresses. Both of the IPs from\nthese two networks will be fed to os-net-config to be added to the\nsame interface. This change only adds ports on the second external\nnetwork to the controllers, for use by HAProxy.\n\nChanges to the loadbalancer.pp module in puppet-tripleo will allow\nfor dual-stack configuration of the endpoints using the PublicVIP\nand KeystoneAdminVIP as an array containing two IP addresses.\n\nNOTE: This is a work in progress\n\nChange-Id: I68e9c0eee4851706440b1ad0f47a5f8f87c16786\nDepends-On: I003b6d7d171652654745861d4231882f9e0d373e\n'}, {'number': 8, 'created': '2016-06-17 19:23:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/b28e4e692ad9f2fad392f7fe014697c099f94ec5', 'message': '[WIP] Enable IPv4/IPv6 dual-stack Public API endpoints\n\nThis change adds the option to create two External networks. This\nallows one main External network with IPv6 addresses and allows a\nsecondary External network with IPv4 addresses. Both of the IPs from\nthese two networks will be fed to os-net-config to be added to the\nsame interface. This change only adds ports on the second external\nnetwork to the controllers, for use by HAProxy.\n\nChanges to the loadbalancer.pp module in puppet-tripleo will allow\nfor dual-stack configuration of the endpoints using the PublicVIP\nand KeystoneAdminVIP as an array containing two IP addresses.\n\nNOTE: This is a work in progress\n\nChange-Id: I68e9c0eee4851706440b1ad0f47a5f8f87c16786\nDepends-On: I003b6d7d171652654745861d4231882f9e0d373e\n'}, {'number': 9, 'created': '2016-06-24 19:22:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/37bb406a9d6cbc7a62544ae5d746aedd213158f6', 'message': ""Enable IPv4/IPv6 dual-stack Public API endpoints\n\nThis change adds the option to create two External networks. This\nallows one main External network with IPv6 addresses and allows a\nsecondary External network with IPv4 addresses. Both of the IPs from\nthese two networks will be fed to os-net-config to be added to the\nsame interface. This change only adds ports on the second external\nnetwork to the controllers, for use by HAProxy.\n\nNOTE: for upgrades, old controller NIC config templates will\nneed to be updated with the ExternalSecondaryIpSubnet parameter,\neven if dual-stack IPs aren't used, and even if no External network\nis used. This is because Heat still tries to assign a parameter\nfor ExternalSecondaryIpSubnet even if it is unused in the template.\n\nRecent changes to the loadbalancer.pp module in puppet-tripleo\nallow for dual-stack configuration of the endpoints using the\npublic_virtual_ip and keystone_public_api_vip hieradata. This data\nwill now be given as an array of the External VIP and the\nExternalSecondary VIP. If the ExternalSecondary network/VIP is not\ninstantiated, then the control plane IP will be passed. The new\nlist_to_hash function in Puppet will ignore the second value if\nit is equal to the control plane IP, but if two IPs are provided\n(one IPv4 and one IPv6), then both will be configured in HAProxy.\n\nChange-Id: I68e9c0eee4851706440b1ad0f47a5f8f87c16786\nDepends-On: I003b6d7d171652654745861d4231882f9e0d373e\n""}, {'number': 10, 'created': '2016-06-27 21:35:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/c59845c61b01d2dc8e258d5abf9ce224894b592f', 'message': ""Enable IPv4/IPv6 dual-stack Public API endpoints\n\nThis change adds the option to create two External networks. This\nallows one main External network with IPv6 addresses and allows a\nsecondary External network with IPv4 addresses. Both of the IPs from\nthese two networks will be fed to os-net-config to be added to the\nsame interface. This change only adds ports on the second external\nnetwork to the controllers, for use by HAProxy.\n\nNOTE: for upgrades, old controller NIC config templates will\nneed to be updated with the ExternalSecondaryIpSubnet parameter,\neven if dual-stack IPs aren't used, and even if no External network\nis used. This is because Heat still tries to assign a parameter\nfor ExternalSecondaryIpSubnet even if it is unused in the template.\n\nRecent changes to the loadbalancer.pp module in puppet-tripleo\nallow for dual-stack configuration of the endpoints using the\npublic_virtual_ip and keystone_public_api_vip hieradata. This data\nwill now be given as an array of the External VIP and the\nExternalSecondary VIP. If the ExternalSecondary network/VIP is not\ninstantiated, then the control plane IP will be passed. The new\nlist_to_hash function in Puppet will ignore the second value if\nit is equal to the control plane IP, but if two IPs are provided\n(one IPv4 and one IPv6), then both will be configured in HAProxy.\n\nChange-Id: I68e9c0eee4851706440b1ad0f47a5f8f87c16786\nDepends-On: I003b6d7d171652654745861d4231882f9e0d373e\n""}, {'number': 11, 'created': '2016-06-27 21:39:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/dac033b7e0d4e41547343fe1fe8e807fd59e9663', 'message': ""Enable IPv4/IPv6 dual-stack Public API endpoints\n\nThis change adds the option to create two External networks. This\nallows one main External network with IPv6 addresses and allows a\nsecondary External network with IPv4 addresses. Both of the IPs from\nthese two networks will be fed to os-net-config to be added to the\nsame interface. This change only adds ports on the second external\nnetwork to the controllers, for use by HAProxy.\n\nNOTE: for upgrades, old controller NIC config templates will\nneed to be updated with the ExternalSecondaryIpSubnet parameter,\neven if dual-stack IPs aren't used, and even if no External network\nis used. This is because Heat still tries to assign a parameter\nfor ExternalSecondaryIpSubnet even if it is unused in the template.\n\nRecent changes to the loadbalancer.pp module in puppet-tripleo\nallow for dual-stack configuration of the endpoints using the\npublic_virtual_ip and keystone_public_api_vip hieradata. This data\nwill now be given as an array of the External VIP and the\nExternalSecondary VIP. If the ExternalSecondary network/VIP is not\ninstantiated, then the control plane IP will be passed. The new\nlist_to_hash function in Puppet will ignore the second value if\nit is equal to the control plane IP, but if two IPs are provided\n(one IPv4 and one IPv6), then both will be configured in HAProxy.\n\nChange-Id: I68e9c0eee4851706440b1ad0f47a5f8f87c16786\nDepends-On: I003b6d7d171652654745861d4231882f9e0d373e\n""}, {'number': 12, 'created': '2016-06-28 16:37:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/d2ac8ccc18e359f610bf40fe7e38181faa6b33a0', 'message': ""Enable IPv4/IPv6 dual-stack Public API endpoints\n\nThis change adds the option to create two External networks. This\nallows one main External network with IPv6 addresses and allows a\nsecondary External network with IPv4 addresses. Both of the IPs from\nthese two networks will be fed to os-net-config to be added to the\nsame interface. This change only adds ports on the second external\nnetwork to the controllers, for use by HAProxy.\n\nNOTE: for upgrades, old controller NIC config templates will\nneed to be updated with the ExternalSecondaryIpSubnet parameter,\neven if dual-stack IPs aren't used, and even if no External network\nis used. This is because Heat still tries to assign a parameter\nfor ExternalSecondaryIpSubnet even if it is unused in the template.\n\nRecent changes to the loadbalancer.pp module in puppet-tripleo\nallow for dual-stack configuration of the endpoints using the\npublic_virtual_ip and keystone_public_api_vip hieradata. This data\nwill now be given as an array of the External VIP and the\nExternalSecondary VIP. If the ExternalSecondary network/VIP is not\ninstantiated, then the control plane IP will be passed. The new\nlist_to_hash function in Puppet will ignore the second value if\nit is equal to the control plane IP, but if two IPs are provided\n(one IPv4 and one IPv6), then both will be configured in HAProxy.\n\nChange-Id: I68e9c0eee4851706440b1ad0f47a5f8f87c16786\nDepends-On: I003b6d7d171652654745861d4231882f9e0d373e\n""}, {'number': 13, 'created': '2016-06-28 18:46:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/346198e9c41eacf27affd0fa8f69226b2ef13f5d', 'message': ""Enable IPv4/IPv6 dual-stack Public API endpoints\n\nThis change adds the option to create two External networks. This\nallows one main External network with IPv6 addresses and allows a\nsecondary External network with IPv4 addresses. Both of the IPs from\nthese two networks will be fed to os-net-config to be added to the\nsame interface. This change only adds ports on the second external\nnetwork to the controllers, for use by HAProxy.\n\nNOTE: for upgrades, old controller NIC config templates will\nneed to be updated with the ExternalSecondaryIpSubnet parameter,\neven if dual-stack IPs aren't used, and even if no External network\nis used. This is because Heat still tries to assign a parameter\nfor ExternalSecondaryIpSubnet even if it is unused in the template.\n\nRecent changes to the loadbalancer.pp module in puppet-tripleo\nallow for dual-stack configuration of the endpoints using the\npublic_virtual_ip and keystone_public_api_vip hieradata. This data\nwill now be given as an array of the External VIP and the\nExternalSecondary VIP. If the ExternalSecondary network/VIP is not\ninstantiated, then the control plane IP will be passed. The new\nlist_to_hash function in Puppet will ignore the second value if\nit is equal to the control plane IP, but if two IPs are provided\n(one IPv4 and one IPv6), then both will be configured in HAProxy.\n\nChange-Id: I68e9c0eee4851706440b1ad0f47a5f8f87c16786\nDepends-On: I003b6d7d171652654745861d4231882f9e0d373e\n""}, {'number': 14, 'created': '2016-06-28 21:28:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/87c3f8268235fbc6eb309a42d88079f2aefdecf1', 'message': 'Enable IPv4/IPv6 dual-stack Public API endpoints\n\nThis change adds the option to create two External networks. This\nallows one main External network with IPv6 addresses and allows a\nsecondary External network with IPv4 addresses. Both of the IPs from\nthese two networks will be fed to os-net-config to be added to the\nsame interface. This change only adds ports on the second external\nnetwork to the controllers, for use by HAProxy.\n\nNOTE: for upgrades, old controller NIC config templates will\nneed to be updated with the ExternalSecondaryIpSubnet parameter,\neven if dual-stack IPs aren\'t used, and even if no External network\nis used. This is because Heat still tries to assign a parameter\nfor ExternalSecondaryIpSubnet even if it is unused in the template,\nso that parameter has been added to all boilerplate templates.\n\nRecent changes to the loadbalancer.pp module in puppet-tripleo\nallow for dual-stack configuration of the endpoints using the\npublic_virtual_ip and keystone_public_api_vip hieradata. This data\nwill now be given as an array of the External VIP and the\nExternalSecondary VIP. If the ExternalSecondary network/VIP is not\ninstantiated, then the control plane IP will be passed. The new\nlist_to_hash function in Puppet will ignore the second value if\nit is equal to the control plane IP, but if two IPs are provided\n(one IPv4 and one IPv6), then both will be configured in HAProxy.\n\nAn example of this array being defined from overcloud.yaml:\n\npublic_virtual_ip:\n  str_replace:\n    template: ""[%IP1%,%IP2%]""\n  params:\n    \'%IP1%\': {get_attr: [VipMap, net_ip_map, external]}\n    \'%IP2%\': {get_attr: [VipMap, net_ip_map, external_secondary]}\n\nChange-Id: I68e9c0eee4851706440b1ad0f47a5f8f87c16786\nDepends-On: I003b6d7d171652654745861d4231882f9e0d373e\n'}, {'number': 15, 'created': '2016-06-30 00:13:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/82fd8c51d4288b8e88ccaa5174b578faae2f02d7', 'message': 'Enable IPv4/IPv6 dual-stack Public API endpoints\n\nThis change adds the option to create two External networks. This\nallows one main External network with IPv6 addresses and allows a\nsecondary External network with IPv4 addresses. Both of the IPs from\nthese two networks will be fed to os-net-config to be added to the\nsame interface. This change only adds ports on the second external\nnetwork to the controllers, for use by HAProxy.\n\nNOTE: for upgrades, old controller NIC config templates will\nneed to be updated with the ExternalSecondaryIpSubnet parameter,\neven if dual-stack IPs aren\'t used, and even if no External network\nis used. This is because Heat still tries to assign a parameter\nfor ExternalSecondaryIpSubnet even if it is unused in the template,\nso that parameter has been added to all boilerplate templates.\n\nRecent changes to the loadbalancer.pp module in puppet-tripleo\nallow for dual-stack configuration of the endpoints using the\npublic_virtual_ip and keystone_public_api_vip hieradata. This data\nwill now be given as an array of the External VIP and the\nExternalSecondary VIP. If the ExternalSecondary network/VIP is not\ninstantiated, then the control plane IP will be passed. The new\nlist_to_hash function in Puppet will ignore the second value if\nit is equal to the control plane IP, but if two IPs are provided\n(one IPv4 and one IPv6), then both will be configured in HAProxy.\n\nAn example of this array being defined from overcloud.yaml:\n\npublic_virtual_ip:\n  str_replace:\n    template: ""[%IP1%,%IP2%]""\n  params:\n    \'%IP1%\': {get_attr: [VipMap, net_ip_map, external]}\n    \'%IP2%\': {get_attr: [VipMap, net_ip_map, external_secondary]}\n\nChange-Id: I68e9c0eee4851706440b1ad0f47a5f8f87c16786\nDepends-On: I003b6d7d171652654745861d4231882f9e0d373e\n'}, {'number': 16, 'created': '2016-07-25 21:25:01.000000000', 'files': ['environments/network-isolation-v6-v4.yaml', 'network/config/single-nic-vlans/controller.yaml', 'net-config-static-bridge.yaml', 'network/external_v6.yaml', 'net-config-static.yaml', 'network/config/bond-with-vlans/controller-no-external.yaml', 'network/ports/net_ip_list_map.yaml', 'network/config/multiple-nics/controller-v6-v4.yaml', 'network/config/multiple-nics/controller-v6.yaml', 'puppet/controller.yaml', 'net-config-noop.yaml', 'network/ports/net_ip_map.yaml', 'network/config/single-nic-linux-bridge-vlans/controller-v6.yaml', 'network/config/single-nic-linux-bridge-vlans/controller.yaml', 'overcloud.yaml', 'network/config/single-nic-vlans/controller-no-external.yaml', 'network/config/bond-with-vlans/controller-v6-v4.yaml', 'network/config/bond-with-vlans/controller-v6.yaml', 'net-config-linux-bridge.yaml', 'net-config-bond.yaml', 'overcloud-resource-registry-puppet.yaml', 'network/config/single-nic-vlans/controller-v6-v4.yaml', 'network/external_secondary.yaml', 'environments/network-isolation-v4-external.yaml', 'network/ports/external_secondary.yaml', 'network/config/bond-with-vlans/controller.yaml', 'network/config/single-nic-linux-bridge-vlans/controller-v6-v4.yaml', 'network/networks.yaml', 'network/config/single-nic-vlans/controller-v6.yaml', 'net-config-bridge.yaml', 'network/config/multiple-nics/controller.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/d02d5302d89c36022647ea39919cc2abdcd7495c', 'message': 'Enable IPv4/IPv6 dual-stack Public API endpoints\n\nThis change adds the option to create two External networks. This\nallows one main External network with IPv6 addresses and allows a\nsecondary External network with IPv4 addresses. Both of the IPs from\nthese two networks will be fed to os-net-config to be added to the\nsame interface. This change only adds ports on the second external\nnetwork to the controllers, for use by HAProxy.\n\nNOTE: for upgrades, old controller NIC config templates will\nneed to be updated with the ExternalSecondaryIpSubnet parameter,\neven if dual-stack IPs aren\'t used, and even if no External network\nis used. This is because Heat still tries to assign a parameter\nfor ExternalSecondaryIpSubnet even if it is unused in the template,\nso that parameter has been added to all boilerplate templates.\n\nRecent changes to the loadbalancer.pp module in puppet-tripleo\nallow for dual-stack configuration of the endpoints using the\npublic_virtual_ip and keystone_public_api_vip hieradata. This data\nwill now be given as an array of the External VIP and the\nExternalSecondary VIP. If the ExternalSecondary network/VIP is not\ninstantiated, then the control plane IP will be passed. The new\nlist_to_hash function in Puppet will ignore the second value if\nit is equal to the control plane IP, but if two IPs are provided\n(one IPv4 and one IPv6), then both will be configured in HAProxy.\n\nAn example of this array being defined from overcloud.yaml:\n\npublic_virtual_ip:\n  str_replace:\n    template: ""[%IP1%,%IP2%]""\n  params:\n    \'%IP1%\': {get_attr: [VipMap, net_ip_map, external]}\n    \'%IP2%\': {get_attr: [VipMap, net_ip_map, external_secondary]}\n\nChange-Id: I68e9c0eee4851706440b1ad0f47a5f8f87c16786\nDepends-On: I003b6d7d171652654745861d4231882f9e0d373e\n'}]",12,289279,d02d5302d89c36022647ea39919cc2abdcd7495c,69,4,16,12398,,,0,"Enable IPv4/IPv6 dual-stack Public API endpoints

This change adds the option to create two External networks. This
allows one main External network with IPv6 addresses and allows a
secondary External network with IPv4 addresses. Both of the IPs from
these two networks will be fed to os-net-config to be added to the
same interface. This change only adds ports on the second external
network to the controllers, for use by HAProxy.

NOTE: for upgrades, old controller NIC config templates will
need to be updated with the ExternalSecondaryIpSubnet parameter,
even if dual-stack IPs aren't used, and even if no External network
is used. This is because Heat still tries to assign a parameter
for ExternalSecondaryIpSubnet even if it is unused in the template,
so that parameter has been added to all boilerplate templates.

Recent changes to the loadbalancer.pp module in puppet-tripleo
allow for dual-stack configuration of the endpoints using the
public_virtual_ip and keystone_public_api_vip hieradata. This data
will now be given as an array of the External VIP and the
ExternalSecondary VIP. If the ExternalSecondary network/VIP is not
instantiated, then the control plane IP will be passed. The new
list_to_hash function in Puppet will ignore the second value if
it is equal to the control plane IP, but if two IPs are provided
(one IPv4 and one IPv6), then both will be configured in HAProxy.

An example of this array being defined from overcloud.yaml:

public_virtual_ip:
  str_replace:
    template: ""[%IP1%,%IP2%]""
  params:
    '%IP1%': {get_attr: [VipMap, net_ip_map, external]}
    '%IP2%': {get_attr: [VipMap, net_ip_map, external_secondary]}

Change-Id: I68e9c0eee4851706440b1ad0f47a5f8f87c16786
Depends-On: I003b6d7d171652654745861d4231882f9e0d373e
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/79/289279/16 && git format-patch -1 --stdout FETCH_HEAD,"['environments/network-isolation-v6-v4.yaml', 'network/external_v6.yaml', 'overcloud-resource-registry-puppet.yaml', 'network/ports/net_ip_list_map.yaml', 'network/ports/net_ip_subnet_map.yaml', 'puppet/cinder-storage.yaml', 'environments/network-external-ipv6-ipv4-ds.yaml', 'puppet/controller.yaml', 'network/ports/net_ip_map.yaml', 'overcloud.yaml', 'puppet/swift-storage.yaml', 'puppet/compute.yaml', 'puppet/ceph-storage.yaml']",13,564e3da7a2b4e581d0a7ff8334ead0c6b751edde,dual_stack_public_vip_2," ExternalSecondaryPort: type: OS::TripleO::CephStorage::Ports::ExternalSecondaryPort properties: ControlPlaneIP: {get_attr: [CephStorage, networks, ctlplane, 0]} ExternalSecondaryIpSubnet: {get_attr: [ExternalSecondaryPort, ip_subnet]} ExternalSecondaryIp: {get_attr: [ExternalSecondaryPort, ip_address]} ExternalSecondaryIpUri: {get_attr: [ExternalSecondaryPort, ip_address_uri]} ExternalSecondaryIpSubnet: {get_attr: [ExternalSecondaryPort, ip_subnet]} EXTERNALSECONDARYIP EXTERNALSECONDARYHOST EXTERNALSECONDARYIP: {get_attr: [ExternalSecondaryPort, ip_address]} EXTERNALHOST: list_join: - '-' - - {get_attr: [CephStorage, name]} - external_secondary external_secondary_ip_address: description: IP address (secondary) of the server in the external network value: {get_attr: [ExternalSecondaryPort, ip_address]}",,217,1
openstack%2Ftripleo-heat-templates~master~I4d2a0816a22dae9f9fbc7c18ca786ef12ceeea83,openstack/tripleo-heat-templates,master,I4d2a0816a22dae9f9fbc7c18ca786ef12ceeea83,Implement str_replace to unify IPv4/IPv6 ports [DO NOT MERGE],ABANDONED,2016-01-27 00:57:53.000000000,2016-08-29 21:22:47.000000000,,"[{'_account_id': 3}, {'_account_id': 12398}]","[{'number': 1, 'created': '2016-01-27 00:57:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/212c6e76542a8920f65c972df2c80428b7a65459', 'message': 'Implement str_replace to unify IPv4/IPv6 ports [DO NOT MERGE]\n\nThis change implements a suggestion by Steven Hardy to use str_replace\nin order to format IPv6 addresses with brackets for use in URLs. This\nallows the IPv4 and IPv6 port resources to use the same file, and the\naction is changed based on the value of the format string used for the\nstr_replace function.\n\nSince the ports can now be used for either IPv4 or IPv6 networks, the\nnetwork-isolation-v6.yaml was updated to use the original port resource\nfiles.\n\nI actually think this might not be the right approach, for two reasons:\n\n1) We need to specify whether or not to bracket the IP addresses on a\n   per-network basis, since some networks might be IPv4 and some IPv6.\n   This means we have to set a string format parameter for each network.\n\n2) We need to support dual-stack networks, where the node will have\n   both an IPv4 and an IPv6 address on a given network. In this\n   situation, there needs to be one port resource that returns a raw\n   IPv4 address, and another that returns a bracketed IPv6 address.\n\nIn the dual-stack case, I suppose one option is to instantiate the\nsame port resource twice, but set a parameter on the resource for the\nIP format string. This would mean setting a lot of top-level parameters\ninside of the environment yaml. For instance (psuedocode):\n\nparameters:\n  Controller:\n    ExternalPort:\n      IpFormatString: ""[%IP%]""\n    ExternalPort2:\n      IpFormatString: ""%IP%""\n    InternalApiPort:\n      IpFormatString: ""[%IP%]""\n    InternalApiPort2:\n      IpFormatString: ""%IP%""\n    [...]\n\nHaving to put that level of detail for every port of every node in\nthe environment file to intantiate dual-stack networking feels to\nme like maybe the wrong approach.\n\nChange-Id: I4d2a0816a22dae9f9fbc7c18ca786ef12ceeea83\n'}, {'number': 2, 'created': '2016-01-27 02:20:41.000000000', 'files': ['network/ports/noop.yaml', 'network/ports/external.yaml', 'network/ports/vip_v6.yaml', 'network/ports/storage.yaml', 'network/ports/storage_from_pool.yaml', 'network/ports/ctlplane_vip.yaml', 'network/ports/external_from_pool.yaml', 'network/ports/internal_api.yaml', 'network/ports/storage_mgmt.yaml', 'network/ports/vip.yaml', 'network/ports/tenant_from_pool.yaml', 'network/ports/internal_api_from_pool.yaml', 'network/ports/storage_mgmt_from_pool.yaml', 'network/ports/tenant.yaml', 'network/ports/management.yaml', 'environments/network-isolation-v6.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/f040c06e3303d1c45a09e4bbb3a7ed6d034be4dc', 'message': 'Implement str_replace to unify IPv4/IPv6 ports [DO NOT MERGE]\n\nThis change implements a suggestion by Steven Hardy to use str_replace\nin order to format IPv6 addresses with brackets for use in URLs. This\nallows the IPv4 and IPv6 port resources to use the same file, and the\naction is changed based on the value of the format string used for the\nstr_replace function.\n\nSince the ports can now be used for either IPv4 or IPv6 networks, the\nnetwork-isolation-v6.yaml was updated to use the original port resource\nfiles.\n\nI actually think this might not be the right approach, for two reasons:\n\n1) We need to specify whether or not to bracket the IP addresses on a\n   per-network basis, since some networks might be IPv4 and some IPv6.\n   This means we have to set a string format parameter for each network.\n\n2) We need to support dual-stack networks, where the node will have\n   both an IPv4 and an IPv6 address on a given network. In this\n   situation, there needs to be one port resource that returns a raw\n   IPv4 address, and another that returns a bracketed IPv6 address.\n\nIn the dual-stack case, I suppose one option is to instantiate the\nsame port resource twice, but set a parameter on the resource for the\nIP format string. This would mean setting a lot of top-level parameters\ninside of the environment yaml. For instance (psuedocode):\n\nparameters:\n  Controller:\n    ExternalPort:\n      IpFormatString: ""[%IP%]""\n    ExternalPort2:\n      IpFormatString: ""%IP%""\n    InternalApiPort:\n      IpFormatString: ""[%IP%]""\n    InternalApiPort2:\n      IpFormatString: ""%IP%""\n    [...]\n\nHaving to put that level of detail for every port of every node in\nthe environment file to intantiate dual-stack networking feels to\nme like maybe the wrong approach.\n\nChange-Id: I4d2a0816a22dae9f9fbc7c18ca786ef12ceeea83\n'}]",0,272856,f040c06e3303d1c45a09e4bbb3a7ed6d034be4dc,9,2,2,12398,,,0,"Implement str_replace to unify IPv4/IPv6 ports [DO NOT MERGE]

This change implements a suggestion by Steven Hardy to use str_replace
in order to format IPv6 addresses with brackets for use in URLs. This
allows the IPv4 and IPv6 port resources to use the same file, and the
action is changed based on the value of the format string used for the
str_replace function.

Since the ports can now be used for either IPv4 or IPv6 networks, the
network-isolation-v6.yaml was updated to use the original port resource
files.

I actually think this might not be the right approach, for two reasons:

1) We need to specify whether or not to bracket the IP addresses on a
   per-network basis, since some networks might be IPv4 and some IPv6.
   This means we have to set a string format parameter for each network.

2) We need to support dual-stack networks, where the node will have
   both an IPv4 and an IPv6 address on a given network. In this
   situation, there needs to be one port resource that returns a raw
   IPv4 address, and another that returns a bracketed IPv6 address.

In the dual-stack case, I suppose one option is to instantiate the
same port resource twice, but set a parameter on the resource for the
IP format string. This would mean setting a lot of top-level parameters
inside of the environment yaml. For instance (psuedocode):

parameters:
  Controller:
    ExternalPort:
      IpFormatString: ""[%IP%]""
    ExternalPort2:
      IpFormatString: ""%IP%""
    InternalApiPort:
      IpFormatString: ""[%IP%]""
    InternalApiPort2:
      IpFormatString: ""%IP%""
    [...]

Having to put that level of detail for every port of every node in
the environment file to intantiate dual-stack networking feels to
me like maybe the wrong approach.

Change-Id: I4d2a0816a22dae9f9fbc7c18ca786ef12ceeea83
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/56/272856/1 && git format-patch -1 --stdout FETCH_HEAD,"['network/ports/noop.yaml', 'network/ports/external.yaml', 'network/ports/vip_v6.yaml', 'network/ports/storage.yaml', 'network/ports/storage_from_pool.yaml', 'network/ports/ctlplane_vip.yaml', 'network/ports/external_from_pool.yaml', 'network/ports/internal_api.yaml', 'network/ports/storage_mgmt.yaml', 'network/ports/vip.yaml', 'network/ports/tenant_from_pool.yaml', 'network/ports/internal_api_from_pool.yaml', 'network/ports/storage_mgmt_from_pool.yaml', 'network/ports/tenant.yaml', 'network/ports/management.yaml', 'environments/network-isolation-v6.yaml']",16,212c6e76542a8920f65c972df2c80428b7a65459,ipv6_str_replace_simplification," OS::TripleO::Network::Ports::ExternalVipPort: ../network/ports/external.yaml OS::TripleO::Network::Ports::InternalApiVipPort: ../network/ports/internal_api.yaml OS::TripleO::Network::Ports::StorageVipPort: ../network/ports/storage.yaml OS::TripleO::Network::Ports::StorageMgmtVipPort: ../network/ports/storage_mgmt.yaml OS::TripleO::Network::Ports::RedisVipPort: ../network/ports/vip.yaml OS::TripleO::Controller::Ports::ExternalPort: ../network/ports/external.yaml OS::TripleO::Controller::Ports::InternalApiPort: ../network/ports/internal_api.yaml OS::TripleO::Controller::Ports::StoragePort: ../network/ports/storage.yaml OS::TripleO::Controller::Ports::StorageMgmtPort: ../network/ports/storage_mgmt.yaml OS::TripleO::Controller::Ports::TenantPort: ../network/ports/tenant.yaml OS::TripleO::Controller::Ports::ManagementPort: ../network/ports/noop.yaml OS::TripleO::Compute::Ports::ExternalPort: ../network/ports/noop.yaml OS::TripleO::Compute::Ports::InternalApiPort: ../network/ports/internal_api.yaml OS::TripleO::Compute::Ports::StoragePort: ../network/ports/storage.yaml OS::TripleO::Compute::Ports::StorageMgmtPort: ../network/ports/noop.yaml OS::TripleO::Compute::Ports::TenantPort: ../network/ports/tenant.yaml OS::TripleO::Compute::Ports::ManagementPort: ../network/ports/noop.yaml OS::TripleO::CephStorage::Ports::ExternalPort: ../network/ports/noop.yaml OS::TripleO::CephStorage::Ports::InternalApiPort: ../network/ports/noop.yaml OS::TripleO::CephStorage::Ports::StoragePort: ../network/ports/storage.yaml OS::TripleO::CephStorage::Ports::StorageMgmtPort: ../network/ports/storage_mgmt.yaml OS::TripleO::CephStorage::Ports::TenantPort: ../network/ports/noop.yaml OS::TripleO::CephStorage::Ports::ManagementPort: ../network/ports/noop.yaml OS::TripleO::SwiftStorage::Ports::ExternalPort: ../network/ports/noop.yaml OS::TripleO::SwiftStorage::Ports::InternalApiPort: ../network/ports/internal_api.yaml OS::TripleO::SwiftStorage::Ports::StoragePort: ../network/ports/storage.yaml OS::TripleO::SwiftStorage::Ports::StorageMgmtPort: ../network/ports/storage_mgmt.yaml OS::TripleO::SwiftStorage::Ports::TenantPort: ../network/ports/noop.yaml OS::TripleO::SwiftStorage::Ports::ManagementPort: ../network/ports/noop.yaml OS::TripleO::BlockStorage::Ports::ExternalPort: ../network/ports/noop.yaml OS::TripleO::BlockStorage::Ports::InternalApiPort: ../network/ports/internal_api.yaml OS::TripleO::BlockStorage::Ports::StoragePort: ../network/ports/storage.yaml OS::TripleO::BlockStorage::Ports::StorageMgmtPort: ../network/ports/storage_mgmt.yaml OS::TripleO::BlockStorage::Ports::TenantPort: ../network/ports/noop.yaml OS::TripleO::BlockStorage::Ports::ManagementPort: ../network/ports/noop.yaml # For IPv4 networks, ""%IP%"" is used for raw IPs in URLs, but when IPv6 is # used on a network, ""[%IP%]"" is used to wrap IPv6 IPs in brackets for URLs ExternalIpUriFormat: ""[%IP%]"" InternalApiIpUriFormat: ""[%IP%]"" StorageIpUriFormat: ""[%IP%]"" StorageMgmtIpUriFormat: ""[%IP%]"" TenantIpUriFormat: ""[%IP%]"" # ManagementIpUriFormat: ""%IP%""", OS::TripleO::Network::Ports::ExternalVipPort: ../network/ports/external_v6.yaml OS::TripleO::Network::Ports::InternalApiVipPort: ../network/ports/internal_api_v6.yaml OS::TripleO::Network::Ports::StorageVipPort: ../network/ports/storage_v6.yaml OS::TripleO::Network::Ports::StorageMgmtVipPort: ../network/ports/storage_mgmt_v6.yaml OS::TripleO::Network::Ports::RedisVipPort: ../network/ports/vip_v6.yaml OS::TripleO::Controller::Ports::ExternalPort: ../network/ports/external_v6.yaml OS::TripleO::Controller::Ports::InternalApiPort: ../network/ports/internal_api_v6.yaml OS::TripleO::Controller::Ports::StoragePort: ../network/ports/storage_v6.yaml OS::TripleO::Controller::Ports::StorageMgmtPort: ../network/ports/storage_mgmt_v6.yaml OS::TripleO::Controller::Ports::TenantPort: ../network/ports/tenant_v6.yaml OS::TripleO::Compute::Ports::InternalApiPort: ../network/ports/internal_api_v6.yaml OS::TripleO::Compute::Ports::StoragePort: ../network/ports/storage_v6.yaml OS::TripleO::Compute::Ports::TenantPort: ../network/ports/tenant_v6.yaml OS::TripleO::CephStorage::Ports::StoragePort: ../network/ports/storage_v6.yaml OS::TripleO::CephStorage::Ports::StorageMgmtPort: ../network/ports/storage_mgmt_v6.yaml OS::TripleO::SwiftStorage::Ports::InternalApiPort: ../network/ports/internal_api_v6.yaml OS::TripleO::SwiftStorage::Ports::StoragePort: ../network/ports/storage_v6.yaml OS::TripleO::SwiftStorage::Ports::StorageMgmtPort: ../network/ports/storage_mgmt_v6.yaml OS::TripleO::BlockStorage::Ports::InternalApiPort: ../network/ports/internal_api_v6.yaml OS::TripleO::BlockStorage::Ports::StoragePort: ../network/ports/storage_v6.yaml OS::TripleO::BlockStorage::Ports::StorageMgmtPort: ../network/ports/storage_mgmt_v6.yaml,190,94
openstack%2Frelease-test~master~I9bf4f14a7dc059b90dfe4fee1c6e58f752d781a5,openstack/release-test,master,I9bf4f14a7dc059b90dfe4fee1c6e58f752d781a5,tweak release note for bug 1602862,MERGED,2016-08-29 21:20:07.000000000,2016-08-29 21:20:29.000000000,2016-08-29 21:20:27.000000000,"[{'_account_id': 3}, {'_account_id': 2472}]","[{'number': 1, 'created': '2016-08-29 21:20:07.000000000', 'files': ['releasenotes/notes/faux-bug-1f38be77c952e9ec.yaml'], 'web_link': 'https://opendev.org/openstack/release-test/commit/ecda79f509fe2d9c1e69e121721dc988933a0fcd', 'message': 'tweak release note for bug 1602862\n\nChange-Id: I9bf4f14a7dc059b90dfe4fee1c6e58f752d781a5\nCloses-Bug: #1602862\nSigned-off-by: Doug Hellmann <doug@doughellmann.com>\n'}]",0,362452,ecda79f509fe2d9c1e69e121721dc988933a0fcd,6,2,1,2472,,,0,"tweak release note for bug 1602862

Change-Id: I9bf4f14a7dc059b90dfe4fee1c6e58f752d781a5
Closes-Bug: #1602862
Signed-off-by: Doug Hellmann <doug@doughellmann.com>
",git fetch https://review.opendev.org/openstack/release-test refs/changes/52/362452/1 && git format-patch -1 --stdout FETCH_HEAD,['releasenotes/notes/faux-bug-1f38be77c952e9ec.yaml'],1,ecda79f509fe2d9c1e69e121721dc988933a0fcd,bug/1602862, - Fixes the bug https://bugs.launchpad.net/reno/+bug/1602862, - Fixes bug https://bugs.launchpad.net/reno/+bug/1602862,1,1
openstack%2Fheat-specs~master~Id28f0ee290dbc74591e0a1b0228ac36d29b06a1b,openstack/heat-specs,master,Id28f0ee290dbc74591e0a1b0228ac36d29b06a1b,create ocata spec template and directory,MERGED,2016-08-26 16:17:49.000000000,2016-08-29 21:18:34.000000000,2016-08-29 21:18:34.000000000,"[{'_account_id': 3}, {'_account_id': 7253}, {'_account_id': 13009}]","[{'number': 1, 'created': '2016-08-26 16:17:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-specs/commit/0a8f102e6239d19d7895d6470da8a9b62b7b9cf8', 'message': 'create ocata spec template and directory\n\nChange-Id: Id28f0ee290dbc74591e0a1b0228ac36d29b06a1b\n'}, {'number': 2, 'created': '2016-08-26 20:02:31.000000000', 'files': ['specs/ocata/ocata-template.rst', 'doc/source/index.rst', 'specs/templates/ocata-template.rst'], 'web_link': 'https://opendev.org/openstack/heat-specs/commit/912ae3086a039631cf40cb24a92cb1bda79ee918', 'message': 'create ocata spec template and directory\n\nChange-Id: Id28f0ee290dbc74591e0a1b0228ac36d29b06a1b\n'}]",0,361347,912ae3086a039631cf40cb24a92cb1bda79ee918,9,3,2,8745,,,0,"create ocata spec template and directory

Change-Id: Id28f0ee290dbc74591e0a1b0228ac36d29b06a1b
",git fetch https://review.opendev.org/openstack/heat-specs refs/changes/47/361347/2 && git format-patch -1 --stdout FETCH_HEAD,"['specs/ocata/ocata-template.rst', 'specs/templates/ocata-template.rst']",2,0a8f102e6239d19d7895d6470da8a9b62b7b9cf8,bp/template-inheritance,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode .. This template should be in ReSTructured text. The filename in the git repository should match the launchpad URL, for example a URL of https://blueprints.launchpad.net/heat/+spec/awesome-thing should be named awesome-thing.rst . Please do not delete any of the sections in this template. If you have nothing to say for a whole section, just write: None For help with syntax, see http://sphinx-doc.org/rest.html To test out your formatting, see http://www.tele3.cz/jbar/rest/rest.html =========================== The title of your blueprint =========================== Include the URL of your launchpad blueprint: https://blueprints.launchpad.net/heat/+spec/example Introduction paragraph -- why are we doing anything? Problem description =================== A detailed description of the problem. Proposed change =============== Here is where you cover the change you propose to make in detail. How do you propose to solve this problem? If this is one part of a larger effort make it clear where this piece ends. In other words, what's the scope of this effort? Include where in the heat tree hierarchy this will reside. If your specification proposes any changes to the Heat REST API such as changing parameters which can be returned or accepted, or even the semantics of what happens when a client calls into the API, then you should add the APIImpact flag to the commit message. Specifications with the APIImpact flag can be found with the following query: https://review.openstack.org/#/q/status:open+project:openstack/heat-specs+message:apiimpact,n,z Alternatives ------------ This is an optional section, where it does apply we'd just like a demonstration that some thought has been put into why the proposed approach is the best one. Implementation ============== Assignee(s) ----------- Who is leading the writing of the code? Or is this a blueprint where you're throwing it out there to see who picks it up? If more than one person is working on the implementation, please designate the primary author and contact. Primary assignee: <launchpad-id or None> Can optionally can list additional ids if they intend on doing substantial implementation work on this blueprint. Milestones ---------- Target Milestone for completion: ocata-1 Work Items ---------- Work items or tasks -- break the feature up into the things that need to be done to implement it. Those parts might end up being done by different people, but we're mostly trying to understand the timeline for implementation. Dependencies ============ - Include specific references to specs and/or blueprints in heat, or in other projects, that this one either depends on or is related to. - Does this feature require any new library dependencies or code otherwise not included in OpenStack? Or does it depend on a specific version of library? ",,96,0
openstack%2Fjs-openstack-lib~master~I40c92bfe046cb1596c6d0e9693c4f405ba78e783,openstack/js-openstack-lib,master,I40c92bfe046cb1596c6d0e9693c4f405ba78e783,[WIP] Fix devstack gate configuration,ABANDONED,2016-08-26 23:30:33.000000000,2016-08-29 21:17:33.000000000,,"[{'_account_id': 3}, {'_account_id': 8614}, {'_account_id': 22670}]","[{'number': 1, 'created': '2016-08-26 23:30:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/js-openstack-lib/commit/c28d5164bc801d04de476cb940311486956e6071', 'message': 'Fix devstack gate configuration\n\nWhen devstack gate setup is ran, ""configure-devstack"" task fails with\na permission denied error.\nThis is because ""local.conf"" file generated to add CORS headers\nis created under a directory owned by ""stack"" user, not ""jenkins""\nThis patch forces the configure-devstack job to run as ""stack"" user.\nAs this babel-node is run with this user, it won\'t be able to save\ncache files in jenkins home, so babel cache must be disabled.\n\nChange-Id: I40c92bfe046cb1596c6d0e9693c4f405ba78e783\n'}, {'number': 2, 'created': '2016-08-29 13:56:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/js-openstack-lib/commit/9d82b0bfda1d82cb7700d3d2cbee2d1943bd1ea0', 'message': '[WIP] Fix devstack gate configuration\n\nWhen devstack gate setup is ran, ""configure-devstack"" task fails with\na permission denied error.\nThis is because ""local.conf"" file generated to add CORS headers\nis created under a directory owned by ""stack"" user, not ""jenkins""\nThis patch forces the configure-devstack job to run as ""stack"" user.\nAs this babel-node is run with this user, it won\'t be able to save\ncache files in jenkins home, so babel cache must be disabled.\n\nChange-Id: I40c92bfe046cb1596c6d0e9693c4f405ba78e783\n'}, {'number': 3, 'created': '2016-08-29 14:24:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/js-openstack-lib/commit/e50de6bfa592108aabc3b46536161bcca466d58f', 'message': '[WIP] Fix devstack gate configuration\n\nWhen devstack gate setup is ran, ""configure-devstack"" task fails with\na permission denied error.\nThis is because ""local.conf"" file generated to add CORS headers\nis created under a directory owned by ""stack"" user, not ""jenkins""\nThis patch forces the configure-devstack job to run as ""stack"" user.\nAs this babel-node is run with this user, it won\'t be able to save\ncache files in jenkins home, so babel cache must be disabled.\n\nChange-Id: I40c92bfe046cb1596c6d0e9693c4f405ba78e783\n'}, {'number': 4, 'created': '2016-08-29 15:22:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/js-openstack-lib/commit/fe6e88fd5d58d05f5f96288e141085c75d665ec8', 'message': '[WIP] Fix devstack gate configuration\n\nWhen devstack gate setup is ran, ""configure-devstack"" task fails with\na permission denied error.\nThis is because ""local.conf"" file generated to add CORS headers\nis created under a directory owned by ""stack"" user, not ""jenkins""\nThis patch forces the configure-devstack job to run as ""stack"" user.\nAs this babel-node is run with this user, it won\'t be able to save\ncache files in jenkins home, so babel cache must be disabled.\n\nChange-Id: I40c92bfe046cb1596c6d0e9693c4f405ba78e783\n'}, {'number': 5, 'created': '2016-08-29 15:37:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/js-openstack-lib/commit/361dad3ef5771fb7fbc18e06961c17d5ebd3300c', 'message': 'Fix devstack gate configuration\n\nWhen devstack gate setup is ran, ""configure-devstack"" task fails with\na permission denied error.\nThis is because ""local.conf"" file generated to add CORS headers\nis created under a directory owned by ""stack"" user, not ""jenkins""\nThis patch forces the configure-devstack job to run as ""stack"" user.\nAs this babel-node is run with this user, it won\'t be able to save\ncache files in jenkins home, so babel cache must be disabled.\n\nChange-Id: I40c92bfe046cb1596c6d0e9693c4f405ba78e783\n'}, {'number': 6, 'created': '2016-08-29 19:19:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/js-openstack-lib/commit/5f50e551b6dfe151f81e5bd928904319297a63bd', 'message': 'Fix devstack gate configuration\n\nWhen devstack gate setup is ran, ""configure-devstack"" task fails with\na permission denied error.\nThis is because ""local.conf"" file generated to add CORS headers\nis created under a directory owned by ""stack"" user, not ""jenkins""\nThis patch forces the configure-devstack job to run as ""stack"" user.\nAs this babel-node is run with this user, it won\'t be able to save\ncache files in jenkins home, so babel cache must be disabled.\n\nDepends-On: I53aaef0f8092e0006818200c2478762056014985\nChange-Id: I40c92bfe046cb1596c6d0e9693c4f405ba78e783\n'}, {'number': 7, 'created': '2016-08-29 20:33:07.000000000', 'files': ['bindep.txt', 'package.json'], 'web_link': 'https://opendev.org/openstack/js-openstack-lib/commit/287ea9671c2774243b295bf2a0cbbb0aedc0a9e3', 'message': '[WIP] Fix devstack gate configuration\n\nWhen devstack gate setup is ran, ""configure-devstack"" task fails with\na permission denied error.\nThis is because ""local.conf"" file generated to add CORS headers\nis created under a directory owned by ""stack"" user, not ""jenkins""\nThis patch forces the configure-devstack job to run as ""stack"" user.\nAs this babel-node is run with this user, it won\'t be able to save\ncache files in jenkins home, so babel cache must be disabled.\n\nDepends-On: I53aaef0f8092e0006818200c2478762056014985\nChange-Id: I40c92bfe046cb1596c6d0e9693c4f405ba78e783\n'}]",0,361525,287ea9671c2774243b295bf2a0cbbb0aedc0a9e3,21,3,7,8614,,,0,"[WIP] Fix devstack gate configuration

When devstack gate setup is ran, ""configure-devstack"" task fails with
a permission denied error.
This is because ""local.conf"" file generated to add CORS headers
is created under a directory owned by ""stack"" user, not ""jenkins""
This patch forces the configure-devstack job to run as ""stack"" user.
As this babel-node is run with this user, it won't be able to save
cache files in jenkins home, so babel cache must be disabled.

Depends-On: I53aaef0f8092e0006818200c2478762056014985
Change-Id: I40c92bfe046cb1596c6d0e9693c4f405ba78e783
",git fetch https://review.opendev.org/openstack/js-openstack-lib refs/changes/25/361525/5 && git format-patch -1 --stdout FETCH_HEAD,['package.json'],1,c28d5164bc801d04de476cb940311486956e6071,build_system," ""configure-devstack"": ""sudo -u stack BASE=$BASE BABEL_DISABLE_CACHE=1 ./node_modules/.bin/babel-node ./configure-devstack.js"","," ""configure-devstack"": ""babel-node ./configure-devstack.js"",",1,1
openstack%2Fos-client-config~master~I5faa86e94d6f71282ac270e2acfbd3016638c780,openstack/os-client-config,master,I5faa86e94d6f71282ac270e2acfbd3016638c780,Add prompting for KSA options,MERGED,2016-08-29 18:30:29.000000000,2016-08-29 21:10:34.000000000,2016-08-29 21:10:34.000000000,"[{'_account_id': 2}, {'_account_id': 3}, {'_account_id': 6482}]","[{'number': 1, 'created': '2016-08-29 18:30:29.000000000', 'files': ['os_client_config/config.py', 'os_client_config/tests/test_config.py'], 'web_link': 'https://opendev.org/openstack/os-client-config/commit/2b52bcf6943369fe96db3aefe2ee7473dd51b934', 'message': 'Add prompting for KSA options\n\nTeach OpenStackConfig to prompt the user for KSA plugin options\nthat have no value but have a prompt string defined.\n\n* Add pw_func argument to __init__() to be used as the callback\n  for prompting the user.  The default is None which skips the\n  prompt step.\n* Add option_prompt() method to perform the checks for prompting,\n  call the callback and save the returned value. This is public\n  to handle cases where simply passing in a callback is insufficient\n  for the prompt mechanism.\n\nRelated-Bug: #1617384\nChange-Id: I5faa86e94d6f71282ac270e2acfbd3016638c780\n'}]",0,362314,2b52bcf6943369fe96db3aefe2ee7473dd51b934,7,3,1,970,,,0,"Add prompting for KSA options

Teach OpenStackConfig to prompt the user for KSA plugin options
that have no value but have a prompt string defined.

* Add pw_func argument to __init__() to be used as the callback
  for prompting the user.  The default is None which skips the
  prompt step.
* Add option_prompt() method to perform the checks for prompting,
  call the callback and save the returned value. This is public
  to handle cases where simply passing in a callback is insufficient
  for the prompt mechanism.

Related-Bug: #1617384
Change-Id: I5faa86e94d6f71282ac270e2acfbd3016638c780
",git fetch https://review.opendev.org/openstack/os-client-config refs/changes/14/362314/1 && git format-patch -1 --stdout FETCH_HEAD,"['os_client_config/config.py', 'os_client_config/tests/test_config.py']",2,2b52bcf6943369fe96db3aefe2ee7473dd51b934,bug/1617384,"def prompt_for_password(prompt=None): """"""Fake prompt function that just returns a constant string"""""" return 'promptpass' class TestConfigPrompt(base.TestCase): def setUp(self): super(TestConfigPrompt, self).setUp() self.args = dict( auth_url='http://example.com/v2', username='user', project_name='project', # region_name='region2', auth_type='password', ) self.options = argparse.Namespace(**self.args) def test_get_one_cloud_prompt(self): c = config.OpenStackConfig( config_files=[self.cloud_yaml], vendor_files=[self.vendor_yaml], pw_func=prompt_for_password, ) # This needs a cloud definition without a password. # If this starts failing unexpectedly check that the cloud_yaml # and/or vendor_yaml do not have a password in the selected cloud. cc = c.get_one_cloud( cloud='_test_cloud_no_vendor', argparse=self.options, ) self.assertEqual('promptpass', cc.auth['password']) ",,59,1
openstack%2Fpython-openstackclient~master~Ic86d56b8a6844516292fb74513712b486fec4442,openstack/python-openstackclient,master,Ic86d56b8a6844516292fb74513712b486fec4442,Fix auth prompt brokenness,MERGED,2016-08-29 16:15:03.000000000,2016-08-29 21:09:58.000000000,2016-08-29 21:09:58.000000000,"[{'_account_id': 3}, {'_account_id': 6482}, {'_account_id': 8410}]","[{'number': 1, 'created': '2016-08-29 16:15:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/44f58a0b9646d1851848592a9b99286c283070ed', 'message': 'Fix auth prompt brokenness\n\nWe start by fixing this in the already-present OSC_Config class so OSC\ncan move forward.  This change needs to get ported down into\nos-client-config in the near future, maybe even soon enough to make the\nclient library freeze this week.\n\n* Add the pw-func argument to the OSC_Config (or OpenStackConfig) __init__()\n* When looping through the auth options from the KSA plugin look for any\n  that have a prompt defined and do not have a value already, so ask for one.\n\nCloses-bug: #1617384\nChange-Id: Ic86d56b8a6844516292fb74513712b486fec4442\n'}, {'number': 2, 'created': '2016-08-29 16:21:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/b827c22dcfa018ada4e45c7388a169763f43f4ce', 'message': 'Fix auth prompt brokenness\n\nWe start by fixing this in the already-present OSC_Config class so OSC\ncan move forward.  This change needs to get ported down into\nos-client-config in the near future, maybe even soon enough to make the\nclient library freeze this week.\n\n* Add the pw-func argument to the OSC_Config (or OpenStackConfig) __init__()\n* When looping through the auth options from the KSA plugin look for any\n  that have a prompt defined and do not have a value already, so ask for one.\n\nCloses-bug: #1617384\nChange-Id: Ic86d56b8a6844516292fb74513712b486fec4442\n'}, {'number': 3, 'created': '2016-08-29 16:47:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/2258055f80e6613df991cad93832d48c2bbdc87b', 'message': 'Fix auth prompt brokenness\n\nWe start by fixing this in the already-present OSC_Config class so OSC\ncan move forward.  This change needs to get ported down into\nos-client-config in the near future, maybe even soon enough to make the\nclient library freeze this week.\n\n* Add the pw-func argument to the OSC_Config (or OpenStackConfig) __init__()\n* When looping through the auth options from the KSA plugin look for any\n  that have a prompt defined and do not have a value already, so ask for one.\n\nCloses-bug: #1617384\nChange-Id: Ic86d56b8a6844516292fb74513712b486fec4442\n'}, {'number': 4, 'created': '2016-08-29 17:06:49.000000000', 'files': ['openstackclient/common/client_config.py', 'openstackclient/tests/test_shell_integ.py', 'openstackclient/shell.py', 'openstackclient/common/clientmanager.py'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/bec206fa0a0214d856259661c5e32086f33d2f62', 'message': 'Fix auth prompt brokenness\n\nWe start by fixing this in the already-present OSC_Config class so OSC\ncan move forward.  This change needs to get ported down into\nos-client-config in the near future, maybe even soon enough to make the\nclient library freeze this week.\n\n* Add the pw-func argument to the OSC_Config (or OpenStackConfig) __init__()\n* When looping through the auth options from the KSA plugin look for any\n  that have a prompt defined and do not have a value already, so ask for one.\n\nCloses-bug: #1617384\nChange-Id: Ic86d56b8a6844516292fb74513712b486fec4442\n'}]",0,362243,bec206fa0a0214d856259661c5e32086f33d2f62,12,3,4,970,,,0,"Fix auth prompt brokenness

We start by fixing this in the already-present OSC_Config class so OSC
can move forward.  This change needs to get ported down into
os-client-config in the near future, maybe even soon enough to make the
client library freeze this week.

* Add the pw-func argument to the OSC_Config (or OpenStackConfig) __init__()
* When looping through the auth options from the KSA plugin look for any
  that have a prompt defined and do not have a value already, so ask for one.

Closes-bug: #1617384
Change-Id: Ic86d56b8a6844516292fb74513712b486fec4442
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/43/362243/4 && git format-patch -1 --stdout FETCH_HEAD,"['openstackclient/common/client_config.py', 'openstackclient/tests/test_shell_integ.py', 'openstackclient/shell.py']",3,44f58a0b9646d1851848592a9b99286c283070ed,bug/1617384," pw_func=shell.prompt_for_password,",,101,0
openstack%2Fneutron~stable%2Fmitaka~I1fb533d7804b131f709b790fc730ed7b97cb5499,openstack/neutron,stable/mitaka,I1fb533d7804b131f709b790fc730ed7b97cb5499,L3 DVR: use fanout when sending dvr arp table update,MERGED,2016-08-25 18:51:07.000000000,2016-08-29 21:05:13.000000000,2016-08-29 21:05:12.000000000,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 1131}, {'_account_id': 5170}, {'_account_id': 9681}, {'_account_id': 9732}, {'_account_id': 14208}]","[{'number': 1, 'created': '2016-08-25 18:51:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/33ced8d02ea943c8efd4d9901114fd32ab0fdcbc', 'message': 'L3 DVR: use fanout when sending dvr arp table update\n\nSending arp update to each l3 dvr agent one by one on every port\ncreation is not scalable and causes serious performance degradation\nif router is hosted on lots of l3 dvr agents on compute nodes (see\nbug report). This increases port creation time and eventually leads\nto timeouts in Nova and VMs going to ERROR state.\n\nThis patch changes notification to be fanout.\nThe downside is that with fanout the arp notification will be sent to\neach l3 agent, even those not hosting the router. However such agents\nwill just skip the notification if not hosting the router - this should\nbe quite cheap.\n\nCloses-Bug: #1614452\nChange-Id: I1fb533d7804b131f709b790fc730ed7b97cb5499\n(cherry picked from commit 4bdab5cf1da333cf4e7aaf893e14b094fc5fad61)\n'}, {'number': 2, 'created': '2016-08-25 18:52:32.000000000', 'files': ['neutron/tests/unit/api/rpc/agentnotifiers/test_l3_rpc_agent_api.py', 'neutron/api/rpc/agentnotifiers/l3_rpc_agent_api.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/d56016425d85118dba8a8123cd357b4082478278', 'message': 'L3 DVR: use fanout when sending dvr arp table update\n\nSending arp update to each l3 dvr agent one by one on every port\ncreation is not scalable and causes serious performance degradation\nif router is hosted on lots of l3 dvr agents on compute nodes (see\nbug report). This increases port creation time and eventually leads\nto timeouts in Nova and VMs going to ERROR state.\n\nThis patch changes notification to be fanout.\nThe downside is that with fanout the arp notification will be sent to\neach l3 agent, even those not hosting the router. However such agents\nwill just skip the notification if not hosting the router - this should\nbe quite cheap.\n\nCloses-Bug: #1614452\nChange-Id: I1fb533d7804b131f709b790fc730ed7b97cb5499\n(cherry picked from commit 4bdab5cf1da333cf4e7aaf893e14b094fc5fad61)\n'}]",0,360732,d56016425d85118dba8a8123cd357b4082478278,14,7,2,5948,,,0,"L3 DVR: use fanout when sending dvr arp table update

Sending arp update to each l3 dvr agent one by one on every port
creation is not scalable and causes serious performance degradation
if router is hosted on lots of l3 dvr agents on compute nodes (see
bug report). This increases port creation time and eventually leads
to timeouts in Nova and VMs going to ERROR state.

This patch changes notification to be fanout.
The downside is that with fanout the arp notification will be sent to
each l3 agent, even those not hosting the router. However such agents
will just skip the notification if not hosting the router - this should
be quite cheap.

Closes-Bug: #1614452
Change-Id: I1fb533d7804b131f709b790fc730ed7b97cb5499
(cherry picked from commit 4bdab5cf1da333cf4e7aaf893e14b094fc5fad61)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/32/360732/2 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/unit/api/rpc/agentnotifiers/test_l3_rpc_agent_api.py', 'neutron/api/rpc/agentnotifiers/l3_rpc_agent_api.py']",2,33ced8d02ea943c8efd4d9901114fd32ab0fdcbc,bug/1614452," dvr_arptable = {'router_id': router_id, 'arp_table': data} LOG.debug('Fanout dvr_arptable update: %s', dvr_arptable) cctxt = self.client.prepare(fanout=True, version='1.2') cctxt.cast(context, method, payload=dvr_arptable)"," adminContext = (context.is_admin and context or context.elevated()) plugin = manager.NeutronManager.get_service_plugins().get( service_constants.L3_ROUTER_NAT) hosts = plugin.get_hosts_to_notify(adminContext, router_id) # TODO(murali): replace cast with fanout to avoid performance # issues at greater scale. for host in hosts: log_topic = '%s.%s' % (topics.L3_AGENT, host) LOG.debug('Casting message %(method)s with topic %(topic)s', {'topic': log_topic, 'method': method}) dvr_arptable = {'router_id': router_id, 'arp_table': data} cctxt = self.client.prepare(topic=topics.L3_AGENT, server=host, version='1.2') cctxt.cast(context, method, payload=dvr_arptable)",51,17
openstack%2Fkeystone~master~I97e7701bc5b8765d207cc721793643bcefa2d4e2,openstack/keystone,master,I97e7701bc5b8765d207cc721793643bcefa2d4e2,Add credential setup command,MERGED,2016-08-29 13:39:27.000000000,2016-08-29 21:04:08.000000000,2016-08-29 21:04:08.000000000,"[{'_account_id': 3}, {'_account_id': 6482}, {'_account_id': 7725}, {'_account_id': 8119}, {'_account_id': 11022}]","[{'number': 1, 'created': '2016-08-29 13:39:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/578bdb09cd0045a31fd4a30ae76206846b6a6aa1', 'message': 'Add credential setup command\n\nThis will add a command to keystone-manage to setup a fernet key repository for\nencrypting credentials.\n\npartially-implements bp credential-encryption\n\nChange-Id: I97e7701bc5b8765d207cc721793643bcefa2d4e2\n'}, {'number': 2, 'created': '2016-08-29 13:55:39.000000000', 'files': ['keystone/cmd/cli.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/ceec0099b3164dc3f9a50d15f1c56ec54e0d7063', 'message': 'Add credential setup command\n\nThis will add a command to keystone-manage to setup a fernet key repository for\nencrypting credentials.\n\npartially-implements bp credential-encryption\n\nChange-Id: I97e7701bc5b8765d207cc721793643bcefa2d4e2\n'}]",2,362122,ceec0099b3164dc3f9a50d15f1c56ec54e0d7063,11,5,2,5046,,,0,"Add credential setup command

This will add a command to keystone-manage to setup a fernet key repository for
encrypting credentials.

partially-implements bp credential-encryption

Change-Id: I97e7701bc5b8765d207cc721793643bcefa2d4e2
",git fetch https://review.opendev.org/openstack/keystone refs/changes/22/362122/1 && git format-patch -1 --stdout FETCH_HEAD,['keystone/cmd/cli.py'],1,578bdb09cd0045a31fd4a30ae76206846b6a6aa1,bug/credential-encryption,"from keystone.credential.providers import fernet as credential_fernetclass CredentialSetup(BasePermissionsSetup): """"""Setup a Fernet key repository for credential encryption. The purpose of this command is very similar to `keystone-manage fernet_setup` only the keys included in this repository are for encrypting and decrypting credential secrets instead of token payloads. Key can be rotated using `keystone-manage credential_rotate`. """""" name = 'credential_setup' @classmethod def main(cls): from keystone.common import fernet_utils as utils fernet_utils = utils.FernetUtils( CONF.credential.key_repository, credential_fernet.MAX_ACTIVE_KEYS ) keystone_user_id, keystone_group_id = cls.get_user_group() fernet_utils.create_key_directory(keystone_user_id, keystone_group_id) if fernet_utils.validate_key_repository(requires_write=True): fernet_utils.initialize_key_repository( keystone_user_id, keystone_group_id ) CredentialSetup,",,30,0
openstack%2Fkeystone~master~I6be5e37fac9a40e405158e09b3af47c7325de524,openstack/keystone,master,I6be5e37fac9a40e405158e09b3af47c7325de524,Let upgrade tests control all 4 repositories at once,MERGED,2016-08-25 16:31:35.000000000,2016-08-29 21:03:53.000000000,2016-08-29 21:03:53.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 5046}, {'_account_id': 5707}, {'_account_id': 6482}, {'_account_id': 7725}, {'_account_id': 23058}]","[{'number': 1, 'created': '2016-08-25 16:31:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/873e25ba73925aa8d46240669c65707f16ad3c02', 'message': 'Let upgrade tests control all 4 repositories at once\n\nChange-Id: I6be5e37fac9a40e405158e09b3af47c7325de524\n'}, {'number': 2, 'created': '2016-08-25 18:26:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/23c8cd7e24c26641f39e2e630a694a8ad6088bb7', 'message': 'Let upgrade tests control all 4 repositories at once\n\nChange-Id: I6be5e37fac9a40e405158e09b3af47c7325de524\n'}, {'number': 3, 'created': '2016-08-25 18:50:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/f35374a2a52f348e5d45dc6dd31e2aa5bcace6ea', 'message': 'Let upgrade tests control all 4 repositories at once\n\nChange-Id: I6be5e37fac9a40e405158e09b3af47c7325de524\n'}, {'number': 4, 'created': '2016-08-25 19:41:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/6a914d46f3184f9982d78b5a59673b54ea871aee', 'message': 'Let upgrade tests control all 4 repositories at once\n\nChange-Id: I6be5e37fac9a40e405158e09b3af47c7325de524\n'}, {'number': 5, 'created': '2016-08-25 19:58:32.000000000', 'files': ['keystone/tests/unit/test_sql_upgrade.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/f66077f356538736f875e15b56d25ee876fbb884', 'message': 'Let upgrade tests control all 4 repositories at once\n\nChange-Id: I6be5e37fac9a40e405158e09b3af47c7325de524\n'}]",6,360667,f66077f356538736f875e15b56d25ee876fbb884,18,7,5,4,,,0,"Let upgrade tests control all 4 repositories at once

Change-Id: I6be5e37fac9a40e405158e09b3af47c7325de524
",git fetch https://review.opendev.org/openstack/keystone refs/changes/67/360667/5 && git format-patch -1 --stdout FETCH_HEAD,['keystone/tests/unit/test_sql_upgrade.py'],1,873e25ba73925aa8d46240669c65707f16ad3c02,bug/credential-encryption,"class MigrationRepository(object): def __init__(self, engine, repo_name): self.repo_name = repo_name package=sql, repo_name=self.repo_name) engine, self.repo_path, self._initial_db_version) self.metadata = sqlalchemy.MetaData() self.metadata.bind = engine def upgrade(self, version=None, current_schema=None): version = version or self.max_version err = '' upgrade = True version = versioning_api._migrate_version( self.schema_, version, upgrade, err) if not current_schema: current_schema = self.schema_ changeset = current_schema.changeset(version) for ver, change in changeset: self.schema_.runchange(ver, change, changeset.step) if self.schema_.version != version: raise Exception( 'Actual version (%s) of %s does not equal expected ' 'version (%s)' % ( self.schema_.version, self.repo_name, version)) class SqlMigrateBase(test_base.DbTestCase): self.repositories = { 'legacy': MigrationRepository(self.engine, 'migrate_repo'), 'expand': MigrationRepository(self.engine, 'expand_repo'), 'migrate': MigrationRepository(self.engine, 'data_migration_repo'), 'contract': MigrationRepository(self.engine, 'contract_repo')} def upgrade(self, *args, **kwargs): """"""Upgrade the legacy migration repository."""""" self.repositories['legacy'].upgrade(*args, **kwargs) def expand(self, *args, **kwargs): """"""Expand database schema."""""" self.repositories['expand'].upgrade(*args, **kwargs) def migrate(self, *args, **kwargs): """"""Migrate data."""""" self.repositories['migrate'].upgrade(*args, **kwargs) def contract(self, *args, **kwargs): """"""Contract database schema."""""" self.repositories['contract'].upgrade(*args, **kwargs) @property def metadata(self): """"""Pass the legacy metadata reference through for legacy repo tests."""""" return self.repositories['legacy'].metadata self.upgrade() self.expand(1) self.migrate(1) self.contract(1) self.expand(2) self.migrate(2) self.contract(2)","class SqlMigrateBase(test_base.DbTestCase): # override this in subclasses. The default of zero covers tests such # as extensions upgrades. _initial_db_version = 0 def initialize_sql(self): self.metadata = sqlalchemy.MetaData() self.metadata.bind = self.engine def repo_package(self): return sql def initialize_repo(self, repo_name=LEGACY_REPO): package=self.repo_package(), repo_name=repo_name) self.engine, self.repo_path, self._initial_db_version) self.initialize_sql() self.initialize_repo() def upgrade(self, *args, **kwargs): self._migrate(*args, **kwargs) def _migrate(self, version, repository=None, downgrade=False, current_schema=None): repository = repository or self.repo_path err = '' version = versioning_api._migrate_version(self.schema_, version, not downgrade, err) if not current_schema: current_schema = self.schema_ changeset = current_schema.changeset(version) for ver, change in changeset: self.schema_.runchange(ver, change, changeset.step) self.assertEqual(self.schema_.version, version) self.initialize_sql() _initial_db_version = migration_helpers.get_init_version() self.upgrade(self.max_version) self.initialize_repo(repo_name=EXPAND_REPO) self.upgrade(1) self.initialize_repo(repo_name=DATA_MIGRATION_REPO) self.upgrade(1) self.initialize_repo(repo_name=CONTRACT_REPO) self.upgrade(1) self.initialize_repo(repo_name=EXPAND_REPO) self.upgrade(2) self.initialize_repo(repo_name=DATA_MIGRATION_REPO) self.upgrade(2) self.initialize_repo(repo_name=CONTRACT_REPO) self.upgrade(2)",61,53
openstack%2Fkeystone~master~I2cd3970d9eac00d9d832f97d44f0750671ecb131,openstack/keystone,master,I2cd3970d9eac00d9d832f97d44f0750671ecb131,Fix wrong response codes in 'groups' APIs.,MERGED,2016-08-29 09:45:09.000000000,2016-08-29 21:03:36.000000000,2016-08-29 21:03:36.000000000,"[{'_account_id': 3}, {'_account_id': 6482}, {'_account_id': 7725}, {'_account_id': 11022}, {'_account_id': 15905}, {'_account_id': 17860}, {'_account_id': 18338}]","[{'number': 1, 'created': '2016-08-29 09:45:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/d2df3035eab8f4f6d98c64e53dec8d3768ef3bad', 'message': ""Fix wrong response codes in 'groups' APIs.\n\nChange-Id: I2cd3970d9eac00d9d832f97d44f0750671ecb131\n""}, {'number': 2, 'created': '2016-08-29 18:19:11.000000000', 'files': ['api-ref/source/v3/groups.inc'], 'web_link': 'https://opendev.org/openstack/keystone/commit/c81b3374df4312f1351ae8828998fab69f3e00cb', 'message': ""Fix wrong response codes in 'groups' APIs.\n\nChange-Id: I2cd3970d9eac00d9d832f97d44f0750671ecb131\n""}]",6,361973,c81b3374df4312f1351ae8828998fab69f3e00cb,13,7,2,19935,,,0,"Fix wrong response codes in 'groups' APIs.

Change-Id: I2cd3970d9eac00d9d832f97d44f0750671ecb131
",git fetch https://review.opendev.org/openstack/keystone refs/changes/73/361973/1 && git format-patch -1 --stdout FETCH_HEAD,['api-ref/source/v3/groups.inc'],1,d2df3035eab8f4f6d98c64e53dec8d3768ef3bad,,"Normal response codes: 204 Error response codes: 413, 415, 405, 404, 403, 401, 400, 503, 409Normal response codes: 200, 201 Error response codes: 413,415,405,404,403,401,400,503,409","Error response codes:204,413,415,405,404,403,401,400,503,409,Error response codes:204,413,415,405,404,403,401,400,503,409,",6,2
openstack%2Fkeystone~master~I6cc9c7a0e306dbbad61c77caa07df00fb3fa7a97,openstack/keystone,master,I6cc9c7a0e306dbbad61c77caa07df00fb3fa7a97,Make token_id a required parameter in v3_to_v2_token,MERGED,2016-08-29 15:56:21.000000000,2016-08-29 21:02:46.000000000,2016-08-29 21:02:46.000000000,"[{'_account_id': 3}, {'_account_id': 5046}, {'_account_id': 6482}, {'_account_id': 8119}, {'_account_id': 17860}, {'_account_id': 18338}, {'_account_id': 21728}]","[{'number': 1, 'created': '2016-08-29 15:56:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/9a10dd310b230af1f5c28b7ee331fc85064747c1', 'message': 'Make token_id a required parameter in v3_to_v2_token\n\nThe v3_to_v2_token() method in keystone.token.providers.common\naccepted token_id as an option parameter. This is because it was\nnever always passed in on validation. This commit makes token_id\na required parameter of the method and fixes its useage to always\nsupply it.\n\nChange-Id: I6cc9c7a0e306dbbad61c77caa07df00fb3fa7a97\n'}, {'number': 2, 'created': '2016-08-29 17:18:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/c7ad5edfd02ac6a4f18408656b54f348d28ae5a1', 'message': 'Make token_id a required parameter in v3_to_v2_token\n\nThe v3_to_v2_token() method in keystone.token.providers.common\naccepted token_id as an option parameter. This is because it was\nnever always passed in on validation. This commit makes token_id\na required parameter of the method and fixes its useage to always\nsupply it.\n\nChange-Id: I6cc9c7a0e306dbbad61c77caa07df00fb3fa7a97\n'}, {'number': 3, 'created': '2016-08-29 17:44:08.000000000', 'files': ['keystone/token/provider.py', 'keystone/token/providers/common.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/94b08af4314bf6552183573fb2f92ceca15dd50a', 'message': 'Make token_id a required parameter in v3_to_v2_token\n\nThe v3_to_v2_token() method in keystone.token.providers.common\naccepted token_id as an option parameter. This is because it was\nnot always passed in on validation. This commit makes token_id\na required parameter of the method and fixes its usage to always\nsupply it.\n\nChange-Id: I6cc9c7a0e306dbbad61c77caa07df00fb3fa7a97\n'}]",12,362220,94b08af4314bf6552183573fb2f92ceca15dd50a,21,7,3,5046,,,0,"Make token_id a required parameter in v3_to_v2_token

The v3_to_v2_token() method in keystone.token.providers.common
accepted token_id as an option parameter. This is because it was
not always passed in on validation. This commit makes token_id
a required parameter of the method and fixes its usage to always
supply it.

Change-Id: I6cc9c7a0e306dbbad61c77caa07df00fb3fa7a97
",git fetch https://review.opendev.org/openstack/keystone refs/changes/20/362220/3 && git format-patch -1 --stdout FETCH_HEAD,"['keystone/token/provider.py', 'keystone/token/providers/common.py']",2,9a10dd310b230af1f5c28b7ee331fc85064747c1,362220," def v3_to_v2_token(self, v3_token_data, token_id): token_id = token_ref['id'] token_data, token_id)"," def v3_to_v2_token(self, v3_token_data, token_id=None): token_data) token_id = token_ref['token_data']['access']['token']['id']",4,5
openstack%2Fswift~master~Ie70e40d6b55f379b0cc9bc372a35705462cade8b,openstack/swift,master,Ie70e40d6b55f379b0cc9bc372a35705462cade8b,Remove unnecessary tearDown,MERGED,2016-08-29 06:15:00.000000000,2016-08-29 21:01:08.000000000,2016-08-29 21:01:08.000000000,"[{'_account_id': 3}, {'_account_id': 6968}, {'_account_id': 15343}]","[{'number': 1, 'created': '2016-08-29 06:15:00.000000000', 'files': ['test/probe/test_object_metadata_replication.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/d68b1bd6ddf44c5088e9d02dcb2f1b802c71411b', 'message': 'Remove unnecessary tearDown\n\nThis is to remove unnecessary tearDown to keep code clean.\n\nChange-Id: Ie70e40d6b55f379b0cc9bc372a35705462cade8b\n'}]",0,361870,d68b1bd6ddf44c5088e9d02dcb2f1b802c71411b,8,3,1,20190,,,0,"Remove unnecessary tearDown

This is to remove unnecessary tearDown to keep code clean.

Change-Id: Ie70e40d6b55f379b0cc9bc372a35705462cade8b
",git fetch https://review.opendev.org/openstack/swift refs/changes/70/361870/1 && git format-patch -1 --stdout FETCH_HEAD,['test/probe/test_object_metadata_replication.py'],1,d68b1bd6ddf44c5088e9d02dcb2f1b802c71411b,,," def tearDown(self): super(Test, self).tearDown() ",0,3
openstack%2Fsyntribos~master~I125b77bf8e71d3b54baa1d719945b18c36136cfb,openstack/syntribos,master,I125b77bf8e71d3b54baa1d719945b18c36136cfb,payload data now processed as unicode,ABANDONED,2016-05-10 17:55:11.000000000,2016-08-29 21:00:20.000000000,,"[{'_account_id': 3}, {'_account_id': 15259}, {'_account_id': 15515}, {'_account_id': 17709}, {'_account_id': 18462}, {'_account_id': 18729}, {'_account_id': 21297}]","[{'number': 1, 'created': '2016-05-10 17:55:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/syntribos/commit/6ded931b8b829fa67754c7699f5c314d4b97eddc', 'message': 'Fixes bug 1580250\n\npayload data now processed as unicode\n\nChange-Id: I125b77bf8e71d3b54baa1d719945b18c36136cfb\n'}, {'number': 2, 'created': '2016-05-10 17:59:33.000000000', 'files': ['syntribos/tests/fuzz/datagen.py', 'syntribos/tests/fuzz/base_fuzz.py', 'syntribos/clients/http/models.py'], 'web_link': 'https://opendev.org/openstack/syntribos/commit/f2669a894f06f613d2851d09d23872ff54d90b8b', 'message': 'payload data now processed as unicode\n\nFixes bug 1580250\n\nChange-Id: I125b77bf8e71d3b54baa1d719945b18c36136cfb\n'}]",0,314700,f2669a894f06f613d2851d09d23872ff54d90b8b,9,7,2,17709,,,0,"payload data now processed as unicode

Fixes bug 1580250

Change-Id: I125b77bf8e71d3b54baa1d719945b18c36136cfb
",git fetch https://review.opendev.org/openstack/syntribos refs/changes/00/314700/2 && git format-patch -1 --stdout FETCH_HEAD,"['syntribos/tests/fuzz/datagen.py', 'syntribos/tests/fuzz/base_fuzz.py', 'syntribos/clients/http/models.py']",3,6ded931b8b829fa67754c7699f5c314d4b97eddc,bug/1580250," str_data = ElementTree.tostring(data, encoding=""UTF-8"")", str_data = ElementTree.tostring(data),4,3
openstack%2Ffuel-library~master~I2b02bf692b3778c85715dc9058a482bea4072ecb,openstack/fuel-library,master,I2b02bf692b3778c85715dc9058a482bea4072ecb,Puppet4 support: l23network l3_clear_route,ABANDONED,2016-08-29 15:16:38.000000000,2016-08-29 20:59:48.000000000,,"[{'_account_id': 3}, {'_account_id': 7468}, {'_account_id': 8971}, {'_account_id': 11827}, {'_account_id': 16771}, {'_account_id': 20656}]","[{'number': 1, 'created': '2016-08-29 15:16:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/63dcdc4cd232de496b91fa1702dbc5a7bbd7f116', 'message': 'Puppet4 support: l23network l3_clear_route\n\n* Remove the mutators for the frozen strings in the validator\n\nChange-Id: I2b02bf692b3778c85715dc9058a482bea4072ecb\nRelated-Bug: 1586480\n'}, {'number': 2, 'created': '2016-08-29 19:06:55.000000000', 'files': ['deployment/puppet/l23network/lib/puppet/type/l3_clear_route.rb'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/c98595b570fa7ba8e08556c2cc5de2d614df5dd6', 'message': 'Puppet4 support: l23network l3_clear_route\n\n* Remove the mutators for the frozen strings in the validator\n\nChange-Id: I2b02bf692b3778c85715dc9058a482bea4072ecb\nRelated-Bug: 1586480\n'}]",0,362186,c98595b570fa7ba8e08556c2cc5de2d614df5dd6,37,6,2,9037,,,0,"Puppet4 support: l23network l3_clear_route

* Remove the mutators for the frozen strings in the validator

Change-Id: I2b02bf692b3778c85715dc9058a482bea4072ecb
Related-Bug: 1586480
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/86/362186/2 && git format-patch -1 --stdout FETCH_HEAD,['deployment/puppet/l23network/lib/puppet/type/l3_clear_route.rb'],1,63dcdc4cd232de496b91fa1702dbc5a7bbd7f116,bug/1586480, val = val.strip val = val.strip, val.strip! val.strip!,2,2
openstack%2Ftripleo-heat-templates~master~I12562d3ae5178bbce66d346066b6fa095ba63781,openstack/tripleo-heat-templates,master,I12562d3ae5178bbce66d346066b6fa095ba63781,Test new scenario001 job,ABANDONED,2016-08-24 18:35:26.000000000,2016-08-29 20:59:06.000000000,,"[{'_account_id': 3}, {'_account_id': 3153}]","[{'number': 1, 'created': '2016-08-24 18:35:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/a5dbf74ccbd8b58af67177b5f0882e2be2710d8f', 'message': ""Test new scenario001 job\n\nTest new scenario001 job that:\n- doesn't deploy Swift and Cinder\n- deploy Sahara\n- deploy Glance with file backend\n\nDepends-On: I25521a8bf8b91f7df4020de6599c4e8420e81fef\nChange-Id: I12562d3ae5178bbce66d346066b6fa095ba63781\n""}, {'number': 2, 'created': '2016-08-25 01:21:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/f4b7d869dfe59b1a034e3a8591495cf2b2140430', 'message': ""Test new scenario001 job\n\nTest new scenario001 job that:\n- doesn't deploy Swift and Cinder\n- deploy Sahara\n- deploy Glance with file backend\n\nDepends-On: I25521a8bf8b91f7df4020de6599c4e8420e81fef\nChange-Id: I12562d3ae5178bbce66d346066b6fa095ba63781\n""}, {'number': 3, 'created': '2016-08-25 02:23:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/f81e4f412d5a7ae8b41ce8e86ac4f460d6a5187a', 'message': ""Test new scenario001 job\n\nTest new scenario001 job that:\n- doesn't deploy Swift and Cinder\n- deploy Sahara\n- deploy Glance with file backend\n\nDo not merge it.\n\nDepends-On: I25521a8bf8b91f7df4020de6599c4e8420e81fef\nChange-Id: I12562d3ae5178bbce66d346066b6fa095ba63781\n""}, {'number': 4, 'created': '2016-08-25 17:59:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/928c0a0086dd6ec747d6d7ee2d078d066eff87b0', 'message': ""Test new scenario001 job\n\nTest new scenario001 job that:\n- doesn't deploy Swift and Cinder\n- deploy Sahara\n- deploy Glance with file backend\n\nDo not merge it.\n\nDepends-On: I25521a8bf8b91f7df4020de6599c4e8420e81fef\nChange-Id: I12562d3ae5178bbce66d346066b6fa095ba63781\n""}, {'number': 5, 'created': '2016-08-26 13:37:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/80de9a1f3bd74431f993c77e7e84ac836519aea1', 'message': ""Test new scenario001 job\n\nTest new scenario001 job that:\n- doesn't deploy Swift and Cinder\n- deploy Sahara\n- deploy Glance with file backend\n\nDo not merge it.\n\nDepends-On: I25521a8bf8b91f7df4020de6599c4e8420e81fef\nChange-Id: I12562d3ae5178bbce66d346066b6fa095ba63781\n""}, {'number': 6, 'created': '2016-08-26 16:31:36.000000000', 'files': ['puppet/services/sahara-base.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/3cb80231e02836e1c7e8a21e8a70a893bbf8650d', 'message': ""Test new scenario001 job\n\nTest new scenario001 job that:\n- doesn't deploy Swift and Cinder\n- deploy Sahara\n- deploy Glance with file backend\n\nDo not merge it.\n\nDepends-On: I25521a8bf8b91f7df4020de6599c4e8420e81fef\nChange-Id: I12562d3ae5178bbce66d346066b6fa095ba63781\n""}]",0,360040,3cb80231e02836e1c7e8a21e8a70a893bbf8650d,37,2,6,3153,,,0,"Test new scenario001 job

Test new scenario001 job that:
- doesn't deploy Swift and Cinder
- deploy Sahara
- deploy Glance with file backend

Do not merge it.

Depends-On: I25521a8bf8b91f7df4020de6599c4e8420e81fef
Change-Id: I12562d3ae5178bbce66d346066b6fa095ba63781
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/40/360040/6 && git format-patch -1 --stdout FETCH_HEAD,['puppet/services/sahara-base.yaml'],1,a5dbf74ccbd8b58af67177b5f0882e2be2710d8f,scenario001,# test ,,2,0
openstack%2Fneutron~master~I41940bea0327ee31494bd95867d0e60d9b5a24b8,openstack/neutron,master,I41940bea0327ee31494bd95867d0e60d9b5a24b8,Auto allocation: ensure that networks and subnets are cleaned up,MERGED,2016-08-28 07:22:12.000000000,2016-08-29 20:54:45.000000000,2016-08-29 20:54:45.000000000,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 1131}, {'_account_id': 1653}, {'_account_id': 5170}, {'_account_id': 6524}, {'_account_id': 9732}, {'_account_id': 10385}, {'_account_id': 13933}, {'_account_id': 14208}, {'_account_id': 14611}, {'_account_id': 15752}, {'_account_id': 16376}]","[{'number': 1, 'created': '2016-08-28 07:22:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/702f683ebe3e06d4467c2ff2f31e381242383214', 'message': 'Auto allocation: add in extra debug info\n\nWhen router allocation fails it is difficult for an admin to\nunderstand the root cause. Adding the exception here will provide\na little additional information.\n\nTrivialFix\n\nChange-Id: I41940bea0327ee31494bd95867d0e60d9b5a24b8\n'}, {'number': 2, 'created': '2016-08-28 08:07:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/39311d1e084aeab166d8ef89fe817d09b091b3b7', 'message': 'Auto allocation: ensure that networks and subnets are cleaned up\n\nIn the event of a router create failure we need to make sure that\nthe allocated resources are cleaned up.\n\nWhen router allocation fails it is difficult for an admin to\nunderstand the root cause. Adding the exception here will provide\na little additional information.\n\nCloses-bug: #1617707\n\nChange-Id: I41940bea0327ee31494bd95867d0e60d9b5a24b8\n'}, {'number': 3, 'created': '2016-08-28 08:45:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e9623b2ba3272c0693b82d910b88d823d83b7f00', 'message': 'Auto allocation: ensure that networks and subnets are cleaned up\n\nIn the event of a router create failure we need to make sure that\nthe allocated resources are cleaned up.\n\nWhen router allocation fails it is difficult for an admin to\nunderstand the root cause. Adding the exception here will provide\na little additional information.\n\nCloses-bug: #1617707\n\nChange-Id: I41940bea0327ee31494bd95867d0e60d9b5a24b8\n'}, {'number': 4, 'created': '2016-08-28 08:54:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/9f88641562030f2fe64777072f91941dc5ccc32f', 'message': 'Auto allocation: ensure that networks and subnets are cleaned up\n\nIn the event of a router create failure we need to make sure that\nthe allocated resources are cleaned up.\n\nWhen router allocation fails it is difficult for an admin to\nunderstand the root cause. Adding the exception here will provide\na little additional information.\n\nCloses-bug: #1617707\n\nChange-Id: I41940bea0327ee31494bd95867d0e60d9b5a24b8\n'}, {'number': 5, 'created': '2016-08-29 15:42:22.000000000', 'files': ['neutron/services/auto_allocate/db.py', 'neutron/tests/unit/services/auto_allocate/test_db.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/8fdc430e62e8f575499940ea73225d842db3927a', 'message': 'Auto allocation: ensure that networks and subnets are cleaned up\n\nIn the event of a router create failure we need to make sure that\nthe allocated resources are cleaned up.\n\nWhen router allocation fails it is difficult for an admin to\nunderstand the root cause. Adding the exception here will provide\na little additional information.\n\nCloses-bug: #1617707\n\nChange-Id: I41940bea0327ee31494bd95867d0e60d9b5a24b8\n'}]",7,361699,8fdc430e62e8f575499940ea73225d842db3927a,40,13,5,1653,,,0,"Auto allocation: ensure that networks and subnets are cleaned up

In the event of a router create failure we need to make sure that
the allocated resources are cleaned up.

When router allocation fails it is difficult for an admin to
understand the root cause. Adding the exception here will provide
a little additional information.

Closes-bug: #1617707

Change-Id: I41940bea0327ee31494bd95867d0e60d9b5a24b8
",git fetch https://review.opendev.org/openstack/neutron refs/changes/99/361699/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/services/auto_allocate/db.py'],1,702f683ebe3e06d4467c2ff2f31e381242383214,router-exception," except n_exc.BadRequest as e: ""%(tenant_id)s because of router errors. "" ""Reason: %(reason)s""), {'tenant_id': tenant_id, 'reason': e})"," except n_exc.BadRequest: ""%s because of router errors.""), tenant_id)",4,2
openstack%2Fsyntribos~master~Id39e122b2b4c1c9cafab09fdbc5d172dec012d22,openstack/syntribos,master,Id39e122b2b4c1c9cafab09fdbc5d172dec012d22,Revamped results schema,MERGED,2016-08-26 22:30:36.000000000,2016-08-29 20:51:52.000000000,2016-08-29 20:51:52.000000000,"[{'_account_id': 3}, {'_account_id': 15515}, {'_account_id': 17709}, {'_account_id': 18462}]","[{'number': 1, 'created': '2016-08-26 22:30:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/syntribos/commit/ca8e638feef2d09b2b203e700a77fbaa3111b8d5', 'message': 'Revamped results schema\n\nResults are now formatted in the schema as defined here:\nhttps://gist.github.com/cneill/a511451284a0c5f33295477150bd94d4\n\nFurthermore, the json formatter is no longer responsible for the aggregation\nof issues. Instead, this logic has been moved to the IssueTestResult class\n\nChange-Id: Id39e122b2b4c1c9cafab09fdbc5d172dec012d22\n'}, {'number': 2, 'created': '2016-08-26 22:46:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/syntribos/commit/cfb64f91f86fcb8b5fbc93a8e5587595e39fadd5', 'message': 'Revamped results schema\n\nResults are now formatted in the schema as defined here:\nhttps://gist.github.com/cneill/a511451284a0c5f33295477150bd94d4\n\nFurthermore, the json formatter is no longer responsible for the aggregation\nof issues. Instead, this logic has been moved to the IssueTestResult class\n\nChange-Id: Id39e122b2b4c1c9cafab09fdbc5d172dec012d22\n'}, {'number': 3, 'created': '2016-08-26 23:00:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/syntribos/commit/f8811637d9fecf2a392ea2b56a4499f3330a314a', 'message': 'Revamped results schema\n\nResults are now formatted in the schema as defined here:\nhttps://gist.github.com/cneill/a511451284a0c5f33295477150bd94d4\n\nFurthermore, the json formatter is no longer responsible for the aggregation\nof issues. Instead, this logic has been moved to the IssueTestResult class\n\nChange-Id: Id39e122b2b4c1c9cafab09fdbc5d172dec012d22\n'}, {'number': 4, 'created': '2016-08-26 23:38:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/syntribos/commit/6426ccbdb32da88a9c6dfd8fbb667f0b76a76f67', 'message': 'Revamped results schema\n\nResults are now formatted in the schema as defined here:\nhttps://gist.github.com/cneill/a511451284a0c5f33295477150bd94d4\n\nFurthermore, the json formatter is no longer responsible for the aggregation\nof issues. Instead, this logic has been moved to the IssueTestResult class\n\nChange-Id: Id39e122b2b4c1c9cafab09fdbc5d172dec012d22\n'}, {'number': 5, 'created': '2016-08-29 20:35:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/syntribos/commit/5b99ced8efb5f3458eaeb1caa4eba6db7dd12552', 'message': 'Revamped results schema\n\nResults are now formatted in the schema as defined here:\nhttps://gist.github.com/cneill/a511451284a0c5f33295477150bd94d4\n\nFurthermore, the json formatter is no longer responsible for the aggregation\nof issues. Instead, this logic has been moved to the IssueTestResult class\n\nChange-Id: Id39e122b2b4c1c9cafab09fdbc5d172dec012d22\n'}, {'number': 6, 'created': '2016-08-29 20:40:08.000000000', 'files': ['syntribos/tests/fuzz/base_fuzz.py', 'syntribos/runner.py', 'syntribos/formatters/json_formatter.py', 'tests/unit/test_results.py', 'syntribos/result.py'], 'web_link': 'https://opendev.org/openstack/syntribos/commit/adca69a2723dac8aa9d722324e422a9f49f17680', 'message': 'Revamped results schema\n\nResults are now formatted in the schema as defined here:\nhttps://gist.github.com/cneill/a511451284a0c5f33295477150bd94d4\n\nFurthermore, the json formatter is no longer responsible for the aggregation\nof issues. Instead, this logic has been moved to the IssueTestResult class\n\nChange-Id: Id39e122b2b4c1c9cafab09fdbc5d172dec012d22\n'}]",1,361507,adca69a2723dac8aa9d722324e422a9f49f17680,20,4,6,17709,,,0,"Revamped results schema

Results are now formatted in the schema as defined here:
https://gist.github.com/cneill/a511451284a0c5f33295477150bd94d4

Furthermore, the json formatter is no longer responsible for the aggregation
of issues. Instead, this logic has been moved to the IssueTestResult class

Change-Id: Id39e122b2b4c1c9cafab09fdbc5d172dec012d22
",git fetch https://review.opendev.org/openstack/syntribos refs/changes/07/361507/6 && git format-patch -1 --stdout FETCH_HEAD,"['syntribos/runner.py', 'syntribos/formatters/json_formatter.py', 'syntribos/config.py', 'syntribos/result.py']",4,ca8e638feef2d09b2b203e700a77fbaa3111b8d5,formatter_schema," output = {""failures"": {}, ""errors"": [], ""stats"": {}} output[""stats""][""severity""] = { ""UNDEFINED"": 0, ""LOW"": 0, ""MEDIUM"": 0, ""HIGH"": 0 } severity_counter_dict = {} failure_id = 0 Appends issues to the result""s list of failures, as well as for issue in test.failures: defect_type = issue.defect_type if any([True for x in CONF.syntribos.exclude_results if x and x in defect_type]): continue target = issue.target path = issue.path url = ""{0}{1}"".format(target, path) description = issue.description failure_obj = None for f in self.failures: if (f[""url""] == url and f[""defect_type""] == defect_type and f[""description""] == description): failure_obj = f break if not failure_obj: failure_obj = { ""url"": url, ""defect_type"": defect_type, ""description"": description, ""failure_id"": self.failure_id, ""instances"": [] } self.failures.append(failure_obj) self.failure_id += 1 signals = {} if issue.init_signals: signals[""init_signals""] = set( [s.slug for s in issue.init_signals]) if issue.test_signals: signals[""test_signals""] = set( [s.slug for s in issue.test_signals]) if issue.diff_signals: signals[""diff_signals""] = set( [s.slug for s in issue.diff_signals]) sev_rating = syntribos.RANKING[issue.severity] conf_rating = syntribos.RANKING[issue.confidence] if issue.impacted_parameter: method = issue.impacted_parameter.method loc = issue.impacted_parameter.location name = issue.impacted_parameter.name content_type = issue.content_type payload_string = issue.impacted_parameter.trunc_fuzz_string param = { ""method"": method, ""location"": loc, } if loc == ""data"": param[""type""] = content_type instance_obj = None for i in failure_obj[""instances""]: if(i[""confidence""] == conf_rating and i[""severity""] == sev_rating and i[""param""][""method""] == method and i[""param""][""location""] == loc): i[""param""][""variables""].add(name) for sig_type in signals: if sig_type in i[""signals""]: i[""signals""][sig_type].update( signals[sig_type]) else: i[""signals""][sig_type] = signals[sig_type] i[""strings""].add(payload_string) instance_obj = i break if not instance_obj: param[""variables""] = set([name]) instance_obj = { ""confidence"": conf_rating, ""severity"": sev_rating, ""param"": param, ""strings"": set([payload_string]), ""signals"": signals } failure_obj[""instances""].append(instance_obj) else: instance_obj = None for i in failure_obj[""instance""]: if(i[""confidence""] == conf_rating and i[""severity""] == sev_rating): for sig_type in signals: if sig_type in i[""signals""]: i[""signals""][sig_type].update( signals[sig_type]) else: i[""signals""][sig_type] = signals[sig_type] instance_obj = i break if not instance_obj: instance_obj = { ""confidence"": conf_rating, ""severity"": sev_rating, ""signals"": signals } failure_obj[""instances""].append(instance_obj) self.errors.append( { ""test"": self.getDescription(test), ""error"": self._exc_info_to_string(err, test) }) def printErrors(self, output_format): self.output[""errors""] = self.errors self.output[""failures""] = self.failures formatter.report(self.output) self.printErrors(CONF.output_format) num_fail = self.stats[""failures""] num_err = self.stats[""errors""] f=num_fail, e=num_err, fsuff=""s"" * bool(num_fail - 1), esuff=""s"" * bool(num_err - 1)))"," Appends issues to the result's list of failures, as well as self.failures.append((test, test.failures)) self.errors.append((test, self._exc_info_to_string(err, test))) def printErrors(self, output_format, min_severity, min_confidence, exclude_results): formatter.report(min_severity, min_confidence, exclude_results) self.printErrors( CONF.output_format, CONF.min_severity, CONF.min_confidence, CONF.syntribos.exclude_results) f=len(self.failures), e=len(self.errors), fsuff=""s"" * bool(len(self.failures) - 1), esuff=""s"" * bool(len(self.errors) - 1)))",133,127
openstack%2Fironic-python-agent~master~Ib5c0c57cafdb6ffd7456e61f3b1bb5fa57520e5a,openstack/ironic-python-agent,master,Ib5c0c57cafdb6ffd7456e61f3b1bb5fa57520e5a,Enforce upper-constraints when building ramdisks,MERGED,2016-08-22 20:50:20.000000000,2016-08-29 20:49:23.000000000,2016-08-29 20:49:23.000000000,"[{'_account_id': 3}, {'_account_id': 7080}, {'_account_id': 10342}, {'_account_id': 11655}, {'_account_id': 12898}, {'_account_id': 14760}]","[{'number': 1, 'created': '2016-08-22 20:50:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/cd38ffbdb27c3f3ed70192c6baa12fa8bc12703f', 'message': 'Enforce upper-constraints when building CoreOS image\n\nCurrently, building the CoreOS installs ironic-python-agent without\npassing any upper-constraints to pip. This causes the package to be\npossibly installed with newer, untested dependencies.\n\nThis commits passes the $UPPER_CONSTRAINTS_FILE variable as\nPIP_CONSTRAINT (equivalent to the ""-c"" parameter to pip [0]). It also\ndefaults to the URL for ""master"". The URL was separated in it\'s own\nvariable to make backports and maintenance easier.\n\n[0] https://pip.pypa.io/en/stable/user_guide/#environment-variables\n\nChange-Id: Ib5c0c57cafdb6ffd7456e61f3b1bb5fa57520e5a\n'}, {'number': 2, 'created': '2016-08-23 17:43:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/314f7f11e7d6d6babe3a578df3f8e060cf04ad00', 'message': 'Enforce upper-constraints when building ramdisks\n\nCurrently, building ramdisks installs ironic-python-agent without any\nupper-constraints. This causes the package to be installed with newer,\nuntested dependencies.\n\nThis commits introduces a tool to generate a local upper-constraints\nfile based on predefined business logic. Additionally, the fallback to\nthe openstack/requirements uses the URL defined in tox.ini instead of\nredefining it. This prevents having to keep track of two separate\nvariables when releasing.\n\nChange-Id: Ib5c0c57cafdb6ffd7456e61f3b1bb5fa57520e5a\n'}, {'number': 3, 'created': '2016-08-23 20:30:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/4613247d50887115682cb15c1342443b976d8c1b', 'message': 'Enforce upper-constraints when building ramdisks\n\nCurrently, building ramdisks installs ironic-python-agent without any\nupper-constraints. This causes the package to be installed with newer,\nuntested dependencies.\n\nThis commits introduces a tool to generate a local upper-constraints\nfile based on predefined business logic. Additionally, the fallback to\nthe openstack/requirements uses the URL defined in tox.ini instead of\nredefining it. This prevents having to keep track of two separate\nvariables when releasing.\n\nChange-Id: Ib5c0c57cafdb6ffd7456e61f3b1bb5fa57520e5a\n'}, {'number': 4, 'created': '2016-08-23 20:31:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/d72cdc7b04d9108022f874ebc452ba037d2daed7', 'message': 'Enforce upper-constraints when building ramdisks\n\nCurrently, building ramdisks installs ironic-python-agent without any\nupper-constraints. This causes the package to be installed with newer,\nuntested dependencies.\n\nThis commits introduces a tool to generate a local upper-constraints\nfile based on predefined business logic. Additionally, the fallback to\nthe openstack/requirements uses the URL defined in tox.ini instead of\nredefining it. This prevents having to keep track of two separate\nvariables when releasing.\n\nChange-Id: Ib5c0c57cafdb6ffd7456e61f3b1bb5fa57520e5a\n'}, {'number': 5, 'created': '2016-08-23 23:49:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/fd15db8223d5f198042e75ecdf5bb22accbdd5cd', 'message': 'Enforce upper-constraints when building ramdisks\n\nCurrently, building ramdisks installs ironic-python-agent without any\nupper-constraints. This causes the package to be installed with newer,\nuntested dependencies.\n\nThis commits introduces a tool to generate a local upper-constraints\nfile based on predefined business logic. Additionally, the fallback to\nthe openstack/requirements uses the URL defined in tox.ini instead of\nredefining it. This prevents having to keep track of two separate\nvariables when releasing.\n\nChange-Id: Ib5c0c57cafdb6ffd7456e61f3b1bb5fa57520e5a\n'}, {'number': 6, 'created': '2016-08-24 00:39:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/688eb3a88bf6fc569b9f5146aa756e93d414d2e8', 'message': 'Enforce upper-constraints when building ramdisks\n\nCurrently, building ramdisks installs ironic-python-agent without any\nupper-constraints. This causes the package to be installed with newer,\nuntested dependencies.\n\nThis commits introduces a tool to generate a local upper-constraints\nfile based on predefined business logic. Additionally, the fallback to\nthe openstack/requirements uses the URL defined in tox.ini instead of\nredefining it. This prevents having to keep track of two separate\nvariables when releasing.\n\nChange-Id: Ib5c0c57cafdb6ffd7456e61f3b1bb5fa57520e5a\n'}, {'number': 7, 'created': '2016-08-24 15:23:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/b181cd1efc42a639f7aee02fbec51fcce3597a24', 'message': 'Enforce upper-constraints when building ramdisks\n\nCurrently, building ramdisks installs ironic-python-agent without any\nupper-constraints. This causes the package to be installed with newer,\nuntested dependencies.\n\nThis commits introduces a tool to generate a local upper-constraints\nfile based on predefined strategies (below). Additionally, the fallback\nto the openstack/requirements uses the URL defined in tox.ini instead of\nredefining it. This prevents having to keep track of two separate\nvariables when releasing.\n\nupper-constraints lookup strategies (in order):\n\n  * UPPER_CONSTRAINTS_FILE points to a local file\n  * UPPER_CONSTRAINTS_FILE points to a URL\n  * /opt/stack/new/requirements/upper-constraints.txt\n  * upper-constraints.txt from openstack/requirements git repository\n\nChange-Id: Ib5c0c57cafdb6ffd7456e61f3b1bb5fa57520e5a\n'}, {'number': 8, 'created': '2016-08-24 15:23:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/ced3a9814bc09f2afc5d5604bc5151b36f5a41ab', 'message': 'Enforce upper-constraints when building ramdisks\n\nCurrently, building ramdisks installs ironic-python-agent without any\nupper-constraints. This causes the package to be installed with newer,\nuntested dependencies.\n\nThis commits introduces a tool to generate a local upper-constraints\nfile based on predefined strategies (below). Additionally, the fallback\nto the openstack/requirements uses the URL defined in tox.ini instead of\nredefining it. This prevents having to keep track of two separate\nvariables when releasing.\n\nupper-constraints lookup strategies (in order):\n\n  * UPPER_CONSTRAINTS_FILE points to a local file\n  * UPPER_CONSTRAINTS_FILE points to a URL\n  * /opt/stack/new/requirements/upper-constraints.txt\n  * upper-constraints.txt from openstack/requirements git repository\n\nPartial-bug: #1611528\nChange-Id: Ib5c0c57cafdb6ffd7456e61f3b1bb5fa57520e5a\n'}, {'number': 9, 'created': '2016-08-24 17:02:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/f7ead01f12ce799a29e46b50be936ff3d812f904', 'message': 'Enforce upper-constraints when building ramdisks\n\nCurrently, building ramdisks installs ironic-python-agent without any\nupper-constraints. This causes the package to be installed with newer,\nuntested dependencies.\n\nThis commits introduces a tool to generate a local upper-constraints\nfile based on predefined strategies (below). Additionally, the fallback\nto the openstack/requirements uses the URL defined in tox.ini instead of\nredefining it. This prevents having to keep track of two separate\nvariables when releasing.\n\nupper-constraints lookup strategies (in order):\n\n  * UPPER_CONSTRAINTS_FILE points to a local file\n  * UPPER_CONSTRAINTS_FILE points to a URL\n  * /opt/stack/new/requirements/upper-constraints.txt\n  * upper-constraints.txt from openstack/requirements git repository\n\nPartial-bug: #1616554\nChange-Id: Ib5c0c57cafdb6ffd7456e61f3b1bb5fa57520e5a\n'}, {'number': 10, 'created': '2016-08-26 13:06:25.000000000', 'files': ['imagebuild/common/extract_upper_constraints_from_tox_ini.sh', 'imagebuild/common/generate_upper_constraints.sh', 'Dockerfile', '.gitignore', 'imagebuild/tinyipa/build-tinyipa.sh', 'imagebuild/coreos/docker_build.bash', 'imagebuild/tinyipa/finalise-tinyipa.sh'], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/a0ca6ce157b8a84f282d8abbdd27c75f48d991ff', 'message': 'Enforce upper-constraints when building ramdisks\n\nCurrently, building ramdisks installs ironic-python-agent without any\nupper-constraints. This causes the package to be installed with newer,\nuntested dependencies.\n\nThis commits introduces a tool to generate a local upper-constraints\nfile based on predefined strategies (below). Additionally, the fallback\nto the openstack/requirements uses the URL defined in tox.ini instead of\nredefining it. This prevents having to keep track of two separate\nvariables when releasing.\n\nupper-constraints lookup strategies (in order):\n\n  * UPPER_CONSTRAINTS_FILE points to a local file\n  * UPPER_CONSTRAINTS_FILE points to a URL\n  * /opt/stack/new/requirements/upper-constraints.txt\n  * upper-constraints.txt from openstack/requirements git repository\n\nPartial-bug: #1616554\nChange-Id: Ib5c0c57cafdb6ffd7456e61f3b1bb5fa57520e5a\n'}]",38,358855,a0ca6ce157b8a84f282d8abbdd27c75f48d991ff,47,6,10,7080,,,0,"Enforce upper-constraints when building ramdisks

Currently, building ramdisks installs ironic-python-agent without any
upper-constraints. This causes the package to be installed with newer,
untested dependencies.

This commits introduces a tool to generate a local upper-constraints
file based on predefined strategies (below). Additionally, the fallback
to the openstack/requirements uses the URL defined in tox.ini instead of
redefining it. This prevents having to keep track of two separate
variables when releasing.

upper-constraints lookup strategies (in order):

  * UPPER_CONSTRAINTS_FILE points to a local file
  * UPPER_CONSTRAINTS_FILE points to a URL
  * /opt/stack/new/requirements/upper-constraints.txt
  * upper-constraints.txt from openstack/requirements git repository

Partial-bug: #1616554
Change-Id: Ib5c0c57cafdb6ffd7456e61f3b1bb5fa57520e5a
",git fetch https://review.opendev.org/openstack/ironic-python-agent refs/changes/55/358855/8 && git format-patch -1 --stdout FETCH_HEAD,"['Dockerfile', 'imagebuild/coreos/docker_build.bash']",2,cd38ffbdb27c3f3ed70192c6baa12fa8bc12703f,bug/1616554,"CONSTRAINTS_URL=""https://git.openstack.org/cgit/openstack/requirements/plain/upper-constraints.txt""echo ""PIP_CONSTRAINT=${UPPER_CONSTRAINTS_FILE-""$CONSTRAINTS_URL""} http_proxy=${http_proxy:-} https_proxy=${https_proxy:-} no_proxy=${no_proxy:-} ""'$*' >> proxy.sh","echo ""http_proxy=${http_proxy:-} https_proxy=${https_proxy:-} no_proxy=${no_proxy:-} ""'$*' >> proxy.sh",4,2
openstack%2Fheat~master~I1427e394975baac3377a4a8d67f44f65d404f8b4,openstack/heat,master,I1427e394975baac3377a4a8d67f44f65d404f8b4,Add doc and reno note for environment merging,MERGED,2016-08-29 11:35:02.000000000,2016-08-29 20:45:30.000000000,2016-08-29 20:45:30.000000000,"[{'_account_id': 3}, {'_account_id': 4257}, {'_account_id': 7385}, {'_account_id': 13009}]","[{'number': 1, 'created': '2016-08-29 11:35:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/3a66a0b267adc04fb61c361f20133c79290cb89e', 'message': 'Add doc and reno note for environment merging\n\nChange-Id: I1427e394975baac3377a4a8d67f44f65d404f8b4\nBlueprint: environment-merging\n'}, {'number': 2, 'created': '2016-08-29 14:31:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/2833847ec66e6722733d30c6c64e5ec186b8528c', 'message': 'Add doc and reno note for environment merging\n\nChange-Id: I1427e394975baac3377a4a8d67f44f65d404f8b4\nBlueprint: environment-merging\n'}, {'number': 3, 'created': '2016-08-29 14:50:30.000000000', 'files': ['releasenotes/notes/environment-merging-d623362fac1279f7.yaml', 'doc/source/template_guide/environment.rst'], 'web_link': 'https://opendev.org/openstack/heat/commit/3f646800ddbd81c2ba150c1bdfefd7b872240871', 'message': 'Add doc and reno note for environment merging\n\nChange-Id: I1427e394975baac3377a4a8d67f44f65d404f8b4\nBlueprint: environment-merging\n'}]",4,362035,3f646800ddbd81c2ba150c1bdfefd7b872240871,13,4,3,8833,,,0,"Add doc and reno note for environment merging

Change-Id: I1427e394975baac3377a4a8d67f44f65d404f8b4
Blueprint: environment-merging
",git fetch https://review.opendev.org/openstack/heat refs/changes/35/362035/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/environment-merging-d623362fac1279f7.yaml', 'doc/source/template_guide/environment.rst']",2,3a66a0b267adc04fb61c361f20133c79290cb89e,bp/environment-merging,"It also can contain some other sections: ``parameter_defaults`` Default parameters passed to all template resources. ``encrypted_parameters`` List of encrypted parameters. ``event_sinks`` List of endpoints that would receive stack events. ``parameter_merge_strategies`` Merge strategies for merging parameters and parameter defaults from the environment file. Environment Merging ~~~~~~~~~~~~~~~~~~~ Parameters and their defaults(``parameter_defaults``) are merged based on merge strategies specified in an environment file. There are three merge strategy types: ``overwrite`` Overwrites a parameter, existing parameter values are replaced. ``merge`` Merges the exising parameter value and the new value. String values are concatenated, comma delimited lists are extended and json values are updated. ``deep_merge`` Json values are deep merged. Not useful for other types like comma delimited lists and strings. If specfied for them, it falls back to ``merge``. You can specify a default merge strategy and/or parameter specific merge strategies per environment file. Parameter specific merge strategy is only used for the specific parameter. An example of ``parameter_merge_strategies`` section in an environment file:: parameter_merge_strategies: default: merge param1: overwrite param2: deep_merge If no merge strategy is specified in an environment file, ``overwrite`` becomes the default merge strategy for all ``parameters`` and ``parameter_defaults`` in that environment file.",,59,0
openstack%2Ffuel-octane~master~Id302c0b49022a5ff322f9c52dee2140dcff1b722,openstack/fuel-octane,master,Id302c0b49022a5ff322f9c52dee2140dcff1b722,Add tests for preupgrade compute,MERGED,2016-08-25 08:37:44.000000000,2016-08-29 20:43:57.000000000,2016-08-29 20:42:19.000000000,"[{'_account_id': 3}, {'_account_id': 708}, {'_account_id': 1531}, {'_account_id': 6677}, {'_account_id': 12559}, {'_account_id': 19157}, {'_account_id': 20384}, {'_account_id': 20656}]","[{'number': 1, 'created': '2016-08-25 08:37:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-octane/commit/f6bceab70f662e9bee52264590958736c187ccf3', 'message': 'Add tests for preupgrade compute\n\n* test for preuepgrade_compute command was added\n* test for util functions for change_repositories was added\n\nChange-Id: Id302c0b49022a5ff322f9c52dee2140dcff1b722\n'}, {'number': 2, 'created': '2016-08-25 11:16:54.000000000', 'files': ['octane/tests/test_preupgrade_compute.py', 'octane/tests/test_util_ssh.py'], 'web_link': 'https://opendev.org/openstack/fuel-octane/commit/ed841dbf39804c29f7b1724f7cde372f6bf37185', 'message': 'Add tests for preupgrade compute\n\n* test for preuepgrade_compute command was added\n* test for util functions for change_repositories was added\n\nChange-Id: Id302c0b49022a5ff322f9c52dee2140dcff1b722\n'}]",0,360331,ed841dbf39804c29f7b1724f7cde372f6bf37185,16,8,2,21696,,,0,"Add tests for preupgrade compute

* test for preuepgrade_compute command was added
* test for util functions for change_repositories was added

Change-Id: Id302c0b49022a5ff322f9c52dee2140dcff1b722
",git fetch https://review.opendev.org/openstack/fuel-octane refs/changes/31/360331/2 && git format-patch -1 --stdout FETCH_HEAD,"['octane/tests/test_preupgrade_compute.py', 'octane/tests/test_util_ssh.py']",2,f6bceab70f662e9bee52264590958736c187ccf3,,"import os @pytest.mark.parametrize(""dir_names,lists_files"", [ ([""test_dir_1"", ""test_dir_2""], [[""file_1"", ""file_2""], [""file_3""]]), ([""test_dir_3"", ""test_dir_4""], [[], []]) ]) def test_remove_all_files_from_dirs(mocker, dir_names, lists_files): node = mock.Mock() mock_sftp = mocker.patch(""octane.util.ssh.sftp"") mock_list_dir = mocker.patch('paramiko.SFTPClient.listdir') mock_list_dir.side_effect = lists_files mock_unlink = mocker.patch(""paramiko.SFTPClient.unlink"") ssh.remove_all_files_from_dirs(dir_names, node) mock_sftp.assert_called_once_with(node) mock_list_dir.call_args_list == [ mock.call(dir_name) for dir_name in dir_names ] mock_unlink.call_args_list == [ mock.call(os.path.join(dir_name, file) for dir_name, files in zip(dir_names, lists_files) for file in files) ] def test_write_content_to_file(mocker): filename = ""filename"" content = ""content"" sftp = mocker.patch(""paramiko.SFTPClient"") mock_open = mocker.patch(""paramiko.SFTPClient.open"") ssh.write_content_to_file(sftp, filename, content) mock_open.assert_called_once_with(filename, 'w')",,251,1
openstack%2Fneutron~master~I432aabb3c22b12faa29ca88e13392e6c2d0e33d8,openstack/neutron,master,I432aabb3c22b12faa29ca88e13392e6c2d0e33d8,Include db_models document to avoid errors,MERGED,2016-08-09 23:12:47.000000000,2016-08-29 20:43:04.000000000,2016-08-29 20:43:03.000000000,"[{'_account_id': 3}, {'_account_id': 4694}, {'_account_id': 5170}, {'_account_id': 6524}, {'_account_id': 7037}, {'_account_id': 8726}, {'_account_id': 9656}, {'_account_id': 9845}, {'_account_id': 10184}, {'_account_id': 14208}, {'_account_id': 15752}, {'_account_id': 16376}]","[{'number': 1, 'created': '2016-08-09 23:12:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/852a1a5c22dc2e41f3852138220c25c8a2c3bde0', 'message': 'Include db_models document to avoid errors\n\nThe db_models.rst file was not refence by any other document. This was\ngenerating warnings failing during the creation of documentation.\n\nChange-Id: I432aabb3c22b12faa29ca88e13392e6c2d0e33d8\nCloses-Bug: #1611546\n'}, {'number': 2, 'created': '2016-08-10 14:12:19.000000000', 'files': ['doc/source/devref/index.rst'], 'web_link': 'https://opendev.org/openstack/neutron/commit/f1edd59b1f129f86cfb15154e059c29ab69d4bf2', 'message': 'Include db_models document to avoid errors\n\nThe db_models.rst file was not referenced by any other document. This\nwas generating warnings during the creation of documentation.\n\nChange-Id: I432aabb3c22b12faa29ca88e13392e6c2d0e33d8\nCloses-Bug: #1611546\n'}]",4,353158,f1edd59b1f129f86cfb15154e059c29ab69d4bf2,24,12,2,8726,,,0,"Include db_models document to avoid errors

The db_models.rst file was not referenced by any other document. This
was generating warnings during the creation of documentation.

Change-Id: I432aabb3c22b12faa29ca88e13392e6c2d0e33d8
Closes-Bug: #1611546
",git fetch https://review.opendev.org/openstack/neutron refs/changes/58/353158/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/devref/index.rst'],1,852a1a5c22dc2e41f3852138220c25c8a2c3bde0,bug/1611546, db_models,,1,0
openstack%2Fpython-magnumclient~master~If2ad6ed438a74e47f83a2775560ded413feaf315,openstack/python-magnumclient,master,If2ad6ed438a74e47f83a2775560ded413feaf315,Magnum client to support sync and async bay opts,MERGED,2016-08-17 19:58:44.000000000,2016-08-29 20:37:23.000000000,2016-08-29 20:37:23.000000000,"[{'_account_id': 3}, {'_account_id': 668}, {'_account_id': 7049}, {'_account_id': 7230}, {'_account_id': 7494}, {'_account_id': 8143}, {'_account_id': 9591}, {'_account_id': 10206}, {'_account_id': 10263}, {'_account_id': 11536}, {'_account_id': 11650}, {'_account_id': 12053}, {'_account_id': 12175}, {'_account_id': 12385}, {'_account_id': 13861}, {'_account_id': 18464}, {'_account_id': 20498}, {'_account_id': 21469}, {'_account_id': 21660}]","[{'number': 1, 'created': '2016-08-17 19:58:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-magnumclient/commit/09fead5374828d438d675b38633231f7f17c6f6d', 'message': 'Magnum client to support sync and async bay opts\n\nProviding support to magnum client for Sync and Async Bay operations based on\nthe magnum-api-version supplied.\n\nChange-Id: If2ad6ed438a74e47f83a2775560ded413feaf315\n'}, {'number': 2, 'created': '2016-08-26 17:52:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-magnumclient/commit/e66437526c5bf728f976969598e8a9dd03ced471', 'message': 'Magnum client to support sync and async bay opts\n\nProviding support to magnum client for Sync and Async Bay operations based on\nthe magnum-api-version supplied.\n\nChange-Id: If2ad6ed438a74e47f83a2775560ded413feaf315\n'}, {'number': 3, 'created': '2016-08-29 15:53:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-magnumclient/commit/32d322cb072878e64c8f8f2d960e150502a6b59f', 'message': 'Magnum client to support sync and async bay opts\n\nProviding support to magnum client for Sync and Async Bay operations based on\nthe magnum-api-version supplied.\n\nChange-Id: If2ad6ed438a74e47f83a2775560ded413feaf315\n'}, {'number': 4, 'created': '2016-08-29 16:03:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-magnumclient/commit/d6852d6ecc56ccd6455a6f5cc12a5a5ad673124a', 'message': 'Magnum client to support sync and async bay opts\n\nProviding support to magnum client for Sync and Async Bay operations based on\nthe magnum-api-version supplied.\n\nChange-Id: If2ad6ed438a74e47f83a2775560ded413feaf315\n'}, {'number': 5, 'created': '2016-08-29 17:48:15.000000000', 'files': ['magnumclient/v1/clusters_shell.py', 'magnumclient/v1/bays_shell.py'], 'web_link': 'https://opendev.org/openstack/python-magnumclient/commit/f12e7a99f91217e4740c7c2dfa147b9e43761db9', 'message': 'Magnum client to support sync and async bay opts\n\nProviding support to magnum client for Sync and Async Bay\noperations based on the magnum-api-version supplied.\n\nChange-Id: If2ad6ed438a74e47f83a2775560ded413feaf315\nDepends-On: I4ca1f9f386b6417726154c466e7a9104b6e6e5e1\n'}]",3,356681,f12e7a99f91217e4740c7c2dfa147b9e43761db9,29,19,5,22224,,,0,"Magnum client to support sync and async bay opts

Providing support to magnum client for Sync and Async Bay
operations based on the magnum-api-version supplied.

Change-Id: If2ad6ed438a74e47f83a2775560ded413feaf315
Depends-On: I4ca1f9f386b6417726154c466e7a9104b6e6e5e1
",git fetch https://review.opendev.org/openstack/python-magnumclient refs/changes/81/356681/3 && git format-patch -1 --stdout FETCH_HEAD,['magnumclient/v1/bays_shell.py'],1,09fead5374828d438d675b38633231f7f17c6f6d,async_bay," if args.magnum_api_version and float(args.magnum_api_version) < 1.2: bay = cs.bays.create(**opts) _show_bay(bay) else: bay = cs.bays.create(**opts) fields = str(bay).split(""u'"") uuid = fields[2] print(""Request to create bay %s has been accepted."" % uuid[:-3]) if args.magnum_api_version and float(args.magnum_api_version) < 1.2: bay = cs.bays.update(args.bay, patch) _show_bay(bay) else: cs.bays.update(args.bay, patch) print(""Request to update bay %s has been accepted."" % args.bay)"," cs.bays.create(**opts) print(""Request to create bay %s has been accepted."" % args.name) cs.bays.update(args.bay, patch) print(""Request to update bay %s has been accepted."" % args.bay)",14,4
openstack%2Fmurano~master~Ia7b0f61370effe4f13fed4ec85e806f3b0fdb80b,openstack/murano,master,Ia7b0f61370effe4f13fed4ec85e806f3b0fdb80b,TestFixture mocks were updated,MERGED,2016-08-29 17:06:13.000000000,2016-08-29 20:34:39.000000000,2016-08-29 20:34:39.000000000,"[{'_account_id': 3}, {'_account_id': 7225}, {'_account_id': 7821}, {'_account_id': 15168}, {'_account_id': 20364}]","[{'number': 1, 'created': '2016-08-29 17:06:13.000000000', 'files': ['meta/io.murano/Classes/test/TestFixture.yaml', 'murano/cmd/test_runner.py'], 'web_link': 'https://opendev.org/openstack/murano/commit/2f2132350dbd942f3a29fce2d9723642dff2de80', 'message': 'TestFixture mocks were updated\n\nCore library was updated as part of the multi-region support\neffort. FormatVersion of the core library was incremented and,\nas a result $dict.key expressions started to work as they are in\nyaql 1.0 rather than in 0.2 and the presence of the key become\nmandatory. However Network mock in the TextFixture used to\nreturn empty dictionary and it caused Instance class to fail.\nThe commit adds missing keys to the dictionary returned by\nthe joinInstance() method.\n\nAlso the test runner was improved to print the stack trace\nupon failures so that it is possible to identify where the\nerror happened.\n\nChange-Id: Ia7b0f61370effe4f13fed4ec85e806f3b0fdb80b\n'}]",0,362284,2f2132350dbd942f3a29fce2d9723642dff2de80,10,5,1,7226,,,0,"TestFixture mocks were updated

Core library was updated as part of the multi-region support
effort. FormatVersion of the core library was incremented and,
as a result $dict.key expressions started to work as they are in
yaql 1.0 rather than in 0.2 and the presence of the key become
mandatory. However Network mock in the TextFixture used to
return empty dictionary and it caused Instance class to fail.
The commit adds missing keys to the dictionary returned by
the joinInstance() method.

Also the test runner was improved to print the stack trace
upon failures so that it is possible to identify where the
error happened.

Change-Id: Ia7b0f61370effe4f13fed4ec85e806f3b0fdb80b
",git fetch https://review.opendev.org/openstack/murano refs/changes/84/362284/1 && git format-patch -1 --stdout FETCH_HEAD,"['meta/io.murano/Classes/test/TestFixture.yaml', 'murano/cmd/test_runner.py']",2,2f2132350dbd942f3a29fce2d9723642dff2de80,,"from murano.dsl import dsl_exception msg = ''.join(( FAIL_COLOR, 'FAIL!', END_COLOR, '\n')) if isinstance(e, dsl_exception.MuranoPlException): tb = e.format() else: tb = traceback.format_exc() sys.stdout.write(''.join(( FAIL_COLOR, tb, END_COLOR, '\n' ))) if isinstance(e, dsl_exception.MuranoPlException): tb = e.format() else: tb = traceback.format_exc()"," msg = '{0}{1}: {2}{3}\n'.format(FAIL_COLOR, 'FAIL!', e, END_COLOR) tb = traceback.format_exc()",23,7
openstack%2Fopenstack-ansible~liberty~I33ae86506bf38d48fe285222305f404604f88a4e,openstack/openstack-ansible,liberty,I33ae86506bf38d48fe285222305f404604f88a4e,Update all SHAs for 12.2.3,MERGED,2016-08-25 17:24:32.000000000,2016-08-29 20:33:11.000000000,2016-08-29 20:33:11.000000000,"[{'_account_id': 3}, {'_account_id': 538}, {'_account_id': 7353}, {'_account_id': 14805}]","[{'number': 1, 'created': '2016-08-25 17:24:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/e1d37c0dd3cec7c3a7bd1dfb344764282de4f396', 'message': 'Update all SHAs for 12.2.3\n\nThis patch includes updates of any changed paste, policy and rootwrap\nconfigurations. It also includes updates to the pip, wheel and\nsetuptools pins. Finally, it also updates the required roles and\ncopies any release notes from those roles.\n\nChange-Id: I33ae86506bf38d48fe285222305f404604f88a4e\nDepends-On: I6bb22dd11e512642e04b6c8faed851357df4590a\n'}, {'number': 2, 'created': '2016-08-26 10:40:16.000000000', 'files': ['playbooks/defaults/repo_packages/openstack_services.yml', 'global-requirement-pins.txt', 'scripts/scripts-library.sh', 'playbooks/inventory/group_vars/hosts.yml', 'playbooks/inventory/group_vars/all.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/1d7f2091c2b515435a5415eeefe1431153f5bbf3', 'message': 'Update all SHAs for 12.2.3\n\nThis patch includes updates of any changed paste, policy and rootwrap\nconfigurations. It also includes updates to the pip, wheel and\nsetuptools pins. Finally, it also updates the required roles and\ncopies any release notes from those roles.\n\nChange-Id: I33ae86506bf38d48fe285222305f404604f88a4e\nDepends-On: I6bb22dd11e512642e04b6c8faed851357df4590a\n'}]",0,360694,1d7f2091c2b515435a5415eeefe1431153f5bbf3,12,4,2,6816,,,0,"Update all SHAs for 12.2.3

This patch includes updates of any changed paste, policy and rootwrap
configurations. It also includes updates to the pip, wheel and
setuptools pins. Finally, it also updates the required roles and
copies any release notes from those roles.

Change-Id: I33ae86506bf38d48fe285222305f404604f88a4e
Depends-On: I6bb22dd11e512642e04b6c8faed851357df4590a
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/94/360694/1 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/defaults/repo_packages/openstack_services.yml', 'global-requirement-pins.txt', 'scripts/scripts-library.sh', 'playbooks/inventory/group_vars/hosts.yml', 'playbooks/inventory/group_vars/all.yml']",5,e1d37c0dd3cec7c3a7bd1dfb344764282de4f396,sha-update,openstack_release: 12.2.3,openstack_release: 12.2.2,18,18
openstack%2Fopenstack-ansible-os_neutron~master~Idd8111856d9462e5d34e7c2d0c0b190812ae1409,openstack/openstack-ansible-os_neutron,master,Idd8111856d9462e5d34e7c2d0c0b190812ae1409,Open vSwitch documentation in Neutron Role,MERGED,2016-08-12 19:25:46.000000000,2016-08-29 20:30:06.000000000,2016-08-29 20:30:06.000000000,"[{'_account_id': 3}, {'_account_id': 6816}, {'_account_id': 7353}, {'_account_id': 8190}, {'_account_id': 10347}, {'_account_id': 10607}, {'_account_id': 11268}, {'_account_id': 12402}, {'_account_id': 13883}, {'_account_id': 19814}]","[{'number': 1, 'created': '2016-08-12 19:25:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_neutron/commit/b7d52de5ee6375269795d0b8105488401a8d5fdf', 'message': 'WIP: Open vSwitch documentation in Neutron Role\n\nThis change adds the documentation forthe Open vSwitch Neutron Agent\nconfiguration.\n\nChange-Id: Idd8111856d9462e5d34e7c2d0c0b190812ae1409\n'}, {'number': 2, 'created': '2016-08-16 22:51:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_neutron/commit/9d5151f26d16f1ed72e999e4742514ab36db85a7', 'message': 'WIP: Open vSwitch documentation in Neutron Role\n\nThis change adds the documentation forthe Open vSwitch Neutron Agent\nconfiguration.\n\nBuilds on top of the OVS blog post from Travis Truman:\nhttps://medium.com/@travistruman/\n  configuring-openstack-ansible-for-open-vswitch-b7e70e26009d\n\nChange-Id: Idd8111856d9462e5d34e7c2d0c0b190812ae1409\n'}, {'number': 3, 'created': '2016-08-18 17:16:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_neutron/commit/4257d7384d890c9b793a1ee0257af4d26450b3f3', 'message': 'WIP: Open vSwitch documentation in Neutron Role\n\nThis change adds the documentation forthe Open vSwitch Neutron Agent\nconfiguration.\n\nBuilds on top of the OVS blog post from Travis Truman:\nhttps://medium.com/@travistruman/\n  configuring-openstack-ansible-for-open-vswitch-b7e70e26009d\n\nChange-Id: Idd8111856d9462e5d34e7c2d0c0b190812ae1409\n'}, {'number': 4, 'created': '2016-08-26 19:26:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_neutron/commit/819c85e23ceb84c949ae5cd6d23781dd23ef00ed', 'message': 'WIP: Open vSwitch documentation in Neutron Role\n\nThis change adds the documentation forthe Open vSwitch Neutron Agent\nconfiguration.\n\nBuilds on top of the OVS blog post from Travis Truman:\nhttps://medium.com/@travistruman/\n  configuring-openstack-ansible-for-open-vswitch-b7e70e26009d\n\nChange-Id: Idd8111856d9462e5d34e7c2d0c0b190812ae1409\n'}, {'number': 5, 'created': '2016-08-29 20:18:33.000000000', 'files': ['doc/source/index.rst', 'doc/source/app-openvswitch.rst'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_neutron/commit/ea0b0356b4c4ee88e6d268dface042b9e489eab3', 'message': 'Open vSwitch documentation in Neutron Role\n\nThis change adds the documentation forthe Open vSwitch Neutron Agent\nconfiguration.\n\nBuilds on top of the OVS blog post from Travis Truman:\nhttps://medium.com/@travistruman/\n  configuring-openstack-ansible-for-open-vswitch-b7e70e26009d\n\nChange-Id: Idd8111856d9462e5d34e7c2d0c0b190812ae1409\n'}]",78,355041,ea0b0356b4c4ee88e6d268dface042b9e489eab3,29,10,5,8190,,,0,"Open vSwitch documentation in Neutron Role

This change adds the documentation forthe Open vSwitch Neutron Agent
configuration.

Builds on top of the OVS blog post from Travis Truman:
https://medium.com/@travistruman/
  configuring-openstack-ansible-for-open-vswitch-b7e70e26009d

Change-Id: Idd8111856d9462e5d34e7c2d0c0b190812ae1409
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_neutron refs/changes/41/355041/4 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/index.rst', 'doc/source/app-openvswitch.rst']",2,b7d52de5ee6375269795d0b8105488401a8d5fdf,ovs_initial_guide,"============================= Scenario - Using Open vSwitch ============================= Overview ~~~~~~~~ Operators may choose to utilize Open vSwitch instead of Linux Bridges for the Neutron Agent. This offers different capabilities and integration points with Neutron. This document outlines how to set it up in your environment. Pre-Requisites ~~~~~~~~~~~~~~ Since the Open vSwitch capabilities are for the comptue node, it requires that the following bridges be configured on the system ahead of time. - br-mgmt - br-vlan (optional - Used for vlan networks) - br-vxlan (optional - Used for vxlan tenant networks) - br-storage (optional - Used for certain storage devices) These bridges may be configured as either a Linux Bridge (which would connect to the Open vSwitch controlled by Neutron) or as Open vSwitch's themselves. Configuring Edge Bridges (Linux Bridge) ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ The following is an example of how to configure an 'edge' bridge (ex. br-mgmt) with a Linux Bridge on Ubuntu 16.04 LTS. ``/etc/network/interfaces`` .. code-block:: shell-session auto lo iface lo inet loopback # Management network auto eth0 iface eth0 inet manual # VLAN network auto eth1 iface eth1 inet manual source /etc/network/interfaces.d/*.cfg ``/etc/network/interfaces.d/br-mgmt.cfg`` .. code-block:: shell-session # OpenStack Management network bridge auto br-mgmt iface br-mgmt inet static bridge_stp off bridge_waitport 0 bridge_fd 0 bridge_ports eth0 address MANAGEMENT_NETWORK_IP netmask 255.255.255.0 gateway 192.168.1.1 dns-nameservers 8.8.8.8 8.8.4.4 One br-<type>.cfg is required for each bridge that is required. VLAN interfaces can be used to back the br-<type> bridges if there are limited physical adapters on the system. Configuring Edge Bridges (Open vSwitch) ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Another configuration method is to have all of the routing to be done by Open vSwitch itself. The 'edge' bridge (ex. br-mgmt) can be an Open vSwitch itself. The following is an example of how to configure an 'edge' bridge (ex. br-mgmt) with Open vSwitch on Ubuntu 16.04 LTS. ``/etc/network/interfaces`` .. code-block:: shell-session auto lo iface lo inet loopback source /etc/network/interfaces.d/*.cfg # Management network auto eth0 allow-br-mgmt eth0 iface eth0 inet manual ovs_bridge br-mgmt ovs_type OVSPort # VLAN network auto eth1 allow-br-vlan eth1 iface eth1 inet manual ovs_bridge br-vlan ovs_type OVSPort ``/etc/network/interfaces.d/br-mgmt.cfg`` .. code-block:: shell-session # OpenStack Management network bridge auto br-mgmt iface br-mgmt inet static address MANAGEMENT_NETWORK_IP netmask 255.255.255.0 gateway 192.168.1.1 dns-nameservers 8.8.8.8 8.8.4.4 ovs_type OVSBridge ovs_ports eth0 One br-<type>.cfg is required for each bridge that is required. VLAN interfaces can be used to back the br-<type> bridges if there are limited physical adapters on the system. OpenStack-Ansible User Variables ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Set the following user variables in your /etc/openstack_deploy/user_variables.yml .. code-block:: shell-session # Ensure the openvswitch kernel module is loaded openstack_host_specific_kernel_modules: - name: ""openvswitch"" pattern: ""CONFIG_OPENVSWITCH="" group: ""network_hosts"" ### Neutron specific config neutron_plugin_type: ml2.ovs neutron_ml2_drivers_type: ""flat,vlan"" # Typically this would be defined by the os-neutron-install # playbook. The provider_networks library would parse the # provider_networks list in openstack_user_config.yml and # generate the values of network_types, network_vlan_ranges # and network_mappings. network_mappings would have a # different value for each host in the inventory based on # whether or not the host was metal (typically a compute host) # or a container (typically a neutron agent container) # # When using Open vSwitch, we override it to take into account # the Open vSwitch bridge we are going to define outside of # OpenStack-Ansible plays neutron_provider_networks: network_flat_networks: ""*"" network_types: ""vlan"" network_vlan_ranges: ""physnet1:102:199"" network_mappings: ""physnet1:br-provider"" Customization is needed to support additional network types such as vxlan, GRE or Geneve. Refer to the Neutron Open vSwitch agent configuration for more information on these attributes. ",,160,0
openstack%2Ftrove~master~I4f765c4ebb3ebde958f10bb1329964da3c4d0fb3,openstack/trove,master,I4f765c4ebb3ebde958f10bb1329964da3c4d0fb3,Send up guest agent logs over the conductor channel to trove controller,ABANDONED,2015-10-20 17:51:30.000000000,2016-08-29 20:28:33.000000000,,"[{'_account_id': 3}, {'_account_id': 5293}, {'_account_id': 6413}, {'_account_id': 9664}, {'_account_id': 10215}, {'_account_id': 14576}]","[{'number': 1, 'created': '2015-10-20 17:51:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/0795b0f091e875ed6f8cc832537c38e8918b3fc3', 'message': ""Send up guest agent logs over the conductor channel to trove controller\n\nIn debugging guest failures (especially in the gate) we are hampered\nby the fact that we can't see what's happening on the guest. While\nthis change won't give us *everything* that's happening on the guest,\nit will send up everything that the guest agent is logging up the wire\nto the host. And it'll show up in the conductor log file.\n\nChange-Id: I4f765c4ebb3ebde958f10bb1329964da3c4d0fb3\nCloses-Bug: #1508144\n""}, {'number': 2, 'created': '2015-10-21 12:57:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/b7a1b33fa591d488b5fcb59432795bad5e6a792c', 'message': ""Send up guest agent logs over the conductor channel to trove controller\n\nIn debugging guest failures (especially in the gate) we are hampered\nby the fact that we can't see what's happening on the guest. While\nthis change won't give us *everything* that's happening on the guest,\nit will send up everything that the guest agent is logging up the wire\nto the host. And it'll show up in the conductor log file.\n\nThe failure from yesterday's run of the dsvm test indicated that the\nguest agent that had to do the incremental restore never even\nresponded to a prepare (or at least, that's what the conductor logging\nindicated). So I've just added a message into prepare() to indicate\nthat it was received. If dsvm fails again, we should know for sure\nwhat's going on.\n\nChange-Id: I4f765c4ebb3ebde958f10bb1329964da3c4d0fb3\nCloses-Bug: #1508144\n""}, {'number': 3, 'created': '2015-10-21 14:39:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/5e7c6e687450fc94801c8d485a38003b913802f4', 'message': ""Send up guest agent logs over the conductor channel to trove controller\n\nIn debugging guest failures (especially in the gate) we are hampered\nby the fact that we can't see what's happening on the guest. While\nthis change won't give us *everything* that's happening on the guest,\nit will send up everything that the guest agent is logging up the wire\nto the host. And it'll show up in the conductor log file.\n\nThe failure from yesterday's run of the dsvm test indicated that the\nguest agent that had to do the incremental restore never even\nresponded to a prepare (or at least, that's what the conductor logging\nindicated). So I've just added a message into prepare() to indicate\nthat it was received. If dsvm fails again, we should know for sure\nwhat's going on.\n\nChange-Id: I4f765c4ebb3ebde958f10bb1329964da3c4d0fb3\nCloses-Bug: #1508144\n""}, {'number': 4, 'created': '2015-10-22 18:21:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/a4d5525bdea3052026ff4695a1fd4cdee6759f27', 'message': ""Send up guest agent logs over the conductor channel to trove controller\n\nIn debugging guest failures (especially in the gate) we are hampered\nby the fact that we can't see what's happening on the guest. While\nthis change won't give us *everything* that's happening on the guest,\nit will send up everything that the guest agent is logging up the wire\nto the host. And it'll show up in the conductor log file.\n\nThe failure from yesterday's run of the dsvm test indicated that the\nguest agent that had to do the incremental restore never even\nresponded to a prepare (or at least, that's what the conductor logging\nindicated). So I've just added a message into prepare() to indicate\nthat it was received. If dsvm fails again, we should know for sure\nwhat's going on.\n\nChange-Id: I4f765c4ebb3ebde958f10bb1329964da3c4d0fb3\nCloses-Bug: #1508144\n""}, {'number': 5, 'created': '2015-10-22 20:57:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/80f8ec043d2f6c403b5f14b1a3fcfd2fccda82ed', 'message': ""Send up guest agent logs over the conductor channel to trove controller\n\nIn debugging guest failures (especially in the gate) we are hampered\nby the fact that we can't see what's happening on the guest. While\nthis change won't give us *everything* that's happening on the guest,\nit will send up everything that the guest agent is logging up the wire\nto the host. And it'll show up in the conductor log file.\n\nThe failure from yesterday's run of the dsvm test indicated that the\nguest agent that had to do the incremental restore never even\nresponded to a prepare (or at least, that's what the conductor logging\nindicated). So I've just added a message into prepare() to indicate\nthat it was received. If dsvm fails again, we should know for sure\nwhat's going on.\n\nChange-Id: I4f765c4ebb3ebde958f10bb1329964da3c4d0fb3\nCloses-Bug: #1508144\n""}, {'number': 6, 'created': '2015-10-30 02:29:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/4cc9e41ed51e26f419ed58b87b88b2a3f9c28c85', 'message': ""Send up guest agent logs over the conductor channel to trove controller\n\nIn debugging guest failures (especially in the gate) we are hampered\nby the fact that we can't see what's happening on the guest. While\nthis change won't give us *everything* that's happening on the guest,\nit will send up everything that the guest agent is logging up the wire\nto the host. And it'll show up in the conductor log file.\n\nThe failure from yesterday's run of the dsvm test indicated that the\nguest agent that had to do the incremental restore never even\nresponded to a prepare (or at least, that's what the conductor logging\nindicated). So I've just added a message into prepare() to indicate\nthat it was received. If dsvm fails again, we should know for sure\nwhat's going on.\n\nChange-Id: I4f765c4ebb3ebde958f10bb1329964da3c4d0fb3\nCloses-Bug: #1508144\n""}, {'number': 7, 'created': '2015-11-03 09:27:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/6a3a9f77e44f5ea4d0f67a2038438b3e8ca1e26e', 'message': ""Send up guest agent logs over the conductor channel to trove controller\n\nIn debugging guest failures (especially in the gate) we are hampered\nby the fact that we can't see what's happening on the guest. While\nthis change won't give us *everything* that's happening on the guest,\nit will send up everything that the guest agent is logging up the wire\nto the host. And it'll show up in the conductor log file.\n\nThe failure from yesterday's run of the dsvm test indicated that the\nguest agent that had to do the incremental restore never even\nresponded to a prepare (or at least, that's what the conductor logging\nindicated). So I've just added a message into prepare() to indicate\nthat it was received. If dsvm fails again, we should know for sure\nwhat's going on.\n\nChange-Id: I4f765c4ebb3ebde958f10bb1329964da3c4d0fb3\nCloses-Bug: #1508144\n""}, {'number': 8, 'created': '2015-11-10 01:30:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/f981bfabb1b4ab6670eeb639075e0ed3915d31e7', 'message': ""Send up guest agent logs over the conductor channel to trove controller\n\nIn debugging guest failures (especially in the gate) we are hampered\nby the fact that we can't see what's happening on the guest. While\nthis change won't give us *everything* that's happening on the guest,\nit will send up everything that the guest agent is logging up the wire\nto the host. And it'll show up in the conductor log file.\n\nThe failure from yesterday's run of the dsvm test indicated that the\nguest agent that had to do the incremental restore never even\nresponded to a prepare (or at least, that's what the conductor logging\nindicated). So I've just added a message into prepare() to indicate\nthat it was received. If dsvm fails again, we should know for sure\nwhat's going on.\n\nChange-Id: I4f765c4ebb3ebde958f10bb1329964da3c4d0fb3\nCloses-Bug: #1508144\n""}, {'number': 9, 'created': '2015-11-10 12:35:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/385d3aae26b26b44670e5518814d99cc72ad75e3', 'message': ""Send up guest agent logs over the conductor channel to trove controller\n\nIn debugging guest failures (especially in the gate) we are hampered\nby the fact that we can't see what's happening on the guest. While\nthis change won't give us *everything* that's happening on the guest,\nit will send up everything that the guest agent is logging up the wire\nto the host. And it'll show up in the conductor log file.\n\nThe failure from yesterday's run of the dsvm test indicated that the\nguest agent that had to do the incremental restore never even\nresponded to a prepare (or at least, that's what the conductor logging\nindicated). So I've just added a message into prepare() to indicate\nthat it was received. If dsvm fails again, we should know for sure\nwhat's going on.\n\nChange-Id: I4f765c4ebb3ebde958f10bb1329964da3c4d0fb3\nCloses-Bug: #1508144\n""}, {'number': 10, 'created': '2015-11-21 11:58:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/08aafbb0a0ca97d9532e81ae7b93a472857b562c', 'message': ""Send up guest agent logs over the conductor channel to trove controller\n\nIn debugging guest failures (especially in the gate) we are hampered\nby the fact that we can't see what's happening on the guest. While\nthis change won't give us *everything* that's happening on the guest,\nit will send up everything that the guest agent is logging up the wire\nto the host. And it'll show up in the conductor log file.\n\nThe code is checked in with the default config value set to False. If\nyou have a gate failure, you'll have to flip it to True and try again\nand hope it fails again.\n\nChange-Id: I4f765c4ebb3ebde958f10bb1329964da3c4d0fb3\nCloses-Bug: #1508144\n""}, {'number': 11, 'created': '2016-01-05 13:33:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/4bae51387de5842f5e0618acd451e52caa54997e', 'message': ""Send up guest agent logs over the conductor channel to trove controller\n\nIn debugging guest failures (especially in the gate) we are hampered\nby the fact that we can't see what's happening on the guest. While\nthis change won't give us *everything* that's happening on the guest,\nit will send up everything that the guest agent is logging up the wire\nto the host. And it'll show up in the conductor log file.\n\nThe code is checked in with the default config value set to False. If\nyou have a gate failure, you'll have to flip it to True and try again\nand hope it fails again.\n\nChange-Id: I4f765c4ebb3ebde958f10bb1329964da3c4d0fb3\nCloses-Bug: #1508144\n""}, {'number': 12, 'created': '2016-01-13 13:03:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/db9e409ec77dccf6e86cbd0283caa68c10319925', 'message': ""Send up guest agent logs over the conductor channel to trove controller\n\nIn debugging guest failures (especially in the gate) we are hampered\nby the fact that we can't see what's happening on the guest. While\nthis change won't give us *everything* that's happening on the guest,\nit will send up everything that the guest agent is logging up the wire\nto the host. And it'll show up in the conductor log file.\n\nThe code is checked in with the default config value set to False. If\nyou have a gate failure, you'll have to flip it to True and try again\nand hope it fails again.\n\nChange-Id: I4f765c4ebb3ebde958f10bb1329964da3c4d0fb3\nCloses-Bug: #1508144\n""}, {'number': 13, 'created': '2016-01-15 12:36:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/0b02f38d9bad755ca0027e9aca9366650fb2b970', 'message': ""Send up guest agent logs over the conductor channel to trove controller\n\nIn debugging guest failures (especially in the gate) we are hampered\nby the fact that we can't see what's happening on the guest. While\nthis change won't give us *everything* that's happening on the guest,\nit will send up everything that the guest agent is logging up the wire\nto the host. And it'll show up in the conductor log file.\n\nThe code is checked in with the default config value set to False. If\nyou have a gate failure, you'll have to flip it to True and try again\nand hope it fails again.\n\nChange-Id: I4f765c4ebb3ebde958f10bb1329964da3c4d0fb3\nCloses-Bug: #1508144\n""}, {'number': 14, 'created': '2016-01-27 14:59:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/c5cd08a9a732a3b9a41e9c771992b683444f1874', 'message': ""Send up guest agent logs over the conductor channel to trove controller\n\nIn debugging guest failures (especially in the gate) we are hampered\nby the fact that we can't see what's happening on the guest. While\nthis change won't give us *everything* that's happening on the guest,\nit will send up everything that the guest agent is logging up the wire\nto the host. And it'll show up in the conductor log file.\n\nThe code is checked in with the default config value set to False. If\nyou have a gate failure, you'll have to flip it to True and try again\nand hope it fails again.\n\nChange-Id: I4f765c4ebb3ebde958f10bb1329964da3c4d0fb3\nCloses-Bug: #1508144\n""}, {'number': 15, 'created': '2016-07-07 10:36:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/276d1df71a85c9f2eec51178543e26477a69d1d3', 'message': ""Send up guest agent logs over the conductor channel to trove controller\n\nIn debugging guest failures (especially in the gate) we are hampered\nby the fact that we can't see what's happening on the guest. While\nthis change won't give us *everything* that's happening on the guest,\nit will send up everything that the guest agent is logging up the wire\nto the host. And it'll show up in the conductor log file.\n\nThe code is checked in with the default config value set to False.\n\nChange-Id: I4f765c4ebb3ebde958f10bb1329964da3c4d0fb3\nCloses-Bug: #1508144\n""}, {'number': 16, 'created': '2016-07-07 16:08:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/1a10ee3d76e5848e18effb0ef758c1c83f64fc9f', 'message': ""Send up guest agent logs over the conductor channel to trove controller\n\nIn debugging guest failures (especially in the gate) we are hampered\nby the fact that we can't see what's happening on the guest. While\nthis change won't give us *everything* that's happening on the guest,\nit will send up everything that the guest agent is logging up the wire\nto the host. And it'll show up in the conductor log file.\n\nThe code is checked in with the default config value set to False.\n\nChange-Id: I4f765c4ebb3ebde958f10bb1329964da3c4d0fb3\nCloses-Bug: #1508144\n""}, {'number': 17, 'created': '2016-07-07 16:08:48.000000000', 'files': ['trove/conductor/manager.py', 'trove/conductor/api.py', 'trove/common/cfg.py', 'etc/trove/trove.conf.test', 'trove/taskmanager/models.py', 'trove/cmd/guest.py'], 'web_link': 'https://opendev.org/openstack/trove/commit/7ac9fab254c6601c95577a34c432cad76e2cef86', 'message': ""Send up guest agent logs over the conductor channel to trove controller\n\nIn debugging guest failures (especially in the gate) we are hampered\nby the fact that we can't see what's happening on the guest. While\nthis change won't give us *everything* that's happening on the guest,\nit will send up everything that the guest agent is logging up the wire\nto the host. And it'll show up in the conductor log file.\n\nThe code is checked in with the default config value set to False.\n\nChange-Id: I4f765c4ebb3ebde958f10bb1329964da3c4d0fb3\nCloses-Bug: #1508144\n""}]",8,237710,7ac9fab254c6601c95577a34c432cad76e2cef86,78,6,17,9664,,,0,"Send up guest agent logs over the conductor channel to trove controller

In debugging guest failures (especially in the gate) we are hampered
by the fact that we can't see what's happening on the guest. While
this change won't give us *everything* that's happening on the guest,
it will send up everything that the guest agent is logging up the wire
to the host. And it'll show up in the conductor log file.

The code is checked in with the default config value set to False.

Change-Id: I4f765c4ebb3ebde958f10bb1329964da3c4d0fb3
Closes-Bug: #1508144
",git fetch https://review.opendev.org/openstack/trove refs/changes/10/237710/3 && git format-patch -1 --stdout FETCH_HEAD,"['trove/conductor/manager.py', 'trove/conductor/api.py', 'trove/common/cfg.py', 'etc/trove/trove.conf.test', 'trove/taskmanager/models.py', 'trove/cmd/guest.py']",6,0795b0f091e875ed6f8cc832537c38e8918b3fc3,gate-test-review,"import logging as base_loggingfrom trove.common import context as trove_contextfrom trove.conductor import apiCONF.register_opts([openstack_cfg.BoolOpt('guest_log_to_host', default=True, help='Indicate whether the guest ' 'messages should be sent to ' 'conductor.')]) class GuestConductorHandler(base_logging.StreamHandler): __handler = base_logging.StreamHandler() __singleton = None __nested_call = False @classmethod def activate(cls): cls.__handler.acquire() if cls.__singleton is None: cls.__singleton = GuestConductorHandler() cls.__handler.release() return cls.__singleton def __init__(self): if GuestConductorHandler.__singleton is not None: raise Exception( ""Don't directly instantiate GuestConductorHandler."") super(GuestConductorHandler, self).__init__() def emit(self, record): GuestConductorHandler.__handler.acquire() if GuestConductorHandler.__nested_call: GuestConductorHandler.__handler.release() return GuestConductorHandler.__nested_call = True context = trove_context.TroveContext() api.API(context).log_message(CONF.guest_id, record.levelno, self.format(record)) GuestConductorHandler.__nested_call = False GuestConductorHandler.__handler.release() if CONF.guest_log_to_host: base_logging.getLogger(None).addHandler( GuestConductorHandler.activate()) ",,71,2
openstack%2Fshade~master~I782d3b914a1b66b5af20315e58568a715222fe58,openstack/shade,master,I782d3b914a1b66b5af20315e58568a715222fe58,Change naming style of submitTask,MERGED,2016-08-22 14:41:21.000000000,2016-08-29 20:23:51.000000000,2016-08-29 20:23:50.000000000,"[{'_account_id': 2}, {'_account_id': 3}, {'_account_id': 3099}]","[{'number': 1, 'created': '2016-08-22 14:41:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/shade/commit/b1c5e0c2b58752f65dcdbd1baaa96bdd3e147b98', 'message': 'Change naming style of submitTask\n\nsubmitTask is camel cased because it came from nodepool, where camel\ncase is the prevailing style and thus correct. However, in shade,\nunderscores are the prevailing style, so this always feels weird.\n\nMake the method submit_task - but add an alias for submitTask to not\nbreak any code using the old method name.\n\nChange-Id: I782d3b914a1b66b5af20315e58568a715222fe58\n'}, {'number': 2, 'created': '2016-08-25 12:42:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/shade/commit/f6bfb93c0eb37fda81f8a1dcbbd28efd4ae7564e', 'message': 'Change naming style of submitTask\n\nsubmitTask is camel cased because it came from nodepool, where camel\ncase is the prevailing style and thus correct. However, in shade,\nunderscores are the prevailing style, so this always feels weird.\n\nMake the method submit_task - but add an alias for submitTask to not\nbreak any code using the old method name.\n\nChange-Id: I782d3b914a1b66b5af20315e58568a715222fe58\n'}, {'number': 3, 'created': '2016-08-27 18:32:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/shade/commit/fcb3c63a54f39dcff1571f45128fe6288d7d3595', 'message': 'Change naming style of submitTask\n\nsubmitTask is camel cased because it came from nodepool, where camel\ncase is the prevailing style and thus correct. However, in shade,\nunderscores are the prevailing style, so this always feels weird.\n\nMake the method submit_task - but add an alias for submitTask to not\nbreak any code using the old method name.\n\nChange-Id: I782d3b914a1b66b5af20315e58568a715222fe58\n'}, {'number': 4, 'created': '2016-08-29 16:45:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/shade/commit/d7dbc496acc042bd1e0e4a16c08e2d51f358919b', 'message': 'Change naming style of submitTask\n\nsubmitTask is camel cased because it came from nodepool, where camel\ncase is the prevailing style and thus correct. However, in shade,\nunderscores are the prevailing style, so this always feels weird.\n\nMake the method submit_task - but add an alias for submitTask to not\nbreak any code using the old method name.\n\nChange-Id: I782d3b914a1b66b5af20315e58568a715222fe58\n'}, {'number': 5, 'created': '2016-08-29 18:44:56.000000000', 'files': ['shade/operatorcloud.py', 'shade/tests/unit/test_task_manager.py', 'shade/task_manager.py', 'shade/openstackcloud.py'], 'web_link': 'https://opendev.org/openstack/shade/commit/5c1371b22655235fa6b394c89732ca5326d334b8', 'message': 'Change naming style of submitTask\n\nsubmitTask is camel cased because it came from nodepool, where camel\ncase is the prevailing style and thus correct. However, in shade,\nunderscores are the prevailing style, so this always feels weird.\n\nMake the method submit_task - but add an alias for submitTask to not\nbreak any code using the old method name.\n\nChange-Id: I782d3b914a1b66b5af20315e58568a715222fe58\n'}]",0,358684,5c1371b22655235fa6b394c89732ca5326d334b8,21,3,5,2,,,0,"Change naming style of submitTask

submitTask is camel cased because it came from nodepool, where camel
case is the prevailing style and thus correct. However, in shade,
underscores are the prevailing style, so this always feels weird.

Make the method submit_task - but add an alias for submitTask to not
break any code using the old method name.

Change-Id: I782d3b914a1b66b5af20315e58568a715222fe58
",git fetch https://review.opendev.org/openstack/shade refs/changes/84/358684/5 && git format-patch -1 --stdout FETCH_HEAD,"['shade/operatorcloud.py', 'shade/tests/unit/test_task_manager.py', 'shade/task_manager.py', 'shade/openstackcloud.py']",4,b1c5e0c2b58752f65dcdbd1baaa96bdd3e147b98,ksa-task-manager," projects = self.manager.submit_task( projects = self.manager.submit_task( project = self.manager.submit_task(_tasks.ProjectUpdate( project = self.manager.submit_task(_tasks.ProjectCreate( self.manager.submit_task(_tasks.ProjectDelete(**params)) users = self.manager.submit_task(_tasks.UserList()) user = self.manager.submit_task(_tasks.UserGet(user=user_id)) user = self.manager.submit_task(_tasks.UserPasswordUpdate( user = self.manager.submit_task(_tasks.UserUpdate(**kwargs)) user = self.manager.submit_task(_tasks.UserCreate( self.manager.submit_task(_tasks.UserDelete(user=user)) self.manager.submit_task( return self.manager.submit_task( self.manager.submit_task( self.manager.submit_task(_tasks.StackCreate(**params)) self.manager.submit_task(_tasks.StackUpdate(**params)) self.manager.submit_task(_tasks.StackDelete(id=stack['id'])) for extension in self.manager.submit_task( return self.manager.submit_task(_tasks.KeypairList()) return self.manager.submit_task( return self.manager.submit_task( return self.manager.submit_task( return self.manager.submit_task( self.manager.submit_task(_tasks.VolumeList())) flavors = self.manager.submit_task( flavor.extra_specs = self.manager.submit_task( stacks = self.manager.submit_task(_tasks.StackList()) groups = self.manager.submit_task( return self.manager.submit_task( groups = self.manager.submit_task( self.manager.submit_task(_tasks.ServerList()), return self.manager.submit_task(_tasks.ServerGroupList()) image_list = self.manager.submit_task( image_list = self.manager.submit_task(_tasks.NovaImageList()) return self.manager.submit_task(_tasks.FloatingIPPoolList()) return self.manager.submit_task( return self.manager.submit_task(_tasks.NovaFloatingIPList()) self.manager.submit_task(_tasks.ServerGet(server=id)), stack = self.manager.submit_task( return self.manager.submit_task(_tasks.KeypairCreate( self.manager.submit_task(_tasks.KeypairDelete(key=name)) net = self.manager.submit_task( self.manager.submit_task( return self.manager.submit_task( return self.manager.submit_task( new_router = self.manager.submit_task( new_router = self.manager.submit_task( self.manager.submit_task( image_id = str(self.manager.submit_task(_tasks.ImageSnapshotCreate( self.manager.submit_task( self.manager.submit_task( image = self.manager.submit_task(_tasks.ImageCreate( self.manager.submit_task(_tasks.ImageUpload( self.manager.submit_task(_tasks.ImageDelete(image_id=image.id)) image = self.manager.submit_task(_tasks.ImageCreate( self.manager.submit_task(_tasks.ImageUpdate( self.manager.submit_task(_tasks.ImageDelete(image=image.id)) glance_task = self.manager.submit_task( status = self.manager.submit_task( glance_task = self.manager.submit_task( self.manager.submit_task(_tasks.ImageUpdate( self.manager.submit_task(_tasks.ImageUpdate( volume = self.manager.submit_task(_tasks.VolumeCreate( self.manager.submit_task( self.manager.submit_task( vol = self.manager.submit_task( snapshot = self.manager.submit_task( snapshot = self.manager.submit_task( self.manager.submit_task( self.manager.submit_task( [self.manager.submit_task(_tasks.NeutronFloatingIPCreate( pool_ip = self.manager.submit_task( self.manager.submit_task( self.manager.submit_task( return self.manager.submit_task(_tasks.NeutronFloatingIPUpdate( return self.manager.submit_task(_tasks.NovaFloatingIPAttach( self.manager.submit_task(_tasks.NeutronFloatingIPUpdate( self.manager.submit_task(_tasks.NovaFloatingIPDetach( server = self.manager.submit_task(_tasks.ServerCreate( server = self.manager.submit_task(_tasks.ServerRebuild( self.manager.submit_task( self.manager.submit_task( self.manager.submit_task( return self.manager.submit_task( return self.manager.submit_task(_tasks.ServerGroupCreate( self.manager.submit_task( return self.manager.submit_task(_tasks.ContainerList( container = self.manager.submit_task( self.manager.submit_task( self.manager.submit_task( self.manager.submit_task( return self.manager.submit_task(_tasks.ObjectCapabilities()) for r in self.manager.submit_task(_tasks.ObjectCreate( return self.manager.submit_task( return self.manager.submit_task(_tasks.ObjectList( self.manager.submit_task(_tasks.ObjectDelete( return self.manager.submit_task(_tasks.ObjectMetadata( return self.manager.submit_task(_tasks.ObjectGet( new_subnet = self.manager.submit_task( self.manager.submit_task( new_subnet = self.manager.submit_task( return self.manager.submit_task( return self.manager.submit_task( self.manager.submit_task(_tasks.PortDelete(port=port['id'])) group = self.manager.submit_task( group = self.manager.submit_task( self.manager.submit_task( self.manager.submit_task( group = self.manager.submit_task( group = self.manager.submit_task( rule = self.manager.submit_task( rule = self.manager.submit_task( self.manager.submit_task( self.manager.submit_task( return self.manager.submit_task(_tasks.ZoneList()) return self.manager.submit_task(_tasks.ZoneCreate( new_zone = self.manager.submit_task( self.manager.submit_task( return self.manager.submit_task(_tasks.RecordSetList(zone=zone)) return self.manager.submit_task(_tasks.RecordSetGet( return self.manager.submit_task(_tasks.RecordSetCreate( new_recordset = self.manager.submit_task( self.manager.submit_task( cluster_templates = self.manager.submit_task( cluster_template = self.manager.submit_task( self.manager.submit_task( self.manager.submit_task("," projects = self.manager.submitTask( projects = self.manager.submitTask( project = self.manager.submitTask(_tasks.ProjectUpdate( project = self.manager.submitTask(_tasks.ProjectCreate( self.manager.submitTask(_tasks.ProjectDelete(**params)) users = self.manager.submitTask(_tasks.UserList()) user = self.manager.submitTask(_tasks.UserGet(user=user_id)) user = self.manager.submitTask(_tasks.UserPasswordUpdate( user = self.manager.submitTask(_tasks.UserUpdate(**kwargs)) user = self.manager.submitTask(_tasks.UserCreate( self.manager.submitTask(_tasks.UserDelete(user=user)) self.manager.submitTask( return self.manager.submitTask( self.manager.submitTask( self.manager.submitTask(_tasks.StackCreate(**params)) self.manager.submitTask(_tasks.StackUpdate(**params)) self.manager.submitTask(_tasks.StackDelete(id=stack['id'])) for extension in self.manager.submitTask( return self.manager.submitTask(_tasks.KeypairList()) return self.manager.submitTask( return self.manager.submitTask( return self.manager.submitTask( return self.manager.submitTask( self.manager.submitTask(_tasks.VolumeList())) flavors = self.manager.submitTask( flavor.extra_specs = self.manager.submitTask( stacks = self.manager.submitTask(_tasks.StackList()) groups = self.manager.submitTask( return self.manager.submitTask( groups = self.manager.submitTask( self.manager.submitTask(_tasks.ServerList()), return self.manager.submitTask(_tasks.ServerGroupList()) image_list = self.manager.submitTask( image_list = self.manager.submitTask(_tasks.NovaImageList()) return self.manager.submitTask(_tasks.FloatingIPPoolList()) return self.manager.submitTask( return self.manager.submitTask(_tasks.NovaFloatingIPList()) self.manager.submitTask(_tasks.ServerGet(server=id)), stack = self.manager.submitTask( return self.manager.submitTask(_tasks.KeypairCreate( self.manager.submitTask(_tasks.KeypairDelete(key=name)) net = self.manager.submitTask( self.manager.submitTask( return self.manager.submitTask( return self.manager.submitTask( new_router = self.manager.submitTask( new_router = self.manager.submitTask( self.manager.submitTask( image_id = str(self.manager.submitTask(_tasks.ImageSnapshotCreate( self.manager.submitTask( self.manager.submitTask( image = self.manager.submitTask(_tasks.ImageCreate( self.manager.submitTask(_tasks.ImageUpload( self.manager.submitTask(_tasks.ImageDelete(image_id=image.id)) image = self.manager.submitTask(_tasks.ImageCreate( self.manager.submitTask(_tasks.ImageUpdate( self.manager.submitTask(_tasks.ImageDelete(image=image.id)) glance_task = self.manager.submitTask( status = self.manager.submitTask( glance_task = self.manager.submitTask( self.manager.submitTask(_tasks.ImageUpdate( self.manager.submitTask(_tasks.ImageUpdate( volume = self.manager.submitTask(_tasks.VolumeCreate( self.manager.submitTask( self.manager.submitTask( vol = self.manager.submitTask( snapshot = self.manager.submitTask( snapshot = self.manager.submitTask( self.manager.submitTask( self.manager.submitTask( [self.manager.submitTask(_tasks.NeutronFloatingIPCreate( pool_ip = self.manager.submitTask( self.manager.submitTask( self.manager.submitTask( return self.manager.submitTask(_tasks.NeutronFloatingIPUpdate( return self.manager.submitTask(_tasks.NovaFloatingIPAttach( self.manager.submitTask(_tasks.NeutronFloatingIPUpdate( self.manager.submitTask(_tasks.NovaFloatingIPDetach( server = self.manager.submitTask(_tasks.ServerCreate( server = self.manager.submitTask(_tasks.ServerRebuild( self.manager.submitTask( self.manager.submitTask( self.manager.submitTask( return self.manager.submitTask( return self.manager.submitTask(_tasks.ServerGroupCreate( self.manager.submitTask( return self.manager.submitTask(_tasks.ContainerList( container = self.manager.submitTask( self.manager.submitTask( self.manager.submitTask( self.manager.submitTask( return self.manager.submitTask(_tasks.ObjectCapabilities()) for r in self.manager.submitTask(_tasks.ObjectCreate( return self.manager.submitTask( return self.manager.submitTask(_tasks.ObjectList( self.manager.submitTask(_tasks.ObjectDelete( return self.manager.submitTask(_tasks.ObjectMetadata( return self.manager.submitTask(_tasks.ObjectGet( new_subnet = self.manager.submitTask( self.manager.submitTask( new_subnet = self.manager.submitTask( return self.manager.submitTask( return self.manager.submitTask( self.manager.submitTask(_tasks.PortDelete(port=port['id'])) group = self.manager.submitTask( group = self.manager.submitTask( self.manager.submitTask( self.manager.submitTask( group = self.manager.submitTask( group = self.manager.submitTask( rule = self.manager.submitTask( rule = self.manager.submitTask( self.manager.submitTask( self.manager.submitTask( return self.manager.submitTask(_tasks.ZoneList()) return self.manager.submitTask(_tasks.ZoneCreate( new_zone = self.manager.submitTask( self.manager.submitTask( return self.manager.submitTask(_tasks.RecordSetList(zone=zone)) return self.manager.submitTask(_tasks.RecordSetGet( return self.manager.submitTask(_tasks.RecordSetCreate( new_recordset = self.manager.submitTask( self.manager.submitTask( cluster_templates = self.manager.submitTask( cluster_template = self.manager.submitTask( self.manager.submitTask( self.manager.submitTask(",210,208
openstack%2Fkolla-kubernetes~master~I528fc5d84e790bd739c8cb900a9ee14ba7bec9fb,openstack/kolla-kubernetes,master,I528fc5d84e790bd739c8cb900a9ee14ba7bec9fb,Getting NOVA pieces together to launch VM,MERGED,2016-08-23 00:30:46.000000000,2016-08-29 20:14:00.000000000,2016-08-29 20:14:00.000000000,"[{'_account_id': 3}, {'_account_id': 9237}, {'_account_id': 10419}, {'_account_id': 19384}]","[{'number': 1, 'created': '2016-08-23 00:30:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-kubernetes/commit/83fb959087ea7ff420efe3d5e3ea6c3ddea56514', 'message': 'WIP Getting NOVA pieces together to launch VM\n\nThis PS gets NOVA related pieces together in order to be able to\nlaunch a VM. It builds upon the work done by wirehead.\n\nTrivialFix\n\nChange-Id: I528fc5d84e790bd739c8cb900a9ee14ba7bec9fb\n'}, {'number': 2, 'created': '2016-08-23 00:58:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-kubernetes/commit/d5a10e8da41de729e801ef36f9a29bdd82407900', 'message': 'WIP Getting NOVA pieces together to launch VM\n\nThis PS gets NOVA related pieces together in order to be able to\nlaunch a VM. It builds upon the work done by wirehead.\n\nPartially-Implements: blueprint nova-kubernetes\n\nChange-Id: I528fc5d84e790bd739c8cb900a9ee14ba7bec9fb\n'}, {'number': 3, 'created': '2016-08-23 00:59:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-kubernetes/commit/230dcd03fd3aa62aa30b1ac4df9f797bcbf93a96', 'message': 'WIP Getting NOVA pieces together to launch VM\n\nThis PS gets NOVA related pieces together in order to be able to\nlaunch a VM. It builds upon the work done by wirehead.\n\nPartially-Implements: blueprint nova-kubernetes\n\nChange-Id: I528fc5d84e790bd739c8cb900a9ee14ba7bec9fb\n'}, {'number': 4, 'created': '2016-08-23 12:05:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-kubernetes/commit/3ad8ba49c2381004d5e7c7c4e0bfe471ad7b788e', 'message': 'WIP Getting NOVA pieces together to launch VM\n\nThis PS gets NOVA related pieces together in order to be able to\nlaunch a VM. It builds upon the work done by wirehead.\n\nPartially-Implements: blueprint nova-kubernetes\n\nChange-Id: I528fc5d84e790bd739c8cb900a9ee14ba7bec9fb\n'}, {'number': 5, 'created': '2016-08-23 12:19:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-kubernetes/commit/326e22e3467c5035a193c1da556556a5027feda9', 'message': 'WIP Getting NOVA pieces together to launch VM\n\nThis PS gets NOVA related pieces together in order to be able to\nlaunch a VM. It builds upon the work done by wirehead.\n\nPartially-Implements: blueprint nova-kubernetes\n\nChange-Id: I528fc5d84e790bd739c8cb900a9ee14ba7bec9fb\n'}, {'number': 6, 'created': '2016-08-23 12:32:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-kubernetes/commit/50f47001a158d6e1dac245818abbf99dc9d63fcd', 'message': 'WIP Getting NOVA pieces together to launch VM\n\nThis PS gets NOVA related pieces together in order to be able to\nlaunch a VM. It builds upon the work done by wirehead.\n\nPartially-Implements: blueprint nova-kubernetes\n\nChange-Id: I528fc5d84e790bd739c8cb900a9ee14ba7bec9fb\n'}, {'number': 7, 'created': '2016-08-23 14:15:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-kubernetes/commit/c38c12ba2bbdacd1a40aa3f7627f960464cc1afd', 'message': 'WIP Getting NOVA pieces together to launch VM\n\nThis PS gets NOVA related pieces together in order to be able to\nlaunch a VM. It builds upon the work done by wirehead.\n\nPartially-Implements: blueprint nova-kubernetes\n\nChange-Id: I528fc5d84e790bd739c8cb900a9ee14ba7bec9fb\n'}, {'number': 8, 'created': '2016-08-23 15:32:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-kubernetes/commit/73e85a078aa65e02b653fcdb423f78a2bcc158df', 'message': 'WIP Getting NOVA pieces together to launch VM\n\nThis PS gets NOVA related pieces together in order to be able to\nlaunch a VM. It builds upon the work done by wirehead.\n\nPartially-Implements: blueprint nova-kubernetes\n\nChange-Id: I528fc5d84e790bd739c8cb900a9ee14ba7bec9fb\n'}, {'number': 9, 'created': '2016-08-23 21:47:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-kubernetes/commit/fb2a19bb5d59b0d30df4eb5c5b0b191c69908448', 'message': 'WIP Getting NOVA pieces together to launch VM\n\nThis PS gets NOVA related pieces together in order to be able to\nlaunch a VM. It builds upon the work done by wirehead.\n\nPartially-Implements: blueprint nova-kubernetes\n\nChange-Id: I528fc5d84e790bd739c8cb900a9ee14ba7bec9fb\n'}, {'number': 10, 'created': '2016-08-23 22:24:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-kubernetes/commit/bc61f7ff7cee7a559a4d934298481d168b614e7b', 'message': 'WIP Getting NOVA pieces together to launch VM\n\nThis PS gets NOVA related pieces together in order to be able to\nlaunch a VM. It builds upon the work done by wirehead.\n\nPartially-Implements: blueprint nova-kubernetes\n\nChange-Id: I528fc5d84e790bd739c8cb900a9ee14ba7bec9fb\n'}, {'number': 11, 'created': '2016-08-26 13:17:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-kubernetes/commit/662848fac747efbd65d4acb87f6df8f2b37ec061', 'message': 'Getting NOVA pieces together to launch VM\n\nThis PS gets NOVA related pieces together in order to be able to\nlaunch a VM. It builds upon the work done by wirehead.\n\nPartially-Implements: blueprint nova-kubernetes\n\nChange-Id: I528fc5d84e790bd739c8cb900a9ee14ba7bec9fb\n'}, {'number': 12, 'created': '2016-08-26 13:33:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-kubernetes/commit/b3ffb5f80fb78c2340bc11e5ad220d3069a89d53', 'message': 'Getting NOVA pieces together to launch VM\n\nThis PS gets NOVA related pieces together in order to be able to\nlaunch a VM. It builds upon the work done by wirehead.\n\nPartially-Implements: blueprint nova-kubernetes\n\nChange-Id: I528fc5d84e790bd739c8cb900a9ee14ba7bec9fb\n'}, {'number': 13, 'created': '2016-08-26 16:34:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-kubernetes/commit/b255629206bde6171de597e96364813e67fd3ef2', 'message': 'Getting NOVA pieces together to launch VM\n\nThis PS gets NOVA related pieces together in order to be able to\nlaunch a VM. It builds upon the work done by wirehead.\n\nPartially-Implements: blueprint nova-kubernetes\n\nChange-Id: I528fc5d84e790bd739c8cb900a9ee14ba7bec9fb\n'}, {'number': 14, 'created': '2016-08-26 21:33:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-kubernetes/commit/330dd115a4bedbb5f4ea9ff9fbf18e04e21ba341', 'message': 'Getting NOVA pieces together to launch VM\n\nThis PS gets NOVA related pieces together in order to be able to\nlaunch a VM. It builds upon the work done by wirehead.\n\nPartially-Implements: blueprint nova-kubernetes\n\nChange-Id: I528fc5d84e790bd739c8cb900a9ee14ba7bec9fb\n'}, {'number': 15, 'created': '2016-08-27 03:09:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-kubernetes/commit/c4a0f8a627378b515a096be310a26c3c50947ca3', 'message': 'Getting NOVA pieces together to launch VM\n\nThis PS gets NOVA related pieces together in order to be able to\nlaunch a VM. It builds upon the work done by wirehead.\n\nPartially-Implements: blueprint nova-kubernetes\n\nChange-Id: I528fc5d84e790bd739c8cb900a9ee14ba7bec9fb\n'}, {'number': 16, 'created': '2016-08-29 13:17:27.000000000', 'files': ['services/nova/nova-control-scheduler-pod.yml.j2', 'services/nova/nova-control-api-pod.yml.j2', 'services/nova/nova-control-conductor-pod.yml.j2', 'services/nova/nova-control-bootstrap-job-create-nova-endpoints.yml.j2', 'services/nova/nova-compute-bootstrap-job.yml.j2', 'services/nova/nova-libvirt-pod.yml.j2', 'etc/kolla-kubernetes/kolla-kubernetes.yml', 'services/nova/nova-control-bootstrap-job.yml.j2', 'services/nova/nova-compute-pod.yml.j2', 'services/nova/nova-control-bootstrap-job-create-nova-api-db.yml.j2', 'services/nova/nova-control-bootstrap-job-create-nova-db.yml.j2'], 'web_link': 'https://opendev.org/openstack/kolla-kubernetes/commit/316f546f04c90e419fe68c5a8381a6c7529a29e0', 'message': 'Getting NOVA pieces together to launch VM\n\nThis PS gets NOVA related pieces together in order to be able to\nlaunch a VM. It builds upon the work done by wirehead.\n\nPartially-Implements: blueprint nova-kubernetes\n\nChange-Id: I528fc5d84e790bd739c8cb900a9ee14ba7bec9fb\n'}]",30,358911,316f546f04c90e419fe68c5a8381a6c7529a29e0,50,4,16,19384,,,0,"Getting NOVA pieces together to launch VM

This PS gets NOVA related pieces together in order to be able to
launch a VM. It builds upon the work done by wirehead.

Partially-Implements: blueprint nova-kubernetes

Change-Id: I528fc5d84e790bd739c8cb900a9ee14ba7bec9fb
",git fetch https://review.opendev.org/openstack/kolla-kubernetes refs/changes/11/358911/14 && git format-patch -1 --stdout FETCH_HEAD,"['services/nova/nova-control-bootstrap-job-create-nova-endpoints.yml.j2', 'etc/kolla-kubernetes/kolla-kubernetes.yml', 'services/nova/nova-control-bootstrap-job.yml.j2', 'services/nova/nova-control-bootstrap-job-create-nova-api-db.yml.j2', 'services/nova/nova-control-bootstrap-job-create-nova-db.yml.j2']",5,83fb959087ea7ff420efe3d5e3ea6c3ddea56514,bp/nova-kubernetes,"apiVersion: batch/v1 kind: Job spec: template: metadata: name: nova-control-bootstrap-create-nova-db spec: containers: - image: ""{{ kolla_toolbox_image_full }}"" name: creating-nova-database-and-users command: [""sh"", ""-c""] args: - ansible localhost -vvvv -m mysql_db -a ""login_host=mariadb login_port='{{ mariadb_port }}' login_user='{{ database_user }}' login_password='$DATABASE_PASSWORD' name='{{ nova_database_name }}'"" && ansible localhost -vvvv -m mysql_db -a ""login_host=mariadb login_port='{{ mariadb_port }}' login_user='{{ database_user }}' login_password='$DATABASE_PASSWORD' name='{{ nova_api_database_name }}'"" && ansible localhost -m mysql_user -a ""login_host=mariadb login_port='{{ mariadb_port }}' login_user='{{ database_user }}' login_password='$DATABASE_PASSWORD' name='{{ nova_database_name }}' password='$NOVA_DATABASE_PASSWORD' host='%' priv='{{ nova_database_name }}.*:ALL' append_privs='yes'"" && ansible localhost -m mysql_user -a ""login_host=mariadb login_port='{{ mariadb_port }}' login_user='{{ database_user }}' login_password='$DATABASE_PASSWORD' name='{{ nova_api_database_name }}' password='$NOVA_API_DATABASE_PASSWORD' host='%' priv='{{ nova_api_database_name }}.*:ALL' append_privs='yes'"" volumeMounts: - mountPath: /var/log/kolla name: kolla-logs env: - name: ANSIBLE_NOCOLOR value: ""1"" - name: ANSIBLE_LIBRARY value: ""/usr/share/ansible"" - name: DATABASE_PASSWORD valueFrom: secretKeyRef: name: database-password key: password - name: NOVA_DATABASE_PASSWORD valueFrom: secretKeyRef: name: nova-database-password key: password - name: NOVA_API_DATABASE_PASSWORD valueFrom: secretKeyRef: name: nova-api-database-password key: password volumes: - name: nova-api-config configMap: name: nova-api-configmap - name: etc-localtime hostPath: path: /etc/localtime - name: lib-modules hostPath: path: /lib/modules - name: kolla-logs emptyDir: {} restartPolicy: OnFailure metadata: name: nova-control-bootstrap-create-nova-db ",,208,134
openstack%2Fsyntribos~master~I6d1e656ac7c5a68efcc02b0710ae7e2f05a4798f,openstack/syntribos,master,I6d1e656ac7c5a68efcc02b0710ae7e2f05a4798f,patch to sanitize debug log,MERGED,2016-08-25 00:08:06.000000000,2016-08-29 20:10:48.000000000,2016-08-29 20:10:48.000000000,"[{'_account_id': 3}, {'_account_id': 8119}, {'_account_id': 15515}, {'_account_id': 17709}, {'_account_id': 18462}, {'_account_id': 21297}, {'_account_id': 22221}, {'_account_id': 22781}]","[{'number': 1, 'created': '2016-08-25 00:08:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/syntribos/commit/a28bc9b5011d92852f1381e2cea50477071027dc', 'message': 'patch to sanitize debug log\n\npatch to sanitize `secrets` from debug log.\n\nChange-Id: I6d1e656ac7c5a68efcc02b0710ae7e2f05a4798f\n'}, {'number': 2, 'created': '2016-08-25 04:35:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/syntribos/commit/63338db0c751c24df75a93357e4caf0ee4e5d224', 'message': 'patch to sanitize debug log\n\npatch to sanitize `secrets` from debug log.\n\nChange-Id: I6d1e656ac7c5a68efcc02b0710ae7e2f05a4798f\n'}, {'number': 3, 'created': '2016-08-25 04:56:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/syntribos/commit/117876ddb5073564dbdcda38cdf3bd4eebf6e2f3', 'message': 'patch to sanitize debug log\n\npatch to sanitize `secrets` from debug log.\n\nChange-Id: I6d1e656ac7c5a68efcc02b0710ae7e2f05a4798f\n'}, {'number': 4, 'created': '2016-08-25 04:58:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/syntribos/commit/ac87a6e1dae392fd60ad975e8903b37d69246eb0', 'message': 'patch to sanitize debug log\n\npatch to sanitize `secrets` from debug log.\n\nChange-Id: I6d1e656ac7c5a68efcc02b0710ae7e2f05a4798f\n'}, {'number': 5, 'created': '2016-08-25 05:24:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/syntribos/commit/dc7dc3ab28e0e586b9d9f99faf92344d42657c56', 'message': 'patch to sanitize debug log\n\npatch to sanitize `secrets` from debug log.\n\nChange-Id: I6d1e656ac7c5a68efcc02b0710ae7e2f05a4798f\n'}, {'number': 6, 'created': '2016-08-26 22:24:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/syntribos/commit/622018bf3f16e0b9066a17aceb3f9b73f29ddb28', 'message': 'patch to sanitize debug log\n\npatch to sanitize `secrets` from debug log.\n\nChange-Id: I6d1e656ac7c5a68efcc02b0710ae7e2f05a4798f\n'}, {'number': 7, 'created': '2016-08-26 22:28:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/syntribos/commit/67dda0c7e5fd1b7f8f453d30cf24be3edb33e9ad', 'message': 'patch to sanitize debug log\n\npatch to sanitize `secrets` from debug log.\n\nChange-Id: I6d1e656ac7c5a68efcc02b0710ae7e2f05a4798f\n'}, {'number': 8, 'created': '2016-08-26 22:51:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/syntribos/commit/55dd21361a65bfef1a3114fc4133a06b172acfee', 'message': 'patch to sanitize debug log\n\npatch to sanitize `secrets` from debug log.\n\nChange-Id: I6d1e656ac7c5a68efcc02b0710ae7e2f05a4798f\n'}, {'number': 9, 'created': '2016-08-26 22:57:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/syntribos/commit/33aaf20d28007f30ee22527b78a554d4426e35cc', 'message': 'patch to sanitize debug log\n\npatch to sanitize `secrets` from debug log.\n\nChange-Id: I6d1e656ac7c5a68efcc02b0710ae7e2f05a4798f\n'}, {'number': 10, 'created': '2016-08-27 17:08:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/syntribos/commit/4b1c655e2da76feae49df1181fbe018658347b15', 'message': 'patch to sanitize debug log\n\npatch to sanitize `secrets` from debug log.\n\nChange-Id: I6d1e656ac7c5a68efcc02b0710ae7e2f05a4798f\n'}, {'number': 11, 'created': '2016-08-29 04:15:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/syntribos/commit/90e93558d8b8e63e53d6d2c70bf02c811eee088b', 'message': 'patch to sanitize debug log\n\npatch to sanitize `secrets` from debug log.\n\nChange-Id: I6d1e656ac7c5a68efcc02b0710ae7e2f05a4798f\n'}, {'number': 12, 'created': '2016-08-29 17:27:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/syntribos/commit/b02863f7ce8e251e1f627199c70fb0ca16dc9490', 'message': 'patch to sanitize debug log\n\npatch to sanitize `secrets` from debug log.\n\nChange-Id: I6d1e656ac7c5a68efcc02b0710ae7e2f05a4798f\n'}, {'number': 13, 'created': '2016-08-29 18:47:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/syntribos/commit/3d4653d9393e5cb6bdc88345da4027ac4bd0c745', 'message': 'patch to sanitize debug log\n\npatch to sanitize `secrets` from debug log.\n\nChange-Id: I6d1e656ac7c5a68efcc02b0710ae7e2f05a4798f\n'}, {'number': 14, 'created': '2016-08-29 19:13:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/syntribos/commit/57d5c1c8e8eb70e7763ae2e5748671d88d8282b5', 'message': 'patch to sanitize debug log\n\npatch to sanitize `secrets` from debug log.\n\nChange-Id: I6d1e656ac7c5a68efcc02b0710ae7e2f05a4798f\n'}, {'number': 15, 'created': '2016-08-29 19:16:51.000000000', 'files': ['syntribos/clients/http/base_http_client.py', 'requirements.txt', 'tests/unit/test_debug_logger.py', 'syntribos/extensions/identity/client.py', 'syntribos/clients/http/debug_logger.py', 'syntribos/clients/http/client.py', 'syntribos/clients/http/models.py'], 'web_link': 'https://opendev.org/openstack/syntribos/commit/824928799ec898be52292cd2194c81a9719bf476', 'message': 'patch to sanitize debug log\n\npatch to sanitize `secrets` from debug log.\n\nChange-Id: I6d1e656ac7c5a68efcc02b0710ae7e2f05a4798f\n'}]",15,360127,824928799ec898be52292cd2194c81a9719bf476,48,8,15,18462,,,0,"patch to sanitize debug log

patch to sanitize `secrets` from debug log.

Change-Id: I6d1e656ac7c5a68efcc02b0710ae7e2f05a4798f
",git fetch https://review.opendev.org/openstack/syntribos refs/changes/27/360127/3 && git format-patch -1 --stdout FETCH_HEAD,"['syntribos/clients/http/base_http_client.py', 'syntribos/extensions/identity/client.py', 'syntribos/clients/http/debug_logger.py', 'syntribos/clients/http/client.py', 'syntribos/clients/http/models.py']",5,a28bc9b5011d92852f1381e2cea50477071027dc,sanitze_logs," :ivar bool filter_secrets: Boolean variable used to filter secrets params=None, data=None, filter_secrets=False): self.filter_secrets = filter_secrets"," params=None, data=None):",57,20
openstack%2Ftrove~master~Ibd9e77c24f56e7886459fce00a4ed33b3e9e1011,openstack/trove,master,Ibd9e77c24f56e7886459fce00a4ed33b3e9e1011,Add tox entry for py35 tests,MERGED,2016-08-23 21:53:17.000000000,2016-08-29 20:08:23.000000000,2016-08-29 20:08:23.000000000,"[{'_account_id': 3}, {'_account_id': 10215}, {'_account_id': 12758}, {'_account_id': 14576}, {'_account_id': 22694}, {'_account_id': 23058}]","[{'number': 1, 'created': '2016-08-23 21:53:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/61dd7924a195963b63b5d07a0c756956ece5dc33', 'message': 'Add tox entry for py35 tests\n\nAdded an entry for the py35 tests.  Put the default\nvalues into a py3base entry and referred to them\nfrom both py34 and py35.\n\nChange-Id: Ibd9e77c24f56e7886459fce00a4ed33b3e9e1011\n'}, {'number': 2, 'created': '2016-08-23 22:18:46.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/trove/commit/d19f5dc7aa7c62bf21eabc0426af6463bcd2fc8d', 'message': 'Add tox entry for py35 tests\n\nAdded an entry for the py35 tests.  Put the default\nvalues into a py3base entry and referred to them\nfrom both py34 and py35.\n\nChange-Id: Ibd9e77c24f56e7886459fce00a4ed33b3e9e1011\n'}]",0,359446,d19f5dc7aa7c62bf21eabc0426af6463bcd2fc8d,36,6,2,10215,,,0,"Add tox entry for py35 tests

Added an entry for the py35 tests.  Put the default
values into a py3base entry and referred to them
from both py34 and py35.

Change-Id: Ibd9e77c24f56e7886459fce00a4ed33b3e9e1011
",git fetch https://review.opendev.org/openstack/trove refs/changes/46/359446/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,61dd7924a195963b63b5d07a0c756956ece5dc33,,"[py3base] find ./trove -type f -name ""*.pyc"" -delete find [testenv:py34] commands = {[py3base]commands} whitelist_externals = {[py3base]whitelist_externals} [testenv:py35] commands = {[py3base]commands} whitelist_externals = {[py3base]whitelist_externals}",[testenv:py34],10,1
openstack%2Ftripleo-heat-templates~master~Ib60198adf76bb69ffbafbfac739e356d153f6194,openstack/tripleo-heat-templates,master,Ib60198adf76bb69ffbafbfac739e356d153f6194,Convert ServiceNetMap to a nested template,MERGED,2016-08-09 17:31:19.000000000,2016-08-29 20:05:28.000000000,2016-08-15 15:09:44.000000000,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 3153}, {'_account_id': 6796}, {'_account_id': 10873}, {'_account_id': 12398}]","[{'number': 1, 'created': '2016-08-09 17:31:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/75217dbb017a18ab0e8ea3e8276b1f61b352ec70', 'message': ""Convert ServiceNetMap to a nested template\n\nWe introduce a new ServiceNetMap resource which enables some more flexible\nmappings between the services and their networks.\n\nSpecifically this patch means:\n\n1. ServiceNetMap no longer has to specify the entire list of all services,\noperators may if they wish, but a subset is now valid where you want to\naccept the defaults for some services (the defaults are now accessible via\nthe ServiceNetMapDefaults parameter.\n\n2. We can map some keys which don't fit a pattern that enables conversion\nfrom CamelCase to snake_case which is required for compatibility with the\nservice_names in puppet/services*\n\nThis should be backwards compatible, and in future when we remove internal\ndependency on the CamelCase names, we could also enable operators to\nspecify e.g heat_api_network in ServiceNetMap which would be more consistent.\n\nChange-Id: Ib60198adf76bb69ffbafbfac739e356d153f6194\nPartially-Implements: blueprint custom-roles\n""}, {'number': 2, 'created': '2016-08-09 21:28:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/e4db0dec7890e23053df1f03c89edf740b5ba23b', 'message': ""Convert ServiceNetMap to a nested template\n\nWe introduce a new ServiceNetMap resource which enables some more flexible\nmappings between the services and their networks.\n\nSpecifically this patch means:\n\n1. ServiceNetMap no longer has to specify the entire list of all services,\noperators may if they wish, but a subset is now valid where you want to\naccept the defaults for some services (the defaults are now accessible via\nthe ServiceNetMapDefaults parameter.\n\n2. We can map some keys which don't fit a pattern that enables conversion\nfrom CamelCase to snake_case which is required for compatibility with the\nservice_names in puppet/services*\n\nThis should be backwards compatible, and in future when we remove internal\ndependency on the CamelCase names, we could also enable operators to\nspecify e.g heat_api_network in ServiceNetMap which would be more consistent.\n\nChange-Id: Ib60198adf76bb69ffbafbfac739e356d153f6194\nPartially-Implements: blueprint custom-roles\n""}, {'number': 3, 'created': '2016-08-11 06:23:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/6cc78fab6ec7d7ee44cd253aeda2be94c25156f2', 'message': ""Convert ServiceNetMap to a nested template\n\nWe introduce a new ServiceNetMap resource which enables some more flexible\nmappings between the services and their networks.\n\nSpecifically this patch means:\n\n1. ServiceNetMap no longer has to specify the entire list of all services,\noperators may if they wish, but a subset is now valid where you want to\naccept the defaults for some services (the defaults are now accessible via\nthe ServiceNetMapDefaults parameter.\n\n2. We can map some keys which don't fit a pattern that enables conversion\nfrom CamelCase to snake_case which is required for compatibility with the\nservice_names in puppet/services*\n\nThis should be backwards compatible, and in future when we remove internal\ndependency on the CamelCase names, we could also enable operators to\nspecify e.g heat_api_network in ServiceNetMap which would be more consistent.\n\nChange-Id: Ib60198adf76bb69ffbafbfac739e356d153f6194\nPartially-Implements: blueprint custom-roles\n""}, {'number': 4, 'created': '2016-08-11 11:36:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/f5a2f07833dee9f43ebcbfd66ba509e906de9730', 'message': ""Convert ServiceNetMap to a nested template\n\nWe introduce a new ServiceNetMap resource which enables some more flexible\nmappings between the services and their networks.\n\nSpecifically this patch means:\n\n1. ServiceNetMap no longer has to specify the entire list of all services,\noperators may if they wish, but a subset is now valid where you want to\naccept the defaults for some services (the defaults are now accessible via\nthe ServiceNetMapDefaults parameter.\n\n2. We can map some keys which don't fit a pattern that enables conversion\nfrom CamelCase to snake_case which is required for compatibility with the\nservice_names in puppet/services*\n\nThis should be backwards compatible, and in future when we remove internal\ndependency on the CamelCase names, we could also enable operators to\nspecify e.g heat_api_network in ServiceNetMap which would be more consistent.\n\nChange-Id: Ib60198adf76bb69ffbafbfac739e356d153f6194\nPartially-Implements: blueprint custom-roles\n""}, {'number': 5, 'created': '2016-08-12 13:55:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/5b74edf4cd0ac0837f496bb3e79d2a962bc20f83', 'message': ""Convert ServiceNetMap to a nested template\n\nWe introduce a new ServiceNetMap resource which enables some more flexible\nmappings between the services and their networks.\n\nSpecifically this patch means:\n\n1. ServiceNetMap no longer has to specify the entire list of all services,\noperators may if they wish, but a subset is now valid where you want to\naccept the defaults for some services (the defaults are now accessible via\nthe ServiceNetMapDefaults parameter.\n\n2. We can map some keys which don't fit a pattern that enables conversion\nfrom CamelCase to snake_case which is required for compatibility with the\nservice_names in puppet/services*\n\nThis should be backwards compatible, and in future when we remove internal\ndependency on the CamelCase names, we could also enable operators to\nspecify e.g heat_api_network in ServiceNetMap which would be more consistent.\n\nChange-Id: Ib60198adf76bb69ffbafbfac739e356d153f6194\nPartially-Implements: blueprint custom-roles\n""}, {'number': 6, 'created': '2016-08-12 20:28:25.000000000', 'files': ['puppet/controller.yaml', 'environments/updates/update-from-keystone-admin-internal-api.yaml', 'overcloud-resource-registry-puppet.yaml', 'overcloud.yaml', 'network/service_net_map.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/ac8d5919d86027aa9e0f523f77e3071b36b8a7d0', 'message': ""Convert ServiceNetMap to a nested template\n\nWe introduce a new ServiceNetMap resource which enables some more flexible\nmappings between the services and their networks.\n\nSpecifically this patch means:\n\n1. ServiceNetMap no longer has to specify the entire list of all services,\noperators may if they wish, but a subset is now valid where you want to\naccept the defaults for some services (the defaults are now accessible via\nthe ServiceNetMapDefaults parameter.\n\n2. We can map some keys which don't fit a pattern that enables conversion\nfrom CamelCase to snake_case which is required for compatibility with the\nservice_names in puppet/services*\n\nThis should be backwards compatible, and in future when we remove internal\ndependency on the CamelCase names, we could also enable operators to\nspecify e.g heat_api_network in ServiceNetMap which would be more consistent.\n\nChange-Id: Ib60198adf76bb69ffbafbfac739e356d153f6194\nPartially-Implements: blueprint custom-roles\n""}]",1,353032,ac8d5919d86027aa9e0f523f77e3071b36b8a7d0,31,6,6,4328,,,0,"Convert ServiceNetMap to a nested template

We introduce a new ServiceNetMap resource which enables some more flexible
mappings between the services and their networks.

Specifically this patch means:

1. ServiceNetMap no longer has to specify the entire list of all services,
operators may if they wish, but a subset is now valid where you want to
accept the defaults for some services (the defaults are now accessible via
the ServiceNetMapDefaults parameter.

2. We can map some keys which don't fit a pattern that enables conversion
from CamelCase to snake_case which is required for compatibility with the
service_names in puppet/services*

This should be backwards compatible, and in future when we remove internal
dependency on the CamelCase names, we could also enable operators to
specify e.g heat_api_network in ServiceNetMap which would be more consistent.

Change-Id: Ib60198adf76bb69ffbafbfac739e356d153f6194
Partially-Implements: blueprint custom-roles
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/32/353032/1 && git format-patch -1 --stdout FETCH_HEAD,"['puppet/controller.yaml', 'environments/updates/update-from-keystone-admin-internal-api.yaml', 'overcloud-resource-registry-puppet.yaml', 'overcloud.yaml', 'network/service_net_map.yaml']",5,75217dbb017a18ab0e8ea3e8276b1f61b352ec70,bp/custom-roles,"heat_template_version: 2016-10-14 description: > Mapping of service_name_network -> network name parameters: ServiceNetMap: description: Mapping of service_name -> network name. Typically set via parameter_defaults in the resource registry. This mapping overrides those in ServiceNetMapDefaults. default: {} type: json ServiceNetMapDefaults: default: NeutronTenantNetwork: tenant CeilometerApiNetwork: internal_api AodhApiNetwork: internal_api GnocchiApiNetwork: internal_api MongodbNetwork: internal_api CinderApiNetwork: internal_api CinderIscsiNetwork: storage GlanceApiNetwork: storage GlanceRegistryNetwork: internal_api IronicApiNetwork: internal_api KeystoneAdminApiNetwork: ctlplane # allows undercloud to config endpoints KeystonePublicApiNetwork: internal_api ManilaApiNetwork: internal_api NeutronApiNetwork: internal_api HeatApiNetwork: internal_api NovaApiNetwork: internal_api NovaMetadataNetwork: internal_api NovaVncProxyNetwork: internal_api SwiftMgmtNetwork: storage_mgmt SwiftProxyNetwork: storage SaharaApiNetwork: internal_api HorizonNetwork: internal_api MemcachedNetwork: internal_api RabbitmqNetwork: internal_api RedisNetwork: internal_api MysqlNetwork: internal_api CephClusterNetwork: storage_mgmt CephPublicNetwork: storage ControllerHostnameResolveNetwork: internal_api ComputeHostnameResolveNetwork: internal_api BlockStorageHostnameResolveNetwork: internal_api ObjectStorageHostnameResolveNetwork: internal_api CephStorageHostnameResolveNetwork: storage PublicNetwork: external description: Mapping of service_name -> network name. Typically set via parameter_defaults in the resource registry. type: json # We define mappings to work around names that break when doing the # CamelCase to snake_case conversion to align with service_names ServiceNetMapDeprecatedMapping: default: MongoDbNetwork: MongodbNetwork RabbitMqNetwork: RabbitmqNetwork description: Mapping older deprecated service names, intended for internal use only, this will be removed in future. type: json parameter_groups: - label: deprecated description: Do not use deprecated params, they will be removed. parameters: - ServiceNetMapDeprecatedMapping outputs: service_net_map: value: map_merge: - {get_param: ServiceNetMapDefaults} - map_replace: - {get_param: ServiceNetMap} - keys: {get_param: ServiceNetMapDeprecatedMapping} service_net_map_lower: value: # This does a conversion from CamelCase to snake_case, # e.g HeatApiNetwork becomes heat_api_network so it # matches the service names. yaql: expression: dict($.data.map.items().select([ regex(`([a-z0-9])([A-Z])`).replace($[0], '\\1_\\2').toLower(), $[1]])) data: map: map_merge: - {get_param: ServiceNetMapDefaults} - map_replace: - {get_param: ServiceNetMap} - keys: {get_param: ServiceNetMapDeprecatedMapping} ",,172,113
openstack%2Fmurano~master~If0e21c2a8c545c4a0419e0ec58e5d129318bb4c2,openstack/murano,master,If0e21c2a8c545c4a0419e0ec58e5d129318bb4c2,New framework for contracts,MERGED,2016-08-14 07:01:02.000000000,2016-08-29 20:01:04.000000000,2016-08-29 20:01:04.000000000,"[{'_account_id': 3}, {'_account_id': 7225}, {'_account_id': 7535}, {'_account_id': 7821}, {'_account_id': 15168}]","[{'number': 1, 'created': '2016-08-14 07:01:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/afc1ccd3da3ff789b710f922fd18f17b2b696e03', 'message': '[WiP] New framework for contracts\n\nChange-Id: If0e21c2a8c545c4a0419e0ec58e5d129318bb4c2\n'}, {'number': 2, 'created': '2016-08-15 00:16:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/3cc24bd3bcd11dac9a65d8c90ba814b860130936', 'message': '[WiP] New framework for contracts\n\nChange-Id: If0e21c2a8c545c4a0419e0ec58e5d129318bb4c2\n'}, {'number': 3, 'created': '2016-08-15 03:39:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/edbe50efe1d27f62eba4176dcd71ac2c2629095e', 'message': '[WiP] New framework for contracts\n\nChange-Id: If0e21c2a8c545c4a0419e0ec58e5d129318bb4c2\n'}, {'number': 4, 'created': '2016-08-15 20:07:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/787a08449e3628ab000ba382afdc7c2aa8789bf3', 'message': '[WiP] New framework for contracts\n\nChange-Id: If0e21c2a8c545c4a0419e0ec58e5d129318bb4c2\n'}, {'number': 5, 'created': '2016-08-16 20:57:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/e626f471f65c873a1ed4c827fca0274c87c9d4cd', 'message': '[WiP] New framework for contracts\n\nChange-Id: If0e21c2a8c545c4a0419e0ec58e5d129318bb4c2\n'}, {'number': 6, 'created': '2016-08-22 18:58:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/10a4e5dfdf29a8cbd2b0aee6f548b798092a5618', 'message': '[WiP] New framework for contracts\n\nChange-Id: If0e21c2a8c545c4a0419e0ec58e5d129318bb4c2\n'}, {'number': 7, 'created': '2016-08-22 20:07:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/648b6af89808c689eddbfa819183b150ce33eda9', 'message': 'New framework for contracts\n\nNew framework for MuranoPL contracts was written. Now instead of several\nindependent implementations of the same yaql methods (string(), class()\netc.) all implementations of the same method are combined into single\nclass so no we have class per contract method. This also simplifies\ndevelopment of new contracts. Each such class can provide methods for\ndata transformation (default contract usqage), validation that is used\nto decide if the method can be considered an extension method for the\nvalue, and json schema generation method that were moved from the schema\ngenerator script.\n\nPreviously for when the class used to override property from the parent\nclass assigned value were stored separately for both of them transformed\nby each of the contracts. Thus each class saw the value by its contract.\nIn absolute majority of the cases the observed value was the same. However\nif the contracts were compatible on the provided value (say int() and\nstring() contracts on the value ""123"") they were different. This is\nconsidered to be a bad pattern.\n\nNow the value is stored only once per object and transformed by the\ncontract defined in the actual object type. All base contracts are used\nto validate the transformed object thus the this pattern will not work\nanymore.\n\nThe value that is stored in the object\'s properties is obtained by\nexecuting special ""finalize"" contract implementation which usually\nreturns the input value unmodified. Because validation happens on\nthe transformed value before it gets finalized it is possible for\ntransformation to return a value that will pass the validation though\nthe final value won\'t. This is used to relax the template() contract\nlimitation that prevented child class to exclude additional properties\nfrom the template.\n\nstring() contracts is no longer converts to string anythin possible but\nonly the scalar values. Previous behavior caused string() property\naccept lists and convert them to their Python string representation which\nis clearly not what developers expected.\n\nDue to the refactoring contracts work a little bit faster because there is\nno more need to generate yaql function definition of each contract method\non each call.\n\nChange-Id: If0e21c2a8c545c4a0419e0ec58e5d129318bb4c2\n'}, {'number': 8, 'created': '2016-08-23 02:51:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/19f75f9559b44317d5393472e52f2100e272fb2b', 'message': 'New framework for contracts\n\nNew framework for MuranoPL contracts was written. Now instead of several\nindependent implementations of the same yaql methods (string(), class()\netc.) all implementations of the same method are combined into single\nclass so no we have class per contract method. This also simplifies\ndevelopment of new contracts. Each such class can provide methods for\ndata transformation (default contract usqage), validation that is used\nto decide if the method can be considered an extension method for the\nvalue, and json schema generation method that were moved from the schema\ngenerator script.\n\nPreviously for when the class used to override property from the parent\nclass assigned value were stored separately for both of them transformed\nby each of the contracts. Thus each class saw the value by its contract.\nIn absolute majority of the cases the observed value was the same. However\nif the contracts were compatible on the provided value (say int() and\nstring() contracts on the value ""123"") they were different. This is\nconsidered to be a bad pattern.\n\nNow the value is stored only once per object and transformed by the\ncontract defined in the actual object type. All base contracts are used\nto validate the transformed object thus the this pattern will not work\nanymore.\n\nThe value that is stored in the object\'s properties is obtained by\nexecuting special ""finalize"" contract implementation which usually\nreturns the input value unmodified. Because validation happens on\nthe transformed value before it gets finalized it is possible for\ntransformation to return a value that will pass the validation though\nthe final value won\'t. This is used to relax the template() contract\nlimitation that prevented child class to exclude additional properties\nfrom the template.\n\nstring() contracts is no longer converts to string anythin possible but\nonly the scalar values. Previous behavior caused string() property\naccept lists and convert them to their Python string representation which\nis clearly not what developers expected.\n\nDue to the refactoring contracts work a little bit faster because there is\nno more need to generate yaql function definition of each contract method\non each call.\n\nChange-Id: If0e21c2a8c545c4a0419e0ec58e5d129318bb4c2\n'}, {'number': 9, 'created': '2016-08-23 14:29:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/a6bc78a9ae7ca1361c68311c6bf29a40e68820a8', 'message': 'New framework for contracts\n\nNew framework for MuranoPL contracts was written. Now instead of several\nindependent implementations of the same yaql methods (string(), class()\netc.) all implementations of the same method are combined into single\nclass so no we have class per contract method. This also simplifies\ndevelopment of new contracts. Each such class can provide methods for\ndata transformation (default contract usqage), validation that is used\nto decide if the method can be considered an extension method for the\nvalue, and json schema generation method that were moved from the schema\ngenerator script.\n\nPreviously for when the class used to override property from the parent\nclass assigned value were stored separately for both of them transformed\nby each of the contracts. Thus each class saw the value by its contract.\nIn absolute majority of the cases the observed value was the same. However\nif the contracts were compatible on the provided value (say int() and\nstring() contracts on the value ""123"") they were different. This is\nconsidered to be a bad pattern.\n\nNow the value is stored only once per object and transformed by the\ncontract defined in the actual object type. All base contracts are used\nto validate the transformed object thus the this pattern will not work\nanymore.\n\nThe value that is stored in the object\'s properties is obtained by\nexecuting special ""finalize"" contract implementation which usually\nreturns the input value unmodified. Because validation happens on\nthe transformed value before it gets finalized it is possible for\ntransformation to return a value that will pass the validation though\nthe final value won\'t. This is used to relax the template() contract\nlimitation that prevented child class to exclude additional properties\nfrom the template.\n\nstring() contracts is no longer converts to string anythin possible but\nonly the scalar values. Previous behavior caused string() property\naccept lists and convert them to their Python string representation which\nis clearly not what developers expected.\n\nDue to the refactoring contracts work a little bit faster because there is\nno more need to generate yaql function definition of each contract method\non each call.\n\nChange-Id: If0e21c2a8c545c4a0419e0ec58e5d129318bb4c2\n'}, {'number': 10, 'created': '2016-08-28 21:20:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/0b3d089466969757e6df874151a1f4c4b787a2ae', 'message': 'New framework for contracts\n\nNew framework for MuranoPL contracts was written. Now instead of several\nindependent implementations of the same yaql methods (string(), class()\netc.) all implementations of the same method are combined into single\nclass so no we have class per contract method. This also simplifies\ndevelopment of new contracts. Each such class can provide methods for\ndata transformation (default contract usqage), validation that is used\nto decide if the method can be considered an extension method for the\nvalue, and json schema generation method that were moved from the schema\ngenerator script.\n\nPreviously for when the class used to override property from the parent\nclass assigned value were stored separately for both of them transformed\nby each of the contracts. Thus each class saw the value by its contract.\nIn absolute majority of the cases the observed value was the same. However\nif the contracts were compatible on the provided value (say int() and\nstring() contracts on the value ""123"") they were different. This is\nconsidered to be a bad pattern.\n\nNow the value is stored only once per object and transformed by the\ncontract defined in the actual object type. All base contracts are used\nto validate the transformed object thus the this pattern will not work\nanymore.\n\nThe value that is stored in the object\'s properties is obtained by\nexecuting special ""finalize"" contract implementation which usually\nreturns the input value unmodified. Because validation happens on\nthe transformed value before it gets finalized it is possible for\ntransformation to return a value that will pass the validation though\nthe final value won\'t. This is used to relax the template() contract\nlimitation that prevented child class to exclude additional properties\nfrom the template.\n\nstring() contracts is no longer converts to string anythin possible but\nonly the scalar values. Previous behavior caused string() property\naccept lists and convert them to their Python string representation which\nis clearly not what developers expected.\n\nDue to the refactoring contracts work a little bit faster because there is\nno more need to generate yaql function definition of each contract method\non each call.\n\nChange-Id: If0e21c2a8c545c4a0419e0ec58e5d129318bb4c2\n'}, {'number': 11, 'created': '2016-08-29 17:14:11.000000000', 'files': ['murano/dsl/typespec.py', 'murano/dsl/type_scheme.py', 'murano/tests/unit/dsl/meta/ParentClass1.yaml', 'murano/tests/unit/dsl/test_property_access.py', 'murano/dsl/contracts/basic.py', 'murano/tests/unit/dsl/meta/DerivedFrom2Classes.yaml', 'murano/dsl/contracts/contracts.py', 'murano/dsl/helpers.py', 'murano/tests/unit/dsl/meta/ParentClass2.yaml', 'murano/dsl/contracts/__init__.py', 'murano/dsl/dsl.py', 'releasenotes/notes/new-contract-framework-1dede2d16b2e9c71.yaml', 'murano/tests/unit/dsl/test_contracts.py', 'murano/dsl/murano_property.py', 'murano/dsl/yaql_integration.py', 'murano/tests/unit/dsl/meta/CommonParent.yaml', 'murano/dsl/murano_object.py', 'murano/dsl/contracts/instances.py', 'murano/dsl/serializer.py', 'murano/tests/unit/dsl/meta/ContractExamples.yaml', 'murano/dsl/contracts/check.py'], 'web_link': 'https://opendev.org/openstack/murano/commit/7e8fb5f570a60a8fedf9816722f756fb2d26dfcc', 'message': 'New framework for contracts\n\nNew framework for MuranoPL contracts was written. Now instead of several\nindependent implementations of the same yaql methods (string(), class()\netc.) all implementations of the same method are combined into single\nclass so no we have class per contract method. This also simplifies\ndevelopment of new contracts. Each such class can provide methods for\ndata transformation (default contract usqage), validation that is used\nto decide if the method can be considered an extension method for the\nvalue, and json schema generation method that were moved from the schema\ngenerator script.\n\nPreviously for when the class used to override property from the parent\nclass assigned value were stored separately for both of them transformed\nby each of the contracts. Thus each class saw the value by its contract.\nIn absolute majority of the cases the observed value was the same. However\nif the contracts were compatible on the provided value (say int() and\nstring() contracts on the value ""123"") they were different. This is\nconsidered to be a bad pattern.\n\nNow the value is stored only once per object and transformed by the\ncontract defined in the actual object type. All base contracts are used\nto validate the transformed object thus the this pattern will not work\nanymore.\n\nThe value that is stored in the object\'s properties is obtained by\nexecuting special ""finalize"" contract implementation which usually\nreturns the input value unmodified. Because validation happens on\nthe transformed value before it gets finalized it is possible for\ntransformation to return a value that will pass the validation though\nthe final value won\'t. This is used to relax the template() contract\nlimitation that prevented child class to exclude additional properties\nfrom the template.\n\nstring() contracts is no longer converts to string anythin possible but\nonly the scalar values. Previous behavior caused string() property\naccept lists and convert them to their Python string representation which\nis clearly not what developers expected.\n\nDue to the refactoring contracts work a little bit faster because there is\nno more need to generate yaql function definition of each contract method\non each call.\n\nChange-Id: If0e21c2a8c545c4a0419e0ec58e5d129318bb4c2\n'}]",0,355227,7e8fb5f570a60a8fedf9816722f756fb2d26dfcc,50,5,11,7226,,,0,"New framework for contracts

New framework for MuranoPL contracts was written. Now instead of several
independent implementations of the same yaql methods (string(), class()
etc.) all implementations of the same method are combined into single
class so no we have class per contract method. This also simplifies
development of new contracts. Each such class can provide methods for
data transformation (default contract usqage), validation that is used
to decide if the method can be considered an extension method for the
value, and json schema generation method that were moved from the schema
generator script.

Previously for when the class used to override property from the parent
class assigned value were stored separately for both of them transformed
by each of the contracts. Thus each class saw the value by its contract.
In absolute majority of the cases the observed value was the same. However
if the contracts were compatible on the provided value (say int() and
string() contracts on the value ""123"") they were different. This is
considered to be a bad pattern.

Now the value is stored only once per object and transformed by the
contract defined in the actual object type. All base contracts are used
to validate the transformed object thus the this pattern will not work
anymore.

The value that is stored in the object's properties is obtained by
executing special ""finalize"" contract implementation which usually
returns the input value unmodified. Because validation happens on
the transformed value before it gets finalized it is possible for
transformation to return a value that will pass the validation though
the final value won't. This is used to relax the template() contract
limitation that prevented child class to exclude additional properties
from the template.

string() contracts is no longer converts to string anythin possible but
only the scalar values. Previous behavior caused string() property
accept lists and convert them to their Python string representation which
is clearly not what developers expected.

Due to the refactoring contracts work a little bit faster because there is
no more need to generate yaql function definition of each contract method
on each call.

Change-Id: If0e21c2a8c545c4a0419e0ec58e5d129318bb4c2
",git fetch https://review.opendev.org/openstack/murano refs/changes/27/355227/11 && git format-patch -1 --stdout FETCH_HEAD,"['murano/dsl/murano_property.py', 'murano/dsl/typespec.py', 'murano/dsl/type_scheme.py', 'murano/dsl/contracts/basic.py', 'murano/dsl/contracts/contracts.py', 'murano/dsl/helpers.py', 'murano/dsl/contracts/__init__.py', 'murano/dsl/dsl.py', 'murano/dsl/contracts/check.py', 'murano/dsl/contracts/references.py']",10,afc1ccd3da3ff789b710f922fd18f17b2b696e03,356438,"# Copyright (c) 2016 Mirantis, Inc. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import six from yaql.language import specs from yaql.language import utils from yaql.language import yaqltypes from murano.dsl import contracts from murano.dsl import dsl from murano.dsl import dsl_types from murano.dsl import exceptions from murano.dsl import helpers class Class(contracts.ContractMethod): name = 'class' @specs.parameter('name', dsl.MuranoTypeParameter( nullable=False, lazy=True)) @specs.parameter('default_name', dsl.MuranoTypeParameter( nullable=True, lazy=True)) @specs.parameter('version_spec', yaqltypes.String(True)) def __init__(self, name, default_name=None, version_spec=None): self.type = name(self.context) self.default_type = default_name(self.context) or self.type self.version_spec = version_spec def validate(self): if helpers.is_instance_of( self.value, self.type.type.name, self.version_spec or helpers.get_names_scope( self.root_context)): return self.value raise exceptions.ContractViolationException() def transform(self): value = self.value object_store = helpers.get_object_store() murano_class = self.type.type if isinstance(self.value, contracts.ObjRef): value = self.value.object_id if value is None: return None if isinstance(value, dsl_types.MuranoObject): obj = value elif isinstance(value, dsl_types.MuranoObjectInterface): obj = value.object elif isinstance(value, utils.MappingType): obj = object_store.load( value, self.owner, context=self.root_context, default_type=self.default_type, scope_type=self.calling_type) elif isinstance(value, six.string_types): obj = object_store.get(value) if obj is None: if not object_store.initializing: raise exceptions.NoObjectFoundError(value) else: return contracts.ObjRef(value) else: raise exceptions.ContractViolationException( 'Value {0} cannot be represented as class {1}'.format( helpers.format_scalar(value), self.type)) if not helpers.is_instance_of( obj, murano_class.name, self.version_spec or helpers.get_type(self.root_context)): raise exceptions.ContractViolationException( 'Object of type {0} is not compatible with ' 'requested type {1}'.format(obj.type.name, self.type)) return obj class Owned(contracts.ContractMethod): name = 'owned' def validate(self): pass def transform(self): if self.value is None or isinstance(self.value, contracts.ObjRef): return self.value if isinstance(self.value, dsl_types.MuranoObject): p = self.value.owner while p is not None: if p is self.this: return self.validate() p = p.owner raise exceptions.ContractViolationException( 'Object {0} violates owned() contract'.format(self.value)) raise exceptions.ContractViolationException( 'Value {0} is not an object'.format(self.value)) class NotOwned(contracts.ContractMethod): name = 'not_owned' def validate(self): pass def transform(self): if self.value is None or isinstance(self.value, contracts.ObjRef): return self.value if isinstance(self.value, dsl_types.MuranoObject): p = self.value.owner while p is not None: if p is self.this: raise exceptions.ContractViolationException( 'Object {0} violates notOwned() contract'.format( self.value)) p = p.owner return self.value raise exceptions.ContractViolationException( 'Value {0} is not an object'.format(self.value)) ",,570,416
openstack%2Fmurano~master~I016d6932ee45e2eeee2147da6370be7f7b585267,openstack/murano,master,I016d6932ee45e2eeee2147da6370be7f7b585267,firstOrDefault() was replaced with first(null),MERGED,2016-08-26 15:25:26.000000000,2016-08-29 20:00:44.000000000,2016-08-29 20:00:44.000000000,"[{'_account_id': 3}, {'_account_id': 7225}, {'_account_id': 7535}, {'_account_id': 7821}, {'_account_id': 13149}, {'_account_id': 20364}, {'_account_id': 20563}]","[{'number': 1, 'created': '2016-08-26 15:25:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/8d02d1e53acaaa1fe38d3854053ea13d33fba4ea', 'message': 'firstOrDefault() was replaced with first(null)\n\nAfter the FormatVersion of core library was updated\nthere is no mo legacy firstOrDefault() method.\nInstead native yaql first(null) must be used\n\nChange-Id: I016d6932ee45e2eeee2147da6370be7f7b585267\n'}, {'number': 2, 'created': '2016-08-29 17:06:13.000000000', 'files': ['meta/io.murano/Classes/resources/Instance.yaml', 'meta/io.murano/Classes/resources/ExistingNeutronNetwork.yaml'], 'web_link': 'https://opendev.org/openstack/murano/commit/1f3b1be24e03ffb8f84e04b4968cabf82378d035', 'message': 'firstOrDefault() was replaced with first(null)\n\nAfter the FormatVersion of core library was updated\nthere is no mo legacy firstOrDefault() method.\nInstead native yaql first(null) must be used\n\nChange-Id: I016d6932ee45e2eeee2147da6370be7f7b585267\n'}]",0,361305,1f3b1be24e03ffb8f84e04b4968cabf82378d035,16,7,2,7226,,,0,"firstOrDefault() was replaced with first(null)

After the FormatVersion of core library was updated
there is no mo legacy firstOrDefault() method.
Instead native yaql first(null) must be used

Change-Id: I016d6932ee45e2eeee2147da6370be7f7b585267
",git fetch https://review.opendev.org/openstack/murano refs/changes/05/361305/2 && git format-patch -1 --stdout FETCH_HEAD,"['meta/io.murano/Classes/resources/Instance.yaml', 'meta/io.murano/Classes/resources/ExistingNeutronNetwork.yaml']",2,8d02d1e53acaaa1fe38d3854053ea13d33fba4ea,, $.get('router:external') = true and $.id in $networkCandidates).first(null) $.get('router:external') = true).select($.name).first(null), $.get('router:external') = true and $.id in $networkCandidates). firstOrDefault() $.get('router:external') = true).select($.name).firstOrDefault(),3,4
openstack%2Fneutron-vpnaas~master~Ibe1a057958f7c5b791788e2b44a1f13993a620bf,openstack/neutron-vpnaas,master,Ibe1a057958f7c5b791788e2b44a1f13993a620bf,Readd tox_install NEUTRON_DIR,MERGED,2016-08-29 16:43:27.000000000,2016-08-29 19:57:21.000000000,2016-08-29 19:57:20.000000000,"[{'_account_id': 3}, {'_account_id': 6659}, {'_account_id': 11682}]","[{'number': 1, 'created': '2016-08-29 16:43:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-vpnaas/commit/79358bb8e40fbf4d1d6b00cd1b8e1e32e29ad75d', 'message': ""Readd tox_install NEUTRON\n\nAs part of Id56b9b70fb9c4113f4641e5b3f35ab63cfff6d4e, the special\nhandling of NEUTRON_DIR was removed. Readd it since it's needed to\ninstall the proper version of neutron when testing neutron changes with\nneutron-fwaas's functional tests. Otherwise those tests install neutron\nHEAD.\n\nAdd a big comment to explain the reason for this.\n\nChange-Id: Ibe1a057958f7c5b791788e2b44a1f13993a620bf\n""}, {'number': 2, 'created': '2016-08-29 16:44:51.000000000', 'files': ['tools/tox_install.sh'], 'web_link': 'https://opendev.org/openstack/neutron-vpnaas/commit/0002c570a2cea65be40f5da821dfc9d2ab5724f6', 'message': ""Readd tox_install NEUTRON_DIR\n\nAs part of Id56b9b70fb9c4113f4641e5b3f35ab63cfff6d4e, the special\nhandling of NEUTRON_DIR was removed. Readd it since it's needed to\ninstall the proper version of neutron when testing neutron changes with\nneutron-fwaas's functional tests. Otherwise those tests install neutron\nHEAD.\n\nAdd a big comment to explain the reason for this.\n\nChange-Id: Ibe1a057958f7c5b791788e2b44a1f13993a620bf\n""}]",3,362274,0002c570a2cea65be40f5da821dfc9d2ab5724f6,14,3,2,6547,,,0,"Readd tox_install NEUTRON_DIR

As part of Id56b9b70fb9c4113f4641e5b3f35ab63cfff6d4e, the special
handling of NEUTRON_DIR was removed. Readd it since it's needed to
install the proper version of neutron when testing neutron changes with
neutron-fwaas's functional tests. Otherwise those tests install neutron
HEAD.

Add a big comment to explain the reason for this.

Change-Id: Ibe1a057958f7c5b791788e2b44a1f13993a620bf
",git fetch https://review.opendev.org/openstack/neutron-vpnaas refs/changes/74/362274/1 && git format-patch -1 --stdout FETCH_HEAD,['tools/tox_install.sh'],1,79358bb8e40fbf4d1d6b00cd1b8e1e32e29ad75d,NEUTRON_DIR,"NEUTRON_DIR=$HOME/neutron# The devstack based functional tests have neutron checked out in # $NEUTRON_DIR on the test systems - with the change to test in it. # Use this directory if it exists, so that this script installs the # neutron version to test here. # Note that the functional tests use sudo to run tox and thus # variables used for zuul-cloner to check out the correct version are # lost. if [ -d ""$NEUTRON_DIR"" ]; then echo ""FOUND Neutron code at $NEUTRON_DIR - using"" $install_cmd -U -e $NEUTRON_DIR elif [ $neutron_installed -eq 0 ]; then # since it is referenced after $install_cmd -e.",if [ $neutron_installed -eq 0 ]; then # since it is reference after $install_cmd -e.,13,2
openstack%2Fopenstack-manuals~master~I99bcaf014c210f2598c1809b52ea46967b025a74,openstack/openstack-manuals,master,I99bcaf014c210f2598c1809b52ea46967b025a74,New key manager config update,MERGED,2016-06-27 17:07:05.000000000,2016-08-29 19:48:15.000000000,2016-08-29 19:48:15.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 6547}, {'_account_id': 6802}, {'_account_id': 7012}, {'_account_id': 7764}, {'_account_id': 8623}, {'_account_id': 10607}, {'_account_id': 10897}, {'_account_id': 17130}, {'_account_id': 22165}]","[{'number': 1, 'created': '2016-06-27 17:07:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/d74e05f467a2b95f07410b2df6ff4ead539e1aa2', 'message': 'New key manager config update\n\nA configuration guide update for nova.conf and cinder.conf is needed\ndue to a new key manager interface. The interface is based on the\nCastellan key manager which provides a consistent front-end interface\nto support different back end key managers (Barbican is the default\nback-end.) The code patch for Nova is merged, and corresponding patch\nfor Cinder is in review.\n\nDepends-On: Ib563b0ea4b8b4bc1833bf52bf49a68546c384996\nDepends-On: Ief8885bb4ca8d62b03cf1a52c25dd0e62c835bfe\nCloses-Bug: # 1592026\n\nChange-Id: I99bcaf014c210f2598c1809b52ea46967b025a74\n'}, {'number': 2, 'created': '2016-06-28 11:02:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/479a16ef4cc98bbc86a7f760f34f9ac4f5603459', 'message': 'New key manager config update\n\nA configuration guide update for nova.conf and cinder.conf is needed\ndue to a new key manager interface. The interface is based on the\nCastellan key manager which provides a consistent front-end interface\nto support different back end key managers (Barbican is the default\nback-end.) The code patch for Nova is merged, and corresponding patch\nfor Cinder is in review.\n\nDepends-On: Ib563b0ea4b8b4bc1833bf52bf49a68546c384996\nDepends-On: Ief8885bb4ca8d62b03cf1a52c25dd0e62c835bfe\nCloses-Bug: #1592026\n\nChange-Id: I99bcaf014c210f2598c1809b52ea46967b025a74\n'}, {'number': 3, 'created': '2016-08-29 18:45:58.000000000', 'files': ['doc/config-reference/source/block-storage/volume-encryption.rst'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/8a2467162f32c900df4f2af7195315934a4f4084', 'message': 'New key manager config update\n\nA configuration guide update for nova.conf and cinder.conf is needed\ndue to a new key manager interface. The interface is based on the\nCastellan key manager which provides a consistent front-end interface\nto support different back end key managers (Barbican is the default\nback-end.) The code patch for Nova is merged, and corresponding patch\nfor Cinder is in review.\n\nDepends-On: Ib563b0ea4b8b4bc1833bf52bf49a68546c384996\nDepends-On: Ief8885bb4ca8d62b03cf1a52c25dd0e62c835bfe\nCloses-Bug: #1592026\n\nChange-Id: I99bcaf014c210f2598c1809b52ea46967b025a74\n'}]",1,334570,8a2467162f32c900df4f2af7195315934a4f4084,23,11,3,6804,,,0,"New key manager config update

A configuration guide update for nova.conf and cinder.conf is needed
due to a new key manager interface. The interface is based on the
Castellan key manager which provides a consistent front-end interface
to support different back end key managers (Barbican is the default
back-end.) The code patch for Nova is merged, and corresponding patch
for Cinder is in review.

Depends-On: Ib563b0ea4b8b4bc1833bf52bf49a68546c384996
Depends-On: Ief8885bb4ca8d62b03cf1a52c25dd0e62c835bfe
Closes-Bug: #1592026

Change-Id: I99bcaf014c210f2598c1809b52ea46967b025a74
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/70/334570/2 && git format-patch -1 --stdout FETCH_HEAD,['doc/config-reference/source/block-storage/volume-encryption.rst'],1,d74e05f467a2b95f07410b2df6ff4ead539e1aa2,bug/1592026, * Look for the ``[key_manager]`` section. * Enter a new line directly below ``[key_manager]`` with the following: api_class = cinder.key_manager.barbican.BarbicanKeyManager [key_manager] api_class = nova.key_manager.barbican.BarbicanKeyManager, * Look for the ``[keymgr]`` section. * Enter a new line directly below ``[keymgr]`` with the following: api_class = cinder.keymgr.barbican.BarbicanKeyManager [keymgr] api_class = nova.keymgr.barbican.BarbicanKeyManager,5,5
openstack%2Fpuppet-keystone~master~I2680602a3c41aed8c0630d1003e759bec8e876cd,openstack/puppet-keystone,master,I2680602a3c41aed8c0630d1003e759bec8e876cd,CI test - never merge,ABANDONED,2016-08-29 17:37:00.000000000,2016-08-29 19:48:06.000000000,,[{'_account_id': 8971}],"[{'number': 1, 'created': '2016-08-29 17:37:00.000000000', 'files': ['test'], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/c4d4031c3daa51578ac65466b2eabe2703bcf27f', 'message': 'CI test - never merge\n\nChange-Id: I2680602a3c41aed8c0630d1003e759bec8e876cd\n'}]",0,362296,c4d4031c3daa51578ac65466b2eabe2703bcf27f,3,1,1,3153,,,0,"CI test - never merge

Change-Id: I2680602a3c41aed8c0630d1003e759bec8e876cd
",git fetch https://review.opendev.org/openstack/puppet-keystone refs/changes/96/362296/1 && git format-patch -1 --stdout FETCH_HEAD,['test'],1,c4d4031c3daa51578ac65466b2eabe2703bcf27f,ci-test,test ,,1,0
openstack%2Ftripleo-docs~master~I8679b904fa90abb0b9a6fafd2cb1b8392831f4d2,openstack/tripleo-docs,master,I8679b904fa90abb0b9a6fafd2cb1b8392831f4d2,Deploy and Scale Swift,MERGED,2016-03-16 08:34:24.000000000,2016-08-29 19:48:04.000000000,2016-08-29 19:48:04.000000000,"[{'_account_id': 3}, {'_account_id': 597}, {'_account_id': 3153}, {'_account_id': 6968}, {'_account_id': 7144}, {'_account_id': 9625}, {'_account_id': 9712}]","[{'number': 1, 'created': '2016-03-16 08:34:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-docs/commit/c3dabd4dfa055b0688eb1949121391e2d0357277', 'message': 'Deploy and Scale Swift\n\nChange-Id: I8679b904fa90abb0b9a6fafd2cb1b8392831f4d2\nDepends-On: I081393d59726c9378cc557ab923d4c40ff4d7cbb\n'}, {'number': 2, 'created': '2016-03-17 11:51:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-docs/commit/e0d8ba4f52df430b5686dbfeca9b37cb078df1a2', 'message': 'Deploy and Scale Swift\n\nChange-Id: I8679b904fa90abb0b9a6fafd2cb1b8392831f4d2\nDepends-On: I081393d59726c9378cc557ab923d4c40ff4d7cbb\n'}, {'number': 3, 'created': '2016-03-17 15:15:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-docs/commit/fc5907291b0e87db9e936e4ddbc1f3fdd70add02', 'message': 'Deploy and Scale Swift\n\nChange-Id: I8679b904fa90abb0b9a6fafd2cb1b8392831f4d2\nDepends-On: I081393d59726c9378cc557ab923d4c40ff4d7cbb\n'}, {'number': 4, 'created': '2016-03-17 15:57:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-docs/commit/e0bafcfb2e72ce7a186b9ec804d670ad403e724a', 'message': 'Deploy and Scale Swift\n\nChange-Id: I8679b904fa90abb0b9a6fafd2cb1b8392831f4d2\nDepends-On: I081393d59726c9378cc557ab923d4c40ff4d7cbb\n'}, {'number': 5, 'created': '2016-03-21 17:14:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-docs/commit/37bd6be4c8b0c12988c78b57da269625abb592cf', 'message': 'Deploy and Scale Swift\n\nDepends-On: I56978b15823dd6eaf4b6fd3440df2f895e89611a\nChange-Id: I8679b904fa90abb0b9a6fafd2cb1b8392831f4d2\n'}, {'number': 6, 'created': '2016-05-16 10:44:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-docs/commit/f6e797cdb9dd29e180a1f2b8f86664f8129ca372', 'message': 'Deploy and Scale Swift\n\nDepends-On: I56978b15823dd6eaf4b6fd3440df2f895e89611a\nChange-Id: I8679b904fa90abb0b9a6fafd2cb1b8392831f4d2\n'}, {'number': 7, 'created': '2016-08-02 07:13:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-docs/commit/069f3a753a9bc43321ea0ae00732f4484479343e', 'message': 'Deploy and Scale Swift\n\nDepends-On: I56978b15823dd6eaf4b6fd3440df2f895e89611a\nChange-Id: I8679b904fa90abb0b9a6fafd2cb1b8392831f4d2\n'}, {'number': 8, 'created': '2016-08-25 07:51:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-docs/commit/7fc148bb2293f64dbb01a027e1c40c202520b88b', 'message': 'Deploy and Scale Swift\n\nDepends-On: I56978b15823dd6eaf4b6fd3440df2f895e89611a\nChange-Id: I8679b904fa90abb0b9a6fafd2cb1b8392831f4d2\n'}, {'number': 9, 'created': '2016-08-26 08:42:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-docs/commit/7744ec75a2acd24c775660f5af032b6b2210e20f', 'message': 'Deploy and Scale Swift\n\nDepends-On: I56978b15823dd6eaf4b6fd3440df2f895e89611a\nChange-Id: I8679b904fa90abb0b9a6fafd2cb1b8392831f4d2\n'}, {'number': 10, 'created': '2016-08-26 09:58:22.000000000', 'files': ['doc/source/advanced_deployment/custom.rst', 'doc/source/advanced_deployment/deploy_swift.rst'], 'web_link': 'https://opendev.org/openstack/tripleo-docs/commit/891139ca8334ff8b63576a343ea95be5c4c187f3', 'message': 'Deploy and Scale Swift\n\nCo-Authored-By: Christian Schwede <cschwede@redhat.com>\nDepends-On: I56978b15823dd6eaf4b6fd3440df2f895e89611a\nChange-Id: I8679b904fa90abb0b9a6fafd2cb1b8392831f4d2\n'}]",25,293311,891139ca8334ff8b63576a343ea95be5c4c187f3,44,7,10,9712,,,0,"Deploy and Scale Swift

Co-Authored-By: Christian Schwede <cschwede@redhat.com>
Depends-On: I56978b15823dd6eaf4b6fd3440df2f895e89611a
Change-Id: I8679b904fa90abb0b9a6fafd2cb1b8392831f4d2
",git fetch https://review.opendev.org/openstack/tripleo-docs refs/changes/11/293311/9 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/advanced_deployment/advanced_deployment.rst', 'doc/source/advanced_deployment/deploy_swift.rst']",2,c3dabd4dfa055b0688eb1949121391e2d0357277,291711,"Deploy and Scale Swift in the Overcloud ======================================= This guide assumes that you are ready to deploy a new overcloud. To ensure that Swift nodes are all using the same Ring, some manual steps are required. Initial Deploy -------------- To correctly deploy Swift, we need to manually manage the Swift Rings. This can be achieved by disabling the Ring building process in TripleO by setting the ``SwiftRingBuild`` and ``RingBuild`` parameters both to ``false``. For example:: parameter_defaults: SwiftRingBuild: false RingBuild: false .. note:: If this is saved in a file named ``deploy-parameters.yaml`` then it can be deployed with ``openstack overcloud deploy --templates -e deploy- parameters.yaml``. After the deploy is completed, you will need to ssh onto the overcloud node as the ``heat-admin`` user. The IP addresses is available in the output of ``openstack server list``. Once connected, in the ``/etc/swift/`` directory follow the instructions in the `Swift documentation <http://docs.openstack.org/liberty/install-guide-rdo/swift-initial- rings.html>`_ to create the Ring. After this is completed you will need to copy the ``/etc/swift/*.ring.gz`` and ``/etc/swift/*.builder`` files from the controller. These will be used when we add additional swift nodes. You should have six files:: /etc/swift/account.builder /etc/swift/account.ring.gz /etc/swift/container.builder /etc/swift/container.ring.gz /etc/swift/object.builder /etc/swift/object.ring.gz Scaling Swift ------------- TripleO doesn't currently automatically update and scale Swift Rings. This needs to be done manually, with similar steps to the above initial deployment. First we need to define how many dedicated Swift nodes we want to deploy with the ``ObjectStorageCount`` parameter. In this example we are adding two Swift nodes:: parameter_defaults: SwiftRingBuild: false RingBuild: false ObjectStorageCount: 2 After we have deployed again with this new environment we will have two swift nodes that need to be added to the Ring we created during the initial deployment. The six files we copied from the Controller node need to be added to each of the new swift nodes. Viewing the Ring ---------------- The swift ring can be viewed on each node with the ``swift-ring-builder`` command. It's output will display all the nodes like this:: $ swift-ring-builder /etc/swift/object.builder /etc/swift/object.builder, build version 4 1024 partitions, 3.000000 replicas, 1 regions, 1 zones, 3 devices, 0.00 balance, 0.00 dispersion The minimum number of hours before a partition can be reassigned is 1 The overload factor is 0.00% (0.000000) Devices: id region zone ip address port replication ip replication port name weight partitions balance meta 0 1 1 192.0.2.22 6000 192.0.2.22 6000 d1 100.00 1024 0.00 1 1 1 192.0.2.24 6000 192.0.2.24 6000 d1 100.00 1024 0.00 2 1 1 192.0.2.6 6000 192.0.2.6 6000 d1 100.00 1024 0.00 Ring configuration be verified by checking the hash of the ``*.ring.gz`` files. It should be the same on all nodes in the ring.:: $ sha1sum /etc/swift/*.ring.gz d41c1b4f93a98a693a6ede074a1b78585af2dc89 /etc/swift/account.ring.gz 1d10d8cb826308a058c7089fdedfeca122426da9 /etc/swift/container.ring.gz f26639938660ee0111e4e7bc1b45f28a0b9f6079 /etc/swift/object.ring.gz ",,87,0
openstack%2Fpython-swiftclient~master~I04a8d2d6fa92ff2c4ebe595de4882eeeadc49d80,openstack/python-swiftclient,master,I04a8d2d6fa92ff2c4ebe595de4882eeeadc49d80,Closes-Bug: 1586690 Content length is not returned for 0B files added statement to check that,NEW,2016-05-29 07:37:05.000000000,2016-08-29 19:44:32.000000000,,"[{'_account_id': 3}, {'_account_id': 10068}, {'_account_id': 12279}, {'_account_id': 15343}]","[{'number': 1, 'created': '2016-05-29 07:37:05.000000000', 'files': ['swiftclient/service.py'], 'web_link': 'https://opendev.org/openstack/python-swiftclient/commit/a710a7920a99b47e5bc09ca2f12b318c65022f80', 'message': 'Closes-Bug: 1586690 Content length is not returned for 0B files added statement to check that\n\nChange-Id: I04a8d2d6fa92ff2c4ebe595de4882eeeadc49d80\n'}]",1,322471,a710a7920a99b47e5bc09ca2f12b318c65022f80,5,4,1,21900,,,0,"Closes-Bug: 1586690 Content length is not returned for 0B files added statement to check that

Change-Id: I04a8d2d6fa92ff2c4ebe595de4882eeeadc49d80
",git fetch https://review.opendev.org/openstack/python-swiftclient refs/changes/71/322471/1 && git format-patch -1 --stdout FETCH_HEAD,['swiftclient/service.py'],1,a710a7920a99b47e5bc09ca2f12b318c65022f80,bug/1586690, if headers.get('content-length'): cl = int(headers.get('content-length')) else: cl = 0 , cl = int(headers.get('content-length')),5,1
openstack%2Fyaql~master~Ib55b04c7c0a5b2afcd7db118e0291c9aa4e46858,openstack/yaql,master,Ib55b04c7c0a5b2afcd7db118e0291c9aa4e46858,Replace ValueError with StopIteration in single() method,MERGED,2016-08-29 08:01:05.000000000,2016-08-29 19:40:36.000000000,2016-08-29 19:40:36.000000000,"[{'_account_id': 3}, {'_account_id': 7225}, {'_account_id': 7226}]","[{'number': 1, 'created': '2016-08-29 08:01:05.000000000', 'files': ['yaql/standard_library/queries.py', 'yaql/tests/test_queries.py'], 'web_link': 'https://opendev.org/openstack/yaql/commit/4e822b0aaa82cae5efa120546cf0cd4c54775311', 'message': 'Replace ValueError with StopIteration in single() method\n\nThe thrown error for single() method in case of collection to\nhave more than one element should be StopIteration unlike ValueError,\nfor consistency with other code.\n\nChange-Id: Ib55b04c7c0a5b2afcd7db118e0291c9aa4e46858\n'}]",0,361924,4e822b0aaa82cae5efa120546cf0cd4c54775311,7,3,1,20563,,,0,"Replace ValueError with StopIteration in single() method

The thrown error for single() method in case of collection to
have more than one element should be StopIteration unlike ValueError,
for consistency with other code.

Change-Id: Ib55b04c7c0a5b2afcd7db118e0291c9aa4e46858
",git fetch https://review.opendev.org/openstack/yaql refs/changes/24/361924/1 && git format-patch -1 --stdout FETCH_HEAD,"['yaql/standard_library/queries.py', 'yaql/tests/test_queries.py']",2,4e822b0aaa82cae5efa120546cf0cd4c54775311,single_method," self.assertRaises(StopIteration, self.eval, 'list(1, 2).single()')"," self.assertRaises(ValueError, self.eval, 'list(1, 2).single()')",2,2
openstack%2Fmagnum~master~If6b0eed553e03562a82a90946cc3e849b5d69294,openstack/magnum,master,If6b0eed553e03562a82a90946cc3e849b5d69294,Updated from global requirements,MERGED,2016-08-23 22:17:42.000000000,2016-08-29 19:37:28.000000000,2016-08-29 19:37:28.000000000,"[{'_account_id': 3}, {'_account_id': 668}, {'_account_id': 11536}, {'_account_id': 12385}]","[{'number': 1, 'created': '2016-08-23 22:17:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/061e3801a31ad664e14396442342eb52ed89de20', 'message': 'Updated from global requirements\n\nChange-Id: If6b0eed553e03562a82a90946cc3e849b5d69294\n'}, {'number': 2, 'created': '2016-08-24 01:33:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/0893f3544f152c6259dbad2554246bbc2a5f65ff', 'message': 'Updated from global requirements\n\nChange-Id: If6b0eed553e03562a82a90946cc3e849b5d69294\n'}, {'number': 3, 'created': '2016-08-25 01:06:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/d193ade05de16dd21d1e2afd55ebfbb5c17a7769', 'message': 'Updated from global requirements\n\nChange-Id: If6b0eed553e03562a82a90946cc3e849b5d69294\n'}, {'number': 4, 'created': '2016-08-25 04:59:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/808af84e9b77461d90ec6a207903f05524e1b8ef', 'message': 'Updated from global requirements\n\nChange-Id: If6b0eed553e03562a82a90946cc3e849b5d69294\n'}, {'number': 5, 'created': '2016-08-26 05:08:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/b315269aa8321d0776390294f6d6f59ca0b17a10', 'message': 'Updated from global requirements\n\nChange-Id: If6b0eed553e03562a82a90946cc3e849b5d69294\n'}, {'number': 6, 'created': '2016-08-26 22:07:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/7515128398a3c92a4a46a0c8a62a49e5755b197f', 'message': 'Updated from global requirements\n\nChange-Id: If6b0eed553e03562a82a90946cc3e849b5d69294\n'}, {'number': 7, 'created': '2016-08-29 06:01:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/c8f0efcae23d589129284ba4487376ccfb6ff00e', 'message': 'Updated from global requirements\n\nChange-Id: If6b0eed553e03562a82a90946cc3e849b5d69294\n'}, {'number': 8, 'created': '2016-08-29 06:11:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/2e5f094b5a71e6afc56bdee29ee28035f7aef527', 'message': 'Updated from global requirements\n\nChange-Id: If6b0eed553e03562a82a90946cc3e849b5d69294\n'}, {'number': 9, 'created': '2016-08-29 06:33:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/83fcb2612b9bfa5a81c70e66a447b0602a95927c', 'message': 'Updated from global requirements\n\nChange-Id: If6b0eed553e03562a82a90946cc3e849b5d69294\n'}, {'number': 10, 'created': '2016-08-29 16:48:43.000000000', 'files': ['requirements.txt', 'test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/magnum/commit/77c4f5057a5b62f14780a9265e168f9b298a96eb', 'message': 'Updated from global requirements\n\nChange-Id: If6b0eed553e03562a82a90946cc3e849b5d69294\n'}]",0,359460,77c4f5057a5b62f14780a9265e168f9b298a96eb,24,4,10,11131,,,0,"Updated from global requirements

Change-Id: If6b0eed553e03562a82a90946cc3e849b5d69294
",git fetch https://review.opendev.org/openstack/magnum refs/changes/60/359460/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,061e3801a31ad664e14396442342eb52ed89de20,openstack/requirements,"pecan!=1.0.2,!=1.0.3,!=1.0.4,>=1.0.0 # BSD",pecan>=1.0.0 # BSD,1,1
openstack%2Fcinder~master~I97ad90756674851a4940015443394e7c99c3d9cb,openstack/cinder,master,I97ad90756674851a4940015443394e7c99c3d9cb,Volume Manage/Unmanage Support for IBM FlashSystem,MERGED,2016-08-11 06:45:51.000000000,2016-08-29 19:35:30.000000000,2016-08-28 21:44:05.000000000,"[{'_account_id': 3}, {'_account_id': 6491}, {'_account_id': 7198}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9732}, {'_account_id': 10058}, {'_account_id': 10621}, {'_account_id': 10622}, {'_account_id': 11904}, {'_account_id': 12016}, {'_account_id': 12033}, {'_account_id': 12369}, {'_account_id': 12514}, {'_account_id': 12516}, {'_account_id': 12778}, {'_account_id': 12822}, {'_account_id': 13394}, {'_account_id': 13628}, {'_account_id': 14384}, {'_account_id': 14797}, {'_account_id': 14865}, {'_account_id': 15249}, {'_account_id': 15296}, {'_account_id': 15374}, {'_account_id': 15386}, {'_account_id': 15831}, {'_account_id': 16269}, {'_account_id': 16422}, {'_account_id': 16660}, {'_account_id': 16862}, {'_account_id': 16880}, {'_account_id': 16883}, {'_account_id': 16897}, {'_account_id': 16898}, {'_account_id': 17382}, {'_account_id': 18026}, {'_account_id': 18444}, {'_account_id': 18752}, {'_account_id': 19146}, {'_account_id': 19852}, {'_account_id': 19933}, {'_account_id': 21144}, {'_account_id': 21193}, {'_account_id': 21428}, {'_account_id': 21863}, {'_account_id': 21976}, {'_account_id': 22126}, {'_account_id': 22248}, {'_account_id': 22510}]","[{'number': 1, 'created': '2016-08-11 06:45:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/e10491c90598a51880ce06d797d496f98a57fb54', 'message': 'Volume Manage/Unmanage Support for IBM FlashSystem\n\nThis patch introduce volume manage/unmanage feature for IBM FlashSystem.\n\nIn this patch,\n* Add volume manage/unmanage feature for IBM FlashSystem driver.\n* Bump version to 1.0.12.\n\nChange-Id: I97ad90756674851a4940015443394e7c99c3d9cb\nImplements: blueprint ibm-flashsystem-manage-unmanage\n'}, {'number': 2, 'created': '2016-08-12 05:59:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/987b5e4c0428a738212cf3860ec49bef45b91424', 'message': 'Volume Manage/Unmanage Support for IBM FlashSystem\n\nThis patch introduce volume manage/unmanage feature for IBM FlashSystem.\n\nIn this patch,\n* Add volume manage/unmanage feature for IBM FlashSystem driver.\n* Bump version to 1.0.12.\n\nDocImpact\nChange-Id: I97ad90756674851a4940015443394e7c99c3d9cb\nImplements: blueprint ibm-flashsystem-manage-unmanage\n'}, {'number': 3, 'created': '2016-08-17 09:09:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/f6ab78f211d327399ce09f20a7fe3e8efcb2fd58', 'message': 'Volume Manage/Unmanage Support for IBM FlashSystem\n\nThis patch introduce volume manage/unmanage feature for IBM FlashSystem.\n\nIn this patch,\n* Add volume manage/unmanage feature for IBM FlashSystem driver.\n* Bump version to 1.0.12.\n\nDocImpact\nChange-Id: I97ad90756674851a4940015443394e7c99c3d9cb\nImplements: blueprint ibm-flashsystem-manage-unmanage\n'}, {'number': 4, 'created': '2016-08-17 14:01:58.000000000', 'files': ['cinder/volume/drivers/ibm/flashsystem_common.py', 'cinder/tests/unit/volume/drivers/ibm/test_ibm_flashsystem.py', 'cinder/volume/drivers/ibm/flashsystem_iscsi.py', 'cinder/volume/drivers/ibm/flashsystem_fc.py', 'releasenotes/notes/ibm-flashsystem-manage-unmanage-88e56837102f838c.yaml', 'cinder/tests/unit/volume/drivers/ibm/test_ibm_flashsystem_iscsi.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/5242d1f09f2b50b9ced65b72f7aa157ed73a53d8', 'message': 'Volume Manage/Unmanage Support for IBM FlashSystem\n\nThis patch introduce volume manage/unmanage feature for IBM FlashSystem.\n\nIn this patch,\n* Add volume manage/unmanage feature for IBM FlashSystem driver.\n* Bump version to 1.0.12.\n\nDocImpact\nChange-Id: I97ad90756674851a4940015443394e7c99c3d9cb\nImplements: blueprint ibm-flashsystem-manage-unmanage\n'}]",21,353856,5242d1f09f2b50b9ced65b72f7aa157ed73a53d8,116,50,4,12514,,,0,"Volume Manage/Unmanage Support for IBM FlashSystem

This patch introduce volume manage/unmanage feature for IBM FlashSystem.

In this patch,
* Add volume manage/unmanage feature for IBM FlashSystem driver.
* Bump version to 1.0.12.

DocImpact
Change-Id: I97ad90756674851a4940015443394e7c99c3d9cb
Implements: blueprint ibm-flashsystem-manage-unmanage
",git fetch https://review.opendev.org/openstack/cinder refs/changes/56/353856/4 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/volume/drivers/ibm/flashsystem_common.py', 'cinder/tests/unit/volume/drivers/ibm/test_ibm_flashsystem.py', 'cinder/volume/drivers/ibm/flashsystem_iscsi.py', 'cinder/volume/drivers/ibm/flashsystem_fc.py', 'cinder/tests/unit/volume/drivers/ibm/test_ibm_flashsystem_iscsi.py']",5,e10491c90598a51880ce06d797d496f98a57fb54,bp/ibm-flashsystem-manage-unmanage," def test_flashsystem_manage_existing(self): # case 1: manage a vdisk good path kwargs = {'name': u'unmanage-vol-01', 'size': u'1', 'unit': 'gb'} self.sim._cmd_mkvdisk(**kwargs) vol1 = self._generate_vol_info(None) existing_ref = {'source-name': u'unmanage-vol-01'} self.driver.manage_existing(vol1, existing_ref) self.driver.delete_volume(vol1) # case 2: manage a vdisk not exist vol1 = self._generate_vol_info(None) existing_ref = {'source-name': u'unmanage-vol-01'} self.assertRaises(exception.ManageExistingInvalidReference, self.driver.manage_existing, vol1, existing_ref) # case 3: manage a vdisk without name and uid kwargs = {'name': u'unmanage-vol-01', 'size': u'1', 'unit': 'gb'} self.sim._cmd_mkvdisk(**kwargs) vol1 = self._generate_vol_info(None) existing_ref = {} self.assertRaises(exception.ManageExistingInvalidReference, self.driver.manage_existing, vol1, existing_ref) vdisk1 = {'obj': u'unmanage-vol-01'} self.sim._cmd_rmvdisk(**vdisk1) @mock.patch.object(flashsystem_iscsi.FlashSystemISCSIDriver, '_get_vdiskhost_mappings') def test_flashsystem_manage_existing_get_size_mapped( self, _get_vdiskhost_mappings_mock): # case 2: manage a vdisk with mappings _get_vdiskhost_mappings_mock.return_value = {'mapped': u'yes'} kwargs = {'name': u'unmanage-vol-01', 'size': u'1', 'unit': 'gb'} self.sim._cmd_mkvdisk(**kwargs) vol1 = self._generate_vol_info(None) existing_ref = {'source-name': u'unmanage-vol-01'} self.assertRaises(exception.ManageExistingInvalidReference, self.driver.manage_existing_get_size, vol1, existing_ref) # clean environment vdisk1 = {'obj': u'unmanage-vol-01'} self.sim._cmd_rmvdisk(**vdisk1) def test_flashsystem_manage_existing_get_size(self): # case 1: bad existing_ref vol1 = self._generate_vol_info(None, None) existing_ref = {} self.assertRaises(exception.ManageExistingInvalidReference, self.driver.manage_existing_get_size, vol1, existing_ref) # case 2: vdisk not exist vol1 = self._generate_vol_info(None) existing_ref = {'source-name': u'unmanage-vol-01'} self.assertRaises(exception.ManageExistingInvalidReference, self.driver.manage_existing_get_size, vol1, existing_ref) # case 3: good path kwargs = {'name': u'unmanage-vol-01', 'size': u'10001', 'unit': 'gb'} self.sim._cmd_mkvdisk(**kwargs) vol1 = self._generate_vol_info(None) existing_ref = {'source-name': u'unmanage-vol-01'} vdisk_size = self.driver.manage_existing_get_size(vol1, existing_ref) self.assertEqual(10001, vdisk_size) self.driver.delete_volume(vol1)",,242,5
openstack%2Ftosca-parser~master~I62f3d58ffd7390d76c3c67cb7ddd0f09db7b5875,openstack/tosca-parser,master,I62f3d58ffd7390d76c3c67cb7ddd0f09db7b5875,Remove openstack common file,MERGED,2016-08-29 14:15:48.000000000,2016-08-29 19:35:19.000000000,2016-08-29 19:35:19.000000000,"[{'_account_id': 3}, {'_account_id': 6456}]","[{'number': 1, 'created': '2016-08-29 14:15:48.000000000', 'files': ['openstack-common.conf'], 'web_link': 'https://opendev.org/openstack/tosca-parser/commit/e748990b0f8a017e04a39965398f6e0dfda14531', 'message': ""Remove openstack common file\n\nThe file is empty and shouldn't be kept around. Major projects like nova,\nkeystone aslo doesn't have this file.\n\nChange-Id: I62f3d58ffd7390d76c3c67cb7ddd0f09db7b5875\n""}]",0,362146,e748990b0f8a017e04a39965398f6e0dfda14531,6,2,1,6456,,,0,"Remove openstack common file

The file is empty and shouldn't be kept around. Major projects like nova,
keystone aslo doesn't have this file.

Change-Id: I62f3d58ffd7390d76c3c67cb7ddd0f09db7b5875
",git fetch https://review.opendev.org/openstack/tosca-parser refs/changes/46/362146/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack-common.conf'],1,e748990b0f8a017e04a39965398f6e0dfda14531,,, ,0,1
openstack%2Fkolla~master~I8b5046a438c0ef3599a4333bbe77333f0af323ff,openstack/kolla,master,I8b5046a438c0ef3599a4333bbe77333f0af323ff,Fix removing nova_libvirt container issue,MERGED,2016-08-28 12:36:18.000000000,2016-08-29 19:30:35.000000000,2016-08-29 19:30:35.000000000,"[{'_account_id': 3}, {'_account_id': 2834}, {'_account_id': 7488}, {'_account_id': 10787}]","[{'number': 1, 'created': '2016-08-28 12:36:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/fabc0c667502d5a9bb5b756bdd268b406587a4eb', 'message': 'Fix removing nova_libvirt container issue\n\nRetry once when removing or upgrading nova_libvirt to ensure it is\nremoved\n\nSigned-off-by: Jeffrey Zhang <jeffrey.zhang@99cloud.net>\nCloses-Bug: #1617741\nChange-Id: I8b5046a438c0ef3599a4333bbe77333f0af323ff\n'}, {'number': 2, 'created': '2016-08-28 12:46:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/2044e59d816817a3a7a11c7f88bd5aa92201e5e9', 'message': 'Fix removing nova_libvirt container issue\n\nRetry once when removing or upgrading nova_libvirt to ensure it is\nremoved\n\nCloses-Bug: #1617741\nChange-Id: I8b5046a438c0ef3599a4333bbe77333f0af323ff\nSigned-off-by: Jeffrey Zhang <zhang.lei.fly@gmail.com>\n'}, {'number': 3, 'created': '2016-08-29 07:39:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/936c006a5b5df00fdc438b3380829eedd42e811a', 'message': 'Fix removing nova_libvirt container issue\n\nRetry once when removing or upgrading nova_libvirt to ensure it is\nremoved\n\nCloses-Bug: #1617741\nChange-Id: I8b5046a438c0ef3599a4333bbe77333f0af323ff\nSigned-off-by: Jeffrey Zhang <zhang.lei.fly@gmail.com>\n'}, {'number': 4, 'created': '2016-08-29 08:37:58.000000000', 'files': ['ansible/roles/nova/tasks/start_compute.yml', 'ansible/roles/nova/tasks/do_reconfigure.yml'], 'web_link': 'https://opendev.org/openstack/kolla/commit/9092f4a10495af9f2def15518e81d4ae5ea5f102', 'message': 'Fix removing nova_libvirt container issue\n\nRetry once when removing or upgrading nova_libvirt to ensure it is\nremoved\n\nCloses-Bug: #1617741\nChange-Id: I8b5046a438c0ef3599a4333bbe77333f0af323ff\nSigned-off-by: Jeffrey Zhang <zhang.lei.fly@gmail.com>\n'}]",0,361728,9092f4a10495af9f2def15518e81d4ae5ea5f102,17,4,4,7488,,,0,"Fix removing nova_libvirt container issue

Retry once when removing or upgrading nova_libvirt to ensure it is
removed

Closes-Bug: #1617741
Change-Id: I8b5046a438c0ef3599a4333bbe77333f0af323ff
Signed-off-by: Jeffrey Zhang <zhang.lei.fly@gmail.com>
",git fetch https://review.opendev.org/openstack/kolla refs/changes/28/361728/3 && git format-patch -1 --stdout FETCH_HEAD,"['ansible/roles/nova/tasks/start_compute.yml', 'ansible/roles/nova/tasks/do_reconfigure.yml']",2,fabc0c667502d5a9bb5b756bdd268b406587a4eb,bug/1617741," until: remote_container|success retries: ""{{ item[0]['retries']|default('0') }}"" # NOTE(Jeffrey4l): retry 1 to remove nova_libvirt container because when # guests running, nova_libvirt will raise error even though it is removed. - [{ name: nova_libvirt, group: compute, retries: 1 },"," - [{ name: nova_libvirt, group: compute },",10,1
openstack%2Fopenstack-ansible-tests~master~Ied18863d194e610d9cd96f74749f70b83f361a1e,openstack/openstack-ansible-tests,master,Ied18863d194e610d9cd96f74749f70b83f361a1e,Removed yum cache update,MERGED,2016-08-29 19:09:58.000000000,2016-08-29 19:26:19.000000000,2016-08-29 19:26:19.000000000,"[{'_account_id': 3}, {'_account_id': 12807}, {'_account_id': 14805}]","[{'number': 1, 'created': '2016-08-29 19:09:58.000000000', 'files': ['common-tasks/test-force-package-cache-update.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-tests/commit/5958fae42845bee92e108a2ac345e25810f60686', 'message': 'Removed yum cache update\n\nThis command is not needed and is buggy.\n\nChange-Id: Ied18863d194e610d9cd96f74749f70b83f361a1e\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}]",0,362329,5958fae42845bee92e108a2ac345e25810f60686,10,3,1,7353,,,0,"Removed yum cache update

This command is not needed and is buggy.

Change-Id: Ied18863d194e610d9cd96f74749f70b83f361a1e
Signed-off-by: Kevin Carter <kevin.carter@rackspace.com>
",git fetch https://review.opendev.org/openstack/openstack-ansible-tests refs/changes/29/362329/1 && git format-patch -1 --stdout FETCH_HEAD,['common-tasks/test-force-package-cache-update.yml'],1,5958fae42845bee92e108a2ac345e25810f60686,,, - name: First ensure yum cache is always refreshed yum: update_cache: true when: - ansible_pkg_mgr == 'yum',0,6
openstack%2Fopenstack-ansible-tests~master~I9c16378cee3862cd8ce2d87e8c5483533f98c94d,openstack/openstack-ansible-tests,master,I9c16378cee3862cd8ce2d87e8c5483533f98c94d,Updated host prep tasks,MERGED,2016-08-29 18:10:44.000000000,2016-08-29 19:26:13.000000000,2016-08-29 19:26:13.000000000,"[{'_account_id': 3}, {'_account_id': 12807}, {'_account_id': 14805}]","[{'number': 1, 'created': '2016-08-29 18:10:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-tests/commit/b29585678813df32acd14f00d064b513659561ba', 'message': 'Updated host prep tasks\n\nChange so that local ssh is no longer assumed to be available. The\ntasks for keyfile generation and insertion as root are now done\nin the same place.\n\nWhen running on an APT system the backports repo will be made available\nif its found within the sources list file.\n\nChange-Id: I9c16378cee3862cd8ce2d87e8c5483533f98c94d\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 2, 'created': '2016-08-29 18:35:33.000000000', 'files': ['common-tasks/test-force-package-cache-update.yml', 'test-prepare-host.yml', 'test-prepare-keys.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-tests/commit/7bccc59c6ee3fc32ed8240561807a9c2deefc329', 'message': 'Updated host prep tasks\n\nChange so that local ssh is no longer assumed to be available. The\ntasks for keyfile generation and insertion as root are now done\nin the same place.\n\nWhen running on an APT systems the backports repo will be made available\nif its found within the sources list file.\n\nChange-Id: I9c16378cee3862cd8ce2d87e8c5483533f98c94d\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}]",1,362308,7bccc59c6ee3fc32ed8240561807a9c2deefc329,9,3,2,7353,,,0,"Updated host prep tasks

Change so that local ssh is no longer assumed to be available. The
tasks for keyfile generation and insertion as root are now done
in the same place.

When running on an APT systems the backports repo will be made available
if its found within the sources list file.

Change-Id: I9c16378cee3862cd8ce2d87e8c5483533f98c94d
Signed-off-by: Kevin Carter <kevin.carter@rackspace.com>
",git fetch https://review.opendev.org/openstack/openstack-ansible-tests refs/changes/08/362308/1 && git format-patch -1 --stdout FETCH_HEAD,"['common-tasks/test-force-package-cache-update.yml', 'test-prepare-host.yml', 'test-prepare-keys.yml']",3,b29585678813df32acd14f00d064b513659561ba,," connection: local gather_facts: false - name: Ensure root can ssh to localhost authorized_key: user: ""root"" key: ""{{ lxc_container_ssh_key }}""",,13,5
openstack%2Fproject-config~master~I53aaef0f8092e0006818200c2478762056014985,openstack/project-config,master,I53aaef0f8092e0006818200c2478762056014985,NPM Projects: sudo needed for DSVM jobs,MERGED,2016-08-29 15:57:01.000000000,2016-08-29 19:25:21.000000000,2016-08-29 19:25:21.000000000,"[{'_account_id': 3}, {'_account_id': 6316}, {'_account_id': 6547}, {'_account_id': 22670}]","[{'number': 1, 'created': '2016-08-29 15:57:01.000000000', 'files': ['jenkins/jobs/javascript.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/7c780ed1a0f3e9881b03ae7e7d84a6fa939d85ca', 'message': 'NPM Projects: sudo needed for DSVM jobs\n\nFunctional tests for NPM Projects like js-openstack-lib are run\nagainst devstack, using devstack-gate. However, the scripts that\nsetup devstack need sudo access in order to setup and configure the\nstack properly.\n\nChange-Id: I53aaef0f8092e0006818200c2478762056014985\n'}]",0,362222,7c780ed1a0f3e9881b03ae7e7d84a6fa939d85ca,10,4,1,8614,,,0,"NPM Projects: sudo needed for DSVM jobs

Functional tests for NPM Projects like js-openstack-lib are run
against devstack, using devstack-gate. However, the scripts that
setup devstack need sudo access in order to setup and configure the
stack properly.

Change-Id: I53aaef0f8092e0006818200c2478762056014985
",git fetch https://review.opendev.org/openstack/project-config refs/changes/22/362222/1 && git format-patch -1 --stdout FETCH_HEAD,['jenkins/jobs/javascript.yaml'],1,7c780ed1a0f3e9881b03ae7e7d84a6fa939d85ca,npm,, - revoke-sudo,0,1
openstack%2Ftacker~master~I334e0e79c8bdba4a10d97ab691b1e6b242a0f1c5,openstack/tacker,master,I334e0e79c8bdba4a10d97ab691b1e6b242a0f1c5,Device refactor Part3: Rename device in codes,MERGED,2016-08-08 03:47:52.000000000,2016-08-29 19:20:40.000000000,2016-08-29 19:20:40.000000000,"[{'_account_id': 3}, {'_account_id': 2874}, {'_account_id': 9375}, {'_account_id': 10487}, {'_account_id': 13380}, {'_account_id': 18955}]","[{'number': 1, 'created': '2016-08-08 03:47:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker/commit/a009b594e169eae33ead65b318c2abc7821a843c', 'message': 'Rename device into vnf, device_template into vnfd\n\nPrevious patch https://review.openstack.org/#/c/349776/\nhas renamed the DB part.\n\nChange-Id: I334e0e79c8bdba4a10d97ab691b1e6b242a0f1c5\nPartial-bug: #1589018\n'}, {'number': 2, 'created': '2016-08-08 04:17:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker/commit/0074e395bf0aa5c6d271fbe2e2b92594116e15e0', 'message': 'Device refactor Part3: Rename device in codes\n\nPrevious patch https://review.openstack.org/#/c/349776/\nhas renamed the DB part.\n\nChange-Id: I334e0e79c8bdba4a10d97ab691b1e6b242a0f1c5\nPartial-bug: #1589018\n'}, {'number': 3, 'created': '2016-08-08 06:56:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker/commit/828da38bc454cdb92952d37f44ecf4295698a328', 'message': 'Device refactor Part3: Rename device in codes\n\nPrevious patch https://review.openstack.org/#/c/349776/\nhas renamed the DB part.\n\nChange-Id: I334e0e79c8bdba4a10d97ab691b1e6b242a0f1c5\nPartial-bug: #1589018\n'}, {'number': 4, 'created': '2016-08-08 09:35:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker/commit/34091a62d78d07706850a7db930ac9f6c31a9b4e', 'message': 'Device refactor Part3: Rename device in codes\n\nPrevious patch https://review.openstack.org/#/c/349776/\nhas renamed the DB part.\n\nChange-Id: I334e0e79c8bdba4a10d97ab691b1e6b242a0f1c5\nPartial-bug: #1589018\n'}, {'number': 5, 'created': '2016-08-08 10:51:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker/commit/1d0f50aca2a70ece67faa0e6685df0fe738f7f0c', 'message': 'Device refactor Part3: Rename device in codes\n\nPrevious patch https://review.openstack.org/#/c/349776/\nhas renamed the DB part.\n\nChange-Id: I334e0e79c8bdba4a10d97ab691b1e6b242a0f1c5\nPartial-bug: #1589018\n'}, {'number': 6, 'created': '2016-08-08 11:16:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker/commit/451ad3a5e7ceb030abaf3a6744b89e3ca223a123', 'message': 'Device refactor Part3: Rename device in codes\n\nPrevious patch https://review.openstack.org/#/c/349776/\nhas renamed the DB part.\n\nChange-Id: I334e0e79c8bdba4a10d97ab691b1e6b242a0f1c5\nPartial-bug: #1589018\n'}, {'number': 7, 'created': '2016-08-25 09:43:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker/commit/053ba045b87570429952365526835c64eb47c45c', 'message': 'Device refactor Part3: Rename device in codes\n\nPrevious patch https://review.openstack.org/#/c/349776/\nhas renamed the DB part.\n\nChange-Id: I334e0e79c8bdba4a10d97ab691b1e6b242a0f1c5\nPartial-bug: #1589018\n'}, {'number': 8, 'created': '2016-08-25 09:49:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker/commit/7131c89c1dc162f68ae9dd7ad2e420f39caba475', 'message': ""Device refactor Part3: Rename device in codes\n\nPrevious patch https://review.openstack.org/#/c/349776/\nhas renamed the DB part.\n\ntacker/vm/plugin.py and tacker/db/vm/vm_db.py are not renamed\nin this patch due to the git problem. (It is always be done by\n'delete/add' instead of 'rename').\nThey will be renamed in later patch with unit tests.\n\nChange-Id: I334e0e79c8bdba4a10d97ab691b1e6b242a0f1c5\nPartial-bug: #1589018\n""}, {'number': 9, 'created': '2016-08-25 10:02:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker/commit/1bc2dcc0d18cdd8a137dacce8ca3ec7fa4fdf3a0', 'message': ""Device refactor Part3: Rename device in codes\n\nPrevious patch https://review.openstack.org/#/c/349776/\nhas renamed the DB part.\n\ntacker/vm/plugin.py and tacker/db/vm/vm_db.py are not renamed\nin this patch due to the git problem. (It is always be done by\n'delete/add' instead of 'rename').\nThey will be renamed in later patch with unit tests.\n\nChange-Id: I334e0e79c8bdba4a10d97ab691b1e6b242a0f1c5\nPartial-bug: #1589018\n""}, {'number': 10, 'created': '2016-08-26 06:20:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker/commit/44e896dee19b47462c77b88e06d15878a6131734', 'message': ""Device refactor Part3: Rename device in codes\n\nPrevious patch https://review.openstack.org/#/c/349776/\nhas renamed the DB part.\n\ntacker/vm/plugin.py and tacker/db/vm/vm_db.py are not renamed\nin this patch due to the git problem. (It is always be done by\n'delete/add' instead of 'rename').\nThey will be renamed in later patch with unit tests.\n\nChange-Id: I334e0e79c8bdba4a10d97ab691b1e6b242a0f1c5\nPartial-bug: #1589018\n""}, {'number': 11, 'created': '2016-08-26 08:27:13.000000000', 'files': ['tacker/vnfm/infra_drivers/__init__.py', 'tacker/vnfm/monitor_drivers/ping/__init__.py', 'tacker/vnfm/tosca/__init__.py', 'tacker/vnfm/mgmt_drivers/openwrt/__init__.py', 'tacker/vnfm/tosca/lib/tacker_nfv_defs.yaml', 'doc/source/devref/monitor-api.rst', 'tacker/extensions/vnfm.py', 'tacker/vnfm/infra_drivers/heat/heat.py', 'tacker/vnfm/constants.py', 'tacker/vm/plugin.py', 'tacker/vnfm/__init__.py', 'tacker/vnfm/monitor_drivers/__init__.py', 'tacker/vnfm/mgmt_drivers/abstract_driver.py', 'tacker/vnfm/infra_drivers/scale_driver.py', 'tacker/vnfm/monitor_drivers/ping/ping.py', 'tacker/vnfm/tosca/lib/tacker_defs.yaml', 'tacker/tests/unit/vm/test_vim_client.py', 'tacker/vnfm/monitor_drivers/http_ping/__init__.py', 'tacker/vnfm/infra_drivers/noop.py', 'tacker/vnfm/monitor_drivers/http_ping/http_ping.py', 'tacker/tests/unit/vm/test_plugin.py', 'tacker/vnfm/mgmt_drivers/__init__.py', 'tacker/tests/unit/vm/monitor_drivers/ping/test_ping.py', 'tacker/tests/functional/vnfm/test_tosca_vnf_multiple_vdu.py', 'tacker/tests/unit/vm/test_tosca_templates_under_samples.py', 'tacker/vnfm/mgmt_drivers/constants.py', 'tacker/tests/unit/vm/monitor_drivers/http_ping/test_http_ping.py', 'tacker/tests/unit/vm/test_toscautils.py', 'setup.cfg', 'tacker/vnfm/infra_drivers/heat/__init__.py', 'tacker/tests/unit/vm/test_monitor.py', 'tacker/vnfm/mgmt_drivers/noop.py', 'tacker/tests/unit/vm/nfvo/drivers/vim/test_openstack_driver.py', 'tacker/vnfm/infra_drivers/nova/__init__.py', 'tacker/vnfm/keystone.py', 'tacker/vnfm/mgmt_drivers/openwrt/openwrt.py', 'tacker/common/clients.py', 'tacker/nfvo/drivers/vim/openstack_driver.py', 'tacker/tests/unit/db/utils.py', 'tacker/vnfm/monitor.py', 'tacker/vnfm/tosca/utils.py', 'etc/config-generator.conf', 'tacker/db/vm/vm_db.py', 'tacker/tests/unit/vm/infra_drivers/heat/test_heat.py', 'tacker/vnfm/vim_client.py', 'tacker/vnfm/infra_drivers/nova/nova.py', 'tacker/db/nfvo/nfvo_db.py', 'tacker/vnfm/monitor_drivers/abstract_driver.py', 'tacker/vnfm/infra_drivers/abstract_driver.py'], 'web_link': 'https://opendev.org/openstack/tacker/commit/3c422ddc3e8de1cd1774cbf1bee2679afe5e4579', 'message': ""Device refactor Part3: Rename device in codes\n\nPrevious patch https://review.openstack.org/#/c/349776/\nhas renamed the DB part.\n\ntacker/vm/plugin.py and tacker/db/vm/vm_db.py are not renamed\nin this patch due to the git problem. (It is always be done by\n'delete/add' instead of 'rename').\nThey will be renamed in later patch with unit tests.\n\nChange-Id: I334e0e79c8bdba4a10d97ab691b1e6b242a0f1c5\nPartial-bug: #1589018\n""}]",23,352205,3c422ddc3e8de1cd1774cbf1bee2679afe5e4579,37,6,11,2874,,,0,"Device refactor Part3: Rename device in codes

Previous patch https://review.openstack.org/#/c/349776/
has renamed the DB part.

tacker/vm/plugin.py and tacker/db/vm/vm_db.py are not renamed
in this patch due to the git problem. (It is always be done by
'delete/add' instead of 'rename').
They will be renamed in later patch with unit tests.

Change-Id: I334e0e79c8bdba4a10d97ab691b1e6b242a0f1c5
Partial-bug: #1589018
",git fetch https://review.opendev.org/openstack/tacker refs/changes/05/352205/10 && git format-patch -1 --stdout FETCH_HEAD,"['tacker/vnfm/infra_drivers/__init__.py', 'tacker/vnfm/monitor_drivers/ping/__init__.py', 'tacker/vnfm/tosca/__init__.py', 'tacker/vnfm/mgmt_drivers/openwrt/__init__.py', 'tacker/vnfm/tosca/lib/tacker_nfv_defs.yaml', 'doc/source/devref/monitor-api.rst', 'tacker/extensions/vnfm.py', 'tacker/vnfm/infra_drivers/heat/heat.py', 'tacker/vnfm/constants.py', 'tacker/vm/plugin.py', 'tacker/vnfm/plugin.py', 'tacker/vnfm/__init__.py', 'tacker/vnfm/monitor_drivers/__init__.py', 'tacker/vnfm/mgmt_drivers/abstract_driver.py', 'tacker/vnfm/infra_drivers/scale_driver.py', 'tacker/vnfm/monitor_drivers/ping/ping.py', 'tacker/vnfm/tosca/lib/tacker_defs.yaml', 'tacker/tests/unit/vm/test_vim_client.py', 'tacker/vnfm/monitor_drivers/http_ping/__init__.py', 'tacker/vnfm/infra_drivers/noop.py', 'tacker/vnfm/monitor_drivers/http_ping/http_ping.py', 'tacker/tests/unit/vm/test_plugin.py', 'tacker/vnfm/mgmt_drivers/__init__.py', 'tacker/tests/unit/vm/monitor_drivers/ping/test_ping.py', 'tacker/tests/functional/vnfm/test_tosca_vnf_multiple_vdu.py', 'tacker/tests/unit/vm/test_tosca_templates_under_samples.py', 'tacker/vnfm/mgmt_drivers/constants.py', 'tacker/tests/unit/vm/monitor_drivers/http_ping/test_http_ping.py', 'tacker/tests/unit/vm/test_toscautils.py', 'setup.cfg', 'tacker/vnfm/infra_drivers/heat/__init__.py', 'tacker/tests/unit/vm/test_monitor.py', 'tacker/vnfm/mgmt_drivers/noop.py', 'tacker/tests/unit/vm/nfvo/drivers/vim/test_openstack_driver.py', 'tacker/vnfm/infra_drivers/nova/__init__.py', 'tacker/vnfm/keystone.py', 'tacker/vnfm/mgmt_drivers/openwrt/openwrt.py', 'tacker/common/clients.py', 'tacker/nfvo/drivers/vim/openstack_driver.py', 'tacker/db/migration/models/head.py', 'tacker/vnfm/monitor.py', 'tacker/vnfm/tosca/utils.py', 'tacker/db/vm/vm_db.py', 'tacker/tests/unit/vm/infra_drivers/heat/test_heat.py', 'tacker/vnfm/vim_client.py', 'tacker/vnfm/infra_drivers/nova/nova.py', 'tacker/db/nfvo/nfvo_db.py', 'tacker/db/vnfm/__init__.py', 'tacker/vnfm/hosting_device_scheduler.py', 'tacker/vnfm/monitor_drivers/abstract_driver.py', 'tacker/vnfm/infra_drivers/abstract_driver.py', 'tacker/db/vnfm/vnfm_db.py']",52,a009b594e169eae33ead65b318c2abc7821a843c,bug/1589018,"# Copyright 2013, 2014 Intel Corporation. # All Rights Reserved. # # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import uuid from oslo_log import log as logging import sqlalchemy as sa from sqlalchemy import orm from sqlalchemy.orm import exc as orm_exc from tacker.api.v1 import attributes from tacker import context as t_context from tacker.db import db_base from tacker.db import model_base from tacker.db import models_v1 from tacker.db import types from tacker.extensions import vnfm from tacker import manager from tacker.plugins.common import constants LOG = logging.getLogger(__name__) _ACTIVE_UPDATE = (constants.ACTIVE, constants.PENDING_UPDATE) _ACTIVE_UPDATE_ERROR_DEAD = ( constants.PENDING_CREATE, constants.ACTIVE, constants.PENDING_UPDATE, constants.ERROR, constants.DEAD) CREATE_STATES = (constants.PENDING_CREATE, constants.DEAD) ########################################################################### # db tables class VNFD(model_base.BASE, models_v1.HasId, models_v1.HasTenant): """"""Represents VNFD to create VNF."""""" __tablename__ = 'vnfds' # Descriptive name name = sa.Column(sa.String(255), nullable=False) description = sa.Column(sa.Text) # service type that this service vm provides. # At first phase, this includes only single service # In future, single service VM may accomodate multiple services. service_types = orm.relationship('ServiceType', backref='vnfd') # driver to create hosting vnf. e.g. noop, nova, heat, etc... infra_driver = sa.Column(sa.String(255)) # driver to communicate with service managment mgmt_driver = sa.Column(sa.String(255)) # (key, value) pair to spin up attributes = orm.relationship('VNFDAttribute', backref='vnfd') class ServiceType(model_base.BASE, models_v1.HasId, models_v1.HasTenant): """"""Represents service type which hosting vnf provides. Since a vnf may provide many services, This is one-to-many relationship. """""" vnfd_id = sa.Column(types.Uuid, sa.ForeignKey('vnfds.id'), nullable=False) service_type = sa.Column(sa.String(64), nullable=False) class VNFDAttribute(model_base.BASE, models_v1.HasId): """"""Represents attributes necessary for spinning up VM in (key, value) pair key value pair is adopted for being agnostic to actuall manager of VMs like nova, heat or others. e.g. image-id, flavor-id for Nova. The interpretation is up to actual driver of hosting vnf. """""" __tablename__ = 'vnfdattributes' vnfd_id = sa.Column(types.Uuid, sa.ForeignKey('vnfds.id'), nullable=False) key = sa.Column(sa.String(255), nullable=False) value = sa.Column(sa.TEXT(65535), nullable=True) class VNF(model_base.BASE, models_v1.HasId, models_v1.HasTenant): """"""Represents vnfs that hosts services. Here the term, 'VM', is intentionally avoided because it can be VM or other container. """""" __tablename__ = 'vnfs' vnfd_id = sa.Column(types.Uuid, sa.ForeignKey('vnfds.id')) vnfd = orm.relationship('VNFD') name = sa.Column(sa.String(255), nullable=False) description = sa.Column(sa.Text, nullable=True) # sufficient information to uniquely identify hosting vnf. # In case of service VM, it's UUID of nova VM. instance_id = sa.Column(sa.String(64), nullable=True) # For a management tool to talk to manage this hosting vnf. # opaque string. # e.g. (driver, mgmt_url) = (ssh, ip address), ... mgmt_url = sa.Column(sa.String(255), nullable=True) attributes = orm.relationship(""VNFAttribute"", backref=""vnf"") status = sa.Column(sa.String(64), nullable=False) vim_id = sa.Column(types.Uuid, sa.ForeignKey('vims.id'), nullable=False) placement_attr = sa.Column(types.Json, nullable=True) vim = orm.relationship('Vim') error_reason = sa.Column(sa.Text, nullable=True) class VNFAttribute(model_base.BASE, models_v1.HasId): """"""Represents kwargs necessary for spinning up VM in (key, value) pair. key value pair is adopted for being agnostic to actuall manager of VMs like nova, heat or others. e.g. image-id, flavor-id for Nova. The interpretation is up to actual driver of hosting vnf. """""" __tablename__ = 'vnfattributes' vnf_id = sa.Column(types.Uuid, sa.ForeignKey('vnfs.id'), nullable=False) key = sa.Column(sa.String(255), nullable=False) # json encoded value. example # ""nic"": [{""net-id"": <net-uuid>}, {""port-id"": <port-uuid>}] value = sa.Column(sa.TEXT(65535), nullable=True) class VNFMPluginDb(vnfm.VNFMPluginBase, db_base.CommonDbMixin): @property def _core_plugin(self): return manager.TackerManager.get_plugin() def subnet_id_to_network_id(self, context, subnet_id): subnet = self._core_plugin.get_subnet(context, subnet_id) return subnet['network_id'] def __init__(self): super(VNFMPluginDb, self).__init__() def _get_resource(self, context, model, id): try: return self._get_by_id(context, model, id) except orm_exc.NoResultFound: if issubclass(model, VNFD): raise vnfm.VNFDNotFound(vnfd_id=id) elif issubclass(model, ServiceType): raise vnfm.ServiceTypeNotFound(service_type_id=id) if issubclass(model, VNF): raise vnfm.VNFNotFound(vnf_id=id) else: raise def _make_attributes_dict(self, attributes_db): return dict((attr.key, attr.value) for attr in attributes_db) def _make_service_types_list(self, service_types): return [{'id': service_type.id, 'service_type': service_type.service_type} for service_type in service_types] def _make_vnfd_dict(self, vnfd, fields=None): res = { 'attributes': self._make_attributes_dict(vnfd['attributes']), 'service_types': self._make_service_types_list( vnfd.service_types) } key_list = ('id', 'tenant_id', 'name', 'description', 'infra_driver', 'mgmt_driver') res.update((key, vnfd[key]) for key in key_list) return self._fields(res, fields) def _make_dev_attrs_dict(self, dev_attrs_db): return dict((arg.key, arg.value) for arg in dev_attrs_db) def _make_vnf_dict(self, vnf_db, fields=None): LOG.debug(_('vnf_db %s'), vnf_db) LOG.debug(_('vnf_db attributes %s'), vnf_db.attributes) res = { 'vnfd': self._make_vnfd_dict(vnf_db.vnfd), 'attributes': self._make_dev_attrs_dict(vnf_db.attributes), } key_list = ('id', 'tenant_id', 'name', 'description', 'instance_id', 'vim_id', 'placement_attr', 'vnfd_id', 'status', 'mgmt_url', 'error_reason') res.update((key, vnf_db[key]) for key in key_list) return self._fields(res, fields) @staticmethod def _infra_driver_name(vnf_dict): return vnf_dict['vnfd']['infra_driver'] @staticmethod def _mgmt_driver_name(vnf_dict): return vnf_dict['vnfd']['mgmt_driver'] @staticmethod def _instance_id(vnf_dict): return vnf_dict['instance_id'] def create_vnfd(self, context, vnfd): vnfd = vnfd['vnfd'] LOG.debug(_('vnfd %s'), vnfd) tenant_id = self._get_tenant_id_for_create(context, vnfd) infra_driver = vnfd.get('infra_driver') mgmt_driver = vnfd.get('mgmt_driver') service_types = vnfd.get('service_types') if (not attributes.is_attr_set(infra_driver)): LOG.debug(_('hosting vnf driver unspecified')) raise vnfm.InfraDriverNotSpecified() if (not attributes.is_attr_set(mgmt_driver)): LOG.debug(_('mgmt driver unspecified')) raise vnfm.MGMTDriverNotSpecified() if (not attributes.is_attr_set(service_types)): LOG.debug(_('service types unspecified')) raise vnfm.ServiceTypesNotSpecified() with context.session.begin(subtransactions=True): vnfd_id = str(uuid.uuid4()) vnfd_db = VNFD( id=vnfd_id, tenant_id=tenant_id, name=vnfd.get('name'), description=vnfd.get('description'), infra_driver=infra_driver, mgmt_driver=mgmt_driver) context.session.add(vnfd_db) for (key, value) in vnfd.get('attributes', {}).items(): attribute_db = VNFDAttribute( id=str(uuid.uuid4()), vnfd_id=vnfd_id, key=key, value=value) context.session.add(attribute_db) for service_type in (item['service_type'] for item in vnfd['service_types']): service_type_db = ServiceType( id=str(uuid.uuid4()), tenant_id=tenant_id, vnfd_id=vnfd_id, service_type=service_type) context.session.add(service_type_db) LOG.debug(_('vnfd_db %(vnfd_db)s %(attributes)s '), {'vnfd_db': vnfd_db, 'attributes': vnfd_db.attributes}) return self._make_vnfd_dict(vnfd_db) def update_vnfd(self, context, vnfd_id, vnfd): with context.session.begin(subtransactions=True): vnfd_db = self._get_resource(context, VNFD, vnfd_id) vnfd_db.update(vnfd['vnfd']) return self._make_vnfd_dict(vnfd_db) def delete_vnfd(self, context, vnfd_id): with context.session.begin(subtransactions=True): # TODO(yamahata): race. prevent from newly inserting hosting vnf # that refers to this vnfd vnfs_db = context.session.query(VNF).filter_by( vnfd_id=vnfd_id).first() if vnfs_db is not None: raise vnfm.VNFDInUse( vnfd_id=vnfd_id) context.session.query(ServiceType).filter_by( vnfd_id=vnfd_id).delete() context.session.query(VNFDAttribute).filter_by( vnfd_id=vnfd_id).delete() vnfd_db = self._get_resource(context, VNFD, vnfd_id) context.session.delete(vnfd_db) def get_vnfd(self, context, vnfd_id, fields=None): vnfd_db = self._get_resource(context, VNFD, vnfd_id) return self._make_vnfd_dict(vnfd_db) def get_vnfds(self, context, filters, fields=None): return self._get_collection(context, VNFD, self._make_vnfd_dict, filters=filters, fields=fields) def choose_vnfd(self, context, service_type, required_attributes=None): required_attributes = required_attributes or [] LOG.debug(_('required_attributes %s'), required_attributes) with context.session.begin(subtransactions=True): query = ( context.session.query(VNFD). filter( sa.exists(). where(sa.and_( VNFD.id == ServiceType.vnfd_id, ServiceType.service_type == service_type)))) for key in required_attributes: query = query.filter( sa.exists(). where(sa.and_( VNFD.id == VNFDAttribute.vnfd_id, VNFDAttribute.key == key))) LOG.debug(_('statements %s'), query) vnfd_db = query.first() if vnfd_db: return self._make_vnfd_dict(vnfd_db) def _vnf_attribute_update_or_create( self, context, vnf_id, key, value): arg = (self._model_query(context, VNFAttribute). filter(VNFAttribute.vnf_id == vnf_id). filter(VNFAttribute.key == key).first()) if arg: arg.value = value else: arg = VNFAttribute( id=str(uuid.uuid4()), vnf_id=vnf_id, key=key, value=value) context.session.add(arg) # called internally, not by REST API def _create_vnf_pre(self, context, vnf): LOG.debug(_('vnf %s'), vnf) tenant_id = self._get_tenant_id_for_create(context, vnf) vnfd_id = vnf['vnfd_id'] name = vnf.get('name') vnf_id = str(uuid.uuid4()) attributes = vnf.get('attributes', {}) vim_id = vnf.get('vim_id') placement_attr = vnf.get('placement_attr', {}) with context.session.begin(subtransactions=True): vnfd_db = self._get_resource(context, VNFD, vnfd_id) vnf_db = VNF( id=vnf_id, tenant_id=tenant_id, name=name, description=vnfd_db.description, instance_id=None, vnfd_id=vnfd_id, vim_id=vim_id, placement_attr=placement_attr, status=constants.PENDING_CREATE, error_reason=None) context.session.add(vnf_db) for key, value in attributes.items(): arg = VNFAttribute( id=str(uuid.uuid4()), vnf_id=vnf_id, key=key, value=value) context.session.add(arg) return self._make_vnf_dict(vnf_db) # called internally, not by REST API # intsance_id = None means error on creation def _create_vnf_post(self, context, vnf_id, instance_id, mgmt_url, vnf_dict): LOG.debug(_('vnf_dict %s'), vnf_dict) with context.session.begin(subtransactions=True): query = (self._model_query(context, VNF). filter(VNF.id == vnf_id). filter(VNF.status.in_(CREATE_STATES)). one()) query.update({'instance_id': instance_id, 'mgmt_url': mgmt_url}) if instance_id is None or vnf_dict['status'] == constants.ERROR: query.update({'status': constants.ERROR}) for (key, value) in vnf_dict['attributes'].items(): # do not store decrypted vim auth in vnf attr table if 'vim_auth' not in key: self._vnf_attribute_update_or_create(context, vnf_id, key, value) def _create_vnf_status(self, context, vnf_id, new_status): with context.session.begin(subtransactions=True): query = (self._model_query(context, VNF). filter(VNF.id == vnf_id). filter(VNF.status.in_(CREATE_STATES)).one()) query.update({'status': new_status}) def _get_vnf_db(self, context, vnf_id, current_statuses, new_status): try: vnf_db = ( self._model_query(context, VNF). filter(VNF.id == vnf_id). filter(VNF.status.in_(current_statuses)). with_lockmode('update').one()) except orm_exc.NoResultFound: raise vnfm.VNFNotFound(vnf_id=vnf_id) if vnf_db.status == constants.PENDING_UPDATE: raise vnfm.VNFInUse(vnf_id=vnf_id) vnf_db.update({'status': new_status}) return vnf_db def _update_vnf_scaling_status(self, context, policy, previous_statuses, status, mgmt_url=None): with context.session.begin(subtransactions=True): vnf_db = self._get_vnf_db( context, policy['vnf']['id'], previous_statuses, status) if mgmt_url: vnf_db.update({'mgmt_url': mgmt_url}) return self._make_vnf_dict(vnf_db) def _update_vnf_pre(self, context, vnf_id): with context.session.begin(subtransactions=True): vnf_db = self._get_vnf_db( context, vnf_id, _ACTIVE_UPDATE, constants.PENDING_UPDATE) return self._make_vnf_dict(vnf_db) def _update_vnf_post(self, context, vnf_id, new_status, new_vnf_dict=None): with context.session.begin(subtransactions=True): (self._model_query(context, VNF). filter(VNF.id == vnf_id). filter(VNF.status == constants.PENDING_UPDATE). update({'status': new_status})) dev_attrs = new_vnf_dict.get('attributes', {}) (context.session.query(VNFAttribute). filter(VNFAttribute.vnf_id == vnf_id). filter(~VNFAttribute.key.in_(dev_attrs.keys())). delete(synchronize_session='fetch')) for (key, value) in dev_attrs.items(): if 'vim_auth' not in key: self._vnf_attribute_update_or_create(context, vnf_id, key, value) def _delete_vnf_pre(self, context, vnf_id): with context.session.begin(subtransactions=True): vnf_db = self._get_vnf_db( context, vnf_id, _ACTIVE_UPDATE_ERROR_DEAD, constants.PENDING_DELETE) return self._make_vnf_dict(vnf_db) def _delete_vnf_post(self, context, vnf_id, error): with context.session.begin(subtransactions=True): query = ( self._model_query(context, VNF). filter(VNF.id == vnf_id). filter(VNF.status == constants.PENDING_DELETE)) if error: query.update({'status': constants.ERROR}) else: (self._model_query(context, VNFAttribute). filter(VNFAttribute.vnf_id == vnf_id).delete()) query.delete() # reference implementation. needs to be overrided by subclass def create_vnf(self, context, vnf): vnf_dict = self._create_vnf_pre(context, vnf) # start actual creation of hosting vnf. # Waiting for completion of creation should be done backgroundly # by another thread if it takes a while. instance_id = str(uuid.uuid4()) vnf_dict['instance_id'] = instance_id self._create_vnf_post(context, vnf_dict['id'], instance_id, None, vnf_dict) self._create_vnf_status(context, vnf_dict['id'], constants.ACTIVE) return vnf_dict # reference implementation. needs to be overrided by subclass def update_vnf(self, context, vnf_id, vnf): vnf_dict = self._update_vnf_pre(context, vnf_id) # start actual update of hosting vnf # waiting for completion of update should be done backgroundly # by another thread if it takes a while self._update_vnf_post(context, vnf_id, constants.ACTIVE) return vnf_dict # reference implementation. needs to be overrided by subclass def delete_vnf(self, context, vnf_id): self._delete_vnf_pre(context, vnf_id) # start actual deletion of hosting vnf. # Waiting for completion of deletion should be done backgroundly # by another thread if it takes a while. self._delete_vnf_post(context, vnf_id, False) def get_vnf(self, context, vnf_id, fields=None): vnf_db = self._get_resource(context, VNF, vnf_id) return self._make_vnf_dict(vnf_db, fields) def get_vnfs(self, context, filters=None, fields=None): return self._get_collection(context, VNF, self._make_vnf_dict, filters=filters, fields=fields) def set_vnf_error_status_reason(self, context, vnf_id, new_reason): with context.session.begin(subtransactions=True): (self._model_query(context, VNF). filter(VNF.id == vnf_id). update({'error_reason': new_reason})) def _mark_vnf_status(self, vnf_id, exclude_status, new_status): context = t_context.get_admin_context() with context.session.begin(subtransactions=True): try: vnf_db = ( self._model_query(context, VNF). filter(VNF.id == vnf_id). filter(~VNF.status.in_(exclude_status)). with_lockmode('update').one()) except orm_exc.NoResultFound: LOG.warning(_('no vnf found %s'), vnf_id) return False vnf_db.update({'status': new_status}) return True def _mark_vnf_error(self, vnf_id): return self._mark_vnf_status( vnf_id, [constants.DEAD], constants.ERROR) def _mark_vnf_dead(self, vnf_id): exclude_status = [ constants.DOWN, constants.PENDING_CREATE, constants.PENDING_UPDATE, constants.PENDING_DELETE, constants.INACTIVE, constants.ERROR] return self._mark_vnf_status( vnf_id, exclude_status, constants.DEAD) ",,1340,1369
openstack%2Fhorizon~master~Ib2f85913a020fc63c2ef4de22c917bdb4924b0b8,openstack/horizon,master,Ib2f85913a020fc63c2ef4de22c917bdb4924b0b8,Updated from global requirements,MERGED,2016-08-29 06:11:18.000000000,2016-08-29 19:16:48.000000000,2016-08-29 19:16:48.000000000,"[{'_account_id': 3}, {'_account_id': 9576}, {'_account_id': 12071}]","[{'number': 1, 'created': '2016-08-29 06:11:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/50a3a7a2d7717ac6ca7b6ac442f3c9426efadd80', 'message': 'Updated from global requirements\n\nChange-Id: Ib2f85913a020fc63c2ef4de22c917bdb4924b0b8\n'}, {'number': 2, 'created': '2016-08-29 16:48:05.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/horizon/commit/da109c4779cdd76f6628fac59e29747e18e0fb85', 'message': 'Updated from global requirements\n\nChange-Id: Ib2f85913a020fc63c2ef4de22c917bdb4924b0b8\n'}]",0,361864,da109c4779cdd76f6628fac59e29747e18e0fb85,11,3,2,11131,,,0,"Updated from global requirements

Change-Id: Ib2f85913a020fc63c2ef4de22c917bdb4924b0b8
",git fetch https://review.opendev.org/openstack/horizon refs/changes/64/361864/2 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,50a3a7a2d7717ac6ca7b6ac442f3c9426efadd80,openstack/requirements,python-heatclient>=1.4.0 # Apache-2.0,python-heatclient>=1.1.0 # Apache-2.0,1,1
openstack%2Fnetworking-sfc~master~I50007e9c1d55843d30dbf3dff4d466e7a88bdc14,openstack/networking-sfc,master,I50007e9c1d55843d30dbf3dff4d466e7a88bdc14,set [flowclassifier] section drivers to be ovs in devstack setup.,MERGED,2016-08-27 19:21:13.000000000,2016-08-29 19:13:48.000000000,2016-08-29 19:13:48.000000000,"[{'_account_id': 3}, {'_account_id': 11313}, {'_account_id': 11907}, {'_account_id': 14605}, {'_account_id': 19948}, {'_account_id': 20434}]","[{'number': 1, 'created': '2016-08-27 19:21:13.000000000', 'files': ['devstack/settings'], 'web_link': 'https://opendev.org/openstack/networking-sfc/commit/e405ab40fb5c6f51771352f10f664266d5410fa3', 'message': 'set [flowclassifier] section drivers to be ovs in devstack setup.\n\n  - To fix the issue that when we do not give logical source port when\n    create flowclassifier, there is no exception thrown.\n\nChange-Id: I50007e9c1d55843d30dbf3dff4d466e7a88bdc14\n'}]",7,361650,e405ab40fb5c6f51771352f10f664266d5410fa3,16,6,1,17540,,,0,"set [flowclassifier] section drivers to be ovs in devstack setup.

  - To fix the issue that when we do not give logical source port when
    create flowclassifier, there is no exception thrown.

Change-Id: I50007e9c1d55843d30dbf3dff4d466e7a88bdc14
",git fetch https://review.opendev.org/openstack/networking-sfc refs/changes/50/361650/1 && git format-patch -1 --stdout FETCH_HEAD,['devstack/settings'],1,e405ab40fb5c6f51771352f10f664266d5410fa3,networking-sfc bug/1617904,"NEUTRON_FLOWCLASSIFIER_DRIVERS=${NEUTRON_FLOWCLASSIFIER_DRIVERS:-""ovs""}","NEUTRON_FLOWCLASSIFIER_DRIVER=${NEUTRON_FLOWCLASSIFIER_DRIVER:-""ovs""}",1,1
openstack%2Fneutron~master~If3dc64fb37708a56ed863de9fe2b933f203bc22a,openstack/neutron,master,If3dc64fb37708a56ed863de9fe2b933f203bc22a,Add FWaaS v2 for L2 to neutron setup.cfg,ABANDONED,2016-08-29 01:30:46.000000000,2016-08-29 19:12:49.000000000,,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 5170}, {'_account_id': 6995}, {'_account_id': 9656}, {'_account_id': 9732}, {'_account_id': 10385}, {'_account_id': 10850}, {'_account_id': 13702}, {'_account_id': 14208}, {'_account_id': 15752}, {'_account_id': 16376}, {'_account_id': 17292}]","[{'number': 1, 'created': '2016-08-29 01:30:46.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/neutron/commit/0058092102c5b83245e5c5a5376e10781f132b1f', 'message': 'Add FWaaS v2 for L2 to neutron setup.cfg\n\nAdd FWaaS v2 directives specific to L2 agent extensions to the neutron\nsetup.cfg.\n\nChange-Id: If3dc64fb37708a56ed863de9fe2b933f203bc22a\nDepends-On: I94b224813c85b7e611e9681323a2f0d2806e0d41\nDepends-On: I9f172be46ee590b99313106fa262019a2583774a\n'}]",1,361786,0058092102c5b83245e5c5a5376e10781f132b1f,15,13,1,13995,,,0,"Add FWaaS v2 for L2 to neutron setup.cfg

Add FWaaS v2 directives specific to L2 agent extensions to the neutron
setup.cfg.

Change-Id: If3dc64fb37708a56ed863de9fe2b933f203bc22a
Depends-On: I94b224813c85b7e611e9681323a2f0d2806e0d41
Depends-On: I9f172be46ee590b99313106fa262019a2583774a
",git fetch https://review.opendev.org/openstack/neutron refs/changes/86/361786/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,0058092102c5b83245e5c5a5376e10781f132b1f,fwaas_l2_setup_cfg, fwaasv2 = neutron_fwaas.services.firewall.agents.v2.l2.extensions.fwaas:FWaaSV2AgentExtension,,1,0
openstack%2Fironic~stable%2Fmitaka~I6a7f522ae9c7d58f216a7d5dfedf067da0a0fc32,openstack/ironic,stable/mitaka,I6a7f522ae9c7d58f216a7d5dfedf067da0a0fc32,IPMINative: Check the boot mode when setting the boot device,MERGED,2016-08-11 16:07:40.000000000,2016-08-29 19:05:19.000000000,2016-08-29 19:05:19.000000000,"[{'_account_id': 3}, {'_account_id': 2889}, {'_account_id': 7080}, {'_account_id': 10239}, {'_account_id': 19901}]","[{'number': 1, 'created': '2016-08-11 16:07:40.000000000', 'files': ['releasenotes/notes/ipminative-bootdev-uefi-954a0dd825bcef97.yaml', 'ironic/drivers/modules/ipminative.py', 'ironic/tests/unit/drivers/modules/test_ipminative.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/018e0615710224cc4040cbc413ac1b28953847dd', 'message': 'IPMINative: Check the boot mode when setting the boot device\n\nThis patch is making the ipminative drive to take in consideration the\nboot mode (UEFI or BIOS) of the node when changing its boot device\norder. Otherwise, nodes in UEFI will switch to legacy BIOS as part of\nthe set_boot_device() call.\n\nCloses-Bug: #1612287\nChange-Id: I6a7f522ae9c7d58f216a7d5dfedf067da0a0fc32\n(cherry picked from commit bcfab9f8ba6c1fb8f31c6b1f861620ac98d638b0)\n'}]",3,354187,018e0615710224cc4040cbc413ac1b28953847dd,18,5,1,6773,,,0,"IPMINative: Check the boot mode when setting the boot device

This patch is making the ipminative drive to take in consideration the
boot mode (UEFI or BIOS) of the node when changing its boot device
order. Otherwise, nodes in UEFI will switch to legacy BIOS as part of
the set_boot_device() call.

Closes-Bug: #1612287
Change-Id: I6a7f522ae9c7d58f216a7d5dfedf067da0a0fc32
(cherry picked from commit bcfab9f8ba6c1fb8f31c6b1f861620ac98d638b0)
",git fetch https://review.opendev.org/openstack/ironic refs/changes/87/354187/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/ipminative-bootdev-uefi-954a0dd825bcef97.yaml', 'ironic/drivers/modules/ipminative.py', 'ironic/tests/unit/drivers/modules/test_ipminative.py']",3,018e0615710224cc4040cbc413ac1b28953847dd,bug/1612287,"from ironic.drivers.modules import deploy_utils ipmicmd.set_bootdev.assert_called_once_with('network', persist=False, uefiboot=False) ipmicmd.set_bootdev.assert_called_once_with('network', persist=False, uefiboot=False) ipmicmd.set_bootdev.assert_called_once_with('network', persist=False, uefiboot=False) @mock.patch.object(deploy_utils, 'get_boot_mode_for_deploy') @mock.patch('pyghmi.ipmi.command.Command', autospec=True) def test_set_boot_device_uefi(self, ipmi_mock, boot_mode_mock): ipmicmd = ipmi_mock.return_value boot_mode_mock.return_value = 'uefi' with task_manager.acquire(self.context, self.node.uuid) as task: self.driver.management.set_boot_device(task, boot_devices.PXE) # PXE is converted to 'network' internally by ipminative ipmicmd.set_bootdev.assert_called_once_with('network', persist=False, uefiboot=True) @mock.patch.object(deploy_utils, 'get_boot_mode_for_deploy') @mock.patch('pyghmi.ipmi.command.Command', autospec=True) def test_set_boot_device_uefi_and_persistent( self, ipmi_mock, boot_mode_mock): ipmicmd = ipmi_mock.return_value boot_mode_mock.return_value = 'uefi' with task_manager.acquire(self.context, self.node.uuid) as task: self.driver.management.set_boot_device(task, boot_devices.PXE, persistent=True) # PXE is converted to 'network' internally by ipminative ipmicmd.set_bootdev.assert_called_once_with('network', persist=True, uefiboot=True) "," ipmicmd.set_bootdev.assert_called_once_with('network', persist=False) ipmicmd.set_bootdev.assert_called_once_with('network', persist=False) ipmicmd.set_bootdev.assert_called_once_with('network', persist=False)",43,4
openstack%2Foctavia~master~I68deb7a9795cbb135dbbef5dea0bfc6aa89db5b3,openstack/octavia,master,I68deb7a9795cbb135dbbef5dea0bfc6aa89db5b3,Rewrite create_load_balancer flow,MERGED,2016-07-20 19:34:49.000000000,2016-08-29 19:04:57.000000000,2016-08-29 19:01:15.000000000,"[{'_account_id': 3}, {'_account_id': 6116}, {'_account_id': 10273}, {'_account_id': 10806}, {'_account_id': 11628}, {'_account_id': 11685}, {'_account_id': 12040}, {'_account_id': 14591}, {'_account_id': 16923}, {'_account_id': 21138}]","[{'number': 1, 'created': '2016-07-20 19:34:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/1c0e645421e632d737cc88936fda3ce028210449', 'message': 'Rewrite create_load_balancer flow\n\nJoin two flows (create_lb_tf, post_lb_amp_assoc) into one\n\nChange-Id: I68deb7a9795cbb135dbbef5dea0bfc6aa89db5b3\nCloses-Bug: #1552599\n'}, {'number': 2, 'created': '2016-07-29 18:57:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/b77c039ecbefcd7b6cba51daa3b34645343741a8', 'message': 'Rewrite create_load_balancer flow\n\nJoin two flows (create_lb_tf, post_lb_amp_assoc) into one\n\nChange-Id: I68deb7a9795cbb135dbbef5dea0bfc6aa89db5b3\nCloses-Bug: #1552599\n'}, {'number': 3, 'created': '2016-08-02 02:16:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/394fe6b05c25ad5f6fcc3f24a467451d40e676c2', 'message': 'Rewrite create_load_balancer flow\n\nJoin two flows (create_lb_tf, post_lb_amp_assoc) into one\n\nChange-Id: I68deb7a9795cbb135dbbef5dea0bfc6aa89db5b3\nCloses-Bug: #1552599\n'}, {'number': 4, 'created': '2016-08-09 20:04:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/d9289b267c32cf2b3a36e84896c0f4aecd28efcc', 'message': 'Rewrite create_load_balancer flow\n\nJoin two flows (create_lb_tf, post_lb_amp_assoc) into one\n\nChange-Id: I68deb7a9795cbb135dbbef5dea0bfc6aa89db5b3\nCloses-Bug: #1552599\n'}, {'number': 5, 'created': '2016-08-28 14:46:52.000000000', 'files': ['octavia/tests/unit/controller/worker/test_controller_worker.py', 'octavia/controller/worker/flows/load_balancer_flows.py', 'tools/flow-list.txt', 'octavia/controller/worker/controller_worker.py', 'tools/create_flow_docs.py', 'octavia/tests/unit/controller/worker/flows/test_load_balancer_flows.py'], 'web_link': 'https://opendev.org/openstack/octavia/commit/aae434e19acf8581df54d822265ae29caf70a8c0', 'message': 'Rewrite create_load_balancer flow\n\nJoin two flows (create_lb_tf, post_lb_amp_assoc) into one\n\nChange-Id: I68deb7a9795cbb135dbbef5dea0bfc6aa89db5b3\nCloses-Bug: #1552599\n'}]",5,345003,aae434e19acf8581df54d822265ae29caf70a8c0,38,10,5,14591,,,0,"Rewrite create_load_balancer flow

Join two flows (create_lb_tf, post_lb_amp_assoc) into one

Change-Id: I68deb7a9795cbb135dbbef5dea0bfc6aa89db5b3
Closes-Bug: #1552599
",git fetch https://review.opendev.org/openstack/octavia refs/changes/03/345003/4 && git format-patch -1 --stdout FETCH_HEAD,"['octavia/tests/unit/controller/worker/test_controller_worker.py', 'octavia/controller/worker/flows/load_balancer_flows.py', 'octavia/controller/worker/controller_worker.py', 'octavia/tests/unit/controller/worker/flows/test_load_balancer_flows.py']",4,1c0e645421e632d737cc88936fda3ce028210449,bug/1552599," def test_get_create_load_balancer_flows_single_listeners( self, mock_get_net_driver): create_flow = ( self.LBFlow.get_create_load_balancer_flow( constants.TOPOLOGY_SINGLE, True self.assertIsInstance(create_flow, flow.Flow) self.assertIn(constants.LOADBALANCER_ID, create_flow.requires) self.assertIn(constants.UPDATE_DICT, create_flow.requires) self.assertIn(constants.LOADBALANCER, create_flow.provides) self.assertIn(constants.LISTENERS, create_flow.provides) self.assertIn(constants.AMPHORA, create_flow.provides) self.assertIn(constants.AMPHORA_ID, create_flow.provides) self.assertIn(constants.COMPUTE_ID, create_flow.provides) self.assertIn(constants.COMPUTE_OBJ, create_flow.provides) self.assertIn(constants.LOADBALANCER, create_flow.provides) self.assertIn(constants.DELTAS, create_flow.provides) self.assertIn(constants.ADDED_PORTS, create_flow.provides) self.assertIn(constants.VIP, create_flow.provides) self.assertIn(constants.AMPS_DATA, create_flow.provides) create_flow.provides) self.assertEqual(2, len(create_flow.requires)) self.assertEqual(12, len(create_flow.provides), create_flow.provides) def test_get_create_load_balancer_flows_active_standby_listeners( self, mock_get_net_driver): create_flow = ( self.LBFlow.get_create_load_balancer_flow( constants.TOPOLOGY_ACTIVE_STANDBY, True self.assertIsInstance(create_flow, flow.Flow) self.assertIn(constants.LOADBALANCER_ID, create_flow.requires) self.assertIn(constants.UPDATE_DICT, create_flow.requires) self.assertIn(constants.LOADBALANCER, create_flow.provides) self.assertIn(constants.LISTENERS, create_flow.provides) self.assertIn(constants.AMPHORA, create_flow.provides) self.assertIn(constants.AMPHORA_ID, create_flow.provides) self.assertIn(constants.COMPUTE_ID, create_flow.provides) self.assertIn(constants.COMPUTE_OBJ, create_flow.provides) self.assertIn(constants.LOADBALANCER, create_flow.provides) self.assertIn(constants.DELTAS, create_flow.provides) self.assertIn(constants.ADDED_PORTS, create_flow.provides) self.assertIn(constants.VIP, create_flow.provides) self.assertIn(constants.AMPS_DATA, create_flow.provides) create_flow.provides) self.assertEqual(2, len(create_flow.requires)) self.assertEqual(12, len(create_flow.provides), create_flow.provides)"," def test_get_create_load_balancer_graph_flows(self, mock_get_net_driver): allocate_amp_flow, post_amp_flow = ( self.LBFlow.get_create_load_balancer_graph_flows( constants.TOPOLOGY_SINGLE, '123' self.assertIsInstance(allocate_amp_flow, flow.Flow) self.assertIn(constants.LOADBALANCER_ID, allocate_amp_flow.requires) self.assertIn(constants.AMPHORA, allocate_amp_flow.provides) self.assertIn(constants.AMPHORA_ID, allocate_amp_flow.provides) self.assertIn(constants.COMPUTE_ID, allocate_amp_flow.provides) self.assertIn(constants.COMPUTE_OBJ, allocate_amp_flow.provides) self.assertEqual(1, len(allocate_amp_flow.requires)) self.assertEqual(5, len(allocate_amp_flow.provides), allocate_amp_flow.provides) self.assertIsInstance(post_amp_flow, flow.Flow) self.assertIn(constants.LOADBALANCER_ID, post_amp_flow.requires) self.assertIn(constants.UPDATE_DICT, post_amp_flow.requires) self.assertIn(constants.LOADBALANCER, post_amp_flow.provides) self.assertIn(constants.DELTAS, post_amp_flow.provides) self.assertIn(constants.ADDED_PORTS, post_amp_flow.provides) self.assertIn(constants.VIP, post_amp_flow.provides) self.assertIn(constants.AMPS_DATA, post_amp_flow.provides) post_amp_flow.provides) self.assertEqual(2, len(post_amp_flow.requires)) self.assertEqual(7, len(post_amp_flow.provides)) # Test Active/Standby allocate_amp_flow, post_amp_flow = ( self.LBFlow.get_create_load_balancer_graph_flows( constants.TOPOLOGY_ACTIVE_STANDBY, '123' self.assertIsInstance(allocate_amp_flow, flow.Flow) self.assertIn(constants.LOADBALANCER_ID, allocate_amp_flow.requires) self.assertIn(constants.AMPHORA, allocate_amp_flow.provides) self.assertIn(constants.AMPHORA_ID, allocate_amp_flow.provides) self.assertIn(constants.COMPUTE_ID, allocate_amp_flow.provides) self.assertIn(constants.COMPUTE_OBJ, allocate_amp_flow.provides) self.assertEqual(1, len(allocate_amp_flow.requires)) self.assertEqual(5, len(allocate_amp_flow.provides)) self.assertIsInstance(post_amp_flow, flow.Flow) self.assertIn(constants.LOADBALANCER_ID, post_amp_flow.requires) self.assertIn(constants.UPDATE_DICT, post_amp_flow.requires) self.assertIn(constants.LOADBALANCER, post_amp_flow.provides) self.assertIn(constants.DELTAS, post_amp_flow.provides) self.assertIn(constants.ADDED_PORTS, post_amp_flow.provides) self.assertIn(constants.VIP, post_amp_flow.provides) self.assertIn(constants.AMPS_DATA, post_amp_flow.provides) post_amp_flow.provides) self.assertEqual(2, len(post_amp_flow.requires)) self.assertEqual(7, len(post_amp_flow.provides))",219,237
openstack%2Fshade~master~I416a7077bdd3427262243d8a39b6ed6b35ae4018,openstack/shade,master,I416a7077bdd3427262243d8a39b6ed6b35ae4018,Add submit_function method to TaskManager,MERGED,2016-08-22 13:31:49.000000000,2016-08-29 19:03:46.000000000,2016-08-29 19:03:46.000000000,"[{'_account_id': 2}, {'_account_id': 3}, {'_account_id': 3099}]","[{'number': 1, 'created': '2016-08-22 13:31:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/shade/commit/fb3254582c4819c550367d763c154e3cb33121a7', 'message': 'Add submit_function method to TaskManager\n\nTaskManager operates on Tasks - which is awesome for things like shade\nand nodepool where the discrete actions embodied by a task can be\npre-conceived. However, making a task class is a pretty heavy weight\noperation to require for ad-hoc tasks. Luckily, Python lets us create\nclasses and closures. Add a method that allows someone to pass in a\ncallable or the name of a callable that should be found on client.\n\nChange-Id: I416a7077bdd3427262243d8a39b6ed6b35ae4018\n'}, {'number': 2, 'created': '2016-08-22 14:41:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/shade/commit/225aa8b236e72517b4eff7143ebcdee0423b0609', 'message': 'Add submit_function method to TaskManager\n\nTaskManager operates on Tasks - which is awesome for things like shade\nand nodepool where the discrete actions embodied by a task can be\npre-conceived. However, making a task class is a pretty heavy weight\noperation to require for ad-hoc tasks. Luckily, Python lets us create\nclasses and closures. Add a method that allows someone to pass in a\ncallable or the name of a callable that should be found on client.\n\nChange-Id: I416a7077bdd3427262243d8a39b6ed6b35ae4018\n'}, {'number': 3, 'created': '2016-08-25 12:42:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/shade/commit/7117a3c6560a8066244e519d212addf43084b046', 'message': 'Add submit_function method to TaskManager\n\nTaskManager operates on Tasks - which is awesome for things like shade\nand nodepool where the discrete actions embodied by a task can be\npre-conceived. However, making a task class is a pretty heavy weight\noperation to require for ad-hoc tasks. Luckily, Python lets us create\nclasses and closures. Add a method that allows someone to pass in a\ncallable or the name of a callable that should be found on client.\n\nChange-Id: I416a7077bdd3427262243d8a39b6ed6b35ae4018\n'}, {'number': 4, 'created': '2016-08-27 18:32:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/shade/commit/0ed23e4d6b49617bea19f7c2229484152f6de135', 'message': 'Add submit_function method to TaskManager\n\nTaskManager operates on Tasks - which is awesome for things like shade\nand nodepool where the discrete actions embodied by a task can be\npre-conceived. However, making a task class is a pretty heavy weight\noperation to require for ad-hoc tasks. Luckily, Python lets us create\nclasses and closures. Add a method that allows someone to pass in a\ncallable or the name of a callable that should be found on client.\n\nChange-Id: I416a7077bdd3427262243d8a39b6ed6b35ae4018\n'}, {'number': 5, 'created': '2016-08-29 16:45:08.000000000', 'files': ['shade/task_manager.py'], 'web_link': 'https://opendev.org/openstack/shade/commit/522db8e6e49752da203cc3532bebc14014b6c076', 'message': 'Add submit_function method to TaskManager\n\nTaskManager operates on Tasks - which is awesome for things like shade\nand nodepool where the discrete actions embodied by a task can be\npre-conceived. However, making a task class is a pretty heavy weight\noperation to require for ad-hoc tasks. Luckily, Python lets us create\nclasses and closures. Add a method that allows someone to pass in a\ncallable or the name of a callable that should be found on client.\n\nChange-Id: I416a7077bdd3427262243d8a39b6ed6b35ae4018\n'}]",0,358647,522db8e6e49752da203cc3532bebc14014b6c076,16,3,5,2,,,0,"Add submit_function method to TaskManager

TaskManager operates on Tasks - which is awesome for things like shade
and nodepool where the discrete actions embodied by a task can be
pre-conceived. However, making a task class is a pretty heavy weight
operation to require for ad-hoc tasks. Luckily, Python lets us create
classes and closures. Add a method that allows someone to pass in a
callable or the name of a callable that should be found on client.

Change-Id: I416a7077bdd3427262243d8a39b6ed6b35ae4018
",git fetch https://review.opendev.org/openstack/shade refs/changes/47/358647/2 && git format-patch -1 --stdout FETCH_HEAD,['shade/task_manager.py'],1,fb3254582c4819c550367d763c154e3cb33121a7,ksa-task-manager,"def _result_filter_cb(result): return result def generate_task_class(method, result_filter_cb): class RunTask(Task): def __init__(self, **kw): super(RunTask, self).__init__(**kw) if callable(method): self.name = method.__name__ else: self.name = method self._method = method def wait(self, raw=False): super(RequestTask, self).wait() if raw: # Do NOT convert the result. return self._result return result_filter_cb(self._result) def main(self, client): if callable(self._method): return method(**self.args) else: meth = getattr(client, self._method) return meth(**self.args) def __init__(self, client, name, result_filter_cb=None): if not result_filter_cb: self._result_filter_cb = _result_filter_cb else: self._result_filter_cb = result_filter_cb def submit_function(self, method, result_filter_cb=None, **kwargs): """""" Allows submitting an arbitrary method for work. :param method: Method to run in the TaskManager. Can be either the name of a method to find on self.client, or a callable. """""" if not result_filter_cb: result_filter_cb = self._result_filter_cb task_class = generate_task_class(method, result_filter_cb) return self.manager.submitTask(task_class(**kwargs))"," def __init__(self, client, name):",48,1
openstack%2Ffuel-nailgun-extension-cluster-upgrade~master~Iea2301c95ec84e10cda8e1437f85f10c0c3e5437,openstack/fuel-nailgun-extension-cluster-upgrade,master,Iea2301c95ec84e10cda8e1437f85f10c0c3e5437,Return VIPs on the clone operation,MERGED,2016-08-29 10:46:25.000000000,2016-08-29 19:02:18.000000000,2016-08-29 19:01:07.000000000,"[{'_account_id': 3}, {'_account_id': 708}, {'_account_id': 1531}, {'_account_id': 20384}, {'_account_id': 20656}]","[{'number': 1, 'created': '2016-08-29 10:46:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-nailgun-extension-cluster-upgrade/commit/41148671bd761a22ab602732d7f8c17331c3b3c5', 'message': 'Return VIPs on the clone operation\n\nChange-Id: Iea2301c95ec84e10cda8e1437f85f10c0c3e5437\nCloses-Bug: #1617943\n'}, {'number': 2, 'created': '2016-08-29 16:41:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-nailgun-extension-cluster-upgrade/commit/b4cd23cab8b44c21c41a0b5955ac70af4a93e9fc', 'message': 'Return VIPs on the clone operation\n\nThe test was also fixed and returned to the integrational manner.\n\nChange-Id: Iea2301c95ec84e10cda8e1437f85f10c0c3e5437\nCloses-Bug: #1617943\n'}, {'number': 3, 'created': '2016-08-29 16:45:34.000000000', 'files': ['cluster_upgrade/handlers.py', 'cluster_upgrade/tests/test_handlers.py'], 'web_link': 'https://opendev.org/openstack/fuel-nailgun-extension-cluster-upgrade/commit/5ead3bf1b7957c3e3d9e42be6a31e82ea4e17cfc', 'message': 'Return VIPs on the clone operation\n\nThe test was also fixed and returned to the integrational manner.\n\nChange-Id: Iea2301c95ec84e10cda8e1437f85f10c0c3e5437\nCloses-Bug: #1617943\n'}]",4,362004,5ead3bf1b7957c3e3d9e42be6a31e82ea4e17cfc,21,5,3,1531,,,0,"Return VIPs on the clone operation

The test was also fixed and returned to the integrational manner.

Change-Id: Iea2301c95ec84e10cda8e1437f85f10c0c3e5437
Closes-Bug: #1617943
",git fetch https://review.opendev.org/openstack/fuel-nailgun-extension-cluster-upgrade refs/changes/04/362004/3 && git format-patch -1 --stdout FETCH_HEAD,['cluster_upgrade/handlers.py'],1,41148671bd761a22ab602732d7f8c17331c3b3c5,bug/1617943, @base.serialize cluster_vips = objects.IPAddrCollection.get_vips_by_cluster_id( cluster.id) return objects.IPAddrCollection.to_list(cluster_vips),,4,0
openstack%2Fshade~master~Id5c8caa924e8abbecef26d54d225bb10e9676d5d,openstack/shade,master,Id5c8caa924e8abbecef26d54d225bb10e9676d5d,Refactor TaskManager to be more generic,MERGED,2016-08-22 13:31:49.000000000,2016-08-29 19:01:02.000000000,2016-08-29 19:01:02.000000000,"[{'_account_id': 2}, {'_account_id': 3}, {'_account_id': 2903}, {'_account_id': 3099}]","[{'number': 1, 'created': '2016-08-22 13:31:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/shade/commit/01d43b6ae7f2d9e48d48592f45d397812f4a032e', 'message': 'Refactor TaskManager to be more generic\n\nIn preparation for maybe putting TaskManager into keystoneauth, we need\nto make the shade/nodepool things in it be explicitly shade/nodepool\nthings, and the base classes actually be generic.\n\nChange-Id: Id5c8caa924e8abbecef26d54d225bb10e9676d5d\n'}, {'number': 2, 'created': '2016-08-22 14:41:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/shade/commit/21cdb75d01718d8f4126ddee6da5a2752e8c4c2d', 'message': 'Refactor TaskManager to be more generic\n\nThe functionality that TaskManager represents could provide value to a\nlot of people if we put it into the guts of keystoneauth so that a\nperson could do rate-limiting on all REST operations. It would also\ncatch some of the ""hidden"" operations, like fetching a token.\nAlso, TaskManager is a _very_ stable set of code, so moving it a little\nfurther away shouldn\'t run the risk of deep/long bug chasing.\n\nIn preparation for that, we need to make the shade/nodepool things in\nit be explicitly shade/nodepool things, and the base classes actually\nbe generic. Doing the refactoring here first reduces the complexity of a\nmove. Next step would be adding this version of TaskManager to ksa, then\nin a subsequent patch we can remove it from shade. If we never do that,\nnothing in this should hurt anything.\n\nChange-Id: Id5c8caa924e8abbecef26d54d225bb10e9676d5d\n'}, {'number': 3, 'created': '2016-08-25 12:42:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/shade/commit/120ea1de3e220e8a558a30d743df3ad37067a45b', 'message': 'Refactor TaskManager to be more generic\n\nThe functionality that TaskManager represents could provide value to a\nlot of people if we put it into the guts of keystoneauth so that a\nperson could do rate-limiting on all REST operations. It would also\ncatch some of the ""hidden"" operations, like fetching a token.\nAlso, TaskManager is a _very_ stable set of code, so moving it a little\nfurther away shouldn\'t run the risk of deep/long bug chasing.\n\nIn preparation for that, we need to make the shade/nodepool things in\nit be explicitly shade/nodepool things, and the base classes actually\nbe generic. Doing the refactoring here first reduces the complexity of a\nmove. Next step would be adding this version of TaskManager to ksa, then\nin a subsequent patch we can remove it from shade. If we never do that,\nnothing in this should hurt anything.\n\nChange-Id: Id5c8caa924e8abbecef26d54d225bb10e9676d5d\n'}, {'number': 4, 'created': '2016-08-27 18:31:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/shade/commit/deb0e9599d552fd7f7419fb8f90c71e76cca9d41', 'message': 'Refactor TaskManager to be more generic\n\nThe functionality that TaskManager represents could provide value to a\nlot of people if we put it into the guts of keystoneauth so that a\nperson could do rate-limiting on all REST operations. It would also\ncatch some of the ""hidden"" operations, like fetching a token.\nAlso, TaskManager is a _very_ stable set of code, so moving it a little\nfurther away shouldn\'t run the risk of deep/long bug chasing.\n\nIn preparation for that, we need to make the shade/nodepool things in\nit be explicitly shade/nodepool things, and the base classes actually\nbe generic. Doing the refactoring here first reduces the complexity of a\nmove. Next step would be adding this version of TaskManager to ksa, then\nin a subsequent patch we can remove it from shade. If we never do that,\nnothing in this should hurt anything.\n\nChange-Id: Id5c8caa924e8abbecef26d54d225bb10e9676d5d\n'}, {'number': 5, 'created': '2016-08-29 16:44:50.000000000', 'files': ['shade/task_manager.py'], 'web_link': 'https://opendev.org/openstack/shade/commit/24a61fc53d0a9dc560859bb816796431e5e00cad', 'message': 'Refactor TaskManager to be more generic\n\nThe functionality that TaskManager represents could provide value to a\nlot of people if we put it into the guts of keystoneauth so that a\nperson could do rate-limiting on all REST operations. It would also\ncatch some of the ""hidden"" operations, like fetching a token.\nAlso, TaskManager is a _very_ stable set of code, so moving it a little\nfurther away shouldn\'t run the risk of deep/long bug chasing.\n\nIn preparation for that, we need to make the shade/nodepool things in\nit be explicitly shade/nodepool things, and the base classes actually\nbe generic. Doing the refactoring here first reduces the complexity of a\nmove. Next step would be adding this version of TaskManager to ksa, then\nin a subsequent patch we can remove it from shade. If we never do that,\nnothing in this should hurt anything.\n\nChange-Id: Id5c8caa924e8abbecef26d54d225bb10e9676d5d\n'}]",5,358646,24a61fc53d0a9dc560859bb816796431e5e00cad,22,4,5,2,,,0,"Refactor TaskManager to be more generic

The functionality that TaskManager represents could provide value to a
lot of people if we put it into the guts of keystoneauth so that a
person could do rate-limiting on all REST operations. It would also
catch some of the ""hidden"" operations, like fetching a token.
Also, TaskManager is a _very_ stable set of code, so moving it a little
further away shouldn't run the risk of deep/long bug chasing.

In preparation for that, we need to make the shade/nodepool things in
it be explicitly shade/nodepool things, and the base classes actually
be generic. Doing the refactoring here first reduces the complexity of a
move. Next step would be adding this version of TaskManager to ksa, then
in a subsequent patch we can remove it from shade. If we never do that,
nothing in this should hurt anything.

Change-Id: Id5c8caa924e8abbecef26d54d225bb10e9676d5d
",git fetch https://review.opendev.org/openstack/shade refs/changes/46/358646/2 && git format-patch -1 --stdout FETCH_HEAD,['shade/task_manager.py'],1,01d43b6ae7f2d9e48d48592f45d397812f4a032e,ksa-task-manager,"def _is_listlike(obj): # NOTE(Shrews): Since the client API might decide to subclass one # of these result types, we use isinstance() here instead of type(). return ( isinstance(obj, list) or isinstance(obj, types.GeneratorType)) def _is_dictlike(obj): # NOTE(Shrews): Since the client API might decide to subclass one # of these result types, we use isinstance() here instead of type(). return ( not isinstance(obj, bool) and not isinstance(obj, int) and not isinstance(obj, float) and not isinstance(obj, six.string_types) and not isinstance(obj, set) and not isinstance(obj, tuple) and not isinstance(obj, types.GeneratorType)) class BaseTask(object): self.name = type(self).__name__ self._result = result return self._resultclass Task(BaseTask): """""" Shade specific additions to the BaseTask Interface. """""" def wait(self, raw=False): super(Task, self).wait() if raw: # Do NOT convert the result. return self._result if _is_listlike(self._result): return meta.obj_list_to_dict(self._result) elif _is_dictlike(self._result): return meta.obj_to_dict(self._result) else: return self._result class RequestTask(BaseTask): """""" Extensions to the Shade Tasks to handle raw requests """""" def wait(self, raw=False): super(RequestTask, self).wait() if raw: # Do NOT convert the result. return self._result if _is_listlike(self._result): new_list = [] for obj in self._result: if _is_dictlike(obj): obj['x_openstack_request_ids'] = [self._request_id] new_list.append(obj) self._result = new_list elif _is_dictlike(self._result): self._result['x_openstack_request_ids'] = [self._request_id] return self._result log = _log.setup_logging(__name__) ""Manager %s running task %s"" % (self.name, task.name)) self.name, task.name, (end - start)))","class Task(object): self.requests = False self._request_id = None if self.requests: self._response, self._result = result else: self._result = result if raw: # Do NOT convert the result. return self._result # NOTE(Shrews): Since the client API might decide to subclass one # of these result types, we use isinstance() here instead of type(). if (isinstance(self._result, list) or isinstance(self._result, types.GeneratorType)): return meta.obj_list_to_dict( self._result, request_id=self._request_id) elif (not isinstance(self._result, bool) and not isinstance(self._result, int) and not isinstance(self._result, float) and not isinstance(self._result, str) and not isinstance(self._result, set) and not isinstance(self._result, tuple) and not isinstance(self._result, types.GeneratorType)): return meta.obj_to_dict(self._result, request_id=self._request_id) else: return self._resultclass RequestTask(Task): log = _log.setup_logging(""shade.TaskManager"") ""Manager %s running task %s"" % (self.name, type(task).__name__)) self.name, type(task).__name__, (end - start)))",67,31
openstack%2Fpython-brick-cinderclient-ext~master~Ib8e3f5c2d1b006d2d2255760efd2add9b5c3babd,openstack/python-brick-cinderclient-ext,master,Ib8e3f5c2d1b006d2d2255760efd2add9b5c3babd,Added release notes for attach/detach features.,MERGED,2016-08-29 08:45:59.000000000,2016-08-29 18:58:23.000000000,2016-08-29 18:58:23.000000000,"[{'_account_id': 3}, {'_account_id': 6491}, {'_account_id': 11904}]","[{'number': 1, 'created': '2016-08-29 08:45:59.000000000', 'files': ['releasenotes/notes/local-attach-feature-474283267873f091.yaml'], 'web_link': 'https://opendev.org/openstack/python-brick-cinderclient-ext/commit/852f53984bf249be79cb5a2805ca687eb942c92d', 'message': 'Added release notes for attach/detach features.\n\nPatches Ibd7616273342ff27628fb4abf48dd16847b2a636 and\nI558ba135581c96358fdb96f7bd8d24e0dbdae427 were merged without release\nnotes. These features is very important for current release and should\nbe anounced in release notes.\n\nChange-Id: Ib8e3f5c2d1b006d2d2255760efd2add9b5c3babd\n'}]",0,361945,852f53984bf249be79cb5a2805ca687eb942c92d,7,3,1,1736,,,0,"Added release notes for attach/detach features.

Patches Ibd7616273342ff27628fb4abf48dd16847b2a636 and
I558ba135581c96358fdb96f7bd8d24e0dbdae427 were merged without release
notes. These features is very important for current release and should
be anounced in release notes.

Change-Id: Ib8e3f5c2d1b006d2d2255760efd2add9b5c3babd
",git fetch https://review.opendev.org/openstack/python-brick-cinderclient-ext refs/changes/45/361945/1 && git format-patch -1 --stdout FETCH_HEAD,['releasenotes/notes/local-attach-feature-474283267873f091.yaml'],1,852f53984bf249be79cb5a2805ca687eb942c92d,attach-detach-relnotes,--- features: - Local attach/detach features implemented Introduced new Python and CLI APIs to attach Cinder volumes to any host including baremetal instances and containers. Current implementation supports only iSCSI and RBD protocols and it was tested only on Linux hosts. ,,7,0
openstack%2Fpython-brick-cinderclient-ext~master~Ia05e3edebf2d1ffb046c56e78c81d469856c8f46,openstack/python-brick-cinderclient-ext,master,Ia05e3edebf2d1ffb046c56e78c81d469856c8f46,Require root permissions for local-attach and local-detach CLI,MERGED,2016-08-29 08:38:34.000000000,2016-08-29 18:58:17.000000000,2016-08-29 18:58:17.000000000,"[{'_account_id': 3}, {'_account_id': 6491}, {'_account_id': 11904}]","[{'number': 1, 'created': '2016-08-29 08:38:34.000000000', 'files': ['releasenotes/notes/require-root-for-attach-detach-commands-c3a63f6c5213e28c.yaml', 'brick_cinderclient_ext/__init__.py'], 'web_link': 'https://opendev.org/openstack/python-brick-cinderclient-ext/commit/acaeff2187874d4883d0ac02f932216e26347e2b', 'message': 'Require root permissions for local-attach and local-detach CLI\n\nlocal-attach and local-detach require root permissions to execute\nsuccessfully. This patch adds checks if user has such privileges.\n\nChange-Id: Ia05e3edebf2d1ffb046c56e78c81d469856c8f46\n'}]",0,361938,acaeff2187874d4883d0ac02f932216e26347e2b,7,3,1,1736,,,0,"Require root permissions for local-attach and local-detach CLI

local-attach and local-detach require root permissions to execute
successfully. This patch adds checks if user has such privileges.

Change-Id: Ia05e3edebf2d1ffb046c56e78c81d469856c8f46
",git fetch https://review.opendev.org/openstack/python-brick-cinderclient-ext refs/changes/38/361938/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/require-root-for-attach-detach-commands-c3a63f6c5213e28c.yaml', 'brick_cinderclient_ext/__init__.py']",2,acaeff2187874d4883d0ac02f932216e26347e2b,root-attach-detach,@brick_utils.require_root@brick_utils.require_root,,5,0
openstack%2Freleases~master~Ic4a2900ba18099689cab6eaee797d745ab06cd30,openstack/releases,master,Ic4a2900ba18099689cab6eaee797d745ab06cd30,Release ironic-staging-drivers 0.3.0,MERGED,2016-08-29 13:36:04.000000000,2016-08-29 18:53:24.000000000,2016-08-29 18:53:24.000000000,"[{'_account_id': 3}, {'_account_id': 2472}]","[{'number': 1, 'created': '2016-08-29 13:36:04.000000000', 'files': ['deliverables/_independent/ironic-staging-drivers.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/293412ca92d923083a2bb1bfd9dc8d5ff27a2c92', 'message': 'Release ironic-staging-drivers 0.3.0\n\nChange-Id: Ic4a2900ba18099689cab6eaee797d745ab06cd30\n'}]",0,362117,293412ca92d923083a2bb1bfd9dc8d5ff27a2c92,7,2,1,6773,,,0,"Release ironic-staging-drivers 0.3.0

Change-Id: Ic4a2900ba18099689cab6eaee797d745ab06cd30
",git fetch https://review.opendev.org/openstack/releases refs/changes/17/362117/1 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/_independent/ironic-staging-drivers.yaml'],1,293412ca92d923083a2bb1bfd9dc8d5ff27a2c92,ironic-staging-drivers,--- launchpad: ironic-staging-drivers team: ironic-staging-drivers send-announcements-to: openstack-dev@lists.openstack.org releases: - version: 0.3.0 projects: - repo: openstack/ironic-staging-drivers hash: f3698f57edfc1ba445dd5e52668379686fdf32db ,,9,0
openstack%2Fshade~master~I9d3ececbf5de8b2763da0716ef9bec77b8a0b11e,openstack/shade,master,I9d3ececbf5de8b2763da0716ef9bec77b8a0b11e,Cleanup old internal/external network handling,MERGED,2016-08-29 15:58:04.000000000,2016-08-29 18:51:53.000000000,2016-08-29 18:51:53.000000000,"[{'_account_id': 1}, {'_account_id': 3}, {'_account_id': 3099}]","[{'number': 1, 'created': '2016-08-29 15:58:04.000000000', 'files': ['shade/openstackcloud.py'], 'web_link': 'https://opendev.org/openstack/shade/commit/cf9989806d853032d87e55bdfaa1b91d81a1efaa', 'message': ""Cleanup old internal/external network handling\n\nWe don't really need the non-ipv4/ipv6 versions of these anymore, but we\nkeep them for backwards compat. Pull out the processing of them and have\nthem instead rely on the underlying ipv4/ipv6 code.\n\nChange-Id: I9d3ececbf5de8b2763da0716ef9bec77b8a0b11e\n""}]",0,362223,cf9989806d853032d87e55bdfaa1b91d81a1efaa,7,3,1,2,,,0,"Cleanup old internal/external network handling

We don't really need the non-ipv4/ipv6 versions of these anymore, but we
keep them for backwards compat. Pull out the processing of them and have
them instead rely on the underlying ipv4/ipv6 code.

Change-Id: I9d3ececbf5de8b2763da0716ef9bec77b8a0b11e
",git fetch https://review.opendev.org/openstack/shade refs/changes/23/362223/1 && git format-patch -1 --stdout FETCH_HEAD,['shade/openstackcloud.py'],1,cf9989806d853032d87e55bdfaa1b91d81a1efaa,, return list( set(self._external_ipv4_networks) | set(self._external_ipv6_networks)) return list( set(self._internal_ipv4_networks) | set(self._internal_ipv6_networks))," # The first two aren't useful to us anymore, but we still do them # because there are two methods that won't work without them self._external_network_names = cloud_config.get_external_networks() self._internal_network_names = cloud_config.get_internal_networks() self._external_networks = [] self._internal_networks = [] external_networks = [] internal_networks = [] # Old External networks if (network['name'] in self._external_network_names or network['id'] in self._external_network_names): external_networks.append(network) elif ((('router:external' in network and network['router:external']) or network.get('provider:physical_network')) and network['name'] not in self._internal_network_names and network['id'] not in self._internal_network_names): external_networks.append(network) # Old Internal networks if (network['name'] in self._internal_network_names or network['id'] in self._internal_network_names): internal_networks.append(network) elif (not network.get('router:external', False) and not network.get('provider:physical_network') and network['name'] not in self._external_network_names and network['id'] not in self._external_network_names): internal_networks.append(network) for net_name in self._external_network_names: if net_name not in [net['name'] for net in external_networks]: raise OpenStackCloudException( ""Networks: {network} was provided for external"" "" access and those networks could not be found"".format( network=net_name)) for net_name in self._internal_network_names: if net_name not in [net['name'] for net in internal_networks]: raise OpenStackCloudException( ""Networks: {network} was provided for internal"" "" access and those networks could not be found"".format( network=net_name)) self._external_networks = external_networks self._internal_networks = internal_networks return self._external_networks return self._internal_networks",6,47
openstack%2Fmagnum~master~Ia7efaed157971ad7631ddffb9c1400f3516720f0,openstack/magnum,master,Ia7efaed157971ad7631ddffb9c1400f3516720f0,Rename Bay to Cluster in docs,MERGED,2016-08-11 21:15:34.000000000,2016-08-29 18:48:23.000000000,2016-08-29 18:48:22.000000000,"[{'_account_id': 3}, {'_account_id': 668}, {'_account_id': 7230}, {'_account_id': 9591}, {'_account_id': 10206}, {'_account_id': 11536}, {'_account_id': 20498}, {'_account_id': 21469}, {'_account_id': 21660}]","[{'number': 1, 'created': '2016-08-11 21:15:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/c35d00f4503581afce91662efbc933ae70d902c8', 'message': '[WIP]Rename Bay to Cluster in docs\n\nThis is a continuation of patch 353726 and includes all of the\ndoc changes for replacing the term bay with cluster.\n\nChange-Id: Ia7efaed157971ad7631ddffb9c1400f3516720f0\nImplements: blueprint rename-bay-to-cluster\n'}, {'number': 2, 'created': '2016-08-11 21:33:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/225db42fc5199467f35dde4a25ea7c2c133bbb86', 'message': '[WIP]Rename Bay to Cluster in docs\n\nThis is a continuation of patch 353726 and includes all of the\ndoc changes for replacing the term bay with cluster.\n\nChange-Id: Ia7efaed157971ad7631ddffb9c1400f3516720f0\nImplements: blueprint rename-bay-to-cluster\n'}, {'number': 3, 'created': '2016-08-12 21:16:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/3d1e4d8bbdf4c1eca4d8f16c1b6fffdc1b26d0f5', 'message': '[WIP]Rename Bay to Cluster in docs\n\nThis is a continuation of patch 353726 and includes all of the\ndoc changes for replacing the term bay with cluster.\n\nChange-Id: Ia7efaed157971ad7631ddffb9c1400f3516720f0\nImplements: blueprint rename-bay-to-cluster\n'}, {'number': 4, 'created': '2016-08-15 15:58:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/f6c5f3322132a810b6fcf466312f1f5dc2ccec88', 'message': 'Rename Bay to Cluster in docs\n\nThis is a continuation of patch 353726 and includes all of the\ndoc changes for replacing the term bay with cluster and\nBayModel with ClusterTemplate.\n\nChange-Id: Ia7efaed157971ad7631ddffb9c1400f3516720f0\nImplements: blueprint rename-bay-to-cluster\n'}, {'number': 5, 'created': '2016-08-16 15:59:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/da5d9af50f33df349d7e2532cf185cda4ba615cc', 'message': 'Rename Bay to Cluster in docs\n\nThis is a continuation of patch 353726 and includes all of the\ndoc changes for replacing the term bay with cluster and\nBayModel with ClusterTemplate.\n\nChange-Id: Ia7efaed157971ad7631ddffb9c1400f3516720f0\nImplements: blueprint rename-bay-to-cluster\n'}, {'number': 6, 'created': '2016-08-16 20:06:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/2ef9a4dfc2c6cc4f9d6bbaaa1755b8e88c688873', 'message': 'Rename Bay to Cluster in docs\n\nThis is a continuation of patch 353726 and includes all of the\ndoc changes for replacing the term bay with cluster and\nBayModel with ClusterTemplate.\n\nChange-Id: Ia7efaed157971ad7631ddffb9c1400f3516720f0\nImplements: blueprint rename-bay-to-cluster\n'}, {'number': 7, 'created': '2016-08-22 17:14:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/1acf87e3822046e09fa80692a332fda55654e67e', 'message': 'Rename Bay to Cluster in docs\n\nThis is a continuation of patch 353726 and includes all of the\ndoc changes for replacing the term bay with cluster and\nBayModel with ClusterTemplate.\n\nChange-Id: Ia7efaed157971ad7631ddffb9c1400f3516720f0\nImplements: blueprint rename-bay-to-cluster\n'}, {'number': 8, 'created': '2016-08-26 19:20:12.000000000', 'files': ['doc/source/userguide.rst', 'doc/source/dev/manual-devstack.rst', 'doc/source/heat-templates.rst', 'doc/source/index.rst', 'doc/source/dev/functional-test.rst', 'doc/source/dev/kubernetes-load-balancer.rst', 'doc/source/install-guide-from-source.rst', 'doc/source/dev/quickstart.rst', 'doc/source/troubleshooting-guide.rst', 'doc/source/magnum-proxy.rst', 'doc/source/dev/cluster-type-definition.rst'], 'web_link': 'https://opendev.org/openstack/magnum/commit/584380f8ee3925545a39e6ec8dda5ece3aa930f2', 'message': 'Rename Bay to Cluster in docs\n\nThis is a continuation of patch 353726 and includes all of the\ndoc changes for replacing the term bay with cluster and\nBayModel with ClusterTemplate.\n\nChange-Id: Ia7efaed157971ad7631ddffb9c1400f3516720f0\nImplements: blueprint rename-bay-to-cluster\n'}]",219,354404,584380f8ee3925545a39e6ec8dda5ece3aa930f2,35,9,8,21469,,,0,"Rename Bay to Cluster in docs

This is a continuation of patch 353726 and includes all of the
doc changes for replacing the term bay with cluster and
BayModel with ClusterTemplate.

Change-Id: Ia7efaed157971ad7631ddffb9c1400f3516720f0
Implements: blueprint rename-bay-to-cluster
",git fetch https://review.opendev.org/openstack/magnum refs/changes/04/354404/8 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/userguide.rst', 'doc/source/dev/manual-devstack.rst', 'doc/source/heat-templates.rst', 'doc/source/index.rst', 'doc/source/dev/functional-test.rst', 'doc/source/dev/kubernetes-load-balancer.rst', 'doc/source/install-guide-from-source.rst', 'doc/source/dev/quickstart.rst', 'doc/source/dev/bay-template-example.rst', 'doc/source/magnum-proxy.rst', 'doc/source/troubleshooting-guide.rst']",11,c35d00f4503581afce91662efbc933ae70d902c8,bp/rename-bay-to-cluster,"My cluster-create takes a really long time If you are using devstack on a small VM, cluster-create will take a longMy cluster-create fails with error: ""Failed to create trustee XXX in domain XXX"" Check the `trustee for cluster`_ Kubernetes cluster-create failsSwarm cluster-create failsMesos cluster-create failsI deploy pods on Kubernetes cluster but the status stays ""Pending""I deploy pods and services on Kubernetes cluster but the app is not workingSwarm cluster is created successfully but I cannot deploy containersMesos cluster is created successfully but I cannot deploy containers on MarathonMy cluster-create fails with a resource error on docker_volumeA cluster is deployed by a set of heat stacks: one top level stack and several nested stack. The stack names are prefixed with the cluster name and the nested stack names contain descriptive internal names like *kube_masters*,To list the status of all the stacks for a cluster: heat stack-list -n | grep *cluster-name* If the cluster has failed, then one or more of the heat stacks would have failed. From the stack list above, look for the stacks that failed, thenTrustee for cluster ------------------- When a user creates a cluster, Magnum will dynamically create a service account for the creating cluster. The service account will be used by the cluster to access the OpenStack services (i.e. Neutron, Swift, etc.). A trust relationship will be created between the user who created the cluster (the ""trustor"") and the service account created for the cluster (the ""trustee""). For details, please refer <http://git.openstack.org/cgit/openstack/magnum/tree/specs/create-trustee-user-for-each-cluster.rst>`_.parameter ""external-network-id"" in the cluster model. The ""public"" network- If ""external-network-id"" is specified in the cluster model, does this network specified by ""dns-nameserver"" in the cluster model. in the cluster model, is it reachable and working?particular driver being used for the cluster.Flannel is the default network driver for Kubernetes clusters. Flannel isor Swarm cluster. Flannel provides a flat network space for the containers in the cluster:be able to access services from other containers in the cluster. This can beThe Flannel daemon is run as a systemd service on each node of the cluster. parameters from the cluster model.","My bay-create takes a really long time If you are using devstack on a small VM, bay-create will take a longMy bay-create fails with error: ""Failed to create trustee XXX in domain XXX"" Check the `trustee for bay`_ Kubernetes bay-create failsSwarm bay-create failsMesos bay-create failsI deploy pods on Kubernetes bay but the status stays ""Pending""I deploy pods and services on Kubernetes bay but the app is not workingSwarm bay is created successfully but I cannot deploy containersMesos bay is created successfully but I cannot deploy containers on MarathonMy bay-create fails with a resource error on docker_volumeA bay is deployed by a set of heat stacks: one top level stack and several nested stack. The stack names are prefixed with the bay name and the nested stack names contain descriptive internal names like *kube_masters*,To list the status of all the stacks for a bay: heat stack-list -n | grep *bay-name* If the bay has failed, then one or more of the heat stacks would have failed. From the stack list above, look for the stacks that failed, thenTrustee for bay --------------- When a user creates a bay, Magnum will dynamically create a service account for the creating bay. The service account will be used by the bay to access the OpenStack services (i.e. Neutron, Swift, etc.). A trust relationship will be created between the user who created the bay (the ""trustor"") and the service account created for the bay (the ""trustee""). For details, please refer <http://git.openstack.org/cgit/openstack/magnum/tree/specs/create-trustee-user-for-each-bay.rst>`_.parameter ""external-network-id"" in the bay model. The ""public"" network- If ""external-network-id"" is specified in the bay model, does this network specified by ""dns-nameserver"" in the bay model. in the bay model, is it reachable and working?particular driver being used for the bay.Flannel is the default network driver for Kubernetes bays. Flannel isor Swarm bay. Flannel provides a flat network space for the containers in the bay:be able to access services from other containers in the bay. This can beThe Flannel daemon is run as a systemd service on each node of the bay. parameters from the bay model.",607,580
openstack%2Freleases~master~I9940af93ef65448672d3230357a1320390b3060b,openstack/releases,master,I9940af93ef65448672d3230357a1320390b3060b,openstack-doc-tools 1.0.1 release,MERGED,2016-08-29 11:04:05.000000000,2016-08-29 18:47:33.000000000,2016-08-29 18:47:33.000000000,"[{'_account_id': 3}, {'_account_id': 2472}]","[{'number': 1, 'created': '2016-08-29 11:04:05.000000000', 'files': ['deliverables/_independent/openstack-doc-tools.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/7a5779c326363c466cc832fb1a48324b9767d49b', 'message': 'openstack-doc-tools 1.0.1 release\n\nQuick bug fix release to fix our publishing:\nFix path where some translated install guides get published.\n\nChange-Id: I9940af93ef65448672d3230357a1320390b3060b\n'}]",0,362021,7a5779c326363c466cc832fb1a48324b9767d49b,7,2,1,6547,,,0,"openstack-doc-tools 1.0.1 release

Quick bug fix release to fix our publishing:
Fix path where some translated install guides get published.

Change-Id: I9940af93ef65448672d3230357a1320390b3060b
",git fetch https://review.opendev.org/openstack/releases refs/changes/21/362021/1 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/_independent/openstack-doc-tools.yaml'],1,7a5779c326363c466cc832fb1a48324b9767d49b,doctools, - version: 1.0.1 projects: - repo: openstack/openstack-doc-tools hash: a9b18182238cf8b1f860de414a44d46ff8e69b2c,,4,0
openstack%2Fironic-python-agent~master~I53c6d6d3e53d9fac38c50faf065c131d3aa55224,openstack/ironic-python-agent,master,I53c6d6d3e53d9fac38c50faf065c131d3aa55224,Using assertIsNone() is preferred over assertEqual(),MERGED,2016-08-29 03:10:09.000000000,2016-08-29 18:43:18.000000000,2016-08-29 18:43:18.000000000,"[{'_account_id': 3}, {'_account_id': 7080}, {'_account_id': 10239}, {'_account_id': 10342}, {'_account_id': 13719}, {'_account_id': 18602}, {'_account_id': 20508}]","[{'number': 1, 'created': '2016-08-29 03:10:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/199b2728af76588a094b6adf053506b7bb3c5f1d', 'message': 'Using assertIsNone() is preferred over assertEqual()\n\nFollowing OpenStack Style Guidelines[1]:\nhttp://docs.openstack.org/developer/hacking/#unit-tests-and-assertraises\n\n[H203] Unit test assertions tend to give better messages for more specific assertions.\nAs a result, assertIsNone(...) is preferred over assertEqual(None, ...)\n\nChange-Id: I53c6d6d3e53d9fac38c50faf065c131d3aa55224\n'}, {'number': 2, 'created': '2016-08-29 05:10:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/0da9940885e666a505b5228754c21d09a08a3bf4', 'message': 'Using assertIsNone() is preferred over assertEqual()\n\nFollowing OpenStack Style Guidelines[1]:\nhttp://docs.openstack.org/developer/hacking/#unit-tests-and-assertraises\n\n[H203] Unit test assertions tend to give better messages for more specific assertions.\nAs a result, assertIsNone(...) is preferred over assertEqual(None, ...)\n\nChange-Id: I53c6d6d3e53d9fac38c50faf065c131d3aa55224\n'}, {'number': 3, 'created': '2016-08-29 05:22:40.000000000', 'files': ['ironic_python_agent/tests/unit/test_hardware.py'], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/814b60def3457751f5c4eed9befea2f9f0ec27cd', 'message': 'Using assertIsNone() is preferred over assertEqual()\n\nFollowing OpenStack Style Guidelines[1]:\nhttp://docs.openstack.org/developer/hacking/#unit-tests-and-assertraises\n\n[H203] Unit test assertions tend to give better messages for more specific assertions.\nAs a result, assertIsNone(...) is preferred over assertEqual(None, ...)\n\nChange-Id: I53c6d6d3e53d9fac38c50faf065c131d3aa55224\n'}]",2,361811,814b60def3457751f5c4eed9befea2f9f0ec27cd,15,7,3,22255,,,0,"Using assertIsNone() is preferred over assertEqual()

Following OpenStack Style Guidelines[1]:
http://docs.openstack.org/developer/hacking/#unit-tests-and-assertraises

[H203] Unit test assertions tend to give better messages for more specific assertions.
As a result, assertIsNone(...) is preferred over assertEqual(None, ...)

Change-Id: I53c6d6d3e53d9fac38c50faf065c131d3aa55224
",git fetch https://review.opendev.org/openstack/ironic-python-agent refs/changes/11/361811/3 && git format-patch -1 --stdout FETCH_HEAD,"['.idea/vcs.xml', 'ironic_python_agent/tests/unit/test_hardware.py']",2,199b2728af76588a094b6adf053506b7bb3c5f1d,fixassertEqual, self.assertIsNone(interfaces[0].lldp) self.assertIsNone(interfaces[0].lldp)," self.assertEqual(None, interfaces[0].lldp) self.assertEqual(None, interfaces[0].lldp)",8,2
openstack%2Ftripleo-common~master~I85fb6c1939e711887b2ee91c9cefa41a3da681a3,openstack/tripleo-common,master,I85fb6c1939e711887b2ee91c9cefa41a3da681a3,Workflows to load validations,MERGED,2016-08-11 08:32:21.000000000,2016-08-29 18:38:01.000000000,2016-08-29 18:38:01.000000000,"[{'_account_id': 3}, {'_account_id': 4330}, {'_account_id': 7509}, {'_account_id': 9712}, {'_account_id': 10112}, {'_account_id': 13039}, {'_account_id': 17623}]","[{'number': 1, 'created': '2016-08-11 08:32:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/ba8980e126854ca2788f624b638a62ba0867bc81', 'message': 'Workflows to load validations\n\nThis commit adds workflow to list available validations and validation\ngroups.\n\nChange-Id: I85fb6c1939e711887b2ee91c9cefa41a3da681a3\n'}, {'number': 2, 'created': '2016-08-19 12:42:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/5e218fae2a2913f7fc0d4e2c6b1ff32d6bf9ed55', 'message': 'Workflows to load validations\n\nThis commit adds workflow to list available validations and validation\ngroups.\n\nChange-Id: I85fb6c1939e711887b2ee91c9cefa41a3da681a3\n'}, {'number': 3, 'created': '2016-08-19 14:34:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/b62d372c7401923ed302690483e1fe49b5d81e91', 'message': 'Workflows to load validations\n\nThis commit adds workflow to list available validations and validation\ngroups.\n\nChange-Id: I85fb6c1939e711887b2ee91c9cefa41a3da681a3\n'}, {'number': 4, 'created': '2016-08-24 18:07:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/3190dd155a1c9523e02cc175d73d840fdbc1c4e6', 'message': 'Workflows to load validations\n\nThis commit adds workflow to list available validations and validation\ngroups.\n\nChange-Id: I85fb6c1939e711887b2ee91c9cefa41a3da681a3\n'}, {'number': 5, 'created': '2016-08-25 14:21:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/bc151e370cace2f43a4a054771c11f88e9037325', 'message': 'Workflows to load validations\n\nThis commit adds workflow to list available validations and validation\ngroups.\n\nChange-Id: I85fb6c1939e711887b2ee91c9cefa41a3da681a3\n'}, {'number': 6, 'created': '2016-08-29 11:57:40.000000000', 'files': ['tripleo_common/tests/utils/test_validations.py', 'tripleo_common/constants.py', 'tripleo_common/utils/validations.py', 'workbooks/validations.yaml', 'tripleo_common/actions/validations.py', 'tripleo_common/tests/actions/test_validations.py', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/ceecdadbf46bef8c910aa251deb2f90555d4942f', 'message': 'Workflows to load validations\n\nThis commit adds workflow to list available validations and validation\ngroups.\n\nChange-Id: I85fb6c1939e711887b2ee91c9cefa41a3da681a3\n'}]",2,353898,ceecdadbf46bef8c910aa251deb2f90555d4942f,47,7,6,13039,,,0,"Workflows to load validations

This commit adds workflow to list available validations and validation
groups.

Change-Id: I85fb6c1939e711887b2ee91c9cefa41a3da681a3
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/98/353898/1 && git format-patch -1 --stdout FETCH_HEAD,"['tripleo_common/tests/utils/test_validations.py', 'tripleo_common/constants.py', 'tripleo_common/utils/validations.py', 'workbooks/validations.yaml', 'tripleo_common/actions/validations.py', 'setup.cfg', 'tripleo_common/tests/actions/test_validations.py']",7,ba8980e126854ca2788f624b638a62ba0867bc81,mistral-validations,"from tripleo_common.tests.utils import test_validations class ListValidationsActionTest(base.TestCase): @mock.patch('tripleo_common.utils.validations.load_validations') def test_run_default(self, mock_load_validations): mock_load_validations.return_value = 'list of validations' action = validations.ListValidationsAction() self.assertEqual('list of validations', action.run()) mock_load_validations.assert_called_once_with(groups=None) @mock.patch('tripleo_common.utils.validations.load_validations') def test_run_groups(self, mock_load_validations): mock_load_validations.return_value = 'list of validations' action = validations.ListValidationsAction(groups=['group1', 'group2']) self.assertEqual('list of validations', action.run()) mock_load_validations.assert_called_once_with(groups=['group1', 'group2']) class ListGroupsActionTest(base.TestCase): @mock.patch('tripleo_common.utils.validations.load_validations') def test_run(self, mock_load_validations): mock_load_validations.return_value = [ test_validations.VALIDATION_GROUPS_1_2_PARSED, test_validations.VALIDATION_GROUP_1_PARSED, test_validations.VALIDATION_WITH_METADATA_PARSED] action = validations.ListGroupsAction() self.assertEqual(set(['group1', 'group2']), action.run()) mock_load_validations.assert_called_once_with()",,255,1
openstack%2Fhorizon~master~Ib5ddc29fd94a72e530b81b8094c9a2c5c604b823,openstack/horizon,master,Ib5ddc29fd94a72e530b81b8094c9a2c5c604b823,Imported Translations from Zanata,MERGED,2016-08-27 08:39:43.000000000,2016-08-29 18:35:30.000000000,2016-08-29 18:35:30.000000000,"[{'_account_id': 3}, {'_account_id': 6914}, {'_account_id': 9576}]","[{'number': 1, 'created': '2016-08-27 08:39:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/cd346e47a1241bb529b00ad8a6c87980fb67bdae', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: Ib5ddc29fd94a72e530b81b8094c9a2c5c604b823\n'}, {'number': 2, 'created': '2016-08-28 08:37:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/4f4712912f2732da15a7f28ea61ccf69680b2e04', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: Ib5ddc29fd94a72e530b81b8094c9a2c5c604b823\n'}, {'number': 3, 'created': '2016-08-29 09:54:40.000000000', 'files': ['horizon/locale/ru/LC_MESSAGES/djangojs.po', 'openstack_dashboard/locale/ru/LC_MESSAGES/djangojs.po'], 'web_link': 'https://opendev.org/openstack/horizon/commit/0defe842a9dbf41be97b021dc5487e94f0ef45fe', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: Ib5ddc29fd94a72e530b81b8094c9a2c5c604b823\n'}]",0,361577,0defe842a9dbf41be97b021dc5487e94f0ef45fe,13,3,3,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
https://wiki.openstack.org/wiki/Translations/Infrastructure

Change-Id: Ib5ddc29fd94a72e530b81b8094c9a2c5c604b823
",git fetch https://review.opendev.org/openstack/horizon refs/changes/77/361577/1 && git format-patch -1 --stdout FETCH_HEAD,"['horizon/locale/ru/LC_MESSAGES/djangojs.po', 'openstack_dashboard/locale/ru/LC_MESSAGES/djangojs.po']",2,cd346e47a1241bb529b00ad8a6c87980fb67bdae,zanata/translations,"# Maxim Bozhenko <mbozhenko@gmail.com>, 2016. #zanata""Project-Id-Version: horizon 10.0.0.0b4.dev12\n""""POT-Creation-Date: 2016-08-26 16:05+0000\n""""PO-Revision-Date: 2016-08-26 01:03+0000\n"" ""Last-Translator: Maxim Bozhenko <mbozhenko@gmail.com>\n""msgid ""Charts"" msgstr """" ","""Project-Id-Version: horizon 10.0.0.0b4.dev6\n""""POT-Creation-Date: 2016-08-25 22:19+0000\n""""PO-Revision-Date: 2016-03-24 01:53+0000\n"" ""Last-Translator: Ilya Alekseyev <ilyaalekseyev@acm.org>\n""",86,8
openstack%2Fcinder~master~I3d0f22b81bc521054ff64867c42db9b0d928aa92,openstack/cinder,master,I3d0f22b81bc521054ff64867c42db9b0d928aa92,Quobyte volume driver should use DLM,MERGED,2016-07-27 20:14:10.000000000,2016-08-29 18:33:48.000000000,2016-08-28 21:24:34.000000000,"[{'_account_id': 3}, {'_account_id': 7173}, {'_account_id': 11904}, {'_account_id': 12825}, {'_account_id': 13915}, {'_account_id': 17630}, {'_account_id': 17775}, {'_account_id': 21976}]","[{'number': 1, 'created': '2016-07-27 20:14:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/66d6fb067888449ab9153e3bda67c1b01bcfb63a', 'message': 'quobyte volume driver should use DLM\n\nIn attempt to make Cinder HA A/A ready QuobyteDriver should start\nusing RemoteFSSnapDriverDistributed instead of RemoteFSSnapDriver,\nthis will change locked snapshot operations to use distributed lock manager.\n\nChange-Id: I3d0f22b81bc521054ff64867c42db9b0d928aa92\nCloses-bug: 1606698\n'}, {'number': 2, 'created': '2016-07-27 20:27:09.000000000', 'files': ['cinder/volume/drivers/quobyte.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/4739fef69633d7ebca677acce5b9868505d6b707', 'message': 'Quobyte volume driver should use DLM\n\nIn attempt to make Cinder HA A/A ready QuobyteDriver should start\nusing RemoteFSSnapDriverDistributed instead of RemoteFSSnapDriver,\nthis will change locked snapshot operations to use distributed\nlock manager.\n\nPartially implements: blueprint cinder-volume-active-active-support\nCloses-bug: 1606698\nChange-Id: I3d0f22b81bc521054ff64867c42db9b0d928aa92\n'}]",0,348020,4739fef69633d7ebca677acce5b9868505d6b707,33,8,2,12825,,,0,"Quobyte volume driver should use DLM

In attempt to make Cinder HA A/A ready QuobyteDriver should start
using RemoteFSSnapDriverDistributed instead of RemoteFSSnapDriver,
this will change locked snapshot operations to use distributed
lock manager.

Partially implements: blueprint cinder-volume-active-active-support
Closes-bug: 1606698
Change-Id: I3d0f22b81bc521054ff64867c42db9b0d928aa92
",git fetch https://review.opendev.org/openstack/cinder refs/changes/20/348020/2 && git format-patch -1 --stdout FETCH_HEAD,['cinder/volume/drivers/quobyte.py'],1,66d6fb067888449ab9153e3bda67c1b01bcfb63a,bug/1606698,class QuobyteDriver(remotefs_drv.RemoteFSSnapDriverDistributed):,class QuobyteDriver(remotefs_drv.RemoteFSSnapDriver):,1,1
openstack%2Fsecurity-doc~master~Icf4bddf742d59ba1ad63b3debc5fcc937344530a,openstack/security-doc,master,Icf4bddf742d59ba1ad63b3debc5fcc937344530a,Updated from openstack-manuals,MERGED,2016-08-29 15:01:32.000000000,2016-08-29 18:27:56.000000000,2016-08-29 18:27:56.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 13177}, {'_account_id': 22781}]","[{'number': 1, 'created': '2016-08-29 15:01:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/security-doc/commit/aaa2fde36a74bd88dd92f70b8e752caa21790f0d', 'message': 'Updated from openstack-manuals\n\nChange-Id: Icf4bddf742d59ba1ad63b3debc5fcc937344530a\n'}, {'number': 2, 'created': '2016-08-29 15:18:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/security-doc/commit/891e886b0b3cc71836407227f1c50222a5dccf92', 'message': 'Updated from openstack-manuals\n\nChange-Id: Icf4bddf742d59ba1ad63b3debc5fcc937344530a\n'}, {'number': 3, 'created': '2016-08-29 18:06:16.000000000', 'files': ['security-guide/source/compute/how-to-select-virtual-consoles.rst', 'common/glossary.rst'], 'web_link': 'https://opendev.org/openstack/security-doc/commit/da77668dce24c2d6facfa469d57e19582aa77252', 'message': 'Updated from openstack-manuals\n\n- Resolve SPICE glossary ref\n\nChange-Id: Icf4bddf742d59ba1ad63b3debc5fcc937344530a\n'}]",0,362173,da77668dce24c2d6facfa469d57e19582aa77252,13,4,3,11131,,,0,"Updated from openstack-manuals

- Resolve SPICE glossary ref

Change-Id: Icf4bddf742d59ba1ad63b3debc5fcc937344530a
",git fetch https://review.opendev.org/openstack/security-doc refs/changes/73/362173/2 && git format-patch -1 --stdout FETCH_HEAD,['common/glossary.rst'],1,aaa2fde36a74bd88dd92f70b8e752caa21790f0d,openstack/openstack-manuals," Network Address Translation (NAT) Process of modifying IP address information while in transit. Supported by Compute and Networking. Network Time Protocol (NTP) Method of keeping a clock for a host or node correct via communication with a trusted, accurate time source. "," NAT Network Address Translation; Process of modifying IP address information while in transit. Supported by Compute and Networking. NTP Network Time Protocol; Method of keeping a clock for a host or node correct via communication with a trusted, accurate time source. ",8,10
openstack%2Fmanila-ui~master~I5b778ffc7f0ce776ee1d1753e946f9c7b3c8353e,openstack/manila-ui,master,I5b778ffc7f0ce776ee1d1753e946f9c7b3c8353e,Remove incorrect docstrings,MERGED,2016-07-12 10:24:15.000000000,2016-08-29 18:27:41.000000000,2016-08-29 18:27:41.000000000,"[{'_account_id': 3}, {'_account_id': 2417}, {'_account_id': 6491}, {'_account_id': 6914}, {'_account_id': 7102}, {'_account_id': 8851}, {'_account_id': 11047}, {'_account_id': 11865}, {'_account_id': 14232}, {'_account_id': 14567}, {'_account_id': 15100}]","[{'number': 1, 'created': '2016-07-12 10:24:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila-ui/commit/7817894487b5c9c66683836ce536fc6c799a60d0', 'message': 'Remove incorrect docstrings\n\nThere are six places in Manila-UI where docstrings like this\nare used:\n""""""\nAdmin views for managing shares.\n""""""\n\nSome of them are not quite correct: for example the line above\nis from admin/shares/views.py, but this module also includes\na few other views. Another lines appear to be just an incorrect\ncopy-paste, like a few ""Views for managing shares"" in forms.py\nmodules.\n\nSince there\'s not much sense to keep such kind of docstrings,\nthis patch removes all of them.\n\nChange-Id: I5b778ffc7f0ce776ee1d1753e946f9c7b3c8353e\n'}, {'number': 2, 'created': '2016-07-26 10:32:04.000000000', 'files': ['manila_ui/dashboards/project/shares/shares/views.py', 'manila_ui/dashboards/project/shares/views.py', 'manila_ui/dashboards/project/shares/share_networks/forms.py', 'manila_ui/dashboards/project/shares/security_services/forms.py', 'manila_ui/dashboards/project/shares/shares/forms.py'], 'web_link': 'https://opendev.org/openstack/manila-ui/commit/58c070b85229d4f24fa033e819aa12fc35268793', 'message': 'Remove incorrect docstrings\n\nThere are five places in Manila-UI where the following docstring\nis used:\n\n""""""\nViews for managing shares.\n""""""\n\nThese docstrings appear to be just an incorrect copy-paste from\nadmin/shares/views.py and should be removed.\n\nChange-Id: I5b778ffc7f0ce776ee1d1753e946f9c7b3c8353e\n'}]",6,340843,58c070b85229d4f24fa033e819aa12fc35268793,17,11,2,6914,,,0,"Remove incorrect docstrings

There are five places in Manila-UI where the following docstring
is used:

""""""
Views for managing shares.
""""""

These docstrings appear to be just an incorrect copy-paste from
admin/shares/views.py and should be removed.

Change-Id: I5b778ffc7f0ce776ee1d1753e946f9c7b3c8353e
",git fetch https://review.opendev.org/openstack/manila-ui refs/changes/43/340843/2 && git format-patch -1 --stdout FETCH_HEAD,"['manila_ui/dashboards/project/shares/shares/views.py', 'manila_ui/dashboards/project/shares/views.py', 'manila_ui/dashboards/project/shares/share_networks/forms.py', 'manila_ui/dashboards/project/shares/security_services/forms.py', 'manila_ui/dashboards/admin/shares/views.py', 'manila_ui/dashboards/project/shares/shares/forms.py']",6,7817894487b5c9c66683836ce536fc6c799a60d0,docstrings,,""""""" Views for managing shares. """""" ",0,24
openstack%2Freleases~master~I6bb22dd11e512642e04b6c8faed851357df4590a,openstack/releases,master,I6bb22dd11e512642e04b6c8faed851357df4590a,Release OpenStack-Ansible Liberty/12.2.2,MERGED,2016-08-25 17:21:50.000000000,2016-08-29 18:27:30.000000000,2016-08-29 18:27:30.000000000,"[{'_account_id': 3}, {'_account_id': 2472}]","[{'number': 1, 'created': '2016-08-25 17:21:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/f98bb41dbb7c24f4bb36b3917328758aa0df7111', 'message': 'Release OpenStack-Ansible Liberty/12.2.2\n\nChange-Id: I6bb22dd11e512642e04b6c8faed851357df4590a\n'}, {'number': 2, 'created': '2016-08-26 10:59:31.000000000', 'files': ['deliverables/_independent/openstack-ansible.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/c61e82343a2ce86c143aaa24dfe56ce29f9c8c30', 'message': 'Release OpenStack-Ansible Liberty/12.2.2\n\nChange-Id: I6bb22dd11e512642e04b6c8faed851357df4590a\n'}]",0,360693,c61e82343a2ce86c143aaa24dfe56ce29f9c8c30,9,2,2,6816,,,0,"Release OpenStack-Ansible Liberty/12.2.2

Change-Id: I6bb22dd11e512642e04b6c8faed851357df4590a
",git fetch https://review.opendev.org/openstack/releases refs/changes/93/360693/1 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/_independent/openstack-ansible.yaml'],1,f98bb41dbb7c24f4bb36b3917328758aa0df7111,openstack-ansible, - version: 12.2.2 projects: - repo: openstack/openstack-ansible hash: 43c3baa1098a356179a944814b0cde6055b0a555 - repo: openstack/openstack-ansible-security hash: 6826bccd97a3a01d74886ff8a364a743a4299729,,6,0
openstack%2Ffuel-library~master~I853c0a89b7d2e283b3af7cacadac98cad6e622f0,openstack/fuel-library,master,I853c0a89b7d2e283b3af7cacadac98cad6e622f0,Puppet4 support: ntp_ocf fix,ABANDONED,2016-08-29 15:26:18.000000000,2016-08-29 18:22:15.000000000,,"[{'_account_id': 3}, {'_account_id': 8971}, {'_account_id': 20656}]","[{'number': 1, 'created': '2016-08-29 15:26:18.000000000', 'files': ['deployment/puppet/cluster/manifests/ntp_ocf.pp'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/50d1d5f13858bf12efea5bba72bc6b8eea1443aa', 'message': 'Puppet4 support: ntp_ocf fix\n\nInherit ntp_ocf from the ntp module to avoid service\nduplicate declaration\n\nChange-Id: I853c0a89b7d2e283b3af7cacadac98cad6e622f0\nRelated-Bug: 1586480\n'}]",0,362199,50d1d5f13858bf12efea5bba72bc6b8eea1443aa,19,3,1,9037,,,0,"Puppet4 support: ntp_ocf fix

Inherit ntp_ocf from the ntp module to avoid service
duplicate declaration

Change-Id: I853c0a89b7d2e283b3af7cacadac98cad6e622f0
Related-Bug: 1586480
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/99/362199/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/puppet/cluster/manifests/ntp_ocf.pp'],1,50d1d5f13858bf12efea5bba72bc6b8eea1443aa,bug/1586480,class cluster::ntp_ocf inherits ::ntp { Service[$service_name],"class cluster::ntp_ocf inherits ntp::params { Service['ntp'] if ! defined(Service[$service_name]) { service { $service_name: name => $service_name, enable => true, ensure => 'running', hasstatus => true, hasrestart => true, provider => 'pacemaker', } }",2,13
openstack%2Freleases~master~I46e905f8792da2cdb60e4df288543e4fee9783fd,openstack/releases,master,I46e905f8792da2cdb60e4df288543e4fee9783fd,Release Puppet OpenStack 9.2.0 (newton-3),MERGED,2016-08-29 13:22:28.000000000,2016-08-29 18:20:05.000000000,2016-08-29 18:20:05.000000000,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 5638}]","[{'number': 1, 'created': '2016-08-29 13:22:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/7fc4ac4f0704b254e0e6563faea0f10673925542', 'message': 'Release Puppet OpenStack 9.2.0 (newton-3)\n\nRelease Puppet OpenStack modules newton-3, all tagged 9.2.0 except\npuppet-vswitch 5.2.0.\n\nChange-Id: I46e905f8792da2cdb60e4df288543e4fee9783fd\n'}, {'number': 2, 'created': '2016-08-29 17:58:21.000000000', 'files': ['deliverables/newton/puppet-neutron.yaml', 'deliverables/newton/puppet-openstacklib.yaml', 'deliverables/newton/puppet-trove.yaml', 'deliverables/newton/puppet-mistral.yaml', 'deliverables/newton/puppet-openstack_extras.yaml', 'deliverables/newton/puppet-barbican.yaml', 'deliverables/newton/puppet-ironic.yaml', 'deliverables/newton/puppet-glance.yaml', 'deliverables/newton/puppet-heat.yaml', 'deliverables/newton/puppet-cinder.yaml', 'deliverables/newton/puppet-designate.yaml', 'deliverables/newton/puppet-manila.yaml', 'deliverables/newton/puppet-horizon.yaml', 'deliverables/newton/puppet-oslo.yaml', 'deliverables/newton/puppet-ovn.yaml', 'deliverables/newton/puppet-murano.yaml', 'deliverables/newton/puppet-zaqar.yaml', 'deliverables/newton/puppet-ceilometer.yaml', 'deliverables/newton/puppet-gnocchi.yaml', 'deliverables/newton/puppet-magnum.yaml', 'deliverables/newton/puppet-nova.yaml', 'deliverables/newton/puppet-sahara.yaml', 'deliverables/newton/puppet-vswitch.yaml', 'deliverables/newton/puppet-tempest.yaml', 'deliverables/newton/puppet-aodh.yaml', 'deliverables/newton/puppet-keystone.yaml', 'deliverables/newton/puppet-swift.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/fe4e07c90c7aa40af32fdc50773b143985998dc3', 'message': 'Release Puppet OpenStack 9.2.0 (newton-3)\n\nRelease Puppet OpenStack modules newton-3, all tagged 9.2.0 except\npuppet-vswitch 5.2.0.\n\nChange-Id: I46e905f8792da2cdb60e4df288543e4fee9783fd\n'}]",1,362109,fe4e07c90c7aa40af32fdc50773b143985998dc3,10,3,2,3153,,,0,"Release Puppet OpenStack 9.2.0 (newton-3)

Release Puppet OpenStack modules newton-3, all tagged 9.2.0 except
puppet-vswitch 5.2.0.

Change-Id: I46e905f8792da2cdb60e4df288543e4fee9783fd
",git fetch https://review.opendev.org/openstack/releases refs/changes/09/362109/2 && git format-patch -1 --stdout FETCH_HEAD,"['deliverables/newton/puppet-neutron.yaml', 'deliverables/newton/puppet-openstacklib.yaml', 'deliverables/newton/puppet-trove.yaml', 'deliverables/newton/puppet-mistral.yaml', 'deliverables/newton/puppet-openstack_extras.yaml', 'deliverables/newton/puppet-barbican.yaml', 'deliverables/newton/puppet-ironic.yaml', 'deliverables/newton/puppet-glance.yaml', 'deliverables/newton/puppet-heat.yaml', 'deliverables/newton/puppet-cinder.yaml', 'deliverables/newton/puppet-designate.yaml', 'deliverables/newton/puppet-manila.yaml', 'deliverables/newton/puppet-horizon.yaml', 'deliverables/newton/puppet-oslo.yaml', 'deliverables/newton/puppet-ovn.yaml', 'deliverables/newton/puppet-murano.yaml', 'deliverables/newton/puppet-zaqar.yaml', 'deliverables/newton/puppet-ceilometer.yaml', 'deliverables/newton/puppet-gnocchi.yaml', 'deliverables/newton/puppet-magnum.yaml', 'deliverables/newton/puppet-nova.yaml', 'deliverables/newton/puppet-sahara.yaml', 'deliverables/newton/puppet-vswitch.yaml', 'deliverables/newton/puppet-tempest.yaml', 'deliverables/newton/puppet-aodh.yaml', 'deliverables/newton/puppet-keystone.yaml', 'deliverables/newton/puppet-swift.yaml']",27,7fc4ac4f0704b254e0e6563faea0f10673925542,puppet/9.2.0, - version: 9.2.0 projects: - repo: openstack/puppet-swift hash: 3eb1b82a4d9f8196c1600d1005a5e39310bf2cd6,,108,0
openstack%2Fproject-config~master~I09b3176dd34527d89d2ae5d1e0ddb0df8eeeb30b,openstack/project-config,master,I09b3176dd34527d89d2ae5d1e0ddb0df8eeeb30b,Added new neutronclient gate to test against stable server release,MERGED,2016-08-27 14:22:00.000000000,2016-08-29 18:19:09.000000000,2016-08-29 18:19:09.000000000,"[{'_account_id': 2}, {'_account_id': 3}, {'_account_id': 748}, {'_account_id': 841}, {'_account_id': 6547}, {'_account_id': 8873}, {'_account_id': 9656}, {'_account_id': 12444}]","[{'number': 1, 'created': '2016-08-27 14:22:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/8ca2100507b06171a1420145f1c6d4d94903fb85', 'message': 'Added new neutronclient gate to test against stable server release\n\nGating only against master may lead to landing changes that will\nbreak interaction with older clouds\n\nChange-Id: I09b3176dd34527d89d2ae5d1e0ddb0df8eeeb30b\n'}, {'number': 2, 'created': '2016-08-27 14:32:25.000000000', 'files': ['jenkins/jobs/projects.yaml', 'zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/8b11479c8570b8dd5dd941f950cc9b2dd96faac1', 'message': 'Added new neutronclient gate to test against stable server release\n\nGating only against master may lead to landing changes that will\nbreak interaction with older clouds\n\nChange-Id: I09b3176dd34527d89d2ae5d1e0ddb0df8eeeb30b\n'}]",0,361603,8b11479c8570b8dd5dd941f950cc9b2dd96faac1,14,8,2,16615,,,0,"Added new neutronclient gate to test against stable server release

Gating only against master may lead to landing changes that will
break interaction with older clouds

Change-Id: I09b3176dd34527d89d2ae5d1e0ddb0df8eeeb30b
",git fetch https://review.opendev.org/openstack/project-config refs/changes/03/361603/1 && git format-patch -1 --stdout FETCH_HEAD,"['jenkins/jobs/projects.yaml', 'zuul/layout.yaml']",2,8ca2100507b06171a1420145f1c6d4d94903fb85,, - gate-neutronclient-test-dsvm-mitaka-functional-nv,,7,0
openstack%2Fproject-config~master~I05a102906295b04c7c58cc55b1f7856b42af810b,openstack/project-config,master,I05a102906295b04c7c58cc55b1f7856b42af810b,Enable java test as voting on monasca-api,MERGED,2016-08-26 22:45:51.000000000,2016-08-29 18:18:31.000000000,2016-08-29 18:18:31.000000000,"[{'_account_id': 2}, {'_account_id': 3}, {'_account_id': 2419}, {'_account_id': 6547}]","[{'number': 1, 'created': '2016-08-26 22:45:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/c267e177cbee336f7604c5f8bef04d5b8cc5e623', 'message': 'Enable java test as voting on monasca-api\n\nChange-Id: I05a102906295b04c7c58cc55b1f7856b42af810b\n'}, {'number': 2, 'created': '2016-08-29 14:53:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/2d722e3b096a59d54d7cadd59d53e90e9068e1fd', 'message': 'Enable java test as voting on monasca-api\n\nChange-Id: I05a102906295b04c7c58cc55b1f7856b42af810b\n'}, {'number': 3, 'created': '2016-08-29 14:54:41.000000000', 'files': ['jenkins/jobs/monasca.yaml', 'zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/e086518ea1781d45fc1aff45bd24ba29f0050ecb', 'message': 'Enable java test as voting on monasca-api\n\nChange-Id: I05a102906295b04c7c58cc55b1f7856b42af810b\n'}]",1,361511,e086518ea1781d45fc1aff45bd24ba29f0050ecb,12,4,3,14517,,,0,"Enable java test as voting on monasca-api

Change-Id: I05a102906295b04c7c58cc55b1f7856b42af810b
",git fetch https://review.opendev.org/openstack/project-config refs/changes/11/361511/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul/layout.yaml'],1,c267e177cbee336f7604c5f8bef04d5b8cc5e623,java_voting, - gate-tempest-dsvm-monasca-java-full, - gate-tempest-dsvm-monasca-java-full-nv,1,1
openstack%2Fcharm-ceph-mon~master~Ied73e775bdf58f226f9b7ffcc6353ed1be3ec245,openstack/charm-ceph-mon,master,Ied73e775bdf58f226f9b7ffcc6353ed1be3ec245,Add Admin Relation,MERGED,2016-08-25 20:13:53.000000000,2016-08-29 18:17:34.000000000,2016-08-29 18:17:34.000000000,"[{'_account_id': 3}, {'_account_id': 935}, {'_account_id': 20634}]","[{'number': 1, 'created': '2016-08-25 20:13:53.000000000', 'files': ['hooks/ceph_hooks.py', 'hooks/admin-relation-changed', 'hooks/admin-relation-joined', 'lib/ceph/__init__.py', 'metadata.yaml'], 'web_link': 'https://opendev.org/openstack/charm-ceph-mon/commit/4bdb0174fd9bfe23ecd83c552cd33b119e4090bb', 'message': 'Add Admin Relation\n\nOpenAttic is a manager for Ceph and requires access to the\ncephx admin keyring. This relation can be used by any\nCeph management software that needs the admin key.\n\nChange-Id: Ied73e775bdf58f226f9b7ffcc6353ed1be3ec245\n'}]",2,360769,4bdb0174fd9bfe23ecd83c552cd33b119e4090bb,11,3,1,20812,,,0,"Add Admin Relation

OpenAttic is a manager for Ceph and requires access to the
cephx admin keyring. This relation can be used by any
Ceph management software that needs the admin key.

Change-Id: Ied73e775bdf58f226f9b7ffcc6353ed1be3ec245
",git fetch https://review.opendev.org/openstack/charm-ceph-mon refs/changes/69/360769/1 && git format-patch -1 --stdout FETCH_HEAD,"['hooks/ceph_hooks.py', 'hooks/admin-relation-changed', 'hooks/admin-relation-joined', 'lib/ceph/__init__.py', 'metadata.yaml']",5,4bdb0174fd9bfe23ecd83c552cd33b119e4090bb,openattic-keyring, admin: interface: ceph-admin,,23,1
openstack%2Fshade~master~I5b92018b848d811148377aa0fd9881d5b5daf4c7,openstack/shade,master,I5b92018b848d811148377aa0fd9881d5b5daf4c7,Poll for image to be ready for PUT protocol,MERGED,2016-08-27 13:53:23.000000000,2016-08-29 18:17:02.000000000,2016-08-29 18:17:02.000000000,"[{'_account_id': 2}, {'_account_id': 3}, {'_account_id': 1106}]","[{'number': 1, 'created': '2016-08-27 13:53:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/shade/commit/c363435f78cf8dd97b4a66481e0eea06d5bb19c3', 'message': 'Poll for image to be ready for PUT protocol\n\nWhen we use PUT to upload images, they are not actually immediately\navailable all the time. They can come back in a ""queued"" state. We need\nto wait until they are ready before we return the final image. Also,\nsometimes the get_image call can return None, so trap for that.\n\nChange-Id: I5b92018b848d811148377aa0fd9881d5b5daf4c7\n'}, {'number': 2, 'created': '2016-08-29 16:35:04.000000000', 'files': ['shade/tests/unit/test_caching.py', 'shade/openstackcloud.py'], 'web_link': 'https://opendev.org/openstack/shade/commit/229f3daae0b9a8aba6e41eedf90eae20fcb8ecf5', 'message': 'Poll for image to be ready for PUT protocol\n\nWhen we use PUT to upload images, they are not actually immediately\navailable all the time. They can come back in a ""queued"" state. We need\nto wait until they are ready before we return the final image. Also,\nsometimes the get_image call can return None, so trap for that.\n\nChange-Id: I5b92018b848d811148377aa0fd9881d5b5daf4c7\n'}]",0,361602,229f3daae0b9a8aba6e41eedf90eae20fcb8ecf5,11,3,2,2,,,0,"Poll for image to be ready for PUT protocol

When we use PUT to upload images, they are not actually immediately
available all the time. They can come back in a ""queued"" state. We need
to wait until they are ready before we return the final image. Also,
sometimes the get_image call can return None, so trap for that.

Change-Id: I5b92018b848d811148377aa0fd9881d5b5daf4c7
",git fetch https://review.opendev.org/openstack/shade refs/changes/02/361602/2 && git format-patch -1 --stdout FETCH_HEAD,"['shade/tests/unit/test_caching.py', 'shade/openstackcloud.py']",2,c363435f78cf8dd97b4a66481e0eea06d5bb19c3,dual-stack," name, filename, meta=meta, wait=wait, timeout=timeout, **image_kwargs) self, name, filename, meta, wait, timeout, **image_kwargs): if not wait: return image for count in _utils._iterate_timeout( 60, ""Timeout waiting for the image to finish."", wait=self._get_cache_time('image')): image_obj = self.get_image(image.id) if image_obj and image_obj.status not in ('queued', 'saving'): return image_obj"," name, filename, meta=meta, **image_kwargs) self, name, filename, meta, **image_kwargs): self._cache.invalidate() return self.get_image(image.id)",15,5
openstack%2Ffuel-qa~master~I0aa95fa602a8965376fb20b3a6c2f1b3d9a2ebd7,openstack/fuel-qa,master,I0aa95fa602a8965376fb20b3a6c2f1b3d9a2ebd7,Fix upload test rail cases mechanism,MERGED,2016-08-19 14:27:02.000000000,2016-08-29 18:14:44.000000000,2016-08-29 18:14:44.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 8882}, {'_account_id': 8971}, {'_account_id': 9439}, {'_account_id': 9588}, {'_account_id': 10136}, {'_account_id': 11081}, {'_account_id': 11969}, {'_account_id': 12867}, {'_account_id': 14708}, {'_account_id': 15984}, {'_account_id': 16106}, {'_account_id': 19119}, {'_account_id': 19120}, {'_account_id': 20519}]","[{'number': 1, 'created': '2016-08-19 14:27:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/1315f875167205c214e6b2ae661222b1e2932e48', 'message': 'Fix upload test rail cases mechanism\n\n1. Fix an error with abcent of `custom_job_settings` field\nfor a pytest tests.\n2. Add try/except block for a getting injected vars from several jobs\n\nSee an attached nug for more info.\n\nChange-Id: I0aa95fa602a8965376fb20b3a6c2f1b3d9a2ebd7\nCloses-Bug:1614985\n'}, {'number': 2, 'created': '2016-08-19 14:27:56.000000000', 'files': ['fuelweb_test/testrail/builds.py', 'fuelweb_test/testrail/upload_cases_description.py'], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/332d1ba30f57de65a311f04568fccc9939dac39f', 'message': 'Fix upload test rail cases mechanism\n\n1. Fix an error with abcent of `custom_job_settings` field\nfor the pytest tests.\n2. Add try/except block for a getting injected vars from several jobs\n\nSee an attached bug for more info.\n\nChange-Id: I0aa95fa602a8965376fb20b3a6c2f1b3d9a2ebd7\nCloses-Bug:1614985\n'}]",0,357915,332d1ba30f57de65a311f04568fccc9939dac39f,19,16,2,14057,,,0,"Fix upload test rail cases mechanism

1. Fix an error with abcent of `custom_job_settings` field
for the pytest tests.
2. Add try/except block for a getting injected vars from several jobs

See an attached bug for more info.

Change-Id: I0aa95fa602a8965376fb20b3a6c2f1b3d9a2ebd7
Closes-Bug:1614985
",git fetch https://review.opendev.org/openstack/fuel-qa refs/changes/15/357915/1 && git format-patch -1 --stdout FETCH_HEAD,"['fuelweb_test/testrail/builds.py', 'fuelweb_test/testrail/upload_cases_description.py']",2,1315f875167205c214e6b2ae661222b1e2932e48,bug/1614985," ""custom_test_case_steps"": steps, ""custom_job_settings"": str( groups[jenkins_suffix]['env_vars'])"," ""custom_test_case_steps"": steps",12,2
openstack%2Freleases~master~I2c59afd3908d144ef8a64b33b98dc5249a9ad829,openstack/releases,master,I2c59afd3908d144ef8a64b33b98dc5249a9ad829,Release virtualbmc 0.1.0,MERGED,2016-08-29 14:09:30.000000000,2016-08-29 18:13:07.000000000,2016-08-29 18:13:07.000000000,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 10343}]","[{'number': 1, 'created': '2016-08-29 14:09:30.000000000', 'files': ['deliverables/_independent/virualbmc.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/b569c027361a66b3f7def4d1d499bdf41991bcef', 'message': 'Release virtualbmc 0.1.0\n\nChange-Id: I2c59afd3908d144ef8a64b33b98dc5249a9ad829\n'}]",0,362143,b569c027361a66b3f7def4d1d499bdf41991bcef,8,3,1,6773,,,0,"Release virtualbmc 0.1.0

Change-Id: I2c59afd3908d144ef8a64b33b98dc5249a9ad829
",git fetch https://review.opendev.org/openstack/releases refs/changes/43/362143/1 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/_independent/virualbmc.yaml'],1,b569c027361a66b3f7def4d1d499bdf41991bcef,virtualbmc,--- launchpad: virtualbmc team: ironic send-announcements-to: openstack-dev@lists.openstack.org releases: - version: 0.1.0 projects: - repo: openstack/virtualbmc hash: 9f4d478bd76b5ca76b99bbebb332fcfe11480978 ,,9,0
openstack%2Freleases~master~I3a7b53a10c46f852545c50655ca020343ad562c4,openstack/releases,master,I3a7b53a10c46f852545c50655ca020343ad562c4,Release neutron 8.2.0 (mitaka),MERGED,2016-07-29 10:52:30.000000000,2016-08-29 18:07:06.000000000,2016-08-29 18:07:06.000000000,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 2472}, {'_account_id': 9656}, {'_account_id': 12898}]","[{'number': 1, 'created': '2016-07-29 10:52:30.000000000', 'files': ['deliverables/mitaka/neutron.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/221183946b3ac2aecb49d818b031c76709e5769b', 'message': 'Release neutron 8.2.0 (mitaka)\n\nThis release introduces several minor features in a backwards compatible\nway, so bumping the minor version.\n\nChange-Id: I3a7b53a10c46f852545c50655ca020343ad562c4\n'}]",0,348838,221183946b3ac2aecb49d818b031c76709e5769b,14,5,1,9656,,,0,"Release neutron 8.2.0 (mitaka)

This release introduces several minor features in a backwards compatible
way, so bumping the minor version.

Change-Id: I3a7b53a10c46f852545c50655ca020343ad562c4
",git fetch https://review.opendev.org/openstack/releases refs/changes/38/348838/1 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/mitaka/neutron.yaml'],1,221183946b3ac2aecb49d818b031c76709e5769b,, - version: 8.2.0 projects: - repo: openstack/neutron hash: d1667a4bf52ae485a532885cf65c41d239d1b0ac - repo: openstack/neutron-fwaas hash: cbe18b5de196e8edb9b2528a257206c9463c714c - repo: openstack/neutron-lbaas hash: 799b93e09fe92ffea883238c34676c4342b9f75e - repo: openstack/neutron-vpnaas hash: ea355d1bc6e173cd56c6a975b88e5d5e1f901b5c highlights: |- * Allow min_l3_agents_per_router to equal one * Fix designate dns driver for SSL based endpoints * Fixed --config-dir argument for oslo.config 3.8.0 * OVS: Add support for IPv6 addresses as tunnel endpoints * Require oslo.concurrency>=3.7.1,,16,0
openstack%2Fmagnum~master~I896c8752fbcf15ec8e5bc6b3862a1ed040936215,openstack/magnum,master,I896c8752fbcf15ec8e5bc6b3862a1ed040936215,Init api-ref structure and requirements,MERGED,2016-08-19 03:25:53.000000000,2016-08-29 18:06:28.000000000,2016-08-29 18:06:27.000000000,"[{'_account_id': 3}, {'_account_id': 668}, {'_account_id': 964}, {'_account_id': 11536}, {'_account_id': 13861}, {'_account_id': 19741}, {'_account_id': 20498}, {'_account_id': 21469}]","[{'number': 1, 'created': '2016-08-19 03:25:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/de15993aaf1ba7af092918f60fe4c98cc630f20f', 'message': 'Init api-ref structure and requirements\n\nThis patch init api-ref document structure and\nadding some requirements based on the guidance of\nOpenStack API team.\n\nChange-Id: I896c8752fbcf15ec8e5bc6b3862a1ed040936215\nImplements: blueprint magnum-doc-rest-api\n'}, {'number': 2, 'created': '2016-08-19 03:32:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/1a7542dc5c1aae05f385da4383461ebf8ccc7827', 'message': 'Init api-ref structure and requirements\n\nThis patch init api-ref document structure and\nadding some requirements based on the guidance of\nOpenStack API team.\n\nChange-Id: I896c8752fbcf15ec8e5bc6b3862a1ed040936215\nImplements: blueprint magnum-doc-rest-api\n'}, {'number': 3, 'created': '2016-08-19 04:27:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/317a655401476bae0eb3b3cdc687c2df5cae79f9', 'message': 'Init api-ref structure and requirements\n\nThis patch init api-ref document structure and\nadding some requirements based on the guidance of\nOpenStack API team.\n\nChange-Id: I896c8752fbcf15ec8e5bc6b3862a1ed040936215\nImplements: blueprint magnum-doc-rest-api\n'}, {'number': 4, 'created': '2016-08-19 06:18:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/265b38cc1bced1449652de60427141aa3c06076c', 'message': 'Init api-ref structure and requirements\n\nThis patch init api-ref document structure and\nadding some requirements based on the guidance of\nOpenStack API team.\n\nChange-Id: I896c8752fbcf15ec8e5bc6b3862a1ed040936215\nImplements: blueprint magnum-doc-rest-api\n'}, {'number': 5, 'created': '2016-08-23 06:40:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/909869a6e433297030ae5612b15712e66bbb782e', 'message': 'Init api-ref structure and requirements\n\nThis patch init api-ref document structure and\nadding some requirements based on the guidance of\nOpenStack API team.\n\nChange-Id: I896c8752fbcf15ec8e5bc6b3862a1ed040936215\nImplements: blueprint magnum-doc-rest-api\n'}, {'number': 6, 'created': '2016-08-25 09:46:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/33654b46a7d10114a5ff546d8e241cc96c323a8b', 'message': 'Init api-ref structure and requirements\n\nThis patch init api-ref document structure and\nadding some requirements based on the guidance of\nOpenStack API team.\n\nGet ready for os-api-ref sphinx theme change\n\nChange-Id: I896c8752fbcf15ec8e5bc6b3862a1ed040936215\nImplements: blueprint magnum-doc-rest-api\n'}, {'number': 7, 'created': '2016-08-25 09:54:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/e95b212da604cfb6dc18f4e64457ad4720bd1626', 'message': 'Init api-ref structure and requirements\n\nThis patch init api-ref document structure and\nadding some requirements based on the guidance of\nOpenStack API team.\n\nGet ready for os-api-ref sphinx theme change\n\nChange-Id: I896c8752fbcf15ec8e5bc6b3862a1ed040936215\nImplements: blueprint magnum-doc-rest-api\n'}, {'number': 8, 'created': '2016-08-27 07:55:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/1a0a3f3da71bf688f2582141537017406c71aa80', 'message': 'Init api-ref structure and requirements\n\nThis patch init api-ref document structure and\nadding some requirements based on the guidance of\nOpenStack API team.\n\nGet ready for os-api-ref sphinx theme change\n\nChange-Id: I896c8752fbcf15ec8e5bc6b3862a1ed040936215\nImplements: blueprint magnum-doc-rest-api\n'}, {'number': 9, 'created': '2016-08-27 08:02:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/853c3694324c5ac2b88978e7f16aea9d5c321fdd', 'message': 'Init api-ref structure and requirements\n\nThis patch init api-ref document structure and\nadding some requirements based on the guidance of\nOpenStack API team.\n\nGet ready for os-api-ref sphinx theme change\n\nChange-Id: I896c8752fbcf15ec8e5bc6b3862a1ed040936215\nImplements: blueprint magnum-doc-rest-api\n'}, {'number': 10, 'created': '2016-08-29 15:44:36.000000000', 'files': ['api-ref/source/bays_clusters.inc', 'api-ref/source/urls.inc', 'api-ref/source/index.rst', 'test-requirements.txt', 'api-ref/source/baymodels_clustertemplates.inc', 'api-ref/source/certificates.inc', 'api-ref/source/mservices.inc', 'api-ref/source/conf.py', 'api-ref/source/versions.inc', 'api-ref/source/status.yaml', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/magnum/commit/cdd14f209e4fc538f05613c7cade66c6e1eb80b3', 'message': 'Init api-ref structure and requirements\n\nThis patch init api-ref document structure and\nadding some requirements based on the guidance of\nOpenStack API team.\n\nGet ready for os-api-ref sphinx theme change\n\nChange-Id: I896c8752fbcf15ec8e5bc6b3862a1ed040936215\nImplements: blueprint magnum-doc-rest-api\n'}]",14,357586,cdd14f209e4fc538f05613c7cade66c6e1eb80b3,43,8,10,19741,,,0,"Init api-ref structure and requirements

This patch init api-ref document structure and
adding some requirements based on the guidance of
OpenStack API team.

Get ready for os-api-ref sphinx theme change

Change-Id: I896c8752fbcf15ec8e5bc6b3862a1ed040936215
Implements: blueprint magnum-doc-rest-api
",git fetch https://review.opendev.org/openstack/magnum refs/changes/86/357586/10 && git format-patch -1 --stdout FETCH_HEAD,"['api-ref/source/urls.inc', 'api-ref/source/index.rst', 'test-requirements.txt', 'api-ref/source/bays.inc', 'api-ref/source/baymodels.inc', 'api-ref/source/conf.py', 'api-ref/source/mservices.inc', 'tox.ini']",8,de15993aaf1ba7af092918f60fe4c98cc630f20f,bp/magnum-doc-rest-api," [testenv:api-ref] # This environment is called from CI scripts to test and publish # the API Ref to developer.openstack.org. # NOTE(sdague): this target does not use constraints because # upstream infra does not yet support it. Once that's fixed, we can # drop the install_command. # # we do not used -W here because we are doing some slightly tricky # things to build a single page document, and as such, we are ok # ignoring the duplicate stanzas warning. install_command = pip install -U --force-reinstall {opts} {packages} commands = rm -rf api-ref/build sphinx-build -W -b html -d api-ref/build/doctrees api-ref/source api-ref/build/html",,280,0
openstack%2Freleases~master~I0608ba9efb38219fb25c7d42b1b410d4521aabce,openstack/releases,master,I0608ba9efb38219fb25c7d42b1b410d4521aabce,Final release of tackerclient for newton (0.7.0),MERGED,2016-08-27 17:11:35.000000000,2016-08-29 17:53:26.000000000,2016-08-29 17:53:26.000000000,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 11105}]","[{'number': 1, 'created': '2016-08-27 17:11:35.000000000', 'files': ['deliverables/newton/python-tackerclient.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/89f894d0045178db68ce6f61cbfc8e439c4d4c4c', 'message': 'Final release of tackerclient for newton (0.7.0)\n\nIntroducing client side changes for vnf forwarding graph,\nvnf resource list, and other bug fixes.\n\nChange-Id: I0608ba9efb38219fb25c7d42b1b410d4521aabce\n'}]",0,361643,89f894d0045178db68ce6f61cbfc8e439c4d4c4c,7,3,1,13380,,,0,"Final release of tackerclient for newton (0.7.0)

Introducing client side changes for vnf forwarding graph,
vnf resource list, and other bug fixes.

Change-Id: I0608ba9efb38219fb25c7d42b1b410d4521aabce
",git fetch https://review.opendev.org/openstack/releases refs/changes/43/361643/1 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/newton/python-tackerclient.yaml'],1,89f894d0045178db68ce6f61cbfc8e439c4d4c4c,tackerclient-newton-0.7.0, - version: 0.7.0 projects: - repo: openstack/python-tackerclient hash: 48d458d290c920140b65beeb55ef66999844fff1,,4,0
openstack%2Fossa~master~I7f78f9db9bfbbcb7aed7e4a74c2cec2a67bc8552,openstack/ossa,master,I7f78f9db9bfbbcb7aed7e4a74c2cec2a67bc8552,Four... there are four,MERGED,2016-08-29 17:10:01.000000000,2016-08-29 17:47:22.000000000,2016-08-29 17:47:22.000000000,"[{'_account_id': 3}, {'_account_id': 7473}]","[{'number': 1, 'created': '2016-08-29 17:10:01.000000000', 'files': ['doc/source/index.rst'], 'web_link': 'https://opendev.org/openstack/ossa/commit/12205ff1e82906c74e5b4bf6b5f55216d2684d32', 'message': 'Four... there are four\n\nCorrect an off-by-one error in our documentation.\n\nChange-Id: I7f78f9db9bfbbcb7aed7e4a74c2cec2a67bc8552\n'}]",0,362285,12205ff1e82906c74e5b4bf6b5f55216d2684d32,6,2,1,5263,,,0,"Four... there are four

Correct an off-by-one error in our documentation.

Change-Id: I7f78f9db9bfbbcb7aed7e4a74c2cec2a67bc8552
",git fetch https://review.opendev.org/openstack/ossa refs/changes/85/362285/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/index.rst'],1,12205ff1e82906c74e5b4bf6b5f55216d2684d32,docs,There are four main sources of security guidance for OpenStack deployers:,There are three main sources of security guidance for OpenStack deployers:,1,1
openstack%2Fpuppet-glance~master~I722a1e41b2cee0b3040c37f07adfd13c33edaa5c,openstack/puppet-glance,master,I722a1e41b2cee0b3040c37f07adfd13c33edaa5c,Move Glance to new authtoken scheme,MERGED,2016-07-29 10:13:14.000000000,2016-08-29 17:44:59.000000000,2016-08-29 17:44:59.000000000,"[{'_account_id': 3}, {'_account_id': 1607}, {'_account_id': 3153}, {'_account_id': 7732}, {'_account_id': 7745}, {'_account_id': 8971}, {'_account_id': 14200}, {'_account_id': 14985}, {'_account_id': 15519}]","[{'number': 1, 'created': '2016-07-29 10:13:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-glance/commit/7f9dc12e09da6064a0e076b2ee2a0c2beefb99fb', 'message': 'WIP Move Glance to new authtoken scheme\n\nChange-Id: I722a1e41b2cee0b3040c37f07adfd13c33edaa5c\nCloses-bug: #1604463\n'}, {'number': 2, 'created': '2016-08-01 13:31:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-glance/commit/491feb1b94a00f7c016515ce79a5991cf4201518', 'message': 'WIP Move Glance to new authtoken scheme\n\nChange-Id: I722a1e41b2cee0b3040c37f07adfd13c33edaa5c\nCloses-bug: #1604463\n'}, {'number': 3, 'created': '2016-08-02 11:37:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-glance/commit/ed63dfc8354110c3e422b6e86356d13e724061d6', 'message': 'Move Glance to new authtoken scheme\n\nUse glance::<service>::authtoken to configure keystone_authtoken\nsection in glance configs, with all parameters required\nto configure keystonemiddleware.\n\nChange-Id: I722a1e41b2cee0b3040c37f07adfd13c33edaa5c\nCloses-bug: #1604463\n'}, {'number': 4, 'created': '2016-08-03 15:09:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-glance/commit/6ac547ecd857ba8a12e249b85489f58f7788443b', 'message': 'Move Glance to new authtoken scheme\n\nUse glance::<service>::authtoken to configure keystone_authtoken\nsection in glance configs, with all parameters required\nto configure keystonemiddleware.\n\nAlso changed auth_type to auth_strategy, because auth_type is\nrelated to keystone authentication.\n\nChange-Id: I722a1e41b2cee0b3040c37f07adfd13c33edaa5c\nCloses-bug: #1604463\n'}, {'number': 5, 'created': '2016-08-05 10:46:16.000000000', 'files': ['spec/classes/glance_api_authtoken_spec.rb', 'manifests/api.pp', 'spec/classes/glance_registry_spec.rb', 'manifests/glare.pp', 'spec/classes/glance_glare_spec.rb', 'manifests/glare/authtoken.pp', 'spec/classes/glance_glare_authtoken_spec.rb', 'manifests/registry.pp', 'releasenotes/notes/authtoken-2439e462e0a84399.yaml', 'spec/classes/glance_registry_authtoken_spec.rb', 'spec/acceptance/basic_glance_spec.rb', 'spec/classes/glance_api_spec.rb', 'lib/puppet/provider/glance.rb', 'manifests/api/authtoken.pp', 'manifests/registry/authtoken.pp'], 'web_link': 'https://opendev.org/openstack/puppet-glance/commit/1e09e553edf091f53b3bbfe667630adc236cf223', 'message': 'Move Glance to new authtoken scheme\n\nUse glance::<service>::authtoken to configure keystone_authtoken\nsection in glance configs, with all parameters required\nto configure keystonemiddleware.\n\nAlso changed auth_type to auth_strategy, because auth_type is\nrelated to keystone authentication.\n\nChange-Id: I722a1e41b2cee0b3040c37f07adfd13c33edaa5c\nCloses-bug: #1604463\n'}]",23,348826,1e09e553edf091f53b3bbfe667630adc236cf223,50,9,5,7745,,,0,"Move Glance to new authtoken scheme

Use glance::<service>::authtoken to configure keystone_authtoken
section in glance configs, with all parameters required
to configure keystonemiddleware.

Also changed auth_type to auth_strategy, because auth_type is
related to keystone authentication.

Change-Id: I722a1e41b2cee0b3040c37f07adfd13c33edaa5c
Closes-bug: #1604463
",git fetch https://review.opendev.org/openstack/puppet-glance refs/changes/26/348826/1 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/glare/authtoken.pp', 'spec/classes/glance_glare_authtoken_spec.rb', 'manifests/registry.pp', 'spec/classes/glance_registry_authtoken_spec.rb', 'spec/classes/glance_api_authtoken_spec.rb', 'manifests/api.pp', 'spec/classes/glance_api_spec.rb', 'manifests/api/authtoken.pp', 'manifests/registry/authtoken.pp', 'manifests/glare.pp']",10,7f9dc12e09da6064a0e076b2ee2a0c2beefb99fb,bug/1604463,"# [*auth_strategy*]# [*auth_type*] # (optional) Type is authorization being used. # Defaults to undef. # # [*auth_uri*] # (optional) Complete public Identity API endpoint. # Defaults to undef. # # [*identity_uri*] # (optional) Complete admin Identity API endpoint. # Defaults to undef. # # [*keystone_tenant*] # (optional) Tenant to authenticate to. # Defaults to undef. # # [*keystone_user*] # (optional) User to authenticate as with keystone. # Defaults to undef. # # [*keystone_password*] # (optional) Password used to authentication. # Defaults to undef. # # [*signing_dir*] # (optional) Directory used to cache files related to PKI tokens. # Defaults to undef. # # [*memcached_servers*] # (optinal) a list of memcached server(s) to use for caching. If left undefined, # tokens will instead be cached in-process. # Defaults to undef. # # [*token_cache_time*] # (optional) In order to prevent excessive effort spent validating tokens, # the middleware caches previously-seen tokens for a configurable duration (in seconds). # Set to -1 to disable caching completely. # Defaults to undef. # $auth_strategy = 'keystone', $auth_region = undef, $auth_type = undef, $auth_uri = undef, $identity_uri = undef, $memcached_servers = undef, $keystone_tenant = undef, $keystone_user = undef, $keystone_password = undef, $signing_dir = undef, $token_cache_time = undef, if $keystone_password != undef { warning('glance::glare::keystone_password is deprecated, please use glance::glare::authtoken::keystone_password') } if $auth_type != undef { warning('glance::glare::auth_type is deprecated, please use glance::glare::auth_strategy') $auth_strategy_real = $auth_type } else { $auth_strategy_real = $auth_strategy } if $auth_uri != undef { warning('glance::glare::auth_uri is deprecated, please use glance::glare::authtoken::auth_uri') } if $identity_uri != undef { warning('glance::glare::identity_uri is deprecated, please use glance::glare::authtoken::identity_uri') } if $keystone_tenant != undef { warning('glance::glare::keystone_tenant is deprecated, please use glance::glare::authtoken::keystone_tenant') } if $keystone_user != undef { warning('glance::glare::keystone_user is deprecated, please use glance::glare::authtoken::keystone_user') } if $memcached_servers != undef { warning('glance::glare::memcached_servers is deprecated, please use glance::glare::authtoken::memcached_servers') } if $signing_dir != undef { warning('glance::glare::signing_dir is deprecated, please use glance::glare::authtoken::signing_dir') } if $token_cache_time != undef { warning('glance::glare::token_cache_time is deprecated, please use glance::glare::authtoken::token_cache_time') } if $auth_strategy == 'keystone' { include ::glance::glare::authtoken","# [*auth_type*]# [*auth_uri*] # (optional) Complete public Identity API endpoint. # Defaults to 'http://127.0.0.1:5000/'. # # [*identity_uri*] # (optional) Complete admin Identity API endpoint. # Defaults to 'http://127.0.0.1:35357/'. ## [*keystone_tenant*] # (optional) Tenant to authenticate to. # Defaults to services. # # [*keystone_user*] # (optional) User to authenticate as with keystone. # Defaults to 'glance'. # # [*keystone_password*] # (optional) Password used to authentication. # Defaults to false. ## [*signing_dir*] # (optional) Directory used to cache files related to PKI tokens. # Defaults to $::os_service_default. # # [*memcached_servers*] # (optinal) a list of memcached server(s) to use for caching. If left undefined, # tokens will instead be cached in-process. # Defaults to $::os_service_default. # # [*token_cache_time*] # (optional) In order to prevent excessive effort spent validating tokens, # the middleware caches previously-seen tokens for a configurable duration (in seconds). # Set to -1 to disable caching completely. # Defaults to $::os_service_default. # $auth_type = 'keystone', $auth_uri = 'http://127.0.0.1:5000/', $identity_uri = 'http://127.0.0.1:35357/', $memcached_servers = $::os_service_default, $keystone_tenant = 'services', $keystone_user = 'glance', $keystone_password = false, $signing_dir = $::os_service_default, $token_cache_time = $::os_service_default, $auth_region = $::os_service_default, if $auth_type == 'keystone' { if ! $keystone_password { fail('Parameter keystone_password must be provided, when auth_type is keystone') } glance_glare_config { 'keystone_authtoken/admin_tenant_name': value => $keystone_tenant; 'keystone_authtoken/admin_user': value => $keystone_user; 'keystone_authtoken/admin_password': value => $keystone_password, secret => true; 'keystone_authtoken/token_cache_time': value => $token_cache_time; 'keystone_authtoken/signing_dir': value => $signing_dir; 'keystone_authtoken/auth_uri': value => $auth_uri; 'keystone_authtoken/identity_uri': value => $identity_uri; 'keystone_authtoken/memcached_servers': value => join(any2array($memcached_servers), ','); }",1579,215
openstack%2Fpython-novaclient~master~I39f54149f6485a2db3cb4b8021e74381477da940,openstack/python-novaclient,master,I39f54149f6485a2db3cb4b8021e74381477da940,"The incorrect output of ""nova show"" when VM has long user data.",ABANDONED,2016-08-29 17:40:16.000000000,2016-08-29 17:44:09.000000000,,[],"[{'number': 1, 'created': '2016-08-29 17:40:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/17bcbdb0987b5e7436a9b66d3ca1499b073a6364', 'message': 'The incorrect output of ""nova show"" when VM has long user data fixed.\nNew argument ""--wrap"" is added for ""nova show"" command to wrap the output. The default wrap length is set to 80 now.\nExample: nova show --wrap 60 <server-id>\n\nChange-Id: I39f54149f6485a2db3cb4b8021e74381477da940\n'}, {'number': 2, 'created': '2016-08-29 17:41:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/1b88ca6c4ce0293c2eddd25b879ebc05526294c4', 'message': 'The incorrect output of ""nova show"" when VM has long user data fixed.\n\nChange-Id: I39f54149f6485a2db3cb4b8021e74381477da940\n'}, {'number': 3, 'created': '2016-08-29 17:42:52.000000000', 'files': ['novaclient/v2/shell.py'], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/d9c9f66f4ca261a0890be36449077fd062ff3bba', 'message': 'The incorrect output of ""nova show"" when VM has long user data.\n\nChange-Id: I39f54149f6485a2db3cb4b8021e74381477da940\n'}]",0,362299,d9c9f66f4ca261a0890be36449077fd062ff3bba,4,0,3,22233,,,0,"The incorrect output of ""nova show"" when VM has long user data.

Change-Id: I39f54149f6485a2db3cb4b8021e74381477da940
",git fetch https://review.opendev.org/openstack/python-novaclient refs/changes/99/362299/1 && git format-patch -1 --stdout FETCH_HEAD,['novaclient/v2/shell.py'],1,17bcbdb0987b5e7436a9b66d3ca1499b073a6364,MYFIRST-CONTRIBUTION,"# Copyright 2010 Jacob Kaplan-Moss # Copyright 2011 OpenStack Foundation # Copyright 2013 IBM Corp. # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. from __future__ import print_function import argparse import copy import datetime import functools import getpass import locale import logging import os import sys import time import warnings from oslo_utils import encodeutils from oslo_utils import netutils from oslo_utils import strutils from oslo_utils import timeutils from oslo_utils import uuidutils import six import novaclient from novaclient import api_versions from novaclient import base from novaclient import client from novaclient import exceptions from novaclient.i18n import _ from novaclient.i18n import _LE from novaclient import shell from novaclient import utils from novaclient.v2 import availability_zones from novaclient.v2 import quotas from novaclient.v2 import servers logger = logging.getLogger(__name__) CLIENT_BDM2_KEYS = { 'id': 'uuid', 'source': 'source_type', 'dest': 'destination_type', 'bus': 'disk_bus', 'device': 'device_name', 'size': 'volume_size', 'format': 'guest_format', 'bootindex': 'boot_index', 'type': 'device_type', 'shutdown': 'delete_on_termination', 'tag': 'tag', } # NOTE(mriedem): Remove this along with the deprecated commands in the first # python-novaclient release AFTER the nova server 15.0.0 'O' release. def emit_image_deprecation_warning(command_name): print('WARNING: Command %s is deprecated and will be removed after Nova ' '15.0.0 is released. Use python-glanceclient or openstackclient ' 'instead.' % command_name, file=sys.stderr) def deprecated_network(fn): @functools.wraps(fn) def wrapped(cs, *args, **kwargs): command_name = '-'.join(fn.__name__.split('_')[1:]) print('WARNING: Command %s is deprecated and will be removed ' 'after Nova 15.0.0 is released. Use python-neutronclient ' 'or python-openstackclient instead.' % command_name, file=sys.stderr) # The network proxy API methods were deprecated in 2.36 and will return # a 404 so we fallback to 2.35 to maintain a transition for CLI users. want_version = api_versions.APIVersion('2.35') cur_version = cs.api_version if cs.api_version > want_version: cs.api_version = want_version try: return fn(cs, *args, **kwargs) finally: cs.api_version = cur_version wrapped.__doc__ = 'DEPRECATED: ' + fn.__doc__ return wrapped def _key_value_pairing(text): try: (k, v) = text.split('=', 1) return (k, v) except ValueError: msg = _LE(""'%s' is not in the format of 'key=value'"") % text raise argparse.ArgumentTypeError(msg) def _meta_parsing(metadata): return dict(v.split('=', 1) for v in metadata) def _match_image(cs, wanted_properties): image_list = cs.images.list() images_matched = [] match = set(wanted_properties) for img in image_list: try: if match == match.intersection(set(img.metadata.items())): images_matched.append(img) except AttributeError: pass return images_matched def _parse_block_device_mapping_v2(args, image): bdm = [] if args.boot_volume: bdm_dict = {'uuid': args.boot_volume, 'source_type': 'volume', 'destination_type': 'volume', 'boot_index': 0, 'delete_on_termination': False} bdm.append(bdm_dict) if args.snapshot: bdm_dict = {'uuid': args.snapshot, 'source_type': 'snapshot', 'destination_type': 'volume', 'boot_index': 0, 'delete_on_termination': False} bdm.append(bdm_dict) for device_spec in args.block_device: spec_dict = dict(v.split('=') for v in device_spec.split(',')) bdm_dict = {} for key, value in six.iteritems(spec_dict): bdm_dict[CLIENT_BDM2_KEYS[key]] = value # Convert the delete_on_termination to a boolean or set it to true by # default for local block devices when not specified. if 'delete_on_termination' in bdm_dict: action = bdm_dict['delete_on_termination'] if action not in ['remove', 'preserve']: raise exceptions.CommandError( _(""The value of shutdown key of --block-device shall be "" ""either 'remove' or 'preserve' but it was '%(action)s'"") % {'action': action}) bdm_dict['delete_on_termination'] = (action == 'remove') elif bdm_dict.get('destination_type') == 'local': bdm_dict['delete_on_termination'] = True bdm.append(bdm_dict) for ephemeral_spec in args.ephemeral: bdm_dict = {'source_type': 'blank', 'destination_type': 'local', 'boot_index': -1, 'delete_on_termination': True} try: eph_dict = dict(v.split('=') for v in ephemeral_spec.split(',')) except ValueError: err_msg = (_(""Invalid ephemeral argument '%s'."") % args.ephemeral) raise argparse.ArgumentTypeError(err_msg) if 'size' in eph_dict: bdm_dict['volume_size'] = eph_dict['size'] if 'format' in eph_dict: bdm_dict['guest_format'] = eph_dict['format'] bdm.append(bdm_dict) if args.swap: bdm_dict = {'source_type': 'blank', 'destination_type': 'local', 'boot_index': -1, 'delete_on_termination': True, 'guest_format': 'swap', 'volume_size': args.swap} bdm.append(bdm_dict) return bdm def _parse_nics(cs, args): if cs.api_version >= api_versions.APIVersion('2.32'): err_msg = (_(""Invalid nic argument '%s'. Nic arguments must be of "" ""the form --nic <net-id=net-uuid,"" ""net-name=network-name,v4-fixed-ip=ip-addr,"" ""v6-fixed-ip=ip-addr,port-id=port-uuid,tag=tag>, "" ""with only one of net-id, net-name or port-id "" ""specified."")) else: err_msg = (_(""Invalid nic argument '%s'. Nic arguments must be of "" ""the form --nic <net-id=net-uuid,"" ""net-name=network-name,v4-fixed-ip=ip-addr,"" ""v6-fixed-ip=ip-addr,port-id=port-uuid>, "" ""with only one of net-id, net-name or port-id "" ""specified."")) nics = [] for nic_str in args.nics: nic_info = {""net-id"": """", ""v4-fixed-ip"": """", ""v6-fixed-ip"": """", ""port-id"": """", ""net-name"": """", ""tag"": """"} for kv_str in nic_str.split("",""): try: k, v = kv_str.split(""="", 1) except ValueError: raise exceptions.CommandError(err_msg % nic_str) if k in nic_info: # if user has given a net-name resolve it to network ID if k == 'net-name': k = 'net-id' v = _find_network_id(cs, v) # if some argument was given multiple times if nic_info[k]: raise exceptions.CommandError(err_msg % nic_str) nic_info[k] = v else: raise exceptions.CommandError(err_msg % nic_str) if nic_info['v4-fixed-ip'] and not netutils.is_valid_ipv4( nic_info['v4-fixed-ip']): raise exceptions.CommandError(_(""Invalid ipv4 address."")) if nic_info['v6-fixed-ip'] and not netutils.is_valid_ipv6( nic_info['v6-fixed-ip']): raise exceptions.CommandError(_(""Invalid ipv6 address."")) if bool(nic_info['net-id']) == bool(nic_info['port-id']): raise exceptions.CommandError(err_msg % nic_str) nics.append(nic_info) return nics def _boot(cs, args): """"""Boot a new server."""""" if not args.flavor: raise exceptions.CommandError(_(""you need to specify a Flavor ID."")) if args.image: image = _find_image(cs, args.image) else: image = None if not image and args.image_with: images = _match_image(cs, args.image_with) if images: # TODO(harlowja): log a warning that we # are selecting the first of many? image = images[0] min_count = 1 max_count = 1 if args.min_count is not None: if args.min_count < 1: raise exceptions.CommandError(_(""min_count should be >= 1"")) min_count = args.min_count max_count = min_count if args.max_count is not None: if args.max_count < 1: raise exceptions.CommandError(_(""max_count should be >= 1"")) max_count = args.max_count if (args.min_count is not None and args.max_count is not None and args.min_count > args.max_count): raise exceptions.CommandError(_(""min_count should be <= max_count"")) flavor = _find_flavor(cs, args.flavor) meta = _meta_parsing(args.meta) files = {} for f in args.files: try: dst, src = f.split('=', 1) files[dst] = open(src) except IOError as e: raise exceptions.CommandError(_(""Can't open '%(src)s': %(exc)s"") % {'src': src, 'exc': e}) except ValueError: raise exceptions.CommandError(_(""Invalid file argument '%s'. "" ""File arguments must be of the "" ""form '--file "" ""<dst-path=src-path>'"") % f) # use the os-keypair extension key_name = None if args.key_name is not None: key_name = args.key_name if args.user_data: try: userdata = open(args.user_data) except IOError as e: raise exceptions.CommandError(_(""Can't open '%(user_data)s': "" ""%(exc)s"") % {'user_data': args.user_data, 'exc': e}) else: userdata = None if args.availability_zone: availability_zone = args.availability_zone else: availability_zone = None if args.security_groups: security_groups = args.security_groups.split(',') else: security_groups = None block_device_mapping = {} for bdm in args.block_device_mapping: device_name, mapping = bdm.split('=', 1) block_device_mapping[device_name] = mapping block_device_mapping_v2 = _parse_block_device_mapping_v2(args, image) n_boot_args = len(list(filter( bool, (image, args.boot_volume, args.snapshot)))) have_bdm = block_device_mapping_v2 or block_device_mapping # Fail if more than one boot devices are present # or if there is no device to boot from. if n_boot_args > 1 or n_boot_args == 0 and not have_bdm: raise exceptions.CommandError( _(""you need to specify at least one source ID (Image, Snapshot, "" ""or Volume), a block device mapping or provide a set of "" ""properties to match against an image"")) if block_device_mapping and block_device_mapping_v2: raise exceptions.CommandError( _(""you can't mix old block devices (--block-device-mapping) "" ""with the new ones (--block-device, --boot-volume, --snapshot, "" ""--ephemeral, --swap)"")) nics = _parse_nics(cs, args) hints = {} if args.scheduler_hints: for hint in args.scheduler_hints: key, _sep, value = hint.partition('=') # NOTE(vish): multiple copies of the same hint will # result in a list of values if key in hints: if isinstance(hints[key], six.string_types): hints[key] = [hints[key]] hints[key] += [value] else: hints[key] = value boot_args = [args.name, image, flavor] if str(args.config_drive).lower() in (""true"", ""1""): config_drive = True elif str(args.config_drive).lower() in (""false"", ""0"", """", ""none""): config_drive = None else: config_drive = args.config_drive boot_kwargs = dict( meta=meta, files=files, key_name=key_name, min_count=min_count, max_count=max_count, userdata=userdata, availability_zone=availability_zone, security_groups=security_groups, block_device_mapping=block_device_mapping, block_device_mapping_v2=block_device_mapping_v2, nics=nics, scheduler_hints=hints, config_drive=config_drive, admin_pass=args.admin_pass, access_ip_v4=args.access_ip_v4, access_ip_v6=args.access_ip_v6) if 'description' in args: boot_kwargs[""description""] = args.description return boot_args, boot_kwargs @utils.arg( '--flavor', default=None, metavar='<flavor>', help=_(""Name or ID of flavor (see 'nova flavor-list')."")) @utils.arg( '--image', default=None, metavar='<image>', help=_(""Name or ID of image (see 'glance image-list'). "")) @utils.arg( '--image-with', default=[], type=_key_value_pairing, action='append', metavar='<key=value>', help=_(""Image metadata property (see 'glance image-show'). "")) @utils.arg( '--boot-volume', default=None, metavar=""<volume_id>"", help=_(""Volume ID to boot from."")) @utils.arg( '--snapshot', default=None, metavar=""<snapshot_id>"", help=_(""Snapshot ID to boot from (will create a volume)."")) @utils.arg( '--min-count', default=None, type=int, metavar='<number>', help=_(""Boot at least <number> servers (limited by quota)."")) @utils.arg( '--max-count', default=None, type=int, metavar='<number>', help=_(""Boot up to <number> servers (limited by quota)."")) @utils.arg( '--meta', metavar=""<key=value>"", action='append', default=[], help=_(""Record arbitrary key/value metadata to /meta_data.json "" ""on the metadata server. Can be specified multiple times."")) @utils.arg( '--file', metavar=""<dst-path=src-path>"", action='append', dest='files', default=[], help=_(""Store arbitrary files from <src-path> locally to <dst-path> "" ""on the new server. Limited by the injected_files quota value."")) @utils.arg( '--key-name', default=os.environ.get('NOVACLIENT_DEFAULT_KEY_NAME'), metavar='<key-name>', help=_(""Key name of keypair that should be created earlier with \ the command keypair-add."")) @utils.arg('name', metavar='<name>', help=_('Name for the new server.')) @utils.arg( '--user-data', default=None, metavar='<user-data>', help=_(""user data file to pass to be exposed by the metadata server."")) @utils.arg( '--availability-zone', default=None, metavar='<availability-zone>', help=_(""The availability zone for server placement."")) @utils.arg( '--security-groups', default=None, metavar='<security-groups>', help=_(""Comma separated list of security group names."")) @utils.arg( '--block-device-mapping', metavar=""<dev-name=mapping>"", action='append', default=[], help=_(""Block device mapping in the format "" ""<dev-name>=<id>:<type>:<size(GB)>:<delete-on-terminate>."")) @utils.arg( '--block-device', metavar=""key1=value1[,key2=value2...]"", action='append', default=[], start_version='2.0', end_version='2.31', help=_(""Block device mapping with the keys: "" ""id=UUID (image_id, snapshot_id or volume_id only if using source "" ""image, snapshot or volume) "" ""source=source type (image, snapshot, volume or blank), "" ""dest=destination type of the block device (volume or local), "" ""bus=device's bus (e.g. uml, lxc, virtio, ...; if omitted, "" ""hypervisor driver chooses a suitable default, "" ""honoured only if device type is supplied) "" ""type=device type (e.g. disk, cdrom, ...; defaults to 'disk') "" ""device=name of the device (e.g. vda, xda, ...; "" ""if omitted, hypervisor driver chooses suitable device "" ""depending on selected bus; note the libvirt driver always "" ""uses default device names), "" ""size=size of the block device in MB(for swap) and in "" ""GB(for other formats) "" ""(if omitted, hypervisor driver calculates size), "" ""format=device will be formatted (e.g. swap, ntfs, ...; optional), "" ""bootindex=integer used for ordering the boot disks "" ""(for image backed instances it is equal to 0, "" ""for others need to be specified) and "" ""shutdown=shutdown behaviour (either preserve or remove, "" ""for local destination set to remove)."")) @utils.arg( '--block-device', metavar=""key1=value1[,key2=value2...]"", action='append', default=[], start_version='2.32', help=_(""Block device mapping with the keys: "" ""id=UUID (image_id, snapshot_id or volume_id only if using source "" ""image, snapshot or volume) "" ""source=source type (image, snapshot, volume or blank), "" ""dest=destination type of the block device (volume or local), "" ""bus=device's bus (e.g. uml, lxc, virtio, ...; if omitted, "" ""hypervisor driver chooses a suitable default, "" ""honoured only if device type is supplied) "" ""type=device type (e.g. disk, cdrom, ...; defaults to 'disk') "" ""device=name of the device (e.g. vda, xda, ...; "" ""tag=device metadata tag (optional) "" ""if omitted, hypervisor driver chooses suitable device "" ""depending on selected bus; note the libvirt driver always "" ""uses default device names), "" ""size=size of the block device in MB(for swap) and in "" ""GB(for other formats) "" ""(if omitted, hypervisor driver calculates size), "" ""format=device will be formatted (e.g. swap, ntfs, ...; optional), "" ""bootindex=integer used for ordering the boot disks "" ""(for image backed instances it is equal to 0, "" ""for others need to be specified) and "" ""shutdown=shutdown behaviour (either preserve or remove, "" ""for local destination set to remove)."")) @utils.arg( '--swap', metavar=""<swap_size>"", default=None, help=_(""Create and attach a local swap block device of <swap_size> MB."")) @utils.arg( '--ephemeral', metavar=""size=<size>[,format=<format>]"", action='append', default=[], help=_(""Create and attach a local ephemeral block device of <size> GB "" ""and format it to <format>."")) @utils.arg( '--hint', action='append', dest='scheduler_hints', default=[], metavar='<key=value>', help=_(""Send arbitrary key/value pairs to the scheduler for custom "" ""use."")) @utils.arg( '--nic', metavar=""<net-id=net-uuid,net-name=network-name,v4-fixed-ip=ip-addr,"" ""v6-fixed-ip=ip-addr,port-id=port-uuid>"", action='append', dest='nics', default=[], start_version='2.0', end_version='2.31', help=_(""Create a NIC on the server. "" ""Specify option multiple times to create multiple NICs. "" ""net-id: attach NIC to network with this UUID "" ""net-name: attach NIC to network with this name "" ""(either port-id or net-id or net-name must be provided), "" ""v4-fixed-ip: IPv4 fixed address for NIC (optional), "" ""v6-fixed-ip: IPv6 fixed address for NIC (optional), "" ""port-id: attach NIC to port with this UUID "" ""(either port-id or net-id must be provided)."")) @utils.arg( '--nic', metavar=""<net-id=net-uuid,net-name=network-name,v4-fixed-ip=ip-addr,"" ""v6-fixed-ip=ip-addr,port-id=port-uuid>"", action='append', dest='nics', default=[], start_version='2.32', help=_(""Create a NIC on the server. "" ""Specify option multiple times to create multiple nics. "" ""net-id: attach NIC to network with this UUID "" ""net-name: attach NIC to network with this name "" ""(either port-id or net-id or net-name must be provided), "" ""v4-fixed-ip: IPv4 fixed address for NIC (optional), "" ""v6-fixed-ip: IPv6 fixed address for NIC (optional), "" ""port-id: attach NIC to port with this UUID "" ""tag: interface metadata tag (optional) "" ""(either port-id or net-id must be provided)."")) @utils.arg( '--config-drive', metavar=""<value>"", dest='config_drive', default=False, help=_(""Enable config drive."")) @utils.arg( '--poll', dest='poll', action=""store_true"", default=False, help=_('Report the new server boot progress until it completes.')) @utils.arg( '--admin-pass', dest='admin_pass', metavar='<value>', default=None, help=_('Admin password for the instance.')) @utils.arg( '--access-ip-v4', dest='access_ip_v4', metavar='<value>', default=None, help=_('Alternative access IPv4 of the instance.')) @utils.arg( '--access-ip-v6', dest='access_ip_v6', metavar='<value>', default=None, help=_('Alternative access IPv6 of the instance.')) @utils.arg( '--description', metavar='<description>', dest='description', default=None, help=_('Description for the server.'), start_version=""2.19"") def do_boot(cs, args): """"""Boot a new server."""""" boot_args, boot_kwargs = _boot(cs, args) extra_boot_kwargs = utils.get_resource_manager_extra_kwargs(do_boot, args) boot_kwargs.update(extra_boot_kwargs) server = cs.servers.create(*boot_args, **boot_kwargs) _print_server(cs, args, server) if args.poll: _poll_for_status(cs.servers.get, server.id, 'building', ['active']) def do_cloudpipe_list(cs, _args): """"""Print a list of all cloudpipe instances."""""" cloudpipes = cs.cloudpipe.list() columns = ['Project Id', ""Public IP"", ""Public Port"", ""Internal IP""] utils.print_list(cloudpipes, columns) @utils.arg( 'project', metavar='<project_id>', help=_('UUID of the project to create the cloudpipe for.')) def do_cloudpipe_create(cs, args): """"""Create a cloudpipe instance for the given project."""""" cs.cloudpipe.create(args.project) @utils.arg('address', metavar='<ip address>', help=_('New IP Address.')) @utils.arg('port', metavar='<port>', help=_('New Port.')) def do_cloudpipe_configure(cs, args): """"""Update the VPN IP/port of a cloudpipe instance."""""" cs.cloudpipe.update(args.address, args.port) def _poll_for_status(poll_fn, obj_id, action, final_ok_states, poll_period=5, show_progress=True, status_field=""status"", silent=False): """"""Block while an action is being performed, periodically printing progress. """""" def print_progress(progress): if show_progress: msg = (_('\rServer %(action)s... %(progress)s%% complete') % dict(action=action, progress=progress)) else: msg = _('\rServer %(action)s...') % dict(action=action) sys.stdout.write(msg) sys.stdout.flush() if not silent: print() while True: obj = poll_fn(obj_id) status = getattr(obj, status_field) if status: status = status.lower() progress = getattr(obj, 'progress', None) or 0 if status in final_ok_states: if not silent: print_progress(100) print(_(""\nFinished"")) break elif status == ""error"": if not silent: print(_(""\nError %s server"") % action) raise exceptions.ResourceInErrorState(obj) elif status == ""deleted"": if not silent: print(_(""\nDeleted %s server"") % action) raise exceptions.InstanceInDeletedState(obj.fault[""message""]) if not silent: print_progress(progress) time.sleep(poll_period) def _translate_keys(collection, convert): for item in collection: keys = item.__dict__.keys() for from_key, to_key in convert: if from_key in keys and to_key not in keys: setattr(item, to_key, item._info[from_key]) def _translate_extended_states(collection): power_states = [ 'NOSTATE', # 0x00 'Running', # 0x01 '', # 0x02 'Paused', # 0x03 'Shutdown', # 0x04 '', # 0x05 'Crashed', # 0x06 'Suspended' # 0x07 ] for item in collection: try: setattr(item, 'power_state', power_states[getattr(item, 'power_state')]) except AttributeError: setattr(item, 'power_state', ""N/A"") try: getattr(item, 'task_state') except AttributeError: setattr(item, 'task_state', ""N/A"") def _translate_flavor_keys(collection): _translate_keys(collection, [('ram', 'memory_mb')]) def _print_flavor_extra_specs(flavor): try: return flavor.get_keys() except exceptions.NotFound: return ""N/A"" def _print_flavor_list(flavors, show_extra_specs=False): _translate_flavor_keys(flavors) headers = [ 'ID', 'Name', 'Memory_MB', 'Disk', 'Ephemeral', 'Swap', 'VCPUs', 'RXTX_Factor', 'Is_Public', ] if show_extra_specs: formatters = {'extra_specs': _print_flavor_extra_specs} headers.append('extra_specs') else: formatters = {} utils.print_list(flavors, headers, formatters) @utils.arg( '--extra-specs', dest='extra_specs', action='store_true', default=False, help=_('Get extra-specs of each flavor.')) @utils.arg( '--all', dest='all', action='store_true', default=False, help=_('Display all flavors (Admin only).')) @utils.arg( '--marker', dest='marker', metavar='<marker>', default=None, help=_('The last flavor ID of the previous page; displays list of flavors' ' after ""marker"".')) @utils.arg( '--limit', dest='limit', metavar='<limit>', type=int, default=None, help=_(""Maximum number of flavors to display. If limit == -1, all flavors "" ""will be displayed. If limit is bigger than 'osapi_max_limit' "" ""option of Nova API, limit 'osapi_max_limit' will be used "" ""instead."")) def do_flavor_list(cs, args): """"""Print a list of available 'flavors' (sizes of servers)."""""" if args.all: flavors = cs.flavors.list(is_public=None) else: flavors = cs.flavors.list(marker=args.marker, limit=args.limit) _print_flavor_list(flavors, args.extra_specs) @utils.arg( 'flavor', metavar='<flavor>', help=_(""Name or ID of the flavor to delete."")) def do_flavor_delete(cs, args): """"""Delete a specific flavor"""""" flavorid = _find_flavor(cs, args.flavor) cs.flavors.delete(flavorid) _print_flavor_list([flavorid]) @utils.arg( 'flavor', metavar='<flavor>', help=_(""Name or ID of flavor."")) def do_flavor_show(cs, args): """"""Show details about the given flavor."""""" flavor = _find_flavor(cs, args.flavor) _print_flavor(flavor) @utils.arg( 'name', metavar='<name>', help=_(""Unique name of the new flavor."")) @utils.arg( 'id', metavar='<id>', help=_(""Unique ID of the new flavor."" "" Specifying 'auto' will generated a UUID for the ID."")) @utils.arg( 'ram', metavar='<ram>', help=_(""Memory size in MB."")) @utils.arg( 'disk', metavar='<disk>', help=_(""Disk size in GB."")) @utils.arg( '--ephemeral', metavar='<ephemeral>', help=_(""Ephemeral space size in GB (default 0).""), default=0) @utils.arg( 'vcpus', metavar='<vcpus>', help=_(""Number of vcpus"")) @utils.arg( '--swap', metavar='<swap>', help=_(""Swap space size in MB (default 0).""), default=0) @utils.arg( '--rxtx-factor', metavar='<factor>', help=_(""RX/TX factor (default 1).""), default=1.0) @utils.arg( '--is-public', metavar='<is-public>', help=_(""Make flavor accessible to the public (default true).""), type=lambda v: strutils.bool_from_string(v, True), default=True) def do_flavor_create(cs, args): """"""Create a new flavor."""""" f = cs.flavors.create(args.name, args.ram, args.vcpus, args.disk, args.id, args.ephemeral, args.swap, args.rxtx_factor, args.is_public) _print_flavor_list([f]) @utils.arg( 'flavor', metavar='<flavor>', help=_(""Name or ID of flavor."")) @utils.arg( 'action', metavar='<action>', choices=['set', 'unset'], help=_(""Actions: 'set' or 'unset'."")) @utils.arg( 'metadata', metavar='<key=value>', nargs='+', action='append', default=[], help=_('Extra_specs to set/unset (only key is necessary on unset).')) def do_flavor_key(cs, args): """"""Set or unset extra_spec for a flavor."""""" flavor = _find_flavor(cs, args.flavor) keypair = _extract_metadata(args) if args.action == 'set': flavor.set_keys(keypair) elif args.action == 'unset': flavor.unset_keys(keypair.keys()) @utils.arg( '--flavor', metavar='<flavor>', help=_(""Filter results by flavor name or ID."")) @utils.arg( '--tenant', metavar='<tenant_id>', help=_('Filter results by tenant ID.'), action=shell.DeprecatedAction, real_action='nothing', use=_('this option is not supported, and will be ' 'removed in version 5.0.0.')) def do_flavor_access_list(cs, args): """"""Print access information about the given flavor."""""" if args.flavor: flavor = _find_flavor(cs, args.flavor) if flavor.is_public: raise exceptions.CommandError(_(""Access list not available "" ""for public flavors."")) kwargs = {'flavor': flavor} else: raise exceptions.CommandError(_(""Unable to get all access lists. "" ""Specify --flavor"")) try: access_list = cs.flavor_access.list(**kwargs) except NotImplementedError as e: raise exceptions.CommandError(""%s"" % str(e)) columns = ['Flavor_ID', 'Tenant_ID'] utils.print_list(access_list, columns) @utils.arg( 'flavor', metavar='<flavor>', help=_(""Flavor name or ID to add access for the given tenant."")) @utils.arg( 'tenant', metavar='<tenant_id>', help=_('Tenant ID to add flavor access for.')) def do_flavor_access_add(cs, args): """"""Add flavor access for the given tenant."""""" flavor = _find_flavor(cs, args.flavor) access_list = cs.flavor_access.add_tenant_access(flavor, args.tenant) columns = ['Flavor_ID', 'Tenant_ID'] utils.print_list(access_list, columns) @utils.arg( 'flavor', metavar='<flavor>', help=_(""Flavor name or ID to remove access for the given tenant."")) @utils.arg( 'tenant', metavar='<tenant_id>', help=_('Tenant ID to remove flavor access for.')) def do_flavor_access_remove(cs, args): """"""Remove flavor access for the given tenant."""""" flavor = _find_flavor(cs, args.flavor) access_list = cs.flavor_access.remove_tenant_access(flavor, args.tenant) columns = ['Flavor_ID', 'Tenant_ID'] utils.print_list(access_list, columns) @utils.arg( 'project_id', metavar='<project_id>', help=_('The ID of the project.')) @deprecated_network def do_scrub(cs, args): """"""Delete networks and security groups associated with a project."""""" networks_list = cs.networks.list() networks_list = [network for network in networks_list if getattr(network, 'project_id', '') == args.project_id] search_opts = {'all_tenants': 1} groups = cs.security_groups.list(search_opts) groups = [group for group in groups if group.tenant_id == args.project_id] for network in networks_list: cs.networks.disassociate(network) for group in groups: cs.security_groups.delete(group) @utils.arg( '--fields', default=None, metavar='<fields>', help=_('Comma-separated list of fields to display. ' 'Use the show command to see which fields are available.')) @deprecated_network def do_network_list(cs, args): """"""Print a list of available networks."""""" network_list = cs.networks.list() columns = ['ID', 'Label', 'Cidr'] columns += _get_list_table_columns_and_formatters( args.fields, network_list, exclude_fields=(c.lower() for c in columns))[0] utils.print_list(network_list, columns) @utils.arg( 'network', metavar='<network>', help=_(""UUID or label of network."")) @deprecated_network def do_network_show(cs, args): """"""Show details about the given network."""""" network = utils.find_resource(cs.networks, args.network) utils.print_dict(network._info) @utils.arg( 'network', metavar='<network>', help=_(""UUID or label of network."")) @deprecated_network def do_network_delete(cs, args): """"""Delete network by label or id."""""" network = utils.find_resource(cs.networks, args.network) network.delete() @utils.arg( '--host-only', dest='host_only', metavar='<0|1>', nargs='?', type=int, const=1, default=0) @utils.arg( '--project-only', dest='project_only', metavar='<0|1>', nargs='?', type=int, const=1, default=0) @utils.arg( 'network', metavar='<network>', help=_(""UUID of network."")) @deprecated_network def do_network_disassociate(cs, args): """"""Disassociate host and/or project from the given network."""""" if args.host_only: cs.networks.disassociate(args.network, True, False) elif args.project_only: cs.networks.disassociate(args.network, False, True) else: cs.networks.disassociate(args.network, True, True) @utils.arg( 'network', metavar='<network>', help=_(""UUID of network."")) @utils.arg( 'host', metavar='<host>', help=_(""Name of host"")) @deprecated_network def do_network_associate_host(cs, args): """"""Associate host with network."""""" cs.networks.associate_host(args.network, args.host) @utils.arg( 'network', metavar='<network>', help=_(""UUID of network."")) @deprecated_network def do_network_associate_project(cs, args): """"""Associate project with network."""""" cs.networks.associate_project(args.network) def _filter_network_create_options(args): valid_args = ['label', 'cidr', 'vlan_start', 'vpn_start', 'cidr_v6', 'gateway', 'gateway_v6', 'bridge', 'bridge_interface', 'multi_host', 'dns1', 'dns2', 'uuid', 'fixed_cidr', 'project_id', 'priority', 'vlan', 'mtu', 'dhcp_server', 'allowed_start', 'allowed_end'] kwargs = {} for k, v in args.__dict__.items(): if k in valid_args and v is not None: kwargs[k] = v return kwargs @utils.arg( 'label', metavar='<network_label>', help=_(""Label for network"")) @utils.arg( '--fixed-range-v4', dest='cidr', metavar='<x.x.x.x/yy>', help=_(""IPv4 subnet (ex: 10.0.0.0/8)"")) @utils.arg( '--fixed-range-v6', dest=""cidr_v6"", help=_('IPv6 subnet (ex: fe80::/64')) @utils.arg( '--vlan', dest='vlan', type=int, metavar='<vlan id>', help=_(""The vlan ID to be assigned to the project."")) @utils.arg( '--vlan-start', dest='vlan_start', type=int, metavar='<vlan start>', help=_('First vlan ID to be assigned to the project. Subsequent vlan ' 'IDs will be assigned incrementally.')) @utils.arg( '--vpn', dest='vpn_start', type=int, metavar='<vpn start>', help=_(""vpn start"")) @utils.arg( '--gateway', dest=""gateway"", help=_('gateway')) @utils.arg( '--gateway-v6', dest=""gateway_v6"", help=_('IPv6 gateway')) @utils.arg( '--bridge', dest=""bridge"", metavar='<bridge>', help=_('VIFs on this network are connected to this bridge.')) @utils.arg( '--bridge-interface', dest=""bridge_interface"", metavar='<bridge interface>', help=_('The bridge is connected to this interface.')) @utils.arg( '--multi-host', dest=""multi_host"", metavar=""<'T'|'F'>"", help=_('Multi host')) @utils.arg( '--dns1', dest=""dns1"", metavar=""<DNS Address>"", help=_('First DNS.')) @utils.arg( '--dns2', dest=""dns2"", metavar=""<DNS Address>"", help=_('Second DNS.')) @utils.arg( '--uuid', dest=""uuid"", metavar=""<network uuid>"", help=_('Network UUID.')) @utils.arg( '--fixed-cidr', dest=""fixed_cidr"", metavar='<x.x.x.x/yy>', help=_('IPv4 subnet for fixed IPs (ex: 10.20.0.0/16).')) @utils.arg( '--project-id', dest=""project_id"", metavar=""<project id>"", help=_('Project ID.')) @utils.arg( '--priority', dest=""priority"", metavar=""<number>"", help=_('Network interface priority.')) @utils.arg( '--mtu', dest=""mtu"", type=int, help=_('MTU for network.')) @utils.arg( '--enable-dhcp', dest=""enable_dhcp"", metavar=""<'T'|'F'>"", help=_('Enable DHCP.')) @utils.arg( '--dhcp-server', dest=""dhcp_server"", help=_('DHCP-server address (defaults to gateway address)')) @utils.arg( '--share-address', dest=""share_address"", metavar=""<'T'|'F'>"", help=_('Share address')) @utils.arg( '--allowed-start', dest=""allowed_start"", help=_('Start of allowed addresses for instances.')) @utils.arg( '--allowed-end', dest=""allowed_end"", help=_('End of allowed addresses for instances.')) @deprecated_network def do_network_create(cs, args): """"""Create a network."""""" if not (args.cidr or args.cidr_v6): raise exceptions.CommandError( _(""Must specify either fixed_range_v4 or fixed_range_v6"")) kwargs = _filter_network_create_options(args) if args.multi_host is not None: kwargs['multi_host'] = bool(args.multi_host == 'T' or strutils.bool_from_string(args.multi_host)) if args.enable_dhcp is not None: kwargs['enable_dhcp'] = bool( args.enable_dhcp == 'T' or strutils.bool_from_string(args.enable_dhcp)) if args.share_address is not None: kwargs['share_address'] = bool( args.share_address == 'T' or strutils.bool_from_string(args.share_address)) cs.networks.create(**kwargs) @utils.arg( '--limit', dest=""limit"", metavar=""<limit>"", help=_('Number of images to return per request.')) def do_image_list(cs, _args): """"""DEPRECATED: Print a list of available images to boot from."""""" emit_image_deprecation_warning('image-list') limit = _args.limit image_list = cs.images.list(limit=limit) def parse_server_name(image): try: return image.server['id'] except (AttributeError, KeyError): return '' fmts = {'Server': parse_server_name} utils.print_list(image_list, ['ID', 'Name', 'Status', 'Server'], fmts, sortby_index=1) @utils.arg( 'image', metavar='<image>', help=_(""Name or ID of image."")) @utils.arg( 'action', metavar='<action>', choices=['set', 'delete'], help=_(""Actions: 'set' or 'delete'."")) @utils.arg( 'metadata', metavar='<key=value>', nargs='+', action='append', default=[], help=_('Metadata to add/update or delete (only key is necessary on ' 'delete).')) def do_image_meta(cs, args): """"""DEPRECATED: Set or delete metadata on an image."""""" emit_image_deprecation_warning('image-meta') image = _find_image(cs, args.image) metadata = _extract_metadata(args) if args.action == 'set': cs.images.set_meta(image, metadata) elif args.action == 'delete': cs.images.delete_meta(image, metadata.keys()) def _extract_metadata(args): metadata = {} for metadatum in args.metadata[0]: # Can only pass the key in on 'delete' # So this doesn't have to have '=' if metadatum.find('=') > -1: (key, value) = metadatum.split('=', 1) else: key = metadatum value = None metadata[key] = value return metadata def _print_image(image): info = image._info.copy() # ignore links, we don't need to present those info.pop('links', None) # try to replace a server entity to just an id server = info.pop('server', None) try: info['server'] = server['id'] except (KeyError, TypeError): pass # break up metadata and display each on its own row metadata = info.pop('metadata', {}) try: for key, value in metadata.items(): _key = 'metadata %s' % key info[_key] = value except AttributeError: pass utils.print_dict(info) def _print_flavor(flavor): info = flavor._info.copy() # ignore links, we don't need to present those info.pop('links') info.update({""extra_specs"": _print_flavor_extra_specs(flavor)}) utils.print_dict(info) @utils.arg( 'image', metavar='<image>', help=_(""Name or ID of image."")) def do_image_show(cs, args): """"""DEPRECATED: Show details about the given image."""""" emit_image_deprecation_warning('image-show') image = _find_image(cs, args.image) _print_image(image) @utils.arg( 'image', metavar='<image>', nargs='+', help=_('Name or ID of image(s).')) def do_image_delete(cs, args): """"""DEPRECATED: Delete specified image(s)."""""" emit_image_deprecation_warning('image-delete') for image in args.image: try: # _find_image is using the GlanceManager which doesn't implement # the delete() method so use the ImagesManager for that. image = _find_image(cs, image) cs.images.delete(image) except Exception as e: print(_(""Delete for image %(image)s failed: %(e)s"") % {'image': image, 'e': e}) @utils.arg( '--reservation-id', dest='reservation_id', metavar='<reservation-id>', default=None, help=_('Only return servers that match reservation-id.')) @utils.arg( '--ip', dest='ip', metavar='<ip-regexp>', default=None, help=_('Search with regular expression match by IP address.')) @utils.arg( '--ip6', dest='ip6', metavar='<ip6-regexp>', default=None, help=_('Search with regular expression match by IPv6 address.')) @utils.arg( '--name', dest='name', metavar='<name-regexp>', default=None, help=_('Search with regular expression match by name.')) @utils.arg( '--instance-name', dest='instance_name', metavar='<name-regexp>', default=None, help=_('Search with regular expression match by server name.')) @utils.arg( '--status', dest='status', metavar='<status>', default=None, help=_('Search by server status.')) @utils.arg( '--flavor', dest='flavor', metavar='<flavor>', default=None, help=_('Search by flavor name or ID.')) @utils.arg( '--image', dest='image', metavar='<image>', default=None, help=_('Search by image name or ID.')) @utils.arg( '--host', dest='host', metavar='<hostname>', default=None, help=_('Search servers by hostname to which they are assigned (Admin ' 'only).')) @utils.arg( '--all-tenants', dest='all_tenants', metavar='<0|1>', nargs='?', type=int, const=1, default=int(strutils.bool_from_string( os.environ.get(""ALL_TENANTS"", 'false'), True)), help=_('Display information from all tenants (Admin only).')) @utils.arg( '--tenant', # nova db searches by project_id dest='tenant', metavar='<tenant>', nargs='?', help=_('Display information from single tenant (Admin only).')) @utils.arg( '--user', dest='user', metavar='<user>', nargs='?', help=_('Display information from single user (Admin only).')) @utils.arg( '--deleted', dest='deleted', action=""store_true"", default=False, help=_('Only display deleted servers (Admin only).')) @utils.arg( '--fields', default=None, metavar='<fields>', help=_('Comma-separated list of fields to display. ' 'Use the show command to see which fields are available.')) @utils.arg( '--minimal', dest='minimal', action=""store_true"", default=False, help=_('Get only UUID and name.')) @utils.arg( '--sort', dest='sort', metavar='<key>[:<direction>]', help=_('Comma-separated list of sort keys and directions in the form ' 'of <key>[:<asc|desc>]. The direction defaults to descending if ' 'not specified.')) @utils.arg( '--marker', dest='marker', metavar='<marker>', default=None, help=_('The last server UUID of the previous page; displays list of ' 'servers after ""marker"".')) @utils.arg( '--limit', dest='limit', metavar='<limit>', type=int, default=None, help=_(""Maximum number of servers to display. If limit == -1, all servers "" ""will be displayed. If limit is bigger than 'osapi_max_limit' "" ""option of Nova API, limit 'osapi_max_limit' will be used "" ""instead."")) @utils.arg( '--changes-since', dest='changes_since', metavar='<changes_since>', default=None, help=_(""List only servers changed after a certain point of time."" ""The provided time should be an ISO 8061 formatted time."" ""ex 2016-03-04T06:27:59Z ."")) @utils.arg( '--tags', dest='tags', metavar='<tags>', default=None, help=_(""The given tags must all be present for a server to be included in "" ""the list result. Boolean expression in this case is 't1 AND t2'. "" ""Tags must be separated by commas: --tags <tag1,tag2>""), start_version=""2.26"") @utils.arg( '--tags-any', dest='tags-any', metavar='<tags-any>', default=None, help=_(""If one of the given tags is present the server will be included "" ""in the list result. Boolean expression in this case is "" ""'t1 OR t2'. Tags must be separated by commas: "" ""--tags-any <tag1,tag2>""), start_version=""2.26"") @utils.arg( '--not-tags', dest='not-tags', metavar='<not-tags>', default=None, help=_(""Only the servers that do not have any of the given tags will"" ""be included in the list results. Boolean expression in this case "" ""is 'NOT(t1 AND t2)'. Tags must be separated by commas: "" ""--not-tags <tag1,tag2>""), start_version=""2.26"") @utils.arg( '--not-tags-any', dest='not-tags-any', metavar='<not-tags-any>', default=None, help=_(""Only the servers that do not have at least one of the given tags"" ""will be included in the list result. Boolean expression in this "" ""case is 'NOT(t1 OR t2)'. Tags must be separated by commas: "" ""--not-tags-any <tag1,tag2>""), start_version=""2.26"") def do_list(cs, args): """"""List active servers."""""" imageid = None flavorid = None if args.image: imageid = _find_image(cs, args.image).id if args.flavor: flavorid = _find_flavor(cs, args.flavor).id # search by tenant or user only works with all_tenants if args.tenant or args.user: args.all_tenants = 1 search_opts = { 'all_tenants': args.all_tenants, 'reservation_id': args.reservation_id, 'ip': args.ip, 'ip6': args.ip6, 'name': args.name, 'image': imageid, 'flavor': flavorid, 'status': args.status, 'tenant_id': args.tenant, 'user_id': args.user, 'host': args.host, 'deleted': args.deleted, 'instance_name': args.instance_name, 'changes-since': args.changes_since} for arg in ('tags', ""tags-any"", 'not-tags', 'not-tags-any'): if arg in args: search_opts[arg] = getattr(args, arg) filters = {'flavor': lambda f: f['id'], 'security_groups': utils.format_security_groups} id_col = 'ID' detailed = not args.minimal sort_keys = [] sort_dirs = [] if args.sort: for sort in args.sort.split(','): sort_key, _sep, sort_dir = sort.partition(':') if not sort_dir: sort_dir = 'desc' elif sort_dir not in ('asc', 'desc'): raise exceptions.CommandError(_( 'Unknown sort direction: %s') % sort_dir) sort_keys.append(sort_key) sort_dirs.append(sort_dir) if search_opts['changes-since']: try: timeutils.parse_isotime(search_opts['changes-since']) except ValueError: raise exceptions.CommandError(_('Invalid changes-since value: %s') % search_opts['changes-since']) servers = cs.servers.list(detailed=detailed, search_opts=search_opts, sort_keys=sort_keys, sort_dirs=sort_dirs, marker=args.marker, limit=args.limit) convert = [('OS-EXT-SRV-ATTR:host', 'host'), ('OS-EXT-STS:task_state', 'task_state'), ('OS-EXT-SRV-ATTR:instance_name', 'instance_name'), ('OS-EXT-STS:power_state', 'power_state'), ('hostId', 'host_id')] _translate_keys(servers, convert) _translate_extended_states(servers) formatters = {} cols, fmts = _get_list_table_columns_and_formatters( args.fields, servers, exclude_fields=('id',), filters=filters) if args.minimal: columns = [ id_col, 'Name'] elif cols: columns = [id_col] + cols formatters.update(fmts) else: columns = [ id_col, 'Name', 'Status', 'Task State', 'Power State', 'Networks' ] # If getting the data for all tenants, print # Tenant ID as well if search_opts['all_tenants']: columns.insert(2, 'Tenant ID') if search_opts['changes-since']: columns.append('Updated') formatters['Networks'] = utils.format_servers_list_networks sortby_index = 1 if args.sort: sortby_index = None utils.print_list(servers, columns, formatters, sortby_index=sortby_index) def _get_list_table_columns_and_formatters(fields, objs, exclude_fields=(), filters=None): """"""Check and add fields to output columns. If there is any value in fields that not an attribute of obj, CommandError will be raised. If fields has duplicate values (case sensitive), we will make them unique and ignore duplicate ones. If exclude_fields is specified, any field both in fields and exclude_fields will be ignored. :param fields: A list of string contains the fields to be printed. :param objs: An list of object which will be used to check if field is valid or not. Note, we don't check fields if obj is None or empty. :param exclude_fields: A tuple of string which contains the fields to be excluded. :param filters: A dictionary defines how to get value from fields, this is useful when field's value is a complex object such as dictionary. :return: columns, formatters. columns is a list of string which will be used as table header. formatters is a dictionary specifies how to display the value of the field. They can be [], {}. :raise: novaclient.exceptions.CommandError """""" if not fields: return [], {} if not objs: obj = None elif isinstance(objs, list): obj = objs[0] else: obj = objs columns = [] formatters = {} non_existent_fields = [] exclude_fields = set(exclude_fields) for field in fields.split(','): if not hasattr(obj, field): non_existent_fields.append(field) continue if field in exclude_fields: continue field_title, formatter = utils.make_field_formatter(field, filters) columns.append(field_title) formatters[field_title] = formatter exclude_fields.add(field) if non_existent_fields: raise exceptions.CommandError( _(""Non-existent fields are specified: %s"") % non_existent_fields) return columns, formatters @utils.arg( '--hard', dest='reboot_type', action='store_const', const=servers.REBOOT_HARD, default=servers.REBOOT_SOFT, help=_('Perform a hard reboot (instead of a soft one). ' 'Note: Ironic does not currently support soft reboot; ' 'consequently, bare metal nodes will always do a hard ' 'reboot, regardless of the use of this option.')) @utils.arg( 'server', metavar='<server>', nargs='+', help=_('Name or ID of server(s).')) @utils.arg( '--poll', dest='poll', action=""store_true"", default=False, help=_('Poll until reboot is complete.')) def do_reboot(cs, args): """"""Reboot a server."""""" servers = [_find_server(cs, s) for s in args.server] utils.do_action_on_many( lambda s: s.reboot(args.reboot_type), servers, _(""Request to reboot server %s has been accepted.""), _(""Unable to reboot the specified server(s)."")) if args.poll: utils.do_action_on_many( lambda s: _poll_for_status(cs.servers.get, s.id, 'rebooting', ['active'], show_progress=False), servers, _(""Wait for server %s reboot.""), _(""Wait for specified server(s) failed."")) @utils.arg('server', metavar='<server>', help=_('Name or ID of server.')) @utils.arg('image', metavar='<image>', help=_(""Name or ID of new image."")) @utils.arg( '--rebuild-password', dest='rebuild_password', metavar='<rebuild-password>', default=False, help=_(""Set the provided admin password on the rebuilt server."")) @utils.arg( '--poll', dest='poll', action=""store_true"", default=False, help=_('Report the server rebuild progress until it completes.')) @utils.arg( '--minimal', dest='minimal', action=""store_true"", default=False, help=_('Skips flavor/image lookups when showing servers.')) @utils.arg( '--preserve-ephemeral', action=""store_true"", default=False, help=_('Preserve the default ephemeral storage partition on rebuild.')) @utils.arg( '--name', metavar='<name>', default=None, help=_('Name for the new server.')) @utils.arg( '--description', metavar='<description>', dest='description', default=None, help=_('New description for the server.'), start_version=""2.19"") @utils.arg( '--meta', metavar=""<key=value>"", action='append', default=[], help=_(""Record arbitrary key/value metadata to /meta_data.json "" ""on the metadata server. Can be specified multiple times."")) @utils.arg( '--file', metavar=""<dst-path=src-path>"", action='append', dest='files', default=[], help=_(""Store arbitrary files from <src-path> locally to <dst-path> "" ""on the new server. You may store up to 5 files."")) def do_rebuild(cs, args): """"""Shutdown, re-image, and re-boot a server."""""" server = _find_server(cs, args.server) image = _find_image(cs, args.image) if args.rebuild_password is not False: _password = args.rebuild_password else: _password = None kwargs = utils.get_resource_manager_extra_kwargs(do_rebuild, args) kwargs['preserve_ephemeral'] = args.preserve_ephemeral kwargs['name'] = args.name if 'description' in args: kwargs['description'] = args.description meta = _meta_parsing(args.meta) kwargs['meta'] = meta files = {} for f in args.files: try: dst, src = f.split('=', 1) with open(src, 'r') as s: files[dst] = s.read() except IOError as e: raise exceptions.CommandError(_(""Can't open '%(src)s': %(exc)s"") % {'src': src, 'exc': e}) except ValueError: raise exceptions.CommandError(_(""Invalid file argument '%s'. "" ""File arguments must be of the "" ""form '--file "" ""<dst-path=src-path>'"") % f) kwargs['files'] = files server = server.rebuild(image, _password, **kwargs) _print_server(cs, args, server) if args.poll: _poll_for_status(cs.servers.get, server.id, 'rebuilding', ['active']) @utils.arg( 'server', metavar='<server>', help=_('Name (old name) or ID of server.')) @utils.arg('name', metavar='<name>', help=_('New name for the server.')) def do_rename(cs, args): """"""DEPRECATED, use update instead."""""" do_update(cs, args) @utils.arg( 'server', metavar='<server>', help=_('Name (old name) or ID of server.')) @utils.arg( '--name', metavar='<name>', dest='name', default=None, help=_('New name for the server.')) @utils.arg( '--description', metavar='<description>', dest='description', default=None, help=_('New description for the server. If it equals to empty string ' '(i.g. """"), the server description will be removed.'), start_version=""2.19"") def do_update(cs, args): """"""Update the name or the description for a server."""""" update_kwargs = {} if args.name: update_kwargs[""name""] = args.name # NOTE(andreykurilin): `do_update` method is used by `do_rename` method, # which do not have description argument at all. When `do_rename` will be # removed after deprecation period, feel free to change the check below to: # `if args.description:` if ""description"" in args and args.description is not None: update_kwargs[""description""] = args.description _find_server(cs, args.server).update(**update_kwargs) @utils.arg('server', metavar='<server>', help=_('Name or ID of server.')) @utils.arg( 'flavor', metavar='<flavor>', help=_(""Name or ID of new flavor."")) @utils.arg( '--poll', dest='poll', action=""store_true"", default=False, help=_('Report the server resize progress until it completes.')) def do_resize(cs, args): """"""Resize a server."""""" server = _find_server(cs, args.server) flavor = _find_flavor(cs, args.flavor) kwargs = utils.get_resource_manager_extra_kwargs(do_resize, args) server.resize(flavor, **kwargs) if args.poll: _poll_for_status(cs.servers.get, server.id, 'resizing', ['active', 'verify_resize']) @utils.arg('server', metavar='<server>', help=_('Name or ID of server.')) def do_resize_confirm(cs, args): """"""Confirm a previous resize."""""" _find_server(cs, args.server).confirm_resize() @utils.arg('server', metavar='<server>', help=_('Name or ID of server.')) def do_resize_revert(cs, args): """"""Revert a previous resize (and return to the previous VM)."""""" _find_server(cs, args.server).revert_resize() @utils.arg('server', metavar='<server>', help=_('Name or ID of server.')) @utils.arg( '--poll', dest='poll', action=""store_true"", default=False, help=_('Report the server migration progress until it completes.')) def do_migrate(cs, args): """"""Migrate a server. The new host will be selected by the scheduler."""""" server = _find_server(cs, args.server) server.migrate() if args.poll: _poll_for_status(cs.servers.get, server.id, 'migrating', ['active', 'verify_resize']) @utils.arg('server', metavar='<server>', help=_('Name or ID of server.')) def do_pause(cs, args): """"""Pause a server."""""" _find_server(cs, args.server).pause() @utils.arg('server', metavar='<server>', help=_('Name or ID of server.')) def do_unpause(cs, args): """"""Unpause a server."""""" _find_server(cs, args.server).unpause() @utils.arg( '--all-tenants', action='store_const', const=1, default=0, help=_('Stop server(s) in another tenant by name (Admin only).')) @utils.arg( 'server', metavar='<server>', nargs='+', help=_('Name or ID of server(s).')) def do_stop(cs, args): """"""Stop the server(s)."""""" find_args = {'all_tenants': args.all_tenants} utils.do_action_on_many( lambda s: _find_server(cs, s, **find_args).stop(), args.server, _(""Request to stop server %s has been accepted.""), _(""Unable to stop the specified server(s)."")) @utils.arg( '--all-tenants', action='store_const', const=1, default=0, help=_('Start server(s) in another tenant by name (Admin only).')) @utils.arg( 'server', metavar='<server>', nargs='+', help=_('Name or ID of server(s).')) def do_start(cs, args): """"""Start the server(s)."""""" find_args = {'all_tenants': args.all_tenants} utils.do_action_on_many( lambda s: _find_server(cs, s, **find_args).start(), args.server, _(""Request to start server %s has been accepted.""), _(""Unable to start the specified server(s)."")) @utils.arg('server', metavar='<server>', help=_('Name or ID of server.')) def do_lock(cs, args): """"""Lock a server. A normal (non-admin) user will not be able to execute actions on a locked server. """""" _find_server(cs, args.server).lock() @utils.arg('server', metavar='<server>', help=_('Name or ID of server.')) def do_unlock(cs, args): """"""Unlock a server."""""" _find_server(cs, args.server).unlock() @utils.arg('server', metavar='<server>', help=_('Name or ID of server.')) def do_suspend(cs, args): """"""Suspend a server."""""" _find_server(cs, args.server).suspend() @utils.arg('server', metavar='<server>', help=_('Name or ID of server.')) def do_resume(cs, args): """"""Resume a server."""""" _find_server(cs, args.server).resume() @utils.arg('server', metavar='<server>', help=_('Name or ID of server.')) @utils.arg( '--password', metavar='<password>', dest='password', help=_('The admin password to be set in the rescue environment.')) @utils.arg( '--image', metavar='<image>', dest='image', help=_('The image to rescue with.')) def do_rescue(cs, args): """"""Reboots a server into rescue mode, which starts the machine from either the initial image or a specified image, attaching the current boot disk as secondary. """""" kwargs = {} if args.image: kwargs['image'] = _find_image(cs, args.image) if args.password: kwargs['password'] = args.password utils.print_dict(_find_server(cs, args.server).rescue(**kwargs)[1]) @utils.arg('server', metavar='<server>', help=_('Name or ID of server.')) def do_unrescue(cs, args): """"""Restart the server from normal boot disk again."""""" _find_server(cs, args.server).unrescue() @utils.arg('server', metavar='<server>', help=_('Name or ID of server.')) def do_shelve(cs, args): """"""Shelve a server."""""" _find_server(cs, args.server).shelve() @utils.arg('server', metavar='<server>', help=_('Name or ID of server.')) def do_shelve_offload(cs, args): """"""Remove a shelved server from the compute node."""""" _find_server(cs, args.server).shelve_offload() @utils.arg('server', metavar='<server>', help=_('Name or ID of server.')) def do_unshelve(cs, args): """"""Unshelve a server."""""" _find_server(cs, args.server).unshelve() @utils.arg('server', metavar='<server>', help=_('Name or ID of server.')) def do_diagnostics(cs, args): """"""Retrieve server diagnostics."""""" server = _find_server(cs, args.server) utils.print_dict(cs.servers.diagnostics(server)[1], wrap=80) @utils.arg( 'server', metavar='<server>', help=_('Name or ID of a server for which the network cache should ' 'be refreshed from neutron (Admin only).')) def do_refresh_network(cs, args): """"""Refresh server network information."""""" server = _find_server(cs, args.server) cs.server_external_events.create([{'server_uuid': server.id, 'name': 'network-changed'}]) @utils.arg('server', metavar='<server>', help=_('Name or ID of server.')) def do_root_password(cs, args): """"""DEPRECATED, use set-password instead."""""" do_set_password(cs, args) @utils.arg('server', metavar='<server>', help=_('Name or ID of server.')) def do_set_password(cs, args): """""" Change the admin password for a server. """""" server = _find_server(cs, args.server) p1 = getpass.getpass('New password: ') p2 = getpass.getpass('Again: ') if p1 != p2: raise exceptions.CommandError(_(""Passwords do not match."")) server.change_password(p1) @utils.arg('server', metavar='<server>', help=_('Name or ID of server.')) @utils.arg('name', metavar='<name>', help=_('Name of snapshot.')) @utils.arg( '--metadata', metavar=""<key=value>"", action='append', default=[], help=_(""Record arbitrary key/value metadata to /meta_data.json "" ""on the metadata server. Can be specified multiple times."")) @utils.arg( '--show', dest='show', action=""store_true"", default=False, help=_('Print image info.')) @utils.arg( '--poll', dest='poll', action=""store_true"", default=False, help=_('Report the snapshot progress and poll until image creation is ' 'complete.')) def do_image_create(cs, args): """"""Create a new image by taking a snapshot of a running server."""""" server = _find_server(cs, args.server) meta = _meta_parsing(args.metadata) or None image_uuid = cs.servers.create_image(server, args.name, meta) if args.poll: _poll_for_status(cs.glance.find_image, image_uuid, 'snapshotting', ['active']) # NOTE(sirp): A race-condition exists between when the image finishes # uploading and when the servers's `task_state` is cleared. To account # for this, we need to poll a second time to ensure the `task_state` is # cleared before returning, ensuring that a snapshot taken immediately # after this function returns will succeed. # # A better long-term solution will be to separate 'snapshotting' and # 'image-uploading' in Nova and clear the task-state once the VM # snapshot is complete but before the upload begins. task_state_field = ""OS-EXT-STS:task_state"" if hasattr(server, task_state_field): _poll_for_status(cs.servers.get, server.id, 'image_snapshot', [None], status_field=task_state_field, show_progress=False, silent=True) if args.show: _print_image(_find_image(cs, image_uuid)) @utils.arg('server', metavar='<server>', help=_('Name or ID of server.')) @utils.arg('name', metavar='<name>', help=_('Name of the backup image.')) @utils.arg( 'backup_type', metavar='<backup-type>', help=_('The backup type, like ""daily"" or ""weekly"".')) @utils.arg( 'rotation', metavar='<rotation>', help=_('Int parameter representing how many backups to keep ' 'around.')) def do_backup(cs, args): """"""Backup a server by creating a 'backup' type snapshot."""""" _find_server(cs, args.server).backup(args.name, args.backup_type, args.rotation) @utils.arg( 'server', metavar='<server>', help=_(""Name or ID of server."")) @utils.arg( 'action', metavar='<action>', choices=['set', 'delete'], help=_(""Actions: 'set' or 'delete'."")) @utils.arg( 'metadata', metavar='<key=value>', nargs='+', action='append', default=[], help=_('Metadata to set or delete (only key is necessary on delete).')) def do_meta(cs, args): """"""Set or delete metadata on a server."""""" server = _find_server(cs, args.server) metadata = _extract_metadata(args) if args.action == 'set': cs.servers.set_meta(server, metadata) elif args.action == 'delete': cs.servers.delete_meta(server, sorted(metadata.keys(), reverse=True)) def _print_server(cs, args, server=None, wrap=0): # By default when searching via name we will do a # findall(name=blah) and due a REST /details which is not the same # as a .get() and doesn't get the information about flavors and # images. This fix it as we redo the call with the id which does a # .get() to get all information. if not server: server = _find_server(cs, args.server) minimal = getattr(args, ""minimal"", False) networks = server.networks info = server._info.copy() for network_label, address_list in networks.items(): info['%s network' % network_label] = ', '.join(address_list) flavor = info.get('flavor', {}) flavor_id = flavor.get('id', '') if minimal: info['flavor'] = flavor_id else: try: info['flavor'] = '%s (%s)' % (_find_flavor(cs, flavor_id).name, flavor_id) except Exception: info['flavor'] = '%s (%s)' % (_(""Flavor not found""), flavor_id) if 'security_groups' in info: # when we have multiple nics the info will include the # security groups N times where N == number of nics. Be nice # and only display it once. info['security_groups'] = ', '.join( sorted(set(group['name'] for group in info['security_groups']))) image = info.get('image', {}) if image: image_id = image.get('id', '') if minimal: info['image'] = image_id else: try: info['image'] = '%s (%s)' % (_find_image(cs, image_id).name, image_id) except Exception: info['image'] = '%s (%s)' % (_(""Image not found""), image_id) else: # Booted from volume info['image'] = _(""Attempt to boot from volume - no image supplied"") info.pop('links', None) info.pop('addresses', None) utils.print_dict(info, wrap=wrap) @utils.arg( '--minimal', dest='minimal', action=""store_true"", default=False, help=_('Skips flavor/image lookups when showing servers.')) @utils.arg('server', metavar='<server>', help=_('Name or ID of server.')) @utils.arg( '--wrap', dest='wrap', metavar='<integer>', default=80, help=_('Wrap the output to a specified length, or 0 to disable.')) def do_show(cs, args): """"""Show details about the given server."""""" _print_server(cs, args, wrap=int(args.wrap)) @utils.arg( '--all-tenants', action='store_const', const=1, default=0, help=_('Delete server(s) in another tenant by name (Admin only).')) @utils.arg( 'server', metavar='<server>', nargs='+', help=_('Name or ID of server(s).')) def do_delete(cs, args): """"""Immediately shut down and delete specified server(s)."""""" find_args = {'all_tenants': args.all_tenants} utils.do_action_on_many( lambda s: _find_server(cs, s, **find_args).delete(), args.server, _(""Request to delete server %s has been accepted.""), _(""Unable to delete the specified server(s)."")) def _find_server(cs, server, raise_if_notfound=True, **find_args): """"""Get a server by name or ID. :param cs: NovaClient's instance :param server: identifier of server :param raise_if_notfound: raise an exception if server is not found :param find_args: argument to search server """""" if raise_if_notfound: return utils.find_resource(cs.servers, server, **find_args) else: try: return utils.find_resource(cs.servers, server, wrap_exception=False) except exceptions.NoUniqueMatch as e: raise exceptions.CommandError(six.text_type(e)) except exceptions.NotFound: # The server can be deleted return server def _find_image(cs, image): """"""Get an image by name or ID."""""" try: return cs.glance.find_image(image) except (exceptions.NotFound, exceptions.NoUniqueMatch) as e: raise exceptions.CommandError(six.text_type(e)) def _find_flavor(cs, flavor): """"""Get a flavor by name, ID, or RAM size."""""" try: return utils.find_resource(cs.flavors, flavor, is_public=None) except exceptions.NotFound: return cs.flavors.find(ram=flavor) def _find_network_id_neutron(cs, net_name): """"""Get unique network ID from network name from neutron"""""" try: return cs.neutron.find_network(net_name).id except (exceptions.NotFound, exceptions.NoUniqueMatch) as e: raise exceptions.CommandError(six.text_type(e)) def _find_network_id(cs, net_name): """"""Find the network id for a network name. If we have access to neutron in the service catalog, use neutron for this lookup, otherwise use nova. This ensures that we do the right thing in the future. Once nova network support is deleted, we can delete this check and the has_neutron function. """""" if cs.has_neutron(): return _find_network_id_neutron(cs, net_name) else: # The network proxy API methods were deprecated in 2.36 and will return # a 404 so we fallback to 2.35 to maintain a transition for CLI users. want_version = api_versions.APIVersion('2.35') cur_version = cs.api_version if cs.api_version > want_version: cs.api_version = want_version try: return _find_network_id_novanet(cs, net_name) finally: cs.api_version = cur_version def _find_network_id_novanet(cs, net_name): """"""Get unique network ID from network name."""""" network_id = None for net_info in cs.networks.list(): if net_name == net_info.label: if network_id is not None: msg = (_(""Multiple network name matches found for name '%s', "" ""use network ID to be more specific."") % net_name) raise exceptions.NoUniqueMatch(msg) else: network_id = net_info.id if network_id is None: msg = (_(""No network name match for name '%s'"") % net_name) raise exceptions.ResourceNotFound(msg % {'network': net_name}) else: return network_id @utils.arg('server', metavar='<server>', help=_('Name or ID of server.')) @utils.arg( 'network_id', metavar='<network-id>', help=_('Network ID.')) def do_add_fixed_ip(cs, args): """"""Add new IP address on a network to server."""""" server = _find_server(cs, args.server) server.add_fixed_ip(args.network_id) @utils.arg('server', metavar='<server>', help=_('Name or ID of server.')) @utils.arg('address', metavar='<address>', help=_('IP Address.')) def do_remove_fixed_ip(cs, args): """"""Remove an IP address from a server."""""" server = _find_server(cs, args.server) server.remove_fixed_ip(args.address) def _find_volume(cs, volume): """"""Get a volume by name or ID."""""" return utils.find_resource(cs.volumes, volume) def _find_volume_snapshot(cs, snapshot): """"""Get a volume snapshot by name or ID."""""" return utils.find_resource(cs.volume_snapshots, snapshot) def _print_volume(volume): utils.print_dict(volume._info) def _print_volume_snapshot(snapshot): utils.print_dict(snapshot._info) def _translate_volume_keys(collection): _translate_keys(collection, [('displayName', 'display_name'), ('volumeType', 'volume_type')]) def _translate_volume_snapshot_keys(collection): _translate_keys(collection, [('displayName', 'display_name'), ('volumeId', 'volume_id')]) def _translate_availability_zone_keys(collection): _translate_keys(collection, [('zoneName', 'name'), ('zoneState', 'status')]) def _translate_volume_attachments_keys(collection): _translate_keys(collection, [('serverId', 'server_id'), ('volumeId', 'volume_id')]) @utils.arg( 'server', metavar='<server>', help=_('Name or ID of server.')) @utils.arg( 'volume', metavar='<volume>', help=_('ID of the volume to attach.')) @utils.arg( 'device', metavar='<device>', default=None, nargs='?', help=_('Name of the device e.g. /dev/vdb. ' 'Use ""auto"" for autoassign (if supported). ' 'Libvirt driver will use default device name.')) def do_volume_attach(cs, args): """"""Attach a volume to a server."""""" if args.device == 'auto': args.device = None volume = cs.volumes.create_server_volume(_find_server(cs, args.server).id, args.volume, args.device) _print_volume(volume) @utils.arg( 'server', metavar='<server>', help=_('Name or ID of server.')) @utils.arg( 'attachment_id', metavar='<attachment>', help=_('Attachment ID of the volume.')) @utils.arg( 'new_volume', metavar='<volume>', help=_('ID of the volume to attach.')) def do_volume_update(cs, args): """"""Update volume attachment."""""" cs.volumes.update_server_volume(_find_server(cs, args.server).id, args.attachment_id, args.new_volume) @utils.arg( 'server', metavar='<server>', help=_('Name or ID of server.')) @utils.arg( 'attachment_id', metavar='<volume>', help=_('ID of the volume to detach.')) def do_volume_detach(cs, args): """"""Detach a volume from a server."""""" cs.volumes.delete_server_volume(_find_server(cs, args.server).id, args.attachment_id) @utils.arg( 'server', metavar='<server>', help=_('Name or ID of server.')) def do_volume_attachments(cs, args): """"""List all the volumes attached to a server."""""" volumes = cs.volumes.get_server_volumes(_find_server(cs, args.server).id) _translate_volume_attachments_keys(volumes) utils.print_list(volumes, ['ID', 'DEVICE', 'SERVER ID', 'VOLUME ID']) @api_versions.wraps('2.0', '2.5') def console_dict_accessor(cs, data): return data['console'] @api_versions.wraps('2.6') def console_dict_accessor(cs, data): return data['remote_console'] class Console(object): def __init__(self, console_dict): self.type = console_dict['type'] self.url = console_dict['url'] def print_console(cs, data): utils.print_list([Console(console_dict_accessor(cs, data))], ['Type', 'Url']) @utils.arg('server', metavar='<server>', help=_('Name or ID of server.')) @utils.arg( 'console_type', metavar='<console-type>', help=_('Type of vnc console (""novnc"" or ""xvpvnc"").')) def do_get_vnc_console(cs, args): """"""Get a vnc console to a server."""""" server = _find_server(cs, args.server) data = server.get_vnc_console(args.console_type) print_console(cs, data) @utils.arg('server', metavar='<server>', help=_('Name or ID of server.')) @utils.arg( 'console_type', metavar='<console-type>', help=_('Type of spice console (""spice-html5"").')) def do_get_spice_console(cs, args): """"""Get a spice console to a server."""""" server = _find_server(cs, args.server) data = server.get_spice_console(args.console_type) print_console(cs, data) @utils.arg('server', metavar='<server>', help=_('Name or ID of server.')) @utils.arg( 'console_type', metavar='<console-type>', help=_('Type of rdp console (""rdp-html5"").')) def do_get_rdp_console(cs, args): """"""Get a rdp console to a server."""""" server = _find_server(cs, args.server) data = server.get_rdp_console(args.console_type) print_console(cs, data) @utils.arg('server', metavar='<server>', help=_('Name or ID of server.')) @utils.arg( '--console-type', default='serial', help=_('Type of serial console, default=""serial"".')) def do_get_serial_console(cs, args): """"""Get a serial console to a server."""""" if args.console_type not in ('serial',): raise exceptions.CommandError( _(""Invalid parameter value for 'console_type', "" ""currently supported 'serial'."")) server = _find_server(cs, args.server) data = server.get_serial_console(args.console_type) print_console(cs, data) @api_versions.wraps('2.8') @utils.arg('server', metavar='<server>', help=_('Name or ID of server.')) def do_get_mks_console(cs, args): """"""Get an MKS console to a server."""""" server = _find_server(cs, args.server) data = server.get_mks_console() print_console(cs, data) @utils.arg('server', metavar='<server>', help=_('Name or ID of server.')) @utils.arg( 'private_key', metavar='<private-key>', help=_('Private key (used locally to decrypt password) (Optional). ' 'When specified, the command displays the clear (decrypted) VM ' 'password. When not specified, the ciphered VM password is ' 'displayed.'), nargs='?', default=None) def do_get_password(cs, args): """"""Get the admin password for a server. This operation calls the metadata service to query metadata information and does not read password information from the server itself. """""" server = _find_server(cs, args.server) data = server.get_password(args.private_key) print(data) @utils.arg('server', metavar='<server>', help=_('Name or ID of server.')) def do_clear_password(cs, args): """"""Clear the admin password for a server from the metadata server. This action does not actually change the instance server password. """""" server = _find_server(cs, args.server) server.clear_password() def _print_floating_ip_list(floating_ips): convert = [('instance_id', 'server_id')] _translate_keys(floating_ips, convert) utils.print_list(floating_ips, ['Id', 'IP', 'Server Id', 'Fixed IP', 'Pool']) @utils.arg('server', metavar='<server>', help=_('Name or ID of server.')) @utils.arg( '--length', metavar='<length>', default=None, help=_('Length in lines to tail.')) def do_console_log(cs, args): """"""Get console log output of a server."""""" server = _find_server(cs, args.server) data = server.get_console_output(length=args.length) print(data) @utils.arg('server', metavar='<server>', help=_('Name or ID of server.')) @utils.arg('address', metavar='<address>', help=_('IP Address.')) @utils.arg( '--fixed-address', metavar='<fixed_address>', default=None, help=_('Fixed IP Address to associate with.')) def do_add_floating_ip(cs, args): """"""DEPRECATED, use floating-ip-associate instead."""""" _associate_floating_ip(cs, args) @utils.arg('server', metavar='<server>', help=_('Name or ID of server.')) @utils.arg('address', metavar='<address>', help=_('IP Address.')) @utils.arg( '--fixed-address', metavar='<fixed_address>', default=None, help=_('Fixed IP Address to associate with.')) def do_floating_ip_associate(cs, args): """"""Associate a floating IP address to a server."""""" _associate_floating_ip(cs, args) def _associate_floating_ip(cs, args): server = _find_server(cs, args.server) server.add_floating_ip(args.address, args.fixed_address) @utils.arg('server', metavar='<server>', help=_('Name or ID of server.')) @utils.arg('address', metavar='<address>', help=_('IP Address.')) def do_remove_floating_ip(cs, args): """"""DEPRECATED, use floating-ip-disassociate instead."""""" _disassociate_floating_ip(cs, args) @utils.arg('server', metavar='<server>', help=_('Name or ID of server.')) @utils.arg('address', metavar='<address>', help=_('IP Address.')) def do_floating_ip_disassociate(cs, args): """"""Disassociate a floating IP address from a server."""""" _disassociate_floating_ip(cs, args) def _disassociate_floating_ip(cs, args): server = _find_server(cs, args.server) server.remove_floating_ip(args.address) @utils.arg('server', metavar='<server>', help=_('Name or ID of server.')) @utils.arg( 'secgroup', metavar='<secgroup>', help=_('Name or ID of Security Group.')) def do_add_secgroup(cs, args): """"""Add a Security Group to a server."""""" server = _find_server(cs, args.server) server.add_security_group(args.secgroup) @utils.arg('server', metavar='<server>', help=_('Name or ID of server.')) @utils.arg( 'secgroup', metavar='<secgroup>', help=_('Name of Security Group.')) def do_remove_secgroup(cs, args): """"""Remove a Security Group from a server."""""" server = _find_server(cs, args.server) server.remove_security_group(args.secgroup) @utils.arg('server', metavar='<server>', help=_('Name or ID of server.')) def do_list_secgroup(cs, args): """"""List Security Group(s) of a server."""""" server = _find_server(cs, args.server) groups = server.list_security_group() _print_secgroups(groups) @utils.arg( 'pool', metavar='<floating-ip-pool>', help=_('Name of Floating IP Pool. (Optional)'), nargs='?', default=None) @deprecated_network def do_floating_ip_create(cs, args): """"""Allocate a floating IP for the current tenant."""""" _print_floating_ip_list([cs.floating_ips.create(pool=args.pool)]) @utils.arg('address', metavar='<address>', help=_('IP of Floating IP.')) @deprecated_network def do_floating_ip_delete(cs, args): """"""De-allocate a floating IP."""""" floating_ips = cs.floating_ips.list() for floating_ip in floating_ips: if floating_ip.ip == args.address: return cs.floating_ips.delete(floating_ip.id) raise exceptions.CommandError(_(""Floating IP %s not found."") % args.address) @deprecated_network def do_floating_ip_list(cs, _args): """"""List floating IPs."""""" _print_floating_ip_list(cs.floating_ips.list()) @deprecated_network def do_floating_ip_pool_list(cs, _args): """"""List all floating IP pools."""""" utils.print_list(cs.floating_ip_pools.list(), ['name']) @utils.arg( '--host', dest='host', metavar='<host>', default=None, help=_('Filter by host.')) @deprecated_network def do_floating_ip_bulk_list(cs, args): """"""List all floating IPs (nova-network only)."""""" utils.print_list(cs.floating_ips_bulk.list(args.host), ['project_id', 'address', 'instance_uuid', 'pool', 'interface']) @utils.arg('ip_range', metavar='<range>', help=_('Address range to create.')) @utils.arg( '--pool', dest='pool', metavar='<pool>', default=None, help=_('Pool for new Floating IPs.')) @utils.arg( '--interface', metavar='<interface>', default=None, help=_('Interface for new Floating IPs.')) @deprecated_network def do_floating_ip_bulk_create(cs, args): """"""Bulk create floating IPs by range (nova-network only)."""""" cs.floating_ips_bulk.create(args.ip_range, args.pool, args.interface) @utils.arg('ip_range', metavar='<range>', help=_('Address range to delete.')) @deprecated_network def do_floating_ip_bulk_delete(cs, args): """"""Bulk delete floating IPs by range (nova-network only)."""""" cs.floating_ips_bulk.delete(args.ip_range) def _print_dns_list(dns_entries): utils.print_list(dns_entries, ['ip', 'name', 'domain']) def _print_domain_list(domain_entries): utils.print_list(domain_entries, ['domain', 'scope', 'project', 'availability_zone']) @deprecated_network def do_dns_domains(cs, args): """"""Print a list of available dns domains."""""" domains = cs.dns_domains.domains() _print_domain_list(domains) @utils.arg('domain', metavar='<domain>', help=_('DNS domain.')) @utils.arg('--ip', metavar='<ip>', help=_('IP address.'), default=None) @utils.arg('--name', metavar='<name>', help=_('DNS name.'), default=None) @deprecated_network def do_dns_list(cs, args): """"""List current DNS entries for domain and IP or domain and name."""""" if not (args.ip or args.name): raise exceptions.CommandError( _(""You must specify either --ip or --name"")) if args.name: entry = cs.dns_entries.get(args.domain, args.name) _print_dns_list([entry]) else: entries = cs.dns_entries.get_for_ip(args.domain, ip=args.ip) _print_dns_list(entries) @utils.arg('ip', metavar='<ip>', help=_('IP address.')) @utils.arg('name', metavar='<name>', help=_('DNS name.')) @utils.arg('domain', metavar='<domain>', help=_('DNS domain.')) @utils.arg( '--type', metavar='<type>', help=_('DNS type (e.g. ""A"")'), default='A') @deprecated_network def do_dns_create(cs, args): """"""Create a DNS entry for domain, name, and IP."""""" cs.dns_entries.create(args.domain, args.name, args.ip, args.type) @utils.arg('domain', metavar='<domain>', help=_('DNS domain.')) @utils.arg('name', metavar='<name>', help=_('DNS name.')) @deprecated_network def do_dns_delete(cs, args): """"""Delete the specified DNS entry."""""" cs.dns_entries.delete(args.domain, args.name) @utils.arg('domain', metavar='<domain>', help=_('DNS domain.')) @deprecated_network def do_dns_delete_domain(cs, args): """"""Delete the specified DNS domain."""""" cs.dns_domains.delete(args.domain) @utils.arg('domain', metavar='<domain>', help=_('DNS domain.')) @utils.arg( '--availability-zone', metavar='<availability-zone>', default=None, help=_('Limit access to this domain to servers ' 'in the specified availability zone.')) @deprecated_network def do_dns_create_private_domain(cs, args): """"""Create the specified DNS domain."""""" cs.dns_domains.create_private(args.domain, args.availability_zone) @utils.arg('domain', metavar='<domain>', help=_('DNS domain.')) @utils.arg( '--project', metavar='<project>', help=_('Limit access to this domain to users ' 'of the specified project.'), default=None) @deprecated_network def do_dns_create_public_domain(cs, args): """"""Create the specified DNS domain."""""" cs.dns_domains.create_public(args.domain, args.project) def _print_secgroup_rules(rules, show_source_group=True): class FormattedRule(object): def __init__(self, obj): items = (obj if isinstance(obj, dict) else obj._info).items() for k, v in items: if k == 'ip_range': v = v.get('cidr') elif k == 'group': k = 'source_group' v = v.get('name') if v is None: v = '' setattr(self, k, v) rules = [FormattedRule(rule) for rule in rules] headers = ['IP Protocol', 'From Port', 'To Port', 'IP Range'] if show_source_group: headers.append('Source Group') utils.print_list(rules, headers) def _print_secgroups(secgroups): utils.print_list(secgroups, ['Id', 'Name', 'Description']) def _get_secgroup(cs, secgroup): # Check secgroup is an ID (nova-network) or UUID (neutron) if (utils.is_integer_like(encodeutils.safe_encode(secgroup)) or uuidutils.is_uuid_like(secgroup)): try: return cs.security_groups.get(secgroup) except exceptions.NotFound: pass # Check secgroup as a name match_found = False for s in cs.security_groups.list(): encoding = ( locale.getpreferredencoding() or sys.stdin.encoding or 'UTF-8') if not six.PY3: s.name = s.name.encode(encoding) if secgroup == s.name: if match_found is not False: msg = (_(""Multiple security group matches found for name '%s'"" "", use an ID to be more specific."") % secgroup) raise exceptions.NoUniqueMatch(msg) match_found = s if match_found is False: raise exceptions.CommandError(_(""Secgroup ID or name '%s' not found."") % secgroup) return match_found @utils.arg( 'secgroup', metavar='<secgroup>', help=_('ID or name of security group.')) @utils.arg( 'ip_proto', metavar='<ip-proto>', help=_('IP protocol (icmp, tcp, udp).')) @utils.arg( 'from_port', metavar='<from-port>', help=_('Port at start of range.')) @utils.arg( 'to_port', metavar='<to-port>', help=_('Port at end of range.')) @utils.arg('cidr', metavar='<cidr>', help=_('CIDR for address range.')) @deprecated_network def do_secgroup_add_rule(cs, args): """"""Add a rule to a security group."""""" secgroup = _get_secgroup(cs, args.secgroup) rule = cs.security_group_rules.create(secgroup.id, args.ip_proto, args.from_port, args.to_port, args.cidr) _print_secgroup_rules([rule]) @utils.arg( 'secgroup', metavar='<secgroup>', help=_('ID or name of security group.')) @utils.arg( 'ip_proto', metavar='<ip-proto>', help=_('IP protocol (icmp, tcp, udp).')) @utils.arg( 'from_port', metavar='<from-port>', help=_('Port at start of range.')) @utils.arg( 'to_port', metavar='<to-port>', help=_('Port at end of range.')) @utils.arg('cidr', metavar='<cidr>', help=_('CIDR for address range.')) @deprecated_network def do_secgroup_delete_rule(cs, args): """"""Delete a rule from a security group."""""" secgroup = _get_secgroup(cs, args.secgroup) for rule in secgroup.rules: if (rule['ip_protocol'] and rule['ip_protocol'].upper() == args.ip_proto.upper() and rule['from_port'] == int(args.from_port) and rule['to_port'] == int(args.to_port) and rule['ip_range']['cidr'] == args.cidr): _print_secgroup_rules([rule]) return cs.security_group_rules.delete(rule['id']) raise exceptions.CommandError(_(""Rule not found"")) @utils.arg('name', metavar='<name>', help=_('Name of security group.')) @utils.arg( 'description', metavar='<description>', help=_('Description of security group.')) @deprecated_network def do_secgroup_create(cs, args): """"""Create a security group."""""" secgroup = cs.security_groups.create(args.name, args.description) _print_secgroups([secgroup]) @utils.arg( 'secgroup', metavar='<secgroup>', help=_('ID or name of security group.')) @utils.arg('name', metavar='<name>', help=_('Name of security group.')) @utils.arg( 'description', metavar='<description>', help=_('Description of security group.')) @deprecated_network def do_secgroup_update(cs, args): """"""Update a security group."""""" sg = _get_secgroup(cs, args.secgroup) secgroup = cs.security_groups.update(sg, args.name, args.description) _print_secgroups([secgroup]) @utils.arg( 'secgroup', metavar='<secgroup>', help=_('ID or name of security group.')) @deprecated_network def do_secgroup_delete(cs, args): """"""Delete a security group."""""" secgroup = _get_secgroup(cs, args.secgroup) cs.security_groups.delete(secgroup) _print_secgroups([secgroup]) @utils.arg( '--all-tenants', dest='all_tenants', metavar='<0|1>', nargs='?', type=int, const=1, default=int(strutils.bool_from_string( os.environ.get(""ALL_TENANTS"", 'false'), True)), help=_('Display information from all tenants (Admin only).')) @deprecated_network def do_secgroup_list(cs, args): """"""List security groups for the current tenant."""""" search_opts = {'all_tenants': args.all_tenants} columns = ['Id', 'Name', 'Description'] if args.all_tenants: columns.append('Tenant_ID') groups = cs.security_groups.list(search_opts=search_opts) utils.print_list(groups, columns) @utils.arg( 'secgroup', metavar='<secgroup>', help=_('ID or name of security group.')) @deprecated_network def do_secgroup_list_rules(cs, args): """"""List rules for a security group."""""" secgroup = _get_secgroup(cs, args.secgroup) _print_secgroup_rules(secgroup.rules) @utils.arg( 'secgroup', metavar='<secgroup>', help=_('ID or name of security group.')) @utils.arg( 'source_group', metavar='<source-group>', help=_('ID or name of source group.')) @utils.arg( 'ip_proto', metavar='<ip-proto>', help=_('IP protocol (icmp, tcp, udp).')) @utils.arg( 'from_port', metavar='<from-port>', help=_('Port at start of range.')) @utils.arg( 'to_port', metavar='<to-port>', help=_('Port at end of range.')) @deprecated_network def do_secgroup_add_group_rule(cs, args): """"""Add a source group rule to a security group."""""" secgroup = _get_secgroup(cs, args.secgroup) source_group = _get_secgroup(cs, args.source_group) params = {'group_id': source_group.id} if args.ip_proto or args.from_port or args.to_port: if not (args.ip_proto and args.from_port and args.to_port): raise exceptions.CommandError(_(""ip_proto, from_port, and to_port"" "" must be specified together"")) params['ip_protocol'] = args.ip_proto.upper() params['from_port'] = args.from_port params['to_port'] = args.to_port rule = cs.security_group_rules.create(secgroup.id, **params) _print_secgroup_rules([rule]) @utils.arg( 'secgroup', metavar='<secgroup>', help=_('ID or name of security group.')) @utils.arg( 'source_group', metavar='<source-group>', help=_('ID or name of source group.')) @utils.arg( 'ip_proto', metavar='<ip-proto>', help=_('IP protocol (icmp, tcp, udp).')) @utils.arg( 'from_port', metavar='<from-port>', help=_('Port at start of range.')) @utils.arg( 'to_port', metavar='<to-port>', help=_('Port at end of range.')) @deprecated_network def do_secgroup_delete_group_rule(cs, args): """"""Delete a source group rule from a security group."""""" secgroup = _get_secgroup(cs, args.secgroup) source_group = _get_secgroup(cs, args.source_group) params = {'group_name': source_group.name} if args.ip_proto or args.from_port or args.to_port: if not (args.ip_proto and args.from_port and args.to_port): raise exceptions.CommandError(_(""ip_proto, from_port, and to_port"" "" must be specified together"")) params['ip_protocol'] = args.ip_proto.upper() params['from_port'] = int(args.from_port) params['to_port'] = int(args.to_port) for rule in secgroup.rules: if (rule.get('ip_protocol') and rule['ip_protocol'].upper() == params.get( 'ip_protocol').upper() and rule.get('from_port') == params.get('from_port') and rule.get('to_port') == params.get('to_port') and rule.get('group', {}).get('name') == params.get('group_name')): return cs.security_group_rules.delete(rule['id']) raise exceptions.CommandError(_(""Rule not found"")) @api_versions.wraps(""2.0"", ""2.1"") def _keypair_create(cs, args, name, pub_key): return cs.keypairs.create(name, pub_key) @api_versions.wraps(""2.2"", ""2.9"") def _keypair_create(cs, args, name, pub_key): return cs.keypairs.create(name, pub_key, key_type=args.key_type) @api_versions.wraps(""2.10"") def _keypair_create(cs, args, name, pub_key): return cs.keypairs.create(name, pub_key, key_type=args.key_type, user_id=args.user) @utils.arg('name', metavar='<name>', help=_('Name of key.')) @utils.arg( '--pub-key', metavar='<pub-key>', default=None, help=_('Path to a public ssh key.')) @utils.arg( '--key-type', metavar='<key-type>', default='ssh', help=_('Keypair type. Can be ssh or x509.'), start_version=""2.2"") @utils.arg( '--user', metavar='<user-id>', default=None, help=_('ID of user to whom to add key-pair (Admin only).'), start_version=""2.10"") def do_keypair_add(cs, args): """"""Create a new key pair for use with servers."""""" name = args.name pub_key = args.pub_key if pub_key: if pub_key == '-': pub_key = sys.stdin.read() else: try: with open(os.path.expanduser(pub_key)) as f: pub_key = f.read() except IOError as e: raise exceptions.CommandError( _(""Can't open or read '%(key)s': %(exc)s"") % {'key': pub_key, 'exc': e} ) keypair = _keypair_create(cs, args, name, pub_key) if not pub_key: private_key = keypair.private_key print(private_key) @api_versions.wraps(""2.0"", ""2.9"") @utils.arg('name', metavar='<name>', help=_('Keypair name to delete.')) def do_keypair_delete(cs, args): """"""Delete keypair given by its name."""""" name = _find_keypair(cs, args.name) cs.keypairs.delete(name) @api_versions.wraps(""2.10"") @utils.arg('name', metavar='<name>', help=_('Keypair name to delete.')) @utils.arg( '--user', metavar='<user-id>', default=None, help=_('ID of key-pair owner (Admin only).')) def do_keypair_delete(cs, args): """"""Delete keypair given by its name."""""" cs.keypairs.delete(args.name, args.user) @api_versions.wraps(""2.0"", ""2.1"") def _get_keypairs_list_columns(cs, args): return ['Name', 'Fingerprint'] @api_versions.wraps(""2.2"") def _get_keypairs_list_columns(cs, args): return ['Name', 'Type', 'Fingerprint'] @api_versions.wraps(""2.0"", ""2.9"") def do_keypair_list(cs, args): """"""Print a list of keypairs for a user"""""" keypairs = cs.keypairs.list() columns = _get_keypairs_list_columns(cs, args) utils.print_list(keypairs, columns) @api_versions.wraps(""2.10"", ""2.34"") @utils.arg( '--user', metavar='<user-id>', default=None, help=_('List key-pairs of specified user ID (Admin only).')) def do_keypair_list(cs, args): """"""Print a list of keypairs for a user"""""" keypairs = cs.keypairs.list(args.user) columns = _get_keypairs_list_columns(cs, args) utils.print_list(keypairs, columns) @api_versions.wraps(""2.35"") @utils.arg( '--user', metavar='<user-id>', default=None, help=_('List key-pairs of specified user ID (Admin only).')) @utils.arg( '--marker', dest='marker', metavar='<marker>', default=None, help=_('The last keypair of the previous page; displays list of keypairs ' 'after ""marker"".')) @utils.arg( '--limit', dest='limit', metavar='<limit>', type=int, default=None, help=_(""Maximum number of keypairs to display. If limit == -1, all "" ""keypairs will be displayed. If limit is bigger than "" ""'osapi_max_limit' option of Nova API, limit 'osapi_max_limit' "" ""will be used instead."")) def do_keypair_list(cs, args): """"""Print a list of keypairs for a user"""""" keypairs = cs.keypairs.list(args.user, args.marker, args.limit) columns = _get_keypairs_list_columns(cs, args) utils.print_list(keypairs, columns) def _print_keypair(keypair): kp = keypair._info.copy() pk = kp.pop('public_key') utils.print_dict(kp) print(_(""Public key: %s"") % pk) @api_versions.wraps(""2.0"", ""2.9"") @utils.arg( 'keypair', metavar='<keypair>', help=_(""Name of keypair."")) def do_keypair_show(cs, args): """"""Show details about the given keypair."""""" keypair = _find_keypair(cs, args.keypair) _print_keypair(keypair) @api_versions.wraps(""2.10"") @utils.arg( 'keypair', metavar='<keypair>', help=_(""Name of keypair."")) @utils.arg( '--user', metavar='<user-id>', default=None, help=_('ID of key-pair owner (Admin only).')) def do_keypair_show(cs, args): """"""Show details about the given keypair."""""" keypair = cs.keypairs.get(args.keypair, args.user) _print_keypair(keypair) def _find_keypair(cs, keypair): """"""Get a keypair by name."""""" return utils.find_resource(cs.keypairs, keypair) @utils.arg( '--tenant', # nova db searches by project_id dest='tenant', metavar='<tenant>', nargs='?', help=_('Display information from single tenant (Admin only).')) @utils.arg( '--reserved', dest='reserved', action='store_true', default=False, help=_('Include reservations count.')) def do_absolute_limits(cs, args): """"""DEPRECATED, use limits instead."""""" limits = cs.limits.get(args.reserved, args.tenant).absolute _print_absolute_limits(limits) def _print_absolute_limits(limits): """"""Prints absolute limits."""""" class Limit(object): def __init__(self, name, used, max, other): self.name = name self.used = used self.max = max self.other = other limit_map = { 'maxServerMeta': {'name': 'Server Meta', 'type': 'max'}, 'maxPersonality': {'name': 'Personality', 'type': 'max'}, 'maxPersonalitySize': {'name': 'Personality Size', 'type': 'max'}, 'maxImageMeta': {'name': 'ImageMeta', 'type': 'max'}, 'maxTotalKeypairs': {'name': 'Keypairs', 'type': 'max'}, 'totalCoresUsed': {'name': 'Cores', 'type': 'used'}, 'maxTotalCores': {'name': 'Cores', 'type': 'max'}, 'totalRAMUsed': {'name': 'RAM', 'type': 'used'}, 'maxTotalRAMSize': {'name': 'RAM', 'type': 'max'}, 'totalInstancesUsed': {'name': 'Instances', 'type': 'used'}, 'maxTotalInstances': {'name': 'Instances', 'type': 'max'}, 'totalFloatingIpsUsed': {'name': 'FloatingIps', 'type': 'used'}, 'maxTotalFloatingIps': {'name': 'FloatingIps', 'type': 'max'}, 'totalSecurityGroupsUsed': {'name': 'SecurityGroups', 'type': 'used'}, 'maxSecurityGroups': {'name': 'SecurityGroups', 'type': 'max'}, 'maxSecurityGroupRules': {'name': 'SecurityGroupRules', 'type': 'max'}, 'maxServerGroups': {'name': 'ServerGroups', 'type': 'max'}, 'totalServerGroupsUsed': {'name': 'ServerGroups', 'type': 'used'}, 'maxServerGroupMembers': {'name': 'ServerGroupMembers', 'type': 'max'}, } max = {} used = {} other = {} limit_names = [] columns = ['Name', 'Used', 'Max'] for l in limits: map = limit_map.get(l.name, {'name': l.name, 'type': 'other'}) name = map['name'] if map['type'] == 'max': max[name] = l.value elif map['type'] == 'used': used[name] = l.value else: other[name] = l.value columns.append('Other') if name not in limit_names: limit_names.append(name) limit_names.sort() limit_list = [] for name in limit_names: l = Limit(name, used.get(name, ""-""), max.get(name, ""-""), other.get(name, ""-"")) limit_list.append(l) utils.print_list(limit_list, columns) def do_rate_limits(cs, args): """"""DEPRECATED, use limits instead."""""" limits = cs.limits.get().rate _print_rate_limits(limits) def _print_rate_limits(limits): """"""print rate limits."""""" columns = ['Verb', 'URI', 'Value', 'Remain', 'Unit', 'Next_Available'] utils.print_list(limits, columns) @utils.arg( '--tenant', # nova db searches by project_id dest='tenant', metavar='<tenant>', nargs='?', help=_('Display information from single tenant (Admin only).')) @utils.arg( '--reserved', dest='reserved', action='store_true', default=False, help=_('Include reservations count.')) def do_limits(cs, args): """"""Print rate and absolute limits."""""" limits = cs.limits.get(args.reserved, args.tenant) _print_rate_limits(limits.rate) _print_absolute_limits(limits.absolute) @utils.arg( '--start', metavar='<start>', help=_('Usage range start date ex 2012-01-20. (default: 4 weeks ago)'), default=None) @utils.arg( '--end', metavar='<end>', help=_('Usage range end date, ex 2012-01-20. (default: tomorrow)'), default=None) def do_usage_list(cs, args): """"""List usage data for all tenants."""""" dateformat = ""%Y-%m-%d"" rows = [""Tenant ID"", ""Servers"", ""RAM MB-Hours"", ""CPU Hours"", ""Disk GB-Hours""] now = timeutils.utcnow() if args.start: start = datetime.datetime.strptime(args.start, dateformat) else: start = now - datetime.timedelta(weeks=4) if args.end: end = datetime.datetime.strptime(args.end, dateformat) else: end = now + datetime.timedelta(days=1) def simplify_usage(u): simplerows = [x.lower().replace("" "", ""_"") for x in rows] setattr(u, simplerows[0], u.tenant_id) setattr(u, simplerows[1], ""%d"" % len(u.server_usages)) setattr(u, simplerows[2], ""%.2f"" % u.total_memory_mb_usage) setattr(u, simplerows[3], ""%.2f"" % u.total_vcpus_usage) setattr(u, simplerows[4], ""%.2f"" % u.total_local_gb_usage) usage_list = cs.usage.list(start, end, detailed=True) print(_(""Usage from %(start)s to %(end)s:"") % {'start': start.strftime(dateformat), 'end': end.strftime(dateformat)}) for usage in usage_list: simplify_usage(usage) utils.print_list(usage_list, rows) @utils.arg( '--start', metavar='<start>', help=_('Usage range start date ex 2012-01-20. (default: 4 weeks ago)'), default=None) @utils.arg( '--end', metavar='<end>', help=_('Usage range end date, ex 2012-01-20. (default: tomorrow)'), default=None) @utils.arg( '--tenant', metavar='<tenant-id>', default=None, help=_('UUID of tenant to get usage for.')) def do_usage(cs, args): """"""Show usage data for a single tenant."""""" dateformat = ""%Y-%m-%d"" rows = [""Servers"", ""RAM MB-Hours"", ""CPU Hours"", ""Disk GB-Hours""] now = timeutils.utcnow() if args.start: start = datetime.datetime.strptime(args.start, dateformat) else: start = now - datetime.timedelta(weeks=4) if args.end: end = datetime.datetime.strptime(args.end, dateformat) else: end = now + datetime.timedelta(days=1) def simplify_usage(u): simplerows = [x.lower().replace("" "", ""_"") for x in rows] setattr(u, simplerows[0], ""%d"" % len(u.server_usages)) setattr(u, simplerows[1], ""%.2f"" % u.total_memory_mb_usage) setattr(u, simplerows[2], ""%.2f"" % u.total_vcpus_usage) setattr(u, simplerows[3], ""%.2f"" % u.total_local_gb_usage) if args.tenant: usage = cs.usage.get(args.tenant, start, end) else: if isinstance(cs.client, client.SessionClient): auth = cs.client.auth project_id = auth.get_auth_ref(cs.client.session).project_id usage = cs.usage.get(project_id, start, end) else: usage = cs.usage.get(cs.client.tenant_id, start, end) print(_(""Usage from %(start)s to %(end)s:"") % {'start': start.strftime(dateformat), 'end': end.strftime(dateformat)}) if getattr(usage, 'total_vcpus_usage', None): simplify_usage(usage) utils.print_list([usage], rows) else: print(_('None')) @utils.arg( 'pk_filename', metavar='<private-key-filename>', nargs='?', default='pk.pem', help=_('Filename for the private key. [Default: pk.pem]')) @utils.arg( 'cert_filename', metavar='<x509-cert-filename>', nargs='?', default='cert.pem', help=_('Filename for the X.509 certificate. [Default: cert.pem]')) def do_x509_create_cert(cs, args): """"""Create x509 cert for a user in tenant."""""" if os.path.exists(args.pk_filename): raise exceptions.CommandError(_(""Unable to write privatekey - %s "" ""exists."") % args.pk_filename) if os.path.exists(args.cert_filename): raise exceptions.CommandError(_(""Unable to write x509 cert - %s "" ""exists."") % args.cert_filename) certs = cs.certs.create() try: old_umask = os.umask(0o377) with open(args.pk_filename, 'w') as private_key: private_key.write(certs.private_key) print(_(""Wrote private key to %s"") % args.pk_filename) finally: os.umask(old_umask) with open(args.cert_filename, 'w') as cert: cert.write(certs.data) print(_(""Wrote x509 certificate to %s"") % args.cert_filename) @utils.arg( 'filename', metavar='<filename>', nargs='?', default='cacert.pem', help=_('Filename to write the x509 root cert.')) def do_x509_get_root_cert(cs, args): """"""Fetch the x509 root cert."""""" if os.path.exists(args.filename): raise exceptions.CommandError(_(""Unable to write x509 root cert - \ %s exists."") % args.filename) with open(args.filename, 'w') as cert: cacert = cs.certs.get() cert.write(cacert.data) print(_(""Wrote x509 root cert to %s"") % args.filename) @utils.arg( '--hypervisor', metavar='<hypervisor>', default=None, help=_('Type of hypervisor.')) def do_agent_list(cs, args): """"""List all builds."""""" result = cs.agents.list(args.hypervisor) columns = [""Agent_id"", ""Hypervisor"", ""OS"", ""Architecture"", ""Version"", 'Md5hash', 'Url'] utils.print_list(result, columns) @utils.arg('os', metavar='<os>', help=_('Type of OS.')) @utils.arg( 'architecture', metavar='<architecture>', help=_('Type of architecture.')) @utils.arg('version', metavar='<version>', help=_('Version.')) @utils.arg('url', metavar='<url>', help=_('URL.')) @utils.arg('md5hash', metavar='<md5hash>', help=_('MD5 hash.')) @utils.arg( 'hypervisor', metavar='<hypervisor>', default='xen', help=_('Type of hypervisor.')) def do_agent_create(cs, args): """"""Create new agent build."""""" result = cs.agents.create(args.os, args.architecture, args.version, args.url, args.md5hash, args.hypervisor) utils.print_dict(result._info.copy()) @utils.arg('id', metavar='<id>', help=_('ID of the agent-build.')) def do_agent_delete(cs, args): """"""Delete existing agent build."""""" cs.agents.delete(args.id) @utils.arg('id', metavar='<id>', help=_('ID of the agent-build.')) @utils.arg('version', metavar='<version>', help=_('Version.')) @utils.arg('url', metavar='<url>', help=_('URL')) @utils.arg('md5hash', metavar='<md5hash>', help=_('MD5 hash.')) def do_agent_modify(cs, args): """"""Modify existing agent build."""""" result = cs.agents.update(args.id, args.version, args.url, args.md5hash) utils.print_dict(result._info) def _find_aggregate(cs, aggregate): """"""Get an aggregate by name or ID."""""" return utils.find_resource(cs.aggregates, aggregate) def do_aggregate_list(cs, args): """"""Print a list of all aggregates."""""" aggregates = cs.aggregates.list() columns = ['Id', 'Name', 'Availability Zone'] utils.print_list(aggregates, columns) @utils.arg('name', metavar='<name>', help=_('Name of aggregate.')) @utils.arg( 'availability_zone', metavar='<availability-zone>', default=None, nargs='?', help=_('The availability zone of the aggregate (optional).')) def do_aggregate_create(cs, args): """"""Create a new aggregate with the specified details."""""" aggregate = cs.aggregates.create(args.name, args.availability_zone) _print_aggregate_details(aggregate) @utils.arg( 'aggregate', metavar='<aggregate>', help=_('Name or ID of aggregate to delete.')) def do_aggregate_delete(cs, args): """"""Delete the aggregate."""""" aggregate = _find_aggregate(cs, args.aggregate) cs.aggregates.delete(aggregate) print(_(""Aggregate %s has been successfully deleted."") % aggregate.id) @utils.arg( 'aggregate', metavar='<aggregate>', help=_('Name or ID of aggregate to update.')) @utils.arg( 'name', nargs='?', action=shell.DeprecatedAction, use=_('use ""%s""; this option will be removed in ' 'novaclient 5.0.0.') % '--name', help=argparse.SUPPRESS) @utils.arg( '--name', dest='name', help=_('Name of aggregate.')) @utils.arg( 'availability_zone', metavar='<availability-zone>', nargs='?', default=None, action=shell.DeprecatedAction, use=_('use ""%s""; this option will be removed in ' 'novaclient 5.0.0.') % '--availability_zone', help=argparse.SUPPRESS) @utils.arg( '--availability-zone', metavar='<availability-zone>', dest='availability_zone', help=_('The availability zone of the aggregate.')) def do_aggregate_update(cs, args): """"""Update the aggregate's name and optionally availability zone."""""" aggregate = _find_aggregate(cs, args.aggregate) updates = {} if args.name: updates[""name""] = args.name if args.availability_zone: updates[""availability_zone""] = args.availability_zone aggregate = cs.aggregates.update(aggregate.id, updates) print(_(""Aggregate %s has been successfully updated."") % aggregate.id) _print_aggregate_details(aggregate) @utils.arg( 'aggregate', metavar='<aggregate>', help=_('Name or ID of aggregate to update.')) @utils.arg( 'metadata', metavar='<key=value>', nargs='+', action='append', default=[], help=_('Metadata to add/update to aggregate. ' 'Specify only the key to delete a metadata item.')) def do_aggregate_set_metadata(cs, args): """"""Update the metadata associated with the aggregate."""""" aggregate = _find_aggregate(cs, args.aggregate) metadata = _extract_metadata(args) currentmetadata = getattr(aggregate, 'metadata', {}) if set(metadata.items()) & set(currentmetadata.items()): raise exceptions.CommandError(_(""metadata already exists"")) for key, value in metadata.items(): if value is None and key not in currentmetadata: raise exceptions.CommandError(_(""metadata key %s does not exist"" "" hence can not be deleted"") % key) aggregate = cs.aggregates.set_metadata(aggregate.id, metadata) print(_(""Metadata has been successfully updated for aggregate %s."") % aggregate.id) _print_aggregate_details(aggregate) @utils.arg( 'aggregate', metavar='<aggregate>', help=_('Name or ID of aggregate.')) @utils.arg( 'host', metavar='<host>', help=_('The host to add to the aggregate.')) def do_aggregate_add_host(cs, args): """"""Add the host to the specified aggregate."""""" aggregate = _find_aggregate(cs, args.aggregate) aggregate = cs.aggregates.add_host(aggregate.id, args.host) print(_(""Host %(host)s has been successfully added for aggregate "" ""%(aggregate_id)s "") % {'host': args.host, 'aggregate_id': aggregate.id}) _print_aggregate_details(aggregate) @utils.arg( 'aggregate', metavar='<aggregate>', help=_('Name or ID of aggregate.')) @utils.arg( 'host', metavar='<host>', help=_('The host to remove from the aggregate.')) def do_aggregate_remove_host(cs, args): """"""Remove the specified host from the specified aggregate."""""" aggregate = _find_aggregate(cs, args.aggregate) aggregate = cs.aggregates.remove_host(aggregate.id, args.host) print(_(""Host %(host)s has been successfully removed from aggregate "" ""%(aggregate_id)s "") % {'host': args.host, 'aggregate_id': aggregate.id}) _print_aggregate_details(aggregate) @utils.arg( 'aggregate', metavar='<aggregate>', help=_('Name or ID of aggregate.')) def do_aggregate_details(cs, args): """"""DEPRECATED, use aggregate-show instead."""""" do_aggregate_show(cs, args) @utils.arg( 'aggregate', metavar='<aggregate>', help=_('Name or ID of aggregate.')) def do_aggregate_show(cs, args): """"""Show details of the specified aggregate."""""" aggregate = _find_aggregate(cs, args.aggregate) _print_aggregate_details(aggregate) def _print_aggregate_details(aggregate): columns = ['Id', 'Name', 'Availability Zone', 'Hosts', 'Metadata'] def parser_metadata(fields): return utils.pretty_choice_dict(getattr(fields, 'metadata', {}) or {}) def parser_hosts(fields): return utils.pretty_choice_list(getattr(fields, 'hosts', [])) formatters = { 'Metadata': parser_metadata, 'Hosts': parser_hosts, } utils.print_list([aggregate], columns, formatters=formatters) @utils.arg('server', metavar='<server>', help=_('Name or ID of server.')) @utils.arg( 'host', metavar='<host>', default=None, nargs='?', help=_('Destination host name.')) @utils.arg( '--block-migrate', action='store_true', dest='block_migrate', default=False, help=_('True in case of block_migration. (Default=False:live_migration)'), start_version=""2.0"", end_version=""2.24"") @utils.arg( '--block-migrate', action='store_true', dest='block_migrate', default=""auto"", help=_('True in case of block_migration. (Default=auto:live_migration)'), start_version=""2.25"") @utils.arg( '--disk-over-commit', action='store_true', dest='disk_over_commit', default=False, help=_('Allow overcommit. (Default=False)'), start_version=""2.0"", end_version=""2.24"") @utils.arg( '--force', dest='force', action='store_true', default=False, help=_('Force to not verify the scheduler if a host is provided.'), start_version='2.30') def do_live_migration(cs, args): """"""Migrate running server to a new machine."""""" update_kwargs = {} if 'disk_over_commit' in args: update_kwargs['disk_over_commit'] = args.disk_over_commit if 'force' in args and args.force: update_kwargs['force'] = args.force _find_server(cs, args.server).live_migrate(args.host, args.block_migrate, **update_kwargs) @api_versions.wraps(""2.22"") @utils.arg('server', metavar='<server>', help=_('Name or ID of server.')) @utils.arg('migration', metavar='<migration>', help=_('ID of migration.')) def do_live_migration_force_complete(cs, args): """"""Force on-going live migration to complete."""""" server = _find_server(cs, args.server) cs.server_migrations.live_migrate_force_complete(server, args.migration) @api_versions.wraps(""2.23"") @utils.arg('server', metavar='<server>', help=_('Name or ID of server.')) def do_server_migration_list(cs, args): """"""Get the migrations list of specified server."""""" server = _find_server(cs, args.server) migrations = cs.server_migrations.list(server) fields = ['Id', 'Source Node', 'Dest Node', 'Source Compute', 'Dest Compute', 'Dest Host', 'Status', 'Server UUID', 'Created At', 'Updated At'] format_name = [""Total Memory Bytes"", ""Processed Memory Bytes"", ""Remaining Memory Bytes"", ""Total Disk Bytes"", ""Processed Disk Bytes"", ""Remaining Disk Bytes""] format_key = [""memory_total_bytes"", ""memory_processed_bytes"", ""memory_remaining_bytes"", ""disk_total_bytes"", ""disk_processed_bytes"", ""disk_remaining_bytes""] formatters = map(lambda field: utils.make_field_formatter(field)[1], format_key) formatters = dict(zip(format_name, formatters)) utils.print_list(migrations, fields + format_name, formatters) @api_versions.wraps(""2.23"") @utils.arg('server', metavar='<server>', help=_('Name or ID of server.')) @utils.arg('migration', metavar='<migration>', help=_('ID of migration.')) def do_server_migration_show(cs, args): """"""Get the migration of specified server."""""" server = _find_server(cs, args.server) migration = cs.server_migrations.get(server, args.migration) utils.print_dict(migration._info) @api_versions.wraps(""2.24"") @utils.arg('server', metavar='<server>', help=_('Name or ID of server.')) @utils.arg('migration', metavar='<migration>', help=_('ID of migration.')) def do_live_migration_abort(cs, args): """"""Abort an on-going live migration."""""" server = _find_server(cs, args.server) cs.server_migrations.live_migration_abort(server, args.migration) @utils.arg( '--all-tenants', action='store_const', const=1, default=0, help=_('Reset state server(s) in another tenant by name (Admin only).')) @utils.arg( 'server', metavar='<server>', nargs='+', help=_('Name or ID of server(s).')) @utils.arg( '--active', action='store_const', dest='state', default='error', const='active', help=_('Request the server be reset to ""active"" state instead ' 'of ""error"" state (the default).')) def do_reset_state(cs, args): """"""Reset the state of a server."""""" failure_flag = False find_args = {'all_tenants': args.all_tenants} for server in args.server: try: _find_server(cs, server, **find_args).reset_state(args.state) msg = ""Reset state for server %s succeeded; new state is %s"" print(msg % (server, args.state)) except Exception as e: failure_flag = True msg = ""Reset state for server %s failed: %s"" % (server, e) print(msg) if failure_flag: msg = ""Unable to reset the state for the specified server(s)."" raise exceptions.CommandError(msg) @utils.arg('server', metavar='<server>', help=_('Name or ID of server.')) def do_reset_network(cs, args): """"""Reset network of a server."""""" _find_server(cs, args.server).reset_network() @utils.arg( '--host', metavar='<hostname>', default=None, help=_('Name of host.')) @utils.arg( '--binary', metavar='<binary>', default=None, help=_('Service binary.')) def do_service_list(cs, args): """"""Show a list of all running services. Filter by host & binary."""""" result = cs.services.list(host=args.host, binary=args.binary) columns = [""Binary"", ""Host"", ""Zone"", ""Status"", ""State"", ""Updated_at""] # NOTE(sulo): we check if the response has disabled_reason # so as not to add the column when the extended ext is not enabled. if result and hasattr(result[0], 'disabled_reason'): columns.append(""Disabled Reason"") # NOTE(gtt): After https://review.openstack.org/#/c/39998/ nova will # show id in response. if result and hasattr(result[0], 'id'): columns.insert(0, ""Id"") utils.print_list(result, columns) @utils.arg('host', metavar='<hostname>', help=_('Name of host.')) @utils.arg('binary', metavar='<binary>', help=_('Service binary.')) def do_service_enable(cs, args): """"""Enable the service."""""" result = cs.services.enable(args.host, args.binary) utils.print_list([result], ['Host', 'Binary', 'Status']) @utils.arg('host', metavar='<hostname>', help=_('Name of host.')) @utils.arg('binary', metavar='<binary>', help=_('Service binary.')) @utils.arg( '--reason', metavar='<reason>', help=_('Reason for disabling service.')) def do_service_disable(cs, args): """"""Disable the service."""""" if args.reason: result = cs.services.disable_log_reason(args.host, args.binary, args.reason) utils.print_list([result], ['Host', 'Binary', 'Status', 'Disabled Reason']) else: result = cs.services.disable(args.host, args.binary) utils.print_list([result], ['Host', 'Binary', 'Status']) @api_versions.wraps(""2.11"") @utils.arg('host', metavar='<hostname>', help=_('Name of host.')) @utils.arg('binary', metavar='<binary>', help=_('Service binary.')) @utils.arg( '--unset', dest='force_down', help=_(""Unset the force state down of service.""), action='store_false', default=True) def do_service_force_down(cs, args): """"""Force service to down."""""" result = cs.services.force_down(args.host, args.binary, args.force_down) utils.print_list([result], ['Host', 'Binary', 'Forced down']) @utils.arg('id', metavar='<id>', help=_('ID of service.')) def do_service_delete(cs, args): """"""Delete the service."""""" cs.services.delete(args.id) @api_versions.wraps(""2.0"", ""2.3"") def _print_fixed_ip(cs, fixed_ip): fields = ['address', 'cidr', 'hostname', 'host'] utils.print_list([fixed_ip], fields) @api_versions.wraps(""2.4"") def _print_fixed_ip(cs, fixed_ip): fields = ['address', 'cidr', 'hostname', 'host', 'reserved'] utils.print_list([fixed_ip], fields) @utils.arg('fixed_ip', metavar='<fixed_ip>', help=_('Fixed IP Address.')) @deprecated_network def do_fixed_ip_get(cs, args): """"""Retrieve info on a fixed IP."""""" result = cs.fixed_ips.get(args.fixed_ip) _print_fixed_ip(cs, result) @utils.arg('fixed_ip', metavar='<fixed_ip>', help=_('Fixed IP Address.')) @deprecated_network def do_fixed_ip_reserve(cs, args): """"""Reserve a fixed IP."""""" cs.fixed_ips.reserve(args.fixed_ip) @utils.arg('fixed_ip', metavar='<fixed_ip>', help=_('Fixed IP Address.')) @deprecated_network def do_fixed_ip_unreserve(cs, args): """"""Unreserve a fixed IP."""""" cs.fixed_ips.unreserve(args.fixed_ip) @utils.arg('host', metavar='<hostname>', help=_('Name of host.')) def do_host_describe(cs, args): """"""Describe a specific host."""""" result = cs.hosts.get(args.host) columns = [""HOST"", ""PROJECT"", ""cpu"", ""memory_mb"", ""disk_gb""] utils.print_list(result, columns) @utils.arg( '--zone', metavar='<zone>', default=None, help=_('Filters the list, returning only those hosts in the availability ' 'zone <zone>.')) def do_host_list(cs, args): """"""List all hosts by service."""""" columns = [""host_name"", ""service"", ""zone""] result = cs.hosts.list(args.zone) utils.print_list(result, columns) @utils.arg('host', metavar='<hostname>', help=_('Name of host.')) @utils.arg( '--status', metavar='<enable|disable>', default=None, dest='status', help=_('Either enable or disable a host.')) @utils.arg( '--maintenance', metavar='<enable|disable>', default=None, dest='maintenance', help=_('Either put or resume host to/from maintenance.')) def do_host_update(cs, args): """"""Update host settings."""""" updates = {} columns = [""HOST""] if args.status: updates['status'] = args.status columns.append(""status"") if args.maintenance: updates['maintenance_mode'] = args.maintenance columns.append(""maintenance_mode"") result = cs.hosts.update(args.host, updates) utils.print_list([result], columns) @utils.arg('host', metavar='<hostname>', help=_('Name of host.')) @utils.arg( '--action', metavar='<action>', dest='action', choices=['startup', 'shutdown', 'reboot'], help=_('A power action: startup, reboot, or shutdown.')) def do_host_action(cs, args): """"""Perform a power action on a host."""""" result = cs.hosts.host_action(args.host, args.action) utils.print_list([result], ['HOST', 'power_action']) def _find_hypervisor(cs, hypervisor): """"""Get a hypervisor by name or ID."""""" return utils.find_resource(cs.hypervisors, hypervisor) def _do_hypervisor_list(cs, matching=None, limit=None, marker=None): columns = ['ID', 'Hypervisor hostname', 'State', 'Status'] if matching: utils.print_list(cs.hypervisors.search(matching), columns) else: params = {} if limit is not None: params['limit'] = limit if marker is not None: params['marker'] = marker # Since we're not outputting detail data, choose # detailed=False for server-side efficiency utils.print_list(cs.hypervisors.list(False, **params), columns) @api_versions.wraps(""2.0"", ""2.32"") @utils.arg( '--matching', metavar='<hostname>', default=None, help=_('List hypervisors matching the given <hostname>.')) def do_hypervisor_list(cs, args): """"""List hypervisors."""""" _do_hypervisor_list(cs, matching=args.matching) @api_versions.wraps(""2.33"") @utils.arg( '--matching', metavar='<hostname>', default=None, help=_('List hypervisors matching the given <hostname>. ' 'If matching is used limit and marker options will be ignored.')) @utils.arg( '--marker', dest='marker', metavar='<marker>', default=None, help=_('The last hypervisor of the previous page; displays list of ' 'hypervisors after ""marker"".')) @utils.arg( '--limit', dest='limit', metavar='<limit>', type=int, default=None, help=_(""Maximum number of hypervisors to display. If limit == -1, all "" ""hypervisors will be displayed. If limit is bigger than "" ""'osapi_max_limit' option of Nova API, limit 'osapi_max_limit' "" ""will be used instead."")) def do_hypervisor_list(cs, args): """"""List hypervisors."""""" _do_hypervisor_list( cs, matching=args.matching, limit=args.limit, marker=args.marker) @utils.arg( 'hostname', metavar='<hostname>', help=_('The hypervisor hostname (or pattern) to search for.')) def do_hypervisor_servers(cs, args): """"""List servers belonging to specific hypervisors."""""" hypers = cs.hypervisors.search(args.hostname, servers=True) class InstanceOnHyper(object): def __init__(self, **kwargs): self.__dict__.update(kwargs) # Massage the result into a list to be displayed instances = [] for hyper in hypers: hyper_host = hyper.hypervisor_hostname hyper_id = hyper.id if hasattr(hyper, 'servers'): instances.extend([InstanceOnHyper(id=serv['uuid'], name=serv['name'], hypervisor_hostname=hyper_host, hypervisor_id=hyper_id) for serv in hyper.servers]) # Output the data utils.print_list(instances, ['ID', 'Name', 'Hypervisor ID', 'Hypervisor Hostname']) @utils.arg( 'hypervisor', metavar='<hypervisor>', help=_('Name or ID of the hypervisor to show the details of.')) @utils.arg( '--wrap', dest='wrap', metavar='<integer>', default=40, help=_('Wrap the output to a specified length. ' 'Default is 40 or 0 to disable')) def do_hypervisor_show(cs, args): """"""Display the details of the specified hypervisor."""""" hyper = _find_hypervisor(cs, args.hypervisor) utils.print_dict(utils.flatten_dict(hyper._info), wrap=int(args.wrap)) @utils.arg( 'hypervisor', metavar='<hypervisor>', help=_('Name or ID of the hypervisor to show the uptime of.')) def do_hypervisor_uptime(cs, args): """"""Display the uptime of the specified hypervisor."""""" hyper = _find_hypervisor(cs, args.hypervisor) hyper = cs.hypervisors.uptime(hyper) # Output the uptime information utils.print_dict(hyper._info.copy()) def do_hypervisor_stats(cs, args): """"""Get hypervisor statistics over all compute nodes."""""" stats = cs.hypervisor_stats.statistics() utils.print_dict(stats._info.copy()) def ensure_service_catalog_present(cs): if not hasattr(cs.client, 'service_catalog'): # Turn off token caching and re-auth cs.client.unauthenticate() cs.client.use_token_cache(False) cs.client.authenticate() def do_endpoints(cs, _args): """"""Discover endpoints that get returned from the authenticate services."""""" warnings.warn( ""nova endpoints is deprecated, use openstack catalog list instead"") if isinstance(cs.client, client.SessionClient): access = cs.client.auth.get_access(cs.client.session) for service in access.service_catalog.catalog: _print_endpoints(service, cs.client.region_name) else: ensure_service_catalog_present(cs) catalog = cs.client.service_catalog.catalog region = cs.client.region_name for service in catalog['access']['serviceCatalog']: _print_endpoints(service, region) def _print_endpoints(service, region): name, endpoints = service[""name""], service[""endpoints""] try: endpoint = _get_first_endpoint(endpoints, region) utils.print_dict(endpoint, name) except LookupError: print(_(""WARNING: %(service)s has no endpoint in %(region)s! "" ""Available endpoints for this service:"") % {'service': name, 'region': region}) for other_endpoint in endpoints: utils.print_dict(other_endpoint, name) def _get_first_endpoint(endpoints, region): """"""Find the first suitable endpoint in endpoints. If there is only one endpoint, return it. If there is more than one endpoint, return the first one with the given region. If there are no endpoints, or there is more than one endpoint but none of them match the given region, raise KeyError. """""" if len(endpoints) == 1: return endpoints[0] else: for candidate_endpoint in endpoints: if candidate_endpoint[""region""] == region: return candidate_endpoint raise LookupError(""No suitable endpoint found"") @utils.arg( '--wrap', dest='wrap', metavar='<integer>', default=64, help=_('Wrap PKI tokens to a specified length, or 0 to disable.')) def do_credentials(cs, _args): """"""Show user credentials returned from auth."""""" warnings.warn( ""nova credentials is deprecated, use openstack client instead"") if isinstance(cs.client, client.SessionClient): access = cs.client.auth.get_access(cs.client.session) utils.print_dict(access._user, 'User Credentials', wrap=int(_args.wrap)) if hasattr(access, '_token'): utils.print_dict(access._token, 'Token', wrap=int(_args.wrap)) else: ensure_service_catalog_present(cs) catalog = cs.client.service_catalog.catalog utils.print_dict(catalog['access']['user'], ""User Credentials"", wrap=int(_args.wrap)) utils.print_dict(catalog['access']['token'], ""Token"", wrap=int(_args.wrap)) @utils.arg('server', metavar='<server>', help=_('Name or ID of server.')) @utils.arg( '--port', dest='port', action='store', type=int, default=22, help=_('Optional flag to indicate which port to use for ssh. ' '(Default=22)')) @utils.arg( '--private', dest='private', action='store_true', default=False, help=argparse.SUPPRESS) @utils.arg( '--address-type', dest='address_type', action='store', type=str, default='floating', help=_('Optional flag to indicate which IP type to use. Possible values ' 'includes fixed and floating (the Default).')) @utils.arg( '--network', metavar='<network>', help=_('Network to use for the ssh.'), default=None) @utils.arg( '--ipv6', dest='ipv6', action='store_true', default=False, help=_('Optional flag to indicate whether to use an IPv6 address ' 'attached to a server. (Defaults to IPv4 address)')) @utils.arg( '--login', metavar='<login>', help=_('Login to use.'), default=""root"") @utils.arg( '-i', '--identity', dest='identity', help=_('Private key file, same as the -i option to the ssh command.'), default='') @utils.arg( '--extra-opts', dest='extra', help=_('Extra options to pass to ssh. see: man ssh.'), default='') def do_ssh(cs, args): """"""SSH into a server."""""" if '@' in args.server: user, server = args.server.split('@', 1) args.login = user args.server = server addresses = _find_server(cs, args.server).addresses address_type = ""fixed"" if args.private else args.address_type version = 6 if args.ipv6 else 4 pretty_version = 'IPv%d' % version # Select the network to use. if args.network: network_addresses = addresses.get(args.network) if not network_addresses: msg = _(""Server '%(server)s' is not attached to network "" ""'%(network)s'"") raise exceptions.ResourceNotFound( msg % {'server': args.server, 'network': args.network}) else: if len(addresses) > 1: msg = _(""Server '%(server)s' is attached to more than one network."" "" Please pick the network to use."") raise exceptions.CommandError(msg % {'server': args.server}) elif not addresses: msg = _(""Server '%(server)s' is not attached to any network."") raise exceptions.CommandError(msg % {'server': args.server}) else: network_addresses = list(six.itervalues(addresses))[0] # Select the address in the selected network. # If the extension is not present, we assume the address to be floating. match = lambda addr: all(( addr.get('version') == version, addr.get('OS-EXT-IPS:type', 'floating') == address_type)) matching_addresses = [address.get('addr') for address in network_addresses if match(address)] if not any(matching_addresses): msg = _(""No address that would match network '%(network)s'"" "" and type '%(address_type)s' of version %(pretty_version)s "" ""has been found for server '%(server)s'."") raise exceptions.ResourceNotFound(msg % { 'network': args.network, 'address_type': address_type, 'pretty_version': pretty_version, 'server': args.server}) elif len(matching_addresses) > 1: msg = _(""More than one %(pretty_version)s %(address_type)s address "" ""found."") raise exceptions.CommandError(msg % {'pretty_version': pretty_version, 'address_type': address_type}) else: ip_address = matching_addresses[0] identity = '-i %s' % args.identity if len(args.identity) else '' cmd = ""ssh -%d -p%d %s %s@%s %s"" % (version, args.port, identity, args.login, ip_address, args.extra) logger.debug(""Executing cmd '%s'"", cmd) os.system(cmd) _quota_resources = ['instances', 'cores', 'ram', 'floating_ips', 'fixed_ips', 'metadata_items', 'injected_files', 'injected_file_content_bytes', 'injected_file_path_bytes', 'key_pairs', 'security_groups', 'security_group_rules', 'server_groups', 'server_group_members'] def _quota_show(quotas): class FormattedQuota(object): def __init__(self, key, value): setattr(self, 'quota', key) setattr(self, 'limit', value) quota_list = [] for resource in _quota_resources: try: quota = FormattedQuota(resource, getattr(quotas, resource)) quota_list.append(quota) except AttributeError: pass columns = ['Quota', 'Limit'] utils.print_list(quota_list, columns) def _quota_update(manager, identifier, args): updates = {} for resource in _quota_resources: val = getattr(args, resource, None) if val is not None: updates[resource] = val if updates: # default value of force is None to make sure this client # will be compatible with old nova server force_update = getattr(args, 'force', None) user_id = getattr(args, 'user', None) if isinstance(manager, quotas.QuotaSetManager): manager.update(identifier, force=force_update, user_id=user_id, **updates) else: manager.update(identifier, **updates) @utils.arg( '--tenant', metavar='<tenant-id>', default=None, help=_('ID of tenant to list the quotas for.')) @utils.arg( '--user', metavar='<user-id>', default=None, help=_('ID of user to list the quotas for.')) @utils.arg( '--detail', action='store_true', default=False, help=_('Show detailed info (limit, reserved, in-use).')) def do_quota_show(cs, args): """"""List the quotas for a tenant/user."""""" if args.tenant: project_id = args.tenant elif isinstance(cs.client, client.SessionClient): auth = cs.client.auth project_id = auth.get_auth_ref(cs.client.session).project_id else: project_id = cs.client.tenant_id _quota_show(cs.quotas.get(project_id, user_id=args.user, detail=args.detail)) @utils.arg( '--tenant', metavar='<tenant-id>', default=None, help=_('ID of tenant to list the default quotas for.')) def do_quota_defaults(cs, args): """"""List the default quotas for a tenant."""""" if args.tenant: project_id = args.tenant elif isinstance(cs.client, client.SessionClient): auth = cs.client.auth project_id = auth.get_auth_ref(cs.client.session).project_id else: project_id = cs.client.tenant_id _quota_show(cs.quotas.defaults(project_id)) @api_versions.wraps(""2.0"", ""2.35"") @utils.arg( 'tenant', metavar='<tenant-id>', help=_('ID of tenant to set the quotas for.')) @utils.arg( '--user', metavar='<user-id>', default=None, help=_('ID of user to set the quotas for.')) @utils.arg( '--instances', metavar='<instances>', type=int, default=None, help=_('New value for the ""instances"" quota.')) @utils.arg( '--cores', metavar='<cores>', type=int, default=None, help=_('New value for the ""cores"" quota.')) @utils.arg( '--ram', metavar='<ram>', type=int, default=None, help=_('New value for the ""ram"" quota.')) @utils.arg( '--floating-ips', metavar='<floating-ips>', type=int, default=None, action=shell.DeprecatedAction, help=_('New value for the ""floating-ips"" quota.')) @utils.arg( '--fixed-ips', metavar='<fixed-ips>', type=int, default=None, action=shell.DeprecatedAction, help=_('New value for the ""fixed-ips"" quota.')) @utils.arg( '--metadata-items', metavar='<metadata-items>', type=int, default=None, help=_('New value for the ""metadata-items"" quota.')) @utils.arg( '--injected-files', metavar='<injected-files>', type=int, default=None, help=_('New value for the ""injected-files"" quota.')) @utils.arg( '--injected-file-content-bytes', metavar='<injected-file-content-bytes>', type=int, default=None, help=_('New value for the ""injected-file-content-bytes"" quota.')) @utils.arg( '--injected-file-path-bytes', metavar='<injected-file-path-bytes>', type=int, default=None, help=_('New value for the ""injected-file-path-bytes"" quota.')) @utils.arg( '--key-pairs', metavar='<key-pairs>', type=int, default=None, help=_('New value for the ""key-pairs"" quota.')) @utils.arg( '--security-groups', metavar='<security-groups>', type=int, default=None, action=shell.DeprecatedAction, help=_('New value for the ""security-groups"" quota.')) @utils.arg( '--security-group-rules', metavar='<security-group-rules>', type=int, default=None, action=shell.DeprecatedAction, help=_('New value for the ""security-group-rules"" quota.')) @utils.arg( '--server-groups', metavar='<server-groups>', type=int, default=None, help=_('New value for the ""server-groups"" quota.')) @utils.arg( '--server-group-members', metavar='<server-group-members>', type=int, default=None, help=_('New value for the ""server-group-members"" quota.')) @utils.arg( '--force', dest='force', action=""store_true"", default=None, help=_('Whether force update the quota even if the already used and ' 'reserved exceeds the new quota.')) def do_quota_update(cs, args): """"""Update the quotas for a tenant/user."""""" _quota_update(cs.quotas, args.tenant, args) # 2.36 does not support updating quota for floating IPs, fixed IPs, security # groups or security group rules. @api_versions.wraps(""2.36"") @utils.arg( 'tenant', metavar='<tenant-id>', help=_('ID of tenant to set the quotas for.')) @utils.arg( '--user', metavar='<user-id>', default=None, help=_('ID of user to set the quotas for.')) @utils.arg( '--instances', metavar='<instances>', type=int, default=None, help=_('New value for the ""instances"" quota.')) @utils.arg( '--cores', metavar='<cores>', type=int, default=None, help=_('New value for the ""cores"" quota.')) @utils.arg( '--ram', metavar='<ram>', type=int, default=None, help=_('New value for the ""ram"" quota.')) @utils.arg( '--metadata-items', metavar='<metadata-items>', type=int, default=None, help=_('New value for the ""metadata-items"" quota.')) @utils.arg( '--injected-files', metavar='<injected-files>', type=int, default=None, help=_('New value for the ""injected-files"" quota.')) @utils.arg( '--injected-file-content-bytes', metavar='<injected-file-content-bytes>', type=int, default=None, help=_('New value for the ""injected-file-content-bytes"" quota.')) @utils.arg( '--injected-file-path-bytes', metavar='<injected-file-path-bytes>', type=int, default=None, help=_('New value for the ""injected-file-path-bytes"" quota.')) @utils.arg( '--key-pairs', metavar='<key-pairs>', type=int, default=None, help=_('New value for the ""key-pairs"" quota.')) @utils.arg( '--server-groups', metavar='<server-groups>', type=int, default=None, help=_('New value for the ""server-groups"" quota.')) @utils.arg( '--server-group-members', metavar='<server-group-members>', type=int, default=None, help=_('New value for the ""server-group-members"" quota.')) @utils.arg( '--force', dest='force', action=""store_true"", default=None, help=_('Whether force update the quota even if the already used and ' 'reserved exceeds the new quota.')) def do_quota_update(cs, args): """"""Update the quotas for a tenant/user."""""" _quota_update(cs.quotas, args.tenant, args) @utils.arg( '--tenant', metavar='<tenant-id>', required=True, help=_('ID of tenant to delete quota for.')) @utils.arg( '--user', metavar='<user-id>', help=_('ID of user to delete quota for.')) def do_quota_delete(cs, args): """"""Delete quota for a tenant/user so their quota will Revert back to default. """""" cs.quotas.delete(args.tenant, user_id=args.user) @utils.arg( 'class_name', metavar='<class>', help=_('Name of quota class to list the quotas for.')) def do_quota_class_show(cs, args): """"""List the quotas for a quota class."""""" _quota_show(cs.quota_classes.get(args.class_name)) @api_versions.wraps(""2.0"", ""2.35"") @utils.arg( 'class_name', metavar='<class>', help=_('Name of quota class to set the quotas for.')) @utils.arg( '--instances', metavar='<instances>', type=int, default=None, help=_('New value for the ""instances"" quota.')) @utils.arg( '--cores', metavar='<cores>', type=int, default=None, help=_('New value for the ""cores"" quota.')) @utils.arg( '--ram', metavar='<ram>', type=int, default=None, help=_('New value for the ""ram"" quota.')) @utils.arg( '--floating-ips', metavar='<floating-ips>', type=int, default=None, action=shell.DeprecatedAction, help=_('New value for the ""floating-ips"" quota.')) @utils.arg( '--fixed-ips', metavar='<fixed-ips>', type=int, default=None, action=shell.DeprecatedAction, help=_('New value for the ""fixed-ips"" quota.')) @utils.arg( '--metadata-items', metavar='<metadata-items>', type=int, default=None, help=_('New value for the ""metadata-items"" quota.')) @utils.arg( '--injected-files', metavar='<injected-files>', type=int, default=None, help=_('New value for the ""injected-files"" quota.')) @utils.arg( '--injected-file-content-bytes', metavar='<injected-file-content-bytes>', type=int, default=None, help=_('New value for the ""injected-file-content-bytes"" quota.')) @utils.arg( '--injected-file-path-bytes', metavar='<injected-file-path-bytes>', type=int, default=None, help=_('New value for the ""injected-file-path-bytes"" quota.')) @utils.arg( '--key-pairs', metavar='<key-pairs>', type=int, default=None, help=_('New value for the ""key-pairs"" quota.')) @utils.arg( '--security-groups', metavar='<security-groups>', type=int, default=None, action=shell.DeprecatedAction, help=_('New value for the ""security-groups"" quota.')) @utils.arg( '--security-group-rules', metavar='<security-group-rules>', type=int, default=None, action=shell.DeprecatedAction, help=_('New value for the ""security-group-rules"" quota.')) @utils.arg( '--server-groups', metavar='<server-groups>', type=int, default=None, help=_('New value for the ""server-groups"" quota.')) @utils.arg( '--server-group-members', metavar='<server-group-members>', type=int, default=None, help=_('New value for the ""server-group-members"" quota.')) def do_quota_class_update(cs, args): """"""Update the quotas for a quota class."""""" _quota_update(cs.quota_classes, args.class_name, args) # 2.36 does not support updating quota for floating IPs, fixed IPs, security # groups or security group rules. @api_versions.wraps(""2.36"") @utils.arg( 'class_name', metavar='<class>', help=_('Name of quota class to set the quotas for.')) @utils.arg( '--instances', metavar='<instances>', type=int, default=None, help=_('New value for the ""instances"" quota.')) @utils.arg( '--cores', metavar='<cores>', type=int, default=None, help=_('New value for the ""cores"" quota.')) @utils.arg( '--ram', metavar='<ram>', type=int, default=None, help=_('New value for the ""ram"" quota.')) @utils.arg( '--metadata-items', metavar='<metadata-items>', type=int, default=None, help=_('New value for the ""metadata-items"" quota.')) @utils.arg( '--injected-files', metavar='<injected-files>', type=int, default=None, help=_('New value for the ""injected-files"" quota.')) @utils.arg( '--injected-file-content-bytes', metavar='<injected-file-content-bytes>', type=int, default=None, help=_('New value for the ""injected-file-content-bytes"" quota.')) @utils.arg( '--injected-file-path-bytes', metavar='<injected-file-path-bytes>', type=int, default=None, help=_('New value for the ""injected-file-path-bytes"" quota.')) @utils.arg( '--key-pairs', metavar='<key-pairs>', type=int, default=None, help=_('New value for the ""key-pairs"" quota.')) @utils.arg( '--server-groups', metavar='<server-groups>', type=int, default=None, help=_('New value for the ""server-groups"" quota.')) @utils.arg( '--server-group-members', metavar='<server-group-members>', type=int, default=None, help=_('New value for the ""server-group-members"" quota.')) def do_quota_class_update(cs, args): """"""Update the quotas for a quota class."""""" _quota_update(cs.quota_classes, args.class_name, args) @utils.arg('server', metavar='<server>', help=_('Name or ID of server.')) @utils.arg( 'host', metavar='<host>', nargs='?', help=_(""Name or ID of the target host. "" ""If no host is specified, the scheduler will choose one."")) @utils.arg( '--password', dest='password', metavar='<password>', help=_(""Set the provided admin password on the evacuated server. Not"" "" applicable if the server is on shared storage."")) @utils.arg( '--on-shared-storage', dest='on_shared_storage', action=""store_true"", default=False, help=_('Specifies whether server files are located on shared storage.'), start_version='2.0', end_version='2.13') @utils.arg( '--force', dest='force', action='store_true', default=False, help=_('Force to not verify the scheduler if a host is provided.'), start_version='2.29') def do_evacuate(cs, args): """"""Evacuate server from failed host."""""" server = _find_server(cs, args.server) on_shared_storage = getattr(args, 'on_shared_storage', None) force = getattr(args, 'force', None) update_kwargs = {} if on_shared_storage is not None: update_kwargs['on_shared_storage'] = on_shared_storage if force: update_kwargs['force'] = force res = server.evacuate(host=args.host, password=args.password, **update_kwargs)[1] if isinstance(res, dict): utils.print_dict(res) def _print_interfaces(interfaces): columns = ['Port State', 'Port ID', 'Net ID', 'IP addresses', 'MAC Addr'] class FormattedInterface(object): def __init__(self, interface): for col in columns: key = col.lower().replace("" "", ""_"") if hasattr(interface, key): setattr(self, key, getattr(interface, key)) self.ip_addresses = "","".join([fip['ip_address'] for fip in interface.fixed_ips]) utils.print_list([FormattedInterface(i) for i in interfaces], columns) @utils.arg('server', metavar='<server>', help=_('Name or ID of server.')) def do_interface_list(cs, args): """"""List interfaces attached to a server."""""" server = _find_server(cs, args.server) res = server.interface_list() if isinstance(res, list): _print_interfaces(res) @utils.arg('server', metavar='<server>', help=_('Name or ID of server.')) @utils.arg( '--port-id', metavar='<port_id>', help=_('Port ID.'), dest=""port_id"") @utils.arg( '--net-id', metavar='<net_id>', help=_('Network ID'), default=None, dest=""net_id"") @utils.arg( '--fixed-ip', metavar='<fixed_ip>', help=_('Requested fixed IP.'), default=None, dest=""fixed_ip"") def do_interface_attach(cs, args): """"""Attach a network interface to a server."""""" server = _find_server(cs, args.server) res = server.interface_attach(args.port_id, args.net_id, args.fixed_ip) if isinstance(res, dict): utils.print_dict(res) @utils.arg('server', metavar='<server>', help=_('Name or ID of server.')) @utils.arg('port_id', metavar='<port_id>', help=_('Port ID.')) def do_interface_detach(cs, args): """"""Detach a network interface from a server."""""" server = _find_server(cs, args.server) res = server.interface_detach(args.port_id) if isinstance(res, dict): utils.print_dict(res) @api_versions.wraps(""2.17"") @utils.arg('server', metavar='<server>', help=_('Name or ID of server.')) def do_trigger_crash_dump(cs, args): """"""Trigger crash dump in an instance."""""" server = _find_server(cs, args.server) server.trigger_crash_dump() def _treeizeAvailabilityZone(zone): """"""Build a tree view for availability zones."""""" AvailabilityZone = availability_zones.AvailabilityZone az = AvailabilityZone(zone.manager, copy.deepcopy(zone._info), zone._loaded) result = [] # Zone tree view item az.zoneName = zone.zoneName az.zoneState = ('available' if zone.zoneState['available'] else 'not available') az._info['zoneName'] = az.zoneName az._info['zoneState'] = az.zoneState result.append(az) if zone.hosts is not None: zone_hosts = sorted(zone.hosts.items(), key=lambda x: x[0]) for (host, services) in zone_hosts: # Host tree view item az = AvailabilityZone(zone.manager, copy.deepcopy(zone._info), zone._loaded) az.zoneName = '|- %s' % host az.zoneState = '' az._info['zoneName'] = az.zoneName az._info['zoneState'] = az.zoneState result.append(az) for (svc, state) in services.items(): # Service tree view item az = AvailabilityZone(zone.manager, copy.deepcopy(zone._info), zone._loaded) az.zoneName = '| |- %s' % svc az.zoneState = '%s %s %s' % ( 'enabled' if state['active'] else 'disabled', ':-)' if state['available'] else 'XXX', state['updated_at']) az._info['zoneName'] = az.zoneName az._info['zoneState'] = az.zoneState result.append(az) return result @utils.service_type('compute') def do_availability_zone_list(cs, _args): """"""List all the availability zones."""""" try: availability_zones = cs.availability_zones.list() except exceptions.Forbidden as e: # policy doesn't allow probably try: availability_zones = cs.availability_zones.list(detailed=False) except Exception: raise e result = [] for zone in availability_zones: result += _treeizeAvailabilityZone(zone) _translate_availability_zone_keys(result) utils.print_list(result, ['Name', 'Status'], sortby_index=None) @api_versions.wraps(""2.0"", ""2.12"") def _print_server_group_details(cs, server_group): columns = ['Id', 'Name', 'Policies', 'Members', 'Metadata'] utils.print_list(server_group, columns) @api_versions.wraps(""2.13"") def _print_server_group_details(cs, server_group): # noqa columns = ['Id', 'Name', 'Project Id', 'User Id', 'Policies', 'Members', 'Metadata'] utils.print_list(server_group, columns) @utils.arg( '--all-projects', dest='all_projects', action='store_true', default=False, help=_('Display server groups from all projects (Admin only).')) def do_server_group_list(cs, args): """"""Print a list of all server groups."""""" server_groups = cs.server_groups.list(args.all_projects) _print_server_group_details(cs, server_groups) @deprecated_network def do_secgroup_list_default_rules(cs, args): """"""List rules that will be added to the 'default' security group for new tenants. """""" _print_secgroup_rules(cs.security_group_default_rules.list(), show_source_group=False) @utils.arg( 'ip_proto', metavar='<ip-proto>', help=_('IP protocol (icmp, tcp, udp).')) @utils.arg( 'from_port', metavar='<from-port>', help=_('Port at start of range.')) @utils.arg( 'to_port', metavar='<to-port>', help=_('Port at end of range.')) @utils.arg('cidr', metavar='<cidr>', help=_('CIDR for address range.')) @deprecated_network def do_secgroup_add_default_rule(cs, args): """"""Add a rule to the set of rules that will be added to the 'default' security group for new tenants (nova-network only). """""" rule = cs.security_group_default_rules.create(args.ip_proto, args.from_port, args.to_port, args.cidr) _print_secgroup_rules([rule], show_source_group=False) @utils.arg( 'ip_proto', metavar='<ip-proto>', help=_('IP protocol (icmp, tcp, udp).')) @utils.arg( 'from_port', metavar='<from-port>', help=_('Port at start of range.')) @utils.arg( 'to_port', metavar='<to-port>', help=_('Port at end of range.')) @utils.arg('cidr', metavar='<cidr>', help=_('CIDR for address range.')) @deprecated_network def do_secgroup_delete_default_rule(cs, args): """"""Delete a rule from the set of rules that will be added to the 'default' security group for new tenants (nova-network only). """""" for rule in cs.security_group_default_rules.list(): if (rule.ip_protocol and rule.ip_protocol.upper() == args.ip_proto.upper() and rule.from_port == int(args.from_port) and rule.to_port == int(args.to_port) and rule.ip_range['cidr'] == args.cidr): _print_secgroup_rules([rule], show_source_group=False) return cs.security_group_default_rules.delete(rule.id) raise exceptions.CommandError(_(""Rule not found"")) @utils.arg('name', metavar='<name>', help=_('Server group name.')) # NOTE(wingwj): The '--policy' way is still reserved here for preserving # the backwards compatibility of CLI, even if a user won't get this usage # in '--help' description. It will be deprecated after a suitable deprecation # period(probably 2 coordinated releases or so). # # Moreover, we imagine that a given user will use only positional parameters or # only the ""--policy"" option. So we don't need to properly handle # the possibility that they might mix them here. That usage is unsupported. # The related discussion can be found in # https://review.openstack.org/#/c/96382/2/. @utils.arg( 'policy', metavar='<policy>', default=argparse.SUPPRESS, nargs='*', help=_('Policies for the server groups.')) def do_server_group_create(cs, args): """"""Create a new server group with the specified details."""""" if not args.policy: raise exceptions.CommandError(_(""at least one policy must be "" ""specified"")) kwargs = {'name': args.name, 'policies': args.policy} server_group = cs.server_groups.create(**kwargs) _print_server_group_details(cs, [server_group]) @utils.arg( 'id', metavar='<id>', nargs='+', help=_(""Unique ID(s) of the server group to delete."")) def do_server_group_delete(cs, args): """"""Delete specific server group(s)."""""" failure_count = 0 for sg in args.id: try: cs.server_groups.delete(sg) print(_(""Server group %s has been successfully deleted."") % sg) except Exception as e: failure_count += 1 print(_(""Delete for server group %(sg)s failed: %(e)s"") % {'sg': sg, 'e': e}) if failure_count == len(args.id): raise exceptions.CommandError(_(""Unable to delete any of the "" ""specified server groups."")) @utils.arg( 'id', metavar='<id>', help=_(""Unique ID of the server group to get."")) def do_server_group_get(cs, args): """"""Get a specific server group."""""" server_group = cs.server_groups.get(args.id) _print_server_group_details(cs, [server_group]) def do_version_list(cs, args): """"""List all API versions."""""" result = cs.versions.list() if 'min_version' in dir(result[0]): columns = [""Id"", ""Status"", ""Updated"", ""Min Version"", ""Version""] else: columns = [""Id"", ""Status"", ""Updated""] print(_(""Client supported API versions:"")) print(_(""Minimum version %(v)s"") % {'v': novaclient.API_MIN_VERSION.get_string()}) print(_(""Maximum version %(v)s"") % {'v': novaclient.API_MAX_VERSION.get_string()}) print(_(""\nServer supported API versions:"")) utils.print_list(result, columns) @api_versions.wraps(""2.0"", ""2.11"") def _print_virtual_interface_list(cs, interface_list): columns = ['Id', 'Mac address'] utils.print_list(interface_list, columns) @api_versions.wraps(""2.12"") def _print_virtual_interface_list(cs, interface_list): columns = ['Id', 'Mac address', 'Network ID'] formatters = {""Network ID"": lambda o: o.net_id} utils.print_list(interface_list, columns, formatters) @utils.arg('server', metavar='<server>', help=_('ID of server.')) def do_virtual_interface_list(cs, args): """"""Show virtual interface info about the given server."""""" server = _find_server(cs, args.server) interface_list = cs.virtual_interfaces.list(base.getid(server)) _print_virtual_interface_list(cs, interface_list) @api_versions.wraps(""2.26"") @utils.arg('server', metavar='<server>', help=_('Name or ID of server.')) def do_server_tag_list(cs, args): """"""Get list of tags from a server."""""" server = _find_server(cs, args.server) tags = server.tag_list() formatters = {'Tag': lambda o: o} utils.print_list(tags, ['Tag'], formatters=formatters) @api_versions.wraps(""2.26"") @utils.arg('server', metavar='<server>', help=_('Name or ID of server.')) @utils.arg('tag', metavar='<tag>', help=_('Tag to add.')) def do_server_tag_add(cs, args): """"""Add single tag to a server."""""" server = _find_server(cs, args.server) server.add_tag(args.tag) @api_versions.wraps(""2.26"") @utils.arg('server', metavar='<server>', help=_('Name or ID of server.')) @utils.arg('tags', metavar='<tags>', nargs='+', help=_('Tag(s) to set.')) def do_server_tag_set(cs, args): """"""Set list of tags to a server."""""" server = _find_server(cs, args.server) server.set_tags(args.tags) @api_versions.wraps(""2.26"") @utils.arg('server', metavar='<server>', help=_('Name or ID of server.')) @utils.arg('tag', metavar='<tag>', help=_('Tag to delete.')) def do_server_tag_delete(cs, args): """"""Delete single tag from a server."""""" server = _find_server(cs, args.server) server.delete_tag(args.tag) @api_versions.wraps(""2.26"") @utils.arg('server', metavar='<server>', help=_('Name or ID of server.')) def do_server_tag_delete_all(cs, args): """"""Delete all tags from a server."""""" server = _find_server(cs, args.server) server.delete_all_tags() ","# Copyright 2010 Jacob Kaplan-Moss # Copyright 2011 OpenStack Foundation # Copyright 2013 IBM Corp. # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. from __future__ import print_function import argparse import copy import datetime import functools import getpass import locale import logging import os import sys import time import warnings from oslo_utils import encodeutils from oslo_utils import netutils from oslo_utils import strutils from oslo_utils import timeutils from oslo_utils import uuidutils import six import novaclient from novaclient import api_versions from novaclient import base from novaclient import client from novaclient import exceptions from novaclient.i18n import _ from novaclient.i18n import _LE from novaclient import shell from novaclient import utils from novaclient.v2 import availability_zones from novaclient.v2 import quotas from novaclient.v2 import servers logger = logging.getLogger(__name__) CLIENT_BDM2_KEYS = { 'id': 'uuid', 'source': 'source_type', 'dest': 'destination_type', 'bus': 'disk_bus', 'device': 'device_name', 'size': 'volume_size', 'format': 'guest_format', 'bootindex': 'boot_index', 'type': 'device_type', 'shutdown': 'delete_on_termination', 'tag': 'tag', } # NOTE(mriedem): Remove this along with the deprecated commands in the first # python-novaclient release AFTER the nova server 15.0.0 'O' release. def emit_image_deprecation_warning(command_name): print('WARNING: Command %s is deprecated and will be removed after Nova ' '15.0.0 is released. Use python-glanceclient or openstackclient ' 'instead.' % command_name, file=sys.stderr) def deprecated_network(fn): @functools.wraps(fn) def wrapped(cs, *args, **kwargs): command_name = '-'.join(fn.__name__.split('_')[1:]) print('WARNING: Command %s is deprecated and will be removed ' 'after Nova 15.0.0 is released. Use python-neutronclient ' 'or python-openstackclient instead.' % command_name, file=sys.stderr) # The network proxy API methods were deprecated in 2.36 and will return # a 404 so we fallback to 2.35 to maintain a transition for CLI users. want_version = api_versions.APIVersion('2.35') cur_version = cs.api_version if cs.api_version > want_version: cs.api_version = want_version try: return fn(cs, *args, **kwargs) finally: cs.api_version = cur_version wrapped.__doc__ = 'DEPRECATED: ' + fn.__doc__ return wrapped def _key_value_pairing(text): try: (k, v) = text.split('=', 1) return (k, v) except ValueError: msg = _LE(""'%s' is not in the format of 'key=value'"") % text raise argparse.ArgumentTypeError(msg) def _meta_parsing(metadata): return dict(v.split('=', 1) for v in metadata) def _match_image(cs, wanted_properties): image_list = cs.images.list() images_matched = [] match = set(wanted_properties) for img in image_list: try: if match == match.intersection(set(img.metadata.items())): images_matched.append(img) except AttributeError: pass return images_matched def _parse_block_device_mapping_v2(args, image): bdm = [] if args.boot_volume: bdm_dict = {'uuid': args.boot_volume, 'source_type': 'volume', 'destination_type': 'volume', 'boot_index': 0, 'delete_on_termination': False} bdm.append(bdm_dict) if args.snapshot: bdm_dict = {'uuid': args.snapshot, 'source_type': 'snapshot', 'destination_type': 'volume', 'boot_index': 0, 'delete_on_termination': False} bdm.append(bdm_dict) for device_spec in args.block_device: spec_dict = dict(v.split('=') for v in device_spec.split(',')) bdm_dict = {} for key, value in six.iteritems(spec_dict): bdm_dict[CLIENT_BDM2_KEYS[key]] = value # Convert the delete_on_termination to a boolean or set it to true by # default for local block devices when not specified. if 'delete_on_termination' in bdm_dict: action = bdm_dict['delete_on_termination'] if action not in ['remove', 'preserve']: raise exceptions.CommandError( _(""The value of shutdown key of --block-device shall be "" ""either 'remove' or 'preserve' but it was '%(action)s'"") % {'action': action}) bdm_dict['delete_on_termination'] = (action == 'remove') elif bdm_dict.get('destination_type') == 'local': bdm_dict['delete_on_termination'] = True bdm.append(bdm_dict) for ephemeral_spec in args.ephemeral: bdm_dict = {'source_type': 'blank', 'destination_type': 'local', 'boot_index': -1, 'delete_on_termination': True} try: eph_dict = dict(v.split('=') for v in ephemeral_spec.split(',')) except ValueError: err_msg = (_(""Invalid ephemeral argument '%s'."") % args.ephemeral) raise argparse.ArgumentTypeError(err_msg) if 'size' in eph_dict: bdm_dict['volume_size'] = eph_dict['size'] if 'format' in eph_dict: bdm_dict['guest_format'] = eph_dict['format'] bdm.append(bdm_dict) if args.swap: bdm_dict = {'source_type': 'blank', 'destination_type': 'local', 'boot_index': -1, 'delete_on_termination': True, 'guest_format': 'swap', 'volume_size': args.swap} bdm.append(bdm_dict) return bdm def _parse_nics(cs, args): if cs.api_version >= api_versions.APIVersion('2.32'): err_msg = (_(""Invalid nic argument '%s'. Nic arguments must be of "" ""the form --nic <net-id=net-uuid,"" ""net-name=network-name,v4-fixed-ip=ip-addr,"" ""v6-fixed-ip=ip-addr,port-id=port-uuid,tag=tag>, "" ""with only one of net-id, net-name or port-id "" ""specified."")) else: err_msg = (_(""Invalid nic argument '%s'. Nic arguments must be of "" ""the form --nic <net-id=net-uuid,"" ""net-name=network-name,v4-fixed-ip=ip-addr,"" ""v6-fixed-ip=ip-addr,port-id=port-uuid>, "" ""with only one of net-id, net-name or port-id "" ""specified."")) nics = [] for nic_str in args.nics: nic_info = {""net-id"": """", ""v4-fixed-ip"": """", ""v6-fixed-ip"": """", ""port-id"": """", ""net-name"": """", ""tag"": """"} for kv_str in nic_str.split("",""): try: k, v = kv_str.split(""="", 1) except ValueError: raise exceptions.CommandError(err_msg % nic_str) if k in nic_info: # if user has given a net-name resolve it to network ID if k == 'net-name': k = 'net-id' v = _find_network_id(cs, v) # if some argument was given multiple times if nic_info[k]: raise exceptions.CommandError(err_msg % nic_str) nic_info[k] = v else: raise exceptions.CommandError(err_msg % nic_str) if nic_info['v4-fixed-ip'] and not netutils.is_valid_ipv4( nic_info['v4-fixed-ip']): raise exceptions.CommandError(_(""Invalid ipv4 address."")) if nic_info['v6-fixed-ip'] and not netutils.is_valid_ipv6( nic_info['v6-fixed-ip']): raise exceptions.CommandError(_(""Invalid ipv6 address."")) if bool(nic_info['net-id']) == bool(nic_info['port-id']): raise exceptions.CommandError(err_msg % nic_str) nics.append(nic_info) return nics def _boot(cs, args): """"""Boot a new server."""""" if not args.flavor: raise exceptions.CommandError(_(""you need to specify a Flavor ID."")) if args.image: image = _find_image(cs, args.image) else: image = None if not image and args.image_with: images = _match_image(cs, args.image_with) if images: # TODO(harlowja): log a warning that we # are selecting the first of many? image = images[0] min_count = 1 max_count = 1 if args.min_count is not None: if args.min_count < 1: raise exceptions.CommandError(_(""min_count should be >= 1"")) min_count = args.min_count max_count = min_count if args.max_count is not None: if args.max_count < 1: raise exceptions.CommandError(_(""max_count should be >= 1"")) max_count = args.max_count if (args.min_count is not None and args.max_count is not None and args.min_count > args.max_count): raise exceptions.CommandError(_(""min_count should be <= max_count"")) flavor = _find_flavor(cs, args.flavor) meta = _meta_parsing(args.meta) files = {} for f in args.files: try: dst, src = f.split('=', 1) files[dst] = open(src) except IOError as e: raise exceptions.CommandError(_(""Can't open '%(src)s': %(exc)s"") % {'src': src, 'exc': e}) except ValueError: raise exceptions.CommandError(_(""Invalid file argument '%s'. "" ""File arguments must be of the "" ""form '--file "" ""<dst-path=src-path>'"") % f) # use the os-keypair extension key_name = None if args.key_name is not None: key_name = args.key_name if args.user_data: try: userdata = open(args.user_data) except IOError as e: raise exceptions.CommandError(_(""Can't open '%(user_data)s': "" ""%(exc)s"") % {'user_data': args.user_data, 'exc': e}) else: userdata = None if args.availability_zone: availability_zone = args.availability_zone else: availability_zone = None if args.security_groups: security_groups = args.security_groups.split(',') else: security_groups = None block_device_mapping = {} for bdm in args.block_device_mapping: device_name, mapping = bdm.split('=', 1) block_device_mapping[device_name] = mapping block_device_mapping_v2 = _parse_block_device_mapping_v2(args, image) n_boot_args = len(list(filter( bool, (image, args.boot_volume, args.snapshot)))) have_bdm = block_device_mapping_v2 or block_device_mapping # Fail if more than one boot devices are present # or if there is no device to boot from. if n_boot_args > 1 or n_boot_args == 0 and not have_bdm: raise exceptions.CommandError( _(""you need to specify at least one source ID (Image, Snapshot, "" ""or Volume), a block device mapping or provide a set of "" ""properties to match against an image"")) if block_device_mapping and block_device_mapping_v2: raise exceptions.CommandError( _(""you can't mix old block devices (--block-device-mapping) "" ""with the new ones (--block-device, --boot-volume, --snapshot, "" ""--ephemeral, --swap)"")) nics = _parse_nics(cs, args) hints = {} if args.scheduler_hints: for hint in args.scheduler_hints: key, _sep, value = hint.partition('=') # NOTE(vish): multiple copies of the same hint will # result in a list of values if key in hints: if isinstance(hints[key], six.string_types): hints[key] = [hints[key]] hints[key] += [value] else: hints[key] = value boot_args = [args.name, image, flavor] if str(args.config_drive).lower() in (""true"", ""1""): config_drive = True elif str(args.config_drive).lower() in (""false"", ""0"", """", ""none""): config_drive = None else: config_drive = args.config_drive boot_kwargs = dict( meta=meta, files=files, key_name=key_name, min_count=min_count, max_count=max_count, userdata=userdata, availability_zone=availability_zone, security_groups=security_groups, block_device_mapping=block_device_mapping, block_device_mapping_v2=block_device_mapping_v2, nics=nics, scheduler_hints=hints, config_drive=config_drive, admin_pass=args.admin_pass, access_ip_v4=args.access_ip_v4, access_ip_v6=args.access_ip_v6) if 'description' in args: boot_kwargs[""description""] = args.description return boot_args, boot_kwargs @utils.arg( '--flavor', default=None, metavar='<flavor>', help=_(""Name or ID of flavor (see 'nova flavor-list')."")) @utils.arg( '--image', default=None, metavar='<image>', help=_(""Name or ID of image (see 'glance image-list'). "")) @utils.arg( '--image-with', default=[], type=_key_value_pairing, action='append', metavar='<key=value>', help=_(""Image metadata property (see 'glance image-show'). "")) @utils.arg( '--boot-volume', default=None, metavar=""<volume_id>"", help=_(""Volume ID to boot from."")) @utils.arg( '--snapshot', default=None, metavar=""<snapshot_id>"", help=_(""Snapshot ID to boot from (will create a volume)."")) @utils.arg( '--min-count', default=None, type=int, metavar='<number>', help=_(""Boot at least <number> servers (limited by quota)."")) @utils.arg( '--max-count', default=None, type=int, metavar='<number>', help=_(""Boot up to <number> servers (limited by quota)."")) @utils.arg( '--meta', metavar=""<key=value>"", action='append', default=[], help=_(""Record arbitrary key/value metadata to /meta_data.json "" ""on the metadata server. Can be specified multiple times."")) @utils.arg( '--file', metavar=""<dst-path=src-path>"", action='append', dest='files', default=[], help=_(""Store arbitrary files from <src-path> locally to <dst-path> "" ""on the new server. Limited by the injected_files quota value."")) @utils.arg( '--key-name', default=os.environ.get('NOVACLIENT_DEFAULT_KEY_NAME'), metavar='<key-name>', help=_(""Key name of keypair that should be created earlier with \ the command keypair-add."")) @utils.arg('name', metavar='<name>', help=_('Name for the new server.')) @utils.arg( '--user-data', default=None, metavar='<user-data>', help=_(""user data file to pass to be exposed by the metadata server."")) @utils.arg( '--availability-zone', default=None, metavar='<availability-zone>', help=_(""The availability zone for server placement."")) @utils.arg( '--security-groups', default=None, metavar='<security-groups>', help=_(""Comma separated list of security group names."")) @utils.arg( '--block-device-mapping', metavar=""<dev-name=mapping>"", action='append', default=[], help=_(""Block device mapping in the format "" ""<dev-name>=<id>:<type>:<size(GB)>:<delete-on-terminate>."")) @utils.arg( '--block-device', metavar=""key1=value1[,key2=value2...]"", action='append', default=[], start_version='2.0', end_version='2.31', help=_(""Block device mapping with the keys: "" ""id=UUID (image_id, snapshot_id or volume_id only if using source "" ""image, snapshot or volume) "" ""source=source type (image, snapshot, volume or blank), "" ""dest=destination type of the block device (volume or local), "" ""bus=device's bus (e.g. uml, lxc, virtio, ...; if omitted, "" ""hypervisor driver chooses a suitable default, "" ""honoured only if device type is supplied) "" ""type=device type (e.g. disk, cdrom, ...; defaults to 'disk') "" ""device=name of the device (e.g. vda, xda, ...; "" ""if omitted, hypervisor driver chooses suitable device "" ""depending on selected bus; note the libvirt driver always "" ""uses default device names), "" ""size=size of the block device in MB(for swap) and in "" ""GB(for other formats) "" ""(if omitted, hypervisor driver calculates size), "" ""format=device will be formatted (e.g. swap, ntfs, ...; optional), "" ""bootindex=integer used for ordering the boot disks "" ""(for image backed instances it is equal to 0, "" ""for others need to be specified) and "" ""shutdown=shutdown behaviour (either preserve or remove, "" ""for local destination set to remove)."")) @utils.arg( '--block-device', metavar=""key1=value1[,key2=value2...]"", action='append', default=[], start_version='2.32', help=_(""Block device mapping with the keys: "" ""id=UUID (image_id, snapshot_id or volume_id only if using source "" ""image, snapshot or volume) "" ""source=source type (image, snapshot, volume or blank), "" ""dest=destination type of the block device (volume or local), "" ""bus=device's bus (e.g. uml, lxc, virtio, ...; if omitted, "" ""hypervisor driver chooses a suitable default, "" ""honoured only if device type is supplied) "" ""type=device type (e.g. disk, cdrom, ...; defaults to 'disk') "" ""device=name of the device (e.g. vda, xda, ...; "" ""tag=device metadata tag (optional) "" ""if omitted, hypervisor driver chooses suitable device "" ""depending on selected bus; note the libvirt driver always "" ""uses default device names), "" ""size=size of the block device in MB(for swap) and in "" ""GB(for other formats) "" ""(if omitted, hypervisor driver calculates size), "" ""format=device will be formatted (e.g. swap, ntfs, ...; optional), "" ""bootindex=integer used for ordering the boot disks "" ""(for image backed instances it is equal to 0, "" ""for others need to be specified) and "" ""shutdown=shutdown behaviour (either preserve or remove, "" ""for local destination set to remove)."")) @utils.arg( '--swap', metavar=""<swap_size>"", default=None, help=_(""Create and attach a local swap block device of <swap_size> MB."")) @utils.arg( '--ephemeral', metavar=""size=<size>[,format=<format>]"", action='append', default=[], help=_(""Create and attach a local ephemeral block device of <size> GB "" ""and format it to <format>."")) @utils.arg( '--hint', action='append', dest='scheduler_hints', default=[], metavar='<key=value>', help=_(""Send arbitrary key/value pairs to the scheduler for custom "" ""use."")) @utils.arg( '--nic', metavar=""<net-id=net-uuid,net-name=network-name,v4-fixed-ip=ip-addr,"" ""v6-fixed-ip=ip-addr,port-id=port-uuid>"", action='append', dest='nics', default=[], start_version='2.0', end_version='2.31', help=_(""Create a NIC on the server. "" ""Specify option multiple times to create multiple NICs. "" ""net-id: attach NIC to network with this UUID "" ""net-name: attach NIC to network with this name "" ""(either port-id or net-id or net-name must be provided), "" ""v4-fixed-ip: IPv4 fixed address for NIC (optional), "" ""v6-fixed-ip: IPv6 fixed address for NIC (optional), "" ""port-id: attach NIC to port with this UUID "" ""(either port-id or net-id must be provided)."")) @utils.arg( '--nic', metavar=""<net-id=net-uuid,net-name=network-name,v4-fixed-ip=ip-addr,"" ""v6-fixed-ip=ip-addr,port-id=port-uuid>"", action='append', dest='nics', default=[], start_version='2.32', help=_(""Create a NIC on the server. "" ""Specify option multiple times to create multiple nics. "" ""net-id: attach NIC to network with this UUID "" ""net-name: attach NIC to network with this name "" ""(either port-id or net-id or net-name must be provided), "" ""v4-fixed-ip: IPv4 fixed address for NIC (optional), "" ""v6-fixed-ip: IPv6 fixed address for NIC (optional), "" ""port-id: attach NIC to port with this UUID "" ""tag: interface metadata tag (optional) "" ""(either port-id or net-id must be provided)."")) @utils.arg( '--config-drive', metavar=""<value>"", dest='config_drive', default=False, help=_(""Enable config drive."")) @utils.arg( '--poll', dest='poll', action=""store_true"", default=False, help=_('Report the new server boot progress until it completes.')) @utils.arg( '--admin-pass', dest='admin_pass', metavar='<value>', default=None, help=_('Admin password for the instance.')) @utils.arg( '--access-ip-v4', dest='access_ip_v4', metavar='<value>', default=None, help=_('Alternative access IPv4 of the instance.')) @utils.arg( '--access-ip-v6', dest='access_ip_v6', metavar='<value>', default=None, help=_('Alternative access IPv6 of the instance.')) @utils.arg( '--description', metavar='<description>', dest='description', default=None, help=_('Description for the server.'), start_version=""2.19"") def do_boot(cs, args): """"""Boot a new server."""""" boot_args, boot_kwargs = _boot(cs, args) extra_boot_kwargs = utils.get_resource_manager_extra_kwargs(do_boot, args) boot_kwargs.update(extra_boot_kwargs) server = cs.servers.create(*boot_args, **boot_kwargs) _print_server(cs, args, server) if args.poll: _poll_for_status(cs.servers.get, server.id, 'building', ['active']) def do_cloudpipe_list(cs, _args): """"""Print a list of all cloudpipe instances."""""" cloudpipes = cs.cloudpipe.list() columns = ['Project Id', ""Public IP"", ""Public Port"", ""Internal IP""] utils.print_list(cloudpipes, columns) @utils.arg( 'project', metavar='<project_id>', help=_('UUID of the project to create the cloudpipe for.')) def do_cloudpipe_create(cs, args): """"""Create a cloudpipe instance for the given project."""""" cs.cloudpipe.create(args.project) @utils.arg('address', metavar='<ip address>', help=_('New IP Address.')) @utils.arg('port', metavar='<port>', help=_('New Port.')) def do_cloudpipe_configure(cs, args): """"""Update the VPN IP/port of a cloudpipe instance."""""" cs.cloudpipe.update(args.address, args.port) def _poll_for_status(poll_fn, obj_id, action, final_ok_states, poll_period=5, show_progress=True, status_field=""status"", silent=False): """"""Block while an action is being performed, periodically printing progress. """""" def print_progress(progress): if show_progress: msg = (_('\rServer %(action)s... %(progress)s%% complete') % dict(action=action, progress=progress)) else: msg = _('\rServer %(action)s...') % dict(action=action) sys.stdout.write(msg) sys.stdout.flush() if not silent: print() while True: obj = poll_fn(obj_id) status = getattr(obj, status_field) if status: status = status.lower() progress = getattr(obj, 'progress', None) or 0 if status in final_ok_states: if not silent: print_progress(100) print(_(""\nFinished"")) break elif status == ""error"": if not silent: print(_(""\nError %s server"") % action) raise exceptions.ResourceInErrorState(obj) elif status == ""deleted"": if not silent: print(_(""\nDeleted %s server"") % action) raise exceptions.InstanceInDeletedState(obj.fault[""message""]) if not silent: print_progress(progress) time.sleep(poll_period) def _translate_keys(collection, convert): for item in collection: keys = item.__dict__.keys() for from_key, to_key in convert: if from_key in keys and to_key not in keys: setattr(item, to_key, item._info[from_key]) def _translate_extended_states(collection): power_states = [ 'NOSTATE', # 0x00 'Running', # 0x01 '', # 0x02 'Paused', # 0x03 'Shutdown', # 0x04 '', # 0x05 'Crashed', # 0x06 'Suspended' # 0x07 ] for item in collection: try: setattr(item, 'power_state', power_states[getattr(item, 'power_state')]) except AttributeError: setattr(item, 'power_state', ""N/A"") try: getattr(item, 'task_state') except AttributeError: setattr(item, 'task_state', ""N/A"") def _translate_flavor_keys(collection): _translate_keys(collection, [('ram', 'memory_mb')]) def _print_flavor_extra_specs(flavor): try: return flavor.get_keys() except exceptions.NotFound: return ""N/A"" def _print_flavor_list(flavors, show_extra_specs=False): _translate_flavor_keys(flavors) headers = [ 'ID', 'Name', 'Memory_MB', 'Disk', 'Ephemeral', 'Swap', 'VCPUs', 'RXTX_Factor', 'Is_Public', ] if show_extra_specs: formatters = {'extra_specs': _print_flavor_extra_specs} headers.append('extra_specs') else: formatters = {} utils.print_list(flavors, headers, formatters) @utils.arg( '--extra-specs', dest='extra_specs', action='store_true', default=False, help=_('Get extra-specs of each flavor.')) @utils.arg( '--all', dest='all', action='store_true', default=False, help=_('Display all flavors (Admin only).')) @utils.arg( '--marker', dest='marker', metavar='<marker>', default=None, help=_('The last flavor ID of the previous page; displays list of flavors' ' after ""marker"".')) @utils.arg( '--limit', dest='limit', metavar='<limit>', type=int, default=None, help=_(""Maximum number of flavors to display. If limit == -1, all flavors "" ""will be displayed. If limit is bigger than 'osapi_max_limit' "" ""option of Nova API, limit 'osapi_max_limit' will be used "" ""instead."")) def do_flavor_list(cs, args): """"""Print a list of available 'flavors' (sizes of servers)."""""" if args.all: flavors = cs.flavors.list(is_public=None) else: flavors = cs.flavors.list(marker=args.marker, limit=args.limit) _print_flavor_list(flavors, args.extra_specs) @utils.arg( 'flavor', metavar='<flavor>', help=_(""Name or ID of the flavor to delete."")) def do_flavor_delete(cs, args): """"""Delete a specific flavor"""""" flavorid = _find_flavor(cs, args.flavor) cs.flavors.delete(flavorid) _print_flavor_list([flavorid]) @utils.arg( 'flavor', metavar='<flavor>', help=_(""Name or ID of flavor."")) def do_flavor_show(cs, args): """"""Show details about the given flavor."""""" flavor = _find_flavor(cs, args.flavor) _print_flavor(flavor) @utils.arg( 'name', metavar='<name>', help=_(""Unique name of the new flavor."")) @utils.arg( 'id', metavar='<id>', help=_(""Unique ID of the new flavor."" "" Specifying 'auto' will generated a UUID for the ID."")) @utils.arg( 'ram', metavar='<ram>', help=_(""Memory size in MB."")) @utils.arg( 'disk', metavar='<disk>', help=_(""Disk size in GB."")) @utils.arg( '--ephemeral', metavar='<ephemeral>', help=_(""Ephemeral space size in GB (default 0).""), default=0) @utils.arg( 'vcpus', metavar='<vcpus>', help=_(""Number of vcpus"")) @utils.arg( '--swap', metavar='<swap>', help=_(""Swap space size in MB (default 0).""), default=0) @utils.arg( '--rxtx-factor', metavar='<factor>', help=_(""RX/TX factor (default 1).""), default=1.0) @utils.arg( '--is-public', metavar='<is-public>', help=_(""Make flavor accessible to the public (default true).""), type=lambda v: strutils.bool_from_string(v, True), default=True) def do_flavor_create(cs, args): """"""Create a new flavor."""""" f = cs.flavors.create(args.name, args.ram, args.vcpus, args.disk, args.id, args.ephemeral, args.swap, args.rxtx_factor, args.is_public) _print_flavor_list([f]) @utils.arg( 'flavor', metavar='<flavor>', help=_(""Name or ID of flavor."")) @utils.arg( 'action', metavar='<action>', choices=['set', 'unset'], help=_(""Actions: 'set' or 'unset'."")) @utils.arg( 'metadata', metavar='<key=value>', nargs='+', action='append', default=[], help=_('Extra_specs to set/unset (only key is necessary on unset).')) def do_flavor_key(cs, args): """"""Set or unset extra_spec for a flavor."""""" flavor = _find_flavor(cs, args.flavor) keypair = _extract_metadata(args) if args.action == 'set': flavor.set_keys(keypair) elif args.action == 'unset': flavor.unset_keys(keypair.keys()) @utils.arg( '--flavor', metavar='<flavor>', help=_(""Filter results by flavor name or ID."")) @utils.arg( '--tenant', metavar='<tenant_id>', help=_('Filter results by tenant ID.'), action=shell.DeprecatedAction, real_action='nothing', use=_('this option is not supported, and will be ' 'removed in version 5.0.0.')) def do_flavor_access_list(cs, args): """"""Print access information about the given flavor."""""" if args.flavor: flavor = _find_flavor(cs, args.flavor) if flavor.is_public: raise exceptions.CommandError(_(""Access list not available "" ""for public flavors."")) kwargs = {'flavor': flavor} else: raise exceptions.CommandError(_(""Unable to get all access lists. "" ""Specify --flavor"")) try: access_list = cs.flavor_access.list(**kwargs) except NotImplementedError as e: raise exceptions.CommandError(""%s"" % str(e)) columns = ['Flavor_ID', 'Tenant_ID'] utils.print_list(access_list, columns) @utils.arg( 'flavor', metavar='<flavor>', help=_(""Flavor name or ID to add access for the given tenant."")) @utils.arg( 'tenant', metavar='<tenant_id>', help=_('Tenant ID to add flavor access for.')) def do_flavor_access_add(cs, args): """"""Add flavor access for the given tenant."""""" flavor = _find_flavor(cs, args.flavor) access_list = cs.flavor_access.add_tenant_access(flavor, args.tenant) columns = ['Flavor_ID', 'Tenant_ID'] utils.print_list(access_list, columns) @utils.arg( 'flavor', metavar='<flavor>', help=_(""Flavor name or ID to remove access for the given tenant."")) @utils.arg( 'tenant', metavar='<tenant_id>', help=_('Tenant ID to remove flavor access for.')) def do_flavor_access_remove(cs, args): """"""Remove flavor access for the given tenant."""""" flavor = _find_flavor(cs, args.flavor) access_list = cs.flavor_access.remove_tenant_access(flavor, args.tenant) columns = ['Flavor_ID', 'Tenant_ID'] utils.print_list(access_list, columns) @utils.arg( 'project_id', metavar='<project_id>', help=_('The ID of the project.')) @deprecated_network def do_scrub(cs, args): """"""Delete networks and security groups associated with a project."""""" networks_list = cs.networks.list() networks_list = [network for network in networks_list if getattr(network, 'project_id', '') == args.project_id] search_opts = {'all_tenants': 1} groups = cs.security_groups.list(search_opts) groups = [group for group in groups if group.tenant_id == args.project_id] for network in networks_list: cs.networks.disassociate(network) for group in groups: cs.security_groups.delete(group) @utils.arg( '--fields', default=None, metavar='<fields>', help=_('Comma-separated list of fields to display. ' 'Use the show command to see which fields are available.')) @deprecated_network def do_network_list(cs, args): """"""Print a list of available networks."""""" network_list = cs.networks.list() columns = ['ID', 'Label', 'Cidr'] columns += _get_list_table_columns_and_formatters( args.fields, network_list, exclude_fields=(c.lower() for c in columns))[0] utils.print_list(network_list, columns) @utils.arg( 'network', metavar='<network>', help=_(""UUID or label of network."")) @deprecated_network def do_network_show(cs, args): """"""Show details about the given network."""""" network = utils.find_resource(cs.networks, args.network) utils.print_dict(network._info) @utils.arg( 'network', metavar='<network>', help=_(""UUID or label of network."")) @deprecated_network def do_network_delete(cs, args): """"""Delete network by label or id."""""" network = utils.find_resource(cs.networks, args.network) network.delete() @utils.arg( '--host-only', dest='host_only', metavar='<0|1>', nargs='?', type=int, const=1, default=0) @utils.arg( '--project-only', dest='project_only', metavar='<0|1>', nargs='?', type=int, const=1, default=0) @utils.arg( 'network', metavar='<network>', help=_(""UUID of network."")) @deprecated_network def do_network_disassociate(cs, args): """"""Disassociate host and/or project from the given network."""""" if args.host_only: cs.networks.disassociate(args.network, True, False) elif args.project_only: cs.networks.disassociate(args.network, False, True) else: cs.networks.disassociate(args.network, True, True) @utils.arg( 'network', metavar='<network>', help=_(""UUID of network."")) @utils.arg( 'host', metavar='<host>', help=_(""Name of host"")) @deprecated_network def do_network_associate_host(cs, args): """"""Associate host with network."""""" cs.networks.associate_host(args.network, args.host) @utils.arg( 'network', metavar='<network>', help=_(""UUID of network."")) @deprecated_network def do_network_associate_project(cs, args): """"""Associate project with network."""""" cs.networks.associate_project(args.network) def _filter_network_create_options(args): valid_args = ['label', 'cidr', 'vlan_start', 'vpn_start', 'cidr_v6', 'gateway', 'gateway_v6', 'bridge', 'bridge_interface', 'multi_host', 'dns1', 'dns2', 'uuid', 'fixed_cidr', 'project_id', 'priority', 'vlan', 'mtu', 'dhcp_server', 'allowed_start', 'allowed_end'] kwargs = {} for k, v in args.__dict__.items(): if k in valid_args and v is not None: kwargs[k] = v return kwargs @utils.arg( 'label', metavar='<network_label>', help=_(""Label for network"")) @utils.arg( '--fixed-range-v4', dest='cidr', metavar='<x.x.x.x/yy>', help=_(""IPv4 subnet (ex: 10.0.0.0/8)"")) @utils.arg( '--fixed-range-v6', dest=""cidr_v6"", help=_('IPv6 subnet (ex: fe80::/64')) @utils.arg( '--vlan', dest='vlan', type=int, metavar='<vlan id>', help=_(""The vlan ID to be assigned to the project."")) @utils.arg( '--vlan-start', dest='vlan_start', type=int, metavar='<vlan start>', help=_('First vlan ID to be assigned to the project. Subsequent vlan ' 'IDs will be assigned incrementally.')) @utils.arg( '--vpn', dest='vpn_start', type=int, metavar='<vpn start>', help=_(""vpn start"")) @utils.arg( '--gateway', dest=""gateway"", help=_('gateway')) @utils.arg( '--gateway-v6', dest=""gateway_v6"", help=_('IPv6 gateway')) @utils.arg( '--bridge', dest=""bridge"", metavar='<bridge>', help=_('VIFs on this network are connected to this bridge.')) @utils.arg( '--bridge-interface', dest=""bridge_interface"", metavar='<bridge interface>', help=_('The bridge is connected to this interface.')) @utils.arg( '--multi-host', dest=""multi_host"", metavar=""<'T'|'F'>"", help=_('Multi host')) @utils.arg( '--dns1', dest=""dns1"", metavar=""<DNS Address>"", help=_('First DNS.')) @utils.arg( '--dns2', dest=""dns2"", metavar=""<DNS Address>"", help=_('Second DNS.')) @utils.arg( '--uuid', dest=""uuid"", metavar=""<network uuid>"", help=_('Network UUID.')) @utils.arg( '--fixed-cidr', dest=""fixed_cidr"", metavar='<x.x.x.x/yy>', help=_('IPv4 subnet for fixed IPs (ex: 10.20.0.0/16).')) @utils.arg( '--project-id', dest=""project_id"", metavar=""<project id>"", help=_('Project ID.')) @utils.arg( '--priority', dest=""priority"", metavar=""<number>"", help=_('Network interface priority.')) @utils.arg( '--mtu', dest=""mtu"", type=int, help=_('MTU for network.')) @utils.arg( '--enable-dhcp', dest=""enable_dhcp"", metavar=""<'T'|'F'>"", help=_('Enable DHCP.')) @utils.arg( '--dhcp-server', dest=""dhcp_server"", help=_('DHCP-server address (defaults to gateway address)')) @utils.arg( '--share-address', dest=""share_address"", metavar=""<'T'|'F'>"", help=_('Share address')) @utils.arg( '--allowed-start', dest=""allowed_start"", help=_('Start of allowed addresses for instances.')) @utils.arg( '--allowed-end', dest=""allowed_end"", help=_('End of allowed addresses for instances.')) @deprecated_network def do_network_create(cs, args): """"""Create a network."""""" if not (args.cidr or args.cidr_v6): raise exceptions.CommandError( _(""Must specify either fixed_range_v4 or fixed_range_v6"")) kwargs = _filter_network_create_options(args) if args.multi_host is not None: kwargs['multi_host'] = bool(args.multi_host == 'T' or strutils.bool_from_string(args.multi_host)) if args.enable_dhcp is not None: kwargs['enable_dhcp'] = bool( args.enable_dhcp == 'T' or strutils.bool_from_string(args.enable_dhcp)) if args.share_address is not None: kwargs['share_address'] = bool( args.share_address == 'T' or strutils.bool_from_string(args.share_address)) cs.networks.create(**kwargs) @utils.arg( '--limit', dest=""limit"", metavar=""<limit>"", help=_('Number of images to return per request.')) def do_image_list(cs, _args): """"""DEPRECATED: Print a list of available images to boot from."""""" emit_image_deprecation_warning('image-list') limit = _args.limit image_list = cs.images.list(limit=limit) def parse_server_name(image): try: return image.server['id'] except (AttributeError, KeyError): return '' fmts = {'Server': parse_server_name} utils.print_list(image_list, ['ID', 'Name', 'Status', 'Server'], fmts, sortby_index=1) @utils.arg( 'image', metavar='<image>', help=_(""Name or ID of image."")) @utils.arg( 'action', metavar='<action>', choices=['set', 'delete'], help=_(""Actions: 'set' or 'delete'."")) @utils.arg( 'metadata', metavar='<key=value>', nargs='+', action='append', default=[], help=_('Metadata to add/update or delete (only key is necessary on ' 'delete).')) def do_image_meta(cs, args): """"""DEPRECATED: Set or delete metadata on an image."""""" emit_image_deprecation_warning('image-meta') image = _find_image(cs, args.image) metadata = _extract_metadata(args) if args.action == 'set': cs.images.set_meta(image, metadata) elif args.action == 'delete': cs.images.delete_meta(image, metadata.keys()) def _extract_metadata(args): metadata = {} for metadatum in args.metadata[0]: # Can only pass the key in on 'delete' # So this doesn't have to have '=' if metadatum.find('=') > -1: (key, value) = metadatum.split('=', 1) else: key = metadatum value = None metadata[key] = value return metadata def _print_image(image): info = image._info.copy() # ignore links, we don't need to present those info.pop('links', None) # try to replace a server entity to just an id server = info.pop('server', None) try: info['server'] = server['id'] except (KeyError, TypeError): pass # break up metadata and display each on its own row metadata = info.pop('metadata', {}) try: for key, value in metadata.items(): _key = 'metadata %s' % key info[_key] = value except AttributeError: pass utils.print_dict(info) def _print_flavor(flavor): info = flavor._info.copy() # ignore links, we don't need to present those info.pop('links') info.update({""extra_specs"": _print_flavor_extra_specs(flavor)}) utils.print_dict(info) @utils.arg( 'image', metavar='<image>', help=_(""Name or ID of image."")) def do_image_show(cs, args): """"""DEPRECATED: Show details about the given image."""""" emit_image_deprecation_warning('image-show') image = _find_image(cs, args.image) _print_image(image) @utils.arg( 'image', metavar='<image>', nargs='+', help=_('Name or ID of image(s).')) def do_image_delete(cs, args): """"""DEPRECATED: Delete specified image(s)."""""" emit_image_deprecation_warning('image-delete') for image in args.image: try: # _find_image is using the GlanceManager which doesn't implement # the delete() method so use the ImagesManager for that. image = _find_image(cs, image) cs.images.delete(image) except Exception as e: print(_(""Delete for image %(image)s failed: %(e)s"") % {'image': image, 'e': e}) @utils.arg( '--reservation-id', dest='reservation_id', metavar='<reservation-id>', default=None, help=_('Only return servers that match reservation-id.')) @utils.arg( '--ip', dest='ip', metavar='<ip-regexp>', default=None, help=_('Search with regular expression match by IP address.')) @utils.arg( '--ip6', dest='ip6', metavar='<ip6-regexp>', default=None, help=_('Search with regular expression match by IPv6 address.')) @utils.arg( '--name', dest='name', metavar='<name-regexp>', default=None, help=_('Search with regular expression match by name.')) @utils.arg( '--instance-name', dest='instance_name', metavar='<name-regexp>', default=None, help=_('Search with regular expression match by server name.')) @utils.arg( '--status', dest='status', metavar='<status>', default=None, help=_('Search by server status.')) @utils.arg( '--flavor', dest='flavor', metavar='<flavor>', default=None, help=_('Search by flavor name or ID.')) @utils.arg( '--image', dest='image', metavar='<image>', default=None, help=_('Search by image name or ID.')) @utils.arg( '--host', dest='host', metavar='<hostname>', default=None, help=_('Search servers by hostname to which they are assigned (Admin ' 'only).')) @utils.arg( '--all-tenants', dest='all_tenants', metavar='<0|1>', nargs='?', type=int, const=1, default=int(strutils.bool_from_string( os.environ.get(""ALL_TENANTS"", 'false'), True)), help=_('Display information from all tenants (Admin only).')) @utils.arg( '--tenant', # nova db searches by project_id dest='tenant', metavar='<tenant>', nargs='?', help=_('Display information from single tenant (Admin only).')) @utils.arg( '--user', dest='user', metavar='<user>', nargs='?', help=_('Display information from single user (Admin only).')) @utils.arg( '--deleted', dest='deleted', action=""store_true"", default=False, help=_('Only display deleted servers (Admin only).')) @utils.arg( '--fields', default=None, metavar='<fields>', help=_('Comma-separated list of fields to display. ' 'Use the show command to see which fields are available.')) @utils.arg( '--minimal', dest='minimal', action=""store_true"", default=False, help=_('Get only UUID and name.')) @utils.arg( '--sort', dest='sort', metavar='<key>[:<direction>]', help=_('Comma-separated list of sort keys and directions in the form ' 'of <key>[:<asc|desc>]. The direction defaults to descending if ' 'not specified.')) @utils.arg( '--marker', dest='marker', metavar='<marker>', default=None, help=_('The last server UUID of the previous page; displays list of ' 'servers after ""marker"".')) @utils.arg( '--limit', dest='limit', metavar='<limit>', type=int, default=None, help=_(""Maximum number of servers to display. If limit == -1, all servers "" ""will be displayed. If limit is bigger than 'osapi_max_limit' "" ""option of Nova API, limit 'osapi_max_limit' will be used "" ""instead."")) @utils.arg( '--changes-since', dest='changes_since', metavar='<changes_since>', default=None, help=_(""List only servers changed after a certain point of time."" ""The provided time should be an ISO 8061 formatted time."" ""ex 2016-03-04T06:27:59Z ."")) @utils.arg( '--tags', dest='tags', metavar='<tags>', default=None, help=_(""The given tags must all be present for a server to be included in "" ""the list result. Boolean expression in this case is 't1 AND t2'. "" ""Tags must be separated by commas: --tags <tag1,tag2>""), start_version=""2.26"") @utils.arg( '--tags-any', dest='tags-any', metavar='<tags-any>', default=None, help=_(""If one of the given tags is present the server will be included "" ""in the list result. Boolean expression in this case is "" ""'t1 OR t2'. Tags must be separated by commas: "" ""--tags-any <tag1,tag2>""), start_version=""2.26"") @utils.arg( '--not-tags', dest='not-tags', metavar='<not-tags>', default=None, help=_(""Only the servers that do not have any of the given tags will"" ""be included in the list results. Boolean expression in this case "" ""is 'NOT(t1 AND t2)'. Tags must be separated by commas: "" ""--not-tags <tag1,tag2>""), start_version=""2.26"") @utils.arg( '--not-tags-any', dest='not-tags-any', metavar='<not-tags-any>', default=None, help=_(""Only the servers that do not have at least one of the given tags"" ""will be included in the list result. Boolean expression in this "" ""case is 'NOT(t1 OR t2)'. Tags must be separated by commas: "" ""--not-tags-any <tag1,tag2>""), start_version=""2.26"") def do_list(cs, args): """"""List active servers."""""" imageid = None flavorid = None if args.image: imageid = _find_image(cs, args.image).id if args.flavor: flavorid = _find_flavor(cs, args.flavor).id # search by tenant or user only works with all_tenants if args.tenant or args.user: args.all_tenants = 1 search_opts = { 'all_tenants': args.all_tenants, 'reservation_id': args.reservation_id, 'ip': args.ip, 'ip6': args.ip6, 'name': args.name, 'image': imageid, 'flavor': flavorid, 'status': args.status, 'tenant_id': args.tenant, 'user_id': args.user, 'host': args.host, 'deleted': args.deleted, 'instance_name': args.instance_name, 'changes-since': args.changes_since} for arg in ('tags', ""tags-any"", 'not-tags', 'not-tags-any'): if arg in args: search_opts[arg] = getattr(args, arg) filters = {'flavor': lambda f: f['id'], 'security_groups': utils.format_security_groups} id_col = 'ID' detailed = not args.minimal sort_keys = [] sort_dirs = [] if args.sort: for sort in args.sort.split(','): sort_key, _sep, sort_dir = sort.partition(':') if not sort_dir: sort_dir = 'desc' elif sort_dir not in ('asc', 'desc'): raise exceptions.CommandError(_( 'Unknown sort direction: %s') % sort_dir) sort_keys.append(sort_key) sort_dirs.append(sort_dir) if search_opts['changes-since']: try: timeutils.parse_isotime(search_opts['changes-since']) except ValueError: raise exceptions.CommandError(_('Invalid changes-since value: %s') % search_opts['changes-since']) servers = cs.servers.list(detailed=detailed, search_opts=search_opts, sort_keys=sort_keys, sort_dirs=sort_dirs, marker=args.marker, limit=args.limit) convert = [('OS-EXT-SRV-ATTR:host', 'host'), ('OS-EXT-STS:task_state', 'task_state'), ('OS-EXT-SRV-ATTR:instance_name', 'instance_name'), ('OS-EXT-STS:power_state', 'power_state'), ('hostId', 'host_id')] _translate_keys(servers, convert) _translate_extended_states(servers) formatters = {} cols, fmts = _get_list_table_columns_and_formatters( args.fields, servers, exclude_fields=('id',), filters=filters) if args.minimal: columns = [ id_col, 'Name'] elif cols: columns = [id_col] + cols formatters.update(fmts) else: columns = [ id_col, 'Name', 'Status', 'Task State', 'Power State', 'Networks' ] # If getting the data for all tenants, print # Tenant ID as well if search_opts['all_tenants']: columns.insert(2, 'Tenant ID') if search_opts['changes-since']: columns.append('Updated') formatters['Networks'] = utils.format_servers_list_networks sortby_index = 1 if args.sort: sortby_index = None utils.print_list(servers, columns, formatters, sortby_index=sortby_index) def _get_list_table_columns_and_formatters(fields, objs, exclude_fields=(), filters=None): """"""Check and add fields to output columns. If there is any value in fields that not an attribute of obj, CommandError will be raised. If fields has duplicate values (case sensitive), we will make them unique and ignore duplicate ones. If exclude_fields is specified, any field both in fields and exclude_fields will be ignored. :param fields: A list of string contains the fields to be printed. :param objs: An list of object which will be used to check if field is valid or not. Note, we don't check fields if obj is None or empty. :param exclude_fields: A tuple of string which contains the fields to be excluded. :param filters: A dictionary defines how to get value from fields, this is useful when field's value is a complex object such as dictionary. :return: columns, formatters. columns is a list of string which will be used as table header. formatters is a dictionary specifies how to display the value of the field. They can be [], {}. :raise: novaclient.exceptions.CommandError """""" if not fields: return [], {} if not objs: obj = None elif isinstance(objs, list): obj = objs[0] else: obj = objs columns = [] formatters = {} non_existent_fields = [] exclude_fields = set(exclude_fields) for field in fields.split(','): if not hasattr(obj, field): non_existent_fields.append(field) continue if field in exclude_fields: continue field_title, formatter = utils.make_field_formatter(field, filters) columns.append(field_title) formatters[field_title] = formatter exclude_fields.add(field) if non_existent_fields: raise exceptions.CommandError( _(""Non-existent fields are specified: %s"") % non_existent_fields) return columns, formatters @utils.arg( '--hard', dest='reboot_type', action='store_const', const=servers.REBOOT_HARD, default=servers.REBOOT_SOFT, help=_('Perform a hard reboot (instead of a soft one). ' 'Note: Ironic does not currently support soft reboot; ' 'consequently, bare metal nodes will always do a hard ' 'reboot, regardless of the use of this option.')) @utils.arg( 'server', metavar='<server>', nargs='+', help=_('Name or ID of server(s).')) @utils.arg( '--poll', dest='poll', action=""store_true"", default=False, help=_('Poll until reboot is complete.')) def do_reboot(cs, args): """"""Reboot a server."""""" servers = [_find_server(cs, s) for s in args.server] utils.do_action_on_many( lambda s: s.reboot(args.reboot_type), servers, _(""Request to reboot server %s has been accepted.""), _(""Unable to reboot the specified server(s)."")) if args.poll: utils.do_action_on_many( lambda s: _poll_for_status(cs.servers.get, s.id, 'rebooting', ['active'], show_progress=False), servers, _(""Wait for server %s reboot.""), _(""Wait for specified server(s) failed."")) @utils.arg('server', metavar='<server>', help=_('Name or ID of server.')) @utils.arg('image', metavar='<image>', help=_(""Name or ID of new image."")) @utils.arg( '--rebuild-password', dest='rebuild_password', metavar='<rebuild-password>', default=False, help=_(""Set the provided admin password on the rebuilt server."")) @utils.arg( '--poll', dest='poll', action=""store_true"", default=False, help=_('Report the server rebuild progress until it completes.')) @utils.arg( '--minimal', dest='minimal', action=""store_true"", default=False, help=_('Skips flavor/image lookups when showing servers.')) @utils.arg( '--preserve-ephemeral', action=""store_true"", default=False, help=_('Preserve the default ephemeral storage partition on rebuild.')) @utils.arg( '--name', metavar='<name>', default=None, help=_('Name for the new server.')) @utils.arg( '--description', metavar='<description>', dest='description', default=None, help=_('New description for the server.'), start_version=""2.19"") @utils.arg( '--meta', metavar=""<key=value>"", action='append', default=[], help=_(""Record arbitrary key/value metadata to /meta_data.json "" ""on the metadata server. Can be specified multiple times."")) @utils.arg( '--file', metavar=""<dst-path=src-path>"", action='append', dest='files', default=[], help=_(""Store arbitrary files from <src-path> locally to <dst-path> "" ""on the new server. You may store up to 5 files."")) def do_rebuild(cs, args): """"""Shutdown, re-image, and re-boot a server."""""" server = _find_server(cs, args.server) image = _find_image(cs, args.image) if args.rebuild_password is not False: _password = args.rebuild_password else: _password = None kwargs = utils.get_resource_manager_extra_kwargs(do_rebuild, args) kwargs['preserve_ephemeral'] = args.preserve_ephemeral kwargs['name'] = args.name if 'description' in args: kwargs['description'] = args.description meta = _meta_parsing(args.meta) kwargs['meta'] = meta files = {} for f in args.files: try: dst, src = f.split('=', 1) with open(src, 'r') as s: files[dst] = s.read() except IOError as e: raise exceptions.CommandError(_(""Can't open '%(src)s': %(exc)s"") % {'src': src, 'exc': e}) except ValueError: raise exceptions.CommandError(_(""Invalid file argument '%s'. "" ""File arguments must be of the "" ""form '--file "" ""<dst-path=src-path>'"") % f) kwargs['files'] = files server = server.rebuild(image, _password, **kwargs) _print_server(cs, args, server) if args.poll: _poll_for_status(cs.servers.get, server.id, 'rebuilding', ['active']) @utils.arg( 'server', metavar='<server>', help=_('Name (old name) or ID of server.')) @utils.arg('name', metavar='<name>', help=_('New name for the server.')) def do_rename(cs, args): """"""DEPRECATED, use update instead."""""" do_update(cs, args) @utils.arg( 'server', metavar='<server>', help=_('Name (old name) or ID of server.')) @utils.arg( '--name', metavar='<name>', dest='name', default=None, help=_('New name for the server.')) @utils.arg( '--description', metavar='<description>', dest='description', default=None, help=_('New description for the server. If it equals to empty string ' '(i.g. """"), the server description will be removed.'), start_version=""2.19"") def do_update(cs, args): """"""Update the name or the description for a server."""""" update_kwargs = {} if args.name: update_kwargs[""name""] = args.name # NOTE(andreykurilin): `do_update` method is used by `do_rename` method, # which do not have description argument at all. When `do_rename` will be # removed after deprecation period, feel free to change the check below to: # `if args.description:` if ""description"" in args and args.description is not None: update_kwargs[""description""] = args.description _find_server(cs, args.server).update(**update_kwargs) @utils.arg('server', metavar='<server>', help=_('Name or ID of server.')) @utils.arg( 'flavor', metavar='<flavor>', help=_(""Name or ID of new flavor."")) @utils.arg( '--poll', dest='poll', action=""store_true"", default=False, help=_('Report the server resize progress until it completes.')) def do_resize(cs, args): """"""Resize a server."""""" server = _find_server(cs, args.server) flavor = _find_flavor(cs, args.flavor) kwargs = utils.get_resource_manager_extra_kwargs(do_resize, args) server.resize(flavor, **kwargs) if args.poll: _poll_for_status(cs.servers.get, server.id, 'resizing', ['active', 'verify_resize']) @utils.arg('server', metavar='<server>', help=_('Name or ID of server.')) def do_resize_confirm(cs, args): """"""Confirm a previous resize."""""" _find_server(cs, args.server).confirm_resize() @utils.arg('server', metavar='<server>', help=_('Name or ID of server.')) def do_resize_revert(cs, args): """"""Revert a previous resize (and return to the previous VM)."""""" _find_server(cs, args.server).revert_resize() @utils.arg('server', metavar='<server>', help=_('Name or ID of server.')) @utils.arg( '--poll', dest='poll', action=""store_true"", default=False, help=_('Report the server migration progress until it completes.')) def do_migrate(cs, args): """"""Migrate a server. The new host will be selected by the scheduler."""""" server = _find_server(cs, args.server) server.migrate() if args.poll: _poll_for_status(cs.servers.get, server.id, 'migrating', ['active', 'verify_resize']) @utils.arg('server', metavar='<server>', help=_('Name or ID of server.')) def do_pause(cs, args): """"""Pause a server."""""" _find_server(cs, args.server).pause() @utils.arg('server', metavar='<server>', help=_('Name or ID of server.')) def do_unpause(cs, args): """"""Unpause a server."""""" _find_server(cs, args.server).unpause() @utils.arg( '--all-tenants', action='store_const', const=1, default=0, help=_('Stop server(s) in another tenant by name (Admin only).')) @utils.arg( 'server', metavar='<server>', nargs='+', help=_('Name or ID of server(s).')) def do_stop(cs, args): """"""Stop the server(s)."""""" find_args = {'all_tenants': args.all_tenants} utils.do_action_on_many( lambda s: _find_server(cs, s, **find_args).stop(), args.server, _(""Request to stop server %s has been accepted.""), _(""Unable to stop the specified server(s)."")) @utils.arg( '--all-tenants', action='store_const', const=1, default=0, help=_('Start server(s) in another tenant by name (Admin only).')) @utils.arg( 'server', metavar='<server>', nargs='+', help=_('Name or ID of server(s).')) def do_start(cs, args): """"""Start the server(s)."""""" find_args = {'all_tenants': args.all_tenants} utils.do_action_on_many( lambda s: _find_server(cs, s, **find_args).start(), args.server, _(""Request to start server %s has been accepted.""), _(""Unable to start the specified server(s)."")) @utils.arg('server', metavar='<server>', help=_('Name or ID of server.')) def do_lock(cs, args): """"""Lock a server. A normal (non-admin) user will not be able to execute actions on a locked server. """""" _find_server(cs, args.server).lock() @utils.arg('server', metavar='<server>', help=_('Name or ID of server.')) def do_unlock(cs, args): """"""Unlock a server."""""" _find_server(cs, args.server).unlock() @utils.arg('server', metavar='<server>', help=_('Name or ID of server.')) def do_suspend(cs, args): """"""Suspend a server."""""" _find_server(cs, args.server).suspend() @utils.arg('server', metavar='<server>', help=_('Name or ID of server.')) def do_resume(cs, args): """"""Resume a server."""""" _find_server(cs, args.server).resume() @utils.arg('server', metavar='<server>', help=_('Name or ID of server.')) @utils.arg( '--password', metavar='<password>', dest='password', help=_('The admin password to be set in the rescue environment.')) @utils.arg( '--image', metavar='<image>', dest='image', help=_('The image to rescue with.')) def do_rescue(cs, args): """"""Reboots a server into rescue mode, which starts the machine from either the initial image or a specified image, attaching the current boot disk as secondary. """""" kwargs = {} if args.image: kwargs['image'] = _find_image(cs, args.image) if args.password: kwargs['password'] = args.password utils.print_dict(_find_server(cs, args.server).rescue(**kwargs)[1]) @utils.arg('server', metavar='<server>', help=_('Name or ID of server.')) def do_unrescue(cs, args): """"""Restart the server from normal boot disk again."""""" _find_server(cs, args.server).unrescue() @utils.arg('server', metavar='<server>', help=_('Name or ID of server.')) def do_shelve(cs, args): """"""Shelve a server."""""" _find_server(cs, args.server).shelve() @utils.arg('server', metavar='<server>', help=_('Name or ID of server.')) def do_shelve_offload(cs, args): """"""Remove a shelved server from the compute node."""""" _find_server(cs, args.server).shelve_offload() @utils.arg('server', metavar='<server>', help=_('Name or ID of server.')) def do_unshelve(cs, args): """"""Unshelve a server."""""" _find_server(cs, args.server).unshelve() @utils.arg('server', metavar='<server>', help=_('Name or ID of server.')) def do_diagnostics(cs, args): """"""Retrieve server diagnostics."""""" server = _find_server(cs, args.server) utils.print_dict(cs.servers.diagnostics(server)[1], wrap=80) @utils.arg( 'server', metavar='<server>', help=_('Name or ID of a server for which the network cache should ' 'be refreshed from neutron (Admin only).')) def do_refresh_network(cs, args): """"""Refresh server network information."""""" server = _find_server(cs, args.server) cs.server_external_events.create([{'server_uuid': server.id, 'name': 'network-changed'}]) @utils.arg('server', metavar='<server>', help=_('Name or ID of server.')) def do_root_password(cs, args): """"""DEPRECATED, use set-password instead."""""" do_set_password(cs, args) @utils.arg('server', metavar='<server>', help=_('Name or ID of server.')) def do_set_password(cs, args): """""" Change the admin password for a server. """""" server = _find_server(cs, args.server) p1 = getpass.getpass('New password: ') p2 = getpass.getpass('Again: ') if p1 != p2: raise exceptions.CommandError(_(""Passwords do not match."")) server.change_password(p1) @utils.arg('server', metavar='<server>', help=_('Name or ID of server.')) @utils.arg('name', metavar='<name>', help=_('Name of snapshot.')) @utils.arg( '--metadata', metavar=""<key=value>"", action='append', default=[], help=_(""Record arbitrary key/value metadata to /meta_data.json "" ""on the metadata server. Can be specified multiple times."")) @utils.arg( '--show', dest='show', action=""store_true"", default=False, help=_('Print image info.')) @utils.arg( '--poll', dest='poll', action=""store_true"", default=False, help=_('Report the snapshot progress and poll until image creation is ' 'complete.')) def do_image_create(cs, args): """"""Create a new image by taking a snapshot of a running server."""""" server = _find_server(cs, args.server) meta = _meta_parsing(args.metadata) or None image_uuid = cs.servers.create_image(server, args.name, meta) if args.poll: _poll_for_status(cs.glance.find_image, image_uuid, 'snapshotting', ['active']) # NOTE(sirp): A race-condition exists between when the image finishes # uploading and when the servers's `task_state` is cleared. To account # for this, we need to poll a second time to ensure the `task_state` is # cleared before returning, ensuring that a snapshot taken immediately # after this function returns will succeed. # # A better long-term solution will be to separate 'snapshotting' and # 'image-uploading' in Nova and clear the task-state once the VM # snapshot is complete but before the upload begins. task_state_field = ""OS-EXT-STS:task_state"" if hasattr(server, task_state_field): _poll_for_status(cs.servers.get, server.id, 'image_snapshot', [None], status_field=task_state_field, show_progress=False, silent=True) if args.show: _print_image(_find_image(cs, image_uuid)) @utils.arg('server', metavar='<server>', help=_('Name or ID of server.')) @utils.arg('name', metavar='<name>', help=_('Name of the backup image.')) @utils.arg( 'backup_type', metavar='<backup-type>', help=_('The backup type, like ""daily"" or ""weekly"".')) @utils.arg( 'rotation', metavar='<rotation>', help=_('Int parameter representing how many backups to keep ' 'around.')) def do_backup(cs, args): """"""Backup a server by creating a 'backup' type snapshot."""""" _find_server(cs, args.server).backup(args.name, args.backup_type, args.rotation) @utils.arg( 'server', metavar='<server>', help=_(""Name or ID of server."")) @utils.arg( 'action', metavar='<action>', choices=['set', 'delete'], help=_(""Actions: 'set' or 'delete'."")) @utils.arg( 'metadata', metavar='<key=value>', nargs='+', action='append', default=[], help=_('Metadata to set or delete (only key is necessary on delete).')) def do_meta(cs, args): """"""Set or delete metadata on a server."""""" server = _find_server(cs, args.server) metadata = _extract_metadata(args) if args.action == 'set': cs.servers.set_meta(server, metadata) elif args.action == 'delete': cs.servers.delete_meta(server, sorted(metadata.keys(), reverse=True)) def _print_server(cs, args, server=None): # By default when searching via name we will do a # findall(name=blah) and due a REST /details which is not the same # as a .get() and doesn't get the information about flavors and # images. This fix it as we redo the call with the id which does a # .get() to get all information. if not server: server = _find_server(cs, args.server) minimal = getattr(args, ""minimal"", False) networks = server.networks info = server._info.copy() for network_label, address_list in networks.items(): info['%s network' % network_label] = ', '.join(address_list) flavor = info.get('flavor', {}) flavor_id = flavor.get('id', '') if minimal: info['flavor'] = flavor_id else: try: info['flavor'] = '%s (%s)' % (_find_flavor(cs, flavor_id).name, flavor_id) except Exception: info['flavor'] = '%s (%s)' % (_(""Flavor not found""), flavor_id) if 'security_groups' in info: # when we have multiple nics the info will include the # security groups N times where N == number of nics. Be nice # and only display it once. info['security_groups'] = ', '.join( sorted(set(group['name'] for group in info['security_groups']))) image = info.get('image', {}) if image: image_id = image.get('id', '') if minimal: info['image'] = image_id else: try: info['image'] = '%s (%s)' % (_find_image(cs, image_id).name, image_id) except Exception: info['image'] = '%s (%s)' % (_(""Image not found""), image_id) else: # Booted from volume info['image'] = _(""Attempt to boot from volume - no image supplied"") info.pop('links', None) info.pop('addresses', None) utils.print_dict(info) @utils.arg( '--minimal', dest='minimal', action=""store_true"", default=False, help=_('Skips flavor/image lookups when showing servers.')) @utils.arg('server', metavar='<server>', help=_('Name or ID of server.')) def do_show(cs, args): """"""Show details about the given server."""""" _print_server(cs, args) @utils.arg( '--all-tenants', action='store_const', const=1, default=0, help=_('Delete server(s) in another tenant by name (Admin only).')) @utils.arg( 'server', metavar='<server>', nargs='+', help=_('Name or ID of server(s).')) def do_delete(cs, args): """"""Immediately shut down and delete specified server(s)."""""" find_args = {'all_tenants': args.all_tenants} utils.do_action_on_many( lambda s: _find_server(cs, s, **find_args).delete(), args.server, _(""Request to delete server %s has been accepted.""), _(""Unable to delete the specified server(s)."")) def _find_server(cs, server, raise_if_notfound=True, **find_args): """"""Get a server by name or ID. :param cs: NovaClient's instance :param server: identifier of server :param raise_if_notfound: raise an exception if server is not found :param find_args: argument to search server """""" if raise_if_notfound: return utils.find_resource(cs.servers, server, **find_args) else: try: return utils.find_resource(cs.servers, server, wrap_exception=False) except exceptions.NoUniqueMatch as e: raise exceptions.CommandError(six.text_type(e)) except exceptions.NotFound: # The server can be deleted return server def _find_image(cs, image): """"""Get an image by name or ID."""""" try: return cs.glance.find_image(image) except (exceptions.NotFound, exceptions.NoUniqueMatch) as e: raise exceptions.CommandError(six.text_type(e)) def _find_flavor(cs, flavor): """"""Get a flavor by name, ID, or RAM size."""""" try: return utils.find_resource(cs.flavors, flavor, is_public=None) except exceptions.NotFound: return cs.flavors.find(ram=flavor) def _find_network_id_neutron(cs, net_name): """"""Get unique network ID from network name from neutron"""""" try: return cs.neutron.find_network(net_name).id except (exceptions.NotFound, exceptions.NoUniqueMatch) as e: raise exceptions.CommandError(six.text_type(e)) def _find_network_id(cs, net_name): """"""Find the network id for a network name. If we have access to neutron in the service catalog, use neutron for this lookup, otherwise use nova. This ensures that we do the right thing in the future. Once nova network support is deleted, we can delete this check and the has_neutron function. """""" if cs.has_neutron(): return _find_network_id_neutron(cs, net_name) else: # The network proxy API methods were deprecated in 2.36 and will return # a 404 so we fallback to 2.35 to maintain a transition for CLI users. want_version = api_versions.APIVersion('2.35') cur_version = cs.api_version if cs.api_version > want_version: cs.api_version = want_version try: return _find_network_id_novanet(cs, net_name) finally: cs.api_version = cur_version def _find_network_id_novanet(cs, net_name): """"""Get unique network ID from network name."""""" network_id = None for net_info in cs.networks.list(): if net_name == net_info.label: if network_id is not None: msg = (_(""Multiple network name matches found for name '%s', "" ""use network ID to be more specific."") % net_name) raise exceptions.NoUniqueMatch(msg) else: network_id = net_info.id if network_id is None: msg = (_(""No network name match for name '%s'"") % net_name) raise exceptions.ResourceNotFound(msg % {'network': net_name}) else: return network_id @utils.arg('server', metavar='<server>', help=_('Name or ID of server.')) @utils.arg( 'network_id', metavar='<network-id>', help=_('Network ID.')) def do_add_fixed_ip(cs, args): """"""Add new IP address on a network to server."""""" server = _find_server(cs, args.server) server.add_fixed_ip(args.network_id) @utils.arg('server', metavar='<server>', help=_('Name or ID of server.')) @utils.arg('address', metavar='<address>', help=_('IP Address.')) def do_remove_fixed_ip(cs, args): """"""Remove an IP address from a server."""""" server = _find_server(cs, args.server) server.remove_fixed_ip(args.address) def _find_volume(cs, volume): """"""Get a volume by name or ID."""""" return utils.find_resource(cs.volumes, volume) def _find_volume_snapshot(cs, snapshot): """"""Get a volume snapshot by name or ID."""""" return utils.find_resource(cs.volume_snapshots, snapshot) def _print_volume(volume): utils.print_dict(volume._info) def _print_volume_snapshot(snapshot): utils.print_dict(snapshot._info) def _translate_volume_keys(collection): _translate_keys(collection, [('displayName', 'display_name'), ('volumeType', 'volume_type')]) def _translate_volume_snapshot_keys(collection): _translate_keys(collection, [('displayName', 'display_name'), ('volumeId', 'volume_id')]) def _translate_availability_zone_keys(collection): _translate_keys(collection, [('zoneName', 'name'), ('zoneState', 'status')]) def _translate_volume_attachments_keys(collection): _translate_keys(collection, [('serverId', 'server_id'), ('volumeId', 'volume_id')]) @utils.arg( 'server', metavar='<server>', help=_('Name or ID of server.')) @utils.arg( 'volume', metavar='<volume>', help=_('ID of the volume to attach.')) @utils.arg( 'device', metavar='<device>', default=None, nargs='?', help=_('Name of the device e.g. /dev/vdb. ' 'Use ""auto"" for autoassign (if supported). ' 'Libvirt driver will use default device name.')) def do_volume_attach(cs, args): """"""Attach a volume to a server."""""" if args.device == 'auto': args.device = None volume = cs.volumes.create_server_volume(_find_server(cs, args.server).id, args.volume, args.device) _print_volume(volume) @utils.arg( 'server', metavar='<server>', help=_('Name or ID of server.')) @utils.arg( 'attachment_id', metavar='<attachment>', help=_('Attachment ID of the volume.')) @utils.arg( 'new_volume', metavar='<volume>', help=_('ID of the volume to attach.')) def do_volume_update(cs, args): """"""Update volume attachment."""""" cs.volumes.update_server_volume(_find_server(cs, args.server).id, args.attachment_id, args.new_volume) @utils.arg( 'server', metavar='<server>', help=_('Name or ID of server.')) @utils.arg( 'attachment_id', metavar='<volume>', help=_('ID of the volume to detach.')) def do_volume_detach(cs, args): """"""Detach a volume from a server."""""" cs.volumes.delete_server_volume(_find_server(cs, args.server).id, args.attachment_id) @utils.arg( 'server', metavar='<server>', help=_('Name or ID of server.')) def do_volume_attachments(cs, args): """"""List all the volumes attached to a server."""""" volumes = cs.volumes.get_server_volumes(_find_server(cs, args.server).id) _translate_volume_attachments_keys(volumes) utils.print_list(volumes, ['ID', 'DEVICE', 'SERVER ID', 'VOLUME ID']) @api_versions.wraps('2.0', '2.5') def console_dict_accessor(cs, data): return data['console'] @api_versions.wraps('2.6') def console_dict_accessor(cs, data): return data['remote_console'] class Console(object): def __init__(self, console_dict): self.type = console_dict['type'] self.url = console_dict['url'] def print_console(cs, data): utils.print_list([Console(console_dict_accessor(cs, data))], ['Type', 'Url']) @utils.arg('server', metavar='<server>', help=_('Name or ID of server.')) @utils.arg( 'console_type', metavar='<console-type>', help=_('Type of vnc console (""novnc"" or ""xvpvnc"").')) def do_get_vnc_console(cs, args): """"""Get a vnc console to a server."""""" server = _find_server(cs, args.server) data = server.get_vnc_console(args.console_type) print_console(cs, data) @utils.arg('server', metavar='<server>', help=_('Name or ID of server.')) @utils.arg( 'console_type', metavar='<console-type>', help=_('Type of spice console (""spice-html5"").')) def do_get_spice_console(cs, args): """"""Get a spice console to a server."""""" server = _find_server(cs, args.server) data = server.get_spice_console(args.console_type) print_console(cs, data) @utils.arg('server', metavar='<server>', help=_('Name or ID of server.')) @utils.arg( 'console_type', metavar='<console-type>', help=_('Type of rdp console (""rdp-html5"").')) def do_get_rdp_console(cs, args): """"""Get a rdp console to a server."""""" server = _find_server(cs, args.server) data = server.get_rdp_console(args.console_type) print_console(cs, data) @utils.arg('server', metavar='<server>', help=_('Name or ID of server.')) @utils.arg( '--console-type', default='serial', help=_('Type of serial console, default=""serial"".')) def do_get_serial_console(cs, args): """"""Get a serial console to a server."""""" if args.console_type not in ('serial',): raise exceptions.CommandError( _(""Invalid parameter value for 'console_type', "" ""currently supported 'serial'."")) server = _find_server(cs, args.server) data = server.get_serial_console(args.console_type) print_console(cs, data) @api_versions.wraps('2.8') @utils.arg('server', metavar='<server>', help=_('Name or ID of server.')) def do_get_mks_console(cs, args): """"""Get an MKS console to a server."""""" server = _find_server(cs, args.server) data = server.get_mks_console() print_console(cs, data) @utils.arg('server', metavar='<server>', help=_('Name or ID of server.')) @utils.arg( 'private_key', metavar='<private-key>', help=_('Private key (used locally to decrypt password) (Optional). ' 'When specified, the command displays the clear (decrypted) VM ' 'password. When not specified, the ciphered VM password is ' 'displayed.'), nargs='?', default=None) def do_get_password(cs, args): """"""Get the admin password for a server. This operation calls the metadata service to query metadata information and does not read password information from the server itself. """""" server = _find_server(cs, args.server) data = server.get_password(args.private_key) print(data) @utils.arg('server', metavar='<server>', help=_('Name or ID of server.')) def do_clear_password(cs, args): """"""Clear the admin password for a server from the metadata server. This action does not actually change the instance server password. """""" server = _find_server(cs, args.server) server.clear_password() def _print_floating_ip_list(floating_ips): convert = [('instance_id', 'server_id')] _translate_keys(floating_ips, convert) utils.print_list(floating_ips, ['Id', 'IP', 'Server Id', 'Fixed IP', 'Pool']) @utils.arg('server', metavar='<server>', help=_('Name or ID of server.')) @utils.arg( '--length', metavar='<length>', default=None, help=_('Length in lines to tail.')) def do_console_log(cs, args): """"""Get console log output of a server."""""" server = _find_server(cs, args.server) data = server.get_console_output(length=args.length) print(data) @utils.arg('server', metavar='<server>', help=_('Name or ID of server.')) @utils.arg('address', metavar='<address>', help=_('IP Address.')) @utils.arg( '--fixed-address', metavar='<fixed_address>', default=None, help=_('Fixed IP Address to associate with.')) def do_add_floating_ip(cs, args): """"""DEPRECATED, use floating-ip-associate instead."""""" _associate_floating_ip(cs, args) @utils.arg('server', metavar='<server>', help=_('Name or ID of server.')) @utils.arg('address', metavar='<address>', help=_('IP Address.')) @utils.arg( '--fixed-address', metavar='<fixed_address>', default=None, help=_('Fixed IP Address to associate with.')) def do_floating_ip_associate(cs, args): """"""Associate a floating IP address to a server."""""" _associate_floating_ip(cs, args) def _associate_floating_ip(cs, args): server = _find_server(cs, args.server) server.add_floating_ip(args.address, args.fixed_address) @utils.arg('server', metavar='<server>', help=_('Name or ID of server.')) @utils.arg('address', metavar='<address>', help=_('IP Address.')) def do_remove_floating_ip(cs, args): """"""DEPRECATED, use floating-ip-disassociate instead."""""" _disassociate_floating_ip(cs, args) @utils.arg('server', metavar='<server>', help=_('Name or ID of server.')) @utils.arg('address', metavar='<address>', help=_('IP Address.')) def do_floating_ip_disassociate(cs, args): """"""Disassociate a floating IP address from a server."""""" _disassociate_floating_ip(cs, args) def _disassociate_floating_ip(cs, args): server = _find_server(cs, args.server) server.remove_floating_ip(args.address) @utils.arg('server', metavar='<server>', help=_('Name or ID of server.')) @utils.arg( 'secgroup', metavar='<secgroup>', help=_('Name or ID of Security Group.')) def do_add_secgroup(cs, args): """"""Add a Security Group to a server."""""" server = _find_server(cs, args.server) server.add_security_group(args.secgroup) @utils.arg('server', metavar='<server>', help=_('Name or ID of server.')) @utils.arg( 'secgroup', metavar='<secgroup>', help=_('Name of Security Group.')) def do_remove_secgroup(cs, args): """"""Remove a Security Group from a server."""""" server = _find_server(cs, args.server) server.remove_security_group(args.secgroup) @utils.arg('server', metavar='<server>', help=_('Name or ID of server.')) def do_list_secgroup(cs, args): """"""List Security Group(s) of a server."""""" server = _find_server(cs, args.server) groups = server.list_security_group() _print_secgroups(groups) @utils.arg( 'pool', metavar='<floating-ip-pool>', help=_('Name of Floating IP Pool. (Optional)'), nargs='?', default=None) @deprecated_network def do_floating_ip_create(cs, args): """"""Allocate a floating IP for the current tenant."""""" _print_floating_ip_list([cs.floating_ips.create(pool=args.pool)]) @utils.arg('address', metavar='<address>', help=_('IP of Floating IP.')) @deprecated_network def do_floating_ip_delete(cs, args): """"""De-allocate a floating IP."""""" floating_ips = cs.floating_ips.list() for floating_ip in floating_ips: if floating_ip.ip == args.address: return cs.floating_ips.delete(floating_ip.id) raise exceptions.CommandError(_(""Floating IP %s not found."") % args.address) @deprecated_network def do_floating_ip_list(cs, _args): """"""List floating IPs."""""" _print_floating_ip_list(cs.floating_ips.list()) @deprecated_network def do_floating_ip_pool_list(cs, _args): """"""List all floating IP pools."""""" utils.print_list(cs.floating_ip_pools.list(), ['name']) @utils.arg( '--host', dest='host', metavar='<host>', default=None, help=_('Filter by host.')) @deprecated_network def do_floating_ip_bulk_list(cs, args): """"""List all floating IPs (nova-network only)."""""" utils.print_list(cs.floating_ips_bulk.list(args.host), ['project_id', 'address', 'instance_uuid', 'pool', 'interface']) @utils.arg('ip_range', metavar='<range>', help=_('Address range to create.')) @utils.arg( '--pool', dest='pool', metavar='<pool>', default=None, help=_('Pool for new Floating IPs.')) @utils.arg( '--interface', metavar='<interface>', default=None, help=_('Interface for new Floating IPs.')) @deprecated_network def do_floating_ip_bulk_create(cs, args): """"""Bulk create floating IPs by range (nova-network only)."""""" cs.floating_ips_bulk.create(args.ip_range, args.pool, args.interface) @utils.arg('ip_range', metavar='<range>', help=_('Address range to delete.')) @deprecated_network def do_floating_ip_bulk_delete(cs, args): """"""Bulk delete floating IPs by range (nova-network only)."""""" cs.floating_ips_bulk.delete(args.ip_range) def _print_dns_list(dns_entries): utils.print_list(dns_entries, ['ip', 'name', 'domain']) def _print_domain_list(domain_entries): utils.print_list(domain_entries, ['domain', 'scope', 'project', 'availability_zone']) @deprecated_network def do_dns_domains(cs, args): """"""Print a list of available dns domains."""""" domains = cs.dns_domains.domains() _print_domain_list(domains) @utils.arg('domain', metavar='<domain>', help=_('DNS domain.')) @utils.arg('--ip', metavar='<ip>', help=_('IP address.'), default=None) @utils.arg('--name', metavar='<name>', help=_('DNS name.'), default=None) @deprecated_network def do_dns_list(cs, args): """"""List current DNS entries for domain and IP or domain and name."""""" if not (args.ip or args.name): raise exceptions.CommandError( _(""You must specify either --ip or --name"")) if args.name: entry = cs.dns_entries.get(args.domain, args.name) _print_dns_list([entry]) else: entries = cs.dns_entries.get_for_ip(args.domain, ip=args.ip) _print_dns_list(entries) @utils.arg('ip', metavar='<ip>', help=_('IP address.')) @utils.arg('name', metavar='<name>', help=_('DNS name.')) @utils.arg('domain', metavar='<domain>', help=_('DNS domain.')) @utils.arg( '--type', metavar='<type>', help=_('DNS type (e.g. ""A"")'), default='A') @deprecated_network def do_dns_create(cs, args): """"""Create a DNS entry for domain, name, and IP."""""" cs.dns_entries.create(args.domain, args.name, args.ip, args.type) @utils.arg('domain', metavar='<domain>', help=_('DNS domain.')) @utils.arg('name', metavar='<name>', help=_('DNS name.')) @deprecated_network def do_dns_delete(cs, args): """"""Delete the specified DNS entry."""""" cs.dns_entries.delete(args.domain, args.name) @utils.arg('domain', metavar='<domain>', help=_('DNS domain.')) @deprecated_network def do_dns_delete_domain(cs, args): """"""Delete the specified DNS domain."""""" cs.dns_domains.delete(args.domain) @utils.arg('domain', metavar='<domain>', help=_('DNS domain.')) @utils.arg( '--availability-zone', metavar='<availability-zone>', default=None, help=_('Limit access to this domain to servers ' 'in the specified availability zone.')) @deprecated_network def do_dns_create_private_domain(cs, args): """"""Create the specified DNS domain."""""" cs.dns_domains.create_private(args.domain, args.availability_zone) @utils.arg('domain', metavar='<domain>', help=_('DNS domain.')) @utils.arg( '--project', metavar='<project>', help=_('Limit access to this domain to users ' 'of the specified project.'), default=None) @deprecated_network def do_dns_create_public_domain(cs, args): """"""Create the specified DNS domain."""""" cs.dns_domains.create_public(args.domain, args.project) def _print_secgroup_rules(rules, show_source_group=True): class FormattedRule(object): def __init__(self, obj): items = (obj if isinstance(obj, dict) else obj._info).items() for k, v in items: if k == 'ip_range': v = v.get('cidr') elif k == 'group': k = 'source_group' v = v.get('name') if v is None: v = '' setattr(self, k, v) rules = [FormattedRule(rule) for rule in rules] headers = ['IP Protocol', 'From Port', 'To Port', 'IP Range'] if show_source_group: headers.append('Source Group') utils.print_list(rules, headers) def _print_secgroups(secgroups): utils.print_list(secgroups, ['Id', 'Name', 'Description']) def _get_secgroup(cs, secgroup): # Check secgroup is an ID (nova-network) or UUID (neutron) if (utils.is_integer_like(encodeutils.safe_encode(secgroup)) or uuidutils.is_uuid_like(secgroup)): try: return cs.security_groups.get(secgroup) except exceptions.NotFound: pass # Check secgroup as a name match_found = False for s in cs.security_groups.list(): encoding = ( locale.getpreferredencoding() or sys.stdin.encoding or 'UTF-8') if not six.PY3: s.name = s.name.encode(encoding) if secgroup == s.name: if match_found is not False: msg = (_(""Multiple security group matches found for name '%s'"" "", use an ID to be more specific."") % secgroup) raise exceptions.NoUniqueMatch(msg) match_found = s if match_found is False: raise exceptions.CommandError(_(""Secgroup ID or name '%s' not found."") % secgroup) return match_found @utils.arg( 'secgroup', metavar='<secgroup>', help=_('ID or name of security group.')) @utils.arg( 'ip_proto', metavar='<ip-proto>', help=_('IP protocol (icmp, tcp, udp).')) @utils.arg( 'from_port', metavar='<from-port>', help=_('Port at start of range.')) @utils.arg( 'to_port', metavar='<to-port>', help=_('Port at end of range.')) @utils.arg('cidr', metavar='<cidr>', help=_('CIDR for address range.')) @deprecated_network def do_secgroup_add_rule(cs, args): """"""Add a rule to a security group."""""" secgroup = _get_secgroup(cs, args.secgroup) rule = cs.security_group_rules.create(secgroup.id, args.ip_proto, args.from_port, args.to_port, args.cidr) _print_secgroup_rules([rule]) @utils.arg( 'secgroup', metavar='<secgroup>', help=_('ID or name of security group.')) @utils.arg( 'ip_proto', metavar='<ip-proto>', help=_('IP protocol (icmp, tcp, udp).')) @utils.arg( 'from_port', metavar='<from-port>', help=_('Port at start of range.')) @utils.arg( 'to_port', metavar='<to-port>', help=_('Port at end of range.')) @utils.arg('cidr', metavar='<cidr>', help=_('CIDR for address range.')) @deprecated_network def do_secgroup_delete_rule(cs, args): """"""Delete a rule from a security group."""""" secgroup = _get_secgroup(cs, args.secgroup) for rule in secgroup.rules: if (rule['ip_protocol'] and rule['ip_protocol'].upper() == args.ip_proto.upper() and rule['from_port'] == int(args.from_port) and rule['to_port'] == int(args.to_port) and rule['ip_range']['cidr'] == args.cidr): _print_secgroup_rules([rule]) return cs.security_group_rules.delete(rule['id']) raise exceptions.CommandError(_(""Rule not found"")) @utils.arg('name', metavar='<name>', help=_('Name of security group.')) @utils.arg( 'description', metavar='<description>', help=_('Description of security group.')) @deprecated_network def do_secgroup_create(cs, args): """"""Create a security group."""""" secgroup = cs.security_groups.create(args.name, args.description) _print_secgroups([secgroup]) @utils.arg( 'secgroup', metavar='<secgroup>', help=_('ID or name of security group.')) @utils.arg('name', metavar='<name>', help=_('Name of security group.')) @utils.arg( 'description', metavar='<description>', help=_('Description of security group.')) @deprecated_network def do_secgroup_update(cs, args): """"""Update a security group."""""" sg = _get_secgroup(cs, args.secgroup) secgroup = cs.security_groups.update(sg, args.name, args.description) _print_secgroups([secgroup]) @utils.arg( 'secgroup', metavar='<secgroup>', help=_('ID or name of security group.')) @deprecated_network def do_secgroup_delete(cs, args): """"""Delete a security group."""""" secgroup = _get_secgroup(cs, args.secgroup) cs.security_groups.delete(secgroup) _print_secgroups([secgroup]) @utils.arg( '--all-tenants', dest='all_tenants', metavar='<0|1>', nargs='?', type=int, const=1, default=int(strutils.bool_from_string( os.environ.get(""ALL_TENANTS"", 'false'), True)), help=_('Display information from all tenants (Admin only).')) @deprecated_network def do_secgroup_list(cs, args): """"""List security groups for the current tenant."""""" search_opts = {'all_tenants': args.all_tenants} columns = ['Id', 'Name', 'Description'] if args.all_tenants: columns.append('Tenant_ID') groups = cs.security_groups.list(search_opts=search_opts) utils.print_list(groups, columns) @utils.arg( 'secgroup', metavar='<secgroup>', help=_('ID or name of security group.')) @deprecated_network def do_secgroup_list_rules(cs, args): """"""List rules for a security group."""""" secgroup = _get_secgroup(cs, args.secgroup) _print_secgroup_rules(secgroup.rules) @utils.arg( 'secgroup', metavar='<secgroup>', help=_('ID or name of security group.')) @utils.arg( 'source_group', metavar='<source-group>', help=_('ID or name of source group.')) @utils.arg( 'ip_proto', metavar='<ip-proto>', help=_('IP protocol (icmp, tcp, udp).')) @utils.arg( 'from_port', metavar='<from-port>', help=_('Port at start of range.')) @utils.arg( 'to_port', metavar='<to-port>', help=_('Port at end of range.')) @deprecated_network def do_secgroup_add_group_rule(cs, args): """"""Add a source group rule to a security group."""""" secgroup = _get_secgroup(cs, args.secgroup) source_group = _get_secgroup(cs, args.source_group) params = {'group_id': source_group.id} if args.ip_proto or args.from_port or args.to_port: if not (args.ip_proto and args.from_port and args.to_port): raise exceptions.CommandError(_(""ip_proto, from_port, and to_port"" "" must be specified together"")) params['ip_protocol'] = args.ip_proto.upper() params['from_port'] = args.from_port params['to_port'] = args.to_port rule = cs.security_group_rules.create(secgroup.id, **params) _print_secgroup_rules([rule]) @utils.arg( 'secgroup', metavar='<secgroup>', help=_('ID or name of security group.')) @utils.arg( 'source_group', metavar='<source-group>', help=_('ID or name of source group.')) @utils.arg( 'ip_proto', metavar='<ip-proto>', help=_('IP protocol (icmp, tcp, udp).')) @utils.arg( 'from_port', metavar='<from-port>', help=_('Port at start of range.')) @utils.arg( 'to_port', metavar='<to-port>', help=_('Port at end of range.')) @deprecated_network def do_secgroup_delete_group_rule(cs, args): """"""Delete a source group rule from a security group."""""" secgroup = _get_secgroup(cs, args.secgroup) source_group = _get_secgroup(cs, args.source_group) params = {'group_name': source_group.name} if args.ip_proto or args.from_port or args.to_port: if not (args.ip_proto and args.from_port and args.to_port): raise exceptions.CommandError(_(""ip_proto, from_port, and to_port"" "" must be specified together"")) params['ip_protocol'] = args.ip_proto.upper() params['from_port'] = int(args.from_port) params['to_port'] = int(args.to_port) for rule in secgroup.rules: if (rule.get('ip_protocol') and rule['ip_protocol'].upper() == params.get( 'ip_protocol').upper() and rule.get('from_port') == params.get('from_port') and rule.get('to_port') == params.get('to_port') and rule.get('group', {}).get('name') == params.get('group_name')): return cs.security_group_rules.delete(rule['id']) raise exceptions.CommandError(_(""Rule not found"")) @api_versions.wraps(""2.0"", ""2.1"") def _keypair_create(cs, args, name, pub_key): return cs.keypairs.create(name, pub_key) @api_versions.wraps(""2.2"", ""2.9"") def _keypair_create(cs, args, name, pub_key): return cs.keypairs.create(name, pub_key, key_type=args.key_type) @api_versions.wraps(""2.10"") def _keypair_create(cs, args, name, pub_key): return cs.keypairs.create(name, pub_key, key_type=args.key_type, user_id=args.user) @utils.arg('name', metavar='<name>', help=_('Name of key.')) @utils.arg( '--pub-key', metavar='<pub-key>', default=None, help=_('Path to a public ssh key.')) @utils.arg( '--key-type', metavar='<key-type>', default='ssh', help=_('Keypair type. Can be ssh or x509.'), start_version=""2.2"") @utils.arg( '--user', metavar='<user-id>', default=None, help=_('ID of user to whom to add key-pair (Admin only).'), start_version=""2.10"") def do_keypair_add(cs, args): """"""Create a new key pair for use with servers."""""" name = args.name pub_key = args.pub_key if pub_key: if pub_key == '-': pub_key = sys.stdin.read() else: try: with open(os.path.expanduser(pub_key)) as f: pub_key = f.read() except IOError as e: raise exceptions.CommandError( _(""Can't open or read '%(key)s': %(exc)s"") % {'key': pub_key, 'exc': e} ) keypair = _keypair_create(cs, args, name, pub_key) if not pub_key: private_key = keypair.private_key print(private_key) @api_versions.wraps(""2.0"", ""2.9"") @utils.arg('name', metavar='<name>', help=_('Keypair name to delete.')) def do_keypair_delete(cs, args): """"""Delete keypair given by its name."""""" name = _find_keypair(cs, args.name) cs.keypairs.delete(name) @api_versions.wraps(""2.10"") @utils.arg('name', metavar='<name>', help=_('Keypair name to delete.')) @utils.arg( '--user', metavar='<user-id>', default=None, help=_('ID of key-pair owner (Admin only).')) def do_keypair_delete(cs, args): """"""Delete keypair given by its name."""""" cs.keypairs.delete(args.name, args.user) @api_versions.wraps(""2.0"", ""2.1"") def _get_keypairs_list_columns(cs, args): return ['Name', 'Fingerprint'] @api_versions.wraps(""2.2"") def _get_keypairs_list_columns(cs, args): return ['Name', 'Type', 'Fingerprint'] @api_versions.wraps(""2.0"", ""2.9"") def do_keypair_list(cs, args): """"""Print a list of keypairs for a user"""""" keypairs = cs.keypairs.list() columns = _get_keypairs_list_columns(cs, args) utils.print_list(keypairs, columns) @api_versions.wraps(""2.10"", ""2.34"") @utils.arg( '--user', metavar='<user-id>', default=None, help=_('List key-pairs of specified user ID (Admin only).')) def do_keypair_list(cs, args): """"""Print a list of keypairs for a user"""""" keypairs = cs.keypairs.list(args.user) columns = _get_keypairs_list_columns(cs, args) utils.print_list(keypairs, columns) @api_versions.wraps(""2.35"") @utils.arg( '--user', metavar='<user-id>', default=None, help=_('List key-pairs of specified user ID (Admin only).')) @utils.arg( '--marker', dest='marker', metavar='<marker>', default=None, help=_('The last keypair of the previous page; displays list of keypairs ' 'after ""marker"".')) @utils.arg( '--limit', dest='limit', metavar='<limit>', type=int, default=None, help=_(""Maximum number of keypairs to display. If limit == -1, all "" ""keypairs will be displayed. If limit is bigger than "" ""'osapi_max_limit' option of Nova API, limit 'osapi_max_limit' "" ""will be used instead."")) def do_keypair_list(cs, args): """"""Print a list of keypairs for a user"""""" keypairs = cs.keypairs.list(args.user, args.marker, args.limit) columns = _get_keypairs_list_columns(cs, args) utils.print_list(keypairs, columns) def _print_keypair(keypair): kp = keypair._info.copy() pk = kp.pop('public_key') utils.print_dict(kp) print(_(""Public key: %s"") % pk) @api_versions.wraps(""2.0"", ""2.9"") @utils.arg( 'keypair', metavar='<keypair>', help=_(""Name of keypair."")) def do_keypair_show(cs, args): """"""Show details about the given keypair."""""" keypair = _find_keypair(cs, args.keypair) _print_keypair(keypair) @api_versions.wraps(""2.10"") @utils.arg( 'keypair', metavar='<keypair>', help=_(""Name of keypair."")) @utils.arg( '--user', metavar='<user-id>', default=None, help=_('ID of key-pair owner (Admin only).')) def do_keypair_show(cs, args): """"""Show details about the given keypair."""""" keypair = cs.keypairs.get(args.keypair, args.user) _print_keypair(keypair) def _find_keypair(cs, keypair): """"""Get a keypair by name."""""" return utils.find_resource(cs.keypairs, keypair) @utils.arg( '--tenant', # nova db searches by project_id dest='tenant', metavar='<tenant>', nargs='?', help=_('Display information from single tenant (Admin only).')) @utils.arg( '--reserved', dest='reserved', action='store_true', default=False, help=_('Include reservations count.')) def do_absolute_limits(cs, args): """"""DEPRECATED, use limits instead."""""" limits = cs.limits.get(args.reserved, args.tenant).absolute _print_absolute_limits(limits) def _print_absolute_limits(limits): """"""Prints absolute limits."""""" class Limit(object): def __init__(self, name, used, max, other): self.name = name self.used = used self.max = max self.other = other limit_map = { 'maxServerMeta': {'name': 'Server Meta', 'type': 'max'}, 'maxPersonality': {'name': 'Personality', 'type': 'max'}, 'maxPersonalitySize': {'name': 'Personality Size', 'type': 'max'}, 'maxImageMeta': {'name': 'ImageMeta', 'type': 'max'}, 'maxTotalKeypairs': {'name': 'Keypairs', 'type': 'max'}, 'totalCoresUsed': {'name': 'Cores', 'type': 'used'}, 'maxTotalCores': {'name': 'Cores', 'type': 'max'}, 'totalRAMUsed': {'name': 'RAM', 'type': 'used'}, 'maxTotalRAMSize': {'name': 'RAM', 'type': 'max'}, 'totalInstancesUsed': {'name': 'Instances', 'type': 'used'}, 'maxTotalInstances': {'name': 'Instances', 'type': 'max'}, 'totalFloatingIpsUsed': {'name': 'FloatingIps', 'type': 'used'}, 'maxTotalFloatingIps': {'name': 'FloatingIps', 'type': 'max'}, 'totalSecurityGroupsUsed': {'name': 'SecurityGroups', 'type': 'used'}, 'maxSecurityGroups': {'name': 'SecurityGroups', 'type': 'max'}, 'maxSecurityGroupRules': {'name': 'SecurityGroupRules', 'type': 'max'}, 'maxServerGroups': {'name': 'ServerGroups', 'type': 'max'}, 'totalServerGroupsUsed': {'name': 'ServerGroups', 'type': 'used'}, 'maxServerGroupMembers': {'name': 'ServerGroupMembers', 'type': 'max'}, } max = {} used = {} other = {} limit_names = [] columns = ['Name', 'Used', 'Max'] for l in limits: map = limit_map.get(l.name, {'name': l.name, 'type': 'other'}) name = map['name'] if map['type'] == 'max': max[name] = l.value elif map['type'] == 'used': used[name] = l.value else: other[name] = l.value columns.append('Other') if name not in limit_names: limit_names.append(name) limit_names.sort() limit_list = [] for name in limit_names: l = Limit(name, used.get(name, ""-""), max.get(name, ""-""), other.get(name, ""-"")) limit_list.append(l) utils.print_list(limit_list, columns) def do_rate_limits(cs, args): """"""DEPRECATED, use limits instead."""""" limits = cs.limits.get().rate _print_rate_limits(limits) def _print_rate_limits(limits): """"""print rate limits."""""" columns = ['Verb', 'URI', 'Value', 'Remain', 'Unit', 'Next_Available'] utils.print_list(limits, columns) @utils.arg( '--tenant', # nova db searches by project_id dest='tenant', metavar='<tenant>', nargs='?', help=_('Display information from single tenant (Admin only).')) @utils.arg( '--reserved', dest='reserved', action='store_true', default=False, help=_('Include reservations count.')) def do_limits(cs, args): """"""Print rate and absolute limits."""""" limits = cs.limits.get(args.reserved, args.tenant) _print_rate_limits(limits.rate) _print_absolute_limits(limits.absolute) @utils.arg( '--start', metavar='<start>', help=_('Usage range start date ex 2012-01-20. (default: 4 weeks ago)'), default=None) @utils.arg( '--end', metavar='<end>', help=_('Usage range end date, ex 2012-01-20. (default: tomorrow)'), default=None) def do_usage_list(cs, args): """"""List usage data for all tenants."""""" dateformat = ""%Y-%m-%d"" rows = [""Tenant ID"", ""Servers"", ""RAM MB-Hours"", ""CPU Hours"", ""Disk GB-Hours""] now = timeutils.utcnow() if args.start: start = datetime.datetime.strptime(args.start, dateformat) else: start = now - datetime.timedelta(weeks=4) if args.end: end = datetime.datetime.strptime(args.end, dateformat) else: end = now + datetime.timedelta(days=1) def simplify_usage(u): simplerows = [x.lower().replace("" "", ""_"") for x in rows] setattr(u, simplerows[0], u.tenant_id) setattr(u, simplerows[1], ""%d"" % len(u.server_usages)) setattr(u, simplerows[2], ""%.2f"" % u.total_memory_mb_usage) setattr(u, simplerows[3], ""%.2f"" % u.total_vcpus_usage) setattr(u, simplerows[4], ""%.2f"" % u.total_local_gb_usage) usage_list = cs.usage.list(start, end, detailed=True) print(_(""Usage from %(start)s to %(end)s:"") % {'start': start.strftime(dateformat), 'end': end.strftime(dateformat)}) for usage in usage_list: simplify_usage(usage) utils.print_list(usage_list, rows) @utils.arg( '--start', metavar='<start>', help=_('Usage range start date ex 2012-01-20. (default: 4 weeks ago)'), default=None) @utils.arg( '--end', metavar='<end>', help=_('Usage range end date, ex 2012-01-20. (default: tomorrow)'), default=None) @utils.arg( '--tenant', metavar='<tenant-id>', default=None, help=_('UUID of tenant to get usage for.')) def do_usage(cs, args): """"""Show usage data for a single tenant."""""" dateformat = ""%Y-%m-%d"" rows = [""Servers"", ""RAM MB-Hours"", ""CPU Hours"", ""Disk GB-Hours""] now = timeutils.utcnow() if args.start: start = datetime.datetime.strptime(args.start, dateformat) else: start = now - datetime.timedelta(weeks=4) if args.end: end = datetime.datetime.strptime(args.end, dateformat) else: end = now + datetime.timedelta(days=1) def simplify_usage(u): simplerows = [x.lower().replace("" "", ""_"") for x in rows] setattr(u, simplerows[0], ""%d"" % len(u.server_usages)) setattr(u, simplerows[1], ""%.2f"" % u.total_memory_mb_usage) setattr(u, simplerows[2], ""%.2f"" % u.total_vcpus_usage) setattr(u, simplerows[3], ""%.2f"" % u.total_local_gb_usage) if args.tenant: usage = cs.usage.get(args.tenant, start, end) else: if isinstance(cs.client, client.SessionClient): auth = cs.client.auth project_id = auth.get_auth_ref(cs.client.session).project_id usage = cs.usage.get(project_id, start, end) else: usage = cs.usage.get(cs.client.tenant_id, start, end) print(_(""Usage from %(start)s to %(end)s:"") % {'start': start.strftime(dateformat), 'end': end.strftime(dateformat)}) if getattr(usage, 'total_vcpus_usage', None): simplify_usage(usage) utils.print_list([usage], rows) else: print(_('None')) @utils.arg( 'pk_filename', metavar='<private-key-filename>', nargs='?', default='pk.pem', help=_('Filename for the private key. [Default: pk.pem]')) @utils.arg( 'cert_filename', metavar='<x509-cert-filename>', nargs='?', default='cert.pem', help=_('Filename for the X.509 certificate. [Default: cert.pem]')) def do_x509_create_cert(cs, args): """"""Create x509 cert for a user in tenant."""""" if os.path.exists(args.pk_filename): raise exceptions.CommandError(_(""Unable to write privatekey - %s "" ""exists."") % args.pk_filename) if os.path.exists(args.cert_filename): raise exceptions.CommandError(_(""Unable to write x509 cert - %s "" ""exists."") % args.cert_filename) certs = cs.certs.create() try: old_umask = os.umask(0o377) with open(args.pk_filename, 'w') as private_key: private_key.write(certs.private_key) print(_(""Wrote private key to %s"") % args.pk_filename) finally: os.umask(old_umask) with open(args.cert_filename, 'w') as cert: cert.write(certs.data) print(_(""Wrote x509 certificate to %s"") % args.cert_filename) @utils.arg( 'filename', metavar='<filename>', nargs='?', default='cacert.pem', help=_('Filename to write the x509 root cert.')) def do_x509_get_root_cert(cs, args): """"""Fetch the x509 root cert."""""" if os.path.exists(args.filename): raise exceptions.CommandError(_(""Unable to write x509 root cert - \ %s exists."") % args.filename) with open(args.filename, 'w') as cert: cacert = cs.certs.get() cert.write(cacert.data) print(_(""Wrote x509 root cert to %s"") % args.filename) @utils.arg( '--hypervisor', metavar='<hypervisor>', default=None, help=_('Type of hypervisor.')) def do_agent_list(cs, args): """"""List all builds."""""" result = cs.agents.list(args.hypervisor) columns = [""Agent_id"", ""Hypervisor"", ""OS"", ""Architecture"", ""Version"", 'Md5hash', 'Url'] utils.print_list(result, columns) @utils.arg('os', metavar='<os>', help=_('Type of OS.')) @utils.arg( 'architecture', metavar='<architecture>', help=_('Type of architecture.')) @utils.arg('version', metavar='<version>', help=_('Version.')) @utils.arg('url', metavar='<url>', help=_('URL.')) @utils.arg('md5hash', metavar='<md5hash>', help=_('MD5 hash.')) @utils.arg( 'hypervisor', metavar='<hypervisor>', default='xen', help=_('Type of hypervisor.')) def do_agent_create(cs, args): """"""Create new agent build."""""" result = cs.agents.create(args.os, args.architecture, args.version, args.url, args.md5hash, args.hypervisor) utils.print_dict(result._info.copy()) @utils.arg('id', metavar='<id>', help=_('ID of the agent-build.')) def do_agent_delete(cs, args): """"""Delete existing agent build."""""" cs.agents.delete(args.id) @utils.arg('id', metavar='<id>', help=_('ID of the agent-build.')) @utils.arg('version', metavar='<version>', help=_('Version.')) @utils.arg('url', metavar='<url>', help=_('URL')) @utils.arg('md5hash', metavar='<md5hash>', help=_('MD5 hash.')) def do_agent_modify(cs, args): """"""Modify existing agent build."""""" result = cs.agents.update(args.id, args.version, args.url, args.md5hash) utils.print_dict(result._info) def _find_aggregate(cs, aggregate): """"""Get an aggregate by name or ID."""""" return utils.find_resource(cs.aggregates, aggregate) def do_aggregate_list(cs, args): """"""Print a list of all aggregates."""""" aggregates = cs.aggregates.list() columns = ['Id', 'Name', 'Availability Zone'] utils.print_list(aggregates, columns) @utils.arg('name', metavar='<name>', help=_('Name of aggregate.')) @utils.arg( 'availability_zone', metavar='<availability-zone>', default=None, nargs='?', help=_('The availability zone of the aggregate (optional).')) def do_aggregate_create(cs, args): """"""Create a new aggregate with the specified details."""""" aggregate = cs.aggregates.create(args.name, args.availability_zone) _print_aggregate_details(aggregate) @utils.arg( 'aggregate', metavar='<aggregate>', help=_('Name or ID of aggregate to delete.')) def do_aggregate_delete(cs, args): """"""Delete the aggregate."""""" aggregate = _find_aggregate(cs, args.aggregate) cs.aggregates.delete(aggregate) print(_(""Aggregate %s has been successfully deleted."") % aggregate.id) @utils.arg( 'aggregate', metavar='<aggregate>', help=_('Name or ID of aggregate to update.')) @utils.arg( 'name', nargs='?', action=shell.DeprecatedAction, use=_('use ""%s""; this option will be removed in ' 'novaclient 5.0.0.') % '--name', help=argparse.SUPPRESS) @utils.arg( '--name', dest='name', help=_('Name of aggregate.')) @utils.arg( 'availability_zone', metavar='<availability-zone>', nargs='?', default=None, action=shell.DeprecatedAction, use=_('use ""%s""; this option will be removed in ' 'novaclient 5.0.0.') % '--availability_zone', help=argparse.SUPPRESS) @utils.arg( '--availability-zone', metavar='<availability-zone>', dest='availability_zone', help=_('The availability zone of the aggregate.')) def do_aggregate_update(cs, args): """"""Update the aggregate's name and optionally availability zone."""""" aggregate = _find_aggregate(cs, args.aggregate) updates = {} if args.name: updates[""name""] = args.name if args.availability_zone: updates[""availability_zone""] = args.availability_zone aggregate = cs.aggregates.update(aggregate.id, updates) print(_(""Aggregate %s has been successfully updated."") % aggregate.id) _print_aggregate_details(aggregate) @utils.arg( 'aggregate', metavar='<aggregate>', help=_('Name or ID of aggregate to update.')) @utils.arg( 'metadata', metavar='<key=value>', nargs='+', action='append', default=[], help=_('Metadata to add/update to aggregate. ' 'Specify only the key to delete a metadata item.')) def do_aggregate_set_metadata(cs, args): """"""Update the metadata associated with the aggregate."""""" aggregate = _find_aggregate(cs, args.aggregate) metadata = _extract_metadata(args) currentmetadata = getattr(aggregate, 'metadata', {}) if set(metadata.items()) & set(currentmetadata.items()): raise exceptions.CommandError(_(""metadata already exists"")) for key, value in metadata.items(): if value is None and key not in currentmetadata: raise exceptions.CommandError(_(""metadata key %s does not exist"" "" hence can not be deleted"") % key) aggregate = cs.aggregates.set_metadata(aggregate.id, metadata) print(_(""Metadata has been successfully updated for aggregate %s."") % aggregate.id) _print_aggregate_details(aggregate) @utils.arg( 'aggregate', metavar='<aggregate>', help=_('Name or ID of aggregate.')) @utils.arg( 'host', metavar='<host>', help=_('The host to add to the aggregate.')) def do_aggregate_add_host(cs, args): """"""Add the host to the specified aggregate."""""" aggregate = _find_aggregate(cs, args.aggregate) aggregate = cs.aggregates.add_host(aggregate.id, args.host) print(_(""Host %(host)s has been successfully added for aggregate "" ""%(aggregate_id)s "") % {'host': args.host, 'aggregate_id': aggregate.id}) _print_aggregate_details(aggregate) @utils.arg( 'aggregate', metavar='<aggregate>', help=_('Name or ID of aggregate.')) @utils.arg( 'host', metavar='<host>', help=_('The host to remove from the aggregate.')) def do_aggregate_remove_host(cs, args): """"""Remove the specified host from the specified aggregate."""""" aggregate = _find_aggregate(cs, args.aggregate) aggregate = cs.aggregates.remove_host(aggregate.id, args.host) print(_(""Host %(host)s has been successfully removed from aggregate "" ""%(aggregate_id)s "") % {'host': args.host, 'aggregate_id': aggregate.id}) _print_aggregate_details(aggregate) @utils.arg( 'aggregate', metavar='<aggregate>', help=_('Name or ID of aggregate.')) def do_aggregate_details(cs, args): """"""DEPRECATED, use aggregate-show instead."""""" do_aggregate_show(cs, args) @utils.arg( 'aggregate', metavar='<aggregate>', help=_('Name or ID of aggregate.')) def do_aggregate_show(cs, args): """"""Show details of the specified aggregate."""""" aggregate = _find_aggregate(cs, args.aggregate) _print_aggregate_details(aggregate) def _print_aggregate_details(aggregate): columns = ['Id', 'Name', 'Availability Zone', 'Hosts', 'Metadata'] def parser_metadata(fields): return utils.pretty_choice_dict(getattr(fields, 'metadata', {}) or {}) def parser_hosts(fields): return utils.pretty_choice_list(getattr(fields, 'hosts', [])) formatters = { 'Metadata': parser_metadata, 'Hosts': parser_hosts, } utils.print_list([aggregate], columns, formatters=formatters) @utils.arg('server', metavar='<server>', help=_('Name or ID of server.')) @utils.arg( 'host', metavar='<host>', default=None, nargs='?', help=_('Destination host name.')) @utils.arg( '--block-migrate', action='store_true', dest='block_migrate', default=False, help=_('True in case of block_migration. (Default=False:live_migration)'), start_version=""2.0"", end_version=""2.24"") @utils.arg( '--block-migrate', action='store_true', dest='block_migrate', default=""auto"", help=_('True in case of block_migration. (Default=auto:live_migration)'), start_version=""2.25"") @utils.arg( '--disk-over-commit', action='store_true', dest='disk_over_commit', default=False, help=_('Allow overcommit. (Default=False)'), start_version=""2.0"", end_version=""2.24"") @utils.arg( '--force', dest='force', action='store_true', default=False, help=_('Force to not verify the scheduler if a host is provided.'), start_version='2.30') def do_live_migration(cs, args): """"""Migrate running server to a new machine."""""" update_kwargs = {} if 'disk_over_commit' in args: update_kwargs['disk_over_commit'] = args.disk_over_commit if 'force' in args and args.force: update_kwargs['force'] = args.force _find_server(cs, args.server).live_migrate(args.host, args.block_migrate, **update_kwargs) @api_versions.wraps(""2.22"") @utils.arg('server', metavar='<server>', help=_('Name or ID of server.')) @utils.arg('migration', metavar='<migration>', help=_('ID of migration.')) def do_live_migration_force_complete(cs, args): """"""Force on-going live migration to complete."""""" server = _find_server(cs, args.server) cs.server_migrations.live_migrate_force_complete(server, args.migration) @api_versions.wraps(""2.23"") @utils.arg('server', metavar='<server>', help=_('Name or ID of server.')) def do_server_migration_list(cs, args): """"""Get the migrations list of specified server."""""" server = _find_server(cs, args.server) migrations = cs.server_migrations.list(server) fields = ['Id', 'Source Node', 'Dest Node', 'Source Compute', 'Dest Compute', 'Dest Host', 'Status', 'Server UUID', 'Created At', 'Updated At'] format_name = [""Total Memory Bytes"", ""Processed Memory Bytes"", ""Remaining Memory Bytes"", ""Total Disk Bytes"", ""Processed Disk Bytes"", ""Remaining Disk Bytes""] format_key = [""memory_total_bytes"", ""memory_processed_bytes"", ""memory_remaining_bytes"", ""disk_total_bytes"", ""disk_processed_bytes"", ""disk_remaining_bytes""] formatters = map(lambda field: utils.make_field_formatter(field)[1], format_key) formatters = dict(zip(format_name, formatters)) utils.print_list(migrations, fields + format_name, formatters) @api_versions.wraps(""2.23"") @utils.arg('server', metavar='<server>', help=_('Name or ID of server.')) @utils.arg('migration', metavar='<migration>', help=_('ID of migration.')) def do_server_migration_show(cs, args): """"""Get the migration of specified server."""""" server = _find_server(cs, args.server) migration = cs.server_migrations.get(server, args.migration) utils.print_dict(migration._info) @api_versions.wraps(""2.24"") @utils.arg('server', metavar='<server>', help=_('Name or ID of server.')) @utils.arg('migration', metavar='<migration>', help=_('ID of migration.')) def do_live_migration_abort(cs, args): """"""Abort an on-going live migration."""""" server = _find_server(cs, args.server) cs.server_migrations.live_migration_abort(server, args.migration) @utils.arg( '--all-tenants', action='store_const', const=1, default=0, help=_('Reset state server(s) in another tenant by name (Admin only).')) @utils.arg( 'server', metavar='<server>', nargs='+', help=_('Name or ID of server(s).')) @utils.arg( '--active', action='store_const', dest='state', default='error', const='active', help=_('Request the server be reset to ""active"" state instead ' 'of ""error"" state (the default).')) def do_reset_state(cs, args): """"""Reset the state of a server."""""" failure_flag = False find_args = {'all_tenants': args.all_tenants} for server in args.server: try: _find_server(cs, server, **find_args).reset_state(args.state) msg = ""Reset state for server %s succeeded; new state is %s"" print(msg % (server, args.state)) except Exception as e: failure_flag = True msg = ""Reset state for server %s failed: %s"" % (server, e) print(msg) if failure_flag: msg = ""Unable to reset the state for the specified server(s)."" raise exceptions.CommandError(msg) @utils.arg('server', metavar='<server>', help=_('Name or ID of server.')) def do_reset_network(cs, args): """"""Reset network of a server."""""" _find_server(cs, args.server).reset_network() @utils.arg( '--host', metavar='<hostname>', default=None, help=_('Name of host.')) @utils.arg( '--binary', metavar='<binary>', default=None, help=_('Service binary.')) def do_service_list(cs, args): """"""Show a list of all running services. Filter by host & binary."""""" result = cs.services.list(host=args.host, binary=args.binary) columns = [""Binary"", ""Host"", ""Zone"", ""Status"", ""State"", ""Updated_at""] # NOTE(sulo): we check if the response has disabled_reason # so as not to add the column when the extended ext is not enabled. if result and hasattr(result[0], 'disabled_reason'): columns.append(""Disabled Reason"") # NOTE(gtt): After https://review.openstack.org/#/c/39998/ nova will # show id in response. if result and hasattr(result[0], 'id'): columns.insert(0, ""Id"") utils.print_list(result, columns) @utils.arg('host', metavar='<hostname>', help=_('Name of host.')) @utils.arg('binary', metavar='<binary>', help=_('Service binary.')) def do_service_enable(cs, args): """"""Enable the service."""""" result = cs.services.enable(args.host, args.binary) utils.print_list([result], ['Host', 'Binary', 'Status']) @utils.arg('host', metavar='<hostname>', help=_('Name of host.')) @utils.arg('binary', metavar='<binary>', help=_('Service binary.')) @utils.arg( '--reason', metavar='<reason>', help=_('Reason for disabling service.')) def do_service_disable(cs, args): """"""Disable the service."""""" if args.reason: result = cs.services.disable_log_reason(args.host, args.binary, args.reason) utils.print_list([result], ['Host', 'Binary', 'Status', 'Disabled Reason']) else: result = cs.services.disable(args.host, args.binary) utils.print_list([result], ['Host', 'Binary', 'Status']) @api_versions.wraps(""2.11"") @utils.arg('host', metavar='<hostname>', help=_('Name of host.')) @utils.arg('binary', metavar='<binary>', help=_('Service binary.')) @utils.arg( '--unset', dest='force_down', help=_(""Unset the force state down of service.""), action='store_false', default=True) def do_service_force_down(cs, args): """"""Force service to down."""""" result = cs.services.force_down(args.host, args.binary, args.force_down) utils.print_list([result], ['Host', 'Binary', 'Forced down']) @utils.arg('id', metavar='<id>', help=_('ID of service.')) def do_service_delete(cs, args): """"""Delete the service."""""" cs.services.delete(args.id) @api_versions.wraps(""2.0"", ""2.3"") def _print_fixed_ip(cs, fixed_ip): fields = ['address', 'cidr', 'hostname', 'host'] utils.print_list([fixed_ip], fields) @api_versions.wraps(""2.4"") def _print_fixed_ip(cs, fixed_ip): fields = ['address', 'cidr', 'hostname', 'host', 'reserved'] utils.print_list([fixed_ip], fields) @utils.arg('fixed_ip', metavar='<fixed_ip>', help=_('Fixed IP Address.')) @deprecated_network def do_fixed_ip_get(cs, args): """"""Retrieve info on a fixed IP."""""" result = cs.fixed_ips.get(args.fixed_ip) _print_fixed_ip(cs, result) @utils.arg('fixed_ip', metavar='<fixed_ip>', help=_('Fixed IP Address.')) @deprecated_network def do_fixed_ip_reserve(cs, args): """"""Reserve a fixed IP."""""" cs.fixed_ips.reserve(args.fixed_ip) @utils.arg('fixed_ip', metavar='<fixed_ip>', help=_('Fixed IP Address.')) @deprecated_network def do_fixed_ip_unreserve(cs, args): """"""Unreserve a fixed IP."""""" cs.fixed_ips.unreserve(args.fixed_ip) @utils.arg('host', metavar='<hostname>', help=_('Name of host.')) def do_host_describe(cs, args): """"""Describe a specific host."""""" result = cs.hosts.get(args.host) columns = [""HOST"", ""PROJECT"", ""cpu"", ""memory_mb"", ""disk_gb""] utils.print_list(result, columns) @utils.arg( '--zone', metavar='<zone>', default=None, help=_('Filters the list, returning only those hosts in the availability ' 'zone <zone>.')) def do_host_list(cs, args): """"""List all hosts by service."""""" columns = [""host_name"", ""service"", ""zone""] result = cs.hosts.list(args.zone) utils.print_list(result, columns) @utils.arg('host', metavar='<hostname>', help=_('Name of host.')) @utils.arg( '--status', metavar='<enable|disable>', default=None, dest='status', help=_('Either enable or disable a host.')) @utils.arg( '--maintenance', metavar='<enable|disable>', default=None, dest='maintenance', help=_('Either put or resume host to/from maintenance.')) def do_host_update(cs, args): """"""Update host settings."""""" updates = {} columns = [""HOST""] if args.status: updates['status'] = args.status columns.append(""status"") if args.maintenance: updates['maintenance_mode'] = args.maintenance columns.append(""maintenance_mode"") result = cs.hosts.update(args.host, updates) utils.print_list([result], columns) @utils.arg('host', metavar='<hostname>', help=_('Name of host.')) @utils.arg( '--action', metavar='<action>', dest='action', choices=['startup', 'shutdown', 'reboot'], help=_('A power action: startup, reboot, or shutdown.')) def do_host_action(cs, args): """"""Perform a power action on a host."""""" result = cs.hosts.host_action(args.host, args.action) utils.print_list([result], ['HOST', 'power_action']) def _find_hypervisor(cs, hypervisor): """"""Get a hypervisor by name or ID."""""" return utils.find_resource(cs.hypervisors, hypervisor) def _do_hypervisor_list(cs, matching=None, limit=None, marker=None): columns = ['ID', 'Hypervisor hostname', 'State', 'Status'] if matching: utils.print_list(cs.hypervisors.search(matching), columns) else: params = {} if limit is not None: params['limit'] = limit if marker is not None: params['marker'] = marker # Since we're not outputting detail data, choose # detailed=False for server-side efficiency utils.print_list(cs.hypervisors.list(False, **params), columns) @api_versions.wraps(""2.0"", ""2.32"") @utils.arg( '--matching', metavar='<hostname>', default=None, help=_('List hypervisors matching the given <hostname>.')) def do_hypervisor_list(cs, args): """"""List hypervisors."""""" _do_hypervisor_list(cs, matching=args.matching) @api_versions.wraps(""2.33"") @utils.arg( '--matching', metavar='<hostname>', default=None, help=_('List hypervisors matching the given <hostname>. ' 'If matching is used limit and marker options will be ignored.')) @utils.arg( '--marker', dest='marker', metavar='<marker>', default=None, help=_('The last hypervisor of the previous page; displays list of ' 'hypervisors after ""marker"".')) @utils.arg( '--limit', dest='limit', metavar='<limit>', type=int, default=None, help=_(""Maximum number of hypervisors to display. If limit == -1, all "" ""hypervisors will be displayed. If limit is bigger than "" ""'osapi_max_limit' option of Nova API, limit 'osapi_max_limit' "" ""will be used instead."")) def do_hypervisor_list(cs, args): """"""List hypervisors."""""" _do_hypervisor_list( cs, matching=args.matching, limit=args.limit, marker=args.marker) @utils.arg( 'hostname', metavar='<hostname>', help=_('The hypervisor hostname (or pattern) to search for.')) def do_hypervisor_servers(cs, args): """"""List servers belonging to specific hypervisors."""""" hypers = cs.hypervisors.search(args.hostname, servers=True) class InstanceOnHyper(object): def __init__(self, **kwargs): self.__dict__.update(kwargs) # Massage the result into a list to be displayed instances = [] for hyper in hypers: hyper_host = hyper.hypervisor_hostname hyper_id = hyper.id if hasattr(hyper, 'servers'): instances.extend([InstanceOnHyper(id=serv['uuid'], name=serv['name'], hypervisor_hostname=hyper_host, hypervisor_id=hyper_id) for serv in hyper.servers]) # Output the data utils.print_list(instances, ['ID', 'Name', 'Hypervisor ID', 'Hypervisor Hostname']) @utils.arg( 'hypervisor', metavar='<hypervisor>', help=_('Name or ID of the hypervisor to show the details of.')) @utils.arg( '--wrap', dest='wrap', metavar='<integer>', default=40, help=_('Wrap the output to a specified length. ' 'Default is 40 or 0 to disable')) def do_hypervisor_show(cs, args): """"""Display the details of the specified hypervisor."""""" hyper = _find_hypervisor(cs, args.hypervisor) utils.print_dict(utils.flatten_dict(hyper._info), wrap=int(args.wrap)) @utils.arg( 'hypervisor', metavar='<hypervisor>', help=_('Name or ID of the hypervisor to show the uptime of.')) def do_hypervisor_uptime(cs, args): """"""Display the uptime of the specified hypervisor."""""" hyper = _find_hypervisor(cs, args.hypervisor) hyper = cs.hypervisors.uptime(hyper) # Output the uptime information utils.print_dict(hyper._info.copy()) def do_hypervisor_stats(cs, args): """"""Get hypervisor statistics over all compute nodes."""""" stats = cs.hypervisor_stats.statistics() utils.print_dict(stats._info.copy()) def ensure_service_catalog_present(cs): if not hasattr(cs.client, 'service_catalog'): # Turn off token caching and re-auth cs.client.unauthenticate() cs.client.use_token_cache(False) cs.client.authenticate() def do_endpoints(cs, _args): """"""Discover endpoints that get returned from the authenticate services."""""" warnings.warn( ""nova endpoints is deprecated, use openstack catalog list instead"") if isinstance(cs.client, client.SessionClient): access = cs.client.auth.get_access(cs.client.session) for service in access.service_catalog.catalog: _print_endpoints(service, cs.client.region_name) else: ensure_service_catalog_present(cs) catalog = cs.client.service_catalog.catalog region = cs.client.region_name for service in catalog['access']['serviceCatalog']: _print_endpoints(service, region) def _print_endpoints(service, region): name, endpoints = service[""name""], service[""endpoints""] try: endpoint = _get_first_endpoint(endpoints, region) utils.print_dict(endpoint, name) except LookupError: print(_(""WARNING: %(service)s has no endpoint in %(region)s! "" ""Available endpoints for this service:"") % {'service': name, 'region': region}) for other_endpoint in endpoints: utils.print_dict(other_endpoint, name) def _get_first_endpoint(endpoints, region): """"""Find the first suitable endpoint in endpoints. If there is only one endpoint, return it. If there is more than one endpoint, return the first one with the given region. If there are no endpoints, or there is more than one endpoint but none of them match the given region, raise KeyError. """""" if len(endpoints) == 1: return endpoints[0] else: for candidate_endpoint in endpoints: if candidate_endpoint[""region""] == region: return candidate_endpoint raise LookupError(""No suitable endpoint found"") @utils.arg( '--wrap', dest='wrap', metavar='<integer>', default=64, help=_('Wrap PKI tokens to a specified length, or 0 to disable.')) def do_credentials(cs, _args): """"""Show user credentials returned from auth."""""" warnings.warn( ""nova credentials is deprecated, use openstack client instead"") if isinstance(cs.client, client.SessionClient): access = cs.client.auth.get_access(cs.client.session) utils.print_dict(access._user, 'User Credentials', wrap=int(_args.wrap)) if hasattr(access, '_token'): utils.print_dict(access._token, 'Token', wrap=int(_args.wrap)) else: ensure_service_catalog_present(cs) catalog = cs.client.service_catalog.catalog utils.print_dict(catalog['access']['user'], ""User Credentials"", wrap=int(_args.wrap)) utils.print_dict(catalog['access']['token'], ""Token"", wrap=int(_args.wrap)) @utils.arg('server', metavar='<server>', help=_('Name or ID of server.')) @utils.arg( '--port', dest='port', action='store', type=int, default=22, help=_('Optional flag to indicate which port to use for ssh. ' '(Default=22)')) @utils.arg( '--private', dest='private', action='store_true', default=False, help=argparse.SUPPRESS) @utils.arg( '--address-type', dest='address_type', action='store', type=str, default='floating', help=_('Optional flag to indicate which IP type to use. Possible values ' 'includes fixed and floating (the Default).')) @utils.arg( '--network', metavar='<network>', help=_('Network to use for the ssh.'), default=None) @utils.arg( '--ipv6', dest='ipv6', action='store_true', default=False, help=_('Optional flag to indicate whether to use an IPv6 address ' 'attached to a server. (Defaults to IPv4 address)')) @utils.arg( '--login', metavar='<login>', help=_('Login to use.'), default=""root"") @utils.arg( '-i', '--identity', dest='identity', help=_('Private key file, same as the -i option to the ssh command.'), default='') @utils.arg( '--extra-opts', dest='extra', help=_('Extra options to pass to ssh. see: man ssh.'), default='') def do_ssh(cs, args): """"""SSH into a server."""""" if '@' in args.server: user, server = args.server.split('@', 1) args.login = user args.server = server addresses = _find_server(cs, args.server).addresses address_type = ""fixed"" if args.private else args.address_type version = 6 if args.ipv6 else 4 pretty_version = 'IPv%d' % version # Select the network to use. if args.network: network_addresses = addresses.get(args.network) if not network_addresses: msg = _(""Server '%(server)s' is not attached to network "" ""'%(network)s'"") raise exceptions.ResourceNotFound( msg % {'server': args.server, 'network': args.network}) else: if len(addresses) > 1: msg = _(""Server '%(server)s' is attached to more than one network."" "" Please pick the network to use."") raise exceptions.CommandError(msg % {'server': args.server}) elif not addresses: msg = _(""Server '%(server)s' is not attached to any network."") raise exceptions.CommandError(msg % {'server': args.server}) else: network_addresses = list(six.itervalues(addresses))[0] # Select the address in the selected network. # If the extension is not present, we assume the address to be floating. match = lambda addr: all(( addr.get('version') == version, addr.get('OS-EXT-IPS:type', 'floating') == address_type)) matching_addresses = [address.get('addr') for address in network_addresses if match(address)] if not any(matching_addresses): msg = _(""No address that would match network '%(network)s'"" "" and type '%(address_type)s' of version %(pretty_version)s "" ""has been found for server '%(server)s'."") raise exceptions.ResourceNotFound(msg % { 'network': args.network, 'address_type': address_type, 'pretty_version': pretty_version, 'server': args.server}) elif len(matching_addresses) > 1: msg = _(""More than one %(pretty_version)s %(address_type)s address "" ""found."") raise exceptions.CommandError(msg % {'pretty_version': pretty_version, 'address_type': address_type}) else: ip_address = matching_addresses[0] identity = '-i %s' % args.identity if len(args.identity) else '' cmd = ""ssh -%d -p%d %s %s@%s %s"" % (version, args.port, identity, args.login, ip_address, args.extra) logger.debug(""Executing cmd '%s'"", cmd) os.system(cmd) _quota_resources = ['instances', 'cores', 'ram', 'floating_ips', 'fixed_ips', 'metadata_items', 'injected_files', 'injected_file_content_bytes', 'injected_file_path_bytes', 'key_pairs', 'security_groups', 'security_group_rules', 'server_groups', 'server_group_members'] def _quota_show(quotas): class FormattedQuota(object): def __init__(self, key, value): setattr(self, 'quota', key) setattr(self, 'limit', value) quota_list = [] for resource in _quota_resources: try: quota = FormattedQuota(resource, getattr(quotas, resource)) quota_list.append(quota) except AttributeError: pass columns = ['Quota', 'Limit'] utils.print_list(quota_list, columns) def _quota_update(manager, identifier, args): updates = {} for resource in _quota_resources: val = getattr(args, resource, None) if val is not None: updates[resource] = val if updates: # default value of force is None to make sure this client # will be compatible with old nova server force_update = getattr(args, 'force', None) user_id = getattr(args, 'user', None) if isinstance(manager, quotas.QuotaSetManager): manager.update(identifier, force=force_update, user_id=user_id, **updates) else: manager.update(identifier, **updates) @utils.arg( '--tenant', metavar='<tenant-id>', default=None, help=_('ID of tenant to list the quotas for.')) @utils.arg( '--user', metavar='<user-id>', default=None, help=_('ID of user to list the quotas for.')) @utils.arg( '--detail', action='store_true', default=False, help=_('Show detailed info (limit, reserved, in-use).')) def do_quota_show(cs, args): """"""List the quotas for a tenant/user."""""" if args.tenant: project_id = args.tenant elif isinstance(cs.client, client.SessionClient): auth = cs.client.auth project_id = auth.get_auth_ref(cs.client.session).project_id else: project_id = cs.client.tenant_id _quota_show(cs.quotas.get(project_id, user_id=args.user, detail=args.detail)) @utils.arg( '--tenant', metavar='<tenant-id>', default=None, help=_('ID of tenant to list the default quotas for.')) def do_quota_defaults(cs, args): """"""List the default quotas for a tenant."""""" if args.tenant: project_id = args.tenant elif isinstance(cs.client, client.SessionClient): auth = cs.client.auth project_id = auth.get_auth_ref(cs.client.session).project_id else: project_id = cs.client.tenant_id _quota_show(cs.quotas.defaults(project_id)) @api_versions.wraps(""2.0"", ""2.35"") @utils.arg( 'tenant', metavar='<tenant-id>', help=_('ID of tenant to set the quotas for.')) @utils.arg( '--user', metavar='<user-id>', default=None, help=_('ID of user to set the quotas for.')) @utils.arg( '--instances', metavar='<instances>', type=int, default=None, help=_('New value for the ""instances"" quota.')) @utils.arg( '--cores', metavar='<cores>', type=int, default=None, help=_('New value for the ""cores"" quota.')) @utils.arg( '--ram', metavar='<ram>', type=int, default=None, help=_('New value for the ""ram"" quota.')) @utils.arg( '--floating-ips', metavar='<floating-ips>', type=int, default=None, action=shell.DeprecatedAction, help=_('New value for the ""floating-ips"" quota.')) @utils.arg( '--fixed-ips', metavar='<fixed-ips>', type=int, default=None, action=shell.DeprecatedAction, help=_('New value for the ""fixed-ips"" quota.')) @utils.arg( '--metadata-items', metavar='<metadata-items>', type=int, default=None, help=_('New value for the ""metadata-items"" quota.')) @utils.arg( '--injected-files', metavar='<injected-files>', type=int, default=None, help=_('New value for the ""injected-files"" quota.')) @utils.arg( '--injected-file-content-bytes', metavar='<injected-file-content-bytes>', type=int, default=None, help=_('New value for the ""injected-file-content-bytes"" quota.')) @utils.arg( '--injected-file-path-bytes', metavar='<injected-file-path-bytes>', type=int, default=None, help=_('New value for the ""injected-file-path-bytes"" quota.')) @utils.arg( '--key-pairs', metavar='<key-pairs>', type=int, default=None, help=_('New value for the ""key-pairs"" quota.')) @utils.arg( '--security-groups', metavar='<security-groups>', type=int, default=None, action=shell.DeprecatedAction, help=_('New value for the ""security-groups"" quota.')) @utils.arg( '--security-group-rules', metavar='<security-group-rules>', type=int, default=None, action=shell.DeprecatedAction, help=_('New value for the ""security-group-rules"" quota.')) @utils.arg( '--server-groups', metavar='<server-groups>', type=int, default=None, help=_('New value for the ""server-groups"" quota.')) @utils.arg( '--server-group-members', metavar='<server-group-members>', type=int, default=None, help=_('New value for the ""server-group-members"" quota.')) @utils.arg( '--force', dest='force', action=""store_true"", default=None, help=_('Whether force update the quota even if the already used and ' 'reserved exceeds the new quota.')) def do_quota_update(cs, args): """"""Update the quotas for a tenant/user."""""" _quota_update(cs.quotas, args.tenant, args) # 2.36 does not support updating quota for floating IPs, fixed IPs, security # groups or security group rules. @api_versions.wraps(""2.36"") @utils.arg( 'tenant', metavar='<tenant-id>', help=_('ID of tenant to set the quotas for.')) @utils.arg( '--user', metavar='<user-id>', default=None, help=_('ID of user to set the quotas for.')) @utils.arg( '--instances', metavar='<instances>', type=int, default=None, help=_('New value for the ""instances"" quota.')) @utils.arg( '--cores', metavar='<cores>', type=int, default=None, help=_('New value for the ""cores"" quota.')) @utils.arg( '--ram', metavar='<ram>', type=int, default=None, help=_('New value for the ""ram"" quota.')) @utils.arg( '--metadata-items', metavar='<metadata-items>', type=int, default=None, help=_('New value for the ""metadata-items"" quota.')) @utils.arg( '--injected-files', metavar='<injected-files>', type=int, default=None, help=_('New value for the ""injected-files"" quota.')) @utils.arg( '--injected-file-content-bytes', metavar='<injected-file-content-bytes>', type=int, default=None, help=_('New value for the ""injected-file-content-bytes"" quota.')) @utils.arg( '--injected-file-path-bytes', metavar='<injected-file-path-bytes>', type=int, default=None, help=_('New value for the ""injected-file-path-bytes"" quota.')) @utils.arg( '--key-pairs', metavar='<key-pairs>', type=int, default=None, help=_('New value for the ""key-pairs"" quota.')) @utils.arg( '--server-groups', metavar='<server-groups>', type=int, default=None, help=_('New value for the ""server-groups"" quota.')) @utils.arg( '--server-group-members', metavar='<server-group-members>', type=int, default=None, help=_('New value for the ""server-group-members"" quota.')) @utils.arg( '--force', dest='force', action=""store_true"", default=None, help=_('Whether force update the quota even if the already used and ' 'reserved exceeds the new quota.')) def do_quota_update(cs, args): """"""Update the quotas for a tenant/user."""""" _quota_update(cs.quotas, args.tenant, args) @utils.arg( '--tenant', metavar='<tenant-id>', required=True, help=_('ID of tenant to delete quota for.')) @utils.arg( '--user', metavar='<user-id>', help=_('ID of user to delete quota for.')) def do_quota_delete(cs, args): """"""Delete quota for a tenant/user so their quota will Revert back to default. """""" cs.quotas.delete(args.tenant, user_id=args.user) @utils.arg( 'class_name', metavar='<class>', help=_('Name of quota class to list the quotas for.')) def do_quota_class_show(cs, args): """"""List the quotas for a quota class."""""" _quota_show(cs.quota_classes.get(args.class_name)) @api_versions.wraps(""2.0"", ""2.35"") @utils.arg( 'class_name', metavar='<class>', help=_('Name of quota class to set the quotas for.')) @utils.arg( '--instances', metavar='<instances>', type=int, default=None, help=_('New value for the ""instances"" quota.')) @utils.arg( '--cores', metavar='<cores>', type=int, default=None, help=_('New value for the ""cores"" quota.')) @utils.arg( '--ram', metavar='<ram>', type=int, default=None, help=_('New value for the ""ram"" quota.')) @utils.arg( '--floating-ips', metavar='<floating-ips>', type=int, default=None, action=shell.DeprecatedAction, help=_('New value for the ""floating-ips"" quota.')) @utils.arg( '--fixed-ips', metavar='<fixed-ips>', type=int, default=None, action=shell.DeprecatedAction, help=_('New value for the ""fixed-ips"" quota.')) @utils.arg( '--metadata-items', metavar='<metadata-items>', type=int, default=None, help=_('New value for the ""metadata-items"" quota.')) @utils.arg( '--injected-files', metavar='<injected-files>', type=int, default=None, help=_('New value for the ""injected-files"" quota.')) @utils.arg( '--injected-file-content-bytes', metavar='<injected-file-content-bytes>', type=int, default=None, help=_('New value for the ""injected-file-content-bytes"" quota.')) @utils.arg( '--injected-file-path-bytes', metavar='<injected-file-path-bytes>', type=int, default=None, help=_('New value for the ""injected-file-path-bytes"" quota.')) @utils.arg( '--key-pairs', metavar='<key-pairs>', type=int, default=None, help=_('New value for the ""key-pairs"" quota.')) @utils.arg( '--security-groups', metavar='<security-groups>', type=int, default=None, action=shell.DeprecatedAction, help=_('New value for the ""security-groups"" quota.')) @utils.arg( '--security-group-rules', metavar='<security-group-rules>', type=int, default=None, action=shell.DeprecatedAction, help=_('New value for the ""security-group-rules"" quota.')) @utils.arg( '--server-groups', metavar='<server-groups>', type=int, default=None, help=_('New value for the ""server-groups"" quota.')) @utils.arg( '--server-group-members', metavar='<server-group-members>', type=int, default=None, help=_('New value for the ""server-group-members"" quota.')) def do_quota_class_update(cs, args): """"""Update the quotas for a quota class."""""" _quota_update(cs.quota_classes, args.class_name, args) # 2.36 does not support updating quota for floating IPs, fixed IPs, security # groups or security group rules. @api_versions.wraps(""2.36"") @utils.arg( 'class_name', metavar='<class>', help=_('Name of quota class to set the quotas for.')) @utils.arg( '--instances', metavar='<instances>', type=int, default=None, help=_('New value for the ""instances"" quota.')) @utils.arg( '--cores', metavar='<cores>', type=int, default=None, help=_('New value for the ""cores"" quota.')) @utils.arg( '--ram', metavar='<ram>', type=int, default=None, help=_('New value for the ""ram"" quota.')) @utils.arg( '--metadata-items', metavar='<metadata-items>', type=int, default=None, help=_('New value for the ""metadata-items"" quota.')) @utils.arg( '--injected-files', metavar='<injected-files>', type=int, default=None, help=_('New value for the ""injected-files"" quota.')) @utils.arg( '--injected-file-content-bytes', metavar='<injected-file-content-bytes>', type=int, default=None, help=_('New value for the ""injected-file-content-bytes"" quota.')) @utils.arg( '--injected-file-path-bytes', metavar='<injected-file-path-bytes>', type=int, default=None, help=_('New value for the ""injected-file-path-bytes"" quota.')) @utils.arg( '--key-pairs', metavar='<key-pairs>', type=int, default=None, help=_('New value for the ""key-pairs"" quota.')) @utils.arg( '--server-groups', metavar='<server-groups>', type=int, default=None, help=_('New value for the ""server-groups"" quota.')) @utils.arg( '--server-group-members', metavar='<server-group-members>', type=int, default=None, help=_('New value for the ""server-group-members"" quota.')) def do_quota_class_update(cs, args): """"""Update the quotas for a quota class."""""" _quota_update(cs.quota_classes, args.class_name, args) @utils.arg('server', metavar='<server>', help=_('Name or ID of server.')) @utils.arg( 'host', metavar='<host>', nargs='?', help=_(""Name or ID of the target host. "" ""If no host is specified, the scheduler will choose one."")) @utils.arg( '--password', dest='password', metavar='<password>', help=_(""Set the provided admin password on the evacuated server. Not"" "" applicable if the server is on shared storage."")) @utils.arg( '--on-shared-storage', dest='on_shared_storage', action=""store_true"", default=False, help=_('Specifies whether server files are located on shared storage.'), start_version='2.0', end_version='2.13') @utils.arg( '--force', dest='force', action='store_true', default=False, help=_('Force to not verify the scheduler if a host is provided.'), start_version='2.29') def do_evacuate(cs, args): """"""Evacuate server from failed host."""""" server = _find_server(cs, args.server) on_shared_storage = getattr(args, 'on_shared_storage', None) force = getattr(args, 'force', None) update_kwargs = {} if on_shared_storage is not None: update_kwargs['on_shared_storage'] = on_shared_storage if force: update_kwargs['force'] = force res = server.evacuate(host=args.host, password=args.password, **update_kwargs)[1] if isinstance(res, dict): utils.print_dict(res) def _print_interfaces(interfaces): columns = ['Port State', 'Port ID', 'Net ID', 'IP addresses', 'MAC Addr'] class FormattedInterface(object): def __init__(self, interface): for col in columns: key = col.lower().replace("" "", ""_"") if hasattr(interface, key): setattr(self, key, getattr(interface, key)) self.ip_addresses = "","".join([fip['ip_address'] for fip in interface.fixed_ips]) utils.print_list([FormattedInterface(i) for i in interfaces], columns) @utils.arg('server', metavar='<server>', help=_('Name or ID of server.')) def do_interface_list(cs, args): """"""List interfaces attached to a server."""""" server = _find_server(cs, args.server) res = server.interface_list() if isinstance(res, list): _print_interfaces(res) @utils.arg('server', metavar='<server>', help=_('Name or ID of server.')) @utils.arg( '--port-id', metavar='<port_id>', help=_('Port ID.'), dest=""port_id"") @utils.arg( '--net-id', metavar='<net_id>', help=_('Network ID'), default=None, dest=""net_id"") @utils.arg( '--fixed-ip', metavar='<fixed_ip>', help=_('Requested fixed IP.'), default=None, dest=""fixed_ip"") def do_interface_attach(cs, args): """"""Attach a network interface to a server."""""" server = _find_server(cs, args.server) res = server.interface_attach(args.port_id, args.net_id, args.fixed_ip) if isinstance(res, dict): utils.print_dict(res) @utils.arg('server', metavar='<server>', help=_('Name or ID of server.')) @utils.arg('port_id', metavar='<port_id>', help=_('Port ID.')) def do_interface_detach(cs, args): """"""Detach a network interface from a server."""""" server = _find_server(cs, args.server) res = server.interface_detach(args.port_id) if isinstance(res, dict): utils.print_dict(res) @api_versions.wraps(""2.17"") @utils.arg('server', metavar='<server>', help=_('Name or ID of server.')) def do_trigger_crash_dump(cs, args): """"""Trigger crash dump in an instance."""""" server = _find_server(cs, args.server) server.trigger_crash_dump() def _treeizeAvailabilityZone(zone): """"""Build a tree view for availability zones."""""" AvailabilityZone = availability_zones.AvailabilityZone az = AvailabilityZone(zone.manager, copy.deepcopy(zone._info), zone._loaded) result = [] # Zone tree view item az.zoneName = zone.zoneName az.zoneState = ('available' if zone.zoneState['available'] else 'not available') az._info['zoneName'] = az.zoneName az._info['zoneState'] = az.zoneState result.append(az) if zone.hosts is not None: zone_hosts = sorted(zone.hosts.items(), key=lambda x: x[0]) for (host, services) in zone_hosts: # Host tree view item az = AvailabilityZone(zone.manager, copy.deepcopy(zone._info), zone._loaded) az.zoneName = '|- %s' % host az.zoneState = '' az._info['zoneName'] = az.zoneName az._info['zoneState'] = az.zoneState result.append(az) for (svc, state) in services.items(): # Service tree view item az = AvailabilityZone(zone.manager, copy.deepcopy(zone._info), zone._loaded) az.zoneName = '| |- %s' % svc az.zoneState = '%s %s %s' % ( 'enabled' if state['active'] else 'disabled', ':-)' if state['available'] else 'XXX', state['updated_at']) az._info['zoneName'] = az.zoneName az._info['zoneState'] = az.zoneState result.append(az) return result @utils.service_type('compute') def do_availability_zone_list(cs, _args): """"""List all the availability zones."""""" try: availability_zones = cs.availability_zones.list() except exceptions.Forbidden as e: # policy doesn't allow probably try: availability_zones = cs.availability_zones.list(detailed=False) except Exception: raise e result = [] for zone in availability_zones: result += _treeizeAvailabilityZone(zone) _translate_availability_zone_keys(result) utils.print_list(result, ['Name', 'Status'], sortby_index=None) @api_versions.wraps(""2.0"", ""2.12"") def _print_server_group_details(cs, server_group): columns = ['Id', 'Name', 'Policies', 'Members', 'Metadata'] utils.print_list(server_group, columns) @api_versions.wraps(""2.13"") def _print_server_group_details(cs, server_group): # noqa columns = ['Id', 'Name', 'Project Id', 'User Id', 'Policies', 'Members', 'Metadata'] utils.print_list(server_group, columns) @utils.arg( '--all-projects', dest='all_projects', action='store_true', default=False, help=_('Display server groups from all projects (Admin only).')) def do_server_group_list(cs, args): """"""Print a list of all server groups."""""" server_groups = cs.server_groups.list(args.all_projects) _print_server_group_details(cs, server_groups) @deprecated_network def do_secgroup_list_default_rules(cs, args): """"""List rules that will be added to the 'default' security group for new tenants. """""" _print_secgroup_rules(cs.security_group_default_rules.list(), show_source_group=False) @utils.arg( 'ip_proto', metavar='<ip-proto>', help=_('IP protocol (icmp, tcp, udp).')) @utils.arg( 'from_port', metavar='<from-port>', help=_('Port at start of range.')) @utils.arg( 'to_port', metavar='<to-port>', help=_('Port at end of range.')) @utils.arg('cidr', metavar='<cidr>', help=_('CIDR for address range.')) @deprecated_network def do_secgroup_add_default_rule(cs, args): """"""Add a rule to the set of rules that will be added to the 'default' security group for new tenants (nova-network only). """""" rule = cs.security_group_default_rules.create(args.ip_proto, args.from_port, args.to_port, args.cidr) _print_secgroup_rules([rule], show_source_group=False) @utils.arg( 'ip_proto', metavar='<ip-proto>', help=_('IP protocol (icmp, tcp, udp).')) @utils.arg( 'from_port', metavar='<from-port>', help=_('Port at start of range.')) @utils.arg( 'to_port', metavar='<to-port>', help=_('Port at end of range.')) @utils.arg('cidr', metavar='<cidr>', help=_('CIDR for address range.')) @deprecated_network def do_secgroup_delete_default_rule(cs, args): """"""Delete a rule from the set of rules that will be added to the 'default' security group for new tenants (nova-network only). """""" for rule in cs.security_group_default_rules.list(): if (rule.ip_protocol and rule.ip_protocol.upper() == args.ip_proto.upper() and rule.from_port == int(args.from_port) and rule.to_port == int(args.to_port) and rule.ip_range['cidr'] == args.cidr): _print_secgroup_rules([rule], show_source_group=False) return cs.security_group_default_rules.delete(rule.id) raise exceptions.CommandError(_(""Rule not found"")) @utils.arg('name', metavar='<name>', help=_('Server group name.')) # NOTE(wingwj): The '--policy' way is still reserved here for preserving # the backwards compatibility of CLI, even if a user won't get this usage # in '--help' description. It will be deprecated after a suitable deprecation # period(probably 2 coordinated releases or so). # # Moreover, we imagine that a given user will use only positional parameters or # only the ""--policy"" option. So we don't need to properly handle # the possibility that they might mix them here. That usage is unsupported. # The related discussion can be found in # https://review.openstack.org/#/c/96382/2/. @utils.arg( 'policy', metavar='<policy>', default=argparse.SUPPRESS, nargs='*', help=_('Policies for the server groups.')) def do_server_group_create(cs, args): """"""Create a new server group with the specified details."""""" if not args.policy: raise exceptions.CommandError(_(""at least one policy must be "" ""specified"")) kwargs = {'name': args.name, 'policies': args.policy} server_group = cs.server_groups.create(**kwargs) _print_server_group_details(cs, [server_group]) @utils.arg( 'id', metavar='<id>', nargs='+', help=_(""Unique ID(s) of the server group to delete."")) def do_server_group_delete(cs, args): """"""Delete specific server group(s)."""""" failure_count = 0 for sg in args.id: try: cs.server_groups.delete(sg) print(_(""Server group %s has been successfully deleted."") % sg) except Exception as e: failure_count += 1 print(_(""Delete for server group %(sg)s failed: %(e)s"") % {'sg': sg, 'e': e}) if failure_count == len(args.id): raise exceptions.CommandError(_(""Unable to delete any of the "" ""specified server groups."")) @utils.arg( 'id', metavar='<id>', help=_(""Unique ID of the server group to get."")) def do_server_group_get(cs, args): """"""Get a specific server group."""""" server_group = cs.server_groups.get(args.id) _print_server_group_details(cs, [server_group]) def do_version_list(cs, args): """"""List all API versions."""""" result = cs.versions.list() if 'min_version' in dir(result[0]): columns = [""Id"", ""Status"", ""Updated"", ""Min Version"", ""Version""] else: columns = [""Id"", ""Status"", ""Updated""] print(_(""Client supported API versions:"")) print(_(""Minimum version %(v)s"") % {'v': novaclient.API_MIN_VERSION.get_string()}) print(_(""Maximum version %(v)s"") % {'v': novaclient.API_MAX_VERSION.get_string()}) print(_(""\nServer supported API versions:"")) utils.print_list(result, columns) @api_versions.wraps(""2.0"", ""2.11"") def _print_virtual_interface_list(cs, interface_list): columns = ['Id', 'Mac address'] utils.print_list(interface_list, columns) @api_versions.wraps(""2.12"") def _print_virtual_interface_list(cs, interface_list): columns = ['Id', 'Mac address', 'Network ID'] formatters = {""Network ID"": lambda o: o.net_id} utils.print_list(interface_list, columns, formatters) @utils.arg('server', metavar='<server>', help=_('ID of server.')) def do_virtual_interface_list(cs, args): """"""Show virtual interface info about the given server."""""" server = _find_server(cs, args.server) interface_list = cs.virtual_interfaces.list(base.getid(server)) _print_virtual_interface_list(cs, interface_list) @api_versions.wraps(""2.26"") @utils.arg('server', metavar='<server>', help=_('Name or ID of server.')) def do_server_tag_list(cs, args): """"""Get list of tags from a server."""""" server = _find_server(cs, args.server) tags = server.tag_list() formatters = {'Tag': lambda o: o} utils.print_list(tags, ['Tag'], formatters=formatters) @api_versions.wraps(""2.26"") @utils.arg('server', metavar='<server>', help=_('Name or ID of server.')) @utils.arg('tag', metavar='<tag>', help=_('Tag to add.')) def do_server_tag_add(cs, args): """"""Add single tag to a server."""""" server = _find_server(cs, args.server) server.add_tag(args.tag) @api_versions.wraps(""2.26"") @utils.arg('server', metavar='<server>', help=_('Name or ID of server.')) @utils.arg('tags', metavar='<tags>', nargs='+', help=_('Tag(s) to set.')) def do_server_tag_set(cs, args): """"""Set list of tags to a server."""""" server = _find_server(cs, args.server) server.set_tags(args.tags) @api_versions.wraps(""2.26"") @utils.arg('server', metavar='<server>', help=_('Name or ID of server.')) @utils.arg('tag', metavar='<tag>', help=_('Tag to delete.')) def do_server_tag_delete(cs, args): """"""Delete single tag from a server."""""" server = _find_server(cs, args.server) server.delete_tag(args.tag) @api_versions.wraps(""2.26"") @utils.arg('server', metavar='<server>', help=_('Name or ID of server.')) def do_server_tag_delete_all(cs, args): """"""Delete all tags from a server."""""" server = _find_server(cs, args.server) server.delete_all_tags()",5310,5307
openstack%2Fapi-site~master~Ibe523b4f5b57240635721e4546e2a09657640600,openstack/api-site,master,Ibe523b4f5b57240635721e4546e2a09657640600,Updated from openstack-manuals,MERGED,2016-08-29 15:01:29.000000000,2016-08-29 17:43:45.000000000,2016-08-29 17:43:45.000000000,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2016-08-29 15:01:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/api-site/commit/59cc369b17b6cdea0171c0290038d660f57d6250', 'message': 'Updated from openstack-manuals\n\nChange-Id: Ibe523b4f5b57240635721e4546e2a09657640600\n'}, {'number': 2, 'created': '2016-08-29 15:18:45.000000000', 'files': ['common/glossary.rst'], 'web_link': 'https://opendev.org/openstack/api-site/commit/88aec001c669a2b67738b59ab6e4b10ce91f887a', 'message': 'Updated from openstack-manuals\n\nChange-Id: Ibe523b4f5b57240635721e4546e2a09657640600\n'}]",0,362172,88aec001c669a2b67738b59ab6e4b10ce91f887a,8,2,2,11131,,,0,"Updated from openstack-manuals

Change-Id: Ibe523b4f5b57240635721e4546e2a09657640600
",git fetch https://review.opendev.org/openstack/api-site refs/changes/72/362172/2 && git format-patch -1 --stdout FETCH_HEAD,['common/glossary.rst'],1,59cc369b17b6cdea0171c0290038d660f57d6250,openstack/openstack-manuals," Network Address Translation (NAT) Process of modifying IP address information while in transit. Supported by Compute and Networking. Network Time Protocol (NTP) Method of keeping a clock for a host or node correct via communication with a trusted, accurate time source. "," NAT Network Address Translation; Process of modifying IP address information while in transit. Supported by Compute and Networking. NTP Network Time Protocol; Method of keeping a clock for a host or node correct via communication with a trusted, accurate time source. ",8,10
openstack%2Fneutron-fwaas~master~If3e1a9ff71284cb550d3096728bb10bb9faba1b7,openstack/neutron-fwaas,master,If3e1a9ff71284cb550d3096728bb10bb9faba1b7,[WIP] Import the API spec,ABANDONED,2016-01-07 00:43:17.000000000,2016-08-29 17:38:04.000000000,,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 4656}, {'_account_id': 9423}, {'_account_id': 10692}, {'_account_id': 10980}, {'_account_id': 13995}, {'_account_id': 20035}]","[{'number': 1, 'created': '2016-01-07 00:43:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-fwaas/commit/431dd70e1477cd26f110c881c34d888ca85aae36', 'message': '[WIP] Import the API spec\n\nChange-Id: If3e1a9ff71284cb550d3096728bb10bb9faba1b7\nCo-Authored-By: Mickey Spiegel <emspiege@us.ibm.com>\nCo-Authored-By: Sridar Kandaswamy <skandasw@cisco.com>\nCo-Authored-By: Dustin Lundquist <dustin@null-ptr.net>\nCo-Authored-By: German Eichberger <german.eichberger@hp.com>\nCo-Authored-By: Aishwarya Thangappa <aishwarya.thangappa@gmail.com>\n'}, {'number': 2, 'created': '2016-05-03 16:20:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-fwaas/commit/04885acb271bb9d8668a614f618382976d916997', 'message': '[WIP] Import the API spec\n\nChange-Id: If3e1a9ff71284cb550d3096728bb10bb9faba1b7\nCo-Authored-By: Mickey Spiegel <emspiege@us.ibm.com>\nCo-Authored-By: Sridar Kandaswamy <skandasw@cisco.com>\nCo-Authored-By: Dustin Lundquist <dustin@null-ptr.net>\nCo-Authored-By: German Eichberger <german.eichberger@hp.com>\nCo-Authored-By: Aishwarya Thangappa <aishwarya.thangappa@gmail.com>\n'}, {'number': 3, 'created': '2016-05-25 19:16:12.000000000', 'files': ['doc/source/fwaas-api-2.0.rst'], 'web_link': 'https://opendev.org/openstack/neutron-fwaas/commit/b3600490fbe5120c2bd9f2f741474bd973b4a2bb', 'message': '[WIP] Import the API spec\n\nChange-Id: If3e1a9ff71284cb550d3096728bb10bb9faba1b7\nCo-Authored-By: Mickey Spiegel <emspiege@us.ibm.com>\nCo-Authored-By: Sridar Kandaswamy <skandasw@cisco.com>\nCo-Authored-By: Dustin Lundquist <dustin@null-ptr.net>\nCo-Authored-By: German Eichberger <german.eichberger@hp.com>\nCo-Authored-By: Aishwarya Thangappa <aishwarya.thangappa@gmail.com>\n'}]",1,264487,b3600490fbe5120c2bd9f2f741474bd973b4a2bb,18,8,3,4656,,,0,"[WIP] Import the API spec

Change-Id: If3e1a9ff71284cb550d3096728bb10bb9faba1b7
Co-Authored-By: Mickey Spiegel <emspiege@us.ibm.com>
Co-Authored-By: Sridar Kandaswamy <skandasw@cisco.com>
Co-Authored-By: Dustin Lundquist <dustin@null-ptr.net>
Co-Authored-By: German Eichberger <german.eichberger@hp.com>
Co-Authored-By: Aishwarya Thangappa <aishwarya.thangappa@gmail.com>
",git fetch https://review.opendev.org/openstack/neutron-fwaas refs/changes/87/264487/2 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/fwaas-api-2.0.rst'],1,431dd70e1477cd26f110c881c34d888ca85aae36,fwaas_v2_api,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ========================================== Firewall as a Service API 2.0 ========================================== **Launchpad blueprint:** | https://blueprints.launchpad.net/neutron/+spec/fwaas-api-2.0 This spec introduces a few enhancements to Firewall as a Service (FWaaS) API including making it more granular by giving the users the ability to apply the firewall rules at the port level rather than at the router level. Support is extended to various types of Neutron ports, including VM ports and SFC ports as well as router ports. It also aims to provide better grouping mechanisms (firewall groups, address groups and service groups) and discuss the use of a common classifier in achieving it. While this spec is proposing the API, the implementation will be carried out in phases subject to availability of people to do the work. And at the end of Mitaka - we will have a working reference implementation but, that may not embody all the enhancements in this spec. The implementation phases will be tracked by an appropriate RFE referencing this as the parent spec. Problem Description =================== The Security Group API extension is a well known API for handling network traffic. For basic traffic filtering, the Security Group API is well understood by users, but as cloud infrastructure gains wider acceptance into the enterprise, the security group API, which was built for public cloud infrastructure becomes insufficient for the security and network environments inside the enterprise. As such, one-off changes to the Security Group API end up occurring in each deployment of OpenStack. One solution is to allow deployers of OpenStack to ""extend"" an API extension to make it fit in their security and network environment. Ideally, the Firewall as a Service API is the API where usecases more advanced than the basic ""let any traffic from X IP into Y port into my group of VMs"" should be supported. But the existing Firewall as a Service API has been deprecated in Liberty because it was fairly limited, requiring substantial enhancements to make it cover all the use cases raised by the community. There are also some overlapping functionalities between FWaaS API and the SG API which need to be rationalized. | Use Cases: https://trello.com/b/TIWf4dBJ/fwaas-usecase-categorization Proposed Change =============== It is proposed to harmonize the FWaaS and Security Group models by converging the implementation of FWaaS and Security Groups but keeping a separate API for each of them while relying on a common backend. This spec proposes an enhanced FWaaS API that incorporates Security Groups functionality such that the FWaaS API becomes a superset of what is exposed by the Security Group API. Relative to the FWaaS 1.0 API, the FWaaS 2.0 API provides the following enhancements: * Applies at the granularity of Neutron ports rather than tenant wide or a set of routers in a tenant. * Applies to various types of Neutron ports, including VM ports and SFC ports as well as router ports. By applying FWaaS at VM ports, it will be possible to filter east/west intra-subnet traffic as well as east/west inter-subnet traffic and north/south traffic. This will also allow FWaaS to filter east/west traffic when DVR is used, as opposed to FWaaS 1.0 that only filters north/south traffic in case of DVR [4], [5]. * Allows for different firewall policies with different firewall rules to be applied to different directions (ingress vs egress). * Introduces the Firewall Group construct for Neutron ports. This becomes the association point for binding firewall policies and Neutron ports, as well as a way to specify allowed sources and destinations in firewall rules. This reduces or eliminates the need to specify IP addresses for east/west traffic flows in firewall rules. For example, when Firewall Group A is used as the destination firewall group id in a rule within a policy in Firewall Group B, we care only about the ports associated with Firewall Group A. When a packet arrives, it is matched if its destination ip address matches an IP address of one the ports in Firewall Group A. * Adds indirections through address group and service group that allow groups of addresses and groups of L4 ports to be specified once and reused in multiple rules and multiple firewall policies. * Allows multiple firewall group associations for the same Neutron port. For example, one firewall group applied to a tenant's web servers may specify a firewall policy that restricts traffic to HTTP only (intended for north/south traffic), while another firewall group applied to all the tenant's instances may specify a firewall policy that allows all traffic types between sources and destinations in that firewall group (east/west traffic). Relative to the Security Groups API [7], the FWaaS 2.0 API provides the following enhancements: * Adds an explicit action attribute to rules so that ""deny"" and ""reject"" actions can be specified in addition to the existing ""allow"" action. This is particularly important for tenant or service provider network admins that specify firewall policies meant to apply to all of a tenant's or service provider's instances, regardless of application. * Allows filtering based on both source and destination address prefixes, rather than just the remote (source for ingress traffic, destination for egress traffic) address prefixes. * Allows filtering based on both source and destination L4 port ranges, rather than just destination L4 port range. * By adding indirections through firewall group, address group and service group, allows for operational separation of responsibilities between users and experts such as network admins. Experts can define groups of IP address prefixes in address groups, and define service groups using protocol and source/destination ports. Users can then easily define firewall rules that refer to firewall group and service group, without having to know about IP addresses and L4 ports. For example, a service group named *All Web Server Ports* could be defined with protocol TCP and destination L4 ports 80, 8080, and 443. * Adds a ""description"" attribute to firewall rules. * Adds an ""admin status"" attribute to firewall rules. * Adds a ""public"" attribute allowing sharing of firewall rules between different projects. * Firewall groups reference firewall rules through a firewall policy. In particular, this allows reuse of sharable firewall policies that are referenced by multiple firewall groups. * In the future, it is expected that service groups will support deep packet inspection, so that traffic can be matched based on an application ID and L7 fields such as URL strings, instead of or in addition to L4 port ranges. Relationship Between FWaaS and Security Groups ---------------------------------------------- FWaaS and Security Groups remain as separate features. The Security Group API will be retained in addition to the FWaaS 2.0 API for two reasons. The first reason to retain the existing Security Group API is for those users who want to leverage existing functionality in a way that aligns as closely as possible with non-OpenStack security group definitions. The second reason has to do with ""defense in depth"", where multiple layers of data plane access control are defined and applied. With existing FWaaS 1.0 and Security Groups, the perimeter firewall functionality is defined in FWaaS and enforced at OpenStack routers, while application firewall functionality is defined through Security Groups and enforced at VM ports. Both north/south and inter-subnet traffic must be allowed by both FWaaS and Security Groups in order to pass end-to-end from the source to the destination. With FWaaS 2.0, it is important to retain ""defense in depth"" even when FWaaS is enforced at VM ports. When both FWaaS and Security Groups are associated with the same Neutron port, a packet must be allowed by both features, i.e. ""deny"" wins between FWaaS and Security Groups. This behavior is adopted to address typical use cases where a tenant network admin uses FWaaS to specify tenant wide rules that are to be applied regardless of the application, while an application deployer uses Security Groups to narrow down allowed traffic to only what is needed for a specific application. For example, a network admin creates a firewall rule that denies port 25 traffic. Even if the application deployer creates a security group rule that allows port 25 traffic, the port 25 traffic will be denied. Note that as with the existing FWaaS 1.0 API and Security Groups, by default OpenStack policy does not distinguish between different roles within a project. Default OpenStack policy will not prevent different users from the same project (e.g. application deployers vs tenant network admins) from accessing the FWaaS API. This may be investigated in future phases. In future phases, the FWaaS 2.0 API will be enhanced so that multiple layers of ""defense in depth"" can be defined using only the FWaaS 2.0 API. This will allow application deployers to take advantage of the enhancements of FWaaS 2.0 relative to Security Groups, while retaining ""defense in depth"". This will also allow for more than 2 layers of ""defense in depth"", for example tenant application deployers, tenant network admins, and service provider network admins. REST API Impact --------------- Firewall Address Groups ~~~~~~~~~~~~~~~~~~~~~~~~~ +-------------------+---------+-------+------+---------------------------------------+ | Attribute | Type | Req | CRUD | Description | +===================+=========+=======+======+=======================================+ | id | uuid-str| N/A | R | Unique identifier for the | | | | | | address_group object. | +-------------------+---------+-------+------+---------------------------------------+ | name | String | No | CRU | Human readable name for the address | | | | | | group (255 characters limit). Does not| | | | | | have to be unique. | +-------------------+---------+-------+------+---------------------------------------+ | description | String | No | CRU | Human readable description for the | | | | | | address group (255 characters limit). | +-------------------+---------+-------+------+---------------------------------------+ | project_id | uuid-str| Yes | CR | Owner of the address group. Only | | | | | | admin users can specify a project | | | | | | identifier other than their own. | +-------------------+---------+-------+------+---------------------------------------+ | cidrs | List | Yes | CRU | Array of key-value pairs of cidr and | | | | | | ip version. | +-------------------+---------+-------+------+---------------------------------------+ | | Firewall Rules ~~~~~~~~~~~~~~~ Note that as with FWaaS 1.0, in FWaaS 2.0 firewall rules always use stateful connection tracking. +------------------------+------------+-----+------+---------------------------------------+ | Attribute | Type | Req | CRUD | Description | +========================+============+=====+======+=======================================+ | id | uuid-str | N/A | R | Unique identifier for the firewall | | | | | | rule object. | +------------------------+------------+-----+------+---------------------------------------+ | project_id | uuid-str | Yes | CRU | Owner of the firewall rule. Only | | | | | | admin users can specify a project | | | | | | identifier other than their own. | +------------------------+------------+-----+------+---------------------------------------+ | name | String | No | CRU | Human readable name for the firewall | | | | | | rule (255 characters limit). Does | | | | | | not have to be unique. | +------------------------+------------+-----+------+---------------------------------------+ | description | String | No | CRU | Human readable description for the | | | | | | firewall Rule (255 characters limit). | +------------------------+------------+-----+------+---------------------------------------+ | public | Bool | No | CRU | When set to True makes this firewall | | | | | | rule visible to projects other than | | | | | | its owner, and can be used in | | | | | | firewall policies not owned by its | | | | | | project. | +------------------------+------------+-----+------+---------------------------------------+ | protocol | String | No | CRU | IP Protocol. | +------------------------+------------+-----+------+---------------------------------------+ | source_port | port-range | No | CRU | Source port number or a range (an | | | | | | int in [1, 65535] or range in a:b). | +------------------------+------------+-----+------+---------------------------------------+ | destination_port | port-range | No | CRU | Destination port number or a range ( | | | | | | an int in [1, 65535] or range in a:b).| +------------------------+------------+-----+------+---------------------------------------+ | service_group_id | uuid-str | No | CRU | UUID of the service group [6]. | +------------------------+------------+-----+------+---------------------------------------+ | ip_version | Integer | No | CRU | IP Protocol Version. | +------------------------+------------+-----+------+---------------------------------------+ | source_ip_address | String | No | CRU | Source IP address or CIDR. | +------------------------+------------+-----+------+---------------------------------------+ | destination_ip_address | String | No | CRU | Destination IP address or CIDR. | +------------------------+------------+-----+------+---------------------------------------+ | source_address | uuid-str | No | CRU | When a source_address_group is | | _group_id | | | | specified, it is matched when the | | | | | | source IP address in the packet | | | | | | matches one of the IP addresses in | | | | | | the address group. | +------------------------+------------+-----+------+---------------------------------------+ | destination_address | uuid-str | No | CRU | When a destination_address_group is | | _group_id | | | | specified, it is matched when the | | | | | | destination IP address in the packet | | | | | | matches one of the IP addresses in the| | | | | | address group. | +------------------------+------------+-----+------+---------------------------------------+ | source_firewall_group | uuid-str | No | CRU | When a source_firewall_group is | | _id | | | | specified, it is matched when the | | | | | | source IP address in the packet | | | | | | matches an IP address of one of the | | | | | | ports in the firewall group. | | | | | | Note: This holds true when firewall | | | | | | group contains a list of vm ports. | +------------------------+------------+-----+------+---------------------------------------+ | destination_firewall | uuid-str | No | CRU | When a destination_firewall_group is | | _group_id | | | | specified, it is matched when the | | | | | | destination IP address in the packet | | | | | | matches an IP address of one of the | | | | | | ports in the firewall group. | | | | | | Note: This holds true when firewall | | | | | | group contains a list of vm ports. | +------------------------+------------+-----+------+---------------------------------------+ | action | String | No | CRU | Action to be performed on the | | | | | | traffic matching the rule (ALLOW, | | | | | | DENY, REJECT). Default: DENY. | +------------------------+------------+-----+------+---------------------------------------+ | enabled | Bool | No | CRU | When set to False will disable this | | | | | | rule in the firewall policy. | | | | | | Facilitates selectively turning off | | | | | | rules without having to disassociate | | | | | | the rule from the firewall policy. | | | | | | Default: True. | +------------------------+------------+-----+------+---------------------------------------+ | Note: At most one of source_ip_address, source_address_group_id and source_firewall_group_id can be specified. The rule is matched when the source IP address in the packet matches any one of: source_ip_address, one of the IP addresses in the address group, or an IP address of one of the ports in the firewall group. If you want it to match any packet, set the source or destination to 0.0.0.0/0 or ::/0. The same applies to destination_ip_address, destination_address_group_id, and destination _firewall_group_id, with respect to the destination IP address in the packet. | Firewall policies ~~~~~~~~~~~~~~~~~~ +----------------+------------+-----+------+-----------------------------------------+ | Attribute | Type | Req | CRUD | Description | +================+============+=====+======+=========================================+ | id | uuid-str | N/A | R | Unique identifier for the firewall | | | | | | policy object. | +----------------+------------+-----+------+-----------------------------------------+ | project_id | uuid-str | Yes | CR | Owner of the firewall policy. Only | | | | | | admin users can specify a project | | | | | | identifier other than their own. | +----------------+------------+-----+------+-----------------------------------------+ | name | String | No | CRU | Human readable name for the firewall | | | | | | policy (255 characters limit). Does | | | | | | not have to be unique. | +----------------+------------+-----+------+-----------------------------------------+ | description | String | No | CRU | Human readable description for the | | | | | | firewall Policy (255 characters limit). | +----------------+------------+-----+------+-----------------------------------------+ | firewall_rules | List | No | CRU | This is an ordered list of firewall | | | | | | rule uuids. The firewall applies the | | | | | | rules in the order in which they appear.| +----------------+------------+-----+------+-----------------------------------------+ | audited | Bool | No | CRU | When set to True by the policy owner | | | | | | indicates that the firewall policy has | | | | | | been audited. Each time the firewall | | | | | | policy or the associated firewall | | | | | | rules are changed, this attribute will | | | | | | be set to False and will have to be | | | | | | explicitly set to True through an | | | | | | update operation. | +----------------+------------+-----+------+-----------------------------------------+ | public | Bool | No | CRU | When set to True makes this firewall | | | | | | policy visible to projects other than | | | | | | its owner. | +----------------+------------+-----+------+-----------------------------------------+ | Firewall groups ~~~~~~~~~~~~~~~~ Firewall Groups (similar to Security Groups) are the central construct of the FWaaS 2.0 API. They serve two purposes: 1. Through firewall group / port associations, they specify the the Neutron ports that are the points of enforcement of firewall policies. 2. Through the source_firewall_group_id and destination_firewall _group_id in firewall rules, they allow for filtering based on source and destination identities, while minimizing the need to specify long lists of IP addresses. For each source_firewall_group and destination_firewall_group, the OpenStack controller will tell OpenStack FWaaS agents the set of IP addresses for all VM ports associated with firewall group. The list of router ports associated with the firewall group will be passed as is. Similar to Security Groups, for each project, one Firewall Group named ""default"" will be created automatically. This default Firewall Group will be applied to all new VM ports within that project, unless it is explicitly disassociated from the new VM port. This provides a way for a tenant network admin to define a tenant wide firewall policy that applies to all VM ports, except when explicitly provisioned otherwise. The default firewall rules for the default Firewall Group are allow all, i.e. the tenant network admin will have to explicitly define firewall policies and rules in order for the default Firewall Group to take effect. For example, the tenant network admin may want to deny connectivity to certain IP addresses known to be harmful, or deny use of particular L4 ports. This behavior is chosen assuming that typical deployments will use ""defense in depth"", with application deployers specifying default Security Groups, while tenant network admins specify default Firewall Groups. | +-------------------+---------+-------+------+---------------------------------------+ | Attribute | Type | Req | CRUD | Description | +===================+=========+=======+======+=======================================+ | id | uuid-str| N/A | R | Unique identifier for the firewall | | | | | | group object. | +-------------------+---------+-------+------+---------------------------------------+ | name | string | No | CRU | Human readable name for the firewall | | | | | | group (255 characters limit). Does | | | | | | not have to be unique. | +-------------------+---------+-------+------+---------------------------------------+ | description | string | No | CRU | Human readable description for the | | | | | | firewall group (255 characters limit).| +-------------------+---------+-------+------+---------------------------------------+ | project_id | uuid-str| Yes | CR | Owner of the firewall group. Only | | | | | | admin users can specify a project | | | | | | identifier other than their own. | | | | | | Default: derived from authentication | | | | | | token. | +-------------------+---------+-------+------+---------------------------------------+ | ingress_firewall | uuid-str| No | CRU | 'null' if not associated with any | | _policy_id | | | | firewall policy. | +-------------------+---------+-------+------+---------------------------------------+ | egress_firewall | uuid-str| No | CRU | 'null' if not associated with any | | _policy_id | | | | firewall policy. | +-------------------+---------+-------+------+---------------------------------------+ | ports | List | No | CRU | List of port_ids that will be | | | | | | associated to this firewall_group. | +-------------------+---------+-------+------+---------------------------------------+ List address groups ^^^^^^^^^^^^^^^^^^^^^ Lists address groups. +----------------+------------------------------------------------+ | Request Type | ``GET`` | +----------------+------------------------------------------------+ | Endpoint | ``/fw/address_groups`` | +----------------+---------+--------------------------------------+ | | Success | 200 | | Response Codes +---------+--------------------------------------+ | | Error | Unauthorized(401) | +----------------+---------+--------------------------------------+ | **Example List address groups: JSON request** .. code:: GET /v2.0/fw/address_groups.json User-Agent: python-neutronclient Accept: application/json **Example List address groups: JSON response** .. code:: { ""address_groups"": [ { ""description"": """", ""id"": ""8722e0e0-9cc9-4490-9660-8c9a5732fbb0"", ""name"": ""ADDR_GP_1"", ""project_id"": ""45977fa2dbd7482098dd68d0d8970117"", ""cidrs"": [ {""cidr"": ""132.168.4.12/24"", ""ip_version"": 4}, {""cidr"": ""2001::db8::f00/64"", ""ip_version"": 6} ] } ] } Show address group details ^^^^^^^^^^^^^^^^^^^^^^^^^^^ Shows address group details. +----------------+------------------------------------------------+ | Request Type | ``GET`` | +----------------+------------------------------------------------+ | Endpoint | ``/fw/address_groups/<address_group_id>`` | +----------------+---------+--------------------------------------+ | | Success | 200 | | Response Codes +---------+--------------------------------------+ | | Error | Unauthorized(401), Forbidden(403), \ | | | | Not Found (404) | +----------------+---------+--------------------------------------+ | **Example Show address group: JSON request** .. code:: GET /v2.0/fw/address_groups/9faaf49f-dd89-4e39-a8c6-101839aa49bc.json User-Agent: python-neutronclient Accept: application/json **Example Show address group: JSON response** .. code:: { ""address_group"": { ""description"": """", ""id"": ""8722e0e0-9cc9-4490-9660-8c9a5732fbb0"", ""name"": ""ADDR_GP_1"", ""project_id"": ""45977fa2dbd7482098dd68d0d8970117"", ""cidrs"": [ {""cidr"": ""132.168.4.12/24"", ""ip_version"": 4}, {""cidr"": ""2001::db8::f00/64"", ""ip_version"": 6} ] } } Create address group ^^^^^^^^^^^^^^^^^^^^^ Creates an address group. +----------------+------------------------------------------------+ | Request Type | ``POST`` | +----------------+------------------------------------------------+ | Endpoint | ``/fw/address_groups/`` | +----------------+---------+--------------------------------------+ | | Success | 201 | | Response Codes +---------+--------------------------------------+ | | Error | Unauthorized(401), Bad Request(400) | +----------------+---------+--------------------------------------+ | **Example Create address group: JSON request** .. code:: POST /v2.0/fw/address_groups.json User-Agent: python-neutronclient Accept: application/json .. code:: { ""address_group"": { ""name"": ""ADDR_GP_1"", ""cidrs"": [ {""cidr"": ""132.168.4.12/24"", ""ip_version"": 4}, {""cidr"": ""2001::db8::f00/64"", ""ip_version"": 6} ] } } **Example Create address group: JSON response** .. code:: HTTP/1.1 201 Created Content-Type: application/json; charset=UTF-8 .. code:: { ""address_group"": { ""description"": """", ""id"": ""8722e0e0-9cc9-4490-9660-8c9a5732fbb0"", ""name"": ""ADDR_GP_1"", ""project_id"": ""45977fa2dbd7482098dd68d0d8970117"", ""cidrs"": [ {""cidr"": ""132.168.4.12/24"", ""ip_version"": 4}, {""cidr"": ""2001::db8::f00/64"", ""ip_version"": 6} ] } } Update address group ^^^^^^^^^^^^^^^^^^^^^ Updates an address group. +----------------+------------------------------------------------+ | Request Type | ``PUT`` | +----------------+------------------------------------------------+ | Endpoint | ``/fw/address_groups/<address_group_id>`` | +----------------+---------+--------------------------------------+ | | Success | 200 | | Response Codes +---------+--------------------------------------+ | | Error | Unauthorized(401), Bad Request(400) \| | | | Not Found(404) | +----------------+---------+--------------------------------------+ | **Example Update address group: JSON request** .. code:: PUT /v2.0/fw/address_groups/41bfef97-af4e-4f6b-a5d3-4678859d2485.json User-Agent: python-neutronclient Accept: application/json .. code:: { ""address_group"": { ""cidrs"": [ {""cidr"": ""132.168.4.12/24"", ""ip_version"": 4}, {""cidr"": ""2001::db8::f00/64"", ""ip_version"": 6} ] } } **Example Update address group: JSON response** .. code:: HTTP/1.1 200 OK Content-Type: application/json; charset=UTF-8 .. code:: { ""address_group"": { ""description"": """", ""id"": ""8722e0e0-9cc9-4490-9660-8c9a5732fbb0"", ""name"": ""ADDR_GP_1"", ""project_id"": ""45977fa2dbd7482098dd68d0d8970117"", ""cidrs"": [ {""cidr"": ""132.168.4.12/24"", ""ip_version"": 4}, {""cidr"": ""2001::db8::f00/64"", ""ip_version"": 6} ] } } Delete address group ^^^^^^^^^^^^^^^^^^^^^ Deletes an address group. This operation does not return a response body. +----------------+------------------------------------------------+ | Request Type | ``DELETE`` | +----------------+------------------------------------------------+ | Endpoint | ``/fw/address_groups/<address_group_id>`` | +----------------+---------+--------------------------------------+ | | Success | 204 | | Response Codes +---------+--------------------------------------+ | | Error | Unauthorized(401), Not Found(404) | | | | Conflict(409) The Conflict error | | | | response is returned when an | | | | operation is performed while | | | | address group is in use. | +----------------+---------+--------------------------------------+ | **Example Delete address group: JSON request** .. code:: DELETE /v2.0/fw/address_groups/1be5e5f7-c45e-49ba-85da-156575b60d50.json User-Agent: python-neutronclient Accept: application/json **Example Delete address group: JSON response** .. code:: HTTP/1.1 204 No Content Content-Length: 0 List firewall rules ^^^^^^^^^^^^^^^^^^^^ Lists firewall rules. +----------------+------------------------------------------------+ | Request Type | ``GET`` | +----------------+------------------------------------------------+ | Endpoint | ``/fw/firewall_rules`` | +----------------+---------+--------------------------------------+ | | Success | 200 | | Response Codes +---------+--------------------------------------+ | | Error | Unauthorized(401) | +----------------+---------+--------------------------------------+ | **Example List firewall rules: JSON request** .. code:: GET /v2.0/fw/firewall_rules.json User-Agent: python-neutronclient Accept: application/json **Example List firewall rules: JSON response** .. code:: { ""firewall_rules"": [ { ""action"": ""ALLOW"", ""description"": """", ""service_group_id"":""fe99d33c1-b472-44f9-8226-30dc4ffd45332"", ""enabled"": true, ""firewall_policy_id"": ""asd435dg3-b472-44f9-8226-30dc4ffd45332"", ""id"": ""8722e0e0-9cc9-4490-9660-8c9a5732fbb0"", ""name"": ""ALLOW_HTTP"", ""position"": 1, ""public"": false, ""protocol"": ""tcp"", ""source_port"": null, ""destination_port"": null, ""ip_version"": 4, ""source_ip_address"": null, ""destination_ip_address"": null ""source_address_group_id"": null, ""destination_address_group_id"": null, ""source_firewall_group_id"": ""ds876h5t1-b472-44f9-8226-3087j9u953gh2"", ""destination_firewall_group_id"": ""f98o6h5t1-b472-44f9-8226-3087j9u953gh2"", ""project_id"": ""45977fa2dbd7482098dd68d0d8970117"" } ] } Show firewall rule details ^^^^^^^^^^^^^^^^^^^^^^^^^^^ Shows firewall rule details. +----------------+------------------------------------------------+ | Request Type | ``GET`` | +----------------+------------------------------------------------+ | Endpoint | ``/fw/firewall_rules/<firewall_rule_id>`` | +----------------+---------+--------------------------------------+ | | Success | 200 | | Response Codes +---------+--------------------------------------+ | | Error | Unauthorized(401), Forbidden(403), \ | | | | Not Found (404) | +----------------+---------+--------------------------------------+ | **Example Show firewall rule: JSON request** .. code:: GET /v2.0/fw/firewall_rules/9faaf49f-dd89-4e39-a8c6-101839aa49bc.json User-Agent: python-neutronclient Accept: application/json **Example Show firewall rule: JSON response** .. code:: { ""firewall_rule"": { ""action"": ""ALLOW"", ""description"": """", ""service_group_id"":""fe99d33c1-b472-44f9-8226-30dc4ffd45332"", ""enabled"": true, ""firewall_policy_id"": ""asd435dg3-b472-44f9-8226-30dc4ffd45332"", ""id"": ""9faaf49f-dd89-4e39-a8c6-101839aa49bc"", ""name"": ""ALLOW_HTTP"", ""position"": 1, ""public"": false, ""protocol"": ""tcp"", ""source_port"": null, ""destination_port"": null, ""ip_version"": 4, ""source_ip_address"": null, ""destination_ip_address"": null, ""source_address_group_id"": null, ""destination_address_group_id"": ""f9876h5t1-b472-44f9-8226-3087j9u953gh2"", ""source_firewall_group_id"": ""ds876h5t1-b472-44f9-8226-3087j9u953gh2"", ""destination_firewall_group_id"": null, ""project_id"": ""45977fa2dbd7482098dd68d0d8970117"" } } Create firewall rule ^^^^^^^^^^^^^^^^^^^^^ Creates a firewall rule. +----------------+------------------------------------------------+ | Request Type | ``POST`` | +----------------+------------------------------------------------+ | Endpoint | ``/fw/firewall_rules/`` | +----------------+---------+--------------------------------------+ | | Success | 201 | | Response Codes +---------+--------------------------------------+ | | Error | Unauthorized(401), Bad Request(400) | +----------------+---------+--------------------------------------+ | **Example Create firewall rule: JSON request** .. code:: POST /v2.0/fw/firewall_rules.json User-Agent: python-neutronclient Accept: application/json .. code:: { ""firewall_rule"": { ""action"": ""ALLOW"", ""destination_address_group_id"": ""f9876h5t1-b472-44f9-8226-3087j9u953gh2"" ""service_group_id"": ""d2876h5t1-b472-44f9-8245-308dr4u953gh2"" ""enabled"": true, ""name"": ""ALLOW_HTTP"" } } **Example Create firewall rule: JSON response** .. code:: HTTP/1.1 201 Created Content-Type: application/json; charset=UTF-8 .. code:: { ""firewall_rule"": { ""action"": ""ALLOW"", ""description"": """", ""service_group_id"": ""d2876h5t1-b472-44f9-8245-308dr4u953gh2"" ""enabled"": true, ""firewall_policy_id"": null, ""id"": ""8722e0e0-9cc9-4490-9660-8c9a5732fbb0"", ""name"": ""ALLOW_HTTP"", ""position"": 1, ""public"": false, ""protocol"": ""tcp"", ""source_port"": null, ""destination_port"": null, ""ip_version"": 4, ""source_ip_address"": null, ""destination_ip_address"": null, ""source_address_group_id"": null, ""destination_address_group_id"": ""f9876h5t1-b472-44f9-8226-3087j9u953gh2"", ""source_firewall_group_id"": ""ds876h5t1-b472-44f9-8226-3087j9u953gh2"", ""destination_firewall_group_id"": null, ""project_id"": ""45977fa2dbd7482098dd68d0d8970117"" } } Update firewall rule ^^^^^^^^^^^^^^^^^^^^^ Updates a firewall rule. +----------------+------------------------------------------------+ | Request Type | ``PUT`` | +----------------+------------------------------------------------+ | Endpoint | ``/fw/firewall_rules/<firewall_rule_id>`` | +----------------+---------+--------------------------------------+ | | Success | 200 | | Response Codes +---------+--------------------------------------+ | | Error | Unauthorized(401), Bad Request(400) \| | | | Not Found(404) | +----------------+---------+--------------------------------------+ | **Example Update firewall rule: JSON request** .. code:: PUT /v2.0/fw/firewall_rules/41bfef97-af4e-4f6b-a5d3-4678859d2485.json User-Agent: python-neutronclient Accept: application/json .. code:: { ""firewall_rule"": { ""public"": ""true"" } } **Example Update firewall rule: JSON response** .. code:: HTTP/1.1 200 OK Content-Type: application/json; charset=UTF-8 .. code:: { ""firewall_rule"": { ""action"": ""ALLOW"", ""description"": """", ""service_group_id"": ""d2876h5t1-b472-44f9-8245-308dr4u953gh2"" ""enabled"": true, ""firewall_policy_id"": null, ""id"": ""41bfef97-af4e-4f6b-a5d3-4678859d2485"", ""name"": ""ALLOW_HTTP"", ""position"": 1, ""public"": true, ""protocol"": ""tcp"", ""source_port"": null, ""destination_port"": null, ""ip_version"": 4, ""source_ip_address"": null, ""destination_ip_address"": null, ""source_address_group_id"": null, ""destination_address_group_id"": ""f9876h5t1-b472-44f9-8226-3087j9u953gh2"", ""source_firewall_group_id"": ""ds876h5t1-b472-44f9-8226-3087j9u953gh2"", ""destination_firewall_group_id"": null, ""project_id"": ""45977fa2dbd7482098dd68d0d8970117"" } } | Delete firewall rule ^^^^^^^^^^^^^^^^^^^^^ Deletes a firewall rule. This operation does not return a response body. +----------------+------------------------------------------------+ | Request Type | ``DELETE`` | +----------------+------------------------------------------------+ | Endpoint | ``/fw/firewall_rules/<firewall_rule_id>`` | +----------------+---------+--------------------------------------+ | | Success | 204 | | Response Codes +---------+--------------------------------------+ | | Error | Unauthorized(401), Not Found(404) | | | | Conflict(409) The Conflict error | | | | response is returned when an | | | | operation is performed while | | | | firewall rule is in use. | +----------------+---------+--------------------------------------+ | **Example Delete firewall rule: JSON request** .. code:: DELETE /v2.0/fw/firewall_rules/1be5e5f7-c45e-49ba-85da-156575b60d50.json User-Agent: python-neutronclient Accept: application/json **Example Delete firewall rule: JSON response** .. code:: HTTP/1.1 204 No Content Content-Length: 0 List firewall policies ^^^^^^^^^^^^^^^^^^^^^^^ Lists firewall policies. +----------------+------------------------------------------------+ | Request Type | ``GET`` | +----------------+------------------------------------------------+ | Endpoint | ``/fw/firewall_policies`` | +----------------+---------+--------------------------------------+ | | Success | 200 | | Response Codes +---------+--------------------------------------+ | | Error | Unauthorized(401), Forbidden(403) | +----------------+---------+--------------------------------------+ | **Example List firewall policies: JSON request** .. code:: GET /v2.0/fw/firewall_policies.json User-Agent: python-neutronclient Accept: application/json **Example List firewall policies: JSON response** .. code:: { ""firewall_policies"": [ { ""audited"": false, ""description"": """", ""firewall_rules"": [ ""8722e0e0-9cc9-4490-9660-8c9a5732fbb0"" ], ""id"": ""c69933c1-b472-44f9-8226-30dc4ffd454c"", ""name"": ""test-policy"", ""public"": false, ""project_id"": ""45977fa2dbd7482098dd68d0d8970117"" } ] } Show firewall policy details ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ Shows firewall policy details. +----------------+------------------------------------------------+ | Request Type | ``GET`` | +----------------+------------------------------------------------+ | Endpoint | ``/fw/firewall_policies/<firewall_policy_id>`` | +----------------+---------+--------------------------------------+ | | Success | 200 | | Response Codes +---------+--------------------------------------+ | | Error | Unauthorized(401), Not Found(404) | +----------------+---------+--------------------------------------+ | **Example Show firewall policy: JSON request** .. code:: GET /v2.0/fw/firewall_policies/9faaf49f-dd89-4e39-a8c6-101839aa49bc.json User-Agent: python-neutronclient Accept: application/json **Example Show firewall policy: JSON response** .. code:: { ""firewall_policy"": { ""audited"": false, ""description"": """", ""firewall_rules"": [ ""8722e0e0-9cc9-4490-9660-8c9a5732fbb0"" ], ""id"": ""c69933c1-b472-44f9-8226-30dc4ffd454c"", ""name"": ""test-policy"", ""public"": false, ""project_id"": ""45977fa2dbd7482098dd68d0d8970117"" } } Create firewall policy ^^^^^^^^^^^^^^^^^^^^^^^ Creates a firewall policy. +----------------+------------------------------------------------+ | Request Type | ``POST`` | +----------------+------------------------------------------------+ | Endpoint | ``/fw/firewall_policies`` | +----------------+---------+--------------------------------------+ | | Success | 201 | | Response Codes +---------+--------------------------------------+ | | Error | Unauthorized(401) | +----------------+---------+--------------------------------------+ | **Example Create firewall policy: JSON request** .. code:: POST /v2.0/fw/firewall_policies.json User-Agent: python-neutronclient Accept: application/json .. code:: { ""firewall_policy"": { ""firewall_rules"": [ ""8722e0e0-9cc9-4490-9660-8c9a5732fbb0"" ], ""name"": ""test-policy"" } } **Example Create firewall policy: JSON response** .. code:: HTTP/1.1 201 Created Content-Type: application/json; charset=UTF-8 .. code:: { ""firewall_policy"": { ""audited"": false, ""description"": """", ""firewall_rules"": [ ""8722e0e0-9cc9-4490-9660-8c9a5732fbb0"" ], ""id"": ""c69933c1-b472-44f9-8226-30dc4ffd454c"", ""name"": ""test-policy"", ""public"": false, ""project_id"": ""45977fa2dbd7482098dd68d0d8970117"" } } Update firewall policy ^^^^^^^^^^^^^^^^^^^^^^^ Updates a firewall policy. +----------------+------------------------------------------------+ | Request Type | ``PUT`` | +----------------+------------------------------------------------+ | Endpoint | ``/fw/firewall_policies/<firewall_policy_id>`` | +----------------+---------+--------------------------------------+ | | Success | 200 | | Response Codes +---------+--------------------------------------+ | | Error | Unauthorized(401), Not Found (404) | +----------------+---------+--------------------------------------+ | **Example Update firewall policy: JSON request** .. code:: PUT /v2.0/fw/firewall_policies/41bfef97-af4e-4f6b-a5d3-4678859d2485.json User-Agent: python-neutronclient Accept: application/json .. code:: { ""firewall_policy"": { ""firewall_rules"": [ ""a08ef905-0ff6-4784-8374-175fffe7dade"", ""8722e0e0-9cc9-4490-9660-8c9a5732fbb0"" ] } } **Example Update firewall policy: JSON response** .. code:: HTTP/1.1 200 OK Content-Type: application/json; charset=UTF-8 .. code:: { ""firewall_policy"": { ""audited"": false, ""description"": """", ""firewall_rules"": [ ""a08ef905-0ff6-4784-8374-175fffe7dade"", ""8722e0e0-9cc9-4490-9660-8c9a5732fbb0"" ], ""id"": ""c69933c1-b472-44f9-8226-30dc4ffd454c"", ""name"": ""test-policy"", ""public"": false, ""project_id"": ""45977fa2dbd7482098dd68d0d8970117"" } } Delete firewall policy ^^^^^^^^^^^^^^^^^^^^^^^ Deletes a firewall policy. +----------------+------------------------------------------------+ | Request Type | ``DELETE`` | +----------------+------------------------------------------------+ | Endpoint | ``/fw/firewall_policies/<firewall_policy_id>`` | +----------------+---------+--------------------------------------+ | | Success | 204 | | Response Codes +---------+--------------------------------------+ | | Error | Unauthorized(401), Not Found(404) | | | | Conflict(409) The Conflict error | | | | response is returned when an | | | | operation is performed while the | | | | firewall policy is in use. | +----------------+---------+--------------------------------------+ | **Example Delete firewall policy: JSON request** .. code:: DELETE /v2.0/fw/firewall_policies/1be5e5f7-c45e-49ba-85da-156575b60d50.json User-Agent: python-neutronclient Accept: application/json **Example Delete firewall policy: JSON response** .. code:: HTTP/1.1 204 No Content Content-Length: 0 Insert firewall rule in firewall policy ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ Inserts a firewall rule in a firewall policy relative to the position of other rules. +----------------+------------------------------------------------+ | Request Type | ``PUT`` | +----------------+------------------------------------------------+ | Endpoint | ``/fw/firewall_policies/<firewall_policy_id>\ | | | /insert_rule`` | +----------------+---------+--------------------------------------+ | | Success | 200 | | Response Codes +---------+--------------------------------------+ | | Error | Unauthorized(401), Not Found(404) | | | | Bad Request(400) Bad Request error | | | | response is returned when the rule | | | | information is missing, Conflict(409)| +----------------+---------+--------------------------------------+ | **Example Insert firewall rule in firewall policy: JSON request** .. code:: PUT /v2.0/fw/firewall_policies/41bfef97-af4e-4f6b-a5d3-4678859d2485/insert_rule.json User-Agent: python-neutronclient Accept: application/json .. code:: { ""firewall_rule_id"": ""7bc34b8c-8d3b-4ada-a9c8-1f4c11c65692"", ""insert_after"": ""a08ef905-0ff6-4784-8374-175fffe7dade"", ""insert_before"": """" } **Example Insert firewall rule in firewall policy: Response** .. code:: HTTP/1.1 200 OK Content-Type: application/json; charset=UTF-8 .. code:: { ""audited"": false, ""description"": """", ""firewall_rules"": [ ""a08ef905-0ff6-4784-8374-175fffe7dade"", ""7bc34b8c-8d3b-4ada-a9c8-1f4c11c65692"", ""8722e0e0-9cc9-4490-9660-8c9a5732fbb0"" ], ""id"": ""c69933c1-b472-44f9-8226-30dc4ffd454c"", ""name"": ""test-policy"", ""public"": False, ""project_id"": ""45977fa2dbd7482098dd68d0d8970117"" } Note: insert_before and insert_after parameters refer to firewall rule uuids already associated with the firewall policy. firewall_rule_id refers to uuid of the rule being inserted. When using ""insert_after"", if there are any rules after the specified rule, they get shifted down by one to later position. When using ""insert_before"", all rules from the specified rule on get shifted down by one to a later position. Only one of insert_after or insert_before can be non-null and if neither is specified, firewall_rule_is inserted at the first position. Remove firewall rule from firewall policy ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ Removes a firewall rule from a firewall policy. +----------------+------------------------------------------------+ | Request Type | ``PUT`` | +----------------+------------------------------------------------+ | Endpoint | ``/fw/firewall_policies/<firewall_policy_id>\ | | | /remove_rule`` | +----------------+---------+--------------------------------------+ | | Success | 200 | | Response Codes +---------+--------------------------------------+ | | Error | Unauthorized(401), Not Found(404) | | | | Bad Request(400) Bad Request error | | | | response is returned when the rule | | | | information is missing or when a | | | | firewall rule is tried to be | | | | removed from a firewall policy to | | | | which it is not associated. | +----------------+---------+--------------------------------------+ | **Example Remove firewall rule from firewall policy: JSON request** .. code:: PUT /v2.0/fw/firewall_policies/41bfef97-af4e-4f6b-a5d3-4678859d2485/remove_rule.json User-Agent: python-neutronclient Accept: application/json .. code:: { ""firewall_rule_id"": ""7bc34b8c-8d3b-4ada-a9c8-1f4c11c65692"" } **Example Remove firewall rule from firewall policy: JSON response** .. code:: HTTP/1.1 200 OK Content-Type: application/json; charset=UTF-8 .. code:: { ""audited"": false, ""description"": """", ""firewall_rules"": [ ""a08ef905-0ff6-4784-8374-175fffe7dade"", ""8722e0e0-9cc9-4490-9660-8c9a5732fbb0"" ], ""id"": ""c69933c1-b472-44f9-8226-30dc4ffd454c"", ""name"": ""test-policy"", ""public"": false, ""project_id"": ""45977fa2dbd7482098dd68d0d8970117"" } List firewall groups ^^^^^^^^^^^^^^^^^^^^^ Lists firewall groups. +----------------+------------------------------------------------+ | Request Type | ``GET`` | +----------------+------------------------------------------------+ | Endpoint | ``/fw/firewall_groups`` | +----------------+---------+--------------------------------------+ | | Success | 200 | | Response Codes +---------+--------------------------------------+ | | Error | Unauthorized(401) | +----------------+---------+--------------------------------------+ | **Example List firewall groups: JSON request** .. code:: GET /v2.0/fw/firewall_groups.json User-Agent: python-neutronclient Accept: application/json **Example List firewall groups: JSON response** .. code:: { ""firewall_groups"": [ { ""description"": """", ""ingress_firewall_policy_id"": null, ""egress_firewall_policy_id"": null, ""id"": ""8722e0e0-9cc9-4490-9660-8c9a5732fbb0"", ""name"": ""FW_GROUP_1"", ""project_id"": ""45977fa2dbd7482098dd68d0d8970117"", ""ports"":[ ""8722e0e0-9cc9-4490-9660-8c9a5732fbb0"" ], } ] } Show firewall group details ^^^^^^^^^^^^^^^^^^^^^^^^^^^^ Shows firewall group details. +----------------+------------------------------------------------+ | Request Type | ``GET`` | +----------------+------------------------------------------------+ | Endpoint | ``/fw/firewall_groups/<firewall_group_id>`` | +----------------+---------+--------------------------------------+ | | Success | 200 | | Response Codes +---------+--------------------------------------+ | | Error | Unauthorized(401), Forbidden(403), \ | | | | Not Found (404) | +----------------+---------+--------------------------------------+ | **Example Show firewall group: JSON request** .. code:: GET /v2.0/fw/firewall_groups/9faaf49f-dd89-4e39-a8c6-101839aa49bc.json User-Agent: python-neutronclient Accept: application/json **Example Show firewall group: JSON response** .. code:: { ""firewall_group"": { ""description"": """", ""ingress_firewall_policy_id"": null, ""egress_firewall_policy_id"": null, ""id"": ""8722e0e0-9cc9-4490-9660-8c9a5732fbb0"", ""name"": ""FW_GROUP_1"", ""project_id"": ""45977fa2dbd7482098dd68d0d8970117"", ""ports"":[ ""8722e0e0-9cc9-4490-9660-8c9a5732fbb0"" ], } } Create firewall group ^^^^^^^^^^^^^^^^^^^^^^ Creates a firewall group. +----------------+------------------------------------------------+ | Request Type | ``POST`` | +----------------+------------------------------------------------+ | Endpoint | ``/fw/firewall_groups/`` | +----------------+---------+--------------------------------------+ | | Success | 201 | | Response Codes +---------+--------------------------------------+ | | Error | Unauthorized(401), Bad Request(400) | +----------------+---------+--------------------------------------+ | **Example Create firewall group: JSON request** .. code:: POST /v2.0/fw/firewall_groups.json User-Agent: python-neutronclient Accept: application/json .. code:: { ""firewall_rule"": { ""ports"":[ ""8722e0e0-9cc9-4490-9660-8c9a5732fbb0"" ], ""name"": ""FW_GROUP_1"" } } **Example Create firewall group: JSON response** .. code:: HTTP/1.1 201 Created Content-Type: application/json; charset=UTF-8 .. code:: { ""firewall_group"": { ""description"": """", ""ingress_firewall_policy_id"": null, ""egress_firewall_policy_id"": null, ""id"": ""8722e0e0-9cc9-4490-9660-8c9a5732fbb0"", ""name"": ""FW_GROUP_1"", ""project_id"": ""45977fa2dbd7482098dd68d0d8970117"", ""ports"":[ ""8722e0e0-9cc9-4490-9660-8c9a5732fbb0"" ], } } Update firewall group ^^^^^^^^^^^^^^^^^^^^^^^ Updates a firewall group. +----------------+------------------------------------------------+ | Request Type | ``PUT`` | +----------------+------------------------------------------------+ | Endpoint | ``/fw/firewall_groups/<firewall_group_id>`` | +----------------+---------+--------------------------------------+ | | Success | 200 | | Response Codes +---------+--------------------------------------+ | | Error | Unauthorized(401), Bad Request(400) \| | | | Not Found(404) | +----------------+---------+--------------------------------------+ | **Example Update firewall group: JSON request** .. code:: PUT /v2.0/fw/firewall_groups/41bfef97-af4e-4f6b-a5d3-4678859d2485.json User-Agent: python-neutronclient Accept: application/json .. code:: { ""firewall_group"": { ""ingress_firewall_policy_id"": ""f5876h5t1-b472-44f9-8245-308dr4u953gh2"", ""egress_firewall_policy_id"": ""dg476h5t1-b472-44f9-8245-308dr4u953gh2"" } } **Example Update firewall group: JSON response** .. code:: HTTP/1.1 200 OK Content-Type: application/json; charset=UTF-8 .. code:: { ""firewall_group"": { ""description"": """", ""ingress_firewall_policy_id"": ""f5876h5t1-b472-44f9-8245-308dr4u953gh2"", ""egress_firewall_policy_id"": ""dg476h5t1-b472-44f9-8245-308dr4u953gh2"", ""id"": ""8722e0e0-9cc9-4490-9660-8c9a5732fbb0"", ""name"": ""FW_GROUP_1"", ""project_id"": ""45977fa2dbd7482098dd68d0d8970117"", ""ports"":[ ""8722e0e0-9cc9-4490-9660-8c9a5732fbb0"" ], } } Delete firewall group ^^^^^^^^^^^^^^^^^^^^^^^ Deletes a firewall group. This operation does not return a response body. +----------------+------------------------------------------------+ | Request Type | ``DELETE`` | +----------------+------------------------------------------------+ | Endpoint | ``/fw/firewall_groups/<firewall_group_id>`` | +----------------+---------+--------------------------------------+ | | Success | 204 | | Response Codes +---------+--------------------------------------+ | | Error | Unauthorized(401), Not Found(404) | +----------------+---------+--------------------------------------+ | **Example Delete firewall group: JSON request** .. code:: DELETE /v2.0/fw/firewall_groups/1be5e5f7-c45e-49ba-85da-156575b60d50.json User-Agent: python-neutronclient Accept: application/json **Example Delete firewall group: JSON response** .. code:: HTTP/1.1 204 No Content Content-Length: 0 Data Model Impact ------------------ The following are the backend database tables for the REST API proposed above. | | **Firewall Address Groups** +-------------------+---------+-------+------+----------------------------------------+ | Attribute | Type | Req | CRUD | Description | +===================+=========+=======+======+========================================+ | id | uuid-str| N/A | R | Unique identifier for the | | | | | | address_group object. | +-------------------+---------+-------+------+----------------------------------------+ | name | String | No | CRU | Human readable name for the address | | | | | | group (255 characters limit). Does not | | | | | | have to be unique. | +-------------------+---------+-------+------+----------------------------------------+ | description | String | No | CRU | Human readable description for the | | | | | | address group (255 characters limit). | +-------------------+---------+-------+------+----------------------------------------+ | project_id | uuid-str| Yes | CR | Owner of the address group. Only | | | | | | admin users can specify a project | | | | | | identifier other than their own. | +-------------------+---------+-------+------+----------------------------------------+ | | **Firewall Address Group CIDR associations** +-------------------+---------+-------+------+----------------------------------------+ | Attribute | Type | Req | CRUD | Description | +===================+=========+=======+======+========================================+ | id | uuid-str| N/A | R | Unique identifier for the | | | | | | address_group object. | +-------------------+---------+-------+------+----------------------------------------+ | firewall_address | uuid-str| No | CRU | UUID of firewall address group. | | _group_id | | | | | +-------------------+---------+-------+------+----------------------------------------+ | cidr | String | No | CRU | CIDR that has to be associated to the | | | | | | firewall address group. | +-------------------+---------+-------+------+----------------------------------------+ | ip_version | Integer | No | CRU | IP Protocol Version of the cidr. | +-------------------+---------+-------+------+----------------------------------------+ | | **Firewall Rules** +------------------------+------------+-----+------+---------------------------------------+ | Attribute | Type | Req | CRUD | Description | +========================+============+=====+======+=======================================+ | id | uuid-str | N/A | R | Unique identifier for the firewall | | | | | | rule object. | +------------------------+------------+-----+------+---------------------------------------+ | project_id | uuid-str | Yes | CRU | Owner of the firewall rule. Only | | | | | | admin users can specify a project | | | | | | identifier other than their own. | +------------------------+------------+-----+------+---------------------------------------+ | name | String | No | CRU | Human readable name for the firewall | | | | | | rule (255 characters limit). Does | | | | | | not have to be unique. | +------------------------+------------+-----+------+---------------------------------------+ | description | String | No | CRU | Human readable description for the | | | | | | firewall Rule (255 characters limit). | +------------------------+------------+-----+------+---------------------------------------+ | public | Bool | No | CRU | When set to True makes this firewall | | | | | | rule visible to projects other than | | | | | | its owner, and can be used in | | | | | | firewall policies not owned by its | | | | | | project. | +------------------------+------------+-----+------+---------------------------------------+ | protocol | String | No | CRU | IP Protocol. | +------------------------+------------+-----+------+---------------------------------------+ | source_port | port-range | No | CRU | Source port number or a range (an | | | | | | int in [1, 65535] or range in a:b). | +------------------------+------------+-----+------+---------------------------------------+ | destination_port | port-range | No | CRU | Destination port number or a range ( | | | | | | an int in [1, 65535] or range in a:b).| +------------------------+------------+-----+------+---------------------------------------+ | service_group_id | uuid-str | No | CRU | UUID of the service group [6]. | +------------------------+------------+-----+------+---------------------------------------+ | ip_version | Integer | No | CRU | IP Protocol Version. | +------------------------+------------+-----+------+---------------------------------------+ | source_ip_address | String | No | CRU | Source IP address or CIDR. | +------------------------+------------+-----+------+---------------------------------------+ | destination_ip_address | String | No | CRU | Destination IP address or CIDR. | +------------------------+------------+-----+------+---------------------------------------+ | source_address | uuid-str | No | CRU | When a source_address_group is | | _group_id | | | | specified, it is matched when the | | | | | | source IP address in the packet | | | | | | matches one of the IP addresses in | | | | | | the address group. | +------------------------+------------+-----+------+---------------------------------------+ | destination_address | uuid-str | No | CRU | When a destination_address_group is | | _group_id | | | | specified, it is matched when the | | | | | | destination IP address in the packet | | | | | | matches one of the IP addresses in the| | | | | | address group. | +------------------------+------------+-----+------+---------------------------------------+ | source_firewall_group | uuid-str | No | CRU | When a source_firewall_group is | | _id | | | | specified, it is matched when the | | | | | | source IP address in the packet | | | | | | matches an IP address of one of the | | | | | | ports in the firewall group. | +------------------------+------------+-----+------+---------------------------------------+ | destination_firewall | uuid-str | No | CRU | When a destination_firewall_group is | | _group_id | | | | specified, it is matched when the | | | | | | destination IP address in the packet | | | | | | matches an IP address of one of the | | | | | | ports in the firewall group. | +------------------------+------------+-----+------+---------------------------------------+ | action | String | No | CRU | Action to be performed on the | | | | | | traffic matching the rule (ALLOW, | | | | | | DENY, REJECT). Default: DENY. | +------------------------+------------+-----+------+---------------------------------------+ | enabled | Bool | No | CRU | When set to False will disable this | | | | | | rule in the firewall policy. | | | | | | Facilitates selectively turning off | | | | | | rules without having to disassociate | | | | | | the rule from the firewall policy. | | | | | | Default: True. | +------------------------+------------+-----+------+---------------------------------------+ | | **Firewall Policies** +----------------+------------+-----+------+-----------------------------------------+ | Attribute | Type | Req | CRUD | Description | +================+============+=====+======+=========================================+ | id | uuid-str | N/A | R | Unique identifier for the firewall | | | | | | policy object. | +----------------+------------+-----+------+-----------------------------------------+ | project_id | uuid-str | Yes | CR | Owner of the firewall policy. Only | | | | | | admin users can specify a project | | | | | | identifier other than their own. | +----------------+------------+-----+------+-----------------------------------------+ | name | String | No | CRU | Human readable name for the firewall | | | | | | policy (255 characters limit). Does | | | | | | not have to be unique. | +----------------+------------+-----+------+-----------------------------------------+ | description | String | No | CRU | Human readable description for the | | | | | | firewall Policy (255 characters limit). | +----------------+------------+-----+------+-----------------------------------------+ | audited | Bool | No | CRU | When set to True by the policy owner | | | | | | indicates that the firewall policy has | | | | | | been audited. Each time the firewall | | | | | | policy or the associated firewall | | | | | | rules are changed, this attribute will | | | | | | be set to False and will have to be | | | | | | explicitly set to True through an | | | | | | update operation. | +----------------+------------+-----+------+-----------------------------------------+ | public | Bool | No | CRU | When set to True makes this firewall | | | | | | policy visible to projects other than | | | | | | its owner. | +----------------+------------+-----+------+-----------------------------------------+ | | **Firewall Policy Rule associations** +--------------------+---------+-------+------+---------------------------------------+ | Attribute | Type | Req | CRUD | Description | +====================+=========+=======+======+=======================================+ | id | uuid-str| N/A | R | Unique identifier for the | | | | | | firewall_policy_rules object. | +--------------------+---------+-------+------+---------------------------------------+ | firewall_policy_id | uuid-str| No | CRU | UUID of the firewall policy. | +--------------------+---------+-------+------+---------------------------------------+ | firewall_rule_id | uuid-str| No | CRU | UUID of the firewall rule. | +--------------------+---------+-------+------+---------------------------------------+ | position | Integer | No | CRU | This is an attribute that | | | | | | gets assigned to this rule when the | | | | | | rule is associated with a firewall | | | | | | policy. It indicates the position of | | | | | | this rule in that firewall policy. | +--------------------+---------+-------+------+---------------------------------------+ | | **Firewall Groups** +-------------------+---------+-------+------+---------------------------------------+ | Attribute | Type | Req | CRUD | Description | +===================+=========+=======+======+=======================================+ | id | uuid-str| N/A | R | Unique identifier for the firewall | | | | | | group object. | +-------------------+---------+-------+------+---------------------------------------+ | name | string | No | CRU | Human readable name for the firewall | | | | | | group (255 characters limit). Does | | | | | | not have to be unique. | +-------------------+---------+-------+------+---------------------------------------+ | description | string | No | CRU | Human readable description for the | | | | | | firewall group (255 characters limit).| +-------------------+---------+-------+------+---------------------------------------+ | project_id | uuid-str| Yes | CR | Owner of the firewall group. Only | | | | | | admin users can specify a project | | | | | | identifier other than their own. | | | | | | Default: derived from authentication | | | | | | token. | +-------------------+---------+-------+------+---------------------------------------+ | ingress_firewall | uuid-str| No | CRU | 'null' if not associated with any | | _policy_id | | | | firewall policy. | +-------------------+---------+-------+------+---------------------------------------+ | egress_firewall | uuid-str| No | CRU | 'null' if not associated with any | | _policy_id | | | | firewall policy. | +-------------------+---------+-------+------+---------------------------------------+ | | **Firewall Group Port associations** +-------------------+--------+-------+------+---------------------------------------+ | Attribute | Type | Req | CRUD | Description | +===================+========+=======+======+=======================================+ | id | uuid | N/A | R | Unique identifier for the | | | | | | firewall_group_port object. | +-------------------+--------+-------+------+---------------------------------------+ | firewall_group_id | uuid | No | CRU | UUID of the firewall group. | +-------------------+--------+-------+------+---------------------------------------+ | port_id | uuid | No | CRU | UUID of the port that will be | | | | | | associated to this firewall_group. | | | | | | It can be any Neutron port (VM ports, | | | | | | router ports, SFC ports). | +-------------------+--------+-------+------+---------------------------------------+ | | Multiple Firewall Policies --------------------------- When only one firewall group is associated with a specific Neutron port, the firewall rules are evaluated in order according to their position. Both ""allow"" and ""deny"" rules can be interspersed in any order, with the first match determining the action to be taken. The FWaaS 2.0 API allows for multiple firewall group associations for the same Neutron port. For example, one firewall group applied to a tenant's web servers may specify a firewall policy that restricts traffic to HTTP only (intended for north/south traffic), while another firewall group applied to all the tenant's instances may specify a firewall policy that allows all traffic types between sources and destinations in that firewall group (east/west traffic). When there are multiple firewall groups associated with a specific Neutron port, there is no position or priority between the different firewall groups. Some deterministic behavior must be defined in order to resolve the action to be taken when some firewall groups determine an ""allow"" action while other firewall groups determine a ""deny"" action. This spec defines that packets will be allowed if any one of the firewall groups associated with that Neutron port allows the packet. This behavior is similar to the case of multiple Security Groups associated with the same VM port. In future phases, new constructs will be proposed that will allow for for a ""deny"" action determined by one firewall group to override an ""allow"" action determined by a different firewall group in some cases, depending on how the firewall groups are associated with the Neutron port. Refer ""Stratum"" section in [3] for further details. Security Impact --------------- * **TBD** Notifications Impact -------------------- None. Other End User Impact --------------------- In case of DVR, router ports other than north-facing router ports will not be supported. The asymmetric design of the DVR data plane for east/west traffic prevents the use of connection tracking, which is essential for proper FWaaS operation. The workaround in order to apply FWaaS to east/west traffic is to enforce FWaaS at VM ports rather than router ports. Enforcement of FWaaS at VM ports seems to be better aligned with the distributed architecture of DVR, regardless of this restriction. Performance Impact ------------------ TBD. IPv6 Impact ----------- None Other Deployer Impact --------------------- * We will need new Heat models. Developer Impact ---------------- None. Community Impact ---------------- None. Alternatives ------------ None. Implementation ============== Assignee(s) ----------- Primary assignee: * Sean M. Collins Other contributors: * Aishwarya Thangappa * German Eichberger * James Ardent * Mickey Spiegel * Sridhar Kandaswamy Work Items ---------- * REST API * DB Schema * CLI update Dependencies ============ * Depends on the Service Groups [6] Testing ======= Tempest Tests -------------- * DB mixin and schema tests * FWaaS Plugin with mocked driver end-to-end tests * Tempest tests * CLI tests Functional Tests ---------------- * New tests need to be written API Tests --------- * REST API and attributes validation tests Documentation Impact ==================== User Documentation ------------------- * Neutron CLI and FWaaS API documentation have to be modified. Developer Documentation ----------------------- * neutron-fwaas repo will have a devref and documentation will be written. References =========== [1] https://www.openstack.org/summit/tokyo-2015/videos/presentation/openstack-neutron-fwaas-roadmap [2] https://etherpad.openstack.org/p/mitaka-neutron-next-adv-services [3] https://etherpad.openstack.org/p/fwaas-api-evolution-spec [4] https://etherpad.openstack.org/p/FWaaS_with_DVR [5] https://bugs.launchpad.net/neutron/+bug/1513574 [6] http://specs.openstack.org/openstack/neutron-specs/specs/kilo/service-group.html [7] http://developer.openstack.org/api-ref-networking-v2-ext.html#security_groups ",,2036,0
openstack%2Fneutron-fwaas~master~Iad3317ca3f53e784ac13879981e0483e96919636,openstack/neutron-fwaas,master,Iad3317ca3f53e784ac13879981e0483e96919636,"[WIP] Add ""position"" to the REST API for firewall_rule",ABANDONED,2016-01-07 00:43:17.000000000,2016-08-29 17:37:50.000000000,,"[{'_account_id': 3}, {'_account_id': 4656}, {'_account_id': 10692}, {'_account_id': 13995}, {'_account_id': 16806}]","[{'number': 1, 'created': '2016-01-07 00:43:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-fwaas/commit/921553e3242f5961840280c404b0132290691511', 'message': '[WIP] Add ""posiiton"" to the REST API for firewall_rule\n\nIt was missing from the spec\n\nChange-Id: Iad3317ca3f53e784ac13879981e0483e96919636\n'}, {'number': 2, 'created': '2016-01-07 02:34:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-fwaas/commit/c0a7c8f4eb7cf52cf0d9d24cd99ebc09f502484f', 'message': '[WIP] Add ""position"" to the REST API for firewall_rule\n\nIt was missing from the spec\n\nChange-Id: Iad3317ca3f53e784ac13879981e0483e96919636\n'}, {'number': 3, 'created': '2016-05-03 16:20:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-fwaas/commit/42a08c43dbe72aeda47b69c09f4569df6ba7be38', 'message': '[WIP] Add ""position"" to the REST API for firewall_rule\n\nIt was missing from the spec\n\nChange-Id: Iad3317ca3f53e784ac13879981e0483e96919636\n'}, {'number': 4, 'created': '2016-05-25 19:16:12.000000000', 'files': ['doc/source/fwaas-api-2.0.rst'], 'web_link': 'https://opendev.org/openstack/neutron-fwaas/commit/447f73d547db6162f79c09c77a5d4c37ac6cd4e1', 'message': '[WIP] Add ""position"" to the REST API for firewall_rule\n\nIt was missing from the spec\n\nChange-Id: Iad3317ca3f53e784ac13879981e0483e96919636\n'}]",0,264488,447f73d547db6162f79c09c77a5d4c37ac6cd4e1,19,5,4,4656,,,0,"[WIP] Add ""position"" to the REST API for firewall_rule

It was missing from the spec

Change-Id: Iad3317ca3f53e784ac13879981e0483e96919636
",git fetch https://review.opendev.org/openstack/neutron-fwaas refs/changes/88/264488/2 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/fwaas-api-2.0.rst'],1,921553e3242f5961840280c404b0132290691511,fwaas_v2_api,"| position | String | No | CRU | Indicates the position of a rule | | | | | | within the associated policy, | | | | | | and the order in which rules are | | | | | | evaluated. | | | | | | | +------------------------+------------+-----+------+---------------------------------------+", |,6,2
openstack%2Fopenstack-ansible-os_keystone~master~Ib339cd0657f7008fa48bf74f8d6ddd4b8add2ea1,openstack/openstack-ansible-os_keystone,master,Ib339cd0657f7008fa48bf74f8d6ddd4b8add2ea1,Implement CentOS 7 support in os_keystone,MERGED,2016-05-24 04:10:25.000000000,2016-08-29 17:37:10.000000000,2016-08-29 17:37:10.000000000,"[{'_account_id': 3}, {'_account_id': 538}, {'_account_id': 6816}, {'_account_id': 7353}, {'_account_id': 13095}, {'_account_id': 14805}, {'_account_id': 19814}]","[{'number': 1, 'created': '2016-05-24 04:10:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_keystone/commit/c511d353eaee6238bd76aa5a3e7c2b27dbaefb34', 'message': 'Implement CentOS 7 support in os_keystone\n\nThis change implements CentOS 7 support within the os_keystone role.\n\nChange-Id: Ib339cd0657f7008fa48bf74f8d6ddd4b8add2ea1\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 2, 'created': '2016-05-24 04:54:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_keystone/commit/f5637a12f6e3e248e2cd1a4de3249004a10ba90b', 'message': 'Implement CentOS 7 support in os_keystone\n\nThis change implements CentOS 7 support within the os_keystone role.\n\nChange-Id: Ib339cd0657f7008fa48bf74f8d6ddd4b8add2ea1\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 3, 'created': '2016-05-24 04:58:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_keystone/commit/3825f42a3efe9a772e49610f0a18409b68908e98', 'message': 'Implement CentOS 7 support in os_keystone\n\nThis change implements CentOS 7 support within the os_keystone role.\n\nChange-Id: Ib339cd0657f7008fa48bf74f8d6ddd4b8add2ea1\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 4, 'created': '2016-05-24 05:05:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_keystone/commit/921570bbd52c56401f9bb9b4f49c3b0ed07521a7', 'message': 'Implement CentOS 7 support in os_keystone\n\nThis change implements CentOS 7 support within the os_keystone role.\n\nChange-Id: Ib339cd0657f7008fa48bf74f8d6ddd4b8add2ea1\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 5, 'created': '2016-05-24 05:20:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_keystone/commit/0fa7f59064628517e273e3122f013ebbd0a6bf04', 'message': 'Implement CentOS 7 support in os_keystone\n\nThis change implements CentOS 7 support within the os_keystone role.\n\nChange-Id: Ib339cd0657f7008fa48bf74f8d6ddd4b8add2ea1\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 6, 'created': '2016-05-24 13:38:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_keystone/commit/e3910016d88f06ba1d4f66a09ad6a7d987ee38dc', 'message': 'Implement CentOS 7 support in os_keystone\n\nThis change implements CentOS 7 support within the os_keystone role.\n\nChange-Id: Ib339cd0657f7008fa48bf74f8d6ddd4b8add2ea1\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 7, 'created': '2016-05-24 15:32:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_keystone/commit/fda054c3dabf4e41a1a85df35c0fe3999554b274', 'message': 'Implement CentOS 7 support in os_keystone\n\nThis change implements CentOS 7 support within the os_keystone role.\n\nDepends-on: I7e889ea4653a6972ea7f8208416fc1fc3db45e5c\nChange-Id: Ib339cd0657f7008fa48bf74f8d6ddd4b8add2ea1\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 8, 'created': '2016-05-25 04:17:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_keystone/commit/190a4d6dc52f207ac57506b7276d4b867934d2fa', 'message': 'Implement CentOS 7 support in os_keystone\n\nThis change implements CentOS 7 support within the os_keystone role.\n\nDepends-on: I7e889ea4653a6972ea7f8208416fc1fc3db45e5c\nChange-Id: Ib339cd0657f7008fa48bf74f8d6ddd4b8add2ea1\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 9, 'created': '2016-05-25 05:26:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_keystone/commit/c35e0ac5ce7dee1ba5603df9ff94945778d2c0e4', 'message': 'Implement CentOS 7 support in os_keystone\n\nThis change implements CentOS 7 support within the os_keystone role.\n\nDepends-on: I7e889ea4653a6972ea7f8208416fc1fc3db45e5c\nChange-Id: Ib339cd0657f7008fa48bf74f8d6ddd4b8add2ea1\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 10, 'created': '2016-06-01 17:44:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_keystone/commit/e270c21c1e798da7419fc01369f559029f1e956d', 'message': 'Implement CentOS 7 support in os_keystone\n\nThis change implements CentOS 7 support within the os_keystone role.\n\nDepends-on: I7e889ea4653a6972ea7f8208416fc1fc3db45e5c\nChange-Id: Ib339cd0657f7008fa48bf74f8d6ddd4b8add2ea1\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 11, 'created': '2016-06-03 05:45:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_keystone/commit/42ae2bf86f01ffbed4e3b38764669bdbbbaf3781', 'message': 'Implement CentOS 7 support in os_keystone\n\nThis change implements CentOS 7 support within the os_keystone role.\n\nDepends-on: I333fb1887339e8dc9ebf10ff137dda3cff629dc0\nChange-Id: Ib339cd0657f7008fa48bf74f8d6ddd4b8add2ea1\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 12, 'created': '2016-06-04 12:51:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_keystone/commit/80981607e470ef387aa40825ba0bc200d0a7cbfe', 'message': 'Implement CentOS 7 support in os_keystone\n\nThis change implements CentOS 7 support within the os_keystone role.\n\nDepends-on: I333fb1887339e8dc9ebf10ff137dda3cff629dc0\nChange-Id: Ib339cd0657f7008fa48bf74f8d6ddd4b8add2ea1\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 13, 'created': '2016-06-23 16:12:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_keystone/commit/3678568c9abca872917620938245e31709f94f32', 'message': 'Implement CentOS 7 support in os_keystone\n\nThis change implements CentOS 7 support within the os_keystone role.\n\nDepends-on: I333fb1887339e8dc9ebf10ff137dda3cff629dc0\nChange-Id: Ib339cd0657f7008fa48bf74f8d6ddd4b8add2ea1\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 14, 'created': '2016-06-24 05:24:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_keystone/commit/fd833903af2068b3e95b48278e7e6e96c9029caa', 'message': 'Implement CentOS 7 support in os_keystone\n\nThis change implements CentOS 7 support within the os_keystone role.\n\nDepends-on: I333fb1887339e8dc9ebf10ff137dda3cff629dc0\nChange-Id: Ib339cd0657f7008fa48bf74f8d6ddd4b8add2ea1\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 15, 'created': '2016-07-07 17:43:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_keystone/commit/bf4b28ff9235abbaefc849559b913f2a6ca9e774', 'message': 'Implement CentOS 7 support in os_keystone\n\nThis change implements CentOS 7 support within the os_keystone role.\n\nDepends-on: I333fb1887339e8dc9ebf10ff137dda3cff629dc0\nChange-Id: Ib339cd0657f7008fa48bf74f8d6ddd4b8add2ea1\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 16, 'created': '2016-07-12 00:08:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_keystone/commit/802bc8db2342e4db69bf9f433618f4fd89168397', 'message': 'Implement CentOS 7 support in os_keystone\n\nThis change implements CentOS 7 support within the os_keystone role.\n\nDepends-on: I333fb1887339e8dc9ebf10ff137dda3cff629dc0\nChange-Id: Ib339cd0657f7008fa48bf74f8d6ddd4b8add2ea1\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 17, 'created': '2016-07-25 16:12:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_keystone/commit/3e76dce928919c179d75fc9eb8ce33a252751d7d', 'message': 'Implement CentOS 7 support in os_keystone\n\nThis change implements CentOS 7 support within the os_keystone role.\n\nDepends-on: I333fb1887339e8dc9ebf10ff137dda3cff629dc0\nChange-Id: Ib339cd0657f7008fa48bf74f8d6ddd4b8add2ea1\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 18, 'created': '2016-07-25 20:49:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_keystone/commit/861c0205f8bcf5562d7a8c72acc7babc0d43a25b', 'message': 'Implement CentOS 7 support in os_keystone\n\nThis change implements CentOS 7 support within the os_keystone role.\n\nDepends-on: I333fb1887339e8dc9ebf10ff137dda3cff629dc0\nChange-Id: Ib339cd0657f7008fa48bf74f8d6ddd4b8add2ea1\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 19, 'created': '2016-07-26 22:34:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_keystone/commit/12f5ff3c6652ca82329d0d693639c08884c926da', 'message': 'Implement CentOS 7 support in os_keystone\n\nThis change implements CentOS 7 support within the os_keystone role.\n\nDepends-on: I333fb1887339e8dc9ebf10ff137dda3cff629dc0\nChange-Id: Ib339cd0657f7008fa48bf74f8d6ddd4b8add2ea1\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 20, 'created': '2016-08-02 13:43:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_keystone/commit/62d42e6ef09b95caa9731b958a01771282a617d9', 'message': 'Implement CentOS 7 support in os_keystone\n\nThis change implements CentOS 7 support within the os_keystone role.\n\nDepends-on: I333fb1887339e8dc9ebf10ff137dda3cff629dc0\nChange-Id: Ib339cd0657f7008fa48bf74f8d6ddd4b8add2ea1\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 21, 'created': '2016-08-02 13:49:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_keystone/commit/bdc533966310a392820cfef35d8e71e8cbbc985e', 'message': 'Implement CentOS 7 support in os_keystone\n\nThis change implements CentOS 7 support within the os_keystone role.\n\nDepends-on: I333fb1887339e8dc9ebf10ff137dda3cff629dc0\nChange-Id: Ib339cd0657f7008fa48bf74f8d6ddd4b8add2ea1\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 22, 'created': '2016-08-05 03:52:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_keystone/commit/546d10c10fc9cc024fb02b55369a013dc87dfcca', 'message': 'Implement CentOS 7 support in os_keystone\n\nThis change implements CentOS 7 support within the os_keystone role.\n\nDepends-on: I333fb1887339e8dc9ebf10ff137dda3cff629dc0\nChange-Id: Ib339cd0657f7008fa48bf74f8d6ddd4b8add2ea1\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 23, 'created': '2016-08-06 04:53:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_keystone/commit/45b6718d8e34b2c729ff8be25b6c1128b8b95b0a', 'message': 'Implement CentOS 7 support in os_keystone\n\nThis change implements CentOS 7 support within the os_keystone role.\n\nDepends-on: I333fb1887339e8dc9ebf10ff137dda3cff629dc0\nChange-Id: Ib339cd0657f7008fa48bf74f8d6ddd4b8add2ea1\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 24, 'created': '2016-08-10 14:52:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_keystone/commit/aff70fd4dc8c61f8a92e2953182395e8fb8d9a11', 'message': 'Implement CentOS 7 support in os_keystone\n\nThis change implements CentOS 7 support within the os_keystone role.\n\nDepends-on: I333fb1887339e8dc9ebf10ff137dda3cff629dc0\nChange-Id: Ib339cd0657f7008fa48bf74f8d6ddd4b8add2ea1\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 25, 'created': '2016-08-14 00:24:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_keystone/commit/8c73c496f90addc397d77c2ade75c5534c04f269', 'message': 'Implement CentOS 7 support in os_keystone\n\nThis change implements CentOS 7 support within the os_keystone role.\n\nDepends-on: I333fb1887339e8dc9ebf10ff137dda3cff629dc0\nChange-Id: Ib339cd0657f7008fa48bf74f8d6ddd4b8add2ea1\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 26, 'created': '2016-08-18 14:10:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_keystone/commit/d0eebb2563e7395cb119c784f5f17953fc2a3d43', 'message': 'Implement CentOS 7 support in os_keystone\n\nThis change implements CentOS 7 support within the os_keystone role.\n\nDepends-on: I333fb1887339e8dc9ebf10ff137dda3cff629dc0\nChange-Id: Ib339cd0657f7008fa48bf74f8d6ddd4b8add2ea1\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 27, 'created': '2016-08-18 14:52:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_keystone/commit/e47f9b78e3db69f9645ad09692709f09c9137a9d', 'message': 'Implement CentOS 7 support in os_keystone\n\nThis change implements CentOS 7 support within the os_keystone role.\n\nDepends-on: I333fb1887339e8dc9ebf10ff137dda3cff629dc0\nChange-Id: Ib339cd0657f7008fa48bf74f8d6ddd4b8add2ea1\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 28, 'created': '2016-08-18 15:25:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_keystone/commit/fe151754b8aea1b44ce0972b04c9be7e95335127', 'message': 'Implement CentOS 7 support in os_keystone\n\nThis change implements CentOS 7 support within the os_keystone role.\n\nDepends-on: I333fb1887339e8dc9ebf10ff137dda3cff629dc0\nChange-Id: Ib339cd0657f7008fa48bf74f8d6ddd4b8add2ea1\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 29, 'created': '2016-08-18 17:34:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_keystone/commit/bc362b3bcb3704eeb2dcfff372bace197f32e93a', 'message': 'Implement CentOS 7 support in os_keystone\n\nThis change implements CentOS 7 support within the os_keystone role.\n\nDepends-on: I333fb1887339e8dc9ebf10ff137dda3cff629dc0\nChange-Id: Ib339cd0657f7008fa48bf74f8d6ddd4b8add2ea1\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 30, 'created': '2016-08-18 23:55:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_keystone/commit/c29e7d1a1e41be8812095fdef849ad7f1bbc57bb', 'message': 'Implement CentOS 7 support in os_keystone\n\nThis change implements CentOS 7 support within the os_keystone role.\n\nDepends-on: I333fb1887339e8dc9ebf10ff137dda3cff629dc0\nChange-Id: Ib339cd0657f7008fa48bf74f8d6ddd4b8add2ea1\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 31, 'created': '2016-08-22 04:33:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_keystone/commit/ebd8f86db07743de341e2412c39319a5ab9d3ba4', 'message': 'Implement CentOS 7 support in os_keystone\n\nThis change implements CentOS 7 support within the os_keystone role.\n\nDepends-on: I333fb1887339e8dc9ebf10ff137dda3cff629dc0\nChange-Id: Ib339cd0657f7008fa48bf74f8d6ddd4b8add2ea1\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 32, 'created': '2016-08-22 05:28:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_keystone/commit/a09cdb3850683b03110c8983cc306ad533299a11', 'message': 'Implement CentOS 7 support in os_keystone\n\nThis change implements CentOS 7 support within the os_keystone role.\n\nDepends-on: I333fb1887339e8dc9ebf10ff137dda3cff629dc0\nChange-Id: Ib339cd0657f7008fa48bf74f8d6ddd4b8add2ea1\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 33, 'created': '2016-08-22 06:38:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_keystone/commit/0c395385ed4763f1931259ed53621f16975a0e32', 'message': 'Implement CentOS 7 support in os_keystone\n\nThis change implements CentOS 7 support within the os_keystone role.\n\nDepends-on: I333fb1887339e8dc9ebf10ff137dda3cff629dc0\nChange-Id: Ib339cd0657f7008fa48bf74f8d6ddd4b8add2ea1\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 34, 'created': '2016-08-22 15:18:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_keystone/commit/198328ece0605c26f8cd3e60cc09a343ffb66f3d', 'message': 'Implement CentOS 7 support in os_keystone\n\nThis change implements CentOS 7 support within the os_keystone role.\n\nDepends-on: I333fb1887339e8dc9ebf10ff137dda3cff629dc0\nChange-Id: Ib339cd0657f7008fa48bf74f8d6ddd4b8add2ea1\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 35, 'created': '2016-08-22 16:47:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_keystone/commit/bb140f338677f3aec0f67e7f82a0ad5de61a07c8', 'message': 'Implement CentOS 7 support in os_keystone\n\nThis change implements CentOS 7 support within the os_keystone role.\n\nDepends-on: I333fb1887339e8dc9ebf10ff137dda3cff629dc0\nChange-Id: Ib339cd0657f7008fa48bf74f8d6ddd4b8add2ea1\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 36, 'created': '2016-08-22 20:08:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_keystone/commit/e232c5fe71877142c903dd048e39880f0c9f5578', 'message': 'Implement CentOS 7 support in os_keystone\n\nThis change implements CentOS 7 support within the os_keystone role.\n\nDepends-on: I333fb1887339e8dc9ebf10ff137dda3cff629dc0\nChange-Id: Ib339cd0657f7008fa48bf74f8d6ddd4b8add2ea1\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 37, 'created': '2016-08-22 20:23:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_keystone/commit/05f160f1294132b6e6098d1da3a0a1efd13c8167', 'message': 'Implement CentOS 7 support in os_keystone\n\nThis change implements CentOS 7 support within the os_keystone role.\n\nDepends-on: I333fb1887339e8dc9ebf10ff137dda3cff629dc0\nChange-Id: Ib339cd0657f7008fa48bf74f8d6ddd4b8add2ea1\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 38, 'created': '2016-08-22 20:45:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_keystone/commit/fda63ccfbba2cc091aa915dc3d0344ae347b50ff', 'message': 'Implement CentOS 7 support in os_keystone\n\nThis change implements CentOS 7 support within the os_keystone role.\n\nDepends-on: I333fb1887339e8dc9ebf10ff137dda3cff629dc0\nChange-Id: Ib339cd0657f7008fa48bf74f8d6ddd4b8add2ea1\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 39, 'created': '2016-08-23 04:46:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_keystone/commit/24df37075c352e20038aaeedf202f32567cbf76f', 'message': 'Implement CentOS 7 support in os_keystone\n\nThis change implements CentOS 7 support within the os_keystone role.\n\nDepends-on: I333fb1887339e8dc9ebf10ff137dda3cff629dc0\nChange-Id: Ib339cd0657f7008fa48bf74f8d6ddd4b8add2ea1\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 40, 'created': '2016-08-24 23:34:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_keystone/commit/59732cf456fccc249784bd14cca596ace427ea3d', 'message': 'Implement CentOS 7 support in os_keystone\n\nThis change implements CentOS 7 support within the os_keystone role.\n\nDepends-on: I333fb1887339e8dc9ebf10ff137dda3cff629dc0\nChange-Id: Ib339cd0657f7008fa48bf74f8d6ddd4b8add2ea1\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 41, 'created': '2016-08-25 22:25:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_keystone/commit/c1232619124fd459d83e90acd0cb8b09f94fa357', 'message': 'Implement CentOS 7 support in os_keystone\n\nThis change implements CentOS 7 support within the os_keystone role.\n\nDepends-on: I333fb1887339e8dc9ebf10ff137dda3cff629dc0\nChange-Id: Ib339cd0657f7008fa48bf74f8d6ddd4b8add2ea1\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 42, 'created': '2016-08-26 00:00:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_keystone/commit/49eaab27fb472736e793f773c62bdab82e1fdfdf', 'message': 'Implement CentOS 7 support in os_keystone\n\nThis change implements CentOS 7 support within the os_keystone role.\n\nDepends-on: I333fb1887339e8dc9ebf10ff137dda3cff629dc0\nChange-Id: Ib339cd0657f7008fa48bf74f8d6ddd4b8add2ea1\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 43, 'created': '2016-08-26 14:21:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_keystone/commit/d46178617c5cc5292984fca0b9765d988181667d', 'message': 'Implement CentOS 7 support in os_keystone\n\nThis change implements CentOS 7 support within the os_keystone role.\n\nDepends-on: I333fb1887339e8dc9ebf10ff137dda3cff629dc0\nChange-Id: Ib339cd0657f7008fa48bf74f8d6ddd4b8add2ea1\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 44, 'created': '2016-08-29 14:20:52.000000000', 'files': ['tasks/main.yml', 'tasks/keystone_key_distribute.yml', 'vars/ubuntu-14.04.yml', 'vars/ubuntu-16.04.yml', 'defaults/main.yml', 'tasks/keystone_apache.yml', 'releasenotes/notes/os_keystone-centos7-support-0a5d97f81ac42e44.yaml', 'tests/test-prepare-containers.yml', 'vars/redhat-7.yml', 'tasks/keystone_install.yml', 'tests/test-install-keystone.yml', 'tasks/keystone_ssl_key_create.yml', 'tasks/keystone_idp_self_signed_distribute.yml', 'tasks/keystone_ssl_user_provided.yml', 'tasks/keystone_federation_sp_setup.yml', 'tasks/keystone_idp_self_signed_create.yml', 'tasks/keystone_install_yum.yml', 'tests/test-prepare-host.yml', 'templates/keystone-httpd.conf.j2', 'manual-test.rc', 'handlers/main.yml', 'tests/test-vars.yml', 'tasks/keystone_idp_metadata.yml', 'tasks/keystone_install_apt.yml', 'tasks/keystone_post_install.yml', 'tasks/keystone_ldap_setup.yml', 'tox.ini', 'meta/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_keystone/commit/0de819e92afdb67bd6babf1502c5e463d8c4ed57', 'message': 'Implement CentOS 7 support in os_keystone\n\nThis change implements CentOS 7 support within the os_keystone role.\n\nDepends-on: I333fb1887339e8dc9ebf10ff137dda3cff629dc0\nChange-Id: Ib339cd0657f7008fa48bf74f8d6ddd4b8add2ea1\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}]",13,320216,0de819e92afdb67bd6babf1502c5e463d8c4ed57,162,7,44,7353,,,0,"Implement CentOS 7 support in os_keystone

This change implements CentOS 7 support within the os_keystone role.

Depends-on: I333fb1887339e8dc9ebf10ff137dda3cff629dc0
Change-Id: Ib339cd0657f7008fa48bf74f8d6ddd4b8add2ea1
Signed-off-by: Kevin Carter <kevin.carter@rackspace.com>
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_keystone refs/changes/16/320216/35 && git format-patch -1 --stdout FETCH_HEAD,"['tasks/keystone_install_apt.yml', 'vars/redhat-7.yml', 'tasks/keystone_install.yml', 'vars/ubuntu-14.04.yml', 'vars/ubuntu-16.04.yml', 'defaults/main.yml', 'meta/main.yml', 'releasenotes/notes/os_keystone-centos7-support-0a5d97f81ac42e44.yaml', 'tasks/keystone_install_yum.yml']",9,c511d353eaee6238bd76aa5a3e7c2b27dbaefb34,bp/multi-platform-host,"--- # Copyright 2016, Rackspace US, Inc. # # Licensed under the Apache License, Version 2.0 (the ""License""); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. - name: Install yum packages yum: pkg: ""{{ item }}"" state: latest register: install_packages until: install_packages|success retries: 5 delay: 2 with_items: keystone_packages tags: - keystone-install - keystone-yum-packages - name: Install IdP yum packages yum: pkg: ""{{ item }}"" state: latest register: install_packages until: install_packages|success retries: 5 delay: 2 with_items: keystone_idp_packages when: keystone_idp is defined tags: - keystone-install - keystone-yum-packages #TODO(cloudnull) Remove this task once we move to Ansible 2.1 # where we can leverage the `yum_repository` module: # https://docs.ansible.com/ansible/yum_repository_module.html - name: Add shibboleth repo copy: content: | [{{ item.name }}] name={{ item.name }} description={{ item.description }} baseurl={{ item.baseurl }} gpgkey={{ item.gpgkey }} gpgcheck=1 enabled=1 dest: ""/etc/yum.repos.d/{{ item.file }}.repo"" register: add_repos until: add_repos|success retries: 5 delay: 2 with_items: - ""{{ keystone_shibboleth_repo }}"" when: keystone_sp is defined tags: - keystone-sp-repos - name: Install SP yum packages yum: pkg: ""{{ item }}"" state: latest register: install_packages until: install_packages|success retries: 5 delay: 2 with_items: keystone_sp_packages when: keystone_sp is defined tags: - keystone-install - keystone-yum-packages - name: Install developer mode yum packages yum: pkg: ""{{ item }}"" state: latest register: install_packages until: install_packages|success retries: 5 delay: 2 with_items: keystone_developer_packages when: - keystone_developer_mode | bool tags: - keystone-install - keystone-yum-packages ",,176,21
openstack%2Fneutron-vpnaas~master~I73a1ed5cb3906f10ffd3c52e17c498c04450432f,openstack/neutron-vpnaas,master,I73a1ed5cb3906f10ffd3c52e17c498c04450432f,DO NOT MERGE,ABANDONED,2016-08-29 11:47:01.000000000,2016-08-29 17:31:56.000000000,,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2016-08-29 11:47:01.000000000', 'files': ['neutron_vpnaas/extensions/vpnaas.py'], 'web_link': 'https://opendev.org/openstack/neutron-vpnaas/commit/63c8ea853b90d96aaf3e76bce270e4bb045b029d', 'message': 'DO NOT MERGE\n\nJust testing dependency.\n\nChange-Id: I73a1ed5cb3906f10ffd3c52e17c498c04450432f\nDepends-On: I509e000f2250fd045c5a82d2324e69681be06fe1\n'}]",0,362042,63c8ea853b90d96aaf3e76bce270e4bb045b029d,6,2,1,6547,,,0,"DO NOT MERGE

Just testing dependency.

Change-Id: I73a1ed5cb3906f10ffd3c52e17c498c04450432f
Depends-On: I509e000f2250fd045c5a82d2324e69681be06fe1
",git fetch https://review.opendev.org/openstack/neutron-vpnaas refs/changes/42/362042/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron_vpnaas/extensions/vpnaas.py'],1,63c8ea853b90d96aaf3e76bce270e4bb045b029d,broken,# Random comment ,,2,0
openstack%2Fproject-config~master~I32663f069a45f76943a9f9490563916464f0143e,openstack/project-config,master,I32663f069a45f76943a9f9490563916464f0143e,add gate_hook for networking-sfc tempest tests.,ABANDONED,2016-08-27 07:22:05.000000000,2016-08-29 17:28:39.000000000,,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 7776}, {'_account_id': 11313}]","[{'number': 1, 'created': '2016-08-27 07:22:05.000000000', 'files': ['jenkins/jobs/networking-sfc.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/474d23827f27ebfaf180eae557a46d88080d938e', 'message': 'add gate_hook for networking-sfc tempest tests.\n\nChange-Id: I32663f069a45f76943a9f9490563916464f0143e\n'}]",0,361569,474d23827f27ebfaf180eae557a46d88080d938e,7,4,1,17540,,,0,"add gate_hook for networking-sfc tempest tests.

Change-Id: I32663f069a45f76943a9f9490563916464f0143e
",git fetch https://review.opendev.org/openstack/project-config refs/changes/69/361569/1 && git format-patch -1 --stdout FETCH_HEAD,['jenkins/jobs/networking-sfc.yaml'],1,474d23827f27ebfaf180eae557a46d88080d938e,networking-sfc, function gate_hook {{ if [ -f $BASE/new/neutron/neutron/tests/contrib/gate_hook.sh ] ; then bash -xe $BASE/new/neutron/neutron/tests/contrib/gate_hook.sh dsvm-fullstack fi }} export -f gate_hook ,,7,0
openstack%2Fsyntribos~master~I4928926aa42b568502bd0b99b15b06d0667968ca,openstack/syntribos,master,I4928926aa42b568502bd0b99b15b06d0667968ca,Buffer Overflow data file dependency is removed,MERGED,2016-08-25 13:46:57.000000000,2016-08-29 17:15:02.000000000,2016-08-29 17:13:01.000000000,"[{'_account_id': 3}, {'_account_id': 15515}, {'_account_id': 17709}, {'_account_id': 18462}, {'_account_id': 22221}, {'_account_id': 22781}]","[{'number': 1, 'created': '2016-08-25 13:46:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/syntribos/commit/22373b130b9ec306a32713a9af2f0009ca864a72', 'message': 'Buffer Overflow data file dependency is removed\n\nThe data file buffer-overflow.txt is never used, instead the string\ngenerated in buffer_overflow.py is used for testing buffer overflow,\nso the text file dependency is removed.\n\nChange-Id: I4928926aa42b568502bd0b99b15b06d0667968ca\n'}, {'number': 2, 'created': '2016-08-26 15:52:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/syntribos/commit/27b57a371b82b97e2065e1db3fa43f4cefba5492', 'message': 'Buffer Overflow data file dependency is removed\n\nThe data file buffer-overflow.txt is never used, instead the string\ngenerated in buffer_overflow.py is used for testing buffer overflow,\nso the text file dependency is removed.\n\nChange-Id: I4928926aa42b568502bd0b99b15b06d0667968ca\n'}, {'number': 3, 'created': '2016-08-26 19:31:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/syntribos/commit/f2687ae0625bfd4dfcbd106ef3e5b52ba1fb5d1d', 'message': 'Buffer Overflow data file dependency is removed\n\nThe data file buffer-overflow.txt is never used, instead the string\ngenerated in buffer_overflow.py is used for testing buffer overflow,\nso the text file dependency is removed.\n\nChange-Id: I4928926aa42b568502bd0b99b15b06d0667968ca\n'}, {'number': 4, 'created': '2016-08-26 22:56:26.000000000', 'files': ['syntribos/tests/fuzz/buffer_overflow.py', 'syntribos/tests/fuzz/base_fuzz.py'], 'web_link': 'https://opendev.org/openstack/syntribos/commit/57e6a829937fd9757990b1397c426b6cda02cbc4', 'message': 'Buffer Overflow data file dependency is removed\n\nThe data file buffer-overflow.txt is never used, instead the string\ngenerated in buffer_overflow.py is used for testing buffer overflow,\nso the text file dependency is removed.\n\nChange-Id: I4928926aa42b568502bd0b99b15b06d0667968ca\n'}]",9,360558,57e6a829937fd9757990b1397c426b6cda02cbc4,24,6,4,22221,,,0,"Buffer Overflow data file dependency is removed

The data file buffer-overflow.txt is never used, instead the string
generated in buffer_overflow.py is used for testing buffer overflow,
so the text file dependency is removed.

Change-Id: I4928926aa42b568502bd0b99b15b06d0667968ca
",git fetch https://review.opendev.org/openstack/syntribos refs/changes/58/360558/4 && git format-patch -1 --stdout FETCH_HEAD,"['syntribos/tests/fuzz/base_fuzz.py', 'syntribos/tests/fuzz/buffer_overflow.py']",2,22373b130b9ec306a32713a9af2f0009ca864a72,, data_key = None," data_key = ""buffer-overflow.txt""",4,2
openstack%2Fsyntribos~master~I4f88c255f8d4e6edfe3df3a4e463aee0cdd9c26b,openstack/syntribos,master,I4f88c255f8d4e6edfe3df3a4e463aee0cdd9c26b,Added config file improvements,MERGED,2016-08-22 20:50:43.000000000,2016-08-29 17:11:23.000000000,2016-08-29 17:11:23.000000000,"[{'_account_id': 3}, {'_account_id': 15515}, {'_account_id': 17709}, {'_account_id': 18462}, {'_account_id': 22781}]","[{'number': 1, 'created': '2016-08-22 20:50:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/syntribos/commit/0883a817ad8a5a9fa9735b02321c32c002f37964', 'message': 'Added config file improvements\n\n1) renamed ""user"" section for clarity\n2) Added option to exclude defect type from output\n3) modified default time_diff_percentage and length_diff_percentage values\n4) added sample default values to config for oslo-config-generator\n\nChange-Id: I4f88c255f8d4e6edfe3df3a4e463aee0cdd9c26b\n'}, {'number': 2, 'created': '2016-08-23 22:24:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/syntribos/commit/aafb97f0193c4ff7465c80409bcb0e879762ff1c', 'message': 'Added config file improvements\n\n1) renamed ""user"" section for clarity\n2) Added option to exclude defect type from output\n3) modified default time_diff_percentage and length_diff_percentage values\n4) added sample default values to config for oslo-config-generator\n\nChange-Id: I4f88c255f8d4e6edfe3df3a4e463aee0cdd9c26b\n'}, {'number': 3, 'created': '2016-08-24 22:32:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/syntribos/commit/7d294e909a571f84799800e0caad012ca27d4a6c', 'message': 'Added config file improvements\n\n1) renamed ""user"" section for clarity\n2) Added option to exclude defect type from output\n3) modified default time_diff_percentage and length_diff_percentage values\n4) added sample default values to config for oslo-config-generator\n\nChange-Id: I4f88c255f8d4e6edfe3df3a4e463aee0cdd9c26b\n'}, {'number': 4, 'created': '2016-08-24 22:39:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/syntribos/commit/75b0fd06cb70eff20e9e6cb25e06eac54fac26b2', 'message': 'Added config file improvements\n\n1) renamed ""user"" section for clarity\n2) Added option to exclude defect type from output\n3) modified default time_diff_percentage and length_diff_percentage values\n4) added sample default values to config for oslo-config-generator\n\nChange-Id: I4f88c255f8d4e6edfe3df3a4e463aee0cdd9c26b\n'}, {'number': 5, 'created': '2016-08-25 16:53:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/syntribos/commit/b08c7de7c6b4d848f400cb02532cf2022cc83669', 'message': 'Added config file improvements\n\n1) renamed ""user"" section for clarity\n2) Added option to exclude defect type from output\n3) modified default time_diff_percentage and length_diff_percentage values\n4) added sample default values to config for oslo-config-generator\n\nChange-Id: I4f88c255f8d4e6edfe3df3a4e463aee0cdd9c26b\n'}, {'number': 6, 'created': '2016-08-25 18:20:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/syntribos/commit/7626c7c5980602325ed32242dad683e8578d0a76', 'message': 'Added config file improvements\n\n1) renamed ""user"" section for clarity\n2) Added option to exclude defect type from output\n3) modified default time_diff_percentage and length_diff_percentage values\n4) added sample default values to config for oslo-config-generator\n\nChange-Id: I4f88c255f8d4e6edfe3df3a4e463aee0cdd9c26b\n'}, {'number': 7, 'created': '2016-08-25 19:37:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/syntribos/commit/e5af741bbf0a623ef79b711de4b28112b8108617', 'message': 'Added config file improvements\n\n1) renamed ""user"" section for clarity\n2) Added option to exclude defect type from output\n3) modified default time_diff_percentage and length_diff_percentage values\n4) added sample default values to config for oslo-config-generator\n\nChange-Id: I4f88c255f8d4e6edfe3df3a4e463aee0cdd9c26b\n'}, {'number': 8, 'created': '2016-08-25 22:10:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/syntribos/commit/ca120b57ee20bd1511fb00d7ea35043bedd23404', 'message': 'Added config file improvements\n\n1) renamed ""user"" section for clarity\n2) Added option to exclude defect type from output\n3) modified default time_diff_percentage and length_diff_percentage values\n4) added sample default values to config for oslo-config-generator\n\nChange-Id: I4f88c255f8d4e6edfe3df3a4e463aee0cdd9c26b\n'}, {'number': 9, 'created': '2016-08-26 23:00:55.000000000', 'files': ['syntribos/formatters/json_formatter.py', 'syntribos/config.py', 'syntribos/result.py'], 'web_link': 'https://opendev.org/openstack/syntribos/commit/4876101b551f8f7c9e87dd1caf32c534865e1e95', 'message': 'Added config file improvements\n\n1) renamed ""user"" section for clarity\n2) Added option to exclude defect type from output\n3) modified default time_diff_percentage and length_diff_percentage values\n4) added sample default values to config for oslo-config-generator\n\nChange-Id: I4f88c255f8d4e6edfe3df3a4e463aee0cdd9c26b\n'}]",19,358856,4876101b551f8f7c9e87dd1caf32c534865e1e95,51,5,9,17709,,,0,"Added config file improvements

1) renamed ""user"" section for clarity
2) Added option to exclude defect type from output
3) modified default time_diff_percentage and length_diff_percentage values
4) added sample default values to config for oslo-config-generator

Change-Id: I4f88c255f8d4e6edfe3df3a4e463aee0cdd9c26b
",git fetch https://review.opendev.org/openstack/syntribos refs/changes/56/358856/4 && git format-patch -1 --stdout FETCH_HEAD,"['syntribos/formatters/json_formatter.py', 'syntribos/config.py', 'syntribos/result.py', 'examples/configs/keystone.config']",4,0883a817ad8a5a9fa9735b02321c32c002f37964,formatter_schema,[keystone_user],[user],29,14
openstack%2Fpython-magnumclient~master~I32fdb1c6b396db3613163b3d3558cceebc04b56f,openstack/python-magnumclient,master,I32fdb1c6b396db3613163b3d3558cceebc04b56f,Update magnum client to support async bay operations,ABANDONED,2016-06-23 20:10:13.000000000,2016-08-29 17:07:13.000000000,,"[{'_account_id': 3}, {'_account_id': 7230}, {'_account_id': 9095}, {'_account_id': 9995}, {'_account_id': 10206}, {'_account_id': 12385}, {'_account_id': 20498}, {'_account_id': 21469}, {'_account_id': 22224}]","[{'number': 1, 'created': '2016-06-23 20:10:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-magnumclient/commit/e27ac4d7ff6975ff6c8a33bbb9f842e6822d0997', 'message': 'Update magnum client to support async api behavior\n\nChange-Id: I32fdb1c6b396db3613163b3d3558cceebc04b56f\nDepends-On: I4ca1f9f386b6417726154c466e7a9104b6e6e5e1\n'}, {'number': 2, 'created': '2016-06-27 15:34:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-magnumclient/commit/a4368249c197729702965f599d58acf05a14720e', 'message': 'Update magnum client to support async bay operations\n\nChange-Id: I32fdb1c6b396db3613163b3d3558cceebc04b56f\nDepends-On: I4ca1f9f386b6417726154c466e7a9104b6e6e5e1\n'}, {'number': 3, 'created': '2016-06-27 16:27:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-magnumclient/commit/e391254649098b1c9bea895134fd312724fc7f57', 'message': 'Update magnum client to support async bay operations\n\nChange-Id: I32fdb1c6b396db3613163b3d3558cceebc04b56f\nDepends-On: I4ca1f9f386b6417726154c466e7a9104b6e6e5e1\n'}, {'number': 4, 'created': '2016-08-10 15:47:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-magnumclient/commit/3a0a88f191e6fd9ac0328cbb1cfe08b2d6f7b345', 'message': 'Update magnum client to support async bay operations\n\nChange-Id: I32fdb1c6b396db3613163b3d3558cceebc04b56f\nDepends-On: I4ca1f9f386b6417726154c466e7a9104b6e6e5e1\n'}, {'number': 5, 'created': '2016-08-10 15:54:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-magnumclient/commit/69561a157eae8bba0f8eb43c6835dc618dd41199', 'message': 'Update magnum client to support async bay operations\n\nMagnum bay operations API default behavior changing from\nsynchronous to asynchronous and with this change bay-create,\nbay-update return just bay ID instead of bay object.\nSo updating the magnum client to handle this change.\n\nChange-Id: I32fdb1c6b396db3613163b3d3558cceebc04b56f\nDepends-On: I4ca1f9f386b6417726154c466e7a9104b6e6e5e1\n'}, {'number': 6, 'created': '2016-08-16 16:02:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-magnumclient/commit/5384f14741f9be1ce1bd45646ad69ea80566f7d1', 'message': 'Update magnum client to support async bay operations\n\nMagnum bay operations API default behavior changing from\nsynchronous to asynchronous and with this change bay-create,\nbay-update return just bay ID instead of bay object.\nSo updating the magnum client to handle this change.\n\nChange-Id: I32fdb1c6b396db3613163b3d3558cceebc04b56f\nDepends-On: I4ca1f9f386b6417726154c466e7a9104b6e6e5e1\n'}, {'number': 7, 'created': '2016-08-29 15:53:27.000000000', 'files': ['magnumclient/v1/bays_shell.py'], 'web_link': 'https://opendev.org/openstack/python-magnumclient/commit/6dae231adb6f88ac8d3a8f9549942bf4185a2689', 'message': 'Update magnum client to support async bay operations\n\nMagnum bay operations API default behavior changing from\nsynchronous to asynchronous and with this change bay-create,\nbay-update return just bay ID instead of bay object.\nSo updating the magnum client to handle this change.\n\nChange-Id: I32fdb1c6b396db3613163b3d3558cceebc04b56f\nDepends-On: I4ca1f9f386b6417726154c466e7a9104b6e6e5e1\n'}]",0,333562,6dae231adb6f88ac8d3a8f9549942bf4185a2689,22,9,7,7230,,,0,"Update magnum client to support async bay operations

Magnum bay operations API default behavior changing from
synchronous to asynchronous and with this change bay-create,
bay-update return just bay ID instead of bay object.
So updating the magnum client to handle this change.

Change-Id: I32fdb1c6b396db3613163b3d3558cceebc04b56f
Depends-On: I4ca1f9f386b6417726154c466e7a9104b6e6e5e1
",git fetch https://review.opendev.org/openstack/python-magnumclient refs/changes/62/333562/1 && git format-patch -1 --stdout FETCH_HEAD,['magnumclient/v1/bays_shell.py'],1,e27ac4d7ff6975ff6c8a33bbb9f842e6822d0997,(detached," resp = cs.bays.create(**opts) print(""Request to create bay %s has been accepted."" % args.name) cs.bays.update(args.bay, patch) print(""Request to update bay %s has been accepted."" % args.bay)"," bay = cs.bays.create(**opts) _show_bay(bay) bay = cs.bays.update(args.bay, patch) _show_bay(bay)",4,4
openstack%2Frequirements~master~I8b97f30f520b6283843cfb181cdd4dc28839892e,openstack/requirements,master,I8b97f30f520b6283843cfb181cdd4dc28839892e,update constraint for oslo.middleware to new release 3.19.0,MERGED,2016-08-25 11:58:55.000000000,2016-08-29 17:00:36.000000000,2016-08-29 17:00:36.000000000,"[{'_account_id': 3}, {'_account_id': 11105}, {'_account_id': 12898}, {'_account_id': 14288}]","[{'number': 1, 'created': '2016-08-25 11:58:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/5b04a87155eca69bea2d2a6d07ede5b306c9a9ca', 'message': 'update constraint for oslo.middleware to new release 3.19.0\n\noslo.middleware 3.19.0 release\n\nChange-Id: I8b97f30f520b6283843cfb181cdd4dc28839892e\nmeta:version: 3.19.0\nmeta:diff-start: -\nmeta:series: newton\nmeta:release-type: release\nmeta:announce: openstack-dev@lists.openstack.org\nmeta:pypi: yes\nmeta:first: no\nmeta:release:Author: Joshua Harlow <jxharlow@godaddy.com>\nmeta:release:Commit: Davanum Srinivas <davanum@gmail.com>\nmeta:release:Change-Id: I3c4738cb6fc0baf1e15c9bc17864a6d79a4a786b\n'}, {'number': 2, 'created': '2016-08-26 04:12:23.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/fff4e1623967f7240c35ff6426708615eb71b7b9', 'message': 'update constraint for oslo.middleware to new release 3.19.0\n\noslo.middleware 3.19.0 release\n\nChange-Id: I8b97f30f520b6283843cfb181cdd4dc28839892e\nmeta:version: 3.19.0\nmeta:diff-start: -\nmeta:series: newton\nmeta:release-type: release\nmeta:announce: openstack-dev@lists.openstack.org\nmeta:pypi: yes\nmeta:first: no\nmeta:release:Author: Joshua Harlow <jxharlow@godaddy.com>\nmeta:release:Commit: Davanum Srinivas <davanum@gmail.com>\nmeta:release:Change-Id: I3c4738cb6fc0baf1e15c9bc17864a6d79a4a786b\n'}]",0,360472,fff4e1623967f7240c35ff6426708615eb71b7b9,9,4,2,5638,,,0,"update constraint for oslo.middleware to new release 3.19.0

oslo.middleware 3.19.0 release

Change-Id: I8b97f30f520b6283843cfb181cdd4dc28839892e
meta:version: 3.19.0
meta:diff-start: -
meta:series: newton
meta:release-type: release
meta:announce: openstack-dev@lists.openstack.org
meta:pypi: yes
meta:first: no
meta:release:Author: Joshua Harlow <jxharlow@godaddy.com>
meta:release:Commit: Davanum Srinivas <davanum@gmail.com>
meta:release:Change-Id: I3c4738cb6fc0baf1e15c9bc17864a6d79a4a786b
",git fetch https://review.opendev.org/openstack/requirements refs/changes/72/360472/2 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,5b04a87155eca69bea2d2a6d07ede5b306c9a9ca,new-release,oslo.middleware===3.19.0,oslo.middleware===3.18.0,1,1
openstack%2Frpm-packaging~master~I3e8b72392281670a8c1275379bb39a971a1496ff,openstack/rpm-packaging,master,I3e8b72392281670a8c1275379bb39a971a1496ff,update openstacksdk to 0.9.4 and fix tests,MERGED,2016-08-26 11:08:22.000000000,2016-08-29 16:59:26.000000000,2016-08-29 16:56:50.000000000,"[{'_account_id': 3}, {'_account_id': 6593}, {'_account_id': 7102}, {'_account_id': 7613}, {'_account_id': 12281}, {'_account_id': 13294}, {'_account_id': 19648}, {'_account_id': 20656}]","[{'number': 1, 'created': '2016-08-26 11:08:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/9b99c4dae8ab1a9f93f165a800380956f81273d5', 'message': 'update python-openstackclient to 0.9.4\n\n0.9.4\nRefactor Key Manager for resource2\nFix problems about location header in resource2\nAdd support for claim for Zaqar V2 API\n\n0.9.3\nAdd support for subscription for Zaqar V2 API\nAdd policy validation for senlin\nAdd profile validation for senlin\nAdd QoS policy object and CRUD commands\nUpdated from global requirements\nFix orchestration service initialization\nMinor network RBAC policy updates\nAdd check_stack operation to proxy\nTweak endpoint discovery for apache-style services\n\n0.9.2\nAdd template validation support to orchestration\nAdd SoftwareDeployment resource to orchestration\nAdd SoftwareConfig resource to orchestration\nRebase orchestration to resource2/proxy2\nRelocate alarm service into a submodule\nGet endpoints directly from services\nAdd force-delete into compute service\nAdd services operations into compute service\nFix nova server image and flavor\nAdd support for message resource of Zaqar v2 API\nAdd support for Zaqar V2 queue resource\nAdd collect_cluster_attrs API to cluster service\nUpdated from global requirements\nFix cluster resource in cluster service\nAdd API microversion support\nUpdated from global requirements\nRefactor image v2 to use resource2/proxy2\n\n0.9.1\nRebase cluster service to resource2/proxy2\nImprove docstring for some resource2 methods\nAdd to_dict() method to resource2.Resource\n_alternate_id should return a server-side name\nMake end-user modules accessible from top level\nUpdated from global requirements\nReplace _transpose_component with _filter_component\nFix test_limits functional test failure\nRemove update_flavor method from compute\nExpose requires_id to get_xxx proxy functions\nUpdated from global requirements\nHAProxy uses milliseconds for its timeout values\nSupport fetching network project default quota\n\nChange-Id: I3e8b72392281670a8c1275379bb39a971a1496ff\n'}, {'number': 2, 'created': '2016-08-26 11:21:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/e64cfcefe315a6b5e4567b3cd9fead59d810e87b', 'message': 'update openstacksdk to 0.9.4\n\n0.9.4\nRefactor Key Manager for resource2\nFix problems about location header in resource2\nAdd support for claim for Zaqar V2 API\n\n0.9.3\nAdd support for subscription for Zaqar V2 API\nAdd policy validation for senlin\nAdd profile validation for senlin\nAdd QoS policy object and CRUD commands\nUpdated from global requirements\nFix orchestration service initialization\nMinor network RBAC policy updates\nAdd check_stack operation to proxy\nTweak endpoint discovery for apache-style services\n\n0.9.2\nAdd template validation support to orchestration\nAdd SoftwareDeployment resource to orchestration\nAdd SoftwareConfig resource to orchestration\nRebase orchestration to resource2/proxy2\nRelocate alarm service into a submodule\nGet endpoints directly from services\nAdd force-delete into compute service\nAdd services operations into compute service\nFix nova server image and flavor\nAdd support for message resource of Zaqar v2 API\nAdd support for Zaqar V2 queue resource\nAdd collect_cluster_attrs API to cluster service\nUpdated from global requirements\nFix cluster resource in cluster service\nAdd API microversion support\nUpdated from global requirements\nRefactor image v2 to use resource2/proxy2\n\n0.9.1\nRebase cluster service to resource2/proxy2\nImprove docstring for some resource2 methods\nAdd to_dict() method to resource2.Resource\n_alternate_id should return a server-side name\nMake end-user modules accessible from top level\nUpdated from global requirements\nReplace _transpose_component with _filter_component\nFix test_limits functional test failure\nRemove update_flavor method from compute\nExpose requires_id to get_xxx proxy functions\nUpdated from global requirements\nHAProxy uses milliseconds for its timeout values\nSupport fetching network project default quota\n\nChange-Id: I3e8b72392281670a8c1275379bb39a971a1496ff\n'}, {'number': 3, 'created': '2016-08-26 14:29:09.000000000', 'files': ['openstack/openstacksdk/openstacksdk.spec.j2'], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/f16bbdf57177f1197719de62d6433744d24ae6aa', 'message': 'update openstacksdk to 0.9.4 and fix tests\n\nChange-Id: I3e8b72392281670a8c1275379bb39a971a1496ff\n'}]",1,361084,f16bbdf57177f1197719de62d6433744d24ae6aa,28,8,3,12281,,,0,"update openstacksdk to 0.9.4 and fix tests

Change-Id: I3e8b72392281670a8c1275379bb39a971a1496ff
",git fetch https://review.opendev.org/openstack/rpm-packaging refs/changes/84/361084/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack/openstacksdk/openstacksdk.spec.j2'],1,9b99c4dae8ab1a9f93f165a800380956f81273d5,update_openstacksdk,Version: 0.9.4,Version: 0.9.0,1,1
openstack%2Fsyntribos~master~I15e2c8d288e50e54fb06cdaf91e76db151b7e1c8,openstack/syntribos,master,I15e2c8d288e50e54fb06cdaf91e76db151b7e1c8,Deleting unused data files,MERGED,2016-08-27 17:34:54.000000000,2016-08-29 16:58:30.000000000,2016-08-29 16:58:30.000000000,"[{'_account_id': 3}, {'_account_id': 15515}, {'_account_id': 17709}, {'_account_id': 18462}]","[{'number': 1, 'created': '2016-08-27 17:34:54.000000000', 'files': ['data/disclosure-directory.txt', 'data/file-upload.txt', 'data/disclosure-source.txt', 'data/http-protocol.txt', 'data/format-strings.txt', 'data/path-traversal.txt', 'data/buffer-overflow.txt', 'data/lfi.txt', 'data/disclosure-localpaths.txt', 'data/os-cmd-execution.txt', 'data/os-dir-indexing.txt', 'data/control-chars.txt', 'data/html_fuzz.txt', 'data/rfi.txt', 'data/xml.txt', 'data/server-side-include.txt', 'data/BizLogic.txt', 'data/xpath.txt'], 'web_link': 'https://opendev.org/openstack/syntribos/commit/8bd026a4e7914a34287a65b1637a053e9c787620', 'message': 'Deleting unused data files\n\nRemoving files in data directory which are never used\n\nChange-Id: I15e2c8d288e50e54fb06cdaf91e76db151b7e1c8\n'}]",0,361646,8bd026a4e7914a34287a65b1637a053e9c787620,8,4,1,22221,,,0,"Deleting unused data files

Removing files in data directory which are never used

Change-Id: I15e2c8d288e50e54fb06cdaf91e76db151b7e1c8
",git fetch https://review.opendev.org/openstack/syntribos refs/changes/46/361646/1 && git format-patch -1 --stdout FETCH_HEAD,"['data/disclosure-directory.txt', 'data/file-upload.txt', 'data/disclosure-source.txt', 'data/http-protocol.txt', 'data/format-strings.txt', 'data/path-traversal.txt', 'data/buffer-overflow.txt', 'data/lfi.txt', 'data/disclosure-localpaths.txt', 'data/os-cmd-execution.txt', 'data/os-dir-indexing.txt', 'data/control-chars.txt', 'data/html_fuzz.txt', 'data/rfi.txt', 'data/xml.txt', 'data/server-side-include.txt', 'data/BizLogic.txt', 'data/xpath.txt']",18,8bd026a4e7914a34287a65b1637a053e9c787620,datafile,,' or '1'='1 ' or ''=' x' or 1=1 or 'x'='y / // //* */* @* count(/child::node()) x' or name()='username' or 'x'='y ,0,5513
openstack%2Ftripleo-common~master~I5ba0a3710012c44822dd3b8e69662bbef04d3787,openstack/tripleo-common,master,I5ba0a3710012c44822dd3b8e69662bbef04d3787,Add Mistral action & workflow for root device configuration,MERGED,2016-08-16 13:54:47.000000000,2016-08-29 16:53:23.000000000,2016-08-29 14:20:33.000000000,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 4978}, {'_account_id': 7065}, {'_account_id': 9712}]","[{'number': 1, 'created': '2016-08-16 13:54:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/28a8eb391632f2668748decfc7c2a2a808b90827', 'message': ""Add Mistral action & workflow for root device configuration\n\nThe root device configuration code and unit tests come from the\npython-tripleoclient project. By moving them into a common Mistral\naction, they can be reused by other clients like the UI. The workflows\nwill also be used for the new 'overcloud node configure' command in the\nclient.\n\nChange-Id: I5ba0a3710012c44822dd3b8e69662bbef04d3787\nRelated-Bug: #1595205\n""}, {'number': 2, 'created': '2016-08-16 16:24:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/d175638df4c7add1b86f523a8062aa512fbb98d8', 'message': ""Add Mistral action & workflow for root device configuration\n\nThe root device configuration code and unit tests come from the\npython-tripleoclient project. By moving them into a common Mistral\naction, they can be reused by other clients like the UI. The workflows\nwill also be used for the new 'overcloud node configure' command in the\nclient.\n\nChange-Id: I5ba0a3710012c44822dd3b8e69662bbef04d3787\nRelated-Bug: #1595205\n""}, {'number': 3, 'created': '2016-08-19 11:16:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/ff4cd273c85e0ed3e4efb73a390a819a131740d5', 'message': ""Add Mistral action & workflow for root device configuration\n\nThe root device configuration code and unit tests come from the\npython-tripleoclient project. By moving them into a common Mistral\naction, they can be reused by other clients like the UI. The workflows\nwill also be used for the new 'overcloud node configure' command in the\nclient.\n\nChange-Id: I5ba0a3710012c44822dd3b8e69662bbef04d3787\nRelated-Bug: #1595205\n""}, {'number': 4, 'created': '2016-08-24 07:49:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/f8a45989639107e701c8523f776bf2d811887902', 'message': ""Add Mistral action & workflow for root device configuration\n\nThe root device configuration code and unit tests come from the\npython-tripleoclient project. By moving them into a common Mistral\naction, they can be reused by other clients like the UI. The workflows\nwill also be used for the new 'overcloud node configure' command in the\nclient.\n\nChange-Id: I5ba0a3710012c44822dd3b8e69662bbef04d3787\nRelated-Bug: #1595205\n""}, {'number': 5, 'created': '2016-08-25 19:12:58.000000000', 'files': ['tripleo_common/actions/baremetal.py', 'requirements.txt', 'workbooks/baremetal.yaml', 'tripleo_common/actions/base.py', 'tripleo_common/exception.py', 'setup.cfg', 'tripleo_common/tests/actions/test_baremetal.py'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/cbe0dbf32df9ea1f79dd218437eeb6d3c6279fb4', 'message': ""Add Mistral action & workflow for root device configuration\n\nThe root device configuration code and unit tests come from the\npython-tripleoclient project. By moving them into a common Mistral\naction, they can be reused by other clients like the UI. The workflows\nwill also be used for the new 'overcloud node configure' command in the\nclient.\n\nChange-Id: I5ba0a3710012c44822dd3b8e69662bbef04d3787\nRelated-Bug: #1595205\n""}]",3,355947,cbe0dbf32df9ea1f79dd218437eeb6d3c6279fb4,44,5,5,4978,,,0,"Add Mistral action & workflow for root device configuration

The root device configuration code and unit tests come from the
python-tripleoclient project. By moving them into a common Mistral
action, they can be reused by other clients like the UI. The workflows
will also be used for the new 'overcloud node configure' command in the
client.

Change-Id: I5ba0a3710012c44822dd3b8e69662bbef04d3787
Related-Bug: #1595205
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/47/355947/1 && git format-patch -1 --stdout FETCH_HEAD,"['tripleo_common/actions/baremetal.py', 'requirements.txt', 'workbooks/baremetal.yaml', 'tripleo_common/actions/base.py', 'tripleo_common/exception.py', 'setup.cfg', 'tripleo_common/tests/actions/test_baremetal.py']",7,28a8eb391632f2668748decfc7c2a2a808b90827,bug/1595205,"import ironic_inspector_client from oslo_utils import unitsfrom tripleo_common import exception class TestConfigureRootDeviceAction(base.TestCase): def setUp(self): super(TestConfigureRootDeviceAction, self).setUp() # Mock data self.disks = [ {'name': '/dev/sda', 'size': 11 * units.Gi}, {'name': '/dev/sdb', 'size': 2 * units.Gi}, {'name': '/dev/sdc', 'size': 5 * units.Gi}, {'name': '/dev/sdd', 'size': 21 * units.Gi}, {'name': '/dev/sde', 'size': 13 * units.Gi}, ] for i, disk in enumerate(self.disks): disk['wwn'] = 'wwn%d' % i disk['serial'] = 'serial%d' % i # Ironic mocks self.ironic = mock.MagicMock() ironic_patcher = mock.patch( 'tripleo_common.actions.base.TripleOAction._get_baremetal_client', return_value=self.ironic) self.mock_ironic = ironic_patcher.start() self.addCleanup(self.mock_ironic.stop) self.ironic.node.list.return_value = [ mock.Mock(uuid=""ABCDEFGH""), ] self.node = mock.Mock(uuid=""ABCDEFGH"", properties={}) self.ironic.node.get.return_value = self.node # inspector mocks self.inspector = mock.MagicMock() inspector_patcher = mock.patch( 'tripleo_common.actions.base.TripleOAction.' '_get_baremetal_introspection_client', return_value=self.inspector) self.mock_inspector = inspector_patcher.start() self.addCleanup(self.mock_inspector.stop) self.inspector.get_data.return_value = { 'inventory': {'disks': self.disks} } def test_smallest(self): action = baremetal.ConfigureRootDeviceAction(node_uuid='MOCK_UUID', root_device='smallest') action.run() self.assertEqual(self.ironic.node.update.call_count, 1) root_device_args = self.ironic.node.update.call_args_list[0] expected_patch = [{'op': 'add', 'path': '/properties/root_device', 'value': {'wwn': 'wwn2'}}, {'op': 'add', 'path': '/properties/local_gb', 'value': 4}] self.assertEqual(mock.call('ABCDEFGH', expected_patch), root_device_args) def test_largest(self): action = baremetal.ConfigureRootDeviceAction(node_uuid='MOCK_UUID', root_device='largest') action.run() self.assertEqual(self.ironic.node.update.call_count, 1) root_device_args = self.ironic.node.update.call_args_list[0] expected_patch = [{'op': 'add', 'path': '/properties/root_device', 'value': {'wwn': 'wwn3'}}, {'op': 'add', 'path': '/properties/local_gb', 'value': 20}] self.assertEqual(mock.call('ABCDEFGH', expected_patch), root_device_args) def test_no_overwrite(self): self.node.properties['root_device'] = {'foo': 'bar'} action = baremetal.ConfigureRootDeviceAction(node_uuid='MOCK_UUID', root_device='smallest') action.run() self.assertEqual(self.ironic.node.update.call_count, 0) def test_with_overwrite(self): self.node.properties['root_device'] = {'foo': 'bar'} action = baremetal.ConfigureRootDeviceAction(node_uuid='MOCK_UUID', root_device='smallest', overwrite=True) action.run() self.assertEqual(self.ironic.node.update.call_count, 1) root_device_args = self.ironic.node.update.call_args_list[0] expected_patch = [{'op': 'add', 'path': '/properties/root_device', 'value': {'wwn': 'wwn2'}}, {'op': 'add', 'path': '/properties/local_gb', 'value': 4}] self.assertEqual(mock.call('ABCDEFGH', expected_patch), root_device_args) def test_minimum_size(self): action = baremetal.ConfigureRootDeviceAction(node_uuid='MOCK_UUID', root_device='smallest', minimum_size=10) action.run() self.assertEqual(self.ironic.node.update.call_count, 1) root_device_args = self.ironic.node.update.call_args_list[0] expected_patch = [{'op': 'add', 'path': '/properties/root_device', 'value': {'wwn': 'wwn0'}}, {'op': 'add', 'path': '/properties/local_gb', 'value': 10}] self.assertEqual(mock.call('ABCDEFGH', expected_patch), root_device_args) def test_bad_inventory(self): self.inspector.get_data.return_value = {} action = baremetal.ConfigureRootDeviceAction(node_uuid='MOCK_UUID', root_device='smallest') self.assertRaisesRegexp(exception.RootDeviceDetectionError, ""Malformed introspection data"", action.run) self.assertEqual(self.ironic.node.update.call_count, 0) def test_no_disks(self): self.inspector.get_data.return_value = { 'inventory': { 'disks': [{'name': '/dev/sda', 'size': 1 * units.Gi}] } } action = baremetal.ConfigureRootDeviceAction(node_uuid='MOCK_UUID', root_device='smallest') self.assertRaisesRegexp(exception.RootDeviceDetectionError, ""No suitable disks"", action.run) self.assertEqual(self.ironic.node.update.call_count, 0) def test_no_data(self): self.inspector.get_data.side_effect = ( ironic_inspector_client.ClientError(mock.Mock())) action = baremetal.ConfigureRootDeviceAction(node_uuid='MOCK_UUID', root_device='smallest') self.assertRaisesRegexp(exception.RootDeviceDetectionError, ""No introspection data"", action.run) self.assertEqual(self.ironic.node.update.call_count, 0) def test_no_wwn_and_serial(self): self.inspector.get_data.return_value = { 'inventory': { 'disks': [{'name': '/dev/sda', 'size': 10 * units.Gi}] } } action = baremetal.ConfigureRootDeviceAction(node_uuid='MOCK_UUID', root_device='smallest') self.assertRaisesRegexp(exception.RootDeviceDetectionError, ""Neither WWN nor serial number are known"", action.run) self.assertEqual(self.ironic.node.update.call_count, 0) def test_device_list(self): action = baremetal.ConfigureRootDeviceAction( node_uuid='MOCK_UUID', root_device='hda,sda,sdb,sdc') action.run() self.assertEqual(self.ironic.node.update.call_count, 1) root_device_args = self.ironic.node.update.call_args_list[0] expected_patch = [{'op': 'add', 'path': '/properties/root_device', 'value': {'wwn': 'wwn0'}}, {'op': 'add', 'path': '/properties/local_gb', 'value': 10}] self.assertEqual(mock.call('ABCDEFGH', expected_patch), root_device_args) def test_device_list_not_found(self): action = baremetal.ConfigureRootDeviceAction(node_uuid='MOCK_UUID', root_device='hda') self.assertRaisesRegexp(exception.RootDeviceDetectionError, ""Cannot find a disk"", action.run) self.assertEqual(self.ironic.node.update.call_count, 0)",,461,0
openstack%2Fgnocchi~master~I1258c917bbf2309091595c250d4f94f98f442677,openstack/gnocchi,master,I1258c917bbf2309091595c250d4f94f98f442677,Merge documentation and release notes,MERGED,2016-08-11 16:00:52.000000000,2016-08-29 16:52:53.000000000,2016-08-29 16:52:53.000000000,"[{'_account_id': 3}, {'_account_id': 6537}]","[{'number': 1, 'created': '2016-08-11 16:00:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/023a70d718ce127ae6a62137fab668ff9f38cf28', 'message': 'Merge documentation and release notes\n\nThis will output only one complete website with all the documentation\nand the release note directly available in it.\n\nChange-Id: I1258c917bbf2309091595c250d4f94f98f442677\n'}, {'number': 2, 'created': '2016-08-16 15:18:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/434ad953d7a055c0759caf3ba21415a085b6c4dd', 'message': 'Merge documentation and release notes\n\nThis will output only one complete website with all the documentation\nand the release note directly available in it.\n\nChange-Id: I1258c917bbf2309091595c250d4f94f98f442677\n'}, {'number': 3, 'created': '2016-08-16 16:03:01.000000000', 'files': ['doc/source/releasenotes/index.rst', 'doc/source/index.rst', 'doc/source/releasenotes/2.2.rst', 'doc/source/releasenotes/2.1.rst', 'releasenotes/source/_static/.placeholder', 'doc/source/conf.py', 'doc/source/releasenotes/unreleased.rst', 'releasenotes/source/_templates/.placeholder', 'releasenotes/source/index.rst', 'tox.ini', 'releasenotes/source/conf.py'], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/b8e9d91c0bfb18ce84520e43ca8021687af08094', 'message': 'Merge documentation and release notes\n\nThis will output only one complete website with all the documentation\nand the release note directly available in it.\n\nChange-Id: I1258c917bbf2309091595c250d4f94f98f442677\n'}]",0,354183,b8e9d91c0bfb18ce84520e43ca8021687af08094,14,2,3,1669,,,0,"Merge documentation and release notes

This will output only one complete website with all the documentation
and the release note directly available in it.

Change-Id: I1258c917bbf2309091595c250d4f94f98f442677
",git fetch https://review.opendev.org/openstack/gnocchi refs/changes/83/354183/2 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/index.rst', 'doc/source/releasenotes/index.rst', 'doc/source/releasenotes/2.1.rst', 'releasenotes/source/_static/.placeholder', 'doc/source/conf.py', 'doc/source/releasenotes/unreleased.rst', 'doc/notes/.placeholder', 'releasenotes/source/_templates/.placeholder', 'releasenotes/source/index.rst', 'tox.ini', 'releasenotes/source/conf.py']",11,023a70d718ce127ae6a62137fab668ff9f38cf28,jd/doc,,"# -*- coding: utf-8 -*- # Licensed under the Apache License, Version 2.0 (the ""License""); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or # implied. # See the License for the specific language governing permissions and # limitations under the License. # # Gnocchi Release Notes documentation build configuration file, created by # sphinx-quickstart on Mon Nov 23 20:38:38 2015. # # This file is execfile()d with the current directory set to its # containing dir. # # Note that not all possible configuration values are present in this # autogenerated file. # # All configuration values have a default; values that are commented out # serve to show the default. # If extensions (or modules to document with autodoc) are in another directory, # add these directories to sys.path here. If the directory is relative to the # documentation root, use os.path.abspath to make it absolute, like shown here. # sys.path.insert(0, os.path.abspath('.')) # -- General configuration ------------------------------------------------ # If your documentation needs a minimal Sphinx version, state it here. # needs_sphinx = '1.0' # Add any Sphinx extension module names here, as strings. They can be # extensions coming with Sphinx (named 'sphinx.ext.*') or your custom # ones. extensions = [ 'oslosphinx', 'reno.sphinxext', ] # Add any paths that contain templates here, relative to this directory. templates_path = ['_templates'] # The suffix of source filenames. source_suffix = '.rst' # The encoding of source files. # source_encoding = 'utf-8-sig' # The master toctree document. master_doc = 'index' # General information about the project. project = u'Gnocchi Release Notes' copyright = u'2015-present, Gnocchi developers' # The version info for the project you're documenting, acts as replacement for # |version| and |release|, also used in various other places throughout the # built documents. # import pbr.version gnocchi_version = pbr.version.VersionInfo('gnocchi') # The short X.Y version. version = gnocchi_version.canonical_version_string() # The full version, including alpha/beta/rc tags. release = gnocchi_version.version_string_with_vcs() # The language for content autogenerated by Sphinx. Refer to documentation # for a list of supported languages. # language = None # There are two options for replacing |today|: either, you set today to some # non-false value, then it is used: # today = '' # Else, today_fmt is used as the format for a strftime call. # today_fmt = '%B %d, %Y' # List of patterns, relative to source directory, that match files and # directories to ignore when looking for source files. exclude_patterns = [] # The reST default role (used for this markup: `text`) to use for all # documents. # default_role = None # If true, '()' will be appended to :func: etc. cross-reference text. # add_function_parentheses = True # If true, the current module name will be prepended to all description # unit titles (such as .. function::). # add_module_names = True # If true, sectionauthor and moduleauthor directives will be shown in the # output. They are ignored by default. # show_authors = False # The name of the Pygments (syntax highlighting) style to use. pygments_style = 'sphinx' # A list of ignored prefixes for module index sorting. # modindex_common_prefix = [] # If true, keep warnings as ""system message"" paragraphs in the built documents. # keep_warnings = False # -- Options for HTML output ---------------------------------------------- # The theme to use for HTML and HTML Help pages. See the documentation for # a list of builtin themes. html_theme = 'default' # Theme options are theme-specific and customize the look and feel of a theme # further. For a list of options available for each theme, see the # documentation. # html_theme_options = {} # Add any paths that contain custom themes here, relative to this directory. # html_theme_path = [] # The name for this set of Sphinx documents. If None, it defaults to # ""<project> v<release> documentation"". # html_title = None # A shorter title for the navigation bar. Default is the same as html_title. # html_short_title = None # The name of an image file (relative to this directory) to place at the top # of the sidebar. # html_logo = None # The name of an image file (within the static path) to use as favicon of the # docs. This file should be a Windows icon file (.ico) being 16x16 or 32x32 # pixels large. # html_favicon = None # Add any paths that contain custom static files (such as style sheets) here, # relative to this directory. They are copied after the builtin static files, # so a file named ""default.css"" will overwrite the builtin ""default.css"". html_static_path = ['_static'] # Add any extra paths that contain custom files (such as robots.txt or # .htaccess) here, relative to this directory. These files are copied # directly to the root of the documentation. # html_extra_path = [] # If not '', a 'Last updated on:' timestamp is inserted at every page bottom, # using the given strftime format. # html_last_updated_fmt = '%b %d, %Y' # If true, SmartyPants will be used to convert quotes and dashes to # typographically correct entities. # html_use_smartypants = True # Custom sidebar templates, maps document names to template names. # html_sidebars = {} # Additional templates that should be rendered to pages, maps page names to # template names. # html_additional_pages = {} # If false, no module index is generated. # html_domain_indices = True # If false, no index is generated. # html_use_index = True # If true, the index is split into individual pages for each letter. # html_split_index = False # If true, links to the reST sources are added to the pages. # html_show_sourcelink = True # If true, ""Created using Sphinx"" is shown in the HTML footer. Default is True. # html_show_sphinx = True # If true, ""(C) Copyright ..."" is shown in the HTML footer. Default is True. # html_show_copyright = True # If true, an OpenSearch description file will be output, and all pages will # contain a <link> tag referring to it. The value of this option must be the # base URL from which the finished HTML is served. # html_use_opensearch = '' # This is the file name suffix for HTML files (e.g. "".xhtml""). # html_file_suffix = None # Output file base name for HTML help builder. htmlhelp_basename = 'GnocchiReleaseNotestdoc' # -- Options for LaTeX output --------------------------------------------- latex_elements = { # The paper size ('letterpaper' or 'a4paper'). # 'papersize': 'letterpaper', # The font size ('10pt', '11pt' or '12pt'). # 'pointsize': '10pt', # Additional stuff for the LaTeX preamble. # 'preamble': '', } # Grouping the document tree into LaTeX files. List of tuples # (source start file, target name, title, # author, documentclass [howto, manual, or own class]). latex_documents = [ ('index', 'Gnocchi.tex', u'Gnocchi Release Notes Documentation', u'Gnocchi developers', 'manual'), ] # The name of an image file (relative to this directory) to place at the top of # the title page. # latex_logo = None # For ""manual"" documents, if this is true, then toplevel headings are parts, # not chapters. # latex_use_parts = False # If true, show page references after internal links. # latex_show_pagerefs = False # If true, show URL addresses after external links. # latex_show_urls = False # Documents to append as an appendix to all manuals. # latex_appendices = [] # If false, no module index is generated. # latex_domain_indices = True # -- Options for manual page output --------------------------------------- # One entry per manual page. List of tuples # (source start file, name, description, authors, manual section). man_pages = [ ('index', 'gnocchi', u'Gnocchi Release Notes Documentation', [u'Gnocchi developers'], 1) ] # If true, show URL addresses after external links. # man_show_urls = False # -- Options for Texinfo output ------------------------------------------- # Grouping the document tree into Texinfo files. List of tuples # (source start file, target name, title, author, # dir menu entry, description, category) texinfo_documents = [ ('index', 'Gnocchi', u'Gnocchi Release Notes Documentation', u'Gnocchi developers', 'Gnocchi', 'Gnocchi is a multi-tenant timeseries, metrics and resources database.', 'Miscellaneous'), ] # Documents to append as an appendix to all manuals. # texinfo_appendices = [] # If false, no module index is generated. # texinfo_domain_indices = True # How to display URL addresses: 'footnote', 'no', or 'inline'. # texinfo_show_urls = 'footnote' # If true, do not generate a @detailmenu in the ""Top"" node's menu. # texinfo_no_detailmenu = False ",12,297
openstack%2Fpython-searchlightclient~master~Icc416be929d046e661f51734f4f23f86f688e664,openstack/python-searchlightclient,master,Icc416be929d046e661f51734f4f23f86f688e664,Updated from global requirements,MERGED,2016-08-25 01:11:42.000000000,2016-08-29 16:52:29.000000000,2016-08-29 16:52:29.000000000,"[{'_account_id': 3}, {'_account_id': 7665}, {'_account_id': 14680}]","[{'number': 1, 'created': '2016-08-25 01:11:42.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/python-searchlightclient/commit/10708d25a7a1e80fc99d3c95dd944abd5309d2ee', 'message': 'Updated from global requirements\n\nChange-Id: Icc416be929d046e661f51734f4f23f86f688e664\n'}]",0,360159,10708d25a7a1e80fc99d3c95dd944abd5309d2ee,10,3,1,11131,,,0,"Updated from global requirements

Change-Id: Icc416be929d046e661f51734f4f23f86f688e664
",git fetch https://review.opendev.org/openstack/python-searchlightclient refs/changes/59/360159/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,10708d25a7a1e80fc99d3c95dd944abd5309d2ee,openstack/requirements,osc-lib>=1.0.2 # Apache-2.0,osc-lib>=0.4.0 # Apache-2.0,1,1
openstack%2Fsearchlight-ui~master~I016d0acae32524f38abf41d60684a7b9b86e1198,openstack/searchlight-ui,master,I016d0acae32524f38abf41d60684a7b9b86e1198,Add Angular Instance actions,MERGED,2016-08-17 20:58:49.000000000,2016-08-29 16:50:20.000000000,2016-08-29 16:50:20.000000000,"[{'_account_id': 3}, {'_account_id': 7665}, {'_account_id': 14124}]","[{'number': 1, 'created': '2016-08-17 20:58:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/searchlight-ui/commit/f27958760f0841b391d7e03117c277e59e72d4c6', 'message': 'Add Angular Instance actions\n\nThis patch adds registered Angular Instance actions.\n\nYou will need the following patch in Horizon:\nhttps://review.openstack.org/#/c/344949/\n\nChange-Id: I016d0acae32524f38abf41d60684a7b9b86e1198\n'}, {'number': 2, 'created': '2016-08-18 14:17:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/searchlight-ui/commit/aec25829fca686897e9f82c681badcdb734da924', 'message': 'Add Angular Instance actions\n\nThis patch adds registered Angular Instance actions.\n\nYou will need the following patch in Horizon:\nhttps://review.openstack.org/#/c/344949/\n\nChange-Id: I016d0acae32524f38abf41d60684a7b9b86e1198\nCo-Authored-By: Tyr Johanson <tyr@hpe.com>'}, {'number': 3, 'created': '2016-08-23 16:53:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/searchlight-ui/commit/3ccbe3b93206e5837c7907bf27a12276349c0805', 'message': 'Add Angular Instance actions\n\nThis patch adds registered Angular Instance actions.\n\nYou will need the following patch in Horizon:\nhttps://review.openstack.org/#/c/344949/\n\nChange-Id: I016d0acae32524f38abf41d60684a7b9b86e1198\nCo-Authored-By: Tyr Johanson <tyr@hpe.com>'}, {'number': 4, 'created': '2016-08-24 20:22:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/searchlight-ui/commit/16f2a281f1fe3a24e8e4b689cd262c2eb716c78c', 'message': 'Add Angular Instance actions\n\nThis patch adds registered Angular Instance actions.\n\nChange-Id: I016d0acae32524f38abf41d60684a7b9b86e1198\nCo-Authored-By: Tyr Johanson <tyr@hpe.com>\n'}, {'number': 5, 'created': '2016-08-24 23:02:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/searchlight-ui/commit/c274327b7c2b2204fd222a98420fe8ac228db2c6', 'message': 'Add Angular Instance actions\n\nThis patch adds registered Angular Instance actions.\n\nChange-Id: I016d0acae32524f38abf41d60684a7b9b86e1198\nCo-Authored-By: Tyr Johanson <tyr@hpe.com>\n'}, {'number': 6, 'created': '2016-08-29 14:16:49.000000000', 'files': ['searchlight_ui/static/resources/os-nova-servers/actions/create-snapshot.controller.spec.js', 'searchlight_ui/static/resources/os-nova-servers/actions/generic-actions.service.spec.js', 'searchlight_ui/static/resources/os-nova-servers/actions/hard-reboot.service.js', 'searchlight_ui/static/resources/os-nova-servers/actions/unpause.service.js', 'searchlight_ui/static/resources/os-nova-servers/actions/start.service.js', 'searchlight_ui/static/resources/os-nova-servers/actions/actions.module.js', 'searchlight_ui/static/resources/os-nova-servers/actions/attach-interface.service.js', 'searchlight_ui/static/resources/os-nova-servers/actions/create-snapshot.html', 'searchlight_ui/static/resources/os-nova-servers/actions/suspend.service.js', 'searchlight_ui/static/resources/os-nova-servers/actions/soft-reboot.service.js', 'searchlight_ui/static/resources/os-nova-servers/actions/pause.service.js', 'searchlight_ui/static/resources/os-nova-servers/actions/launch-instance.service.js', 'searchlight_ui/static/resources/os-nova-servers/actions/create-snapshot.controller.js', 'searchlight_ui/static/resources/os-nova-servers/actions/create-snapshot.service.spec.js', 'searchlight_ui/static/resources/os-nova-servers/actions/launch-instance.service.spec.js', 'searchlight_ui/static/resources/os-nova-servers/actions/delete-instance.service.js', 'searchlight_ui/static/resources/os-nova-servers/os-nova-servers.module.js', 'searchlight_ui/static/resources/os-nova-servers/actions/generic-simple.service.js', 'searchlight_ui/static/resources/os-nova-servers/actions/resume.service.js', 'searchlight_ui/static/resources/os-nova-servers/actions/stop.service.js', 'searchlight_ui/static/resources/os-nova-servers/actions/delete-instance.service.spec.js', 'searchlight_ui/static/resources/os-nova-servers/actions/create-snapshot.service.js'], 'web_link': 'https://opendev.org/openstack/searchlight-ui/commit/64ebccf6a005e9b7625125007bbb9be6b0d4848c', 'message': 'Add Angular Instance actions\n\nThis patch adds registered Angular Instance actions.\n\nChange-Id: I016d0acae32524f38abf41d60684a7b9b86e1198\nCo-Authored-By: Tyr Johanson <tyr@hpe.com>\n'}]",0,356716,64ebccf6a005e9b7625125007bbb9be6b0d4848c,29,3,6,14124,,,0,"Add Angular Instance actions

This patch adds registered Angular Instance actions.

Change-Id: I016d0acae32524f38abf41d60684a7b9b86e1198
Co-Authored-By: Tyr Johanson <tyr@hpe.com>
",git fetch https://review.opendev.org/openstack/searchlight-ui refs/changes/16/356716/2 && git format-patch -1 --stdout FETCH_HEAD,"['searchlight_ui/static/resources/os-nova-servers/actions/create-snapshot.controller.spec.js', 'searchlight_ui/static/resources/os-nova-servers/actions/generic-actions.service.spec.js', 'searchlight_ui/static/resources/os-nova-servers/actions/hard-reboot.service.js', 'searchlight_ui/static/resources/os-nova-servers/actions/unpause.service.js', 'searchlight_ui/static/resources/os-nova-servers/actions/start.service.js', 'searchlight_ui/static/resources/os-nova-servers/actions/actions.module.js', 'searchlight_ui/static/resources/os-nova-servers/actions/attach-interface.service.js', 'searchlight_ui/static/resources/os-nova-servers/actions/create-snapshot.html', 'searchlight_ui/static/resources/os-nova-servers/actions/suspend.service.js', 'searchlight_ui/static/resources/os-nova-servers/actions/soft-reboot.service.js', 'searchlight_ui/static/resources/os-nova-servers/actions/pause.service.js', 'searchlight_ui/static/resources/os-nova-servers/actions/launch-instance.service.js', 'searchlight_ui/static/resources/os-nova-servers/actions/create-snapshot.controller.js', 'searchlight_ui/static/resources/os-nova-servers/actions/create-snapshot.service.spec.js', 'searchlight_ui/static/resources/os-nova-servers/actions/launch-instance.service.spec.js', 'searchlight_ui/static/resources/os-nova-servers/actions/delete-instance.service.js', 'searchlight_ui/static/resources/os-nova-servers/os-nova-servers.module.js', 'searchlight_ui/static/resources/os-nova-servers/actions/generic-simple.service.js', 'searchlight_ui/static/resources/os-nova-servers/actions/resume.service.js', 'searchlight_ui/static/resources/os-nova-servers/actions/stop.service.js', 'searchlight_ui/static/resources/os-nova-servers/actions/delete-instance.service.spec.js', 'searchlight_ui/static/resources/os-nova-servers/actions/create-snapshot.service.js']",22,f27958760f0841b391d7e03117c277e59e72d4c6,instance-details,"/** * * (c) Copyright 2016 Hewlett Packard Enterprise Development Company LP * * Licensed under the Apache License, Version 2.0 (the ""License""); you may * not use self file except in compliance with the License. You may obtain * a copy of the License at * * http://www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing, software * distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the * License for the specific language governing permissions and limitations * under the License. */ (function() { 'use strict'; angular .module('resources.os-nova-servers.actions') .factory('resources.os-nova-servers.actions.create-snapshot.service', createSnapshotService); createSnapshotService.$inject = [ '$modal', '$q', 'horizon.app.core.basePath', 'horizon.app.core.images.resourceType', 'horizon.app.core.openstack-service-api.nova', 'horizon.app.core.openstack-service-api.policy', 'horizon.app.core.openstack-service-api.serviceCatalog', 'horizon.framework.util.q.extensions', 'horizon.framework.widgets.toast.service', 'horizon.framework.widgets.modal-wait-spinner.service' ]; /** * @ngDoc factory * @name horizon.app.core.images.actions.create-volume.service * * @Description * Brings up the Create Instance snapshot modal. */ function createSnapshotService( $modal, $q, basePath, imageResourceType, nova, policy, serviceCatalog, $qExtensions, toast, waitSpinner ) { var createSnapshotPolicy, computeServiceEnabled, newSnapshotName; var SNAPSHOT_READY_STATES = [""ACTIVE"", ""SHUTOFF"", ""PAUSED"", ""SUSPENDED""]; var message = { success: gettext('Snapshot %s was successfully created.') }; var service = { initScope: initScope, allowed: allowed, perform: perform }; return service; ///////////////// function initScope() { createSnapshotPolicy = policy.ifAllowed({rules: [['compute', 'compute:snapshot']]}); computeServiceEnabled = serviceCatalog.ifTypeEnabled('compute'); } function allowed(instance) { return $q.all([ createSnapshotPolicy, computeServiceEnabled, instanceSnapshotReady(instance), instanceNotDeleting(instance) ]); } function perform(instance) { var modalParams = { templateUrl: basePath + 'instances/actions/create-snapshot.html', controller: ""CreateSnapshotController as ctrl"", resolve: { context: function() { return { name: undefined, instance_id: instance.id }; } } }; return $modal.open(modalParams).result.then(onSubmit, onCancel); } function onSubmit(context) { // The nova call doesn't return the name of the newly created snapshot. // Instead, remember it so we can display it in the success message. newSnapshotName = context.name; waitSpinner.showModalSpinner(gettext('Creating Snapshot')); return nova.createServerSnapshot({ name: context.name, instance_id: context.instance_id }).then(onSuccess, onFailure); } function onCancel() { waitSpinner.hideModalSpinner(); } function onSuccess(response) { waitSpinner.hideModalSpinner(); var snapshotId = response.data; toast.add('success', interpolate(message.success, [newSnapshotName])); // To make the result of this action generically useful, reformat the return // from the deleteModal into a standard form return { created: [{type: imageResourceType, id: snapshotId}], updated: [], deleted: [], failed: [] }; } function onFailure() { waitSpinner.hideModalSpinner(); } function instanceSnapshotReady(instance) { return $qExtensions.booleanAsPromise( SNAPSHOT_READY_STATES.indexOf(instance.status) >= 0); } function instanceNotDeleting(instance) { var result, taskState; taskState = instance[""OS-EXT-STS:task_state""]; if (!taskState) { result = true; } else { result = taskState.toLowerCase() !== ""deleting""; } return $qExtensions.booleanAsPromise(result); } } })(); ",,1974,1
openstack%2Ftripleo-ci~master~I00d2b3eb9aab9e15965013dd590255dab28f8ffe,openstack/tripleo-ci,master,I00d2b3eb9aab9e15965013dd590255dab28f8ffe,Print services statuses of nodes in CI,MERGED,2016-08-09 13:55:05.000000000,2016-08-29 16:48:42.000000000,2016-08-29 15:59:50.000000000,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 1926}, {'_account_id': 3153}, {'_account_id': 4328}, {'_account_id': 6928}, {'_account_id': 7144}, {'_account_id': 10873}, {'_account_id': 10969}]","[{'number': 1, 'created': '2016-08-09 13:55:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/5cd6b3a77a399f6c103787c554ca54e124661e43', 'message': 'WIP: additional info about host in CI\n\nList all services with their statuses for all machines and\nenvironment variables for undercloud\n\nChange-Id: I00d2b3eb9aab9e15965013dd590255dab28f8ffe\n'}, {'number': 2, 'created': '2016-08-09 18:42:57.000000000', 'files': ['scripts/get_host_info.sh'], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/e3573dd2638a02973112431f89a6db0b55b63ced', 'message': 'Print services statuses of nodes in CI\n\nList all services with their statuses for all machines\n\nChange-Id: I00d2b3eb9aab9e15965013dd590255dab28f8ffe\n'}]",0,352916,e3573dd2638a02973112431f89a6db0b55b63ced,30,9,2,10969,,,0,"Print services statuses of nodes in CI

List all services with their statuses for all machines

Change-Id: I00d2b3eb9aab9e15965013dd590255dab28f8ffe
",git fetch https://review.opendev.org/openstack/tripleo-ci refs/changes/16/352916/2 && git format-patch -1 --stdout FETCH_HEAD,['scripts/get_host_info.sh'],1,5cd6b3a77a399f6c103787c554ca54e124661e43,ext,systemctl list-units -la env | sudo tee /var/log/environment.txt,,2,0
openstack%2Frequirements~master~Id11697d27aaefee8a97fae1e1996fc656ca4b363,openstack/requirements,master,Id11697d27aaefee8a97fae1e1996fc656ca4b363,update constraint for oslotest to new release 2.10.0,MERGED,2016-08-25 12:00:57.000000000,2016-08-29 16:43:52.000000000,2016-08-29 16:43:52.000000000,"[{'_account_id': 3}, {'_account_id': 11105}, {'_account_id': 12898}, {'_account_id': 14288}]","[{'number': 1, 'created': '2016-08-25 12:00:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/e410162e57789b424f0f151fbafb1957d0382b03', 'message': 'update constraint for oslotest to new release 2.10.0\n\noslotest 2.10.0 release\n\nChange-Id: Id11697d27aaefee8a97fae1e1996fc656ca4b363\nmeta:version: 2.10.0\nmeta:diff-start: -\nmeta:series: newton\nmeta:release-type: release\nmeta:announce: openstack-dev@lists.openstack.org\nmeta:pypi: yes\nmeta:first: no\nmeta:release:Author: Joshua Harlow <jxharlow@godaddy.com>\nmeta:release:Commit: Davanum Srinivas <davanum@gmail.com>\nmeta:release:Change-Id: I3c4738cb6fc0baf1e15c9bc17864a6d79a4a786b\n'}, {'number': 2, 'created': '2016-08-26 04:12:23.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/60508e0b621c43835aefb3540c455a0a5b1c2306', 'message': 'update constraint for oslotest to new release 2.10.0\n\noslotest 2.10.0 release\n\nChange-Id: Id11697d27aaefee8a97fae1e1996fc656ca4b363\nmeta:version: 2.10.0\nmeta:diff-start: -\nmeta:series: newton\nmeta:release-type: release\nmeta:announce: openstack-dev@lists.openstack.org\nmeta:pypi: yes\nmeta:first: no\nmeta:release:Author: Joshua Harlow <jxharlow@godaddy.com>\nmeta:release:Commit: Davanum Srinivas <davanum@gmail.com>\nmeta:release:Change-Id: I3c4738cb6fc0baf1e15c9bc17864a6d79a4a786b\n'}]",0,360478,60508e0b621c43835aefb3540c455a0a5b1c2306,11,4,2,5638,,,0,"update constraint for oslotest to new release 2.10.0

oslotest 2.10.0 release

Change-Id: Id11697d27aaefee8a97fae1e1996fc656ca4b363
meta:version: 2.10.0
meta:diff-start: -
meta:series: newton
meta:release-type: release
meta:announce: openstack-dev@lists.openstack.org
meta:pypi: yes
meta:first: no
meta:release:Author: Joshua Harlow <jxharlow@godaddy.com>
meta:release:Commit: Davanum Srinivas <davanum@gmail.com>
meta:release:Change-Id: I3c4738cb6fc0baf1e15c9bc17864a6d79a4a786b
",git fetch https://review.opendev.org/openstack/requirements refs/changes/78/360478/1 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,e410162e57789b424f0f151fbafb1957d0382b03,new-release,oslotest===2.10.0,oslotest===2.9.0,1,1
openstack%2Fsolum~master~I565547f86f8d0260f5b8ac79d9539e65cfa2c553,openstack/solum,master,I565547f86f8d0260f5b8ac79d9539e65cfa2c553,Fix output public_ip  in the coreos.yaml,MERGED,2016-08-29 03:28:00.000000000,2016-08-29 16:43:12.000000000,2016-08-29 16:25:06.000000000,"[{'_account_id': 3}, {'_account_id': 2506}, {'_account_id': 7230}, {'_account_id': 14107}, {'_account_id': 20663}, {'_account_id': 23058}]","[{'number': 1, 'created': '2016-08-29 03:28:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/645024976d32680dafcd6c452550a11bb03c7d6b', 'message': 'update coreos.yaml\n\nChange-Id: I565547f86f8d0260f5b8ac79d9539e65cfa2c553\nCloses-Bug: #1617867\n'}, {'number': 2, 'created': '2016-08-29 03:38:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/f4a19ff3638c768e9644445b6314913b39291269', 'message': 'update coreos.yaml\n\nhttp://pasteboard.co/ekdltN4x1.png\nhttp://pasteboard.co/ekaTgXPNH.png\nhttp://pasteboard.co/ekjozmwpN.png\nChange-Id: I565547f86f8d0260f5b8ac79d9539e65cfa2c553\nCloses-Bug: #1617867\n'}, {'number': 3, 'created': '2016-08-29 14:47:24.000000000', 'files': ['etc/solum/templates/coreos.yaml'], 'web_link': 'https://opendev.org/openstack/solum/commit/44a8a017d32c35cfac20020ce228dd6949c29ae6', 'message': 'Fix output public_ip  in the coreos.yaml\n\nCorrectly parsing the output IP address from spun up stack\nhttp://pasteboard.co/ekdltN4x1.png\nhttp://pasteboard.co/ekaTgXPNH.png\nhttp://pasteboard.co/ekjozmwpN.png\nChange-Id: I565547f86f8d0260f5b8ac79d9539e65cfa2c553\nCloses-Bug: #1617867\n'}]",0,361816,44a8a017d32c35cfac20020ce228dd6949c29ae6,19,6,3,20663,,,0,"Fix output public_ip  in the coreos.yaml

Correctly parsing the output IP address from spun up stack
http://pasteboard.co/ekdltN4x1.png
http://pasteboard.co/ekaTgXPNH.png
http://pasteboard.co/ekjozmwpN.png
Change-Id: I565547f86f8d0260f5b8ac79d9539e65cfa2c553
Closes-Bug: #1617867
",git fetch https://review.opendev.org/openstack/solum refs/changes/16/361816/2 && git format-patch -1 --stdout FETCH_HEAD,['etc/solum/templates/coreos.yaml'],1,645024976d32680dafcd6c452550a11bb03c7d6b,bug/1617867," value: { get_attr: [compute_instance, first_address] }", value: get_attr: - compute_instance - accessIPv4,1,4
openstack%2Fsyntribos~master~I28617c64218ab632c1a35083ef9351874054a26d,openstack/syntribos,master,I28617c64218ab632c1a35083ef9351874054a26d,changes to runner and result,MERGED,2016-08-23 22:18:03.000000000,2016-08-29 16:43:01.000000000,2016-08-29 16:43:01.000000000,"[{'_account_id': 3}, {'_account_id': 15515}, {'_account_id': 17709}, {'_account_id': 18462}]","[{'number': 1, 'created': '2016-08-23 22:18:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/syntribos/commit/a04b0b3f3995c24a75c2b8b5031ea4922247236d', 'message': 'fixed results error and failure counting\n\nChange-Id: I28617c64218ab632c1a35083ef9351874054a26d\n'}, {'number': 2, 'created': '2016-08-23 22:18:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/syntribos/commit/d46b55491c325ac1a1de1fe717e64f924c1aa4d6', 'message': 'fixed results error and failure counting\n\nChange-Id: I28617c64218ab632c1a35083ef9351874054a26d\n'}, {'number': 3, 'created': '2016-08-24 19:23:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/syntribos/commit/3611beb41cb6557c71a38e13ae00ad5cf02b0673', 'message': 'fixed results error and failure counting\n\nChange-Id: I28617c64218ab632c1a35083ef9351874054a26d\n'}, {'number': 4, 'created': '2016-08-24 22:29:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/syntribos/commit/5bddd73f4213d664ec4060b937864e0d1d7eece3', 'message': ""changes to runner and result\n\n1) results are now printed at the end of the run or on interrupt, not after\nevery template\n2) made test_id's globally unique\n3) print number of errors next to number of failures\n4) number of failures printed after next to each progress bar and reported\nin total at end of run now match up\n\nChange-Id: I28617c64218ab632c1a35083ef9351874054a26d\n""}, {'number': 5, 'created': '2016-08-24 22:40:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/syntribos/commit/9c8dda901ec8548d9a695cc40c6f62b97c4541c3', 'message': ""changes to runner and result\n\n1) results are now printed at the end of the run or on interrupt, not after\nevery template\n2) made test_id's globally unique\n3) print number of errors next to number of failures\n4) number of failures printed after next to each progress bar and reported\nin total at end of run now match up\n\nChange-Id: I28617c64218ab632c1a35083ef9351874054a26d\n""}, {'number': 6, 'created': '2016-08-25 18:20:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/syntribos/commit/af7343abeac0ce3cf8c475a01f0299a51c1d5a4b', 'message': ""changes to runner and result\n\n1) results are now printed at the end of the run or on interrupt, not after\nevery template\n2) made test_id's globally unique\n3) print number of errors next to number of failures\n4) number of failures printed after next to each progress bar and reported\nin total at end of run now match up\n\nChange-Id: I28617c64218ab632c1a35083ef9351874054a26d\n""}, {'number': 7, 'created': '2016-08-25 19:37:46.000000000', 'files': ['syntribos/tests/base.py', 'syntribos/runner.py', 'syntribos/result.py'], 'web_link': 'https://opendev.org/openstack/syntribos/commit/e442dc8f6d896f481c31895feb61f843bb8ffa4f', 'message': ""changes to runner and result\n\n1) results are now printed at the end of the run or on interrupt, not after\nevery template\n2) made test_id's globally unique\n3) print number of errors next to number of failures\n4) number of failures printed after next to each progress bar and reported\nin total at end of run now match up\n\nChange-Id: I28617c64218ab632c1a35083ef9351874054a26d\n""}]",2,359463,e442dc8f6d896f481c31895feb61f843bb8ffa4f,22,4,7,17709,,,0,"changes to runner and result

1) results are now printed at the end of the run or on interrupt, not after
every template
2) made test_id's globally unique
3) print number of errors next to number of failures
4) number of failures printed after next to each progress bar and reported
in total at end of run now match up

Change-Id: I28617c64218ab632c1a35083ef9351874054a26d
",git fetch https://review.opendev.org/openstack/syntribos refs/changes/63/359463/7 && git format-patch -1 --stdout FETCH_HEAD,"['syntribos/tests/base.py', 'syntribos/runner.py', 'syntribos/result.py']",3,a04b0b3f3995c24a75c2b8b5031ea4922247236d,config,"def print_log_path_and_stats(result, start_time, testsRun): print(""\nTotal: {f} failure(s) and {e} error(s)"".format( f=result.failures, e=result.errors))def print_result(result, start_time, failures, errors):","def print_log_path_and_stats(start_time, testsRun):def print_result(result, start_time): failures = len(result.failures) errors = len(result.errors)",40,20
openstack%2Ftempest~master~Ief79a6cee55ff5faf64465f6cbc84bec8253a3e1,openstack/tempest,master,Ief79a6cee55ff5faf64465f6cbc84bec8253a3e1,Scenario: remove the `addCleanup_with_wait` helper method.,MERGED,2016-06-20 16:59:24.000000000,2016-08-29 16:38:49.000000000,2016-08-29 16:38:49.000000000,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 4656}, {'_account_id': 6167}, {'_account_id': 7350}, {'_account_id': 9152}, {'_account_id': 9622}, {'_account_id': 9732}, {'_account_id': 10385}, {'_account_id': 12017}, {'_account_id': 14885}, {'_account_id': 21152}]","[{'number': 1, 'created': '2016-06-20 16:59:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/03875200c490127acfd0cbe2c1d7dce6e28f8963', 'message': 'Scenario: remove the `addCleanup_with_wait` helper method.\n\nIt was way too complex. And not used a lot.\n\nAlso remove the related \'wait_on_delete=True\' keyword argument\nof ""create_server"" method because no caller called that method\nwith another value than the default value. Which proved that this\nkwarg was useless.\n\nChange-Id: Ief79a6cee55ff5faf64465f6cbc84bec8253a3e1\n'}, {'number': 2, 'created': '2016-06-20 17:01:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/67d4a363c94904957ae34ac355c51e26fee3a9e6', 'message': 'Scenario: remove the `addCleanup_with_wait` helper method.\n\nIt was way too complex. And not used a lot.\n\nAlso remove the related \'wait_on_delete=True\' keyword argument\nof ""create_server"" method because no caller called that method\nwith another value than the default value. Which proved that this\nkwarg was useless.\n\nChange-Id: Ief79a6cee55ff5faf64465f6cbc84bec8253a3e1\n'}, {'number': 3, 'created': '2016-07-05 13:13:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/f161363583aace2e45dd8e2a7657f84852a53759', 'message': 'Scenario: remove the `addCleanup_with_wait` helper method.\n\nIt was way too complex. And not used a lot.\n\nAlso remove the related \'wait_on_delete=True\' keyword argument\nof ""create_server"" method because no caller called that method\nwith another value than the default value. Which proved that this\nkwarg was useless.\n\nChange-Id: Ief79a6cee55ff5faf64465f6cbc84bec8253a3e1\n'}, {'number': 4, 'created': '2016-08-06 22:10:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/cc6363e28c0da0f1980e09930dd2481a26a9405e', 'message': 'Scenario: remove the `addCleanup_with_wait` helper method.\n\nIt was way too complex. And not used a lot.\n\nAlso remove the related \'wait_on_delete=True\' keyword argument\nof ""create_server"" method because no caller called that method\nwith another value than the default value. Which proved that this\nkwarg was useless.\n\nChange-Id: Ief79a6cee55ff5faf64465f6cbc84bec8253a3e1\n'}, {'number': 5, 'created': '2016-08-18 16:24:28.000000000', 'files': ['tempest/scenario/manager.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/f672b7d317c99dd687bb8140b184cfa7b8749fa6', 'message': 'Scenario: remove the `addCleanup_with_wait` helper method.\n\nIt was way too complex. And not used a lot.\n\nAlso remove the related \'wait_on_delete=True\' keyword argument\nof ""create_server"" method because no caller called that method\nwith another value than the default value. Which proved that this\nkwarg was useless.\n\nChange-Id: Ief79a6cee55ff5faf64465f6cbc84bec8253a3e1\n'}]",0,331764,f672b7d317c99dd687bb8140b184cfa7b8749fa6,35,12,5,7350,,,0,"Scenario: remove the `addCleanup_with_wait` helper method.

It was way too complex. And not used a lot.

Also remove the related 'wait_on_delete=True' keyword argument
of ""create_server"" method because no caller called that method
with another value than the default value. Which proved that this
kwarg was useless.

Change-Id: Ief79a6cee55ff5faf64465f6cbc84bec8253a3e1
",git fetch https://review.opendev.org/openstack/tempest refs/changes/64/331764/1 && git format-patch -1 --stdout FETCH_HEAD,['tempest/scenario/manager.py'],1,03875200c490127acfd0cbe2c1d7dce6e28f8963,kill_add_cleanup_with_wait," clients=None, **kwargs): self.addCleanup(waiters.wait_for_server_termination, clients.servers_client, body['id']) self.addCleanup(test_utils.call_and_ignore_notfound_exc, clients.servers_client.delete_server, body['id']) self.addCleanup(_image_client.wait_for_resource_deletion, image_id) self.addCleanup(test_utils.call_and_ignore_notfound_exc, _image_client.delete_image, image_id) "," # NOTE(yfried): this list is cleaned at the end of test_methods and # not at the end of the class self.addCleanup(self._wait_for_cleanups) def addCleanup_with_wait(self, waiter_callable, thing_id, thing_id_param, cleanup_callable, cleanup_args=None, cleanup_kwargs=None, waiter_client=None): """"""Adds wait for async resource deletion at the end of cleanups @param waiter_callable: callable to wait for the resource to delete with the following waiter_client if specified. @param thing_id: the id of the resource to be cleaned-up @param thing_id_param: the name of the id param in the waiter @param cleanup_callable: method to load pass to self.addCleanup with the following *cleanup_args, **cleanup_kwargs. usually a delete method. """""" if cleanup_args is None: cleanup_args = [] if cleanup_kwargs is None: cleanup_kwargs = {} self.addCleanup(cleanup_callable, *cleanup_args, **cleanup_kwargs) wait_dict = { 'waiter_callable': waiter_callable, thing_id_param: thing_id } if waiter_client: wait_dict['client'] = waiter_client self.cleanup_waits.append(wait_dict) def _wait_for_cleanups(self): # To handle async delete actions, a list of waits is added # which will be iterated over as the last step of clearing the # cleanup queue. That way all the delete calls are made up front # and the tests won't succeed unless the deletes are eventually # successful. This is the same basic approach used in the api tests to # limit cleanup execution time except here it is multi-resource, # because of the nature of the scenario tests. for wait in self.cleanup_waits: waiter_callable = wait.pop('waiter_callable') waiter_callable(**wait) wait_on_delete=True, clients=None, **kwargs): # TODO(jlanoux) Move wait_on_delete in compute.py if wait_on_delete: self.addCleanup(waiters.wait_for_server_termination, clients.servers_client, body['id']) self.addCleanup_with_wait( waiter_callable=waiters.wait_for_server_termination, thing_id=body['id'], thing_id_param='server_id', cleanup_callable=test_utils.call_and_ignore_notfound_exc, cleanup_args=[clients.servers_client.delete_server, body['id']], waiter_client=clients.servers_client) self.addCleanup_with_wait( waiter_callable=_image_client.wait_for_resource_deletion, thing_id=image_id, thing_id_param='id', cleanup_callable=test_utils.call_and_ignore_notfound_exc, cleanup_args=[_image_client.delete_image, image_id])",11,60
openstack%2Fneutron~stable%2Fmitaka~I2fba51bdf8c781fcc0449e1e9947de976c96eec4,openstack/neutron,stable/mitaka,I2fba51bdf8c781fcc0449e1e9947de976c96eec4,Implement the DELETE method for get-me-a-network,ABANDONED,2016-08-27 16:19:35.000000000,2016-08-29 16:37:41.000000000,,"[{'_account_id': 3}, {'_account_id': 5170}, {'_account_id': 9681}, {'_account_id': 9732}, {'_account_id': 14208}, {'_account_id': 16376}]","[{'number': 1, 'created': '2016-08-27 16:19:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/00d420285ac5f8b6e624f3036b581e5840de213d', 'message': ""Implement the DELETE method for get-me-a-network\n\nReview [1] showed how tricky it can be to let the client\nside deal with auto-network-topology cleanups. Rather than\npushing this complexity to the client, we should implement\nthe DELETE method for this extension, as it's rather\ntrival to do on this server side.\n\nSince the DELETE method is exposed, but it fails with 500,\nit is reasonable to deal with this as a bug fix, rather than\nhaving to go through yet another extension. The neutronclient\nside support should be added, but since the first user of this\nis Tempest, we can safely assume they can leverage this directly\nwithout depending on a python-neutronclient version bump.\n\n[1] https://review.openstack.org/#/c/327191/\n\nCloses-bug: #1614872\n\n(cherry picked from commit dfa702fac80312b0c5b93c78e92f9d01ea11bbd6)\n\nConflicts:\n\tneutron/tests/tempest/services/network/json/network_client.py\n\nChange-Id: I2fba51bdf8c781fcc0449e1e9947de976c96eec4\n""}, {'number': 2, 'created': '2016-08-27 16:24:58.000000000', 'files': ['neutron/services/auto_allocate/db.py', 'neutron/tests/api/test_auto_allocated_topology.py', 'neutron/tests/tempest/services/network/json/network_client.py', 'neutron/tests/unit/services/auto_allocate/test_db.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/79c0adab5e6a903b043c627c1147db6f66d41e95', 'message': ""Implement the DELETE method for get-me-a-network\n\nReview [1] showed how tricky it can be to let the client\nside deal with auto-network-topology cleanups. Rather than\npushing this complexity to the client, we should implement\nthe DELETE method for this extension, as it's rather\ntrival to do on this server side.\n\nSince the DELETE method is exposed, but it fails with 500,\nit is reasonable to deal with this as a bug fix, rather than\nhaving to go through yet another extension. The neutronclient\nside support should be added, but since the first user of this\nis Tempest, we can safely assume they can leverage this directly\nwithout depending on a python-neutronclient version bump.\n\n[1] https://review.openstack.org/#/c/327191/\n\nCloses-bug: #1614872\n\n(cherry picked from commit dfa702fac80312b0c5b93c78e92f9d01ea11bbd6)\n\nConflicts:\n\tneutron/tests/tempest/services/network/json/network_client.py\n\nChange-Id: I2fba51bdf8c781fcc0449e1e9947de976c96eec4\n""}]",0,361640,79c0adab5e6a903b043c627c1147db6f66d41e95,10,6,2,748,,,0,"Implement the DELETE method for get-me-a-network

Review [1] showed how tricky it can be to let the client
side deal with auto-network-topology cleanups. Rather than
pushing this complexity to the client, we should implement
the DELETE method for this extension, as it's rather
trival to do on this server side.

Since the DELETE method is exposed, but it fails with 500,
it is reasonable to deal with this as a bug fix, rather than
having to go through yet another extension. The neutronclient
side support should be added, but since the first user of this
is Tempest, we can safely assume they can leverage this directly
without depending on a python-neutronclient version bump.

[1] https://review.openstack.org/#/c/327191/

Closes-bug: #1614872

(cherry picked from commit dfa702fac80312b0c5b93c78e92f9d01ea11bbd6)

Conflicts:
	neutron/tests/tempest/services/network/json/network_client.py

Change-Id: I2fba51bdf8c781fcc0449e1e9947de976c96eec4
",git fetch https://review.opendev.org/openstack/neutron refs/changes/40/361640/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/services/auto_allocate/db.py', 'neutron/tests/api/test_auto_allocated_topology.py', 'neutron/tests/tempest/services/network/json/network_client.py', 'neutron/tests/unit/services/auto_allocate/test_db.py']",4,00d420285ac5f8b6e624f3036b581e5840de213d,bug/1614872," self.mixin._core_plugin = mock.Mock() def test__cleanup_handles_failures(self): retry_then_notfound = ( [db_exc.RetryRequest(ValueError())] + [n_exc.NotFound()] * 10 ) self.mixin._l3_plugin.remove_router_interface.side_effect = ( retry_then_notfound) self.mixin._l3_plugin.delete_router.side_effect = ( retry_then_notfound) self.mixin._core_plugin.delete_network.side_effect = ( retry_then_notfound) self.mixin._cleanup(self.ctx, network_id=44, router_id=45, subnets=[{'id': 46}])",,140,23
openstack%2Fneutron~stable%2Fmitaka~I3d62af3018fb834ec85771d8bc8e7379cc80b72a,openstack/neutron,stable/mitaka,I3d62af3018fb834ec85771d8bc8e7379cc80b72a,Make auto allocate cleanup retry,ABANDONED,2016-08-27 16:15:33.000000000,2016-08-29 16:37:39.000000000,,"[{'_account_id': 3}, {'_account_id': 5170}, {'_account_id': 7787}, {'_account_id': 9681}, {'_account_id': 9732}, {'_account_id': 14208}, {'_account_id': 16376}]","[{'number': 1, 'created': '2016-08-27 16:15:33.000000000', 'files': ['neutron/services/auto_allocate/db.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/b51f747eecd9e7eb18adffbf4fd1e31f2392457e', 'message': 'Make auto allocate cleanup retry\n\nThis adds a retry decorator to the auto allocate cleanup logic\nso it can handle retriable errors during cleanup. It also adds\ncatches for notfound errors to make the function idempotent so\nit works on retries.\n\nChange-Id: I3d62af3018fb834ec85771d8bc8e7379cc80b72a\nCloses-Bug: #1615710\n(cherry picked from commit 11849b7279c5e7afe686fab6f4b21ce6f7366c14)\n'}]",0,361639,b51f747eecd9e7eb18adffbf4fd1e31f2392457e,8,7,1,748,,,0,"Make auto allocate cleanup retry

This adds a retry decorator to the auto allocate cleanup logic
so it can handle retriable errors during cleanup. It also adds
catches for notfound errors to make the function idempotent so
it works on retries.

Change-Id: I3d62af3018fb834ec85771d8bc8e7379cc80b72a
Closes-Bug: #1615710
(cherry picked from commit 11849b7279c5e7afe686fab6f4b21ce6f7366c14)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/39/361639/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/services/auto_allocate/db.py'],1,b51f747eecd9e7eb18adffbf4fd1e31f2392457e,bug/1615710," @db_api.retry_db_errors # TODO(kevinbenton): get rid of the retry and notfound exception # handlers once bug/1612798 is resolved try: self.l3_plugin.remove_router_interface( context, router_id, {'subnet_id': subnet['id']}) except n_exc.NotFound: pass try: self.l3_plugin.delete_router(context, router_id) except n_exc.NotFound: pass try: self.core_plugin.delete_network(context, network_id) except n_exc.NotFound: pass"," self.l3_plugin.remove_router_interface( context, router_id, {'subnet_id': subnet['id']}) self.l3_plugin.delete_router(context, router_id) self.core_plugin.delete_network(context, network_id)",16,4
openstack%2Fneutron~stable%2Fmitaka~I76e9f8e4b61fb3566d70af4236c19e4c5a523646,openstack/neutron,stable/mitaka,I76e9f8e4b61fb3566d70af4236c19e4c5a523646,Make auto-allocate plugin handle sneaky DB errors,ABANDONED,2016-08-27 16:15:11.000000000,2016-08-29 16:37:36.000000000,,"[{'_account_id': 3}, {'_account_id': 5170}, {'_account_id': 9681}, {'_account_id': 9732}, {'_account_id': 14208}, {'_account_id': 16376}]","[{'number': 1, 'created': '2016-08-27 16:15:11.000000000', 'files': ['neutron/services/auto_allocate/db.py', 'neutron/tests/unit/services/auto_allocate/test_db.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/4f2774788dbc4d07f0a65d2f413781db5f9cba27', 'message': 'Make auto-allocate plugin handle sneaky DB errors\n\nDB errors or retry exceptions that bubble up to the\nplugin may get masked by integrity violation errors\ndue to partial provisioning of resources. When that\nhappens, we should make sure any pending resource\nis cleaned up before reattempting the operation.\n\nCloses-bug: #1612615\n\n(cherry picked from commit aa42906143f09a8cf40dfcd91bb211eac6689b80)\n\nConflicts:\n\tneutron/services/auto_allocate/db.py\n\tneutron/tests/unit/services/auto_allocate/test_db.py\n\nChange-Id: I76e9f8e4b61fb3566d70af4236c19e4c5a523646\n'}]",0,361638,4f2774788dbc4d07f0a65d2f413781db5f9cba27,8,6,1,748,,,0,"Make auto-allocate plugin handle sneaky DB errors

DB errors or retry exceptions that bubble up to the
plugin may get masked by integrity violation errors
due to partial provisioning of resources. When that
happens, we should make sure any pending resource
is cleaned up before reattempting the operation.

Closes-bug: #1612615

(cherry picked from commit aa42906143f09a8cf40dfcd91bb211eac6689b80)

Conflicts:
	neutron/services/auto_allocate/db.py
	neutron/tests/unit/services/auto_allocate/test_db.py

Change-Id: I76e9f8e4b61fb3566d70af4236c19e4c5a523646
",git fetch https://review.opendev.org/openstack/neutron refs/changes/38/361638/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/services/auto_allocate/db.py', 'neutron/tests/unit/services/auto_allocate/test_db.py']",2,4f2774788dbc4d07f0a65d2f413781db5f9cba27,bug/1612615,"from oslo_db import exception as db_exc def _test__build_topology(self, exception): with mock.patch.object(self.mixin, '_provision_tenant_private_network', side_effect=exception), \ mock.patch.object(self.mixin, '_cleanup') as f: self.assertRaises(exception, self.mixin._build_topology, self.ctx, mock.ANY, 'foo_net') return f.call_count def test__build_topology_retriable_exception(self): self.assertTrue(self._test__build_topology(db_exc.DBConnectionError)) def test__build_topology_non_retriable_exception(self): self.assertFalse(self._test__build_topology(Exception)) ",,59,18
openstack%2Fneutron~stable%2Fmitaka~Ia6ff5ad975673875216eb470080dfc0dcf6b9ab2,openstack/neutron,stable/mitaka,Ia6ff5ad975673875216eb470080dfc0dcf6b9ab2,Create auto allocated networks in disabled state,ABANDONED,2016-08-27 16:04:22.000000000,2016-08-29 16:37:33.000000000,,"[{'_account_id': 3}, {'_account_id': 5170}, {'_account_id': 9681}, {'_account_id': 9732}, {'_account_id': 14208}, {'_account_id': 16376}]","[{'number': 1, 'created': '2016-08-27 16:04:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/8686f28335fbb6158fb9cec65e306f7021c29847', 'message': 'Create auto allocated networks in disabled state\n\nUnder particular circumstances, multiple requests to the\nauto-allocated-topology extension may lead to the transient\ncreation of duplicated resources. This is dealt with by the\nservice plugin code, which cleans them up once the condition\nis detected. However the client may accidentally be impacted\nand potentially left in error (recoverable on retry).\n\nIn order to address this error condition, the logic to\nprovision the network for any given tenant is tweaked\nslightly so that the network is created in disabled state\nand re-enabled when it is safe to do so. A Neutron client\nshould check the network status to see if the network is\nready for use before getting its hands on it.\n\nCloses-bug: #1591766\n\n(cherry picked from commit d91a4e1930bd8f05f7b2055a2278f5bd788cd6b4)\n\nConflicts:\n\tneutron/plugins/common/utils.py\n\nChange-Id: Ia6ff5ad975673875216eb470080dfc0dcf6b9ab2\n'}, {'number': 2, 'created': '2016-08-27 16:08:01.000000000', 'files': ['neutron/services/auto_allocate/db.py', 'neutron/plugins/common/utils.py', 'neutron/tests/api/test_auto_allocated_topology.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/273f5b2b85992f28f77664ac6d6db294ac10dd1f', 'message': 'Create auto allocated networks in disabled state\n\nUnder particular circumstances, multiple requests to the\nauto-allocated-topology extension may lead to the transient\ncreation of duplicated resources. This is dealt with by the\nservice plugin code, which cleans them up once the condition\nis detected. However the client may accidentally be impacted\nand potentially left in error (recoverable on retry).\n\nIn order to address this error condition, the logic to\nprovision the network for any given tenant is tweaked\nslightly so that the network is created in disabled state\nand re-enabled when it is safe to do so. A Neutron client\nshould check the network status to see if the network is\nready for use before getting its hands on it.\n\nCloses-bug: #1591766\n\n(cherry picked from commit d91a4e1930bd8f05f7b2055a2278f5bd788cd6b4)\n\nConflicts:\n\tneutron/plugins/common/utils.py\n\nChange-Id: Ia6ff5ad975673875216eb470080dfc0dcf6b9ab2\n'}]",0,361636,273f5b2b85992f28f77664ac6d6db294ac10dd1f,10,6,2,748,,,0,"Create auto allocated networks in disabled state

Under particular circumstances, multiple requests to the
auto-allocated-topology extension may lead to the transient
creation of duplicated resources. This is dealt with by the
service plugin code, which cleans them up once the condition
is detected. However the client may accidentally be impacted
and potentially left in error (recoverable on retry).

In order to address this error condition, the logic to
provision the network for any given tenant is tweaked
slightly so that the network is created in disabled state
and re-enabled when it is safe to do so. A Neutron client
should check the network status to see if the network is
ready for use before getting its hands on it.

Closes-bug: #1591766

(cherry picked from commit d91a4e1930bd8f05f7b2055a2278f5bd788cd6b4)

Conflicts:
	neutron/plugins/common/utils.py

Change-Id: Ia6ff5ad975673875216eb470080dfc0dcf6b9ab2
",git fetch https://review.opendev.org/openstack/neutron refs/changes/36/361636/2 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/services/auto_allocate/db.py', 'neutron/plugins/common/utils.py', 'neutron/tests/api/test_auto_allocated_topology.py']",3,8686f28335fbb6158fb9cec65e306f7021c29847,bug/1591766, network = self.client.show_network(topology['id'])['network'] self.assertTrue(network['admin_state_up']),,24,5
openstack%2Fneutron~stable%2Fmitaka~I7440becb6d30af7159ecaeba09d7a28eceb71bea,openstack/neutron,stable/mitaka,I7440becb6d30af7159ecaeba09d7a28eceb71bea,Move DHCP notification logic out of API controller,ABANDONED,2016-08-27 16:00:26.000000000,2016-08-29 16:37:30.000000000,,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 5170}, {'_account_id': 9681}, {'_account_id': 9732}, {'_account_id': 14208}, {'_account_id': 16376}, {'_account_id': 17130}, {'_account_id': 23327}]","[{'number': 1, 'created': '2016-08-27 16:00:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/86c5df3120c6d2738c0c464d634644d0864b07f9', 'message': 'Move DHCP notification logic out of API controller\n\nBug 1591766 unveiled an issue where calling the plugin API does not trigger\nDHCP notifications. This is required by the auto-allocated-topology service\nplugin that calls core_plugin.update_network(), and expect notifications\nto be sent out on state changes. To accomplish this, the logic has been\nencapsulated in the DHCP module, and leveraged via callback mechanisms.\n\nFor this reason, new events have been introduced, AFTER_REQUEST, and\nBEFORE_RESPONSE. The latter in particular is the one needed to hook up\ndhcp notifications in order to preserve backward compatibility.\n\nMore precisely, core plugins that use DHCP as is or implement their own,\n(with or without an agent) should already instantiate their own notifier,\nand if they do not, this should be rectified.\n\nA search on codesearch.openstack.org reveals that out-of-tree plugins\nalready specify their own notifiers, and the default initialization is\nclearly redundant now.\n\nRelated-bug: #1591766\n\n(cherry picked from commit 877778ee4c7f0e83b54f54b2d7bafec98f89626c)\n\nConflicts:\n\tneutron/api/v2/base.py\n\tneutron/tests/unit/api/v2/test_base.py\n\nChange-Id: I7440becb6d30af7159ecaeba09d7a28eceb71bea\n'}, {'number': 2, 'created': '2016-08-27 16:05:11.000000000', 'files': ['neutron/tests/unit/api/v2/test_base.py', 'neutron/callbacks/resources.py', 'neutron/api/v2/base.py', 'neutron/api/rpc/agentnotifiers/dhcp_rpc_agent_api.py', 'neutron/tests/unit/extensions/test_l3.py', 'neutron/tests/unit/db/test_agentschedulers_db.py', 'neutron/callbacks/events.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/2a7fe7f32985faef64434147b978ce0181c89b67', 'message': 'Move DHCP notification logic out of API controller\n\nBug 1591766 unveiled an issue where calling the plugin API does not trigger\nDHCP notifications. This is required by the auto-allocated-topology service\nplugin that calls core_plugin.update_network(), and expect notifications\nto be sent out on state changes. To accomplish this, the logic has been\nencapsulated in the DHCP module, and leveraged via callback mechanisms.\n\nFor this reason, new events have been introduced, AFTER_REQUEST, and\nBEFORE_RESPONSE. The latter in particular is the one needed to hook up\ndhcp notifications in order to preserve backward compatibility.\n\nMore precisely, core plugins that use DHCP as is or implement their own,\n(with or without an agent) should already instantiate their own notifier,\nand if they do not, this should be rectified.\n\nA search on codesearch.openstack.org reveals that out-of-tree plugins\nalready specify their own notifiers, and the default initialization is\nclearly redundant now.\n\nRelated-bug: #1591766\n\n(cherry picked from commit 877778ee4c7f0e83b54f54b2d7bafec98f89626c)\n\nConflicts:\n\tneutron/api/v2/base.py\n\tneutron/tests/unit/api/v2/test_base.py\n\nChange-Id: I7440becb6d30af7159ecaeba09d7a28eceb71bea\n'}]",0,361634,2a7fe7f32985faef64434147b978ce0181c89b67,13,9,2,748,,,0,"Move DHCP notification logic out of API controller

Bug 1591766 unveiled an issue where calling the plugin API does not trigger
DHCP notifications. This is required by the auto-allocated-topology service
plugin that calls core_plugin.update_network(), and expect notifications
to be sent out on state changes. To accomplish this, the logic has been
encapsulated in the DHCP module, and leveraged via callback mechanisms.

For this reason, new events have been introduced, AFTER_REQUEST, and
BEFORE_RESPONSE. The latter in particular is the one needed to hook up
dhcp notifications in order to preserve backward compatibility.

More precisely, core plugins that use DHCP as is or implement their own,
(with or without an agent) should already instantiate their own notifier,
and if they do not, this should be rectified.

A search on codesearch.openstack.org reveals that out-of-tree plugins
already specify their own notifiers, and the default initialization is
clearly redundant now.

Related-bug: #1591766

(cherry picked from commit 877778ee4c7f0e83b54f54b2d7bafec98f89626c)

Conflicts:
	neutron/api/v2/base.py
	neutron/tests/unit/api/v2/test_base.py

Change-Id: I7440becb6d30af7159ecaeba09d7a28eceb71bea
",git fetch https://review.opendev.org/openstack/neutron refs/changes/34/361634/2 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/unit/api/v2/test_base.py', 'neutron/callbacks/resources.py', 'neutron/api/v2/base.py', 'neutron/api/rpc/agentnotifiers/dhcp_rpc_agent_api.py', 'neutron/tests/unit/extensions/test_l3.py', 'neutron/callbacks/events.py', 'neutron/tests/unit/db/test_agentschedulers_db.py']",7,86c5df3120c6d2738c0c464d634644d0864b07f9,bug/1591766," dhcp_notifier_schedule = mock.patch( 'neutron.api.rpc.agentnotifiers.dhcp_rpc_agent_api.' 'DhcpAgentNotifyAPI._schedule_network').start() self.port(subnet=subnet, device_id=device_id),\ return_value=[]): return dhcp_notifier_schedule.call_count > 1"," notifier = plugin.agent_notifiers[constants.AGENT_TYPE_DHCP] return_value=[]),\ mock.patch.object(notifier, '_schedule_network', return_value=[]) as mock_sched: with self.port(subnet=subnet, device_id=device_id): return mock_sched.called",87,81
openstack%2Fneutron~stable%2Fmitaka~Ibbdb7960342dbd298e81b5ae17f50c1a279a2284,openstack/neutron,stable/mitaka,Ibbdb7960342dbd298e81b5ae17f50c1a279a2284,Extend utils create methods to accept check_allow_post,ABANDONED,2016-08-27 15:41:52.000000000,2016-08-29 16:37:27.000000000,,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 5170}, {'_account_id': 9681}, {'_account_id': 9732}, {'_account_id': 14208}, {'_account_id': 16376}]","[{'number': 1, 'created': '2016-08-27 15:41:52.000000000', 'files': ['neutron/plugins/common/utils.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/7601eb91aa2ec3c4c46a85b820e1bbd43c981354', 'message': 'Extend utils create methods to accept check_allow_post\n\nJust like create_port, these methods should also accept the parameter\nthat is used to control whether to validate that the request body\ncontains attributes not allowed during POST requests.\n\nChange-Id: Ibbdb7960342dbd298e81b5ae17f50c1a279a2284\n(cherry picked from commit 5089f41d50c4b3b7a46cd64d74c9b002812c9c59)\n'}]",0,361627,7601eb91aa2ec3c4c46a85b820e1bbd43c981354,9,7,1,748,,,0,"Extend utils create methods to accept check_allow_post

Just like create_port, these methods should also accept the parameter
that is used to control whether to validate that the request body
contains attributes not allowed during POST requests.

Change-Id: Ibbdb7960342dbd298e81b5ae17f50c1a279a2284
(cherry picked from commit 5089f41d50c4b3b7a46cd64d74c9b002812c9c59)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/27/361627/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/plugins/common/utils.py'],1,7601eb91aa2ec3c4c46a85b820e1bbd43c981354,yuk,"def create_network(core_plugin, context, net, check_allow_post=True): net.get('network', {}), check_allow_post=check_allow_post)def create_subnet(core_plugin, context, subnet, check_allow_post=True): subnet.get('subnet', {}), check_allow_post=check_allow_post)","def create_network(core_plugin, context, net): net.get('network', {}))def create_subnet(core_plugin, context, subnet): subnet.get('subnet', {}))",6,4
openstack%2Fpbr~master~I31c4e0e2ed15986ba8274a0c5270a9d214ac4b48,openstack/pbr,master,I31c4e0e2ed15986ba8274a0c5270a9d214ac4b48,Add more words to a confusing error message,MERGED,2016-08-26 15:41:24.000000000,2016-08-29 16:37:11.000000000,2016-08-29 16:37:11.000000000,"[{'_account_id': 1}, {'_account_id': 3}, {'_account_id': 5263}]","[{'number': 1, 'created': '2016-08-26 15:41:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/pbr/commit/4078c1c2022c49c681d3b4ca2f06cbc82813026b', 'message': 'Add more words to a confusing error message\n\nWhen setup.cfg has a different value than pbr.version.VersionInfo(),\nthen the version call is unable to look up the right value in the\npkg_resources metadata. However, nothing in the current error message\ncommunicates this to the user, which leads to them not being able to\nlook in all the right places for the possible error.\n\nChange-Id: I31c4e0e2ed15986ba8274a0c5270a9d214ac4b48\n'}, {'number': 2, 'created': '2016-08-26 15:45:44.000000000', 'files': ['pbr/packaging.py'], 'web_link': 'https://opendev.org/openstack/pbr/commit/8d64858523c68b4111e98b14b01f615d79ee4048', 'message': 'Add more words to a confusing error message\n\nWhen setup.cfg has a different value than pbr.version.VersionInfo(),\nthen the version call is unable to look up the right value in the\npkg_resources metadata. However, nothing in the current error message\ncommunicates this to the user, which leads to them not being able to\nlook in all the right places for the possible error.\n\nChange-Id: I31c4e0e2ed15986ba8274a0c5270a9d214ac4b48\n'}]",0,361317,8d64858523c68b4111e98b14b01f615d79ee4048,8,3,2,2,,,0,"Add more words to a confusing error message

When setup.cfg has a different value than pbr.version.VersionInfo(),
then the version call is unable to look up the right value in the
pkg_resources metadata. However, nothing in the current error message
communicates this to the user, which leads to them not being able to
look in all the right places for the possible error.

Change-Id: I31c4e0e2ed15986ba8274a0c5270a9d214ac4b48
",git fetch https://review.opendev.org/openstack/pbr refs/changes/17/361317/2 && git format-patch -1 --stdout FETCH_HEAD,['pbr/packaging.py'],1,4078c1c2022c49c681d3b4ca2f06cbc82813026b,," "" It's also possible that there is a mismatch between"" "" the package name in setup.cfg and the argument given"" "" to pbr.version.VersionInfo."")"," "" Are you sure that git is installed?"")",3,1
openstack%2Ffuel-astute~master~Ieb01161d92f82768cbc5057b5dbb501fcf53a74f,openstack/fuel-astute,master,Ieb01161d92f82768cbc5057b5dbb501fcf53a74f,Use summary field for sending task summary,MERGED,2016-08-26 12:20:30.000000000,2016-08-29 16:36:52.000000000,2016-08-29 16:26:14.000000000,"[{'_account_id': 3}, {'_account_id': 3009}, {'_account_id': 6506}, {'_account_id': 8776}, {'_account_id': 8786}, {'_account_id': 8971}, {'_account_id': 20656}, {'_account_id': 21013}]","[{'number': 1, 'created': '2016-08-26 12:20:30.000000000', 'files': ['lib/astute/task_node.rb', 'spec/unit/task_node_spec.rb'], 'web_link': 'https://opendev.org/openstack/fuel-astute/commit/aca2bf3cd1f053019d25fb6ad9ea20d46f54bd38', 'message': ""Use summary field for sending task summary\n\nCurrently Astute uses 'custom' field for sending task summary and\nit's wrong, because Nailgun searching for 'summary' field.\n\nChange-Id: Ieb01161d92f82768cbc5057b5dbb501fcf53a74f\n""}]",0,361138,aca2bf3cd1f053019d25fb6ad9ea20d46f54bd38,20,8,1,7745,,,0,"Use summary field for sending task summary

Currently Astute uses 'custom' field for sending task summary and
it's wrong, because Nailgun searching for 'summary' field.

Change-Id: Ieb01161d92f82768cbc5057b5dbb501fcf53a74f
",git fetch https://review.opendev.org/openstack/fuel-astute refs/changes/38/361138/1 && git format-patch -1 --stdout FETCH_HEAD,"['lib/astute/task_node.rb', 'spec/unit/task_node_spec.rb']",2,aca2bf3cd1f053019d25fb6ad9ea20d46f54bd38,," 'summary' => {} 'summary' => {}, 'summary' => {}, 'summary' => {}, 'summary' => {}, 'summary' => {},"," 'custom' => {} 'custom' => {}, 'custom' => {}, 'custom' => {}, 'custom' => {}, 'custom' => {},",7,7
openstack%2Fsearchlight-ui~master~Ic8c085e19b0ecd078de5bcac231c22756c3f6528,openstack/searchlight-ui,master,Ic8c085e19b0ecd078de5bcac231c22756c3f6528,Initial support for sorting,MERGED,2016-08-24 21:16:21.000000000,2016-08-29 16:34:58.000000000,2016-08-29 16:34:58.000000000,"[{'_account_id': 3}, {'_account_id': 7665}, {'_account_id': 10063}, {'_account_id': 14680}]","[{'number': 1, 'created': '2016-08-24 21:16:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/searchlight-ui/commit/dd8a179021632a0922a2f09d9403d8d68f59e73e', 'message': 'Initial support for sorting\n\nSearchlight UI doesn\'t allow you to set sort options.\nTypically, this is done via clicking up / down on table headers.\nHowever, the current dependency on smart table\n(which only does client side sorting) prevents this.\nWe need some way in Newton to perform server side sorting.\n\nThis provides support via the ""Settings"" dialog. A future\npatch will likely improve the UX to make access to settings\neasier (not a modal requiring submit and cancel).\n\nChange-Id: Ic8c085e19b0ecd078de5bcac231c22756c3f6528\nCloses-Bug: 1616632\n'}, {'number': 2, 'created': '2016-08-24 21:59:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/searchlight-ui/commit/6ffce9b4947196cffe9dc651dddb2c083405a314', 'message': 'Initial support for sorting\n\nSearchlight UI doesn\'t allow you to set sort options.\nTypically, this is done via clicking up / down on table headers.\nHowever, the current dependency on smart table\n(which only does client side sorting) prevents this.\nWe need some way in Newton to perform server side sorting.\n\nThis provides support via the ""Settings"" dialog. A future\npatch will likely improve the UX to make access to settings\neasier (not a modal requiring submit and cancel).\n\nChange-Id: Ic8c085e19b0ecd078de5bcac231c22756c3f6528\nCloses-Bug: 1616632\n'}, {'number': 3, 'created': '2016-08-24 22:59:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/searchlight-ui/commit/52f20ad59254f6256a0adad2b240f4f652d883ed', 'message': 'Initial support for sorting\n\nSearchlight UI doesn\'t allow you to set sort options.\nTypically, this is done via clicking up / down on table headers.\nHowever, the current dependency on smart table\n(which only does client side sorting) prevents this.\nWe need some way in Newton to perform server side sorting.\n\nThis provides support via the ""Settings"" dialog. A future\npatch will likely improve the UX to make access to settings\neasier (not a modal requiring submit and cancel).\n\nChange-Id: Ic8c085e19b0ecd078de5bcac231c22756c3f6528\nCloses-Bug: 1616632\n'}, {'number': 4, 'created': '2016-08-25 01:40:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/searchlight-ui/commit/985491ce5c2a6514882fe9a44242309126c4ced2', 'message': 'Initial support for sorting\n\nSearchlight UI doesn\'t allow you to set sort options.\nTypically, this is done via clicking up / down on table headers.\nHowever, the current dependency on smart table\n(which only does client side sorting) prevents this.\nWe need some way in Newton to perform server side sorting.\n\nThis provides support via the ""Settings"" dialog. A future\npatch will likely improve the UX to make access to settings\neasier (not a modal requiring submit and cancel).\n\nChange-Id: Ic8c085e19b0ecd078de5bcac231c22756c3f6528\nCloses-Bug: 1616632\n'}, {'number': 5, 'created': '2016-08-25 02:54:05.000000000', 'files': ['searchlight_ui/static/searchlight-ui/settings/search-settings.service.js', 'searchlight_ui/static/searchlight-ui/settings/search-settings.html', 'searchlight_ui/static/searchlight-ui/util/searchlight-query-generator.service.js'], 'web_link': 'https://opendev.org/openstack/searchlight-ui/commit/d69bcda176dde4e6a90590e833ebd258c91b813f', 'message': 'Initial support for sorting\n\nSearchlight UI doesn\'t allow you to set sort options.\nTypically, this is done via clicking up / down on table headers.\nHowever, the current dependency on smart table\n(which only does client side sorting) prevents this.\nWe need some way in Newton to perform server side sorting.\n\nThis provides support via the ""Settings"" dialog. A future\npatch will likely improve the UX to make access to settings\neasier (not a modal requiring submit and cancel).\n\nChange-Id: Ic8c085e19b0ecd078de5bcac231c22756c3f6528\nCloses-Bug: 1616632\n'}]",0,360090,d69bcda176dde4e6a90590e833ebd258c91b813f,20,4,5,7665,,,0,"Initial support for sorting

Searchlight UI doesn't allow you to set sort options.
Typically, this is done via clicking up / down on table headers.
However, the current dependency on smart table
(which only does client side sorting) prevents this.
We need some way in Newton to perform server side sorting.

This provides support via the ""Settings"" dialog. A future
patch will likely improve the UX to make access to settings
easier (not a modal requiring submit and cancel).

Change-Id: Ic8c085e19b0ecd078de5bcac231c22756c3f6528
Closes-Bug: 1616632
",git fetch https://review.opendev.org/openstack/searchlight-ui refs/changes/90/360090/5 && git format-patch -1 --stdout FETCH_HEAD,"['searchlight_ui/static/searchlight-ui/settings/search-settings.service.js', 'searchlight_ui/static/searchlight-ui/settings/search-settings.html', 'searchlight_ui/static/searchlight-ui/util/searchlight-query-generator.service.js']",3,dd8a179021632a0922a2f09d9403d8d68f59e73e,bug/1616506, searchlightQuery.sort = [settingsService.settings.sort.selected.query];, searchlightQuery.sort = options.sort;,32,3
openstack%2Fshade~master~I12c491ac31b950dde4c1ac55860043fd9d05ece8,openstack/shade,master,I12c491ac31b950dde4c1ac55860043fd9d05ece8,Support dual-stack neutron networks,MERGED,2016-08-18 22:24:43.000000000,2016-08-29 16:31:03.000000000,2016-08-29 16:31:03.000000000,"[{'_account_id': 1}, {'_account_id': 2}, {'_account_id': 3}, {'_account_id': 3099}, {'_account_id': 4146}, {'_account_id': 4656}]","[{'number': 1, 'created': '2016-08-18 22:24:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/shade/commit/1fee5c69dcd6aefb60fb6f44419e5dce0128777a', 'message': ""Support dual-stack neutron networks\n\nIt is totally possible for a neutron network to have a network with a\nglobally routable IPv6 subnet and an RFC-1918 IPv4 subnet. In fact, the\nexisting OSIC Cloud1 does this, and the original region of Dreamhost did\nthis.\n\nThe trouble is, it's not possible in a reasonable way to _infer_ this\nsetup, so we rely on brand-new config functions in os-client-config to\nallow a user to express that a network is external for ipv4 or for ipv6.\n\nChange-Id: I12c491ac31b950dde4c1ac55860043fd9d05ece8\n""}, {'number': 2, 'created': '2016-08-22 13:34:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/shade/commit/63dc7ba5b3c20214c4144d092d5391b1c6fd2072', 'message': ""Support dual-stack neutron networks\n\nIt is totally possible for a neutron network to have a network with a\nglobally routable IPv6 subnet and an RFC-1918 IPv4 subnet. In fact, the\nexisting OSIC Cloud1 does this, and the original region of Dreamhost did\nthis.\n\nThe trouble is, it's not possible in a reasonable way to _infer_ this\nsetup, so we rely on brand-new config functions in os-client-config to\nallow a user to express that a network is external for ipv4 or for ipv6.\n\nChange-Id: I12c491ac31b950dde4c1ac55860043fd9d05ece8\n""}, {'number': 3, 'created': '2016-08-22 13:39:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/shade/commit/47e32aae10c6a1577689d8d646c15f4442917b15', 'message': ""Support dual-stack neutron networks\n\nIt is totally possible for a neutron network to have a network with a\nglobally routable IPv6 subnet and an RFC-1918 IPv4 subnet. In fact, the\nexisting OSIC Cloud1 does this, and the original region of Dreamhost did\nthis.\n\nThe trouble is, it's not possible in a reasonable way to _infer_ this\nsetup, so we rely on brand-new config functions in os-client-config to\nallow a user to express that a network is external for ipv4 or for ipv6.\n\nChange-Id: I12c491ac31b950dde4c1ac55860043fd9d05ece8\n""}, {'number': 4, 'created': '2016-08-22 14:44:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/shade/commit/8fb634069e0b99dfd9c119c2520630304bb0e0e1', 'message': ""Support dual-stack neutron networks\n\nIt is totally possible for a neutron network to have a network with a\nglobally routable IPv6 subnet and an RFC-1918 IPv4 subnet. In fact, the\nexisting OSIC Cloud1 does this, and the original region of Dreamhost did\nthis.\n\nThe trouble is, it's not possible in a reasonable way to _infer_ this\nsetup, so we rely on brand-new config functions in os-client-config to\nallow a user to express that a network is external for ipv4 or for ipv6.\n\nChange-Id: I12c491ac31b950dde4c1ac55860043fd9d05ece8\n""}, {'number': 5, 'created': '2016-08-23 17:29:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/shade/commit/62090c6b482077b7bf878ebb5bc5319b3a3ea4c2', 'message': ""Support dual-stack neutron networks\n\nIt is totally possible for a neutron network to have a network with a\nglobally routable IPv6 subnet and an RFC-1918 IPv4 subnet. In fact, the\nexisting OSIC Cloud1 does this, and the original region of Dreamhost did\nthis.\n\nThe trouble is, it's not possible in a reasonable way to _infer_ this\nsetup, so we rely on brand-new config functions in os-client-config to\nallow a user to express that a network is external for ipv4 or for ipv6.\n\nChange-Id: I12c491ac31b950dde4c1ac55860043fd9d05ece8\n""}, {'number': 6, 'created': '2016-08-23 21:07:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/shade/commit/e166fdfe6276d89ed0882bb74afdcc4c1e30256d', 'message': ""Support dual-stack neutron networks\n\nIt is totally possible for a neutron network to have a network with a\nglobally routable IPv6 subnet and an RFC-1918 IPv4 subnet. In fact, the\nexisting OSIC Cloud1 does this, and the original region of Dreamhost did\nthis.\n\nThe trouble is, it's not possible in a reasonable way to _infer_ this\nsetup, so we rely on brand-new config functions in os-client-config to\nallow a user to express that a network is external for ipv4 or for ipv6.\n\nDepends-On: I6d52316ec06806098d6bcae667901a589e91d8c4\nChange-Id: I12c491ac31b950dde4c1ac55860043fd9d05ece8\n""}, {'number': 7, 'created': '2016-08-25 13:17:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/shade/commit/934945f69e727cb8eb91605932963b5d15fcdfea', 'message': ""Support dual-stack neutron networks\n\nIt is totally possible for a neutron network to have a network with a\nglobally routable IPv6 subnet and an RFC-1918 IPv4 subnet. In fact, the\nexisting OSIC Cloud1 does this, and the original region of Dreamhost did\nthis.\n\nThe trouble is, it's not possible in a reasonable way to _infer_ this\nsetup, so we rely on brand-new config functions in os-client-config to\nallow a user to express that a network is external for ipv4 or for ipv6.\n\nDepends-On: If356106dad846801393e19f97f51498b10d381be\nChange-Id: I12c491ac31b950dde4c1ac55860043fd9d05ece8\n""}, {'number': 8, 'created': '2016-08-25 20:18:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/shade/commit/cca05ac398d3797ce88ab38c2c44106906e6d611', 'message': ""Support dual-stack neutron networks\n\nIt is totally possible for a neutron network to have a network with a\nglobally routable IPv6 subnet and an RFC-1918 IPv4 subnet. In fact, the\nexisting OSIC Cloud1 does this, and the original region of Dreamhost did\nthis.\n\nThe trouble is, it's not possible in a reasonable way to _infer_ this\nsetup, so we rely on brand-new config functions in os-client-config to\nallow a user to express that a network is external for ipv4 or for ipv6.\n\nChange-Id: I12c491ac31b950dde4c1ac55860043fd9d05ece8\n""}, {'number': 9, 'created': '2016-08-25 22:03:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/shade/commit/6fac5587f8a0db30e78199bf09b67105c19dfee4', 'message': ""Support dual-stack neutron networks\n\nIt is totally possible for a neutron network to have a network with a\nglobally routable IPv6 subnet and an RFC-1918 IPv4 subnet. In fact, the\nexisting OSIC Cloud1 does this, and the original region of Dreamhost did\nthis.\n\nThe trouble is, it's not possible in a reasonable way to _infer_ this\nsetup, so we rely on brand-new config functions in os-client-config to\nallow a user to express that a network is external for ipv4 or for ipv6.\n\nChange-Id: I12c491ac31b950dde4c1ac55860043fd9d05ece8\n""}, {'number': 10, 'created': '2016-08-26 11:39:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/shade/commit/5f758c5320ec43d5cce67625721bae226a2463a6', 'message': ""Support dual-stack neutron networks\n\nIt is totally possible for a neutron network to have a network with a\nglobally routable IPv6 subnet and an RFC-1918 IPv4 subnet. In fact, the\nexisting OSIC Cloud1 does this, and the original region of Dreamhost did\nthis.\n\nThe trouble is, it's not possible in a reasonable way to _infer_ this\nsetup, so we rely on brand-new config functions in os-client-config to\nallow a user to express that a network is external for ipv4 or for ipv6.\n\nChange-Id: I12c491ac31b950dde4c1ac55860043fd9d05ece8\n""}, {'number': 11, 'created': '2016-08-26 21:24:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/shade/commit/742aa770cc9b00eb1148a1a14466a380d8fd6071', 'message': ""Support dual-stack neutron networks\n\nIt is totally possible for a neutron network to have a network with a\nglobally routable IPv6 subnet and an RFC-1918 IPv4 subnet. In fact, the\nexisting OSIC Cloud1 does this, and the original region of Dreamhost did\nthis.\n\nThe trouble is, it's not possible in a reasonable way to _infer_ this\nsetup, so we rely on brand-new config functions in os-client-config to\nallow a user to express that a network is external for ipv4 or for ipv6.\n\nDepends-On: I40f5165d36060643943bcb91df14e5e34cd5e3fa\nChange-Id: I12c491ac31b950dde4c1ac55860043fd9d05ece8\n""}, {'number': 12, 'created': '2016-08-29 13:16:03.000000000', 'files': ['shade/tests/unit/test_meta.py', 'requirements.txt', 'shade/tests/unit/test_floating_ip_common.py', 'shade/tests/unit/test_floating_ip_neutron.py', 'shade/meta.py', 'releasenotes/notes/dual-stack-networks-8a81941c97d28deb.yaml', 'shade/openstackcloud.py'], 'web_link': 'https://opendev.org/openstack/shade/commit/6832f734d00f1c118068db1fbd65370ad7f5d178', 'message': ""Support dual-stack neutron networks\n\nIt is totally possible for a neutron network to have a network with a\nglobally routable IPv6 subnet and an RFC-1918 IPv4 subnet. In fact, the\nexisting OSIC Cloud1 does this, and the original region of Dreamhost did\nthis.\n\nThe trouble is, it's not possible in a reasonable way to _infer_ this\nsetup, so we rely on brand-new config functions in os-client-config to\nallow a user to express that a network is external for ipv4 or for ipv6.\n\nDepends-On: I40f5165d36060643943bcb91df14e5e34cd5e3fa\nChange-Id: I12c491ac31b950dde4c1ac55860043fd9d05ece8\n""}]",2,357517,6832f734d00f1c118068db1fbd65370ad7f5d178,51,6,12,2,,,0,"Support dual-stack neutron networks

It is totally possible for a neutron network to have a network with a
globally routable IPv6 subnet and an RFC-1918 IPv4 subnet. In fact, the
existing OSIC Cloud1 does this, and the original region of Dreamhost did
this.

The trouble is, it's not possible in a reasonable way to _infer_ this
setup, so we rely on brand-new config functions in os-client-config to
allow a user to express that a network is external for ipv4 or for ipv6.

Depends-On: I40f5165d36060643943bcb91df14e5e34cd5e3fa
Change-Id: I12c491ac31b950dde4c1ac55860043fd9d05ece8
",git fetch https://review.opendev.org/openstack/shade refs/changes/17/357517/11 && git format-patch -1 --stdout FETCH_HEAD,"['shade/tests/unit/test_meta.py', 'requirements.txt', 'shade/tests/unit/test_floating_ip_neutron.py', 'shade/meta.py', 'shade/openstackcloud.py']",5,1fee5c69dcd6aefb60fb6f44419e5dce0128777a,dual-stack," # The first two aren't useful to us anymore, but we still do them # because there are two methods that won't work without them self._external_ipv4_names = cloud_config.get_external_ipv4_networks() self._internal_ipv4_names = cloud_config.get_internal_ipv4_networks() self._external_ipv6_names = cloud_config.get_external_ipv6_networks() self._internal_ipv6_names = cloud_config.get_internal_ipv6_networks() self._external_ipv4_networks = [] self._internal_ipv4_networks = [] self._external_ipv6_networks = [] self._internal_ipv6_networks = [] external_ipv4_networks = [] internal_ipv4_networks = [] external_ipv6_networks = [] internal_ipv6_networks = [] # Old External networks # Old Internal networks # External IPv4 networks if (network['name'] in self._external_ipv4_names or network['id'] in self._external_ipv4_names): external_ipv4_networks.append(network) elif ((('router:external' in network and network['router:external']) or network.get('provider:physical_network')) and network['name'] not in self._internal_ipv4_names and network['id'] not in self._internal_ipv4_names): external_ipv4_networks.append(network) # Internal networks if (network['name'] in self._internal_ipv4_names or network['id'] in self._internal_ipv4_names): internal_ipv4_networks.append(network) elif (not network.get('router:external', False) and not network.get('provider:physical_network') and network['name'] not in self._external_ipv4_names and network['id'] not in self._external_ipv4_names): internal_ipv4_networks.append(network) # External networks if (network['name'] in self._external_ipv6_names or network['id'] in self._external_ipv6_names): external_ipv6_networks.append(network) elif ((('router:external' in network and network['router:external']) or network.get('provider:physical_network')) and network['name'] not in self._internal_ipv6_names and network['id'] not in self._internal_ipv6_names): external_ipv6_networks.append(network) # Internal networks if (network['name'] in self._internal_ipv6_names or network['id'] in self._internal_ipv6_names): internal_ipv6_networks.append(network) elif (not network.get('router:external', False) and not network.get('provider:physical_network') and network['name'] not in self._external_ipv6_names and network['id'] not in self._external_ipv6_names): internal_ipv6_networks.append(network) for net_name in self._external_ipv4_names: if net_name not in [net['name'] for net in external_ipv4_networks]: raise OpenStackCloudException( ""Networks: {network} was provided for external IPv4"" "" access and those networks could not be found"".format( network=net_name)) for net_name in self._internal_ipv4_names: if net_name not in [net['name'] for net in internal_ipv4_networks]: raise OpenStackCloudException( ""Networks: {network} was provided for internal IPv4"" "" access and those networks could not be found"".format( network=net_name)) for net_name in self._external_ipv6_names: if net_name not in [net['name'] for net in external_ipv6_networks]: raise OpenStackCloudException( ""Networks: {network} was provided for external IPv6"" "" access and those networks could not be found"".format( network=net_name)) for net_name in self._internal_ipv6_names: if net_name not in [net['name'] for net in internal_ipv6_networks]: raise OpenStackCloudException( ""Networks: {network} was provided for internal IPv6"" "" access and those networks could not be found"".format( network=net_name)) self._external_ipv4_networks = external_ipv4_networks self._internal_ipv4_networks = internal_ipv4_networks self._external_ipv6_networks = external_ipv6_networks self._internal_ipv6_networks = internal_ipv6_networks This should be avoided in favor of the specific ipv4/ipv6 method, but is here for backwards compatibility. This should be avoided in favor of the specific ipv4/ipv6 method, but is here for backwards compatibility. def get_external_ipv4_networks(self): """"""Return the networks that are configured to route northbound. :returns: A list of network ``munch.Munch`` if one is found """""" self._find_interesting_networks() return self._external_ipv4_networks def get_internal_ipv4_networks(self): """"""Return the networks that are configured to not route northbound. :returns: A list of network ``munch.Munch`` if one is found """""" self._find_interesting_networks() return self._internal_ipv4_networks def get_external_ipv6_networks(self): """"""Return the networks that are configured to route northbound. :returns: A list of network ``munch.Munch`` if one is found """""" self._find_interesting_networks() return self._external_ipv6_networks def get_internal_ipv6_networks(self): """"""Return the networks that are configured to not route northbound. :returns: A list of network ``munch.Munch`` if one is found """""" self._find_interesting_networks() return self._internal_ipv6_networks for ext_net in self.get_external_ipv4_networks(): # Get first existing external IPv4 network networks = self.get_external_ipv4_networks() networks = self.get_external_ipv4_networks()", # External networks # Internal networks for ext_net in self.get_external_networks(): # Get first existing external network networks = self.get_external_networks() networks = self.get_external_networks(),316,13
openstack%2Ffreezer~master~Ia964bcc72abe39408dd72338951e083926a130ca,openstack/freezer,master,Ia964bcc72abe39408dd72338951e083926a130ca,Added Validation layer for freezer jobs,MERGED,2016-08-29 10:57:23.000000000,2016-08-29 16:28:56.000000000,2016-08-29 16:28:56.000000000,"[{'_account_id': 3}, {'_account_id': 14340}, {'_account_id': 14509}]","[{'number': 1, 'created': '2016-08-29 10:57:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/freezer/commit/ac021856177eb4ee8cd99d6fd591af164d35f483', 'message': 'Added Validation layer for freezer jobs\n\nvalidating arguments before starting freezer job. each job will\nvalidate job-specific arguments and the _general_validate method\nin base Job class will takecare of the common ones.\n\nImplements: blueprint validation-layer-for-freezer-jobs\nChange-Id: Ia964bcc72abe39408dd72338951e083926a130ca\n'}, {'number': 2, 'created': '2016-08-29 12:39:42.000000000', 'files': ['freezer/common/config.py', 'freezer/job.py', 'tests/unit/test_job.py', 'freezer/tests/commons.py', 'tests/unit/utils/test_validator.py', 'freezer/utils/validator.py', 'freezer/main.py'], 'web_link': 'https://opendev.org/openstack/freezer/commit/4277d4a4f317573e1908880a6529165c18a878b8', 'message': 'Added Validation layer for freezer jobs\n\nvalidating arguments before starting freezer job. each job will\nvalidate job-specific arguments and the _general_validate method\nin base Job class will takecare of the common ones.\n\nImplements: blueprint validation-layer-for-freezer-jobs\nChange-Id: Ia964bcc72abe39408dd72338951e083926a130ca\n'}]",0,362015,4277d4a4f317573e1908880a6529165c18a878b8,9,3,2,13940,,,0,"Added Validation layer for freezer jobs

validating arguments before starting freezer job. each job will
validate job-specific arguments and the _general_validate method
in base Job class will takecare of the common ones.

Implements: blueprint validation-layer-for-freezer-jobs
Change-Id: Ia964bcc72abe39408dd72338951e083926a130ca
",git fetch https://review.opendev.org/openstack/freezer refs/changes/15/362015/2 && git format-patch -1 --stdout FETCH_HEAD,"['freezer/common/config.py', 'freezer/job.py', 'tests/unit/test_job.py', 'freezer/tests/commons.py', 'tests/unit/utils/test_validator.py', 'freezer/utils/validator.py', 'freezer/main.py']",7,ac021856177eb4ee8cd99d6fd591af164d35f483,bp/validation-layer-for-freezer-jobs,,from freezer.utils import validator validator.validate(backup_args) ,163,123
openstack%2Fcinder~master~I2e9c8509385a40ae325a3d4c7c1900fc1cf46d6d,openstack/cinder,master,I2e9c8509385a40ae325a3d4c7c1900fc1cf46d6d,Add CI_WIKI_NAME to Tegile volume driver,MERGED,2016-08-11 07:46:32.000000000,2016-08-29 16:27:54.000000000,2016-08-28 19:35:48.000000000,"[{'_account_id': 3}, {'_account_id': 9008}, {'_account_id': 9535}, {'_account_id': 10058}, {'_account_id': 10621}, {'_account_id': 10622}, {'_account_id': 11904}, {'_account_id': 12176}, {'_account_id': 12369}, {'_account_id': 13628}, {'_account_id': 14305}, {'_account_id': 14384}, {'_account_id': 14797}, {'_account_id': 15249}, {'_account_id': 15296}, {'_account_id': 15374}, {'_account_id': 15386}, {'_account_id': 16422}, {'_account_id': 16708}, {'_account_id': 16862}, {'_account_id': 16880}, {'_account_id': 16897}, {'_account_id': 16898}, {'_account_id': 17357}, {'_account_id': 18444}, {'_account_id': 18752}, {'_account_id': 19146}, {'_account_id': 19852}, {'_account_id': 19933}, {'_account_id': 21863}, {'_account_id': 21976}, {'_account_id': 22126}, {'_account_id': 22248}, {'_account_id': 22510}]","[{'number': 1, 'created': '2016-08-11 07:46:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/206dccdd31df7310856bca02aeeb4866b777b93a', 'message': 'Add CI_WIKI_NAME to Tegile volume driver\n\nThis patch adds CI_WIKI_NAME to Tegile driver object. The value is the\nname of Tegile CI ThirdPartySystems wiki page. This value is added to\ntrack CI reporting status.\n\nImplements: blueprint driver-ci-name\nChange-Id: I2e9c8509385a40ae325a3d4c7c1900fc1cf46d6d\n'}, {'number': 2, 'created': '2016-08-15 22:36:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/3726e3eda2eb67c5b994b661351534ef301914c1', 'message': 'Add CI_WIKI_NAME to Tegile volume driver\n\nThis patch extends commit 1a5de5d4bd3fddcce7a4ba80aaca765935d47300\n\nThis patch adds CI_WIKI_NAME to Tegile driver object. The value is the\nname of Tegile CI ThirdPartySystems wiki page. This value is added to\ntrack CI reporting status.\n\nChange-Id: I2e9c8509385a40ae325a3d4c7c1900fc1cf46d6d\n'}, {'number': 3, 'created': '2016-08-15 22:36:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/01807f2765418087ed6713dc1d5c39e4970d45e6', 'message': 'Add CI_WIKI_NAME to Tegile volume driver\n\nThis patch extends commit 0ec5f705e91f680a731648cf50738ea219565f70\n\nThis patch adds CI_WIKI_NAME to Tegile driver object. The value is the\nname of Tegile CI ThirdPartySystems wiki page. This value is added to\ntrack CI reporting status.\n\nChange-Id: I2e9c8509385a40ae325a3d4c7c1900fc1cf46d6d\n'}, {'number': 4, 'created': '2016-08-15 22:37:41.000000000', 'files': ['cinder/volume/drivers/tegile.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/5d28eede4be988c6f216a18d5199dd87fff85704', 'message': 'Add CI_WIKI_NAME to Tegile volume driver\n\nThis patch extends commit 1a5de5d4bd3fddcce7a4ba80aaca765935d47300\n\nThis patch adds CI_WIKI_NAME to Tegile driver object. The value is the\nname of Tegile CI ThirdPartySystems wiki page. This value is added to\ntrack CI reporting status.\n\nChange-Id: I2e9c8509385a40ae325a3d4c7c1900fc1cf46d6d\n'}]",2,353886,5d28eede4be988c6f216a18d5199dd87fff85704,84,34,4,17357,,,0,"Add CI_WIKI_NAME to Tegile volume driver

This patch extends commit 1a5de5d4bd3fddcce7a4ba80aaca765935d47300

This patch adds CI_WIKI_NAME to Tegile driver object. The value is the
name of Tegile CI ThirdPartySystems wiki page. This value is added to
track CI reporting status.

Change-Id: I2e9c8509385a40ae325a3d4c7c1900fc1cf46d6d
",git fetch https://review.opendev.org/openstack/cinder refs/changes/86/353886/2 && git format-patch -1 --stdout FETCH_HEAD,['cinder/volume/drivers/tegile.py'],1,206dccdd31df7310856bca02aeeb4866b777b93a,driver-ci-name," # ThirdPartySystems wiki page CI_WIKI_NAME = ""Tegile_Storage_CI"" ",,3,0
openstack%2Fpuppet-neutron~master~I5bc8a4529e7441e7eb53ae74fc448b1fc01815f3,openstack/puppet-neutron,master,I5bc8a4529e7441e7eb53ae74fc448b1fc01815f3,Adding support for overlay_ip_version,MERGED,2016-08-25 20:10:25.000000000,2016-08-29 16:25:48.000000000,2016-08-29 16:13:23.000000000,"[{'_account_id': 3}, {'_account_id': 7732}, {'_account_id': 7745}, {'_account_id': 8971}]","[{'number': 1, 'created': '2016-08-25 20:10:25.000000000', 'files': ['spec/classes/neutron_plugins_ml2_spec.rb', 'releasenotes/notes/add-overlay-ip-version-6759f0d61c50011c.yaml', 'manifests/plugins/ml2.pp'], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/e6a9d2eccef9fcb5ac69241801765d7c00b67996', 'message': 'Adding support for overlay_ip_version\n\nNeutron recently added support for configuring the IP version used for\noverlay network endpoints.\n\nChange-Id: I5bc8a4529e7441e7eb53ae74fc448b1fc01815f3\n'}]",0,360766,e6a9d2eccef9fcb5ac69241801765d7c00b67996,28,4,1,6681,,,0,"Adding support for overlay_ip_version

Neutron recently added support for configuring the IP version used for
overlay network endpoints.

Change-Id: I5bc8a4529e7441e7eb53ae74fc448b1fc01815f3
",git fetch https://review.opendev.org/openstack/puppet-neutron refs/changes/66/360766/1 && git format-patch -1 --stdout FETCH_HEAD,"['spec/classes/neutron_plugins_ml2_spec.rb', 'releasenotes/notes/add-overlay-ip-version-6759f0d61c50011c.yaml', 'manifests/plugins/ml2.pp']",3,e6a9d2eccef9fcb5ac69241801765d7c00b67996,add-overlay-ip-version,"# [*overlay_ip_version*] # (optional) Configures the IP version used for all overlay network endpoints. Valid values # are 4 and 6. # Defaults to $::os_service_default # $overlay_ip_version = $::os_service_default, if !is_service_default($overlay_ip_version) and !($overlay_ip_version in [4, 6]) { fail('Invalid IP version for overlay_ip_version') } 'ml2/overlay_ip_version': value => $overlay_ip_version;",,42,0
openstack%2Fapp-catalog~master~I624311b0f11fd63ecb1d35e48014b6fecf681414,openstack/app-catalog,master,I624311b0f11fd63ecb1d35e48014b6fecf681414,Fix pbr.version call to match setup.cfg,ABANDONED,2016-08-26 15:13:13.000000000,2016-08-29 16:23:47.000000000,,"[{'_account_id': 3}, {'_account_id': 7369}]","[{'number': 1, 'created': '2016-08-26 15:13:13.000000000', 'files': ['openstack_catalog/__init__.py'], 'web_link': 'https://opendev.org/openstack/app-catalog/commit/5b58ef2c941d602c7637780ccf71a40e3d00e647', 'message': 'Fix pbr.version call to match setup.cfg\n\nChange-Id: I624311b0f11fd63ecb1d35e48014b6fecf681414\n'}]",0,361292,5b58ef2c941d602c7637780ccf71a40e3d00e647,4,2,1,2,,,0,"Fix pbr.version call to match setup.cfg

Change-Id: I624311b0f11fd63ecb1d35e48014b6fecf681414
",git fetch https://review.opendev.org/openstack/app-catalog refs/changes/92/361292/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack_catalog/__init__.py'],1,5b58ef2c941d602c7637780ccf71a40e3d00e647,bp/glare-work, 'openstack_app_catalog').version_string(), 'openstack_catalog').version_string(),1,1
openstack%2Fneutron-vpnaas~master~I6546d71c51eec74c7997d0da44db79624774c073,openstack/neutron-vpnaas,master,I6546d71c51eec74c7997d0da44db79624774c073,Add debug output to tox_install.sh,MERGED,2016-08-29 14:55:09.000000000,2016-08-29 16:22:53.000000000,2016-08-29 16:22:53.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 6524}, {'_account_id': 6659}, {'_account_id': 9656}]","[{'number': 1, 'created': '2016-08-29 14:55:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-vpnaas/commit/ba507955f1e49250beb18d56baf0a0b4e725d8f8', 'message': 'Add debug output to tox_install.sh\n\nUse -x to get proper debug output of the tool.\n\nChange-Id: I6546d71c51eec74c7997d0da44db79624774c073\n'}, {'number': 2, 'created': '2016-08-29 15:00:42.000000000', 'files': ['tools/tox_install.sh'], 'web_link': 'https://opendev.org/openstack/neutron-vpnaas/commit/97cc8fc111a5d63071e0d251043779e59a701712', 'message': 'Add debug output to tox_install.sh\n\nUse -x to get proper debug output of the tool.\n\nPaul pointed out that my previous change broke neutron and\nneutron-vpnaas testing together in a very specific case. Looking at this\nin detail, we need some more debugging output to fix the problem. This\nscript is not logged right now, so, enable logging with -x and then\nuplaod logs with an infra change.\n\nChange-Id: I6546d71c51eec74c7997d0da44db79624774c073\n'}]",0,362164,97cc8fc111a5d63071e0d251043779e59a701712,11,5,2,6547,,,0,"Add debug output to tox_install.sh

Use -x to get proper debug output of the tool.

Paul pointed out that my previous change broke neutron and
neutron-vpnaas testing together in a very specific case. Looking at this
in detail, we need some more debugging output to fix the problem. This
script is not logged right now, so, enable logging with -x and then
uplaod logs with an infra change.

Change-Id: I6546d71c51eec74c7997d0da44db79624774c073
",git fetch https://review.opendev.org/openstack/neutron-vpnaas refs/changes/64/362164/1 && git format-patch -1 --stdout FETCH_HEAD,['tools/tox_install.sh'],1,ba507955f1e49250beb18d56baf0a0b4e725d8f8,set-x,set -x,,1,0
openstack%2Fproject-config~master~I4db68c5c0c9550eea0855a35b77147f4ced5bc7b,openstack/project-config,master,I4db68c5c0c9550eea0855a35b77147f4ced5bc7b,Fuel-qa & fuel-devops: gates changes,MERGED,2016-08-29 13:06:34.000000000,2016-08-29 16:18:37.000000000,2016-08-29 16:18:37.000000000,"[{'_account_id': 1}, {'_account_id': 3}, {'_account_id': 1106}, {'_account_id': 2750}, {'_account_id': 5263}, {'_account_id': 6133}, {'_account_id': 6316}, {'_account_id': 6547}, {'_account_id': 6786}, {'_account_id': 7118}, {'_account_id': 14057}, {'_account_id': 15984}]","[{'number': 1, 'created': '2016-08-29 13:06:34.000000000', 'files': ['jenkins/jobs/projects.yaml', 'zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/3308cbc103ea99903e9812a8c1a40c6196ecc1e1', 'message': 'Fuel-qa & fuel-devops: gates changes\n\n1. Revert coverage job for fuel-qa:\n  no setup.py in this repo for now\n\n  Will run this gate on internal CI\n\n2. Enable ubuntu-trusty gates for alive branches\n\nChange-Id: I4db68c5c0c9550eea0855a35b77147f4ced5bc7b\n'}]",0,362103,3308cbc103ea99903e9812a8c1a40c6196ecc1e1,10,12,1,19119,,,0,"Fuel-qa & fuel-devops: gates changes

1. Revert coverage job for fuel-qa:
  no setup.py in this repo for now

  Will run this gate on internal CI

2. Enable ubuntu-trusty gates for alive branches

Change-Id: I4db68c5c0c9550eea0855a35b77147f4ced5bc7b
",git fetch https://review.opendev.org/openstack/project-config refs/changes/03/362103/1 && git format-patch -1 --stdout FETCH_HEAD,"['jenkins/jobs/projects.yaml', 'zuul/layout.yaml']",2,3308cbc103ea99903e9812a8c1a40c6196ecc1e1,, - name: ^gate-fuel-qa-python27-ubuntu-trusty branch: ^stable/(mitaka|8\.0|7\.0|6\.1)(-mu)?.*$ - name: ^gate-fuel-qa-pep8-ubuntu-trusty branch: ^stable/(mitaka|8\.0|7\.0|6\.1)(-mu)?.*$, - name: ^fuel-qa-coverage-ubuntu-trusty branch: ^stable/mitaka.*$ - name: ^fuel-qa-coverage-ubuntu-xenial branch: ^(?!stable(-mu)?/(?:4\.0|4\.1|5\.0|5\.1|6\.0|6\.1|7\.0|8\.0|mitaka)).*$ - fuel-qa-coverage-ubuntu-trusty - fuel-qa-coverage-ubuntu-xenial - fuel-qa-coverage-ubuntu-trusty - fuel-qa-coverage-ubuntu-xenial,4,9
openstack%2Finstack-undercloud~master~Ia4d8fdf47d9d15e1a1094df5f4e9011c009bae51,openstack/instack-undercloud,master,Ia4d8fdf47d9d15e1a1094df5f4e9011c009bae51,Fix outdated help text from undercloud VIPs,MERGED,2016-08-26 09:14:45.000000000,2016-08-29 16:15:45.000000000,2016-08-29 15:21:05.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 4328}, {'_account_id': 4330}, {'_account_id': 6796}, {'_account_id': 8042}, {'_account_id': 8449}, {'_account_id': 15895}]","[{'number': 1, 'created': '2016-08-26 09:14:45.000000000', 'files': ['instack_undercloud/undercloud.py'], 'web_link': 'https://opendev.org/openstack/instack-undercloud/commit/cccaf4884b320c88e36ab32a4c99f4878631c583', 'message': 'Fix outdated help text from undercloud VIPs\n\nThese are taken into account also with generate_service_certificate\nnot only if we inject a certificate using undercloud_service_certificate.\n\nChange-Id: Ia4d8fdf47d9d15e1a1094df5f4e9011c009bae51\n'}]",0,361020,cccaf4884b320c88e36ab32a4c99f4878631c583,14,8,1,10873,,,0,"Fix outdated help text from undercloud VIPs

These are taken into account also with generate_service_certificate
not only if we inject a certificate using undercloud_service_certificate.

Change-Id: Ia4d8fdf47d9d15e1a1094df5f4e9011c009bae51
",git fetch https://review.opendev.org/openstack/instack-undercloud refs/changes/20/361020/1 && git format-patch -1 --stdout FETCH_HEAD,['instack_undercloud/undercloud.py'],1,cccaf4884b320c88e36ab32a4c99f4878631c583,fix_doco, 'Undercloud services. Only used with SSL.') 'Undercloud services. Only used with SSL.'), 'Undercloud services. Only used if ' 'undercloud_service_certficate is set.') 'Undercloud services. Only used if ' 'undercloud_service_certficate is set.'),2,4
openstack%2Fgovernance~master~I5efe6dbb98785a857192859de38004262a5ba812,openstack/governance,master,I5efe6dbb98785a857192859de38004262a5ba812,Update Glance 'api' location,MERGED,2016-08-16 18:26:09.000000000,2016-08-29 16:13:39.000000000,2016-08-29 16:13:38.000000000,"[{'_account_id': 3}, {'_account_id': 308}, {'_account_id': 964}, {'_account_id': 970}, {'_account_id': 2537}, {'_account_id': 6159}, {'_account_id': 11564}]","[{'number': 1, 'created': '2016-08-16 18:26:09.000000000', 'files': ['reference/projects.yaml'], 'web_link': 'https://opendev.org/openstack/governance/commit/1d406167abae728592dda7a3f5fefd05b790311f', 'message': ""Update Glance 'api' location\n\nThe 'api' field for Glance currently contains a now-outdated URL\nalong with a comment about what to do about multiple API versions.\nThis patch updates the URL to the new api-ref location which consists\nof a landing page containing links to the multiple API versions.\n\nChange-Id: I5efe6dbb98785a857192859de38004262a5ba812\n""}]",0,356089,1d406167abae728592dda7a3f5fefd05b790311f,12,7,1,5314,,,0,"Update Glance 'api' location

The 'api' field for Glance currently contains a now-outdated URL
along with a comment about what to do about multiple API versions.
This patch updates the URL to the new api-ref location which consists
of a landing page containing links to the multiple API versions.

Change-Id: I5efe6dbb98785a857192859de38004262a5ba812
",git fetch https://review.opendev.org/openstack/governance refs/changes/89/356089/1 && git format-patch -1 --stdout FETCH_HEAD,['reference/projects.yaml'],1,1d406167abae728592dda7a3f5fefd05b790311f,update-api-field, api: http://developer.openstack.org/api-ref/image/, api: http://developer.openstack.org/api-ref-image-v2.html # What to do with multiple versions of an API?,1,1
openstack%2Fpuppet-openstack-integration~master~I8c69c41ee18c7c64f9dfa1629a98fac4c008add7,openstack/puppet-openstack-integration,master,I8c69c41ee18c7c64f9dfa1629a98fac4c008add7,Promote RDO to latest trunk,MERGED,2016-08-29 12:10:46.000000000,2016-08-29 16:13:28.000000000,2016-08-29 16:13:28.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 7745}]","[{'number': 1, 'created': '2016-08-29 12:10:46.000000000', 'files': ['manifests/repos.pp'], 'web_link': 'https://opendev.org/openstack/puppet-openstack-integration/commit/983353658e21a33ab13ab12db57a22cb3a35cffa', 'message': 'Promote RDO to latest trunk\n\nChange-Id: I8c69c41ee18c7c64f9dfa1629a98fac4c008add7\n'}]",0,362057,983353658e21a33ab13ab12db57a22cb3a35cffa,10,3,1,3153,,,0,"Promote RDO to latest trunk

Change-Id: I8c69c41ee18c7c64f9dfa1629a98fac4c008add7
",git fetch https://review.opendev.org/openstack/puppet-openstack-integration refs/changes/57/362057/1 && git format-patch -1 --stdout FETCH_HEAD,['manifests/repos.pp'],1,983353658e21a33ab13ab12db57a22cb3a35cffa,rdo/promote," 'baseurl' => 'https://trunk.rdoproject.org/centos7-master/be/26/be26c8448a21e210562ca828805629b12d30da85_048a3d0e/',"," 'baseurl' => 'https://trunk.rdoproject.org/centos7-master/ba/cd/bacdc6e9f4b6b6de604cf2c3c9ba4dd21e709089_19d853ce/',",1,1
openstack%2Ftripleo-ci~master~Iceb2101eccf38201b4b8b10f7f3eb4ae5ac247fb,openstack/tripleo-ci,master,Iceb2101eccf38201b4b8b10f7f3eb4ae5ac247fb,Extract /var/log from all nodes,MERGED,2016-08-26 13:11:04.000000000,2016-08-29 16:13:17.000000000,2016-08-29 16:13:17.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 6928}, {'_account_id': 7144}, {'_account_id': 10239}]","[{'number': 1, 'created': '2016-08-26 13:11:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/d5eb108e73cae24c19d86101222ff7f39581c3b0', 'message': 'Extract /var/log from all nodes\n\nMake the contents of /var/log easily viewable from the web browser and\nfor indexing by elasticsearch.\n\nChange-Id: Iceb2101eccf38201b4b8b10f7f3eb4ae5ac247fb\n'}, {'number': 2, 'created': '2016-08-26 18:29:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/3ea88ce288061450ba896c7a788f1b36f6aaabf6', 'message': 'Extract /var/log and /etc from all nodes\n\nMake the contents of /var/log and /etc easily viewable from the web\nbrowser and for indexing by elasticsearch.\n\nChange-Id: Iceb2101eccf38201b4b8b10f7f3eb4ae5ac247fb\n'}, {'number': 3, 'created': '2016-08-26 18:53:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/024f766116a59b4316e750208188e845a44f46de', 'message': 'Extract /var/log and /etc from all nodes\n\nMake the contents of /var/log and /etc easily viewable from the web\nbrowser and for indexing by elasticsearch.\n\nChange-Id: Iceb2101eccf38201b4b8b10f7f3eb4ae5ac247fb\n'}, {'number': 4, 'created': '2016-08-26 20:23:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/137dc4bc8ec6696c54f3973067cc6c0034d63851', 'message': 'Extract /var/log and /etc from all nodes\n\nMake the contents of /var/log and /etc easily viewable from the web\nbrowser and for indexing by elasticsearch.\n\nChange-Id: Iceb2101eccf38201b4b8b10f7f3eb4ae5ac247fb\n'}, {'number': 5, 'created': '2016-08-26 22:03:08.000000000', 'files': ['scripts/common_functions.sh'], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/efe52f01cea72aab8cf6ea05b25e17d3c63182fb', 'message': 'Extract /var/log from all nodes\n\nMake the contents of /var/log easily viewable from the web\nbrowser and for indexing by elasticsearch.\n\nChange-Id: Iceb2101eccf38201b4b8b10f7f3eb4ae5ac247fb\n'}]",2,361164,efe52f01cea72aab8cf6ea05b25e17d3c63182fb,24,5,5,7144,,,0,"Extract /var/log from all nodes

Make the contents of /var/log easily viewable from the web
browser and for indexing by elasticsearch.

Change-Id: Iceb2101eccf38201b4b8b10f7f3eb4ae5ac247fb
",git fetch https://review.opendev.org/openstack/tripleo-ci refs/changes/64/361164/1 && git format-patch -1 --stdout FETCH_HEAD,['scripts/common_functions.sh'],1,d5eb108e73cae24c19d86101222ff7f39581c3b0,361164, # Extract /var/log for easy viewing tar xf primary_node.tar.xz -C $WORKSPACE/ var/log # Extract /var/log for easy viewing tar xf $WORKSPACE/logs/subnode-$i/subnode-$i.tar.xz -C $WORKSPACE/logs/subnode-$i/ var/log,,4,0
openstack%2Fdeb-python-oslotest~debian%2Fnewton~I637ac1cd9253568ccd4e561e427ae59a9b0c9487,openstack/deb-python-oslotest,debian/newton,I637ac1cd9253568ccd4e561e427ae59a9b0c9487,Update .gitreview file,ABANDONED,2016-08-29 15:32:43.000000000,2016-08-29 16:12:18.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2016-08-29 15:32:43.000000000', 'files': ['.gitreview'], 'web_link': 'https://opendev.org/openstack/deb-python-oslotest/commit/ec7ba9f945217f3cf2f012e4ba44c243ec311172', 'message': 'Update .gitreview file\n\nChange-Id: I637ac1cd9253568ccd4e561e427ae59a9b0c9487\n'}]",0,362204,ec7ba9f945217f3cf2f012e4ba44c243ec311172,3,1,1,12841,,,0,"Update .gitreview file

Change-Id: I637ac1cd9253568ccd4e561e427ae59a9b0c9487
",git fetch https://review.opendev.org/openstack/deb-python-oslotest refs/changes/04/362204/1 && git format-patch -1 --stdout FETCH_HEAD,['.gitreview'],1,ec7ba9f945217f3cf2f012e4ba44c243ec311172,,,defaultbranch=debian/newton,0,1
openstack%2Fopenstack-ansible~liberty~I8f7e499af16be77eaa487020dd75484aebc789cb,openstack/openstack-ansible,liberty,I8f7e499af16be77eaa487020dd75484aebc789cb,Remove unnecessary overrides of service variables,MERGED,2016-08-26 21:50:32.000000000,2016-08-29 16:10:27.000000000,2016-08-29 16:10:27.000000000,"[{'_account_id': 3}, {'_account_id': 538}, {'_account_id': 7353}]","[{'number': 1, 'created': '2016-08-26 21:50:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/a647e96497c92b1b8f7c8799b58d56ab628c612b', 'message': ""Remove unnecessary overrides of service variables\n\nUse the existing service namespaced variables instead of overriding\nand providing a generic 'service_' variable for use with the service\nsetup tasks.\n\n`role_name` is a reserved variable name. Instead, use the explicit\nservice_role_name variables when adding roles to users.\n\nThis also fixes a recursive loop issue seen when deploying the\nintegrated release with Ansible 2.1.\n\nThis is a combined manual backport of the following changes:\nIa5fa0e400aeec6d808891c5dd793ee8177d9b5f3\nIc5fa09d7fd886c4def544c87fa87002c303a4da4\nI350def02e04cd6d8279dcccade607ca3543ef4fa\nI469dcabb03c792abbad7f65a17bfa5f7146dcfa7\nI72dc237623f2307430e219433425a6d67f15050d\nI715be2c77fa5639e28c9baeebe6552747f07bb30\nI4daad47d8e79e811f89f0327929feb3308612ed6\n\nCloses-Bug: 1603703\nChange-Id: I8f7e499af16be77eaa487020dd75484aebc789cb\n""}, {'number': 2, 'created': '2016-08-26 23:20:13.000000000', 'files': ['playbooks/roles/os_aodh/tasks/aodh_service_add.yml', 'playbooks/roles/os_neutron/tasks/neutron_service_setup.yml', 'playbooks/roles/os_aodh/tasks/aodh_service_setup.yml', 'playbooks/roles/os_cinder/tasks/cinder_service_setup.yml', 'playbooks/roles/os_heat/tasks/heat_service_add.yml', 'playbooks/roles/os_nova/tasks/nova_service_setup.yml', 'playbooks/roles/os_nova/tasks/nova_service_add.yml', 'playbooks/roles/os_ceilometer/tasks/ceilometer_service_setup.yml', 'playbooks/roles/os_neutron/tasks/neutron_service_add.yml', 'playbooks/roles/os_cinder/tasks/cinder_service_add.yml', 'playbooks/roles/os_ceilometer/tasks/ceilometer_service_add.yml', 'playbooks/roles/os_heat/tasks/heat_service_setup.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/46e07db03dfb24e7031e46587443913ed3eb630b', 'message': ""Remove unnecessary overrides of service variables\n\nUse the existing service namespaced variables instead of overriding\nand providing a generic 'service_' variable for use with the service\nsetup tasks.\n\n`role_name` is a reserved variable name. Instead, use the explicit\nservice_role_name variables when adding roles to users.\n\nThis also fixes a recursive loop issue seen when deploying the\nintegrated release with Ansible 2.1.\n\nThis is a combined manual backport of the following changes:\nIa5fa0e400aeec6d808891c5dd793ee8177d9b5f3\nIc5fa09d7fd886c4def544c87fa87002c303a4da4\nI350def02e04cd6d8279dcccade607ca3543ef4fa\nI469dcabb03c792abbad7f65a17bfa5f7146dcfa7\nI72dc237623f2307430e219433425a6d67f15050d\nI715be2c77fa5639e28c9baeebe6552747f07bb30\nI4daad47d8e79e811f89f0327929feb3308612ed6\n\nCloses-Bug: 1603703\nChange-Id: I8f7e499af16be77eaa487020dd75484aebc789cb\n""}]",0,361479,46e07db03dfb24e7031e46587443913ed3eb630b,9,3,2,14805,,,0,"Remove unnecessary overrides of service variables

Use the existing service namespaced variables instead of overriding
and providing a generic 'service_' variable for use with the service
setup tasks.

`role_name` is a reserved variable name. Instead, use the explicit
service_role_name variables when adding roles to users.

This also fixes a recursive loop issue seen when deploying the
integrated release with Ansible 2.1.

This is a combined manual backport of the following changes:
Ia5fa0e400aeec6d808891c5dd793ee8177d9b5f3
Ic5fa09d7fd886c4def544c87fa87002c303a4da4
I350def02e04cd6d8279dcccade607ca3543ef4fa
I469dcabb03c792abbad7f65a17bfa5f7146dcfa7
I72dc237623f2307430e219433425a6d67f15050d
I715be2c77fa5639e28c9baeebe6552747f07bb30
I4daad47d8e79e811f89f0327929feb3308612ed6

Closes-Bug: 1603703
Change-Id: I8f7e499af16be77eaa487020dd75484aebc789cb
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/79/361479/1 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/roles/os_aodh/tasks/aodh_service_add.yml', 'playbooks/roles/os_neutron/tasks/neutron_service_setup.yml', 'playbooks/roles/os_aodh/tasks/aodh_service_setup.yml', 'playbooks/roles/os_cinder/tasks/cinder_service_setup.yml', 'playbooks/roles/os_heat/tasks/heat_service_add.yml', 'playbooks/roles/os_nova/tasks/nova_service_setup.yml', 'playbooks/roles/os_nova/tasks/nova_service_add.yml', 'playbooks/roles/os_ceilometer/tasks/ceilometer_service_setup.yml', 'playbooks/roles/os_neutron/tasks/neutron_service_add.yml', 'playbooks/roles/os_cinder/tasks/cinder_service_add.yml', 'playbooks/roles/os_ceilometer/tasks/ceilometer_service_add.yml', 'playbooks/roles/os_heat/tasks/heat_service_setup.yml']",12,a647e96497c92b1b8f7c8799b58d56ab628c612b,bug/1603703,," service_user_name: ""{{ heat_service_user_name }}"" service_tenant_name: ""{{ heat_service_project_name }}"" service_region: ""{{ heat_service_region }}"" service_password: ""{{ heat_service_password }}"" role_name: ""{{ heat_service_role_name }}"" service_user_name: ""{{ heat_service_user_name }}"" service_tenant_name: ""{{ heat_service_project_name }}"" service_region: ""{{ heat_service_region }}"" service_password: ""{{ heat_cfn_service_password }}"" role_name: ""{{ heat_service_role_name }}""",322,462
openstack%2Fdeb-python-wrapt~debian%2Fnewton~I994ce66d30ae8806b97114ad492764e6c53f164a,openstack/deb-python-wrapt,debian/newton,I994ce66d30ae8806b97114ad492764e6c53f164a,Add a .gitreview file,MERGED,2016-08-29 15:25:02.000000000,2016-08-29 16:09:49.000000000,2016-08-29 16:09:49.000000000,"[{'_account_id': 3}, {'_account_id': 6476}]","[{'number': 1, 'created': '2016-08-29 15:25:02.000000000', 'files': ['.gitreview'], 'web_link': 'https://opendev.org/openstack/deb-python-wrapt/commit/26d1a2f2d540a09c5e1e8e18d1e7c9a71ae34de7', 'message': 'Add a .gitreview file\n\nChange-Id: I994ce66d30ae8806b97114ad492764e6c53f164a\n'}]",0,362197,26d1a2f2d540a09c5e1e8e18d1e7c9a71ae34de7,6,2,1,6476,,,0,"Add a .gitreview file

Change-Id: I994ce66d30ae8806b97114ad492764e6c53f164a
",git fetch https://review.opendev.org/openstack/deb-python-wrapt refs/changes/97/362197/1 && git format-patch -1 --stdout FETCH_HEAD,['.gitreview'],1,26d1a2f2d540a09c5e1e8e18d1e7c9a71ae34de7,,[gerrit] host=review.openstack.org port=29418 project=openstack/deb-python-wrapt.git defaultbranch=debian/newton ,,5,0
openstack%2Fdeb-python-txaio~debian%2Fnewton~Iaba81913595457b51724e9c2b8cf64f747b25534,openstack/deb-python-txaio,debian/newton,Iaba81913595457b51724e9c2b8cf64f747b25534,Add a .gitreview file,MERGED,2016-08-29 15:21:06.000000000,2016-08-29 16:08:17.000000000,2016-08-29 16:08:17.000000000,"[{'_account_id': 3}, {'_account_id': 6476}]","[{'number': 1, 'created': '2016-08-29 15:21:06.000000000', 'files': ['.gitreview'], 'web_link': 'https://opendev.org/openstack/deb-python-txaio/commit/0ad41cb1622a54311520dc0adfeaa7e5aab3fba7', 'message': 'Add a .gitreview file\n\nChange-Id: Iaba81913595457b51724e9c2b8cf64f747b25534\n'}]",0,362191,0ad41cb1622a54311520dc0adfeaa7e5aab3fba7,6,2,1,6476,,,0,"Add a .gitreview file

Change-Id: Iaba81913595457b51724e9c2b8cf64f747b25534
",git fetch https://review.opendev.org/openstack/deb-python-txaio refs/changes/91/362191/1 && git format-patch -1 --stdout FETCH_HEAD,['.gitreview'],1,0ad41cb1622a54311520dc0adfeaa7e5aab3fba7,,[gerrit] host=review.openstack.org port=29418 project=openstack/deb-python-txaio.git defaultbranch=debian/newton ,,5,0
openstack%2Fironic~master~I7938f26015d953efdf720774b5ad2cee4068ac90,openstack/ironic,master,I7938f26015d953efdf720774b5ad2cee4068ac90,Refactor ironic enroll-node code,ABANDONED,2015-12-11 11:24:42.000000000,2016-08-29 16:07:16.000000000,,"[{'_account_id': 3}, {'_account_id': 2889}, {'_account_id': 4656}, {'_account_id': 5805}, {'_account_id': 6287}, {'_account_id': 6610}, {'_account_id': 6637}, {'_account_id': 9628}, {'_account_id': 10118}, {'_account_id': 10239}, {'_account_id': 10342}, {'_account_id': 10343}, {'_account_id': 11297}, {'_account_id': 12356}, {'_account_id': 13362}, {'_account_id': 14525}, {'_account_id': 14629}, {'_account_id': 17998}, {'_account_id': 19003}, {'_account_id': 20035}, {'_account_id': 20311}, {'_account_id': 20863}]","[{'number': 1, 'created': '2015-12-11 11:24:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/bbf00992d2cd23989c9f9a9443f2dc2b62f6c79a', 'message': 'refactor ironic enroll-node code\n\nThis change allows to import ironic nodes from INI files.\n\nChange-Id: I7938f26015d953efdf720774b5ad2cee4068ac90\nImplements: blueprint ironic-ml2-integration\n'}, {'number': 2, 'created': '2015-12-16 16:00:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/f03940ac31fe544ec54140c75c4212cc0e4fbd7c', 'message': 'refactor ironic enroll-node code\n\nThis change allows to import ironic nodes from INI files.\n\nChange-Id: I7938f26015d953efdf720774b5ad2cee4068ac90\nImplements: blueprint ironic-ml2-integration\n'}, {'number': 3, 'created': '2015-12-17 08:11:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/8833105495a32cc43f4adff0082bccd93aeedad5', 'message': 'refactor ironic enroll-node code\n\nThis change allows to import ironic nodes from INI files.\n\nDepends-On: I52a69ad3bc8fc528e7f20e6b03a98f327acaaa74\nChange-Id: I7938f26015d953efdf720774b5ad2cee4068ac90\nImplements: blueprint ironic-ml2-integration\n'}, {'number': 4, 'created': '2015-12-21 10:10:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/35ea4023ee32f92d40e0792f0b829265142f9e6e', 'message': 'refactor ironic enroll-node code\n\nThis change allows to import ironic nodes from INI files.\n\nDepends-On: I52a69ad3bc8fc528e7f20e6b03a98f327acaaa74\nChange-Id: I7938f26015d953efdf720774b5ad2cee4068ac90\nPartial-bug: #1526403\n'}, {'number': 5, 'created': '2015-12-23 06:59:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/47cd3c617c9d0d75b9755aadd5c7374eb4cb985b', 'message': 'refactor ironic enroll-node code\n\nThis change allows to import ironic nodes from INI files.\n\nDepends-On: I52a69ad3bc8fc528e7f20e6b03a98f327acaaa74\nChange-Id: I7938f26015d953efdf720774b5ad2cee4068ac90\nPartial-bug: #1526403\n'}, {'number': 6, 'created': '2015-12-29 11:52:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/8c5a83ae74532e904056bc1ab1331f11637ff6f7', 'message': 'refactor ironic enroll-node code\n\nThis change allows to import ironic nodes from INI files.\n\nDepends-On: I52a69ad3bc8fc528e7f20e6b03a98f327acaaa74\nChange-Id: I7938f26015d953efdf720774b5ad2cee4068ac90\nPartial-bug: #1526403\n'}, {'number': 7, 'created': '2016-01-05 17:45:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/87448f94320433471ff0ef44546d24979579db1c', 'message': 'refactor ironic enroll-node code\n\nThis change allows to import ironic nodes from INI files.\n\nDepends-On: I52a69ad3bc8fc528e7f20e6b03a98f327acaaa74\nChange-Id: I7938f26015d953efdf720774b5ad2cee4068ac90\nPartial-bug: #1526403\n'}, {'number': 8, 'created': '2016-01-06 11:34:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/71c4e829752d035dd665f0d6d5ef436960877414', 'message': 'refactor ironic enroll-node code\n\nThis change allows to import ironic nodes from INI files.\n\nDepends-On: I52a69ad3bc8fc528e7f20e6b03a98f327acaaa74\nChange-Id: I7938f26015d953efdf720774b5ad2cee4068ac90\nPartial-bug: #1526403\n'}, {'number': 9, 'created': '2016-01-08 08:58:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/e4fd98a13798ada7034d8cbb1984984774385b30', 'message': 'refactor ironic enroll-node code\n\nThis change allows to import ironic nodes from INI files.\n\nDepends-On: I52a69ad3bc8fc528e7f20e6b03a98f327acaaa74\nChange-Id: I7938f26015d953efdf720774b5ad2cee4068ac90\nPartial-bug: #1526403\n'}, {'number': 10, 'created': '2016-01-13 23:21:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/dc300639d38e5399c5a8b4813e3c885299182096', 'message': 'refactor ironic enroll-node code\n\nThis change allows to import ironic nodes from INI files.\n\nDepends-On: I52a69ad3bc8fc528e7f20e6b03a98f327acaaa74\nChange-Id: I7938f26015d953efdf720774b5ad2cee4068ac90\nPartial-bug: #1526403\n'}, {'number': 11, 'created': '2016-01-18 17:33:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/a42ddac65573bde9acdf0cf8df107f6b6ca3c7ce', 'message': 'refactor ironic enroll-node code\n\nThis change allows to import ironic nodes from INI files.\n\nDepends-On: I52a69ad3bc8fc528e7f20e6b03a98f327acaaa74\nChange-Id: I7938f26015d953efdf720774b5ad2cee4068ac90\nPartial-bug: #1526403\n'}, {'number': 12, 'created': '2016-01-19 09:25:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/b45b0afb065ec3dfb8ee6d17c00b608d2d67598f', 'message': 'refactor ironic enroll-node code\n\nThis change allows to import ironic nodes from INI files.\n\nDepends-On: I52a69ad3bc8fc528e7f20e6b03a98f327acaaa74\nChange-Id: I7938f26015d953efdf720774b5ad2cee4068ac90\nPartial-bug: #1526403\n'}, {'number': 13, 'created': '2016-01-20 12:19:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/c1651d2a6184d36305aa819b92920854832dac7e', 'message': 'refactor ironic enroll-node code\n\nThis change allows to import ironic nodes from INI files.\n\nDepends-On: I52a69ad3bc8fc528e7f20e6b03a98f327acaaa74\nChange-Id: I7938f26015d953efdf720774b5ad2cee4068ac90\nPartial-bug: #1526403\n'}, {'number': 14, 'created': '2016-01-25 12:30:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/a3af80a6d93d1365e00ed4aa6ab47338b5e994a1', 'message': 'refactor ironic enroll-node code\n\nThis change allows to import ironic nodes from INI files.\n\nDepends-On: I52a69ad3bc8fc528e7f20e6b03a98f327acaaa74\nChange-Id: I7938f26015d953efdf720774b5ad2cee4068ac90\nPartial-bug: #1526403\n'}, {'number': 15, 'created': '2016-01-28 00:39:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/77a1062114b2a3b38473ca3a41c94ff2f25a090e', 'message': 'refactor ironic enroll-node code\n\nThis change allows to import ironic nodes from INI files.\n\nDepends-On: I52a69ad3bc8fc528e7f20e6b03a98f327acaaa74\nChange-Id: I7938f26015d953efdf720774b5ad2cee4068ac90\nPartial-bug: #1526403\n'}, {'number': 16, 'created': '2016-01-28 16:46:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/88604acb1dc5ca28502dca09ffdb8eae390a5d43', 'message': 'refactor ironic enroll-node code\n\nThis change allows to import ironic nodes from INI files.\n\nDepends-On: I52a69ad3bc8fc528e7f20e6b03a98f327acaaa74\nChange-Id: I7938f26015d953efdf720774b5ad2cee4068ac90\nPartial-bug: #1526403\n'}, {'number': 17, 'created': '2016-01-29 22:09:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/bae1bec4d2d2398bf157922fe1e777ccfd7610ce', 'message': 'refactor ironic enroll-node code\n\nThis change allows to import ironic nodes from INI files.\n\nDepends-On: I52a69ad3bc8fc528e7f20e6b03a98f327acaaa74\nChange-Id: I7938f26015d953efdf720774b5ad2cee4068ac90\nPartial-bug: #1526403\n'}, {'number': 18, 'created': '2016-01-29 22:13:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/7f34da3dffc67f6d4b0faa52af1f2b8bac448dd5', 'message': 'refactor ironic enroll-node code\n\nThis change allows to import ironic nodes from INI files.\n\nDepends-On: I52a69ad3bc8fc528e7f20e6b03a98f327acaaa74\nChange-Id: I7938f26015d953efdf720774b5ad2cee4068ac90\nPartial-bug: #1526403\n'}, {'number': 19, 'created': '2016-02-03 21:28:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/131e56e21b11142740be420509d0d5d61a5198ff', 'message': 'refactor ironic enroll-node code\n\nThis change allows to import ironic nodes from INI files.\n\nDepends-On: I52a69ad3bc8fc528e7f20e6b03a98f327acaaa74\nChange-Id: I7938f26015d953efdf720774b5ad2cee4068ac90\nPartial-bug: #1526403\n'}, {'number': 20, 'created': '2016-02-04 18:03:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/a099c3d4da39341c50d0ddf1ba97d324bb28d6a5', 'message': 'refactor ironic enroll-node code\n\nThis change allows to import ironic nodes from INI files.\n\nDepends-On: I52a69ad3bc8fc528e7f20e6b03a98f327acaaa74\nChange-Id: I7938f26015d953efdf720774b5ad2cee4068ac90\nPartial-bug: #1526403\n'}, {'number': 21, 'created': '2016-02-04 18:11:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/a351cfef1ee01c534d776b276c38ff4e4b9563fc', 'message': 'refactor ironic enroll-node code\n\nThis change allows to import ironic nodes from INI files.\n\nDepends-On: I52a69ad3bc8fc528e7f20e6b03a98f327acaaa74\nChange-Id: I7938f26015d953efdf720774b5ad2cee4068ac90\nPartial-bug: #1526403\n'}, {'number': 22, 'created': '2016-02-04 20:41:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/8e58f543570faf3d309fc5613b98d57d0859be9f', 'message': 'refactor ironic enroll-node code\n\nThis change allows to import ironic nodes from INI files.\n\nDepends-On: I52a69ad3bc8fc528e7f20e6b03a98f327acaaa74\nChange-Id: I7938f26015d953efdf720774b5ad2cee4068ac90\nPartial-bug: #1526403\n'}, {'number': 23, 'created': '2016-02-05 00:02:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/605df0e856acfa410dc7f11785b487b1a21b9e7a', 'message': 'refactor ironic enroll-node code\n\nThis change allows to import ironic nodes from INI files.\n\nDepends-On: I52a69ad3bc8fc528e7f20e6b03a98f327acaaa74\nChange-Id: I7938f26015d953efdf720774b5ad2cee4068ac90\nPartial-bug: #1526403\n'}, {'number': 24, 'created': '2016-02-05 17:02:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/260f32f79766ea05882c33c55e9bfe132a8cd2bb', 'message': 'refactor ironic enroll-node code\n\nThis change allows to import ironic nodes from INI files.\n\nDepends-On: I52a69ad3bc8fc528e7f20e6b03a98f327acaaa74\nChange-Id: I7938f26015d953efdf720774b5ad2cee4068ac90\nPartial-bug: #1526403\n'}, {'number': 25, 'created': '2016-02-08 08:47:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/c067585249be0c657e235f58a8ffe80b64975790', 'message': 'refactor ironic enroll-node code\n\nThis change allows to import ironic nodes from INI files.\n\nDepends-On: I52a69ad3bc8fc528e7f20e6b03a98f327acaaa74\nChange-Id: I7938f26015d953efdf720774b5ad2cee4068ac90\nPartial-bug: #1526403\n'}, {'number': 26, 'created': '2016-02-08 17:34:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/66bf4b10519d70141991263ad8d20839e3407ff7', 'message': 'refactor ironic enroll-node code\n\nThis change allows to import ironic nodes from INI files.\n\nDepends-On: I52a69ad3bc8fc528e7f20e6b03a98f327acaaa74\nChange-Id: I7938f26015d953efdf720774b5ad2cee4068ac90\nPartial-bug: #1526403\n'}, {'number': 27, 'created': '2016-02-09 12:02:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/6294ed773728bddbe628f036f107a23ffc7e377d', 'message': 'refactor ironic enroll-node code\n\nThis change allows to import ironic nodes from INI files.\n\nDepends-On: I52a69ad3bc8fc528e7f20e6b03a98f327acaaa74\nChange-Id: I7938f26015d953efdf720774b5ad2cee4068ac90\nPartial-bug: #1526403\n'}, {'number': 28, 'created': '2016-02-09 22:09:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/3bb8902427f98213c1f2b362a5504c18d372ec90', 'message': 'refactor ironic enroll-node code\n\nThis change allows to import ironic nodes from INI files.\n\nDepends-On: I52a69ad3bc8fc528e7f20e6b03a98f327acaaa74\nChange-Id: I7938f26015d953efdf720774b5ad2cee4068ac90\nPartial-bug: #1526403\n'}, {'number': 29, 'created': '2016-02-09 22:44:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/1a36f0fe69de1160833678475daf42482fb0c658', 'message': 'refactor ironic enroll-node code\n\nThis change allows to import ironic nodes from INI files.\n\nDepends-On: I52a69ad3bc8fc528e7f20e6b03a98f327acaaa74\nChange-Id: I7938f26015d953efdf720774b5ad2cee4068ac90\nPartial-bug: #1526403\n'}, {'number': 30, 'created': '2016-02-10 02:07:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/1891e92b5aae6fb1a734fb3bb52250ae03a68c68', 'message': 'refactor ironic enroll-node code\n\nThis change allows to import ironic nodes from INI files.\n\nDepends-On: I52a69ad3bc8fc528e7f20e6b03a98f327acaaa74\nChange-Id: I7938f26015d953efdf720774b5ad2cee4068ac90\nPartial-bug: #1526403\n'}, {'number': 31, 'created': '2016-02-10 09:35:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/a936bc5eacd09372018c894767dfaa71dffb824b', 'message': 'refactor ironic enroll-node code\n\nThis change allows to import ironic nodes from INI files.\n\nDepends-On: I52a69ad3bc8fc528e7f20e6b03a98f327acaaa74\nChange-Id: I7938f26015d953efdf720774b5ad2cee4068ac90\nPartial-bug: #1526403\n'}, {'number': 32, 'created': '2016-02-10 14:59:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/f0199c3eb3b5ab305197b93121578f63f3ef3e4a', 'message': 'refactor ironic enroll-node code\n\nThis change allows to import ironic nodes from INI files.\n\nDepends-On: I52a69ad3bc8fc528e7f20e6b03a98f327acaaa74\nChange-Id: I7938f26015d953efdf720774b5ad2cee4068ac90\nPartial-bug: #1526403\n'}, {'number': 33, 'created': '2016-02-10 18:27:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/d361c6f11a06cba6068ded8089c72c11df39038a', 'message': 'refactor ironic enroll-node code\n\nThis change allows to import ironic nodes from INI files.\n\nDepends-On: I52a69ad3bc8fc528e7f20e6b03a98f327acaaa74\nChange-Id: I7938f26015d953efdf720774b5ad2cee4068ac90\nPartial-bug: #1526403\n'}, {'number': 34, 'created': '2016-02-16 14:58:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/ce0455b84a8841bc4637f6aa11a663d45f726ac2', 'message': 'refactor ironic enroll-node code\n\nThis change allows to import ironic nodes from INI files.\n\nDepends-On: I52a69ad3bc8fc528e7f20e6b03a98f327acaaa74\nChange-Id: I7938f26015d953efdf720774b5ad2cee4068ac90\nPartial-bug: #1526403\n'}, {'number': 35, 'created': '2016-02-16 15:39:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/f9ed6fc36eae88b8dc83d93c310bf91327948978', 'message': 'refactor ironic enroll-node code\n\nThis change allows to import ironic nodes from INI files.\n\nDepends-On: I52a69ad3bc8fc528e7f20e6b03a98f327acaaa74\nChange-Id: I7938f26015d953efdf720774b5ad2cee4068ac90\nPartial-bug: #1526403\n'}, {'number': 36, 'created': '2016-02-17 14:44:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/47aa07fbef621012e8e509cd9c606970086332ae', 'message': 'refactor ironic enroll-node code\n\nThis change allows to import ironic nodes from INI files.\n\nDepends-On: I52a69ad3bc8fc528e7f20e6b03a98f327acaaa74\nChange-Id: I7938f26015d953efdf720774b5ad2cee4068ac90\nPartial-bug: #1526403\n'}, {'number': 37, 'created': '2016-02-17 16:27:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/4e0a185464055515514849e2a34645514ea9c6ec', 'message': 'refactor ironic enroll-node code\n\nThis change allows to import ironic nodes from INI files.\n\nDepends-On: I52a69ad3bc8fc528e7f20e6b03a98f327acaaa74\nChange-Id: I7938f26015d953efdf720774b5ad2cee4068ac90\nPartial-bug: #1526403\n'}, {'number': 38, 'created': '2016-02-18 14:55:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/e675445ef1b80283fc8429f82b333f60e2eedd02', 'message': 'refactor ironic enroll-node code\n\nThis change allows to import ironic nodes from INI files.\n\nDepends-On: I52a69ad3bc8fc528e7f20e6b03a98f327acaaa74\nChange-Id: I7938f26015d953efdf720774b5ad2cee4068ac90\nPartial-bug: #1526403\n'}, {'number': 39, 'created': '2016-03-04 23:33:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/3bc938f7bce3ec3f5c879f3f4e5bef7cfa514875', 'message': 'refactor ironic enroll-node code\n\nThis change allows to import ironic nodes from INI files.\n\nDepends-On: I52a69ad3bc8fc528e7f20e6b03a98f327acaaa74\nChange-Id: I7938f26015d953efdf720774b5ad2cee4068ac90\nPartial-bug: #1526403\n'}, {'number': 40, 'created': '2016-03-05 22:58:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/37389fb30148c4635d589fd611835e8d243317ac', 'message': 'refactor ironic enroll-node code\n\nThis change allows to import ironic nodes from INI files.\n\nDepends-On: I52a69ad3bc8fc528e7f20e6b03a98f327acaaa74\nChange-Id: I7938f26015d953efdf720774b5ad2cee4068ac90\nPartial-bug: #1526403\n'}, {'number': 41, 'created': '2016-03-14 09:45:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/499fcec5411d254c412f3a9458463a78ba6e8475', 'message': 'refactor ironic enroll-node code\n\nThis change allows to import ironic nodes from INI files.\n\nDepends-On: I52a69ad3bc8fc528e7f20e6b03a98f327acaaa74\nChange-Id: I7938f26015d953efdf720774b5ad2cee4068ac90\nPartial-bug: #1526403\n'}, {'number': 42, 'created': '2016-03-16 15:47:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/1a33acf0159ed14792e9636668b12b4ab6af584d', 'message': 'refactor ironic enroll-node code\n\nThis change allows to import ironic nodes from INI files.\n\nDepends-On: I52a69ad3bc8fc528e7f20e6b03a98f327acaaa74\nChange-Id: I7938f26015d953efdf720774b5ad2cee4068ac90\nPartial-bug: #1526403\n'}, {'number': 43, 'created': '2016-03-22 21:34:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/b0652af0586a2a24f8d25b0e5189382ef1833080', 'message': 'refactor ironic enroll-node code\n\nThis change allows to import ironic nodes from INI files.\n\nDepends-On: I52a69ad3bc8fc528e7f20e6b03a98f327acaaa74\nChange-Id: I7938f26015d953efdf720774b5ad2cee4068ac90\nPartial-bug: #1526403\n'}, {'number': 44, 'created': '2016-03-23 09:59:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/fca53a84d347764fdbdd3c5e93511789a010d4e5', 'message': 'refactor ironic enroll-node code\n\nThis change allows to import ironic nodes from INI files.\n\nDepends-On: I52a69ad3bc8fc528e7f20e6b03a98f327acaaa74\nChange-Id: I7938f26015d953efdf720774b5ad2cee4068ac90\nPartial-bug: #1526403\n'}, {'number': 45, 'created': '2016-03-24 14:56:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/28950615d78ea6d5a308c7248490f36f3410b916', 'message': 'refactor ironic enroll-node code\n\nThis change allows to import ironic nodes from INI files.\n\nDepends-On: I52a69ad3bc8fc528e7f20e6b03a98f327acaaa74\nChange-Id: I7938f26015d953efdf720774b5ad2cee4068ac90\nPartial-bug: #1526403\n'}, {'number': 46, 'created': '2016-03-25 13:08:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/b9919b14de02b40c38af6e32e01467e8e4dc6b27', 'message': 'refactor ironic enroll-node code\n\nThis change allows to import ironic nodes from INI files.\n\nDepends-On: I52a69ad3bc8fc528e7f20e6b03a98f327acaaa74\nChange-Id: I7938f26015d953efdf720774b5ad2cee4068ac90\nPartial-bug: #1526403\n'}, {'number': 47, 'created': '2016-03-25 17:18:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/eb55202dfe159ea991c3849bafd03b8b804406c8', 'message': 'refactor ironic enroll-node code\n\nThis change allows to import ironic nodes from INI files.\n\nDepends-On: I52a69ad3bc8fc528e7f20e6b03a98f327acaaa74\nChange-Id: I7938f26015d953efdf720774b5ad2cee4068ac90\nPartial-bug: #1526403\n'}, {'number': 48, 'created': '2016-03-25 20:16:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/9ef998ac21474a90e810032bb19a42b0d481845b', 'message': 'refactor ironic enroll-node code\n\nThis change allows to import ironic nodes from INI files.\n\nDepends-On: I52a69ad3bc8fc528e7f20e6b03a98f327acaaa74\nChange-Id: I7938f26015d953efdf720774b5ad2cee4068ac90\nPartial-bug: #1526403\n'}, {'number': 49, 'created': '2016-03-28 05:50:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/02c9aa7b35337bc44ba694e48c1b51b5b89fad1e', 'message': 'refactor ironic enroll-node code\n\nThis change allows to import ironic nodes from INI files.\n\nDepends-On: I52a69ad3bc8fc528e7f20e6b03a98f327acaaa74\nChange-Id: I7938f26015d953efdf720774b5ad2cee4068ac90\nPartial-bug: #1526403\n'}, {'number': 50, 'created': '2016-03-30 09:26:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/aa489e0fe700f558a62893c0ab840b0da3807dda', 'message': 'refactor ironic enroll-node code\n\nThis change allows to import ironic nodes from INI files.\n\nDepends-On: I52a69ad3bc8fc528e7f20e6b03a98f327acaaa74\nChange-Id: I7938f26015d953efdf720774b5ad2cee4068ac90\nPartial-bug: #1526403\n'}, {'number': 51, 'created': '2016-03-30 10:38:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/cfc102a623fbbb47d0fb44fedf7c50d5a80ddcec', 'message': 'refactor ironic enroll-node code\n\nThis change allows to import ironic nodes from INI files.\n\nDepends-On: I52a69ad3bc8fc528e7f20e6b03a98f327acaaa74\nChange-Id: I7938f26015d953efdf720774b5ad2cee4068ac90\nPartial-bug: #1526403\n'}, {'number': 52, 'created': '2016-03-30 15:24:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/0b473e790b9d01dfa82e94b8fc3f912fe7a649cb', 'message': 'refactor ironic enroll-node code\n\nThis change allows to import ironic nodes from INI files.\n\nDepends-On: I52a69ad3bc8fc528e7f20e6b03a98f327acaaa74\nChange-Id: I7938f26015d953efdf720774b5ad2cee4068ac90\nPartial-bug: #1526403\n'}, {'number': 53, 'created': '2016-03-31 06:44:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/a5d0413ef7412e2c691bf4e7ec6794d1aea254ec', 'message': 'refactor ironic enroll-node code\n\nThis change allows to import ironic nodes from INI files.\n\nDepends-On: I52a69ad3bc8fc528e7f20e6b03a98f327acaaa74\nChange-Id: I7938f26015d953efdf720774b5ad2cee4068ac90\nPartial-bug: #1526403\n'}, {'number': 54, 'created': '2016-03-31 11:19:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/d0078dcaa801f0941fb4939ea29679c48abd4ef4', 'message': 'refactor ironic enroll-node code\n\nThis change allows to import ironic nodes from INI files.\n\nDepends-On: I52a69ad3bc8fc528e7f20e6b03a98f327acaaa74\nChange-Id: I7938f26015d953efdf720774b5ad2cee4068ac90\nPartial-bug: #1526403\n'}, {'number': 55, 'created': '2016-04-01 08:49:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/34c361e6ec5e12efdb26d9997fa686f07a6d594f', 'message': 'refactor ironic enroll-node code\n\nThis change allows to import ironic nodes from INI files.\n\nDepends-On: I52a69ad3bc8fc528e7f20e6b03a98f327acaaa74\nChange-Id: I7938f26015d953efdf720774b5ad2cee4068ac90\nPartial-bug: #1526403\n'}, {'number': 56, 'created': '2016-04-01 12:44:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/6418490ada987176ad14ab8c9bad462b3d787582', 'message': 'refactor ironic enroll-node code\n\nThis change allows to import ironic nodes from INI files.\n\nDepends-On: I52a69ad3bc8fc528e7f20e6b03a98f327acaaa74\nChange-Id: I7938f26015d953efdf720774b5ad2cee4068ac90\nPartial-bug: #1526403\n'}, {'number': 57, 'created': '2016-04-07 10:59:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/3e60b45c427850b8599aff7f909d75b7c8927ebb', 'message': 'refactor ironic enroll-node code\n\nThis change allows to import ironic nodes from INI files.\n\nDepends-On: I52a69ad3bc8fc528e7f20e6b03a98f327acaaa74\nChange-Id: I7938f26015d953efdf720774b5ad2cee4068ac90\nPartial-bug: #1526403\n'}, {'number': 58, 'created': '2016-04-11 13:52:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/87cb5e9797aec2fad5fd4a99e9e90cf0b29873ba', 'message': 'refactor ironic enroll-node code\n\nThis change allows to import ironic nodes from INI files.\n\nDepends-On: I52a69ad3bc8fc528e7f20e6b03a98f327acaaa74\nChange-Id: I7938f26015d953efdf720774b5ad2cee4068ac90\nPartial-bug: #1526403\n'}, {'number': 59, 'created': '2016-04-12 13:49:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/31a48715063d50d9be71d2756c011890aca4ce2a', 'message': 'refactor ironic enroll-node code\n\nThis change allows to import ironic nodes from INI files.\n\nDepends-On: I52a69ad3bc8fc528e7f20e6b03a98f327acaaa74\nChange-Id: I7938f26015d953efdf720774b5ad2cee4068ac90\nPartial-bug: #1526403\n'}, {'number': 60, 'created': '2016-04-12 14:04:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/45c01a26e5a770524b215ed5d3bdd1b263b68ccd', 'message': 'refactor ironic enroll-node code\n\nThis change allows to import ironic nodes from INI files.\n\nDepends-On: I52a69ad3bc8fc528e7f20e6b03a98f327acaaa74\nChange-Id: I7938f26015d953efdf720774b5ad2cee4068ac90\nPartial-bug: #1526403\n'}, {'number': 61, 'created': '2016-04-14 14:57:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/a13c855c8f4ada6f8e57f069577af871f501f0e2', 'message': 'refactor ironic enroll-node code\n\nThis change allows to import ironic nodes from INI files.\n\nDepends-On: I52a69ad3bc8fc528e7f20e6b03a98f327acaaa74\nChange-Id: I7938f26015d953efdf720774b5ad2cee4068ac90\nPartial-bug: #1526403\n'}, {'number': 62, 'created': '2016-05-16 09:55:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/aac13e1d3d1e2f49503c2190b1c5396fa04a9d70', 'message': 'refactor ironic enroll-node code\n\nThis change allows to import ironic nodes from INI files.\n\nDepends-On: I52a69ad3bc8fc528e7f20e6b03a98f327acaaa74\nChange-Id: I7938f26015d953efdf720774b5ad2cee4068ac90\nPartial-bug: #1526403\n'}, {'number': 63, 'created': '2016-05-17 11:05:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/76de5dca7c10347967d334449fb76c61608df296', 'message': 'Refactor ironic enroll-node code\n\nThis change allows to import ironic nodes from INI files.\n\nChange-Id: I7938f26015d953efdf720774b5ad2cee4068ac90\n'}, {'number': 64, 'created': '2016-05-24 16:13:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/0557789f842e46df300d14911c84db68827a28a6', 'message': 'Refactor ironic enroll-node code\n\nThis change allows to import ironic nodes from INI files.\n\nChange-Id: I7938f26015d953efdf720774b5ad2cee4068ac90\n'}, {'number': 65, 'created': '2016-05-26 14:56:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/773dcfbb4d78d0421a10102165d287d8951c88db', 'message': 'Refactor ironic enroll-node code\n\nThis change allows to import ironic nodes from INI files.\n\nChange-Id: I7938f26015d953efdf720774b5ad2cee4068ac90\n'}, {'number': 66, 'created': '2016-06-01 08:37:50.000000000', 'files': ['devstack/lib/ironic', 'devstack/tools/ironic/templates/vm.xml', 'devstack/doc/source/guides/ironic-options.rst', 'devstack/tools/ironic/scripts/create-node.sh'], 'web_link': 'https://opendev.org/openstack/ironic/commit/fe624de64b5b9b19b7e1b74af885e52f1c281adc', 'message': 'Refactor ironic enroll-node code\n\nThis change allows to import ironic nodes from INI files.\n\nChange-Id: I7938f26015d953efdf720774b5ad2cee4068ac90\n'}]",26,256364,fe624de64b5b9b19b7e1b74af885e52f1c281adc,214,22,66,14525,,,0,"Refactor ironic enroll-node code

This change allows to import ironic nodes from INI files.

Change-Id: I7938f26015d953efdf720774b5ad2cee4068ac90
",git fetch https://review.opendev.org/openstack/ironic refs/changes/64/256364/66 && git format-patch -1 --stdout FETCH_HEAD,"['devstack/lib/ironic', 'devstack/tools/ironic/templates/vm.xml', 'devstack/tools/ironic/scripts/create-node']",3,bbf00992d2cd23989c9f9a9443f2dc2b62f6c79a,bug/1526403,"ARCH=$5NODES_FILE=$9 # Send node info to NODES_FILE mac_address=$(virsh dumpxml $NAME | grep ""mac address"" | head -1 | cut -d\' -f2) echo ""[$NAME]"" >> $NODES_FILE echo ""mac_address=$mac_address"" >> $NODES_FILE echo """""," case $5 in i386) ARCH='i686' ;; amd64) ARCH='x86_64' ;; *) echo ""Unsupported arch $4!"" ; exit 1 ;; esac # echo mac virsh dumpxml $NAME | grep ""mac address"" | head -1 | cut -d\' -f2",125,72
openstack%2Fpython-ironicclient~master~Ibfba276c3f4c0c090c48897716aaf4fb193370b0,openstack/python-ironicclient,master,Ibfba276c3f4c0c090c48897716aaf4fb193370b0,Add baremetal port list command to OSC plugin,MERGED,2016-07-25 11:55:44.000000000,2016-08-29 16:05:42.000000000,2016-08-29 16:05:41.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 2889}, {'_account_id': 6618}, {'_account_id': 6773}, {'_account_id': 7080}, {'_account_id': 7711}, {'_account_id': 9542}, {'_account_id': 10239}, {'_account_id': 10342}, {'_account_id': 13636}, {'_account_id': 14614}, {'_account_id': 19267}, {'_account_id': 22724}]","[{'number': 1, 'created': '2016-07-25 11:55:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/a1e6f96aa9fbb7b795f9fce6326be26b44118197', 'message': 'Add baremetal port list command to OSC plugin\n\nChange-Id: Ibfba276c3f4c0c090c48897716aaf4fb193370b0\n'}, {'number': 2, 'created': '2016-07-25 13:43:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/2885ccab3a0da0251ea169e96a6bae2e44887100', 'message': 'Add baremetal port list command to OSC plugin\n\nPartial-Bug: #1526479\nChange-Id: Ibfba276c3f4c0c090c48897716aaf4fb193370b0\n'}, {'number': 3, 'created': '2016-07-25 16:55:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/c2e8b34656c0711cbbb9420633cc62c659e02ea2', 'message': 'Add baremetal port list command to OSC plugin\n\nPartial-Bug: #1526479\nChange-Id: Ibfba276c3f4c0c090c48897716aaf4fb193370b0\n'}, {'number': 4, 'created': '2016-07-25 17:11:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/b58a7781da7f0ac29a22f3a04d7185633e2c8d5a', 'message': 'Add baremetal port list command to OSC plugin\n\nPartial-Bug: #1526479\nChange-Id: Ibfba276c3f4c0c090c48897716aaf4fb193370b0\n'}, {'number': 5, 'created': '2016-08-01 15:14:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/467e684e4fcb045c31af84f2feb52cff0b98e224', 'message': 'Add baremetal port list command to OSC plugin\n\nPartial-Bug: #1526479\nChange-Id: Ibfba276c3f4c0c090c48897716aaf4fb193370b0\n'}, {'number': 6, 'created': '2016-08-02 21:03:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/4e25bcf3745ae9d402eb9798ce7967a057ef3dfc', 'message': 'Add baremetal port list command to OSC plugin\n\nPartial-Bug: #1526479\nChange-Id: Ibfba276c3f4c0c090c48897716aaf4fb193370b0\n'}, {'number': 7, 'created': '2016-08-03 10:36:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/2e8794b36612fc8c028fff1575ca7409d3368f7e', 'message': 'Add baremetal port list command to OSC plugin\n\nPartial-Bug: #1526479\nChange-Id: Ibfba276c3f4c0c090c48897716aaf4fb193370b0\n'}, {'number': 8, 'created': '2016-08-23 09:20:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/cff18a1f24e17ce4441b00fc56e35edc43db5327', 'message': 'Add baremetal port list command to OSC plugin\n\nPartial-Bug: #1526479\nChange-Id: Ibfba276c3f4c0c090c48897716aaf4fb193370b0'}, {'number': 9, 'created': '2016-08-26 08:04:07.000000000', 'files': ['ironicclient/tests/unit/osc/v1/fakes.py', 'releasenotes/notes/osc-plugin-7769f5bef627654c.yaml', 'ironicclient/osc/v1/baremetal_port.py', 'ironicclient/tests/unit/osc/v1/test_baremetal_port.py', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/1add122169c1b1beef61813e588c88ada7b7ca90', 'message': 'Add baremetal port list command to OSC plugin\n\nPartial-Bug: #1526479\nChange-Id: Ibfba276c3f4c0c090c48897716aaf4fb193370b0'}]",24,346722,1add122169c1b1beef61813e588c88ada7b7ca90,46,14,9,14614,,,0,"Add baremetal port list command to OSC plugin

Partial-Bug: #1526479
Change-Id: Ibfba276c3f4c0c090c48897716aaf4fb193370b0",git fetch https://review.opendev.org/openstack/python-ironicclient refs/changes/22/346722/9 && git format-patch -1 --stdout FETCH_HEAD,[],0,a1e6f96aa9fbb7b795f9fce6326be26b44118197,bug/1526479-list-port,,,0,0
openstack%2Fmagnum~master~I2ab9078489f30dbc383c068bb9abc0f3b9ee0e62,openstack/magnum,master,I2ab9078489f30dbc383c068bb9abc0f3b9ee0e62,Compare test coverage with the master branch,MERGED,2016-08-11 09:48:51.000000000,2016-08-29 16:02:31.000000000,2016-08-29 16:02:31.000000000,"[{'_account_id': 3}, {'_account_id': 668}, {'_account_id': 9591}, {'_account_id': 11536}, {'_account_id': 12175}, {'_account_id': 20498}]","[{'number': 1, 'created': '2016-08-11 09:48:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/f56c741e49af8dd03c605b6fdd0c8e59df943bed', 'message': 'Compare test coverage with the master branch\n\n* checkout one commit before the latest and check coverage\n* check coverage with the latest commit\n* allow 4 lines of missing tests\n\nThis functionallity essentially compares the current change\nwith the master branch, since the coverage job runs always\nfor only one change.\n\nPartial-Bug: #1511667\nChange-Id: I2ab9078489f30dbc383c068bb9abc0f3b9ee0e62\n'}, {'number': 2, 'created': '2016-08-11 16:04:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/8ecb1e1074ff59a6d0097c326b2d5700d8c2a92a', 'message': 'Compare test coverage with the master branch\n\n* checkout one commit before the latest and check coverage\n* check coverage with the latest commit\n* allow 4 lines of missing tests\n\nThis functionallity essentially compares the current change\nwith the master branch, since the coverage job runs always\nfor only one change.\n\nPartial-Bug: #1511667\nChange-Id: I2ab9078489f30dbc383c068bb9abc0f3b9ee0e62\n'}, {'number': 3, 'created': '2016-08-12 08:16:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/6f42fd57755b282f05319bfc93e44b0a2b877cca', 'message': 'Compare test coverage with the master branch\n\n* checkout one commit before the latest and check coverage\n* check coverage with the latest commit\n* all new lines must be tested\n\nThis functionallity essentially compares the current change\nwith the master branch, since the coverage job runs always\nfor only one change.\n\nPartial-Bug: #1511667\nChange-Id: I2ab9078489f30dbc383c068bb9abc0f3b9ee0e62\n'}, {'number': 4, 'created': '2016-08-29 12:30:06.000000000', 'files': ['.gitignore', 'cover.sh', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/magnum/commit/4d545d6751e92c876ebaec53cc8728fc3c87dfd8', 'message': 'Compare test coverage with the master branch\n\n* checkout one commit before the latest and check coverage\n* check coverage with the latest commit\n* all new lines must be tested\n\nThis functionallity essentially compares the current change\nwith the master branch, since the coverage job runs always\nfor only one change.\n\nPartial-Bug: #1511667\nChange-Id: I2ab9078489f30dbc383c068bb9abc0f3b9ee0e62\n'}]",13,353939,4d545d6751e92c876ebaec53cc8728fc3c87dfd8,26,6,4,20498,,,0,"Compare test coverage with the master branch

* checkout one commit before the latest and check coverage
* check coverage with the latest commit
* all new lines must be tested

This functionallity essentially compares the current change
with the master branch, since the coverage job runs always
for only one change.

Partial-Bug: #1511667
Change-Id: I2ab9078489f30dbc383c068bb9abc0f3b9ee0e62
",git fetch https://review.opendev.org/openstack/magnum refs/changes/39/353939/1 && git format-patch -1 --stdout FETCH_HEAD,"['.gitignore', 'cover.sh', 'tox.ini']",3,f56c741e49af8dd03c605b6fdd0c8e59df943bed,bug/1511667,commands = {toxinidir}/cover.sh {posargs},# NOTE(NiallBunting) Infra does not support constraints for the cover # job. While the file is set no file is there. Can be removed once infra # changes this.commands = python setup.py testr --coverage --testr-args='{posargs}' coverage report,73,5
openstack%2Fpuppet-openstack-integration~master~I332b8412cce2079652b4c2a47157a382f86b90e0,openstack/puppet-openstack-integration,master,I332b8412cce2079652b4c2a47157a382f86b90e0,switch heat to new authtoken class,MERGED,2016-08-26 18:17:24.000000000,2016-08-29 16:00:27.000000000,2016-08-29 16:00:27.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 7745}, {'_account_id': 14985}]","[{'number': 1, 'created': '2016-08-26 18:17:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstack-integration/commit/817c745d29887f113b4dac5aa614664dfed99301', 'message': 'switch heat to new authtoken class\n\nSwift heat configuration to use the new authtoken manifest.\n\nChange-Id: I332b8412cce2079652b4c2a47157a382f86b90e0\n'}, {'number': 2, 'created': '2016-08-26 19:46:18.000000000', 'files': ['manifests/heat.pp'], 'web_link': 'https://opendev.org/openstack/puppet-openstack-integration/commit/68d56c4ef0103753a26d5f44686bcc0a16f8dc8d', 'message': 'switch heat to new authtoken class\n\nSwift heat configuration to use the new authtoken manifest.\n\nChange-Id: I332b8412cce2079652b4c2a47157a382f86b90e0\n'}]",0,361405,68d56c4ef0103753a26d5f44686bcc0a16f8dc8d,15,4,2,3153,,,0,"switch heat to new authtoken class

Swift heat configuration to use the new authtoken manifest.

Change-Id: I332b8412cce2079652b4c2a47157a382f86b90e0
",git fetch https://review.opendev.org/openstack/puppet-openstack-integration refs/changes/05/361405/1 && git format-patch -1 --stdout FETCH_HEAD,['manifests/heat.pp'],1,817c745d29887f113b4dac5aa614664dfed99301,heat/authtoken," class { '::heat::keystone::auth': password => 'a_big_secret', configure_delegated_roles => true, public_url => ""${::openstack_integration::config::base_url}:8004/v1/%(tenant_id)s"", internal_url => ""${::openstack_integration::config::base_url}:8004/v1/%(tenant_id)s"", admin_url => ""${::openstack_integration::config::base_url}:8004/v1/%(tenant_id)s"", } class { '::heat::keystone::authtoken': password => 'a_big_secret', user_domain_name => 'Default', project_domain_name => 'Default', auth_url => $::openstack_integration::config::keystone_admin_uri, auth_uri => $::openstack_integration::config::keystone_auth_uri, memcached_servers => $::openstack_integration::config::memcached_servers,"," identity_uri => $::openstack_integration::config::keystone_auth_uri, memcached_servers => $::openstack_integration::config::memcached_servers, auth_plugin => 'password', keystone_password => 'a_big_secret', class { '::heat::keystone::auth': password => 'a_big_secret', configure_delegated_roles => true, public_url => ""${::openstack_integration::config::base_url}:8004/v1/%(tenant_id)s"", internal_url => ""${::openstack_integration::config::base_url}:8004/v1/%(tenant_id)s"", admin_url => ""${::openstack_integration::config::base_url}:8004/v1/%(tenant_id)s"",",14,10
openstack%2Ftripleo-heat-templates~master~Icfb650a1dff704cdcce7349dfb612298d38f2706,openstack/tripleo-heat-templates,master,Icfb650a1dff704cdcce7349dfb612298d38f2706,Add flag to assert that puppet manages the keystone endpoints,MERGED,2016-08-10 08:27:06.000000000,2016-08-29 16:00:20.000000000,2016-08-29 16:00:20.000000000,"[{'_account_id': 3}, {'_account_id': 2218}, {'_account_id': 3153}, {'_account_id': 6796}, {'_account_id': 7160}, {'_account_id': 10873}]","[{'number': 1, 'created': '2016-08-10 08:27:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/e4c24ed8605cfd59e4ce2cc00740509722c4dee1', 'message': 'Add flag to assert that puppet manages the keystone endpoints\n\nThis will be read by the client and it will furtherly skip the post-config.\n\nDepends-On: I289cda1268688119594e609014fd2398087caab5\nChange-Id: Icfb650a1dff704cdcce7349dfb612298d38f2706\n'}, {'number': 2, 'created': '2016-08-10 09:26:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/21c75bb740edb54d94d5a9f9bd8fdbdc00cec46c', 'message': 'Add flag to assert that puppet manages the keystone endpoints\n\nThis will be read by the client and it will furtherly skip the post-config.\n\nDepends-On: I289cda1268688119594e609014fd2398087caab5\nDepends-On: Ibbbe1e016e7e47ea5577de33c5a11d4088811616\nChange-Id: Icfb650a1dff704cdcce7349dfb612298d38f2706\n'}, {'number': 3, 'created': '2016-08-29 08:45:10.000000000', 'files': ['overcloud.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/f34c6a601317b7783885eed6ce16927d7e9337d8', 'message': 'Add flag to assert that puppet manages the keystone endpoints\n\nThis will be read by the client and it will furtherly skip the post-config.\n\nDepends-On: I36e1c478e7c92be61da6a0d710e9025d4d354072\nDepends-On: Ibbbe1e016e7e47ea5577de33c5a11d4088811616\nChange-Id: Icfb650a1dff704cdcce7349dfb612298d38f2706\n'}]",0,353307,f34c6a601317b7783885eed6ce16927d7e9337d8,58,6,3,10873,,,0,"Add flag to assert that puppet manages the keystone endpoints

This will be read by the client and it will furtherly skip the post-config.

Depends-On: I36e1c478e7c92be61da6a0d710e9025d4d354072
Depends-On: Ibbbe1e016e7e47ea5577de33c5a11d4088811616
Change-Id: Icfb650a1dff704cdcce7349dfb612298d38f2706
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/07/353307/1 && git format-patch -1 --stdout FETCH_HEAD,['overcloud.yaml'],1,e4c24ed8605cfd59e4ce2cc00740509722c4dee1,keystone_endpoints, ManagedEndpoints: description: Asserts that the keystone endpoints have been provisioned. value: true,,3,0
openstack%2Fpuppet-neutron~master~Iaa24d52f4f42e0535ad2d0aed1c0a67178af091a,openstack/puppet-neutron,master,Iaa24d52f4f42e0535ad2d0aed1c0a67178af091a,Fix the neutron-port resource with binding options,MERGED,2016-08-24 15:33:33.000000000,2016-08-29 16:00:14.000000000,2016-08-29 16:00:14.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 7604}, {'_account_id': 7732}, {'_account_id': 7745}, {'_account_id': 8971}, {'_account_id': 14985}, {'_account_id': 22041}, {'_account_id': 22064}]","[{'number': 1, 'created': '2016-08-24 15:33:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/9916e4c893716885cd312cc13c3ab2f227a714a2', 'message': 'Fix the neutron-port resource with binding options\n\nParameters of type dict must be at the end of the\nshell command to not cause conflict with the network name\n\nChange-Id: Iaa24d52f4f42e0535ad2d0aed1c0a67178af091a\n'}, {'number': 2, 'created': '2016-08-24 18:42:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/9449d3dd79630812dccc3c3dcd0d85b75c1e09f5', 'message': 'Fix the neutron-port resource with binding options\n\nParameters of type dict must be at the end of the\nshell command to not cause conflict with the network name\n\nChange-Id: Iaa24d52f4f42e0535ad2d0aed1c0a67178af091a\n'}, {'number': 3, 'created': '2016-08-25 15:27:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/55d9d224c42f3446faa7da01560ab7e20b6a4860', 'message': 'Fix the neutron-port resource with binding options\n\nParameters of type dict must be at the end of the\nshell command to not cause conflict with the network name\n\ncurrent shell generated\n\n/usr/bin/neutron port-create --format=shell --name=testport \\\n--fixed-ip ip_address=172.19.0.2 --binding:host_id=aio \\\n--binding:profile type=dict interface_name=veth1 net-edge1-gw1\n\nthis fails since it matches the first word without ""="" to the network\nname\n\ncorrect call\n\n/usr/bin/neutron port-create --format=shell --name=testport \\\n--fixed-ip ip_address=172.19.0.2 --binding:host_id=aio net-edge1-gw1 \\\n--binding:profile type=dict interface_name=veth1\n\nChange-Id: Iaa24d52f4f42e0535ad2d0aed1c0a67178af091a\n'}, {'number': 4, 'created': '2016-08-25 15:33:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/74be333692602e7cc13661dd3deeefda1d143c39', 'message': 'Fix the neutron-port resource with binding options\n\nParameters of type dict must be at the end of the\nshell command to not cause conflict with the network name\n\ncurrent shell generated\n\n/usr/bin/neutron port-create --format=shell --name=testport \\\n--fixed-ip ip_address=172.19.0.2 --binding:host_id=aio \\\n--binding:profile type=dict interface_name=veth1 net-edge1-gw1\n\nthis fails since it matches the first word without ""--"" to the network\nname\n\ncorrect call\n\n/usr/bin/neutron port-create --format=shell --name=testport \\\n--fixed-ip ip_address=172.19.0.2 --binding:host_id=aio net-edge1-gw1 \\\n--binding:profile type=dict interface_name=veth1\n\nChange-Id: Iaa24d52f4f42e0535ad2d0aed1c0a67178af091a\n'}, {'number': 5, 'created': '2016-08-25 21:27:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/fe118ebf5885bc042acb836de9e404e168927de1', 'message': 'Fix the neutron-port resource with binding options\n\nParameters of type dict must be at the end of the\nshell command to not cause conflict with the network name\n\ncurrent shell generated\n\n/usr/bin/neutron port-create --format=shell --name=testport \\\n--fixed-ip ip_address=172.19.0.2 --binding:host_id=aio \\\n--binding:profile type=dict interface_name=veth1 net-edge1-gw1\n\nthis fails since it matches the first word without ""--"" to the network\nname\n\ncorrect call\n\n/usr/bin/neutron port-create --format=shell --name=testport \\\n--fixed-ip ip_address=172.19.0.2 --binding:host_id=aio net-edge1-gw1 \\\n--binding:profile type=dict interface_name=veth1\n\nChange-Id: Iaa24d52f4f42e0535ad2d0aed1c0a67178af091a\n'}, {'number': 6, 'created': '2016-08-25 21:33:07.000000000', 'files': ['releasenotes/notes/fix-neutron-port-creation-50818b9dc7a9cc05.yaml', 'spec/unit/provider/neutron_port/neutron_spec.rb', 'lib/puppet/provider/neutron_port/neutron.rb'], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/24a60a49d9628616967c81205988e9ded3a7a736', 'message': 'Fix the neutron-port resource with binding options\n\nParameters of type dict must be at the end of the\nshell command to not cause conflict with the network name\n\ncurrent shell generated\n\n/usr/bin/neutron port-create --format=shell --name=testport \\\n--fixed-ip ip_address=172.19.0.2 --binding:host_id=aio \\\n--binding:profile type=dict interface_name=veth1 net-edge1-gw1\n\nthis fails since it matches the first word without ""--"" to the network\nname\n\ncorrect call\n\n/usr/bin/neutron port-create --format=shell --name=testport \\\n--fixed-ip ip_address=172.19.0.2 --binding:host_id=aio net-edge1-gw1 \\\n--binding:profile type=dict interface_name=veth1\n\nChange-Id: Iaa24d52f4f42e0535ad2d0aed1c0a67178af091a\n'}]",3,359967,24a60a49d9628616967c81205988e9ded3a7a736,49,9,6,22041,,,0,"Fix the neutron-port resource with binding options

Parameters of type dict must be at the end of the
shell command to not cause conflict with the network name

current shell generated

/usr/bin/neutron port-create --format=shell --name=testport \
--fixed-ip ip_address=172.19.0.2 --binding:host_id=aio \
--binding:profile type=dict interface_name=veth1 net-edge1-gw1

this fails since it matches the first word without ""--"" to the network
name

correct call

/usr/bin/neutron port-create --format=shell --name=testport \
--fixed-ip ip_address=172.19.0.2 --binding:host_id=aio net-edge1-gw1 \
--binding:profile type=dict interface_name=veth1

Change-Id: Iaa24d52f4f42e0535ad2d0aed1c0a67178af091a
",git fetch https://review.opendev.org/openstack/puppet-neutron refs/changes/67/359967/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/fix-neutron-port-creation-50818b9dc7a9cc05.yaml', 'spec/unit/provider/neutron_port/neutron_spec.rb', 'lib/puppet/provider/neutron_port/neutron.rb']",3,9916e4c893716885cd312cc13c3ab2f227a714a2,," dict_opts = Array.new opts << resource[:ip_address].map{|ip|""ip_address=#{ip}""}.join(',') opts << resource[:subnet_name].map{|s|""subnet_id=#{s}""}.join(',') dict_opts << ""--binding:profile"" dict_opts << ""type=dict"" dict_opts << ""#{binding_profile_opts}"" resource[:network_name], dict_opts"," opts << @resource[:ip_address].map{|ip|""ip_address=#{ip}""}.join(',') opts << @resource[:subnet_name].map{|s|""subnet_id=#{s}""}.join(',') opts << ""--binding:profile type=dict #{binding_profile_opts}"" resource[:network_name]",17,7
openstack%2Fneutron~master~I7291c15ec798e672c18e7a31249f111d39ec1e2c,openstack/neutron,master,I7291c15ec798e672c18e7a31249f111d39ec1e2c,Nofications: only bind callbacks if enabled,ABANDONED,2016-08-28 11:45:04.000000000,2016-08-29 15:58:56.000000000,,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 1131}, {'_account_id': 5170}, {'_account_id': 9732}, {'_account_id': 10385}, {'_account_id': 13933}, {'_account_id': 14208}, {'_account_id': 14605}, {'_account_id': 15752}, {'_account_id': 16376}]","[{'number': 1, 'created': '2016-08-28 11:45:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/6ed16af338fe4d2e2b71230f0dd4526694e7b111', 'message': 'Nofications: only bind callbacks if enabled\n\nCommit 877778ee4c7f0e83b54f54b2d7bafec98f89626c added the\nbindings of the callbacks. The callbacks do not need to be\nbound if the variable is not set.\n\nThis will save needless function calls.\n\nTrivialFix\n\nChange-Id: I7291c15ec798e672c18e7a31249f111d39ec1e2c\n'}, {'number': 2, 'created': '2016-08-28 13:27:12.000000000', 'files': ['neutron/api/rpc/agentnotifiers/dhcp_rpc_agent_api.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/cd878c8d50a979a285550b5cb0052c45db5ec998', 'message': 'Nofications: only bind callbacks if enabled\n\nCommit 877778ee4c7f0e83b54f54b2d7bafec98f89626c added the\nbindings of the callbacks. The callbacks do not need to be\nbound if the variable is not set.\n\nThis will save needless function calls.\n\nTrivialFix\n\nChange-Id: I7291c15ec798e672c18e7a31249f111d39ec1e2c\n'}]",2,361716,cd878c8d50a979a285550b5cb0052c45db5ec998,22,11,2,1653,,,0,"Nofications: only bind callbacks if enabled

Commit 877778ee4c7f0e83b54f54b2d7bafec98f89626c added the
bindings of the callbacks. The callbacks do not need to be
bound if the variable is not set.

This will save needless function calls.

TrivialFix

Change-Id: I7291c15ec798e672c18e7a31249f111d39ec1e2c
",git fetch https://review.opendev.org/openstack/neutron refs/changes/16/361716/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/api/rpc/agentnotifiers/dhcp_rpc_agent_api.py'],1,6ed16af338fe4d2e2b71230f0dd4526694e7b111,config-driven," if cfg.CONF.dhcp_agent_notification: # register callbacks for events pertaining resources affecting DHCP callback_resources = ( resources.NETWORK, resources.NETWORKS, resources.PORT, resources.PORTS, resources.SUBNET, resources.SUBNETS, ) for resource in callback_resources: registry.subscribe(self._send_dhcp_notification, resource, events.BEFORE_RESPONSE) if collection and collection in data: for body in data[collection]: item = {resource: body} self.notify(context, item, method_name) else: self.notify(context, data, method_name)"," # register callbacks for events pertaining resources affecting DHCP callback_resources = ( resources.NETWORK, resources.NETWORKS, resources.PORT, resources.PORTS, resources.SUBNET, resources.SUBNETS, ) for resource in callback_resources: registry.subscribe(self._send_dhcp_notification, resource, events.BEFORE_RESPONSE) if cfg.CONF.dhcp_agent_notification: if collection and collection in data: for body in data[collection]: item = {resource: body} self.notify(context, item, method_name) else: self.notify(context, data, method_name)",21,19
openstack%2Fmanila-image-elements~master~I9fcd47a0bf9302506949fa56efb42b77552710f6,openstack/manila-image-elements,master,I9fcd47a0bf9302506949fa56efb42b77552710f6,Fix package manager call for RHEL-based distros,MERGED,2016-08-12 21:19:01.000000000,2016-08-29 15:58:35.000000000,2016-08-29 15:58:35.000000000,"[{'_account_id': 3}, {'_account_id': 6491}, {'_account_id': 9003}]","[{'number': 1, 'created': '2016-08-12 21:19:01.000000000', 'files': ['bin/manila-image-create'], 'web_link': 'https://opendev.org/openstack/manila-image-elements/commit/e2e7ef98d81867565091df8481d61a9c76d83a72', 'message': 'Fix package manager call for RHEL-based distros\n\nAssuming users will be working with latests versions\nfor RHEL, Centos or Fedora, the requirement for EPEL\nrepo is not longer needed. This requirement was due\nto argparse not being present in standard repos, something\nthat does not hold anymore.\nFor this reason, this patch set removes the installation\nof the EPEL repo.\nOn the other hand, this patch set also makes an extra check\nto use dnf when this script is run on Fedora. Since Fedora 22\ndnf has been the default package manager instead of yum.\n\nChange-Id: I9fcd47a0bf9302506949fa56efb42b77552710f6\nCloses-Bug: #1611527\n'}]",0,355088,e2e7ef98d81867565091df8481d61a9c76d83a72,7,3,1,6413,,,0,"Fix package manager call for RHEL-based distros

Assuming users will be working with latests versions
for RHEL, Centos or Fedora, the requirement for EPEL
repo is not longer needed. This requirement was due
to argparse not being present in standard repos, something
that does not hold anymore.
For this reason, this patch set removes the installation
of the EPEL repo.
On the other hand, this patch set also makes an extra check
to use dnf when this script is run on Fedora. Since Fedora 22
dnf has been the default package manager instead of yum.

Change-Id: I9fcd47a0bf9302506949fa56efb42b77552710f6
Closes-Bug: #1611527
",git fetch https://review.opendev.org/openstack/manila-image-elements refs/changes/88/355088/1 && git format-patch -1 --stdout FETCH_HEAD,['bin/manila-image-create'],1,e2e7ef98d81867565091df8481d61a9c76d83a72,bug/1611527," if [ ${platform} = ""fedora"" ]; then sudo dnf install $package_list -y else sudo yum install $package_list -y"," if [ ${platform} = ""centos"" ]; then # install EPEL repo, in order to install argparse sudo rpm -Uvh --force http://dl.fedoraproject.org/pub/epel/6/x86_64/epel-release-6-8.noarch.rpm sudo yum install $package_list -y",4,4
openstack%2Fdevstack~master~I037429da72d5269288b57fcd5efa2a298811050b,openstack/devstack,master,I037429da72d5269288b57fcd5efa2a298811050b,Fix sha1 download for elasticsearch>2.0,ABANDONED,2016-05-23 21:24:40.000000000,2016-08-29 15:54:25.000000000,,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 7118}, {'_account_id': 7665}, {'_account_id': 10063}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2016-05-23 21:24:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/99206265727495312cd3458e01774dfc8fcb2a6c', 'message': 'Fix sha1 download for elasticsearch>2.0\n\nStarting with elasticsearch 2.0.0, sha1 files dropped their .txt suffix\nand stopped including the filename such that they no longer match the\nformat output by sha1sum. Patch attempts to download ${file}.sha1 if the\n${file}.sha1.txt download fails, and in that case adds the download\nfilename.\n\nChange-Id: I037429da72d5269288b57fcd5efa2a298811050b\n'}, {'number': 2, 'created': '2016-05-24 17:09:32.000000000', 'files': ['pkg/elasticsearch.sh'], 'web_link': 'https://opendev.org/openstack/devstack/commit/76af1ab6fb600a3051f4f18b775b7886763a045d', 'message': 'Fix sha1 download for elasticsearch>2.0\n\nStarting with elasticsearch 2.0.0, sha1 files dropped their .txt suffix\nand stopped including the filename such that they no longer match the\nformat output by sha1sum. Patch attempts to download ${file}.sha1 if the\n${file}.sha1.txt download fails, and in that case adds the download\nfilename.\n\nChange-Id: I037429da72d5269288b57fcd5efa2a298811050b\n'}]",1,320152,76af1ab6fb600a3051f4f18b775b7886763a045d,17,7,2,10063,,,0,"Fix sha1 download for elasticsearch>2.0

Starting with elasticsearch 2.0.0, sha1 files dropped their .txt suffix
and stopped including the filename such that they no longer match the
format output by sha1sum. Patch attempts to download ${file}.sha1 if the
${file}.sha1.txt download fails, and in that case adds the download
filename.

Change-Id: I037429da72d5269288b57fcd5efa2a298811050b
",git fetch https://review.opendev.org/openstack/devstack refs/changes/52/320152/2 && git format-patch -1 --stdout FETCH_HEAD,['pkg/elasticsearch.sh'],1,99206265727495312cd3458e01774dfc8fcb2a6c,elasticsearch-sha1," # Since the 2.0.0 release the sha1 files dropped the .txt filename and ceased # to contain the filename, so they don't match sha1sum's expected input wget $ELASTICSEARCH_BASEURL/${file}.sha1.txt -O ${FILES}/${file}.sha1.txt || \ ( wget $ELASTICSEARCH_BASEURL/${file}.sha1 -O ${FILES}/${file}.sha1.txt && echo "" ${file}"" >> ${FILES}/${file}.sha1.txt )", wget $ELASTICSEARCH_BASEURL/${file}.sha1.txt -O ${FILES}/${file}.sha1.txt,5,1
openstack%2Fmurano-apps~master~Id8dda504bc7a01175cb2769325a9279473002a93,openstack/murano-apps,master,Id8dda504bc7a01175cb2769325a9279473002a93,Simple heat SW example,ABANDONED,2014-08-29 23:59:21.000000000,2016-08-29 15:53:56.000000000,,"[{'_account_id': 3}, {'_account_id': 7225}, {'_account_id': 7226}, {'_account_id': 7549}, {'_account_id': 8127}, {'_account_id': 8443}, {'_account_id': 15168}]","[{'number': 1, 'created': '2014-08-29 23:59:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-apps/commit/77fdb98148f271f30fa480cb40c7e325a5a0ebfc', 'message': 'Simple heat SW example\n\nSimple example of heat SW config using the script provider (an inline\nshell script).\n\nChange-Id: Id8dda504bc7a01175cb2769325a9279473002a93\n'}, {'number': 2, 'created': '2015-06-19 12:01:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-apps/commit/898120c26cd28d722b0c70e73f7dcc556e85c830', 'message': 'Simple heat SW example\n\nSimple example of heat SW config using the script provider (an inline\nshell script).\n\nChange-Id: Id8dda504bc7a01175cb2769325a9279473002a93\n'}, {'number': 3, 'created': '2015-07-08 11:18:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-apps/commit/9d06ccd6d366990cc909f428f388161cf6c1a19c', 'message': 'Simple heat SW example\n\nSimple example of heat SW config using the script provider (an inline\nshell script).\n\nChange-Id: Id8dda504bc7a01175cb2769325a9279473002a93\n'}, {'number': 4, 'created': '2015-07-23 22:58:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-apps/commit/9e5ae95afff7fafb7a6f02a498a526d5da748f14', 'message': 'Simple heat SW example\n\nSimple example of heat SW config using the script provider (an inline\nshell script).\n\nChange-Id: Id8dda504bc7a01175cb2769325a9279473002a93\n'}, {'number': 5, 'created': '2015-07-23 22:59:47.000000000', 'files': ['HeatSoftwareConfig/Readme.rst', 'HeatSoftwareConfig/package/logo.png', 'HeatSoftwareConfig/package/manifest.yaml', 'HeatSoftwareConfig/package/LICENSE', 'HeatSoftwareConfig/package/Classes/Apache.yaml', 'HeatSoftwareConfig/package/UI/Apache.yaml'], 'web_link': 'https://opendev.org/openstack/murano-apps/commit/5054895d51f380e3cd1509e795c750baf1e5ffd2', 'message': 'Simple heat SW example\n\nSimple example of heat SW config using the script provider (an inline\nshell script).\n\nChange-Id: Id8dda504bc7a01175cb2769325a9279473002a93\n'}]",6,117914,5054895d51f380e3cd1509e795c750baf1e5ffd2,24,7,5,10063,,,0,"Simple heat SW example

Simple example of heat SW config using the script provider (an inline
shell script).

Change-Id: Id8dda504bc7a01175cb2769325a9279473002a93
",git fetch https://review.opendev.org/openstack/murano-apps refs/changes/14/117914/1 && git format-patch -1 --stdout FETCH_HEAD,"['io.murano.heat_sw_example/Classes/Apache.yaml', 'io.murano.heat_sw_example/logo.png', 'io.murano.heat_sw_example/UI/Apache.yaml', 'io.murano.heat_sw_example/manifest.yaml']",4,77fdb98148f271f30fa480cb40c7e325a5a0ebfc,add-hot-sw-example,Format: 1.0 Type: Application FullName: io.murano.heat_sw_config Name: Heat SW config example Description: | Heat SW config example. Installs apache from apt-get. Author: 'Steve McLellan' Tags: [Linux] UI: Apache.yaml Classes: io.murano.heat_sw_config.Apache: Apache.yaml ,,135,0
openstack%2Fmagnum~master~I2d89605ee16bdf8b0981ebf8c937fada0bc88cae,openstack/magnum,master,I2d89605ee16bdf8b0981ebf8c937fada0bc88cae,Set default host when conf is blank on Magnum builds,ABANDONED,2016-07-25 16:17:42.000000000,2016-08-29 15:47:37.000000000,,"[{'_account_id': 3}, {'_account_id': 668}, {'_account_id': 9095}, {'_account_id': 11536}, {'_account_id': 11650}, {'_account_id': 19741}, {'_account_id': 20498}, {'_account_id': 21660}]","[{'number': 1, 'created': '2016-07-25 16:17:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/0b38fd5e46c0a6adc73798a0fc69c687c9640131', 'message': ""Set default host to 'localhost' on Magnum builds\n\nChange-Id: I2d89605ee16bdf8b0981ebf8c937fada0bc88cae\nCloses-Bug: 1561226\n""}, {'number': 2, 'created': '2016-07-25 16:27:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/30d55becd9fcc675f8c7c3dfd98e6d2fe8413538', 'message': ""Set default host to 'localhost' on Magnum builds\n\nRemoving build host name injection into the magnum.conf file.\nThis gets us reproducible builds.\n\nChange-Id: I2d89605ee16bdf8b0981ebf8c937fada0bc88cae\nCloses-Bug: 1561226\n""}, {'number': 3, 'created': '2016-08-01 21:59:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/97c2302c03e34e1f38d157095d660c19cf67cef8', 'message': 'Set default host when conf is blank on Magnum builds\n\nRemoving build host name injection into the magnum.conf file.\nThis gets us reproducible builds.\n\nChange-Id: I2d89605ee16bdf8b0981ebf8c937fada0bc88cae\nCloses-Bug: 1561226\n'}, {'number': 4, 'created': '2016-08-02 17:17:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/3760c6a3e85fb891d77a7248ded19f1a1f84c14c', 'message': 'Set default host when conf is blank on Magnum builds\n\nRemoving build host name injection into the magnum.conf file.\nThis gets us reproducible builds.\n\nChange-Id: I2d89605ee16bdf8b0981ebf8c937fada0bc88cae\nCloses-Bug: 1561226\n'}, {'number': 5, 'created': '2016-08-03 01:30:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/03874160c80d73cf89d94394cf0d06de58f64959', 'message': 'Set default host when conf is blank on Magnum builds\n\nRemoving build host name injection into the magnum.conf file.\nThis gets us reproducible builds.\n\nChange-Id: I2d89605ee16bdf8b0981ebf8c937fada0bc88cae\nCloses-Bug: 1561226\n'}, {'number': 6, 'created': '2016-08-03 01:43:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/ea3ee309ba7cfcf5cea653a4af8575fb603565f1', 'message': 'Set default host when conf is blank on Magnum builds\n\nRemoving build host name injection into the magnum.conf file.\nThis gets us reproducible builds.\n\nChange-Id: I2d89605ee16bdf8b0981ebf8c937fada0bc88cae\nCloses-Bug: 1561226\n'}, {'number': 7, 'created': '2016-08-03 02:08:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/7501ce18697b69f20b6349ab82f42a680c19c05c', 'message': 'Set default host when conf is blank on Magnum builds\n\nRemoving build host name injection into the magnum.conf file.\nThis gets us reproducible builds.\n\nChange-Id: I2d89605ee16bdf8b0981ebf8c937fada0bc88cae\nCloses-Bug: 1561226\n'}, {'number': 8, 'created': '2016-08-07 20:05:28.000000000', 'files': ['magnum/api/app.py', 'magnum/common/rpc.py', 'magnum/cmd/api.py', 'magnum/servicegroup/magnum_service_periodic.py', 'magnum/common/service.py'], 'web_link': 'https://opendev.org/openstack/magnum/commit/8caddfe40e229aa2e80aeed31f4723bbb50a2676', 'message': 'Set default host when conf is blank on Magnum builds\n\nRemoving build host name injection into the magnum.conf file.\nThis gets us reproducible builds.\n\nChange-Id: I2d89605ee16bdf8b0981ebf8c937fada0bc88cae\nCloses-Bug: 1561226\n'}]",13,346917,8caddfe40e229aa2e80aeed31f4723bbb50a2676,41,8,8,21660,,,0,"Set default host when conf is blank on Magnum builds

Removing build host name injection into the magnum.conf file.
This gets us reproducible builds.

Change-Id: I2d89605ee16bdf8b0981ebf8c937fada0bc88cae
Closes-Bug: 1561226
",git fetch https://review.opendev.org/openstack/magnum refs/changes/17/346917/2 && git format-patch -1 --stdout FETCH_HEAD,['magnum/common/service.py'],1,0b38fd5e46c0a6adc73798a0fc69c687c9640131,bug/1561226," default='localhost',","import socket default=socket.getfqdn(),",1,3
openstack%2Fironic~master~Ie9356a870ea7b271aa44db57accba02f52b3e948,openstack/ironic,master,Ie9356a870ea7b271aa44db57accba02f52b3e948,Fix pep8 on Python3.5,MERGED,2016-08-29 09:43:23.000000000,2016-08-29 15:47:24.000000000,2016-08-29 14:07:00.000000000,"[{'_account_id': 3}, {'_account_id': 6773}, {'_account_id': 9542}, {'_account_id': 10343}, {'_account_id': 12356}, {'_account_id': 14760}, {'_account_id': 17998}, {'_account_id': 19339}]","[{'number': 1, 'created': '2016-08-29 09:43:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/21def604ed08a0e43670263d9b3558c2dfb39ef9', 'message': 'Fix pep8 on Python3.5\n\nThis patch is fixing the pep8 warning messages when running ""tox -epep8""\nwith the python3.5 interpreter (the default on some distros, e.g Arch\nLinux).\n\nThe method file_open() from common/utils.py was removed because it\nwasn\'t being used anywhere and was violating pep8 by using file() which\nis only present in python2.\n\nChange-Id: Ie9356a870ea7b271aa44db57accba02f52b3e948\nCloses-Bug: #1617947\n'}, {'number': 2, 'created': '2016-08-29 11:07:54.000000000', 'files': ['ironic/common/exception.py', 'ironic/tests/unit/common/test_exception.py', 'ironic/tests/unit/api/v1/test_types.py', 'ironic/common/utils.py', 'devstack/tools/ironic/scripts/configure-vm.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/55410888de5d477274d395fd2a976ad5a54fbb7a', 'message': 'Fix pep8 on Python3.5\n\nThis patch is fixing the pep8 warning messages when running ""tox -epep8""\nwith the python3.5 interpreter (the default on some distros, e.g Arch\nLinux).\n\nThe method file_open() from common/utils.py was removed because it\nwasn\'t being used anywhere and was violating pep8 by using file() which\nis only present in python2.\n\nChange-Id: Ie9356a870ea7b271aa44db57accba02f52b3e948\nCloses-Bug: #1617947\n'}]",2,361971,55410888de5d477274d395fd2a976ad5a54fbb7a,17,8,2,6773,,,0,"Fix pep8 on Python3.5

This patch is fixing the pep8 warning messages when running ""tox -epep8""
with the python3.5 interpreter (the default on some distros, e.g Arch
Linux).

The method file_open() from common/utils.py was removed because it
wasn't being used anywhere and was violating pep8 by using file() which
is only present in python2.

Change-Id: Ie9356a870ea7b271aa44db57accba02f52b3e948
Closes-Bug: #1617947
",git fetch https://review.opendev.org/openstack/ironic refs/changes/71/361971/2 && git format-patch -1 --stdout FETCH_HEAD,"['ironic/common/exception.py', 'ironic/tests/unit/common/test_exception.py', 'ironic/tests/unit/api/v1/test_types.py', 'ironic/common/utils.py', 'devstack/tools/ironic/scripts/configure-vm.py']",5,21def604ed08a0e43670263d9b3558c2dfb39ef9,bug/1617947," with open(templatedir + '/vm.xml', 'rb') as f:"," with file(templatedir + '/vm.xml', 'rb') as f:",5,19
openstack%2Fsolum~master~I4f2650d0c8801dbaccd211353d339565dd2105b3,openstack/solum,master,I4f2650d0c8801dbaccd211353d339565dd2105b3,TrivialFix: Remove logging import unused,MERGED,2016-08-29 03:49:24.000000000,2016-08-29 15:46:00.000000000,2016-08-29 15:41:18.000000000,"[{'_account_id': 3}, {'_account_id': 2506}, {'_account_id': 7230}, {'_account_id': 14107}]","[{'number': 1, 'created': '2016-08-29 03:49:24.000000000', 'files': ['solum/api/handlers/infrastructure_handler.py', 'solum/api/controllers/camp/v1_1/datamodel/plans.py', 'solum/api/controllers/camp/v1_1/plans.py', 'solum/api/handlers/camp/attribute_definition_handler.py'], 'web_link': 'https://opendev.org/openstack/solum/commit/c3e110828cfed1ae122e2c60cefa8b3b8774ad0c', 'message': 'TrivialFix: Remove logging import unused\n\nThis patch removes logging import unused in\nsolum/api/controllers/camp/v1_1/datamodel/plans.py\nsolum/api/controllers/camp/v1_1/plans.py\nsolum/api/handlers/camp/attribute_definition_handler.py\nsolum/api/handlers/infrastructure_handler.py\n\nChange-Id: I4f2650d0c8801dbaccd211353d339565dd2105b3\n'}]",0,361819,c3e110828cfed1ae122e2c60cefa8b3b8774ad0c,8,4,1,15905,,,0,"TrivialFix: Remove logging import unused

This patch removes logging import unused in
solum/api/controllers/camp/v1_1/datamodel/plans.py
solum/api/controllers/camp/v1_1/plans.py
solum/api/handlers/camp/attribute_definition_handler.py
solum/api/handlers/infrastructure_handler.py

Change-Id: I4f2650d0c8801dbaccd211353d339565dd2105b3
",git fetch https://review.opendev.org/openstack/solum refs/changes/19/361819/1 && git format-patch -1 --stdout FETCH_HEAD,"['solum/api/handlers/infrastructure_handler.py', 'solum/api/controllers/camp/v1_1/datamodel/plans.py', 'solum/api/controllers/camp/v1_1/plans.py', 'solum/api/handlers/camp/attribute_definition_handler.py']",4,c3e110828cfed1ae122e2c60cefa8b3b8774ad0c,bug/remove-logging-unused, ,from solum.openstack.common import log as logging LOG = logging.getLogger(__name__) ,0,14
openstack%2Fneutron-dynamic-routing~master~Iafd0ea9fc6a79859313c004845003c7e71c2c216,openstack/neutron-dynamic-routing,master,Iafd0ea9fc6a79859313c004845003c7e71c2c216,"Fixed ""tox -e py27"" warning message",MERGED,2016-05-06 11:07:33.000000000,2016-08-29 15:45:08.000000000,2016-08-29 15:45:08.000000000,"[{'_account_id': 3}, {'_account_id': 4187}, {'_account_id': 7448}, {'_account_id': 7787}, {'_account_id': 13252}, {'_account_id': 14605}, {'_account_id': 17455}]","[{'number': 1, 'created': '2016-05-06 11:07:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-dynamic-routing/commit/d73dc9994ad3a3b347ff8063cfe02692e8a81322', 'message': 'Fixed ""tox -e py27"" warning message\n\ntox shows warning message as follow.\n\n----\npy27 runtests: PYTHONHASHSEED=\'0\'\npy27 runtests: commands[0] | find . -type f -name *.pyc -delete\nWARNING:test command found but not installed in testenv\n  cmd: /usr/bin/find\n  env: /home/vagrant/rally/.tox/py27\nMaybe you forgot to specify a dependency? See also the whitelist_externals envconfig setting.\npy27 runtests: commands[1] | python setup.py testr --slowest --testr-args=\n----\n\nIt seems that ""find"" command needs full path in tox.ini\n\nChange-Id: Iafd0ea9fc6a79859313c004845003c7e71c2c216\n'}, {'number': 2, 'created': '2016-05-06 11:13:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-dynamic-routing/commit/f14018c5eeafe1460c506daac3d2c51eb5960e94', 'message': 'Fixed ""tox -e py27"" warning message\n\ntox shows warning message as follow.\n\n----\npy27 runtests: PYTHONHASHSEED=\'0\'\npy27 runtests: commands[0] | find . -type f -name *.pyc -delete\nWARNING:test command found but not installed in testenv\n  cmd: /usr/bin/find\n  env: /home/vagrant/rally/.tox/py27\nMaybe you forgot to specify a dependency? See also the whitelist_externals envconfig setting.\npy27 runtests: commands[1] | python setup.py testr --slowest --testr-args=\n----\n\nIt seems that ""find"" command needs full path in tox.ini\n\nNote: Similar type of issue was observed for the rally project\n      (https://bugs.launchpad.net/rally/+bug/1464495)\n\nChange-Id: Iafd0ea9fc6a79859313c004845003c7e71c2c216\n'}, {'number': 3, 'created': '2016-05-06 11:15:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-dynamic-routing/commit/c309142ae9a52fcc05254304e173383614027e8e', 'message': 'Fixed ""tox -e py27"" warning message\n\ntox shows warning message as follow.\n\n----\npy27 runtests: PYTHONHASHSEED=\'0\'\npy27 runtests: commands[0] | find . -type f -name *.pyc -delete\nWARNING:test command found but not installed in testenv\n  cmd: /usr/bin/find\n  env: /home/vagrant/rally/.tox/py27\nMaybe you forgot to specify a dependency? See also the whitelist_externals envconfig setting.\npy27 runtests: commands[1] | python setup.py testr --slowest --testr-args=\n----\n\nIt seems that ""find"" command needs full path in tox.ini\n\nNote: Similar type of issue was observed for the rally project\n      (https://bugs.launchpad.net/rally/+bug/1464495)\n\nChange-Id: Iafd0ea9fc6a79859313c004845003c7e71c2c216\nImplements: blueprint bgp-spinout\nPartial-Bug: #1560003\n'}, {'number': 4, 'created': '2016-08-16 08:02:25.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/neutron-dynamic-routing/commit/294b615702b4edd8dd5e03b1d918675e7543833e', 'message': 'Fixed ""tox -e py27"" warning message\n\ntox shows warning message as follow.\n\npy27 runtests: PYTHONHASHSEED=\'3460558810\'\npy27 runtests: commands[0] | find . -type f -name *.py[c|o] -delete\nWARNING:test command found but not installed in testenv\n  cmd: /usr/bin/find\n  env: /home/vikram/myData/work/openstack/neutron-dynamic-routing/.tox/py27\nMaybe you forgot to specify a dependency? See also the whitelist_externals envconfig setting.\npy27 runtests: commands[1] | find . -type d -name __pycache__ -delete\nWARNING:test command found but not installed in testenv\n  cmd: /usr/bin/find\n  env: /home/vikram/myData/work/openstack/neutron-dynamic-routing/.tox/py27\nMaybe you forgot to specify a dependency? See also the whitelist_externals envconfig setting.\npy27 runtests: commands[2] | sh tools/pretty_tox.sh\n\nIt seems that ""find"" command needs full path in tox.ini\n\nPartial-Bug: #1560003\nChange-Id: Iafd0ea9fc6a79859313c004845003c7e71c2c216\n'}]",3,313503,294b615702b4edd8dd5e03b1d918675e7543833e,17,7,4,14605,,,0,"Fixed ""tox -e py27"" warning message

tox shows warning message as follow.

py27 runtests: PYTHONHASHSEED='3460558810'
py27 runtests: commands[0] | find . -type f -name *.py[c|o] -delete
WARNING:test command found but not installed in testenv
  cmd: /usr/bin/find
  env: /home/vikram/myData/work/openstack/neutron-dynamic-routing/.tox/py27
Maybe you forgot to specify a dependency? See also the whitelist_externals envconfig setting.
py27 runtests: commands[1] | find . -type d -name __pycache__ -delete
WARNING:test command found but not installed in testenv
  cmd: /usr/bin/find
  env: /home/vikram/myData/work/openstack/neutron-dynamic-routing/.tox/py27
Maybe you forgot to specify a dependency? See also the whitelist_externals envconfig setting.
py27 runtests: commands[2] | sh tools/pretty_tox.sh

It seems that ""find"" command needs full path in tox.ini

Partial-Bug: #1560003
Change-Id: Iafd0ea9fc6a79859313c004845003c7e71c2c216
",git fetch https://review.opendev.org/openstack/neutron-dynamic-routing refs/changes/03/313503/4 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,d73dc9994ad3a3b347ff8063cfe02692e8a81322,bug/1560003," /usr/bin/find . -type f -name ""*.py[c|o]"" -delete /usr/bin/find . -type d -name ""__pycache__"" -delete"," find . -type f -name ""*.py[c|o]"" -delete find . -type d -name ""__pycache__"" -delete",2,2
openstack%2Fdevstack-gate~master~Ifcf4dad0366a2763bb311f77ab63de1e5b3fafe7,openstack/devstack-gate,master,Ifcf4dad0366a2763bb311f77ab63de1e5b3fafe7,don't start horizon in grenade,MERGED,2016-08-25 13:56:30.000000000,2016-08-29 15:43:06.000000000,2016-08-29 15:43:06.000000000,"[{'_account_id': 2}, {'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 5263}]","[{'number': 1, 'created': '2016-08-25 13:56:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/f8bbadda501ec33327756f9b790059e84a60ed65', 'message': ""don't start horizon in grenade\n\nhorizon is not really tested in grenade, so it's extra effort for no\nreal validation. We should not do this by default as it will shorten\nthe job length.\n\nDepends-On: I2cb3c75bdd738a8e19796456f0aed14237ef755e\n(enables horizon to be conditionally upgraded only if it exists)\n\nChange-Id: Ifcf4dad0366a2763bb311f77ab63de1e5b3fafe7\n""}, {'number': 2, 'created': '2016-08-25 19:46:57.000000000', 'files': ['features.yaml', 'test-features.sh'], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/f7e3f3bfa85f1e5277703ef19ddfb3140358a563', 'message': ""don't start horizon in grenade\n\nhorizon is not really tested in grenade, so it's extra effort for no\nreal validation. We should not do this by default as it will shorten\nthe job length.\n\nDepends-On: I2cb3c75bdd738a8e19796456f0aed14237ef755e\n(enables horizon to be conditionally upgraded only if it exists)\n\nChange-Id: Ifcf4dad0366a2763bb311f77ab63de1e5b3fafe7\n""}]",0,360565,f7e3f3bfa85f1e5277703ef19ddfb3140358a563,12,4,2,2750,,,0,"don't start horizon in grenade

horizon is not really tested in grenade, so it's extra effort for no
real validation. We should not do this by default as it will shorten
the job length.

Depends-On: I2cb3c75bdd738a8e19796456f0aed14237ef755e
(enables horizon to be conditionally upgraded only if it exists)

Change-Id: Ifcf4dad0366a2763bb311f77ab63de1e5b3fafe7
",git fetch https://review.opendev.org/openstack/devstack-gate refs/changes/65/360565/2 && git format-patch -1 --stdout FETCH_HEAD,['features.yaml'],1,f8bbadda501ec33327756f9b790059e84a60ed65,grenade_horizon," rm-features: [trove, sahara, neutron-adv, horizon]"," rm-features: [trove, sahara, neutron-adv]",1,1
openstack%2Fopenstack-ansible-tests~master~I9c8f328736ad9774801205f5abae746888a8940b,openstack/openstack-ansible-tests,master,I9c8f328736ad9774801205f5abae746888a8940b,Add test network config to lxc_host role,MERGED,2016-08-29 14:13:25.000000000,2016-08-29 15:41:06.000000000,2016-08-29 15:41:06.000000000,"[{'_account_id': 3}, {'_account_id': 7307}, {'_account_id': 7414}]","[{'number': 1, 'created': '2016-08-29 14:13:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-tests/commit/f3889909d265d44b1093d97d356ef2cc41f7a67b', 'message': 'Add test network config to lxc_host role\n\nChange-Id: I9c8f328736ad9774801205f5abae746888a8940b\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 2, 'created': '2016-08-29 14:18:20.000000000', 'files': ['test-prepare-host.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-tests/commit/c130bdd1dec03da7c1594f19142bd990fd2da653', 'message': 'Add test network config to lxc_host role\n\nChange-Id: I9c8f328736ad9774801205f5abae746888a8940b\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}]",0,362144,c130bdd1dec03da7c1594f19142bd990fd2da653,8,3,2,7353,,,0,"Add test network config to lxc_host role

Change-Id: I9c8f328736ad9774801205f5abae746888a8940b
Signed-off-by: Kevin Carter <kevin.carter@rackspace.com>
",git fetch https://review.opendev.org/openstack/openstack-ansible-tests refs/changes/44/362144/2 && git format-patch -1 --stdout FETCH_HEAD,['test-prepare-host.yml'],1,f3889909d265d44b1093d97d356ef2cc41f7a67b,," lxc_net_address: 10.100.100.1 lxc_net_dhcp_range: 10.100.100.8,10.100.100.253 lxc_net_bridge: lxcbr0 lxc_kernel_options: - { key: 'fs.inotify.max_user_instances', value: 1024 }",,5,0
openstack%2Fkeystone~master~I1684ebb668a6fe8339dc428dfd70d11ae1dca97c,openstack/keystone,master,I1684ebb668a6fe8339dc428dfd70d11ae1dca97c,api-ref: Splitting status lines in API v3-ext.,MERGED,2016-08-25 06:23:29.000000000,2016-08-29 15:40:56.000000000,2016-08-29 15:40:56.000000000,"[{'_account_id': 3}, {'_account_id': 6482}, {'_account_id': 7725}, {'_account_id': 8119}, {'_account_id': 18338}, {'_account_id': 21420}]","[{'number': 1, 'created': '2016-08-25 06:23:29.000000000', 'files': ['api-ref/source/v3-ext/oauth.inc', 'api-ref/source/v3-ext/trust.inc', 'api-ref/source/v3-ext/ep-filter.inc'], 'web_link': 'https://opendev.org/openstack/keystone/commit/17f96bb8753c4dbac1b1b82704eb057b544e9af5', 'message': ""api-ref: Splitting status lines in API v3-ext.\n\nCurrently, 'Normal response codes' and 'Error response codes' are\nin the same line. We should split them.\n\nChange-Id: I1684ebb668a6fe8339dc428dfd70d11ae1dca97c\n""}]",2,360267,17f96bb8753c4dbac1b1b82704eb057b544e9af5,11,6,1,19935,,,0,"api-ref: Splitting status lines in API v3-ext.

Currently, 'Normal response codes' and 'Error response codes' are
in the same line. We should split them.

Change-Id: I1684ebb668a6fe8339dc428dfd70d11ae1dca97c
",git fetch https://review.opendev.org/openstack/keystone refs/changes/67/360267/1 && git format-patch -1 --stdout FETCH_HEAD,"['api-ref/source/v3-ext/oauth.inc', 'api-ref/source/v3-ext/trust.inc', 'api-ref/source/v3-ext/ep-filter.inc']",3,17f96bb8753c4dbac1b1b82704eb057b544e9af5,api-ref/blank,,,39,0
openstack%2Ffuel-library~master~I0d7231aa5900318f75f71c698f3e1c07f8e5cfbe,openstack/fuel-library,master,I0d7231aa5900318f75f71c698f3e1c07f8e5cfbe,Add upgrade stuff for new versions,MERGED,2016-08-22 15:06:22.000000000,2016-08-29 15:39:55.000000000,2016-08-29 15:36:14.000000000,"[{'_account_id': 3}, {'_account_id': 7468}, {'_account_id': 7732}, {'_account_id': 7745}, {'_account_id': 8971}, {'_account_id': 9037}, {'_account_id': 11090}, {'_account_id': 11827}, {'_account_id': 14200}, {'_account_id': 14985}, {'_account_id': 16771}, {'_account_id': 18290}, {'_account_id': 20517}, {'_account_id': 20656}]","[{'number': 1, 'created': '2016-08-22 15:06:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/c2b05905d988de0c1f5c216001c509cb24f1bfe8', 'message': ""Add upgrade stuff for new versions\n\nFollowing items were added to perform environment update:\n\n  1. Add task to perform upgrade with call of apt-get dist-upgrade.\n     This commands force to keep old configuration files for all\n     services.\n\n  2. If MU upgrade is enabled, we trigger all services to restart.\n     The exception is for MySQL and RabbitMQ.\n\nSome workarounds were implemented for following issues:\n\n  MySQL and RabbitMQ:\n    MySQL and RabbitMQ restart is managed separately from other\n    services and it is disabled by default. To enable it you\n    should set mu_upgrade['restart_mysql'] and mu_upgrade['restart_rabbitmq']\n    to true in astute.yaml.\n\n  Pacemaker service issue:\n    If corosync package was upgraded APT (or dpkg) restarts corosync\n    service and this restart kills pacemaker service. So we need to\n    start it again. Also we should deny APT to stop pacemaker service\n    during upgrade because it leads to unload of all pacemaker resources\n    (all services under it will be stopped). That's not appropriate\n    behaviour during the update process. Puppet will manage pacemaker\n    service itself.\n\nDocImpact\n\nRelated-bug: #1614893\n\nChange-Id: I0d7231aa5900318f75f71c698f3e1c07f8e5cfbe\n""}, {'number': 2, 'created': '2016-08-22 15:12:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/230a2db87568027510df45124556b0b3336b3e71', 'message': ""Add upgrade stuff for new versions\n\nFollowing items were added to perform environment update:\n\n  1. Add task to perform upgrade with call of apt-get dist-upgrade.\n     This commands force to keep old configuration files for all\n     services.\n\n  2. If MU upgrade is enabled, we trigger all services to restart.\n     The exception is for MySQL and RabbitMQ.\n\nSome workarounds were implemented for following issues:\n\n  MySQL and RabbitMQ:\n    MySQL and RabbitMQ restart is managed separately from other\n    services and it is disabled by default. To enable it you\n    should set mu_upgrade['restart_mysql'] and mu_upgrade['restart_rabbitmq']\n    to true in astute.yaml.\n\n  Pacemaker service issue:\n    If corosync package was upgraded APT (or dpkg) restarts corosync\n    service and this restart kills pacemaker service. So we need to\n    start it again. Also we should deny APT to stop pacemaker service\n    during upgrade because it leads to unload of all pacemaker resources\n    (all services under it will be stopped). That's not appropriate\n    behaviour during the update process. Puppet will manage pacemaker\n    service itself.\n\nDocImpact\n\nRelated-bug: #1614893\n\nChange-Id: I0d7231aa5900318f75f71c698f3e1c07f8e5cfbe\n""}, {'number': 3, 'created': '2016-08-22 15:25:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/1450f2cf359312f5da59e4f592ed2a32767f2fe5', 'message': ""Add upgrade stuff for new versions\n\nFollowing items were added to perform environment update:\n\n  1. Add task to perform upgrade with call of apt-get dist-upgrade.\n     This commands force to keep old configuration files for all\n     services.\n\n  2. If MU upgrade is enabled, we trigger all services to restart.\n     The exception is for MySQL and RabbitMQ.\n\nSome workarounds were implemented for following issues:\n\n  MySQL and RabbitMQ:\n    MySQL and RabbitMQ restart is managed separately from other\n    services and it is disabled by default. To enable it you\n    should set mu_upgrade['restart_mysql'] and mu_upgrade['restart_rabbitmq']\n    to true in astute.yaml.\n\n  Pacemaker service issue:\n    If corosync package was upgraded APT (or dpkg) restarts corosync\n    service and this restart kills pacemaker service. So we need to\n    start it again. Also we should deny APT to stop pacemaker service\n    during upgrade because it leads to unload of all pacemaker resources\n    (all services under it will be stopped). That's not appropriate\n    behaviour during the update process. Puppet will manage pacemaker\n    service itself.\n\nDocImpact\n\nRelated-bug: #1614893\n\nChange-Id: I0d7231aa5900318f75f71c698f3e1c07f8e5cfbe\n""}, {'number': 4, 'created': '2016-08-22 17:25:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/fbae44491363576ea2b879ccb4982a1d87fa1f6a', 'message': ""Add upgrade stuff for new versions\n\nFollowing items were added to perform environment update:\n\n  1. Add task to perform upgrade with call of apt-get dist-upgrade.\n     This commands force to keep old configuration files for all\n     services.\n\n  2. If MU upgrade is enabled, we trigger all services to restart.\n     The exception is for MySQL and RabbitMQ.\n\nSome workarounds were implemented for following issues:\n\n  MySQL and RabbitMQ:\n    MySQL and RabbitMQ restart is managed separately from other\n    services and it is disabled by default. To enable it you\n    should set mu_upgrade['restart_mysql'] and mu_upgrade['restart_rabbitmq']\n    to true in astute.yaml.\n\n  Pacemaker service issue:\n    If corosync package was upgraded APT (or dpkg) restarts corosync\n    service and this restart kills pacemaker service. So we need to\n    start it again. Also we should deny APT to stop pacemaker service\n    during upgrade because it leads to unload of all pacemaker resources\n    (all services under it will be stopped). That's not appropriate\n    behaviour during the update process. Puppet will manage pacemaker\n    service itself.\n\nDocImpact\n\nRelated-bug: #1614893\n\nChange-Id: I0d7231aa5900318f75f71c698f3e1c07f8e5cfbe\n""}, {'number': 5, 'created': '2016-08-23 13:39:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/2ef70bf65421ff8786a145a1d4a9cf8e8e91b077', 'message': ""Add upgrade stuff for new versions\n\nFollowing items were added to perform environment update:\n\n  1. Add task to perform upgrade with call of apt-get dist-upgrade.\n     This commands force to keep old configuration files for all\n     services.\n\n  2. If MU upgrade is enabled, we trigger all services to restart.\n     The exception is for Ceph, MySQL and RabbitMQ.\n\nSome workarounds were implemented for following issues:\n\n  MySQL and RabbitMQ:\n    MySQL and RabbitMQ restart is managed separately from other\n    services and it is disabled by default. To enable it you\n    should set mu_upgrade['restart_mysql'] and mu_upgrade['restart_rabbitmq']\n    to true in astute.yaml.\n\n  Pacemaker service issue:\n    If corosync package was upgraded APT (or dpkg) restarts corosync\n    service and this restart kills pacemaker service. So we need to\n    start it again. Also we should deny APT to stop pacemaker service\n    during upgrade because it leads to unload of all pacemaker resources\n    (all services under it will be stopped). That's not appropriate\n    behaviour during the update process. Puppet will manage pacemaker\n    service itself.\n\n  Ceph:\n    Ceph should be upgraded by following next guide [1], otherwise simple\n    restart of services might break the cluster or cause a data loss.\n\n    [1] http://docs.ceph.com/docs/master/install/upgrading-ceph/#upgrade-procedures\n\nDocImpact\n\nRelated-bug: #1614893\n\nChange-Id: I0d7231aa5900318f75f71c698f3e1c07f8e5cfbe\n""}, {'number': 6, 'created': '2016-08-23 15:56:36.000000000', 'files': ['deployment/puppet/openstack_tasks/examples/horizon/horizon.pp', 'deployment/puppet/osnailyfacter/modular/ceph/mon.pp', 'deployment/puppet/openstack_tasks/examples/openstack-network/agents/dhcp.pp', 'deployment/puppet/openstack_tasks/examples/roles/cinder.pp', 'deployment/puppet/openstack_tasks/examples/keystone/keystone.pp', 'deployment/puppet/openstack_tasks/examples/murano/rabbitmq.pp', 'deployment/puppet/openstack_tasks/examples/sahara/sahara.pp', 'deployment/puppet/osnailyfacter/manifests/upgrade/ceph_service.pp', 'deployment/puppet/osnailyfacter/modular/upgrade/pkg_upgrade.pp', 'deployment/puppet/osnailyfacter/modular/apache/apache.pp', 'deployment/puppet/osnailyfacter/modular/ceph/ceph-osd.pp', 'deployment/puppet/openstack_tasks/examples/aodh/aodh.pp', 'deployment/puppet/osnailyfacter/modular/ntp/ntp-server.pp', 'deployment/puppet/osnailyfacter/modular/vmware/cinder-vmware.pp', 'deployment/puppet/osnailyfacter/modular/cluster/cluster.pp', 'deployment/puppet/openstack_tasks/examples/openstack-controller/openstack-controller.pp', 'deployment/puppet/osnailyfacter/manifests/upgrade/mysql_service.pp', 'deployment/puppet/osnailyfacter/modular/upgrade/tasks.yaml', 'deployment/puppet/openstack_tasks/examples/openstack-cinder/openstack-cinder.pp', 'deployment/puppet/osnailyfacter/modular/ceph/ceph_pools.pp', 'deployment/puppet/openstack_tasks/examples/ceilometer/controller.pp', 'deployment/puppet/openstack_tasks/examples/glance/glance.pp', 'deployment/puppet/osnailyfacter/modular/ceph/ceph_compute.pp', 'deployment/puppet/osnailyfacter/modular/cluster/health.pp', 'deployment/puppet/openstack_tasks/examples/openstack-network/agents/l3.pp', 'deployment/puppet/openstack_tasks/examples/heat/heat.pp', 'deployment/puppet/openstack_tasks/examples/openstack-network/agents/sriov.pp', 'deployment/puppet/openstack_tasks/examples/murano/cfapi.pp', 'deployment/puppet/openstack_tasks/examples/murano/murano.pp', 'deployment/puppet/osnailyfacter/modular/cluster-haproxy/cluster-haproxy.pp', 'deployment/puppet/osnailyfacter/modular/memcached/memcached.pp', 'deployment/puppet/openstack_tasks/examples/openstack-network/agents/metadata.pp', 'deployment/puppet/openstack_tasks/examples/ironic/ironic-compute.pp', 'deployment/puppet/osnailyfacter/modular/cluster-vrouter/cluster-vrouter.pp', 'deployment/puppet/osnailyfacter/modular/api-proxy/api-proxy.pp', 'deployment/puppet/osnailyfacter/modular/ceph/radosgw.pp', 'deployment/puppet/osnailyfacter/manifests/upgrade/pkg_upgrade.pp', 'deployment/puppet/osnailyfacter/modular/logging/logging.pp', 'deployment/puppet/openstack_tasks/examples/swift/swift.pp', 'deployment/puppet/openstack_tasks/examples/roles/controller.pp', 'deployment/puppet/openstack_tasks/examples/ceilometer/radosgw_user.pp', 'deployment/puppet/openstack_tasks/examples/roles/ironic-conductor.pp', 'deployment/puppet/osnailyfacter/modular/ntp/ntp-client.pp', 'deployment/puppet/openstack_tasks/examples/roles/mongo.pp', 'deployment/puppet/osnailyfacter/manifests/upgrade/restart_services.pp', 'deployment/puppet/osnailyfacter/modular/tools/tools.pp', 'deployment/puppet/openstack_tasks/examples/swift/proxy_storage.pp', 'deployment/puppet/osnailyfacter/modular/cgroups/cgroups.pp', 'deployment/puppet/osnailyfacter/manifests/upgrade/rabbitmq_service.pp', 'deployment/puppet/osnailyfacter/modular/vmware/vcenter.pp', 'deployment/puppet/openstack_tasks/examples/ironic/ironic.pp', 'deployment/puppet/openstack_tasks/examples/roles/compute.pp', 'deployment/puppet/openstack_tasks/examples/ceilometer/compute.pp', 'deployment/puppet/osnailyfacter/modular/vmware/compute-vmware.pp'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/c154093cd5c493188669f8c47c77857b0507a77b', 'message': ""Add upgrade stuff for new versions\n\nFollowing items were added to perform environment update:\n\n  1. Add task to perform upgrade with call of apt-get dist-upgrade.\n     This commands force to keep old configuration files for all\n     services.\n\n  2. If MU upgrade is enabled, we trigger all services to restart.\n     The exception is for Ceph, MySQL and RabbitMQ.\n\nSome workarounds were implemented for following issues:\n\n  MySQL and RabbitMQ:\n    MySQL and RabbitMQ restart is managed separately from other\n    services and it is disabled by default. To enable it you\n    should set mu_upgrade['restart_mysql'] and mu_upgrade['restart_rabbitmq']\n    to true in astute.yaml.\n\n  Pacemaker service issue:\n    If corosync package was upgraded APT (or dpkg) restarts corosync\n    service and this restart kills pacemaker service. So we need to\n    start it again. Also we should deny APT to stop pacemaker service\n    during upgrade because it leads to unload of all pacemaker resources\n    (all services under it will be stopped). That's not appropriate\n    behaviour during the update process. Puppet will manage pacemaker\n    service itself.\n\n  Ceph:\n    Ceph should be upgraded by following next guide [1], otherwise simple\n    restart of services might break the cluster or cause a data loss.\n\n    [1] http://docs.ceph.com/docs/master/install/upgrading-ceph/#upgrade-procedures\n\nDocImpact\n\nRelated-bug: #1614893\n\nChange-Id: I0d7231aa5900318f75f71c698f3e1c07f8e5cfbe\n""}]",0,358702,c154093cd5c493188669f8c47c77857b0507a77b,155,14,6,7732,,,0,"Add upgrade stuff for new versions

Following items were added to perform environment update:

  1. Add task to perform upgrade with call of apt-get dist-upgrade.
     This commands force to keep old configuration files for all
     services.

  2. If MU upgrade is enabled, we trigger all services to restart.
     The exception is for Ceph, MySQL and RabbitMQ.

Some workarounds were implemented for following issues:

  MySQL and RabbitMQ:
    MySQL and RabbitMQ restart is managed separately from other
    services and it is disabled by default. To enable it you
    should set mu_upgrade['restart_mysql'] and mu_upgrade['restart_rabbitmq']
    to true in astute.yaml.

  Pacemaker service issue:
    If corosync package was upgraded APT (or dpkg) restarts corosync
    service and this restart kills pacemaker service. So we need to
    start it again. Also we should deny APT to stop pacemaker service
    during upgrade because it leads to unload of all pacemaker resources
    (all services under it will be stopped). That's not appropriate
    behaviour during the update process. Puppet will manage pacemaker
    service itself.

  Ceph:
    Ceph should be upgraded by following next guide [1], otherwise simple
    restart of services might break the cluster or cause a data loss.

    [1] http://docs.ceph.com/docs/master/install/upgrading-ceph/#upgrade-procedures

DocImpact

Related-bug: #1614893

Change-Id: I0d7231aa5900318f75f71c698f3e1c07f8e5cfbe
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/02/358702/4 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/puppet/openstack_tasks/examples/horizon/horizon.pp', 'deployment/puppet/osnailyfacter/modular/ceph/mon.pp', 'deployment/puppet/openstack_tasks/examples/openstack-network/agents/dhcp.pp', 'deployment/puppet/openstack_tasks/examples/roles/cinder.pp', 'deployment/puppet/openstack_tasks/examples/keystone/keystone.pp', 'deployment/puppet/openstack_tasks/examples/murano/rabbitmq.pp', 'deployment/puppet/openstack_tasks/examples/sahara/sahara.pp', 'deployment/puppet/osnailyfacter/modular/upgrade/pkg_upgrade.pp', 'deployment/puppet/osnailyfacter/modular/apache/apache.pp', 'deployment/puppet/osnailyfacter/modular/ceph/ceph-osd.pp', 'deployment/puppet/openstack_tasks/examples/aodh/aodh.pp', 'deployment/puppet/osnailyfacter/modular/ntp/ntp-server.pp', 'deployment/puppet/osnailyfacter/modular/vmware/cinder-vmware.pp', 'deployment/puppet/osnailyfacter/modular/cluster/cluster.pp', 'deployment/puppet/openstack_tasks/examples/openstack-controller/openstack-controller.pp', 'deployment/puppet/osnailyfacter/manifests/upgrade/mysql_service.pp', 'deployment/puppet/osnailyfacter/modular/upgrade/tasks.yaml', 'deployment/puppet/openstack_tasks/examples/openstack-cinder/openstack-cinder.pp', 'deployment/puppet/osnailyfacter/modular/ceph/ceph_pools.pp', 'deployment/puppet/openstack_tasks/examples/ceilometer/controller.pp', 'deployment/puppet/openstack_tasks/examples/glance/glance.pp', 'deployment/puppet/osnailyfacter/modular/ceph/ceph_compute.pp', 'deployment/puppet/osnailyfacter/modular/cluster/health.pp', 'deployment/puppet/openstack_tasks/examples/openstack-network/agents/l3.pp', 'deployment/puppet/openstack_tasks/examples/heat/heat.pp', 'deployment/puppet/openstack_tasks/examples/openstack-network/agents/sriov.pp', 'deployment/puppet/openstack_tasks/examples/murano/cfapi.pp', 'deployment/puppet/openstack_tasks/examples/murano/murano.pp', 'deployment/puppet/osnailyfacter/modular/cluster-haproxy/cluster-haproxy.pp', 'deployment/puppet/osnailyfacter/modular/memcached/memcached.pp', 'deployment/puppet/openstack_tasks/examples/openstack-network/agents/metadata.pp', 'deployment/puppet/openstack_tasks/examples/ironic/ironic-compute.pp', 'deployment/puppet/osnailyfacter/modular/cluster-vrouter/cluster-vrouter.pp', 'deployment/puppet/osnailyfacter/modular/api-proxy/api-proxy.pp', 'deployment/puppet/osnailyfacter/modular/ceph/radosgw.pp', 'deployment/puppet/osnailyfacter/manifests/upgrade/pkg_upgrade.pp', 'deployment/puppet/osnailyfacter/modular/logging/logging.pp', 'deployment/puppet/openstack_tasks/examples/swift/swift.pp', 'deployment/puppet/openstack_tasks/examples/roles/controller.pp', 'deployment/puppet/openstack_tasks/examples/ceilometer/radosgw_user.pp', 'deployment/puppet/openstack_tasks/examples/roles/ironic-conductor.pp', 'deployment/puppet/osnailyfacter/modular/ntp/ntp-client.pp', 'deployment/puppet/openstack_tasks/examples/roles/mongo.pp', 'deployment/puppet/osnailyfacter/manifests/upgrade/restart_services.pp', 'deployment/puppet/osnailyfacter/modular/tools/tools.pp', 'deployment/puppet/openstack_tasks/examples/swift/proxy_storage.pp', 'deployment/puppet/osnailyfacter/modular/cgroups/cgroups.pp', 'deployment/puppet/osnailyfacter/manifests/upgrade/rabbitmq_service.pp', 'deployment/puppet/osnailyfacter/modular/vmware/vcenter.pp', 'deployment/puppet/openstack_tasks/examples/ironic/ironic.pp', 'deployment/puppet/openstack_tasks/examples/roles/compute.pp', 'deployment/puppet/openstack_tasks/examples/ceilometer/compute.pp', 'deployment/puppet/osnailyfacter/modular/vmware/compute-vmware.pp']",53,c2b05905d988de0c1f5c216001c509cb24f1bfe8,bug/1614893,class { '::osnailyfacter::upgrade::restart_services' :},,123,23
openstack%2Fdeb-python-weakrefmethod~debian%2Fnewton~I0a2622948b4616ed598ff8b1001837bc8a80ae34,openstack/deb-python-weakrefmethod,debian/newton,I0a2622948b4616ed598ff8b1001837bc8a80ae34,Add a .gitreview file,MERGED,2016-08-29 15:23:52.000000000,2016-08-29 15:38:06.000000000,2016-08-29 15:38:06.000000000,"[{'_account_id': 3}, {'_account_id': 6476}]","[{'number': 1, 'created': '2016-08-29 15:23:52.000000000', 'files': ['.gitreview'], 'web_link': 'https://opendev.org/openstack/deb-python-weakrefmethod/commit/61bd6372b72c4796ff82dcfa36ff64d86e374872', 'message': 'Add a .gitreview file\n\nChange-Id: I0a2622948b4616ed598ff8b1001837bc8a80ae34\n'}]",0,362195,61bd6372b72c4796ff82dcfa36ff64d86e374872,6,2,1,6476,,,0,"Add a .gitreview file

Change-Id: I0a2622948b4616ed598ff8b1001837bc8a80ae34
",git fetch https://review.opendev.org/openstack/deb-python-weakrefmethod refs/changes/95/362195/1 && git format-patch -1 --stdout FETCH_HEAD,['.gitreview'],1,61bd6372b72c4796ff82dcfa36ff64d86e374872,,[gerrit] host=review.openstack.org port=29418 project=openstack/deb-python-weakrefmethod.git defaultbranch=debian/newton ,,5,0
openstack%2Fdeb-python-semver~debian%2Fnewton~I7eae9a5917ae84f28c9574ad3175b812ad1d864d,openstack/deb-python-semver,debian/newton,I7eae9a5917ae84f28c9574ad3175b812ad1d864d,Add a .gitreview file,MERGED,2016-08-29 15:18:36.000000000,2016-08-29 15:37:39.000000000,2016-08-29 15:37:39.000000000,"[{'_account_id': 3}, {'_account_id': 6476}]","[{'number': 1, 'created': '2016-08-29 15:18:36.000000000', 'files': ['.gitreview'], 'web_link': 'https://opendev.org/openstack/deb-python-semver/commit/fbf088d6947096e710a8062a5a8154292feec08d', 'message': 'Add a .gitreview file\n\nChange-Id: I7eae9a5917ae84f28c9574ad3175b812ad1d864d\n'}]",0,362189,fbf088d6947096e710a8062a5a8154292feec08d,6,2,1,6476,,,0,"Add a .gitreview file

Change-Id: I7eae9a5917ae84f28c9574ad3175b812ad1d864d
",git fetch https://review.opendev.org/openstack/deb-python-semver refs/changes/89/362189/1 && git format-patch -1 --stdout FETCH_HEAD,['.gitreview'],1,fbf088d6947096e710a8062a5a8154292feec08d,,[gerrit] host=review.openstack.org port=29418 project=openstack/deb-python-semver.git defaultbranch=debian/newton ,,5,0
openstack%2Fdeb-python-warlock~debian%2Fnewton~Icff6c7ac430195dbd0e2197f89be04b232397a45,openstack/deb-python-warlock,debian/newton,Icff6c7ac430195dbd0e2197f89be04b232397a45,Add a .gitreview file,MERGED,2016-08-29 15:22:34.000000000,2016-08-29 15:36:46.000000000,2016-08-29 15:36:46.000000000,"[{'_account_id': 3}, {'_account_id': 6476}]","[{'number': 1, 'created': '2016-08-29 15:22:34.000000000', 'files': ['.gitreview'], 'web_link': 'https://opendev.org/openstack/deb-python-warlock/commit/3e02f4b94d0721318d4dacd48a1f07b2c85ed06c', 'message': 'Add a .gitreview file\n\nChange-Id: Icff6c7ac430195dbd0e2197f89be04b232397a45\n'}]",0,362192,3e02f4b94d0721318d4dacd48a1f07b2c85ed06c,6,2,1,6476,,,0,"Add a .gitreview file

Change-Id: Icff6c7ac430195dbd0e2197f89be04b232397a45
",git fetch https://review.opendev.org/openstack/deb-python-warlock refs/changes/92/362192/1 && git format-patch -1 --stdout FETCH_HEAD,['.gitreview'],1,3e02f4b94d0721318d4dacd48a1f07b2c85ed06c,,[gerrit] host=review.openstack.org port=29418 project=openstack/deb-python-warlock.git defaultbranch=debian/newton ,,5,0
openstack%2Foslo.middleware~master~I164b192f85ee9232a92ad7a5e99a3af647813dc8,openstack/oslo.middleware,master,I164b192f85ee9232a92ad7a5e99a3af647813dc8,Show more healthcheck examples,MERGED,2016-08-24 06:42:52.000000000,2016-08-29 15:36:00.000000000,2016-08-29 15:34:43.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 6537}]","[{'number': 1, 'created': '2016-08-24 06:42:52.000000000', 'files': ['oslo_middleware/healthcheck/__init__.py'], 'web_link': 'https://opendev.org/openstack/oslo.middleware/commit/e782ca67a1c8c558f13de4a80c0f25c8d5a89bdb', 'message': 'Show more healthcheck examples\n\nChange-Id: I164b192f85ee9232a92ad7a5e99a3af647813dc8\n'}]",0,359626,e782ca67a1c8c558f13de4a80c0f25c8d5a89bdb,7,3,1,1297,,,0,"Show more healthcheck examples

Change-Id: I164b192f85ee9232a92ad7a5e99a3af647813dc8
",git fetch https://review.opendev.org/openstack/oslo.middleware refs/changes/26/359626/1 && git format-patch -1 --stdout FETCH_HEAD,['oslo_middleware/healthcheck/__init__.py'],1,e782ca67a1c8c558f13de4a80c0f25c8d5a89bdb,," If the path is ``/healthcheck``, it will respond 200 with ""OK"" as the body. Or a 503 with the reason as the body if one of the backends reports an application issue. * Load balancers can 'ping' this url to determine service availability. * Provides an endpoint that is similar to 'mod_status' in apache which can provide details (or no details, depending on if configured) about the activity of the server. * *(and more)* Example requests/responses (**not** detailed mode):: $ curl -i -X HEAD ""http://0.0.0.0:8775/healthcheck"" HTTP/1.1 204 No Content Content-Type: text/plain; charset=UTF-8 Content-Length: 0 Date: Fri, 11 Sep 2015 18:55:08 GMT $ curl -i -X GET ""http://0.0.0.0:8775/healthcheck"" HTTP/1.1 200 OK Content-Type: text/plain; charset=UTF-8 Content-Length: 2 Date: Fri, 11 Sep 2015 18:55:43 GMT OK $ curl -X GET -i -H ""Accept: application/json"" ""http://0.0.0.0:8775/healthcheck"" HTTP/1.0 200 OK Date: Wed, 24 Aug 2016 06:09:58 GMT Content-Type: application/json Content-Length: 63 { ""detailed"": false, ""reasons"": [ ""OK"" ] } $ curl -X GET -i -H ""Accept: text/html"" ""http://0.0.0.0:8775/healthcheck"" HTTP/1.0 200 OK Date: Wed, 24 Aug 2016 06:10:42 GMT Content-Type: text/html; charset=UTF-8 Content-Length: 239 <HTML> <HEAD><TITLE>Healthcheck Status</TITLE></HEAD> <BODY> <H2>Result of 1 checks:</H2> <TABLE bgcolor=""#ffffff"" border=""1""> <TBODY> <TR> <TH> Reason </TH> </TR> <TR> <TD>OK</TD> </TR> </TBODY> </TABLE> <HR></HR> </BODY> Example requests/responses (**detailed** mode):: $ curl -X GET -i -H ""Accept: application/json"" ""http://0.0.0.0:8775/healthcheck"" HTTP/1.0 200 OK Date: Wed, 24 Aug 2016 06:11:59 GMT Content-Type: application/json Content-Length: 3480 { ""detailed"": true, ""gc"": { ""counts"": [ 293, 10, 5 ], ""threshold"": [ 700, 10, 10 ] }, ""greenthreads"": [ ... ], ""now"": ""2016-08-24 06:11:59.419267"", ""platform"": ""Linux-4.2.0-27-generic-x86_64-with-Ubuntu-14.04-trusty"", ""python_version"": ""2.7.6 (default, Jun 22 2015, 17:58:13) \\n[GCC 4.8.2]"", ""reasons"": [ { ""class"": ""HealthcheckResult"", ""details"": ""Path '/tmp/dead' was not found"", ""reason"": ""OK"" } ], ""threads"": [ ... ] } $ curl -X GET -i -H ""Accept: text/html"" ""http://0.0.0.0:8775/healthcheck"" HTTP/1.0 200 OK Date: Wed, 24 Aug 2016 06:36:07 GMT Content-Type: text/html; charset=UTF-8 Content-Length: 6838 <HTML> <HEAD><TITLE>Healthcheck Status</TITLE></HEAD> <BODY> <H1>Server status</H1> <B>Server hostname:</B><PRE>...</PRE> <B>Current time:</B><PRE>2016-08-24 06:36:07.302559</PRE> <B>Python version:</B><PRE>2.7.6 (default, Jun 22 2015, 17:58:13) [GCC 4.8.2]</PRE> <B>Platform:</B><PRE>Linux-4.2.0-27-generic-x86_64-with-Ubuntu-14.04-trusty</PRE> <HR></HR> <H2>Garbage collector:</H2> <B>Counts:</B><PRE>(77, 1, 6)</PRE> <B>Thresholds:</B><PRE>(700, 10, 10)</PRE> <HR></HR> <H2>Result of 1 checks:</H2> <TABLE bgcolor=""#ffffff"" border=""1""> <TBODY> <TR> <TH> Kind </TH> <TH> Reason </TH> <TH> Details </TH> </TR> <TR> <TD>HealthcheckResult</TD> <TD>OK</TD> <TD>Path &#39;/tmp/dead&#39; was not found</TD> </TR> </TBODY> </TABLE> <HR></HR> <H2>1 greenthread(s) active:</H2> <TABLE bgcolor=""#ffffff"" border=""1""> <TBODY> <TR> <TD><PRE> File &#34;oslo_middleware/healthcheck/__main__.py&#34;, line 94, in &lt;module&gt; main() File &#34;oslo_middleware/healthcheck/__main__.py&#34;, line 90, in main server.serve_forever() ... </PRE></TD> </TR> </TBODY> </TABLE> <HR></HR> <H2>1 thread(s) active:</H2> <TABLE bgcolor=""#ffffff"" border=""1""> <TBODY> <TR> <TD><PRE> File &#34;oslo_middleware/healthcheck/__main__.py&#34;, line 94, in &lt;module&gt; main() File &#34;oslo_middleware/healthcheck/__main__.py&#34;, line 90, in main server.serve_forever() .... </TR> </TBODY> </TABLE> </BODY> </HTML>"," If the path is /healthcheck, it will respond 200 with ""OK"" as the body. Or 503 with the reason as the body if one of the backend report an application issue. 1. Load balancers can 'ping' this url to determine service availability. 2. Provides an endpoint that is similar to 'mod_status' in apache which can provide details (or no details, depending on if configured) about the activity of the server. Example requests/responses: $ curl -i -X HEAD ""http://0.0.0.0:8775/healthcheck"" HTTP/1.1 204 No Content Content-Type: text/plain; charset=UTF-8 Content-Length: 0 Date: Fri, 11 Sep 2015 18:55:08 GMT $ curl -i ""http://0.0.0.0:8775/healthcheck"" HTTP/1.1 200 OK Content-Type: text/plain; charset=UTF-8 Content-Length: 2 Date: Fri, 11 Sep 2015 18:55:43 GMT OK",174,21
openstack%2Fdeb-python-semantic-version~debian%2Fnewton~Ia79228ae2fcde3ff0f7e5ba962d49578cf093e0a,openstack/deb-python-semantic-version,debian/newton,Ia79228ae2fcde3ff0f7e5ba962d49578cf093e0a,Add a .gitreview file,MERGED,2016-08-29 15:16:53.000000000,2016-08-29 15:35:09.000000000,2016-08-29 15:35:09.000000000,"[{'_account_id': 3}, {'_account_id': 6476}]","[{'number': 1, 'created': '2016-08-29 15:16:53.000000000', 'files': ['.gitreview'], 'web_link': 'https://opendev.org/openstack/deb-python-semantic-version/commit/7eae0cd89feb09cdcbc1656ae28167c4bbe9e544', 'message': 'Add a .gitreview file\n\nChange-Id: Ia79228ae2fcde3ff0f7e5ba962d49578cf093e0a\n'}]",0,362188,7eae0cd89feb09cdcbc1656ae28167c4bbe9e544,6,2,1,6476,,,0,"Add a .gitreview file

Change-Id: Ia79228ae2fcde3ff0f7e5ba962d49578cf093e0a
",git fetch https://review.opendev.org/openstack/deb-python-semantic-version refs/changes/88/362188/1 && git format-patch -1 --stdout FETCH_HEAD,['.gitreview'],1,7eae0cd89feb09cdcbc1656ae28167c4bbe9e544,,[gerrit] host=review.openstack.org port=29418 project=openstack/deb-python-semantic-version.git defaultbranch=debian/newton ,,5,0
openstack%2Fdeb-python-rtslib-fb~debian%2Fnewton~If6eca12e8c613f049085c34f04a6fd5a0cf1b626,openstack/deb-python-rtslib-fb,debian/newton,If6eca12e8c613f049085c34f04a6fd5a0cf1b626,Add a .gitreview file,MERGED,2016-08-29 15:15:19.000000000,2016-08-29 15:34:30.000000000,2016-08-29 15:34:30.000000000,"[{'_account_id': 3}, {'_account_id': 6476}]","[{'number': 1, 'created': '2016-08-29 15:15:19.000000000', 'files': ['.gitreview'], 'web_link': 'https://opendev.org/openstack/deb-python-rtslib-fb/commit/fe123497f237d458ed45607c237ee517ddfd1c26', 'message': 'Add a .gitreview file\n\nChange-Id: If6eca12e8c613f049085c34f04a6fd5a0cf1b626\n'}]",0,362185,fe123497f237d458ed45607c237ee517ddfd1c26,6,2,1,6476,,,0,"Add a .gitreview file

Change-Id: If6eca12e8c613f049085c34f04a6fd5a0cf1b626
",git fetch https://review.opendev.org/openstack/deb-python-rtslib-fb refs/changes/85/362185/1 && git format-patch -1 --stdout FETCH_HEAD,['.gitreview'],1,fe123497f237d458ed45607c237ee517ddfd1c26,,[gerrit] host=review.openstack.org port=29418 project=openstack/deb-python-rtslib-fb.git defaultbranch=debian/newton ,,5,0
openstack%2Fdeb-python-retrying~debian%2Fnewton~I50a8639418f9c9dd8bcb5fab6a48f509d2e08901,openstack/deb-python-retrying,debian/newton,I50a8639418f9c9dd8bcb5fab6a48f509d2e08901,Add a .gitreview file,MERGED,2016-08-29 15:11:01.000000000,2016-08-29 15:34:20.000000000,2016-08-29 15:34:20.000000000,"[{'_account_id': 3}, {'_account_id': 6476}]","[{'number': 1, 'created': '2016-08-29 15:11:01.000000000', 'files': ['.gitreview'], 'web_link': 'https://opendev.org/openstack/deb-python-retrying/commit/ed5a7d72beecaee2dd3d5b691a85551b19f8cd7e', 'message': 'Add a .gitreview file\n\nChange-Id: I50a8639418f9c9dd8bcb5fab6a48f509d2e08901\n'}]",0,362181,ed5a7d72beecaee2dd3d5b691a85551b19f8cd7e,6,2,1,6476,,,0,"Add a .gitreview file

Change-Id: I50a8639418f9c9dd8bcb5fab6a48f509d2e08901
",git fetch https://review.opendev.org/openstack/deb-python-retrying refs/changes/81/362181/1 && git format-patch -1 --stdout FETCH_HEAD,['.gitreview'],1,ed5a7d72beecaee2dd3d5b691a85551b19f8cd7e,,[gerrit] host=review.openstack.org port=29418 project=openstack/deb-python-retrying.git defaultbranch=debian/newton ,,5,0
openstack%2Fdeb-python-rjsmin~debian%2Fnewton~I81761fa5802827e647ff36a6d67cd5138610cde6,openstack/deb-python-rjsmin,debian/newton,I81761fa5802827e647ff36a6d67cd5138610cde6,Add a .gitreview file,MERGED,2016-08-29 15:13:50.000000000,2016-08-29 15:34:14.000000000,2016-08-29 15:34:14.000000000,"[{'_account_id': 3}, {'_account_id': 6476}]","[{'number': 1, 'created': '2016-08-29 15:13:50.000000000', 'files': ['.gitreview'], 'web_link': 'https://opendev.org/openstack/deb-python-rjsmin/commit/d02d1437ccabf827c03388b4e40954f9867a072b', 'message': 'Add a .gitreview file\n\nChange-Id: I81761fa5802827e647ff36a6d67cd5138610cde6\n'}]",0,362184,d02d1437ccabf827c03388b4e40954f9867a072b,6,2,1,6476,,,0,"Add a .gitreview file

Change-Id: I81761fa5802827e647ff36a6d67cd5138610cde6
",git fetch https://review.opendev.org/openstack/deb-python-rjsmin refs/changes/84/362184/1 && git format-patch -1 --stdout FETCH_HEAD,['.gitreview'],1,d02d1437ccabf827c03388b4e40954f9867a072b,,[gerrit] host=review.openstack.org port=29418 project=openstack/deb-python-rjsmin.git defaultbranch=debian/newton ,,5,0
openstack%2Fpython-openstackclient~master~I90afe332e959ba8bbfb1f04cc84454d30a4cf4a8,openstack/python-openstackclient,master,I90afe332e959ba8bbfb1f04cc84454d30a4cf4a8,Updated from global requirements,MERGED,2016-08-29 06:17:19.000000000,2016-08-29 15:30:50.000000000,2016-08-29 15:30:50.000000000,"[{'_account_id': 3}, {'_account_id': 6482}, {'_account_id': 8410}]","[{'number': 1, 'created': '2016-08-29 06:17:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/870d86e593537f4c2faef98a539e6c4debe34fe6', 'message': 'Updated from global requirements\n\nChange-Id: I90afe332e959ba8bbfb1f04cc84454d30a4cf4a8\n'}, {'number': 2, 'created': '2016-08-29 10:57:56.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/5b14741fcc8a27dbd886c647ecc474480ae2d1f0', 'message': 'Updated from global requirements\n\nChange-Id: I90afe332e959ba8bbfb1f04cc84454d30a4cf4a8\n'}]",0,361873,5b14741fcc8a27dbd886c647ecc474480ae2d1f0,9,3,2,11131,,,0,"Updated from global requirements

Change-Id: I90afe332e959ba8bbfb1f04cc84454d30a4cf4a8
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/73/361873/2 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,870d86e593537f4c2faef98a539e6c4debe34fe6,openstack/requirements,python-heatclient>=1.4.0 # Apache-2.0,python-heatclient>=1.1.0 # Apache-2.0,1,1
openstack%2Fkeystone~master~Iecfa8849a57dc895f639ab2e7d910a2a8763f83a,openstack/keystone,master,Iecfa8849a57dc895f639ab2e7d910a2a8763f83a,api-ref: Splitting status lines in API v3.,MERGED,2016-08-25 06:19:25.000000000,2016-08-29 15:29:34.000000000,2016-08-29 15:29:34.000000000,"[{'_account_id': 3}, {'_account_id': 6482}, {'_account_id': 7725}, {'_account_id': 8119}, {'_account_id': 18338}, {'_account_id': 20466}, {'_account_id': 21420}]","[{'number': 1, 'created': '2016-08-25 06:19:25.000000000', 'files': ['api-ref/source/v3/groups.inc', 'api-ref/source/v3/regions-v3.inc', 'api-ref/source/v3/inherit.inc', 'api-ref/source/v3/credentials.inc', 'api-ref/source/v3/projects.inc', 'api-ref/source/v3/domains.inc', 'api-ref/source/v3/service-catalog.inc', 'api-ref/source/v3/domains-config-v3.inc', 'api-ref/source/v3/policies.inc', 'api-ref/source/v3/users.inc', 'api-ref/source/v3/authenticate-v3.inc', 'api-ref/source/v3/roles.inc'], 'web_link': 'https://opendev.org/openstack/keystone/commit/43df6125f96f7699ae66cbd1fbf25c45db40bb36', 'message': ""api-ref: Splitting status lines in API v3.\n\nCurrently, 'Normal response codes' and 'Error response codes' are\nin the same line. We should split them.\n\nChange-Id: Iecfa8849a57dc895f639ab2e7d910a2a8763f83a\n""}]",4,360264,43df6125f96f7699ae66cbd1fbf25c45db40bb36,16,7,1,19935,,,0,"api-ref: Splitting status lines in API v3.

Currently, 'Normal response codes' and 'Error response codes' are
in the same line. We should split them.

Change-Id: Iecfa8849a57dc895f639ab2e7d910a2a8763f83a
",git fetch https://review.opendev.org/openstack/keystone refs/changes/64/360264/1 && git format-patch -1 --stdout FETCH_HEAD,"['api-ref/source/v3/groups.inc', 'api-ref/source/v3/regions-v3.inc', 'api-ref/source/v3/inherit.inc', 'api-ref/source/v3/credentials.inc', 'api-ref/source/v3/projects.inc', 'api-ref/source/v3/domains.inc', 'api-ref/source/v3/service-catalog.inc', 'api-ref/source/v3/domains-config-v3.inc', 'api-ref/source/v3/policies.inc', 'api-ref/source/v3/users.inc', 'api-ref/source/v3/authenticate-v3.inc', 'api-ref/source/v3/roles.inc']",12,43df6125f96f7699ae66cbd1fbf25c45db40bb36,api-ref/blank,,,101,0
openstack%2Fkeystone~master~I196d32e3608b4306fda116ad7ab200827c84bb41,openstack/keystone,master,I196d32e3608b4306fda116ad7ab200827c84bb41,Add Response Example for 'Passwd auth with unscoped authorization',MERGED,2016-08-29 09:18:52.000000000,2016-08-29 15:29:26.000000000,2016-08-29 15:29:26.000000000,"[{'_account_id': 3}, {'_account_id': 6482}, {'_account_id': 11022}, {'_account_id': 15905}]","[{'number': 1, 'created': '2016-08-29 09:18:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/643f201391a3ebfa249fa80d64145765dbdb8dac', 'message': ""Add Response Example for 'Passwd auth with unscoped authorization'\n\nAPI link:\nhttp://developer.openstack.org/api-ref/identity/v3/index.html?expanded=password-authentication-with-unscoped-authorization-detail\n\nChange-Id: I196d32e3608b4306fda116ad7ab200827c84bb41\n""}, {'number': 2, 'created': '2016-08-29 09:21:41.000000000', 'files': ['api-ref/source/v3/authenticate-v3.inc'], 'web_link': 'https://opendev.org/openstack/keystone/commit/e332a3ad506a2a70fc22aa5c1d44bde3bdf75502', 'message': ""Add Response Example for 'Passwd auth with unscoped authorization'\n\nAPI link:\nhttp://developer.openstack.org/api-ref/identity/v3/index.html#password-authentication-with-unscoped-authorization\n\nChange-Id: I196d32e3608b4306fda116ad7ab200827c84bb41\n""}]",0,361960,e332a3ad506a2a70fc22aa5c1d44bde3bdf75502,8,4,2,19935,,,0,"Add Response Example for 'Passwd auth with unscoped authorization'

API link:
http://developer.openstack.org/api-ref/identity/v3/index.html#password-authentication-with-unscoped-authorization

Change-Id: I196d32e3608b4306fda116ad7ab200827c84bb41
",git fetch https://review.opendev.org/openstack/keystone refs/changes/60/361960/2 && git format-patch -1 --stdout FETCH_HEAD,['api-ref/source/v3/authenticate-v3.inc'],1,643f201391a3ebfa249fa80d64145765dbdb8dac,,Response Example ---------------- .. literalinclude:: ./samples/admin/auth-password-unscoped-response.json :language: javascript ,,6,0
openstack%2Fdeb-python-requests-unixsocket~debian%2Fnewton~I558729fdb40dc40d4207b553e47c80214dd8d690,openstack/deb-python-requests-unixsocket,debian/newton,I558729fdb40dc40d4207b553e47c80214dd8d690,Add a .gitreview file,MERGED,2016-08-29 15:09:13.000000000,2016-08-29 15:27:23.000000000,2016-08-29 15:27:23.000000000,"[{'_account_id': 3}, {'_account_id': 6476}]","[{'number': 1, 'created': '2016-08-29 15:09:13.000000000', 'files': ['.gitreview'], 'web_link': 'https://opendev.org/openstack/deb-python-requests-unixsocket/commit/2cd989b63222b2baa4e92aa3c2154073a6ceb2d7', 'message': 'Add a .gitreview file\n\nChange-Id: I558729fdb40dc40d4207b553e47c80214dd8d690\n'}]",0,362179,2cd989b63222b2baa4e92aa3c2154073a6ceb2d7,6,2,1,6476,,,0,"Add a .gitreview file

Change-Id: I558729fdb40dc40d4207b553e47c80214dd8d690
",git fetch https://review.opendev.org/openstack/deb-python-requests-unixsocket refs/changes/79/362179/1 && git format-patch -1 --stdout FETCH_HEAD,['.gitreview'],1,2cd989b63222b2baa4e92aa3c2154073a6ceb2d7,,[gerrit] host=review.openstack.org port=29418 project=openstack/deb-python-requests-unixsocket.git defaultbranch=debian/newton ,,5,0
openstack%2Fdeb-python-requests-mock~debian%2Fnewton~Id1d449f08b3f26b8e3c0e95b88a79a0d891b6350,openstack/deb-python-requests-mock,debian/newton,Id1d449f08b3f26b8e3c0e95b88a79a0d891b6350,Add a .gitreview file,MERGED,2016-08-29 15:07:42.000000000,2016-08-29 15:25:33.000000000,2016-08-29 15:25:33.000000000,"[{'_account_id': 3}, {'_account_id': 6476}]","[{'number': 1, 'created': '2016-08-29 15:07:42.000000000', 'files': ['.gitreview'], 'web_link': 'https://opendev.org/openstack/deb-python-requests-mock/commit/fdf6a9208cc5f984ee830fbc333593a90e0373e1', 'message': 'Add a .gitreview file\n\nChange-Id: Id1d449f08b3f26b8e3c0e95b88a79a0d891b6350\n'}]",0,362178,fdf6a9208cc5f984ee830fbc333593a90e0373e1,6,2,1,6476,,,0,"Add a .gitreview file

Change-Id: Id1d449f08b3f26b8e3c0e95b88a79a0d891b6350
",git fetch https://review.opendev.org/openstack/deb-python-requests-mock refs/changes/78/362178/1 && git format-patch -1 --stdout FETCH_HEAD,['.gitreview'],1,fdf6a9208cc5f984ee830fbc333593a90e0373e1,,project=openstack/deb-python-requests-mock.git defaultbranch=debian/newton,project=openstack/requests-mock.git,2,1
openstack%2Fcinder~master~I91d808021995921fa51a9f99e3a1e9c7091af865,openstack/cinder,master,I91d808021995921fa51a9f99e3a1e9c7091af865,Add get_manageable_* methods to Pure drivers,MERGED,2016-08-05 22:51:17.000000000,2016-08-29 15:25:01.000000000,2016-08-28 19:35:38.000000000,"[{'_account_id': 3}, {'_account_id': 2243}, {'_account_id': 4355}, {'_account_id': 6491}, {'_account_id': 9008}, {'_account_id': 9732}, {'_account_id': 10621}, {'_account_id': 10622}, {'_account_id': 11215}, {'_account_id': 11904}, {'_account_id': 12017}, {'_account_id': 12032}, {'_account_id': 12033}, {'_account_id': 12176}, {'_account_id': 12369}, {'_account_id': 12778}, {'_account_id': 12822}, {'_account_id': 12924}, {'_account_id': 13394}, {'_account_id': 14259}, {'_account_id': 14384}, {'_account_id': 14624}, {'_account_id': 14797}, {'_account_id': 15249}, {'_account_id': 15296}, {'_account_id': 15374}, {'_account_id': 15386}, {'_account_id': 15831}, {'_account_id': 15941}, {'_account_id': 16258}, {'_account_id': 16422}, {'_account_id': 16595}, {'_account_id': 16708}, {'_account_id': 16862}, {'_account_id': 16880}, {'_account_id': 16897}, {'_account_id': 16898}, {'_account_id': 17852}, {'_account_id': 18120}, {'_account_id': 18261}, {'_account_id': 18402}, {'_account_id': 18444}, {'_account_id': 18752}, {'_account_id': 19146}, {'_account_id': 19852}, {'_account_id': 19933}, {'_account_id': 21193}, {'_account_id': 21863}, {'_account_id': 21976}, {'_account_id': 22126}, {'_account_id': 22248}, {'_account_id': 22495}]","[{'number': 1, 'created': '2016-08-05 22:51:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/3d291bc0596575955999077585d220e5c59b486e', 'message': 'Add get_manageable_* methods to Pure drivers\n\nThis implements basic support for the new driver methods\nget_manageable_volumes and get_manageable_snapshots. It\nuses the ""client side"" sorting/pagination like the\nreference driver, and to allow support for largest Purity\nREST API version range. Future additions can do some of\nthe sorting and stuff via the REST API on the FlashArray.\n\nWe only mark volumes as unsafe if they are already managed\nor connected to hosts. For snapshots it is only if they\nare already managed by cinder.\n\nChange-Id: I91d808021995921fa51a9f99e3a1e9c7091af865\n'}, {'number': 3, 'created': '2016-08-08 01:55:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/dfa5a11998cc0ffb0636d8559b90f8a011cfdc8b', 'message': 'Add get_manageable_* methods to Pure drivers\n\nThis implements basic support for the new driver methods\nget_manageable_volumes and get_manageable_snapshots. It\nuses the ""client side"" sorting/pagination like the\nreference driver, and to allow support for largest Purity\nREST API version range. Future additions can do some of\nthe sorting and stuff via the REST API on the FlashArray.\n\nWe only mark volumes as unsafe if they are already managed\nor connected to hosts. For snapshots it is only if they\nare already managed by cinder.\n\nChange-Id: I91d808021995921fa51a9f99e3a1e9c7091af865\n'}, {'number': 4, 'created': '2016-08-14 21:04:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/327e06af9841143d1b40de5d21c78a0f2f059e16', 'message': 'Add get_manageable_* methods to Pure drivers\n\nThis implements basic support for the new driver methods\nget_manageable_volumes and get_manageable_snapshots. It\nuses the ""client side"" sorting/pagination like the\nreference driver, and to allow support for largest Purity\nREST API version range. Future additions can do some of\nthe sorting and stuff via the REST API on the FlashArray.\n\nWe only mark volumes as unsafe if they are already managed\nor connected to hosts. For snapshots it is only if they\nare already managed by cinder.\n\nChange-Id: I91d808021995921fa51a9f99e3a1e9c7091af865'}, {'number': 5, 'created': '2016-08-15 21:25:32.000000000', 'files': ['cinder/volume/drivers/pure.py', 'releasenotes/notes/pure-list-mangeable-fed4a1b23212f545.yaml', 'cinder/tests/unit/volume/drivers/test_pure.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/73d2b55352e5924fe4fa93548b549c00f63ad12e', 'message': 'Add get_manageable_* methods to Pure drivers\n\nThis implements basic support for the new driver methods\nget_manageable_volumes and get_manageable_snapshots. It\nuses the ""client side"" sorting/pagination like the\nreference driver, and to allow support for largest Purity\nREST API version range. Future additions can do some of\nthe sorting and stuff via the REST API on the FlashArray.\n\nWe only mark volumes as unsafe if they are already managed\nor connected to hosts. For snapshots it is only if they\nare already managed by cinder.\n\nChange-Id: I91d808021995921fa51a9f99e3a1e9c7091af865'}]",19,351944,73d2b55352e5924fe4fa93548b549c00f63ad12e,149,52,4,12924,,,0,"Add get_manageable_* methods to Pure drivers

This implements basic support for the new driver methods
get_manageable_volumes and get_manageable_snapshots. It
uses the ""client side"" sorting/pagination like the
reference driver, and to allow support for largest Purity
REST API version range. Future additions can do some of
the sorting and stuff via the REST API on the FlashArray.

We only mark volumes as unsafe if they are already managed
or connected to hosts. For snapshots it is only if they
are already managed by cinder.

Change-Id: I91d808021995921fa51a9f99e3a1e9c7091af865",git fetch https://review.opendev.org/openstack/cinder refs/changes/44/351944/5 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/volume/drivers/pure.py', 'cinder/tests/unit/volume/drivers/test_pure.py']",2,3d291bc0596575955999077585d220e5c59b486e,bp/pure-list-manageable,"from cinder.tests.unit import fake_snapshotMANAGEABLE_PURE_VOLS = [ { 'name': 'myVol1', 'serial': '8E9C7E588B16C1EA00048CCA', 'size': 3221225472, 'created': '2016-08-05T17:26:34Z', 'source': None, }, { 'name': 'myVol2', 'serial': '8E9C7E588B16C1EA00048CCB', 'size': 3221225472, 'created': '2016-08-05T17:26:34Z', 'source': None, }, { 'name': 'myVol3', 'serial': '8E9C7E588B16C1EA00048CCD', 'size': 3221225472, 'created': '2016-08-05T17:26:34Z', 'source': None, } ] MANAGEABLE_PURE_VOL_REFS = [ { 'reference': 'myVol1', 'size': 3, 'safe_to_manage': True, 'reason_not_safe': None, 'cinder_id': None, 'extra_info': None, }, { 'reference': 'myVol2', 'size': 3, 'safe_to_manage': True, 'reason_not_safe': None, 'cinder_id': None, 'extra_info': None, }, { 'reference': 'myVol3', 'size': 3, 'safe_to_manage': True, 'reason_not_safe': None, 'cinder_id': None, 'extra_info': None, } ] MANAGEABLE_PURE_SNAPS = [ { 'name': 'volume-fd33de6e-56f6-452d-a7b6-451c11089a9f-cinder.snap1', 'serial': '8E9C7E588B16C1EA00048CCA', 'size': 3221225472, 'created': '2016-08-05T17:26:34Z', 'source': 'volume-fd33de6e-56f6-452d-a7b6-451c11089a9f-cinder', }, { 'name': 'volume-fd33de6e-56f6-452d-a7b6-451c11089a9f-cinder.snap2', 'serial': '8E9C7E588B16C1EA00048CCB', 'size': 4221225472, 'created': '2016-08-05T17:26:34Z', 'source': 'volume-fd33de6e-56f6-452d-a7b6-451c11089a9f-cinder', }, { 'name': 'volume-fd33de6e-56f6-452d-a7b6-451c11089a9f-cinder.snap3', 'serial': '8E9C7E588B16C1EA00048CCD', 'size': 5221225472, 'created': '2016-08-05T17:26:34Z', 'source': 'volume-fd33de6e-56f6-452d-a7b6-451c11089a9f-cinder', } ] MANAGEABLE_PURE_SNAP_REFS = [ { 'reference': MANAGEABLE_PURE_SNAPS[0]['name'], 'size': 3, 'safe_to_manage': True, 'reason_not_safe': None, 'cinder_id': None, 'extra_info': None, 'source_reference': MANAGEABLE_PURE_SNAPS[0]['source'] }, { 'reference': MANAGEABLE_PURE_SNAPS[1]['name'], 'size': 4, 'safe_to_manage': True, 'reason_not_safe': None, 'cinder_id': None, 'extra_info': None, 'source_reference': MANAGEABLE_PURE_SNAPS[1]['source'] }, { 'reference': MANAGEABLE_PURE_SNAPS[2]['name'], 'size': 5, 'safe_to_manage': True, 'reason_not_safe': None, 'cinder_id': None, 'extra_info': None, 'source_reference': MANAGEABLE_PURE_SNAPS[2]['source'] } ] def _test_get_manageable_things(self, pure_objs=MANAGEABLE_PURE_VOLS, expected_refs=MANAGEABLE_PURE_VOL_REFS, pure_hosts=list(), cinder_objs=list(), is_snapshot=False): self.array.list_volumes.return_value = pure_objs self.array.list_hosts.return_value = pure_hosts marker = mock.Mock() limit = mock.Mock() offset = mock.Mock() sort_keys = mock.Mock() sort_dirs = mock.Mock() with mock.patch('cinder.volume.utils.paginate_entries_list') as mpage: if is_snapshot: test_func = self.driver.get_manageable_snapshots else: test_func = self.driver.get_manageable_volumes test_func(cinder_objs, marker, limit, offset, sort_keys, sort_dirs) mpage.assert_called_once_with( expected_refs, marker, limit, offset, sort_keys, sort_dirs ) def test_get_manageable_volumes(self,): """"""Default success case. Given a list of pure volumes from the REST API, give back a list of volume references. """""" self._test_get_manageable_things(pure_hosts=[PURE_HOST]) def test_get_manageable_volumes_connected_vol(self): """"""Make sure volumes connected to hosts are flagged as unsafe."""""" connected_host = deepcopy(PURE_HOST) connected_host['name'] = 'host2' connected_host['vol'] = MANAGEABLE_PURE_VOLS[0]['name'] pure_hosts = [PURE_HOST, connected_host] expected_refs = deepcopy(MANAGEABLE_PURE_VOL_REFS) expected_refs[0]['safe_to_manage'] = False expected_refs[0]['reason_not_safe'] = 'Volume connected to host host2.' self._test_get_manageable_things(expected_refs=expected_refs, pure_hosts=pure_hosts) def test_get_manageable_volumes_already_managed(self): """"""Make sure volumes already owned by cinder are flagged as unsafe."""""" cinder_vol = fake_volume.fake_volume_obj(mock.MagicMock()) cinder_vol.id = VOLUME_ID cinders_vols = [cinder_vol] # Have one of our vol names match up with the existing cinder volume purity_vols = deepcopy(MANAGEABLE_PURE_VOLS) purity_vols[0]['name'] = 'volume-' + VOLUME_ID + '-cinder' expected_refs = deepcopy(MANAGEABLE_PURE_VOL_REFS) expected_refs[0]['reference'] = purity_vols[0]['name'] expected_refs[0]['safe_to_manage'] = False expected_refs[0]['reason_not_safe'] = 'Volume already managed.' expected_refs[0]['cinder_id'] = VOLUME_ID self._test_get_manageable_things(pure_objs=purity_vols, expected_refs=expected_refs, pure_hosts=[PURE_HOST], cinder_objs=cinders_vols) def test_get_manageable_volumes_no_pure_volumes(self): """"""Expect no refs to be found if no volumes are on Purity."""""" self._test_get_manageable_things(pure_objs=[], expected_refs=[], pure_hosts=[PURE_HOST]) def test_get_manageable_volumes_no_hosts(self): """"""Success case with no hosts on Purity."""""" self._test_get_manageable_things(pure_hosts=[]) def test_get_manageable_snapshots(self): """"""Default success case. Given a list of pure volumes from the REST API, give back a list of volume references. """""" self._test_get_manageable_things( pure_objs=MANAGEABLE_PURE_SNAPS, expected_refs=MANAGEABLE_PURE_SNAP_REFS, pure_hosts=[PURE_HOST], is_snapshot=True ) def test_get_manageable_snapshots_already_managed(self): """"""Make sure snaps already owned by cinder are flagged as unsafe."""""" cinder_vol = fake_volume.fake_volume_obj(mock.MagicMock()) cinder_vol.id = VOLUME_ID cinder_snap = fake_snapshot.fake_snapshot_obj(mock.MagicMock()) cinder_snap.id = SNAPSHOT_ID cinder_snap.volume = cinder_vol cinder_snaps = [cinder_snap] purity_snaps = deepcopy(MANAGEABLE_PURE_SNAPS) purity_snaps[0]['name'] = 'volume-%s-cinder.snapshot-%s' % ( VOLUME_ID, SNAPSHOT_ID ) expected_refs = deepcopy(MANAGEABLE_PURE_SNAP_REFS) expected_refs[0]['reference'] = purity_snaps[0]['name'] expected_refs[0]['safe_to_manage'] = False expected_refs[0]['reason_not_safe'] = 'Snapshot already managed.' expected_refs[0]['cinder_id'] = SNAPSHOT_ID self._test_get_manageable_things( pure_objs=purity_snaps, expected_refs=expected_refs, cinder_objs=cinder_snaps, pure_hosts=[PURE_HOST], is_snapshot=True ) def test_get_manageable_snapshots_no_pure_snapshots(self): """"""Expect no refs to be found if no volumes are on Purity."""""" self._test_get_manageable_things(pure_objs=[], expected_refs=[], pure_hosts=[PURE_HOST], is_snapshot=True) ",,332,2
openstack%2Fneutron~stable%2Fmitaka~Iec171efe8b64f8a6dc6cb003b97c11667c5e0048,openstack/neutron,stable/mitaka,Iec171efe8b64f8a6dc6cb003b97c11667c5e0048,Allow auto-addressed ips deletion on port update,MERGED,2016-08-01 15:13:04.000000000,2016-08-29 15:24:46.000000000,2016-08-25 19:57:28.000000000,"[{'_account_id': 3}, {'_account_id': 1131}, {'_account_id': 5170}, {'_account_id': 7448}, {'_account_id': 7787}, {'_account_id': 9656}, {'_account_id': 9681}, {'_account_id': 9732}, {'_account_id': 12912}, {'_account_id': 13768}, {'_account_id': 14208}, {'_account_id': 16376}]","[{'number': 1, 'created': '2016-08-01 15:13:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e0c6441f5b7e7a648195bf2bd6843614248c28c2', 'message': ""Allow auto-addressed ips deletion on port update\n\nBy default ips for auto-addressed subnets can not be removed from port\nusing port_update workflow. But during subnet_delete it has to be done\nvia update_port to make sure that ipam drivers received appropriate call\nto deallocate ip addresses prior to subnet deletion.\n\n'fixed_ips' property is tweeked to allow deletion ips from\nauto-addressed subnet. 'delete_subnet' boolean is added to mark subnet\nthat is going to be deleted. This flag is analysed in\n_get_changed_ips_for_port to skip re-adding slaac subnets for the port.\n\nManually resolved conflicts.\n\nCloses-Bug: #1564335\nChange-Id: Iec171efe8b64f8a6dc6cb003b97c11667c5e0048\n""}, {'number': 2, 'created': '2016-08-02 17:09:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/d99ec264250772b03a29113069f23cc99cf92900', 'message': ""Allow auto-addressed ips deletion on port update\n\nBy default ips for auto-addressed subnets can not be removed from port\nusing port_update workflow. But during subnet_delete it has to be done\nvia update_port to make sure that ipam drivers received appropriate call\nto deallocate ip addresses prior to subnet deletion.\n\n'fixed_ips' property is tweeked to allow deletion ips from\nauto-addressed subnet. 'delete_subnet' boolean is added to mark subnet\nthat is going to be deleted. This flag is analysed in\n_get_changed_ips_for_port to skip re-adding slaac subnets for the port.\n\nManually resolved conflicts.\n\nCloses-Bug: #1564335\nChange-Id: Iec171efe8b64f8a6dc6cb003b97c11667c5e0048\n""}, {'number': 3, 'created': '2016-08-16 13:42:38.000000000', 'files': ['neutron/tests/unit/db/test_ipam_backend_mixin.py', 'neutron/tests/unit/plugins/ml2/test_plugin.py', 'neutron/db/ipam_backend_mixin.py', 'neutron/plugins/ml2/plugin.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/cf3009a984b01eb90046c8c7513e531b7ab63762', 'message': ""Allow auto-addressed ips deletion on port update\n\nBy default ips for auto-addressed subnets can not be removed from port\nusing port_update workflow. But during subnet_delete it has to be done\nvia update_port to make sure that ipam drivers received appropriate call\nto deallocate ip addresses prior to subnet deletion.\n\n'fixed_ips' property is tweeked to allow deletion ips from\nauto-addressed subnet. 'delete_subnet' boolean is added to mark subnet\nthat is going to be deleted. This flag is analysed in\n_get_changed_ips_for_port to skip re-adding slaac subnets for the port.\n\nManually resolved conflicts:\n    neutron/tests/unit/plugins/ml2/test_plugin.py\n\nCloses-Bug: #1564335\nChange-Id: Iec171efe8b64f8a6dc6cb003b97c11667c5e0048\nCherry-picked-From: dc19411ebf2cab7075dd5abe809797fb7253757c\n""}]",2,349555,cf3009a984b01eb90046c8c7513e531b7ab63762,28,12,3,21198,,,0,"Allow auto-addressed ips deletion on port update

By default ips for auto-addressed subnets can not be removed from port
using port_update workflow. But during subnet_delete it has to be done
via update_port to make sure that ipam drivers received appropriate call
to deallocate ip addresses prior to subnet deletion.

'fixed_ips' property is tweeked to allow deletion ips from
auto-addressed subnet. 'delete_subnet' boolean is added to mark subnet
that is going to be deleted. This flag is analysed in
_get_changed_ips_for_port to skip re-adding slaac subnets for the port.

Manually resolved conflicts:
    neutron/tests/unit/plugins/ml2/test_plugin.py

Closes-Bug: #1564335
Change-Id: Iec171efe8b64f8a6dc6cb003b97c11667c5e0048
Cherry-picked-From: dc19411ebf2cab7075dd5abe809797fb7253757c
",git fetch https://review.opendev.org/openstack/neutron refs/changes/55/349555/3 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/unit/db/test_ipam_backend_mixin.py', 'neutron/tests/unit/plugins/ml2/test_plugin.py', 'neutron/db/ipam_backend_mixin.py', 'neutron/plugins/ml2/plugin.py']",4,e0c6441f5b7e7a648195bf2bd6843614248c28c2,bug/1564335," fixed_ips = [{'subnet_id': ip.subnet_id, 'ip_address': ip.ip_address} for ip in a.port.fixed_ips if ip.subnet_id != id] # By default auto-addressed ips are not removed from port # on port update, so mark subnet with 'delete_subnet' flag # to force ip deallocation on port update. if is_auto_addr_subnet: fixed_ips.append({'subnet_id': id, 'delete_subnet': True}) data = {attributes.PORT: {'fixed_ips': fixed_ips}}"," data = {attributes.PORT: {'fixed_ips': [{'subnet_id': ip.subnet_id, 'ip_address': ip.ip_address} for ip in a.port.fixed_ips if ip.subnet_id != id]}}",87,15
openstack%2Fdeb-python-rfc3986~debian%2Fnewton~Ia452ab3142bf3b13b925670e612beb4299bd195f,openstack/deb-python-rfc3986,debian/newton,Ia452ab3142bf3b13b925670e612beb4299bd195f,Add a .gitreview file,MERGED,2016-08-29 15:04:22.000000000,2016-08-29 15:24:30.000000000,2016-08-29 15:24:30.000000000,"[{'_account_id': 3}, {'_account_id': 6476}]","[{'number': 1, 'created': '2016-08-29 15:04:22.000000000', 'files': ['.gitreview'], 'web_link': 'https://opendev.org/openstack/deb-python-rfc3986/commit/a070550de23276a52268db856c67e4454190aea6', 'message': 'Add a .gitreview file\n\nChange-Id: Ia452ab3142bf3b13b925670e612beb4299bd195f\n'}]",0,362175,a070550de23276a52268db856c67e4454190aea6,6,2,1,6476,,,0,"Add a .gitreview file

Change-Id: Ia452ab3142bf3b13b925670e612beb4299bd195f
",git fetch https://review.opendev.org/openstack/deb-python-rfc3986 refs/changes/75/362175/1 && git format-patch -1 --stdout FETCH_HEAD,['.gitreview'],1,a070550de23276a52268db856c67e4454190aea6,,[gerrit] host=review.openstack.org port=29418 project=openstack/deb-python-rfc3986.git defaultbranch=debian/newton ,,5,0
openstack%2Fdeb-python-requests-kerberos~debian%2Fnewton~I41d5c478f31f09c76511d640866b78600ef0b599,openstack/deb-python-requests-kerberos,debian/newton,I41d5c478f31f09c76511d640866b78600ef0b599,Add a .gitreview file,MERGED,2016-08-29 15:06:03.000000000,2016-08-29 15:24:25.000000000,2016-08-29 15:24:25.000000000,"[{'_account_id': 3}, {'_account_id': 6476}]","[{'number': 1, 'created': '2016-08-29 15:06:03.000000000', 'files': ['.gitreview'], 'web_link': 'https://opendev.org/openstack/deb-python-requests-kerberos/commit/477ee6510b11c454cf5c4d113141131d7b0b8a06', 'message': 'Add a .gitreview file\n\nChange-Id: I41d5c478f31f09c76511d640866b78600ef0b599\n'}]",0,362177,477ee6510b11c454cf5c4d113141131d7b0b8a06,6,2,1,6476,,,0,"Add a .gitreview file

Change-Id: I41d5c478f31f09c76511d640866b78600ef0b599
",git fetch https://review.opendev.org/openstack/deb-python-requests-kerberos refs/changes/77/362177/1 && git format-patch -1 --stdout FETCH_HEAD,['.gitreview'],1,477ee6510b11c454cf5c4d113141131d7b0b8a06,,[gerrit] host=review.openstack.org port=29418 project=openstack/deb-python-requests-kerberos.git defaultbranch=debian/newton ,,5,0
openstack%2Fsolum-dashboard~master~Ib75af4857eb745251ba9e0d22f1a1d1a82634507,openstack/solum-dashboard,master,Ib75af4857eb745251ba9e0d22f1a1d1a82634507,Fix pep8 error,MERGED,2016-08-25 13:39:30.000000000,2016-08-29 15:24:17.000000000,2016-08-29 15:24:17.000000000,"[{'_account_id': 3}, {'_account_id': 2506}]","[{'number': 1, 'created': '2016-08-25 13:39:30.000000000', 'files': ['solumdashboard/languagepacks/tables.py'], 'web_link': 'https://opendev.org/openstack/solum-dashboard/commit/f31a21ddb79ca0fe06f8acd5425ab114feb39372', 'message': 'Fix pep8 error\n\nH238  old style class declaration, use new style (inherit from `object`)\n\nChange-Id: Ib75af4857eb745251ba9e0d22f1a1d1a82634507\n'}]",0,360553,f31a21ddb79ca0fe06f8acd5425ab114feb39372,6,2,1,14107,,,0,"Fix pep8 error

H238  old style class declaration, use new style (inherit from `object`)

Change-Id: Ib75af4857eb745251ba9e0d22f1a1d1a82634507
",git fetch https://review.opendev.org/openstack/solum-dashboard refs/changes/53/360553/1 && git format-patch -1 --stdout FETCH_HEAD,['solumdashboard/languagepacks/tables.py'],1,f31a21ddb79ca0fe06f8acd5425ab114feb39372,, class Meta(object):, class Meta:,1,1
openstack%2Fkeystone~master~I61d2e0fb896c2ea940e29ab58bf11817b0b875e4,openstack/keystone,master,I61d2e0fb896c2ea940e29ab58bf11817b0b875e4,Fix formatting strings when using multiple variables,MERGED,2016-08-29 03:57:01.000000000,2016-08-29 15:23:59.000000000,2016-08-29 15:23:59.000000000,"[{'_account_id': 3}, {'_account_id': 6482}, {'_account_id': 11022}, {'_account_id': 19554}, {'_account_id': 20466}]","[{'number': 1, 'created': '2016-08-29 03:57:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/a06931bafe647da504aa11df6cfc0d21745fb214', 'message': 'Fix formatting strings when using nultiple variables\n\nFollowing OpenStack Style Guidelines:[H703]\nhttp://docs.openstack.org/developer/hacking/#internationalization-i18n-strings\nUsing multiple variables for formmatting strings is\nnot clear as using explicit dictionaries and can hide\nerrors during refactoring.\n\nChange-Id: I61d2e0fb896c2ea940e29ab58bf11817b0b875e4\n'}, {'number': 2, 'created': '2016-08-29 04:38:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/7bc76959a1f11e0782ff6b092506584344825f19', 'message': 'Fix formatting strings when using nultiple variables\n\nFollowing OpenStack Style Guidelines:[H703]\nhttp://docs.openstack.org/developer/hacking/#internationalization-i18n-strings\nUsing multiple variables for formmatting strings is\nnot clear as using explicit dictionaries and can hide\nerrors during refactoring.\n\nChange-Id: I61d2e0fb896c2ea940e29ab58bf11817b0b875e4\n'}, {'number': 3, 'created': '2016-08-29 04:53:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/9c705f8bced2285762260971e028071909de9f51', 'message': 'Fix formatting strings when using multiple variables\n\nFollowing OpenStack Style Guidelines:[H703]\nhttp://docs.openstack.org/developer/hacking/#internationalization-i18n-strings\n\nUsing multiple variables for formmatting strings\nis not clear as using explicit dictionaries and\ncan hide errors during refactoring.\n\nChange-Id: I61d2e0fb896c2ea940e29ab58bf11817b0b875e4\n'}, {'number': 4, 'created': '2016-08-29 05:16:57.000000000', 'files': ['keystone/common/openssl.py', 'keystone/common/utils.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/618d9cac95fc798db5ddc58d1a54eb5ff8d009e8', 'message': 'Fix formatting strings when using multiple variables\n\nFollowing OpenStack Style Guidelines:[H703]\nhttp://docs.openstack.org/developer/hacking/#internationalization-i18n-strings\n\nUsing multiple variables for formmatting strings\nis not clear as using explicit dictionaries and\ncan hide errors during refactoring.\n\nChange-Id: I61d2e0fb896c2ea940e29ab58bf11817b0b875e4\n'}]",9,361822,618d9cac95fc798db5ddc58d1a54eb5ff8d009e8,22,5,4,19554,,,0,"Fix formatting strings when using multiple variables

Following OpenStack Style Guidelines:[H703]
http://docs.openstack.org/developer/hacking/#internationalization-i18n-strings

Using multiple variables for formmatting strings
is not clear as using explicit dictionaries and
can hide errors during refactoring.

Change-Id: I61d2e0fb896c2ea940e29ab58bf11817b0b875e4
",git fetch https://review.opendev.org/openstack/keystone refs/changes/22/361822/4 && git format-patch -1 --stdout FETCH_HEAD,"['keystone/common/openssl.py', 'keystone/common/utils.py']",2,a06931bafe647da504aa11df6cfc0d21745fb214,fix_format," msg = _LE(""Malformed endpoint - %(url)r is not a string"") LOG.error(msg, {""url"": url}) msg = _LE(""Malformed endpoint %(url)s - unknown key "" ""%(keyerror)s"") LOG.error(msg, {""url"": url, ""keyerror"": e}) msg = _LE(""Malformed endpoint '%(url)s'. The following type error "" ""occurred during string substitution: %(typeerror)s"") LOG.error(msg, {""url"": url, ""typeerror"": e}) msg = _LE(""Malformed endpoint %s - incomplete format "" ""(are you missing a type notifier ?)"") LOG.error(msg, url)"," LOG.error(_LE('Malformed endpoint - %(url)r is not a string'), {""url"": url}) LOG.error(_LE(""Malformed endpoint %(url)s - unknown key "" ""%(keyerror)s""), {""url"": url, ""keyerror"": e}) LOG.error(_LE(""Malformed endpoint '%(url)s'. The following type error "" ""occurred during string substitution: %(typeerror)s""), {""url"": url, ""typeerror"": e}) LOG.error(_LE(""Malformed endpoint %s - incomplete format "" ""(are you missing a type notifier ?)""), url)",17,16
openstack%2Fkeystone~master~I6cb8309e254ec9b4d7bae814b15d0f4c064a4fc6,openstack/keystone,master,I6cb8309e254ec9b4d7bae814b15d0f4c064a4fc6,Add Response Example for 'Create credential' API,MERGED,2016-08-29 09:03:44.000000000,2016-08-29 15:22:58.000000000,2016-08-29 15:22:58.000000000,"[{'_account_id': 3}, {'_account_id': 6482}, {'_account_id': 11022}, {'_account_id': 15905}]","[{'number': 1, 'created': '2016-08-29 09:03:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/24c40914447f18b8a4dc7f995a148157c215e217', 'message': ""Add Response Example for 'Update credential' API\n\nChange-Id: I6cb8309e254ec9b4d7bae814b15d0f4c064a4fc6\n""}, {'number': 2, 'created': '2016-08-29 09:48:04.000000000', 'files': ['api-ref/source/v3/credentials.inc'], 'web_link': 'https://opendev.org/openstack/keystone/commit/a8dbe9b4009ad1cb2910fa09bb870ca1faf69dcc', 'message': ""Add Response Example for 'Create credential' API\n\nChange-Id: I6cb8309e254ec9b4d7bae814b15d0f4c064a4fc6\n""}]",1,361954,a8dbe9b4009ad1cb2910fa09bb870ca1faf69dcc,8,4,2,19935,,,0,"Add Response Example for 'Create credential' API

Change-Id: I6cb8309e254ec9b4d7bae814b15d0f4c064a4fc6
",git fetch https://review.opendev.org/openstack/keystone refs/changes/54/361954/2 && git format-patch -1 --stdout FETCH_HEAD,['api-ref/source/v3/credentials.inc'],1,24c40914447f18b8a4dc7f995a148157c215e217,,Response Example ---------------- .. literalinclude:: ./samples/admin/credential-create-response.json :language: javascript ,,6,0
openstack%2Fpuppet-tripleo~master~I19b56c93db82948fb0498a4c9851b522c81946f8,openstack/puppet-tripleo,master,I19b56c93db82948fb0498a4c9851b522c81946f8,Removing WARNING: line has more than 140 characters in puppet-tripleo profiles,MERGED,2016-08-11 13:06:21.000000000,2016-08-29 15:21:14.000000000,2016-08-29 15:21:14.000000000,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 3153}, {'_account_id': 10873}, {'_account_id': 20775}]","[{'number': 1, 'created': '2016-08-11 13:06:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/c316091217876cfafaee53a06fd49b85f9bd17e8', 'message': ""Removing WARNING: line has more than 140 characters in puppet-tripleo profiles\n\nSome link checks are returning:\nWARNING: line has more than 140 characters in puppet-tripleo profiles\n\nThis patch will remove those warnings adding by \\'s\n\nChange-Id: I19b56c93db82948fb0498a4c9851b522c81946f8\n""}, {'number': 2, 'created': '2016-08-11 14:43:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/eb29b17ff426960b4db25a1b00e460b11c43f8e5', 'message': ""Removing WARNING: line has more than 140 characters in puppet-tripleo profiles\n\nSome lint checks are returning:\nWARNING: line has more than 140 characters in puppet-tripleo profiles\n\nThis patch will remove those warnings by adding \\'s\n\nChange-Id: I19b56c93db82948fb0498a4c9851b522c81946f8\n""}, {'number': 3, 'created': '2016-08-11 15:25:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/cc544597c6e5d1f63da1ea850cbc32dd80fd359d', 'message': ""Removing WARNING: line has more than 140 characters in puppet-tripleo profiles\n\nSome lint checks are returning:\nWARNING: line has more than 140 characters in puppet-tripleo profiles\n\nThis patch will remove those warnings by adding \\'s\n\nChange-Id: I19b56c93db82948fb0498a4c9851b522c81946f8\n""}, {'number': 4, 'created': '2016-08-11 19:11:53.000000000', 'files': ['manifests/haproxy.pp', 'manifests/profile/base/cinder/volume.pp', 'manifests/profile/base/ceilometer/expirer.pp', 'manifests/profile/base/snmp.pp', 'manifests/haproxy/endpoint.pp', 'manifests/profile/pacemaker/database/mysql.pp'], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/ea752f3527746e6b7af2c79071a46ade8bceef61', 'message': ""Removing WARNING: line has more than 140 characters in puppet-tripleo profiles\n\nSome lint checks are returning:\nWARNING: line has more than 140 characters in puppet-tripleo profiles\n\nThis patch will remove those warnings by adding \\'s\n\nChange-Id: I19b56c93db82948fb0498a4c9851b522c81946f8\n""}]",0,354054,ea752f3527746e6b7af2c79071a46ade8bceef61,27,5,4,20775,,,0,"Removing WARNING: line has more than 140 characters in puppet-tripleo profiles

Some lint checks are returning:
WARNING: line has more than 140 characters in puppet-tripleo profiles

This patch will remove those warnings by adding \'s

Change-Id: I19b56c93db82948fb0498a4c9851b522c81946f8
",git fetch https://review.opendev.org/openstack/puppet-tripleo refs/changes/54/354054/1 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/haproxy.pp', 'manifests/profile/base/cinder/volume.pp', 'manifests/profile/base/ceilometer/expirer.pp', 'manifests/profile/base/snmp.pp', 'manifests/haproxy/endpoint.pp', 'manifests/profile/pacemaker/database/mysql.pp']",6,c316091217876cfafaee53a06fd49b85f9bd17e8,puppet-cleanup," command => ""/bin/touch /root/.my.cnf && /bin/echo\ \""UPDATE mysql.user\ SET Password = PASSWORD('${mysql_root_password}')\ WHERE user = 'root';\ flush privileges;\"" | /bin/mysql --defaults-extra-file=/root/.my.cnf -u root"","," command => ""/bin/touch /root/.my.cnf && /bin/echo \""UPDATE mysql.user SET Password = PASSWORD('${mysql_root_password}') WHERE user = 'root'; flush privileges;\"" | /bin/mysql --defaults-extra-file=/root/.my.cnf -u root"",",34,7
openstack%2Fkeystone~master~I0a4fefe34a0c6912200d256e7bc3cbef66b34a16,openstack/keystone,master,I0a4fefe34a0c6912200d256e7bc3cbef66b34a16,Make all token provider behave the same with trusts,MERGED,2016-08-03 17:29:01.000000000,2016-08-29 15:19:41.000000000,2016-08-18 23:24:59.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 5046}, {'_account_id': 6482}, {'_account_id': 13063}, {'_account_id': 17445}]","[{'number': 1, 'created': '2016-08-03 17:29:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/adfaf30bc1eae726efde729acc2da2aa8e9da6d3', 'message': 'Make all token provider behave the same with trusts\n\nChange-Id: I0a4fefe34a0c6912200d256e7bc3cbef66b34a16\n'}, {'number': 2, 'created': '2016-08-03 20:51:30.000000000', 'files': ['keystone/models/revoke_model.py', 'keystone/token/provider.py', 'keystone/token/providers/common.py', 'keystone/tests/unit/test_v3_auth.py', 'keystone/tests/unit/test_auth.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/3efd271fbc579b9510c13507092d1aca6ca88e96', 'message': 'Make all token provider behave the same with trusts\n\nChange-Id: I0a4fefe34a0c6912200d256e7bc3cbef66b34a16\n'}]",12,350704,3efd271fbc579b9510c13507092d1aca6ca88e96,15,6,2,5046,,,0,"Make all token provider behave the same with trusts

Change-Id: I0a4fefe34a0c6912200d256e7bc3cbef66b34a16
",git fetch https://review.opendev.org/openstack/keystone refs/changes/04/350704/2 && git format-patch -1 --stdout FETCH_HEAD,"['keystone/models/revoke_model.py', 'keystone/token/provider.py', 'keystone/token/providers/common.py', 'keystone/tests/unit/test_v3_auth.py', 'keystone/tests/unit/test_auth.py']",5,adfaf30bc1eae726efde729acc2da2aa8e9da6d3,," def test_validate_v3_trust_scoped_token_against_v2_succeeds(self): new_trust = self.create_trust(self.sample_data, self.trustor['name']) auth_response = self.fetch_v3_token_from_trust(new_trust, self.trustee) trust_token = auth_response.headers['X-Subject-Token'] self.controller.validate_token(self.make_request(is_admin=True), trust_token) exception.Forbidden, time = datetime.datetime.utcnow() with freezegun.freeze_time(time) as frozen_time: # NOTE(lbragstad): freezegun attempts to patch all things that # issue a time in Python, but it doesn't patch `calendar`. The # `oslo_utils.timeutils` module uses `calendar` which ends up # returning non-patch datetimes. Override oslo's time to use the # frozen_time context we want it to use. timeutils.set_time_override(frozen_time.time_to_freeze) unscoped_token = self.get_unscoped_token(self.trustor['name']) new_trust = self.create_trust(self.sample_data, self.trustor['name']) request = self._create_auth_request( unscoped_token['access']['token']['id']) trust_token_resp = self.fetch_v2_token_from_trust(new_trust) trust_scoped_token_id = trust_token_resp['access']['token']['id'] self.controller.validate_token( self.make_request(is_admin=True), token_id=trust_scoped_token_id ) trust_id = new_trust['id'] frozen_time.tick(delta=datetime.timedelta(seconds=1)) self.trust_controller.delete_trust(request, trust_id=trust_id) self.assertRaises( exception.TokenNotFound, self.controller.validate_token, self.make_request(is_admin=True), token_id=trust_scoped_token_id ) def test_validate_trust_scoped_token_against_v2(self): new_trust = self.create_trust(self.sample_data, self.trustor['name']) trust_token_resp = self.fetch_v2_token_from_trust(new_trust) trust_scoped_token_id = trust_token_resp['access']['token']['id'] self.controller.validate_token(self.make_request(is_admin=True), token_id=trust_scoped_token_id) def test_trust_get_token_fails_if_trustee_disabled(self): # why is this still different than the UUID case?!?!"," exception.Unauthorized, # NOTE(lbragstad): This test doens't really make much sense because we # can't validate trust-scoped tokens against the v2.0 API. unscoped_token = self.get_unscoped_token(self.trustor['name']) new_trust = self.create_trust(self.sample_data, self.trustor['name']) request = self._create_auth_request( unscoped_token['access']['token']['id']) self.fetch_v2_token_from_trust(new_trust) trust_id = new_trust['id'] tokens = self.token_provider_api._persistence._list_tokens( self.trustor['id'], trust_id=trust_id) self.assertEqual(1, len(tokens)) self.trust_controller.delete_trust(request, trust_id=trust_id) tokens = self.token_provider_api._persistence._list_tokens( self.trustor['id'], trust_id=trust_id) self.assertEqual(0, len(tokens)) def test_delete_trust_revokes_token(self): # NOTE(lbragstad): This test doens't really make much sense because we # can't validate trust-scoped tokens against the v2.0 API. This was # originally validating that UUID tokens were removed from the backend # when a trust was deleted. Fernet tokens aren't persisted in the # backend, so I guess the equivalent test through the API is to make # sure a trust-scoped token isn't valid after a trust is deleted. unscoped_token = self.get_unscoped_token(self.trustor['name']) new_trust = self.create_trust(self.sample_data, self.trustor['name']) request = self._create_auth_request( unscoped_token['access']['token']['id']) trust_token_resp = self.fetch_v2_token_from_trust(new_trust) trust_scoped_token_id = trust_token_resp['access']['token']['id'] # TODO(lbragstad): Make this a valid operation in the future? self.assertRaises( exception.Unauthorized, self.controller.validate_token, self.make_request(is_admin=True), token_id=trust_scoped_token_id ) trust_id = new_trust['id'] self.trust_controller.delete_trust(request, trust_id=trust_id) self.assertRaises( exception.Unauthorized, self.controller.validate_token, self.make_request(is_admin=True), token_id=trust_scoped_token_id ) def test_trust_get_token_fails_if_trustee_disabled(self):",87,66
openstack%2Fpython-tripleoclient~master~I3acbfd7900177fc2159448b839b71599e8e51d5f,openstack/python-tripleoclient,master,I3acbfd7900177fc2159448b839b71599e8e51d5f,Use Mistral for baremetal boot configuration,MERGED,2016-08-19 16:49:42.000000000,2016-08-29 15:18:21.000000000,2016-08-29 15:18:21.000000000,"[{'_account_id': 3}, {'_account_id': 7065}, {'_account_id': 9712}]","[{'number': 1, 'created': '2016-08-19 16:49:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/59ff9a16b58607107bf5a77451d6e563ec1d3096', 'message': ""Use Mistral for baremetal boot configuration\n\nThis updates the 'baremetal configure boot' command to work with the\nnew Mistral workflow.\n\nChange-Id: I3acbfd7900177fc2159448b839b71599e8e51d5f\nDepends-On: I5ba0a3710012c44822dd3b8e69662bbef04d3787\nRelated-Bug: #1595205\n""}, {'number': 2, 'created': '2016-08-19 16:52:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/492b837cb9cc5138c3882c6beccde5a971bb267b', 'message': ""Use Mistral for baremetal boot configuration\n\nThis updates the 'baremetal configure boot' command to work with the\nnew Mistral workflow. The Root Device tests have migrated to\ntripleo-common where the main code now lives as a Mistral action (see\ndependent patch).\n\nChange-Id: I3acbfd7900177fc2159448b839b71599e8e51d5f\nDepends-On: I5ba0a3710012c44822dd3b8e69662bbef04d3787\nRelated-Bug: #1595205\n""}, {'number': 3, 'created': '2016-08-25 19:48:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/beb828a93f0a02728a15a04f5251e395d931c5b6', 'message': ""Use Mistral for baremetal boot configuration\n\nThis updates the 'baremetal configure boot' command to work with the\nnew Mistral workflow. The Root Device tests have migrated to\ntripleo-common where the main code now lives as a Mistral action (see\ndependent patch).\n\nChange-Id: I3acbfd7900177fc2159448b839b71599e8e51d5f\nDepends-On: I5ba0a3710012c44822dd3b8e69662bbef04d3787\nRelated-Bug: #1595205\n""}, {'number': 4, 'created': '2016-08-25 19:53:07.000000000', 'files': ['tripleoclient/tests/v1/baremetal/test_baremetal.py', 'tripleoclient/v1/baremetal.py'], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/6900d694e3724b2bd4caf7b82b63f60d2657a5cc', 'message': ""Use Mistral for baremetal boot configuration\n\nThis updates the 'baremetal configure boot' command to work with the\nnew Mistral workflow. The Root Device tests have migrated to\ntripleo-common where the main code now lives as a Mistral action (see\ndependent patch).\n\nChange-Id: I3acbfd7900177fc2159448b839b71599e8e51d5f\nDepends-On: I5ba0a3710012c44822dd3b8e69662bbef04d3787\nRelated-Bug: #1595205\n""}]",0,358012,6900d694e3724b2bd4caf7b82b63f60d2657a5cc,13,3,4,4978,,,0,"Use Mistral for baremetal boot configuration

This updates the 'baremetal configure boot' command to work with the
new Mistral workflow. The Root Device tests have migrated to
tripleo-common where the main code now lives as a Mistral action (see
dependent patch).

Change-Id: I3acbfd7900177fc2159448b839b71599e8e51d5f
Depends-On: I5ba0a3710012c44822dd3b8e69662bbef04d3787
Related-Bug: #1595205
",git fetch https://review.opendev.org/openstack/python-tripleoclient refs/changes/12/358012/1 && git format-patch -1 --stdout FETCH_HEAD,"['tripleoclient/tests/v1/baremetal/test_baremetal.py', 'tripleoclient/v1/baremetal.py']",2,59ff9a16b58607107bf5a77451d6e563ec1d3096,bug/1595205," queue_name = str(uuid.uuid4()) baremetal.configure( self.app.client_manager, node_uuids=[node.uuid], queue_name=queue_name, kernel_name=parsed_args.deploy_kernel, ramdisk_name=parsed_args.deploy_ramdisk, root_device=parsed_args.root_device, root_device_minimum_size=parsed_args.root_device_minimum_size, overwrite_root_device_hints=( parsed_args.overwrite_root_device_hints) )","import ironic_inspector_client from openstackclient.common import utils as osc_utilsfrom oslo_utils import units image_client = self.app.client_manager.image try: kernel_id = osc_utils.find_resource( image_client.images, parsed_args.deploy_kernel).id except AttributeError: self.log.error(""Please make sure that an image named \""%s\"" exists"" "" in Glance and is the only image with this name."" % parsed_args.deploy_ramdisk) return try: ramdisk_id = osc_utils.find_resource( image_client.images, parsed_args.deploy_ramdisk).id except AttributeError: self.log.error(""Please make sure that an image named \""%s\"" exists"" "" in Glance and is the only image with this name."" % parsed_args.deploy_ramdisk) return self.log.debug(""Using kernel ID: {0} and ramdisk ID: {1}"".format( kernel_id, ramdisk_id)) # Get the full node info capabilities = node_detail.properties.get('capabilities', None) # Only update capabilities to add boot_option if it doesn't exist. if capabilities: if 'boot_option' not in capabilities: capabilities = ""boot_option:local,%s"" % capabilities else: capabilities = ""boot_option:local"" self.log.debug(""Configuring boot for Node {0}"".format( node.uuid)) bm_client.node.update(node.uuid, [ { 'op': 'add', 'path': '/properties/capabilities', 'value': capabilities, }, { 'op': 'add', 'path': '/driver_info/deploy_ramdisk', 'value': ramdisk_id, }, { 'op': 'add', 'path': '/driver_info/deploy_kernel', 'value': kernel_id, }, ]) self._apply_root_device_strategy( node_detail, parsed_args.root_device, parsed_args.root_device_minimum_size, parsed_args.overwrite_root_device_hints) def _apply_root_device_strategy(self, node, strategy, minimum_size, overwrite=False): if not strategy: return if node.properties.get('root_device') and not overwrite: # This is a correct situation, we still want to allow people to # fine-tune the root device setting for a subset of nodes. # However, issue a warning, so that they know which nodes were not # updated during this run. self.log.warning('Root device hints are already set for node %s ' 'and overwriting is not requested, skipping', node.uuid) self.log.warning('You may unset them by running $ ironic ' 'node-update %s remove properties/root_device', node.uuid) return inspector_client = self.app.client_manager.baremetal_introspection try: data = inspector_client.get_data(node.uuid) except ironic_inspector_client.ClientError: raise exceptions.RootDeviceDetectionError( 'No introspection data found for node %s, ' 'root device cannot be detected' % node.uuid) except AttributeError: raise RuntimeError('Ironic inspector client version 1.2.0 or ' 'newer is required for detecting root device') try: disks = data['inventory']['disks'] except KeyError: raise exceptions.RootDeviceDetectionError( 'Malformed introspection data for node %s: ' 'disks list is missing' % node.uuid) minimum_size *= units.Gi disks = [d for d in disks if d.get('size', 0) >= minimum_size] if not disks: raise exceptions.RootDeviceDetectionError( 'No suitable disks found for node %s' % node.uuid) if strategy == 'smallest': disks.sort(key=lambda d: d['size']) root_device = disks[0] elif strategy == 'largest': disks.sort(key=lambda d: d['size'], reverse=True) root_device = disks[0] else: disk_names = [x.strip() for x in strategy.split(',')] disks = {d['name']: d for d in disks} for candidate in disk_names: try: root_device = disks['/dev/%s' % candidate] except KeyError: continue else: break else: raise exceptions.RootDeviceDetectionError( 'Cannot find a disk with any of names %(strategy)s ' 'for node %(node)s' % {'strategy': strategy, 'node': node.uuid}) hint = None for hint_name in ('wwn', 'serial'): if root_device.get(hint_name): hint = {hint_name: root_device[hint_name]} break if hint is None: # I don't think it might actually happen, but just in case raise exceptions.RootDeviceDetectionError( 'Neither WWN nor serial number are known for device %(dev)s ' 'on node %(node)s; root device hints cannot be used' % {'dev': root_device['name'], 'node': node.uuid}) # During the introspection process we got local_gb assigned according # to the default strategy. Now we need to update it. new_size = root_device['size'] / units.Gi # This -1 is what we always do to account for partitioning new_size -= 1 bm_client = self.app.client_manager.baremetal bm_client.node.update( node.uuid, [{'op': 'add', 'path': '/properties/root_device', 'value': hint}, {'op': 'add', 'path': '/properties/local_gb', 'value': new_size}]) self.log.info('Updated root device for node %(node)s, new device ' 'is %(dev)s, new local_gb is %(local_gb)d', {'node': node.uuid, 'dev': root_device, 'local_gb': new_size})",104,551
openstack%2Fpython-tripleoclient~master~Ifd868fcdd6ed2d54b40c2e1861558d0233731be5,openstack/python-tripleoclient,master,Ifd868fcdd6ed2d54b40c2e1861558d0233731be5,Add 'openstack overcloud node configure' command,MERGED,2016-07-20 14:53:13.000000000,2016-08-29 15:18:01.000000000,2016-08-29 15:18:01.000000000,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 4978}, {'_account_id': 7065}, {'_account_id': 9712}]","[{'number': 1, 'created': '2016-07-20 14:53:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/608f28714b8023005fd5dfee8e794a7062e6fcc6', 'message': ""[WIP] Add 'openstack overcloud node configure' command\n\nTODO:\n- Discuss whether additional Mistral workflows are required to handle\n  finer configuration (see comment in overcloud_node.py). IIUC the goal\n  of moving toward using Mistral workflows is to help unify the CLI and\n  UI interfaces, so re-implementing commands in Python directly into\n  the CLI seems somewhat counter-productive.\n- Unit tests, etc\n\nChange-Id: Ifd868fcdd6ed2d54b40c2e1861558d0233731be5\nCloses-Bug: #1595205\n""}, {'number': 2, 'created': '2016-07-29 13:20:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/986a0e5d39613ca39632fac6b194be1dd0164a90', 'message': ""[WIP] Add 'openstack overcloud node configure' command\n\nTODO: Everything ;) I uploaded this early to discuss a few\ndetails. Next step is to create then use new Mistral workflows in\ntripleo-common to handle the finer configuration options.\n\nChange-Id: Ifd868fcdd6ed2d54b40c2e1861558d0233731be5\nCloses-Bug: #1595205\n""}, {'number': 3, 'created': '2016-08-17 11:48:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/f0bcf5921f1ed5f075be3023f394955e9b6ea7cb', 'message': ""[WIP] Add 'openstack overcloud node configure' command\n\nCalls to the Mistral workflows to configure boot options and root\ndevice.\n\nTODO:\n- Unit tests\n- Migrate the deprecated 'configure' command to use the workflow too\n- Remove the code that was moved to tripleo-common\n\nChange-Id: Ifd868fcdd6ed2d54b40c2e1861558d0233731be5\nDepends-On: I5ba0a3710012c44822dd3b8e69662bbef04d3787\nCloses-Bug: #1595205\n""}, {'number': 4, 'created': '2016-08-18 13:18:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/c4e5f6a2c10c8fbe861cf35c22108b14c4300df0', 'message': ""Add 'openstack overcloud node configure' command\n\nCalls to the Mistral workflows to configure boot options and the root\ndevice.\n\nChange-Id: Ifd868fcdd6ed2d54b40c2e1861558d0233731be5\nDepends-On: I5ba0a3710012c44822dd3b8e69662bbef04d3787\nCloses-Bug: #1595205\n""}, {'number': 5, 'created': '2016-08-25 19:48:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/c5c758707e3d43a37f7d12d376f1fccafd20af23', 'message': ""Add 'openstack overcloud node configure' command\n\nCalls to the Mistral workflows to configure boot options and the root\ndevice.\n\nChange-Id: Ifd868fcdd6ed2d54b40c2e1861558d0233731be5\nDepends-On: I5ba0a3710012c44822dd3b8e69662bbef04d3787\nCloses-Bug: #1595205\n""}, {'number': 6, 'created': '2016-08-25 19:53:07.000000000', 'files': ['tripleoclient/workflows/baremetal.py', 'tripleoclient/tests/v1/overcloud_node/test_overcloud_node.py', 'tripleoclient/exceptions.py', 'setup.cfg', 'tripleoclient/v1/overcloud_node.py'], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/d0b6de2b4a70527bc03dada31bf2e9b365dfdcc6', 'message': ""Add 'openstack overcloud node configure' command\n\nCalls to the Mistral workflows to configure boot options and the root\ndevice.\n\nChange-Id: Ifd868fcdd6ed2d54b40c2e1861558d0233731be5\nDepends-On: I5ba0a3710012c44822dd3b8e69662bbef04d3787\nCloses-Bug: #1595205\n""}]",3,344875,d0b6de2b4a70527bc03dada31bf2e9b365dfdcc6,35,5,6,4978,,,0,"Add 'openstack overcloud node configure' command

Calls to the Mistral workflows to configure boot options and the root
device.

Change-Id: Ifd868fcdd6ed2d54b40c2e1861558d0233731be5
Depends-On: I5ba0a3710012c44822dd3b8e69662bbef04d3787
Closes-Bug: #1595205
",git fetch https://review.opendev.org/openstack/python-tripleoclient refs/changes/75/344875/6 && git format-patch -1 --stdout FETCH_HEAD,"['setup.cfg', 'tripleoclient/v1/overcloud_node.py']",2,608f28714b8023005fd5dfee8e794a7062e6fcc6,bug/1595205," class ConfigureNode(command.Command): """"""Configure boot options for the specified nodes."""""" log = logging.getLogger(__name__ + "".ConfigureNode"") def get_parser(self, prog_name): parser = super(ConfigureNode, self).get_parser(prog_name) parser.add_argument('--deploy-kernel', default='bm-deploy-kernel', help=_('Image with deploy kernel.')) parser.add_argument('--deploy-ramdisk', default='bm-deploy-ramdisk', help=_('Image with deploy ramdisk.')) parser.add_argument('env_file', type=argparse.FileType('r')) return parser def take_action(self, parsed_args): self.log.debug(""take_action(%s)"" % parsed_args) nodes_config = oooutils.parse_env_file(parsed_args.env_file) queue_name = str(uuid.uuid4()) # TODO(jpichon): This is not ideal at all. This requires nodes # input as JSON rather than IDs, there are no Mistral workflow # for running it on all manageable nodes instead of specific # nodes only (so it is inconsistent with the other 'overcloud # node' commands) and several options available on the original # 'baremetal configure boot' are not included (root-device, # root-device-minimum-size, overwrite-root-device-hints). # # Do we need new Mistral workflows to handle more complex # configuration? # # If not, do we need new workflows to at least be more flexible # with the input (node json vs node uuids)? baremetal.register_or_update( self.app.client_manager, nodes_json=nodes_config, queue_name=queue_name, kernel_name=parsed_args.deploy_kernel, ramdisk_name=parsed_args.deploy_ramdisk )",,46,0
openstack%2Fheat~master~Id7785daa49fe1377b4ce3f9f39ca4b649ea4af18,openstack/heat,master,Id7785daa49fe1377b4ce3f9f39ca4b649ea4af18,Fix incorrect behaviour of repeat function,MERGED,2016-08-26 08:52:04.000000000,2016-08-29 15:17:29.000000000,2016-08-29 15:17:29.000000000,"[{'_account_id': 3}, {'_account_id': 4257}, {'_account_id': 4328}, {'_account_id': 6577}, {'_account_id': 8289}, {'_account_id': 12404}, {'_account_id': 20559}]","[{'number': 1, 'created': '2016-08-26 08:52:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/aa8cfeae0566da1e729ef6b8362e895c2367299c', 'message': ""Fix incorrect behaviour of repeat function\n\nIf template equals to int, float or boolean value,\nrepeat function ignores it and returns None, which is\nincorrect. This patch fixes such behaviour - now if\ntemplate doesn't need in replacement, it returned without\nany changes.\n\nNote that if function looks like:\n\nrepeat:\n  template: True\n  for_each: ['a', 'b', 'c']\n\nresult of the function will equals to [True, True, True].\n\nChange-Id: Id7785daa49fe1377b4ce3f9f39ca4b649ea4af18\nCloses-bug: #1617203\n""}, {'number': 2, 'created': '2016-08-26 13:26:46.000000000', 'files': ['heat/engine/hot/functions.py', 'heat/tests/test_hot.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/3552246d3f6e24271361869f54cfb3afcd8bc57d', 'message': ""Fix incorrect behaviour of repeat function\n\nIf template equals to int, float or boolean value,\nrepeat function ignores it and returns None, which is\nincorrect. This patch fixes such behaviour - now if\ntemplate doesn't need a replacement, it's returned without\nany changes.\n\nNote that if function looks like:\n\nrepeat:\n  template: True\n  for_each: ['a', 'b', 'c']\n\nresult of the function will equals to [True, True, True].\n\nChange-Id: Id7785daa49fe1377b4ce3f9f39ca4b649ea4af18\nCloses-bug: #1617203\n""}]",1,360990,3552246d3f6e24271361869f54cfb3afcd8bc57d,21,7,2,13009,,,0,"Fix incorrect behaviour of repeat function

If template equals to int, float or boolean value,
repeat function ignores it and returns None, which is
incorrect. This patch fixes such behaviour - now if
template doesn't need a replacement, it's returned without
any changes.

Note that if function looks like:

repeat:
  template: True
  for_each: ['a', 'b', 'c']

result of the function will equals to [True, True, True].

Change-Id: Id7785daa49fe1377b4ce3f9f39ca4b649ea4af18
Closes-bug: #1617203
",git fetch https://review.opendev.org/openstack/heat refs/changes/90/360990/1 && git format-patch -1 --stdout FETCH_HEAD,"['heat/engine/hot/functions.py', 'heat/tests/test_hot.py']",2,aa8cfeae0566da1e729ef6b8362e895c2367299c,fix-repeat-func," def test_repeat_dict_with_no_replacement(self): snippet = {'repeat': {'template': {'SERVICE_enabled': True}, 'for_each': {'SERVICE': ['x', 'y', 'z']}}} snippet_resolved = [{'x_enabled': True}, {'y_enabled': True}, {'z_enabled': True}] tmpl = template.Template(hot_newton_tpl_empty) self.assertEqual(snippet_resolved, self.resolve(snippet, tmpl)) ",,11,0
openstack%2Fopenstack-manuals~master~I265d4fb6b8a9e8e92501dd8878d47375c3435781,openstack/openstack-manuals,master,I265d4fb6b8a9e8e92501dd8878d47375c3435781,[glossary] Remove acronyms [O-Z],MERGED,2016-08-19 14:21:25.000000000,2016-08-29 15:12:38.000000000,2016-08-29 15:12:38.000000000,"[{'_account_id': 3}, {'_account_id': 841}, {'_account_id': 6547}, {'_account_id': 9162}, {'_account_id': 10497}, {'_account_id': 23058}]","[{'number': 1, 'created': '2016-08-19 14:21:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/a307adc6aaa7fd954d06a61994dd997ae3edcd08', 'message': '[glossary] Remove acronyms [O-Z]\n\n- Remove acronym-only entries starting with [O-Z].\n- Consolodate duplicate entries.\n- Resolve glossary references\n\nChange-Id: I265d4fb6b8a9e8e92501dd8878d47375c3435781\nImplements: blueprint improve-glossary-usage\n'}, {'number': 2, 'created': '2016-08-19 14:32:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/a511002e708d7671f810e1d5e6d3c8fdf53b5df1', 'message': '[glossary] Remove acronyms [O-Z]\n\n- Remove acronym-only entries starting with [O-Z].\n- Consolodate duplicate entries.\n- Resolve glossary references\n\nChange-Id: I265d4fb6b8a9e8e92501dd8878d47375c3435781\nImplements: blueprint improve-glossary-usage\n'}, {'number': 3, 'created': '2016-08-22 09:52:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/e0470331c6f966d7de74cd8267e50c9c4aa20a9d', 'message': '[glossary] Remove acronyms [O-Z]\n\n- Remove acronym-only entries starting with [O-Z].\n- Consolodate duplicate entries.\n- Resolve glossary references\n\nChange-Id: I265d4fb6b8a9e8e92501dd8878d47375c3435781\nImplements: blueprint improve-glossary-usage\n'}, {'number': 4, 'created': '2016-08-22 13:34:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/0acc5c0abb2373c783b33fdec7437d58f1a02880', 'message': '[glossary] Remove acronyms [O-Z]\n\n- Remove acronym-only entries starting with [O-Z].\n- Consolodate duplicate entries.\n- Resolve glossary references\n\nChange-Id: I265d4fb6b8a9e8e92501dd8878d47375c3435781\nImplements: blueprint improve-glossary-usage\n'}, {'number': 5, 'created': '2016-08-22 15:20:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/47ee3fbdbab3bdbe44cc3f88392d02649f567530', 'message': '[glossary] Remove acronyms [O-Z]\n\n- Remove acronym-only entries starting with [O-Z].\n- Consolodate duplicate entries.\n- Resolve glossary references\n\nChange-Id: I265d4fb6b8a9e8e92501dd8878d47375c3435781\nImplements: blueprint improve-glossary-usage\n'}, {'number': 6, 'created': '2016-08-23 11:56:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/518d2c412b3d85ca19d6af0d7113e241c44da312', 'message': '[glossary] Remove acronyms [O-Z]\n\n- Remove acronym-only entries starting with [O-Z].\n- Consolodate duplicate entries.\n- Resolve glossary references\n\nChange-Id: I265d4fb6b8a9e8e92501dd8878d47375c3435781\nImplements: blueprint improve-glossary-usage\n'}, {'number': 7, 'created': '2016-08-23 15:25:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/bb1cb4693ce7db4bf65bd3d63096efdfe8bb0b3b', 'message': '[glossary] Remove acronyms [O-Z]\n\n- Remove acronym-only entries starting with [O-Z].\n- Consolodate duplicate entries.\n- Resolve glossary references\n\nChange-Id: I265d4fb6b8a9e8e92501dd8878d47375c3435781\nImplements: blueprint improve-glossary-usage\n'}, {'number': 8, 'created': '2016-08-29 02:25:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/3991d94ef730f81cbe99b67aa79aa06057d7985d', 'message': '[glossary] Remove acronyms [O-Z]\n\n- Remove acronym-only entries starting with [O-Z].\n- Consolodate duplicate entries.\n- Resolve glossary references\n\nChange-Id: I265d4fb6b8a9e8e92501dd8878d47375c3435781\nImplements: blueprint improve-glossary-usage\n'}, {'number': 9, 'created': '2016-08-29 02:35:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/cd9960b6f45ef73811c9bd62516fdaf675a6c734', 'message': '[glossary] Remove acronyms [O-Z]\n\n- Remove acronym-only entries starting with [O-Z].\n- Consolodate duplicate entries.\n- Resolve glossary references\n\nChange-Id: I265d4fb6b8a9e8e92501dd8878d47375c3435781\nImplements: blueprint improve-glossary-usage\n'}, {'number': 10, 'created': '2016-08-29 14:55:58.000000000', 'files': ['doc/common/glossary.rst', 'doc/install-guide/source/overview.rst', 'doc/ha-guide/source/intro-ha-concepts.rst'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/5be2d015146d04392f0d2e39d7e598b5da785a7a', 'message': '[glossary] Remove acronyms [O-Z]\n\n- Remove acronym-only entries starting with [O-Z].\n- Consolodate duplicate entries.\n- Resolve glossary references\n\nChange-Id: I265d4fb6b8a9e8e92501dd8878d47375c3435781\nImplements: blueprint improve-glossary-usage\n'}]",0,357911,5be2d015146d04392f0d2e39d7e598b5da785a7a,30,6,10,13177,,,0,"[glossary] Remove acronyms [O-Z]

- Remove acronym-only entries starting with [O-Z].
- Consolodate duplicate entries.
- Resolve glossary references

Change-Id: I265d4fb6b8a9e8e92501dd8878d47375c3435781
Implements: blueprint improve-glossary-usage
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/11/357911/9 && git format-patch -1 --stdout FETCH_HEAD,"['doc/common/glossary.rst', 'doc/install-guide/source/overview.rst', 'doc/ha-guide/source/intro-ha-concepts.rst']",3,a307adc6aaa7fd954d06a61994dd997ae3edcd08,bp/improve-glossary-usage, Requests are handled using a :term:`virtual IP address (VIP)` that, Requests are handled using a :term:`virtual IP` address (VIP) that,9,18
openstack%2Fgnocchi~master~I1308797aded0f18651fc6bbd04046d2140a24714,openstack/gnocchi,master,I1308797aded0f18651fc6bbd04046d2140a24714,carbonara: avoid using futures altogether if no aggregation workers,MERGED,2016-08-20 09:01:56.000000000,2016-08-29 15:11:44.000000000,2016-08-29 15:11:44.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 6537}, {'_account_id': 11564}, {'_account_id': 22739}]","[{'number': 1, 'created': '2016-08-20 09:01:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/5d9206e719c37c9257c586fd89b98efc8eec90bf', 'message': 'carbonara: avoid using futures altogether if no aggregation workers\n\nChange-Id: I1308797aded0f18651fc6bbd04046d2140a24714\n'}, {'number': 2, 'created': '2016-08-24 07:31:06.000000000', 'files': ['gnocchi/storage/_carbonara.py'], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/f916f434e33cfc20ef65701711092763791d7580', 'message': 'carbonara: avoid using futures altogether if no aggregation workers\n\nChange-Id: I1308797aded0f18651fc6bbd04046d2140a24714\n'}]",2,358174,f916f434e33cfc20ef65701711092763791d7580,12,5,2,1669,,,0,"carbonara: avoid using futures altogether if no aggregation workers

Change-Id: I1308797aded0f18651fc6bbd04046d2140a24714
",git fetch https://review.opendev.org/openstack/gnocchi refs/changes/74/358174/2 && git format-patch -1 --stdout FETCH_HEAD,['gnocchi/storage/_carbonara.py'],1,5d9206e719c37c9257c586fd89b98efc8eec90bf,jd/no-threads," if self.aggregation_workers_number == 1: # NOTE(jd) Avoid using futures at all if we don't want any threads. self._map_in_thread = self._map_no_thread else: self._map_in_thread = self._map_in_futures_threads def _map_no_thread(self, method, list_of_args): return list(map(lambda args: method(*args), list_of_args)) def _map_in_futures_threads(self, method, list_of_args):"," def _map_in_thread(self, method, list_of_args):",9,1
openstack%2Fkuryr-kubernetes~master~Iea64d7c7941351d6e0511cafde8914b86c457b1b,openstack/kuryr-kubernetes,master,Iea64d7c7941351d6e0511cafde8914b86c457b1b,Introduce asyncrhonous API requests,MERGED,2016-08-25 09:39:58.000000000,2016-08-29 15:09:11.000000000,2016-08-29 15:09:11.000000000,"[{'_account_id': 3}, {'_account_id': 6598}, {'_account_id': 14352}, {'_account_id': 15967}]","[{'number': 1, 'created': '2016-08-25 09:39:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/359166aa93f3ebbe7eca99eb27802e7d79438499', 'message': ""Introduce asyncrhonous API requests\n\nThis commit introduces the `aio` package, which is a wrapper over\nKenneth Reitz 'requests' library.\n\nIt will be needed to 'watch' Kubernetes API endpoints.\n\nIt also comes with command line utility to test connections and\nresponses. For instance, run:\n\n    python -m kuryr_kubernetes.aio.methods get http://localhost:8080\n\nTo see Kubernetes API root resource response.\n\nIt may make sense to put it in a separated library or in kuryr-lib, but\nfor now and for the sake of push other patches quick, it is better to be\nincluded here.\n\nChange-Id: Iea64d7c7941351d6e0511cafde8914b86c457b1b\nAuthored-By: Antoni Segura Puimedon\nCo-Authored-By: Jaume Devesa <devvesa@gmail.com>\nSigned-off-by: Jaume Devesa <devvesa@gmail.com>\n""}, {'number': 2, 'created': '2016-08-25 10:16:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/1ef739c36edbf5984733967febd28f2b7cdf78fd', 'message': ""Introduce asyncrhonous API requests\n\nThis commit introduces the `aio` package, which is a wrapper over\nKenneth Reitz 'requests' library.\n\nIt will be needed to 'watch' Kubernetes API endpoints.\n\nIt also comes with command line utility to test connections and\nresponses. For instance, run:\n\n    python -m kuryr_kubernetes.aio.methods get http://localhost:8080\n\nTo see Kubernetes API root resource response.\n\nIt may make sense to put it in a separated library or in kuryr-lib, but\nfor now and for the sake of push other patches quick, it is better to be\nincluded here.\n\nChange-Id: Iea64d7c7941351d6e0511cafde8914b86c457b1b\nAuthored-By: Antoni Segura Puimedon\nCo-Authored-By: Jaume Devesa <devvesa@gmail.com>\nSigned-off-by: Jaume Devesa <devvesa@gmail.com>\n""}, {'number': 3, 'created': '2016-08-25 12:10:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/d74e0b19f2f250a83edc99e9295552416abcc52f', 'message': ""Introduce asyncrhonous API requests\n\nThis commit introduces the `aio` package, which is a wrapper over\nKenneth Reitz 'requests' library.\n\nIt will be needed to 'watch' Kubernetes API endpoints.\n\nIt also comes with command line utility to test connections and\nresponses. For instance, run:\n\n    python -m kuryr_kubernetes.aio.methods get http://localhost:8080\n\nTo see Kubernetes API root resource response.\n\nIt may make sense to put it in a separated library or in kuryr-lib, but\nfor now and for the sake of push other patches quick, it is better to be\nincluded here.\n\nChange-Id: Iea64d7c7941351d6e0511cafde8914b86c457b1b\nAuthored-By: Antoni Segura Puimedon\nCo-Authored-By: Jaume Devesa <devvesa@gmail.com>\nSigned-off-by: Jaume Devesa <devvesa@gmail.com>\n""}, {'number': 4, 'created': '2016-08-25 13:47:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/7a0229d4d02cd4149e1eb2d55c678330feda1a65', 'message': ""Introduce asyncrhonous API requests\n\nThis commit introduces the `aio` package, which is a wrapper over\nKenneth Reitz 'requests' library.\n\nIt will be needed to 'watch' Kubernetes API endpoints.\n\nIt also comes with command line utility to test connections and\nresponses. For instance, run:\n\n    python -m kuryr_kubernetes.aio.methods get http://localhost:8080\n\nTo see Kubernetes API root resource response.\n\nIt may make sense to put it in a separated library or in kuryr-lib, but\nfor now and for the sake of push other patches quick, it is better to be\nincluded here.\n\nChange-Id: Iea64d7c7941351d6e0511cafde8914b86c457b1b\nAuthored-By: Antoni Segura Puimedon\nCo-Authored-By: Jaume Devesa <devvesa@gmail.com>\nSigned-off-by: Jaume Devesa <devvesa@gmail.com>\n""}, {'number': 5, 'created': '2016-08-25 13:48:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/a0729ca2d689b157df48bf20e2e12efeb49b46f2', 'message': ""Introduce asyncrhonous API requests\n\nThis commit introduces the `aio` package, which is a wrapper over\nKenneth Reitz 'requests' library.\n\nIt will be needed to 'watch' Kubernetes API endpoints.\n\nIt also comes with command line utility to test connections and\nresponses. For instance, run:\n\n    python -m kuryr_kubernetes.aio.methods get http://localhost:8080\n\nTo see Kubernetes API root resource response.\n\nIt may make sense to put it in a separated library or in kuryr-lib, but\nfor now and for the sake of push other patches quick, it is better to be\nincluded here.\n\nPartial-Implements: blueprint kuryr-k8s-integration\nChange-Id: Iea64d7c7941351d6e0511cafde8914b86c457b1b\nAuthored-By: Antoni Segura Puimedon\nCo-Authored-By: Jaume Devesa <devvesa@gmail.com>\nSigned-off-by: Jaume Devesa <devvesa@gmail.com>\n""}, {'number': 6, 'created': '2016-08-29 09:12:12.000000000', 'files': ['kuryr_kubernetes/aio/methods.py', 'kuryr_kubernetes/aio/headers.py', 'kuryr_kubernetes/aio/__init__.py', 'kuryr_kubernetes/aio/streams.py'], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/a8a91ef38ca47210e626416c1029df380d4323d3', 'message': ""Introduce asyncrhonous API requests\n\nThis commit introduces the `aio` package, which is a wrapper over\nKenneth Reitz 'requests' library.\n\nIt will be needed to 'watch' Kubernetes API endpoints.\n\nIt also comes with command line utility to test connections and\nresponses. For instance, run:\n\n    python -m kuryr_kubernetes.aio.methods get http://localhost:8080\n\nTo see Kubernetes API root resource response.\n\nIt may make sense to put it in a separated library or in kuryr-lib, but\nfor now and for the sake of push other patches quick, it is better to be\nincluded here.\n\nPartial-Implements: blueprint kuryr-k8s-integration\nChange-Id: Iea64d7c7941351d6e0511cafde8914b86c457b1b\nAuthored-By: Antoni Segura Puimedon\nCo-Authored-By: Jaume Devesa <devvesa@gmail.com>\nSigned-off-by: Jaume Devesa <devvesa@gmail.com>\n""}]",7,360376,a8a91ef38ca47210e626416c1029df380d4323d3,21,4,6,7505,,,0,"Introduce asyncrhonous API requests

This commit introduces the `aio` package, which is a wrapper over
Kenneth Reitz 'requests' library.

It will be needed to 'watch' Kubernetes API endpoints.

It also comes with command line utility to test connections and
responses. For instance, run:

    python -m kuryr_kubernetes.aio.methods get http://localhost:8080

To see Kubernetes API root resource response.

It may make sense to put it in a separated library or in kuryr-lib, but
for now and for the sake of push other patches quick, it is better to be
included here.

Partial-Implements: blueprint kuryr-k8s-integration
Change-Id: Iea64d7c7941351d6e0511cafde8914b86c457b1b
Authored-By: Antoni Segura Puimedon
Co-Authored-By: Jaume Devesa <devvesa@gmail.com>
Signed-off-by: Jaume Devesa <devvesa@gmail.com>
",git fetch https://review.opendev.org/openstack/kuryr-kubernetes refs/changes/76/360376/5 && git format-patch -1 --stdout FETCH_HEAD,"['kuryr_kubernetes/aio/methods.py', 'kuryr_kubernetes/aio/headers.py', 'kuryr_kubernetes/aio/__init__.py', 'kuryr_kubernetes/aio/streams.py']",4,359166aa93f3ebbe7eca99eb27802e7d79438499,bp/kuryr-k8s-integration,"# Licensed under the Apache License, Version 2.0 (the ""License""); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or # implied. # See the License for the specific language governing permissions and # limitations under the License. from asyncio import coroutine from asyncio import streams class ChunkedStreamReader(streams.StreamReader): @coroutine def readchunk(self): """"""Modified asyncio.streams.readline for http chunks Returns an HTTP1.1 chunk transfer encoding chunk. Returns None if it is the trailing chunk. """""" if self._exception is not None: raise self._exception chunk_size = bytearray() chunk = bytearray() size = None sep = b'\r\n' while size != 0: while self._buffer and size is None: ichar = self._buffer.find(sep) if ichar < 0: chunk_size.extend(self._buffer) self._buffer.clear() else: # size present chunk_size.extend(self._buffer[:ichar]) size = int(bytes(chunk_size), 16) if size == 0: # Terminal chunk self._buffer.clear() self.feed_eof() return b'' else: del self._buffer[:ichar + len(sep)] while self._buffer and size > 0: buff_size = len(self._buffer) if buff_size < size: chunk.extend(self._buffer) self._buffer.clear() size -= buff_size else: chunk.extend(self._buffer[:size]) del self._buffer[:size + len(sep)] # delete also trailer size = 0 if self._eof: break if size is None or size > 0: yield from self._wait_for_data('readchunk') elif size < 0: raise ValueError('Chunk wrongly encoded') self._maybe_resume_transport() return bytes(chunk) ",,391,0
openstack%2Fceilometer~master~I404c467707dba08a15628f4a04bcc77843436cdf,openstack/ceilometer,master,I404c467707dba08a15628f4a04bcc77843436cdf,Update readme file,MERGED,2016-08-12 05:12:32.000000000,2016-08-29 15:06:05.000000000,2016-08-29 15:06:05.000000000,"[{'_account_id': 3}, {'_account_id': 4491}, {'_account_id': 6537}, {'_account_id': 8290}, {'_account_id': 10705}, {'_account_id': 11564}, {'_account_id': 12807}, {'_account_id': 13229}, {'_account_id': 15843}, {'_account_id': 22752}, {'_account_id': 22779}, {'_account_id': 23058}]","[{'number': 1, 'created': '2016-08-12 05:12:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/27377112e9a328ab17fbd81b5f2290f476659617', 'message': 'Update readme file\n\nAdd project description and update links\n\nChange-Id: I404c467707dba08a15628f4a04bcc77843436cdf\n'}, {'number': 2, 'created': '2016-08-16 01:30:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/e1005d996a63eeed72fd22584f1371be7ce8a80d', 'message': 'Update readme file\n\nAdd project description and update links\n\nChange-Id: I404c467707dba08a15628f4a04bcc77843436cdf\n'}, {'number': 3, 'created': '2016-08-18 23:43:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/22ae924b5c5f7d0ee801571a4f9d0b39f3faf64b', 'message': 'Update readme file\n\nAdd project description and update links\n\nChange-Id: I404c467707dba08a15628f4a04bcc77843436cdf\n'}, {'number': 4, 'created': '2016-08-29 01:27:15.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/0b37c2892690a03d9922305780d89d6fb5d84299', 'message': 'Update readme file\n\nAdd project description and update links\n\nChange-Id: I404c467707dba08a15628f4a04bcc77843436cdf\n'}]",10,354531,0b37c2892690a03d9922305780d89d6fb5d84299,33,12,4,10705,,,0,"Update readme file

Add project description and update links

Change-Id: I404c467707dba08a15628f4a04bcc77843436cdf
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/31/354531/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,27377112e9a328ab17fbd81b5f2290f476659617,readme-edit,"========== CeilometerCeilometer is a data collections service that collects and records event and metering data by monitoring notifications sent from OpenStack services. It publishes collected data to various targets including data stores and message queues, and can create alarms when collected data breaks defined rules for OpenStack core components. Ceilometer is distributed under the terms of the Apache License, Version 2.0. The full terms and conditions of this license are detailed in the LICENSE file. For more information about Ceilometer APIs, see http://developer.openstack.org/api-ref-telemetry-v2.html Release notes are available at http://releases.openstack.org/mitaka/#mitaka-ceilometer Developer documentation is available at http://docs.openstack.org/developer/ceilometer/ For information on how to contribute to ceilometer, see the CONTRIBUTING.rst file. The project home is at http://launchpad.net/ceilometer To report any ceilometer related bugs, see http://bugs.launchpad.net/ceilometer/",ceilometerRelease notes can be read online at: http://docs.openstack.org/developer/ceilometer/releasenotes/index.html Documentation for the project can be found at: http://docs.openstack.org/developer/ceilometer/ The project home is at: http://launchpad.net/ceilometer ,25,7
openstack%2Fneutron-vpnaas~master~Id56b9b70fb9c4113f4641e5b3f35ab63cfff6d4e,openstack/neutron-vpnaas,master,Id56b9b70fb9c4113f4641e5b3f35ab63cfff6d4e,Use temporary directory for neutron install,MERGED,2016-08-28 16:03:54.000000000,2016-08-29 15:04:23.000000000,2016-08-29 10:44:30.000000000,"[{'_account_id': 3}, {'_account_id': 841}, {'_account_id': 6547}, {'_account_id': 6659}, {'_account_id': 9656}]","[{'number': 1, 'created': '2016-08-28 16:03:54.000000000', 'files': ['tools/tox_install.sh', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/neutron-vpnaas/commit/c26a4f665af9561a16d9a6beaa64b14b57fa1a09', 'message': 'Use temporary directory for neutron install\n\nDo not install in /tmp/openstack/neutron and leave the git repository\nthere after the script is run - if zuul-cloner is used.\n\nWe run jobs on long lived workers and also on developers machines, let\'s\ncleanup afterwards.\n\nInstall into a temporary directory that can be removed with ""git clean""\nafterwards. Add this directory to ignore list of pep8.\n\nSimplify with using pushd/popd.\n\nAlso, remove setup of ZUUL_BRANCH, this is not needed with current zuul\nanymore.\n\nSync file with neutron-lbaas.\n\nChange-Id: Id56b9b70fb9c4113f4641e5b3f35ab63cfff6d4e\n'}]",2,361756,c26a4f665af9561a16d9a6beaa64b14b57fa1a09,10,5,1,6547,,,0,"Use temporary directory for neutron install

Do not install in /tmp/openstack/neutron and leave the git repository
there after the script is run - if zuul-cloner is used.

We run jobs on long lived workers and also on developers machines, let's
cleanup afterwards.

Install into a temporary directory that can be removed with ""git clean""
afterwards. Add this directory to ignore list of pep8.

Simplify with using pushd/popd.

Also, remove setup of ZUUL_BRANCH, this is not needed with current zuul
anymore.

Sync file with neutron-lbaas.

Change-Id: Id56b9b70fb9c4113f4641e5b3f35ab63cfff6d4e
",git fetch https://review.opendev.org/openstack/neutron-vpnaas refs/changes/56/361756/1 && git format-patch -1 --stdout FETCH_HEAD,"['tools/tox_install.sh', 'tox.ini']",2,c26a4f665af9561a16d9a6beaa64b14b57fa1a09,tox_install,"exclude = .venv,.git,.tox,dist,doc,.tmp,*lib/python*,*egg,build,tools,.ropeproject,rally-scenarios","exclude = .venv,.git,.tox,dist,doc,*lib/python*,*egg,build,tools,.ropeproject,rally-scenarios",19,15
openstack%2Fdeb-auto-backports~debian%2Fnewton~I1821b16342fa237d5a7210d075076f8a19e274fb,openstack/deb-auto-backports,debian/newton,I1821b16342fa237d5a7210d075076f8a19e274fb,Build python-virtualenv,MERGED,2016-08-25 14:33:29.000000000,2016-08-29 15:04:13.000000000,2016-08-29 15:04:13.000000000,"[{'_account_id': 3}, {'_account_id': 6476}]","[{'number': 1, 'created': '2016-08-25 14:33:29.000000000', 'files': ['packages-list'], 'web_link': 'https://opendev.org/openstack/deb-auto-backports/commit/e235a511414b52365d8fc3f362462556b47018e4', 'message': 'Build python-virtualenv\n\nChange-Id: I1821b16342fa237d5a7210d075076f8a19e274fb\n'}]",0,360592,e235a511414b52365d8fc3f362462556b47018e4,8,2,1,6476,,,0,"Build python-virtualenv

Change-Id: I1821b16342fa237d5a7210d075076f8a19e274fb
",git fetch https://review.opendev.org/openstack/deb-auto-backports refs/changes/92/360592/1 && git format-patch -1 --stdout FETCH_HEAD,['packages-list'],1,e235a511414b52365d8fc3f362462556b47018e4,python-virtualenv,python-virtualenv,#python-virtualenv,1,1
openstack%2Fmurano~master~I751bb63db1eba889504d82847b8f87db38d1a2c1,openstack/murano,master,I751bb63db1eba889504d82847b8f87db38d1a2c1,Updated from global requirements,MERGED,2016-08-29 06:12:21.000000000,2016-08-29 15:02:14.000000000,2016-08-29 15:02:14.000000000,"[{'_account_id': 3}, {'_account_id': 7821}, {'_account_id': 14107}, {'_account_id': 15168}]","[{'number': 1, 'created': '2016-08-29 06:12:21.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/murano/commit/47c8f096ad38d915844d2ed94f9ca9d4420db6d4', 'message': 'Updated from global requirements\n\nChange-Id: I751bb63db1eba889504d82847b8f87db38d1a2c1\n'}]",0,361866,47c8f096ad38d915844d2ed94f9ca9d4420db6d4,9,4,1,11131,,,0,"Updated from global requirements

Change-Id: I751bb63db1eba889504d82847b8f87db38d1a2c1
",git fetch https://review.opendev.org/openstack/murano refs/changes/66/361866/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,47c8f096ad38d915844d2ed94f9ca9d4420db6d4,openstack/requirements,python-heatclient>=1.4.0 # Apache-2.0,python-heatclient>=1.1.0 # Apache-2.0,1,1
openstack%2Fopenstack-manuals~master~I43626ea547b4520e1da51411d982f16005827d68,openstack/openstack-manuals,master,I43626ea547b4520e1da51411d982f16005827d68,[glossary] Remove acronyms [M-N],MERGED,2016-08-19 11:16:15.000000000,2016-08-29 14:55:17.000000000,2016-08-29 14:55:17.000000000,"[{'_account_id': 3}, {'_account_id': 841}, {'_account_id': 6547}, {'_account_id': 9162}, {'_account_id': 10497}]","[{'number': 1, 'created': '2016-08-19 11:16:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/abfdc87a72bca30e95bf2925d1dc696720c5ee3e', 'message': '[glossary] Remove acrynoms [M-N]\n\n- Remove acronym-only entries starting with [M-N].\n- Consolodate duplicate entries.\n- Resolve glossary references.\n\nChange-Id: I43626ea547b4520e1da51411d982f16005827d68\nImplements: blueprint improve-glossary-usage\n'}, {'number': 2, 'created': '2016-08-19 13:00:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/46ce8c98b0904e56640a8e9eee42a17ad36eb487', 'message': '[glossary] Remove acrynoms [M-N]\n\n- Remove acronym-only entries starting with [M-N].\n- Consolodate duplicate entries.\n- Resolve glossary references.\n\nChange-Id: I43626ea547b4520e1da51411d982f16005827d68\nImplements: blueprint improve-glossary-usage\n'}, {'number': 3, 'created': '2016-08-19 14:08:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/7a4597bb0695ed9626b9e260b446fc0e18f4e4a8', 'message': '[glossary] Remove acronyms [M-N]\n\n- Remove acronym-only entries starting with [M-N].\n- Consolodate duplicate entries.\n- Resolve glossary references.\n\nChange-Id: I43626ea547b4520e1da51411d982f16005827d68\nImplements: blueprint improve-glossary-usage\n'}, {'number': 4, 'created': '2016-08-19 14:08:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/41e2bba7d43b7c4c66c22cfb0b0bb8ff35ae7217', 'message': '[glossary] Remove acronyms [M-N]\n\n- Remove acronym-only entries starting with [M-N].\n- Consolodate duplicate entries.\n- Resolve glossary references.\n\nChange-Id: I43626ea547b4520e1da51411d982f16005827d68\nImplements: blueprint improve-glossary-usage\n'}, {'number': 5, 'created': '2016-08-19 14:32:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/d04de4e328fa1ba0daee7d7cd339da92a6715254', 'message': '[glossary] Remove acronyms [M-N]\n\n- Remove acronym-only entries starting with [M-N].\n- Consolodate duplicate entries.\n- Resolve glossary references.\n\nChange-Id: I43626ea547b4520e1da51411d982f16005827d68\nImplements: blueprint improve-glossary-usage\n'}, {'number': 6, 'created': '2016-08-22 09:50:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/9f3749d5286fc57b0dc4a54773cc66e2c31c34c5', 'message': '[glossary] Remove acronyms [M-N]\n\n- Remove acronym-only entries starting with [M-N].\n- Consolodate duplicate entries.\n- Resolve glossary references.\n\nChange-Id: I43626ea547b4520e1da51411d982f16005827d68\nImplements: blueprint improve-glossary-usage\n'}, {'number': 7, 'created': '2016-08-22 13:34:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/8336bee8ac08a378981c329b7b7e504ddd56ba0d', 'message': '[glossary] Remove acronyms [M-N]\n\n- Remove acronym-only entries starting with [M-N].\n- Consolodate duplicate entries.\n- Resolve glossary references.\n\nChange-Id: I43626ea547b4520e1da51411d982f16005827d68\nImplements: blueprint improve-glossary-usage\n'}, {'number': 8, 'created': '2016-08-22 15:20:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/8ff1beca89ad8cf962da2ffdc606915d6361c394', 'message': '[glossary] Remove acronyms [M-N]\n\n- Remove acronym-only entries starting with [M-N].\n- Consolodate duplicate entries.\n- Resolve glossary references.\n\nChange-Id: I43626ea547b4520e1da51411d982f16005827d68\nImplements: blueprint improve-glossary-usage\n'}, {'number': 9, 'created': '2016-08-23 11:56:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/41247f52e05e6405fdca4388cf8a5672bcf3a6b1', 'message': '[glossary] Remove acronyms [M-N]\n\n- Remove acronym-only entries starting with [M-N].\n- Consolodate duplicate entries.\n- Resolve glossary references.\n\nChange-Id: I43626ea547b4520e1da51411d982f16005827d68\nImplements: blueprint improve-glossary-usage\n'}, {'number': 10, 'created': '2016-08-23 15:24:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/877ff5c27dfc4e4a90a8e1e3795649589672ffa7', 'message': '[glossary] Remove acronyms [M-N]\n\n- Remove acronym-only entries starting with [M-N].\n- Consolodate duplicate entries.\n- Resolve glossary references.\n\nChange-Id: I43626ea547b4520e1da51411d982f16005827d68\nImplements: blueprint improve-glossary-usage\n'}, {'number': 11, 'created': '2016-08-29 02:25:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/3085080b719530fc24c26bea2ebb908349b10f9c', 'message': '[glossary] Remove acronyms [M-N]\n\n- Remove acronym-only entries starting with [M-N].\n- Consolodate duplicate entries.\n- Resolve glossary references.\n\nChange-Id: I43626ea547b4520e1da51411d982f16005827d68\nImplements: blueprint improve-glossary-usage\n'}, {'number': 12, 'created': '2016-08-29 02:35:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/ac5bda94c10229a01ebf71d207be1d9cf3de8971', 'message': '[glossary] Remove acronyms [M-N]\n\n- Remove acronym-only entries starting with [M-N].\n- Consolodate duplicate entries.\n- Resolve glossary references.\n\nChange-Id: I43626ea547b4520e1da51411d982f16005827d68\nImplements: blueprint improve-glossary-usage\n'}, {'number': 13, 'created': '2016-08-29 14:40:08.000000000', 'files': ['doc/common/glossary.rst', 'doc/networking-guide/source/intro-os-networking.rst', 'doc/install-guide/source/overview.rst', 'doc/ops-guide/source/arch-example-nova-network.rst', 'doc/install-guide/source/environment-networking.rst', 'doc/install-guide/source/environment-ntp.rst'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/0e39378c218cce0815d1d89715fe58253dcc5185', 'message': '[glossary] Remove acronyms [M-N]\n\n- Remove acronym-only entries starting with [M-N].\n- Consolodate duplicate entries.\n- Resolve glossary references.\n\nChange-Id: I43626ea547b4520e1da51411d982f16005827d68\nImplements: blueprint improve-glossary-usage\n'}]",2,357785,0e39378c218cce0815d1d89715fe58253dcc5185,35,5,13,13177,,,0,"[glossary] Remove acronyms [M-N]

- Remove acronym-only entries starting with [M-N].
- Consolodate duplicate entries.
- Resolve glossary references.

Change-Id: I43626ea547b4520e1da51411d982f16005827d68
Implements: blueprint improve-glossary-usage
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/85/357785/13 && git format-patch -1 --stdout FETCH_HEAD,"['doc/common/glossary.rst', 'doc/networking-guide/source/intro-os-networking.rst', 'doc/install-guide/source/overview.rst', 'doc/ops-guide/source/arch-example-nova-network.rst', 'doc/install-guide/source/environment-networking.rst', 'doc/install-guide/source/environment-ntp.rst']",6,abfdc87a72bca30e95bf2925d1dc696720c5ee3e,bp/improve-glossary-usage,"You should install Chrony, an implementation of :term:`NTP <Network Time Protocol (NTP)>`, to properly synchronize services among nodes. We recommend that you configure the controller node to reference more accurate (lower stratum) servers and other nodes to reference the controller node.","You should install Chrony, an implementation of :term:`NTP`, to properly synchronize services among nodes. We recommend that you configure the controller node to reference more accurate (lower stratum) servers and other nodes to reference the controller node.",29,29
openstack%2Fpython-novaclient~master~I0e4c38a9e0ae25a922f6b0e09f3f2531f49c88c9,openstack/python-novaclient,master,I0e4c38a9e0ae25a922f6b0e09f3f2531f49c88c9,Pick first image if can't find the specific image,MERGED,2016-08-19 12:56:15.000000000,2016-08-29 14:54:04.000000000,2016-08-21 22:07:20.000000000,"[{'_account_id': 3}, {'_account_id': 679}, {'_account_id': 2750}, {'_account_id': 6873}]","[{'number': 1, 'created': '2016-08-19 12:56:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/91838a111002a65922e8812f6852a841ded83aff', 'message': ""Pick first image if can't find the specific image\n\nIn pick_image method to just pick the first image it finds\nif it can't find the specific cirros-*uec image.\n\nChange-Id: I0e4c38a9e0ae25a922f6b0e09f3f2531f49c88c9\nCloses-Bug: 1614118\n""}, {'number': 2, 'created': '2016-08-20 12:38:54.000000000', 'files': ['novaclient/tests/functional/base.py'], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/01de5a9f68ad474e9bfa213ffeb3501066a52ebd', 'message': ""Pick first image if can't find the specific image\n\nIn pick_image method to just pick the first image it finds\nif it can't find the specific cirros-*uec image.\n\nAlso look for the -disk.img since devstack is changing\nthe default image in:\n\nId65ebae73b28da7185cb349b714b659af51ef77f\n\nChange-Id: I0e4c38a9e0ae25a922f6b0e09f3f2531f49c88c9\nCloses-Bug: 1614118\n""}]",5,357845,01de5a9f68ad474e9bfa213ffeb3501066a52ebd,13,4,2,15950,,,0,"Pick first image if can't find the specific image

In pick_image method to just pick the first image it finds
if it can't find the specific cirros-*uec image.

Also look for the -disk.img since devstack is changing
the default image in:

Id65ebae73b28da7185cb349b714b659af51ef77f

Change-Id: I0e4c38a9e0ae25a922f6b0e09f3f2531f49c88c9
Closes-Bug: 1614118
",git fetch https://review.opendev.org/openstack/python-novaclient refs/changes/45/357845/2 && git format-patch -1 --stdout FETCH_HEAD,['novaclient/tests/functional/base.py'],1,91838a111002a65922e8812f6852a841ded83aff,bug/1614118, firstImage = None for image in images: firstImage = firstImage or image if firstImage: return firstImage , for image in images:,6,0
openstack%2Freleases~master~I7ff0b10c1694e784f6adf9a06b4080f181412e96,openstack/releases,master,I7ff0b10c1694e784f6adf9a06b4080f181412e96,fixed example of the Thursday deadlines note,MERGED,2016-08-29 14:24:58.000000000,2016-08-29 14:52:45.000000000,2016-08-29 14:52:45.000000000,"[{'_account_id': 3}, {'_account_id': 2472}]","[{'number': 1, 'created': '2016-08-29 14:24:58.000000000', 'files': ['doc/source/newton/schedule.rst'], 'web_link': 'https://opendev.org/openstack/releases/commit/461737e4cdf6d9a7c9feaa674d5c08d7b7b9607a', 'message': 'fixed example of the Thursday deadlines note\n\nThe Thursday deadlines note takes Feature Freeze as an example but the\nmentioned date was one week off.\n\nChange-Id: I7ff0b10c1694e784f6adf9a06b4080f181412e96\n'}]",0,362151,461737e4cdf6d9a7c9feaa674d5c08d7b7b9607a,6,2,1,22139,,,0,"fixed example of the Thursday deadlines note

The Thursday deadlines note takes Feature Freeze as an example but the
mentioned date was one week off.

Change-Id: I7ff0b10c1694e784f6adf9a06b4080f181412e96
",git fetch https://review.opendev.org/openstack/releases refs/changes/51/362151/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/newton/schedule.rst'],1,461737e4cdf6d9a7c9feaa674d5c08d7b7b9607a,, 1 September. Exceptions to this policy will be explicitly mentioned, 8 September. Exceptions to this policy will be explicitly mentioned,1,1
openstack%2Fceilometer~master~I101f6b70d01cd83a772d1e00949485ec2ef8b448,openstack/ceilometer,master,I101f6b70d01cd83a772d1e00949485ec2ef8b448,Install configuration files in etc,MERGED,2016-06-08 07:34:17.000000000,2016-08-29 14:46:46.000000000,2016-08-29 14:46:46.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2813}, {'_account_id': 4491}, {'_account_id': 6476}, {'_account_id': 6537}, {'_account_id': 6676}, {'_account_id': 6924}, {'_account_id': 7478}, {'_account_id': 8290}, {'_account_id': 9562}, {'_account_id': 11564}, {'_account_id': 13560}, {'_account_id': 15843}, {'_account_id': 22165}, {'_account_id': 22775}, {'_account_id': 22779}]","[{'number': 1, 'created': '2016-06-08 07:34:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/a0aec8bcdd222252ca49eca8143d736d668dd108', 'message': 'Install configuration files in etc\n\nChange-Id: I101f6b70d01cd83a772d1e00949485ec2ef8b448\n'}, {'number': 2, 'created': '2016-07-18 10:08:55.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/e48775633cde89da4babd660307c37bcc30fc4d1', 'message': 'Install configuration files in etc\n\nChange-Id: I101f6b70d01cd83a772d1e00949485ec2ef8b448\n'}]",0,326883,e48775633cde89da4babd660307c37bcc30fc4d1,17,17,2,1669,,,0,"Install configuration files in etc

Change-Id: I101f6b70d01cd83a772d1e00949485ec2ef8b448
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/83/326883/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,a0aec8bcdd222252ca49eca8143d736d668dd108,jd/install-etc,data_files = etc/ceilometer = etc/ceilometer/*,,2,0
openstack%2Fceilometer~master~I50b4f724f58f476619e3b581204db6d0359e60a6,openstack/ceilometer,master,I50b4f724f58f476619e3b581204db6d0359e60a6,api: redirect to Panko if enabled,MERGED,2016-07-18 16:39:18.000000000,2016-08-29 14:46:36.000000000,2016-08-29 14:46:36.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2813}, {'_account_id': 4491}, {'_account_id': 6537}, {'_account_id': 6676}, {'_account_id': 6924}, {'_account_id': 7478}, {'_account_id': 8290}, {'_account_id': 9562}, {'_account_id': 11564}, {'_account_id': 13560}, {'_account_id': 15843}, {'_account_id': 18802}, {'_account_id': 22739}, {'_account_id': 22775}, {'_account_id': 22779}]","[{'number': 1, 'created': '2016-07-18 16:39:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/b009ea9de90702dbfc7cba789fd7ea8473b11681', 'message': 'api: redirect to Panko if enabled\n\nChange-Id: I50b4f724f58f476619e3b581204db6d0359e60a6\n'}, {'number': 2, 'created': '2016-07-19 09:19:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/8a2c90a79df60646a80a0bad61a7c938f70eae96', 'message': 'api: redirect to Panko if enabled\n\nChange-Id: I50b4f724f58f476619e3b581204db6d0359e60a6\n'}, {'number': 3, 'created': '2016-07-19 10:07:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/d1a6b208f436b5d11a392994c3e99e2506ccc2fe', 'message': 'api: redirect to Panko if enabled\n\nChange-Id: I50b4f724f58f476619e3b581204db6d0359e60a6\n'}, {'number': 4, 'created': '2016-07-20 10:11:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/5f4f230e34abb24e6ca9bbec49340918b5b68274', 'message': 'api: redirect to Panko if enabled\n\nChange-Id: I50b4f724f58f476619e3b581204db6d0359e60a6\n'}, {'number': 5, 'created': '2016-08-11 10:50:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/663bcf8f94b50f967430cf09a034f64d1805f6ae', 'message': 'api: redirect to Panko if enabled\n\nChange-Id: I50b4f724f58f476619e3b581204db6d0359e60a6\n'}, {'number': 6, 'created': '2016-08-11 12:15:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/8ef7a0f752ed79bd885f98b0e5c3d59801a920c8', 'message': 'api: redirect to Panko if enabled\n\nChange-Id: I50b4f724f58f476619e3b581204db6d0359e60a6\n'}, {'number': 7, 'created': '2016-08-12 09:24:53.000000000', 'files': ['ceilometer/api/controllers/v2/root.py', 'ceilometer/tests/functional/api/v2/test_api_upgrade.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/bfffe3566d810a6a9f46d00be75a26cb2c97eab6', 'message': 'api: redirect to Panko if enabled\n\nChange-Id: I50b4f724f58f476619e3b581204db6d0359e60a6\n'}]",8,343781,bfffe3566d810a6a9f46d00be75a26cb2c97eab6,35,17,7,1669,,,0,"api: redirect to Panko if enabled

Change-Id: I50b4f724f58f476619e3b581204db6d0359e60a6
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/81/343781/6 && git format-patch -1 --stdout FETCH_HEAD,"['ceilometer/api/controllers/v2/root.py', 'ceilometer/tests/functional/api/v2/test_api_upgrade.py']",2,b009ea9de90702dbfc7cba789fd7ea8473b11681,jd/redirect-panko," self.CONF.set_override('panko_is_enabled', True, group='api') self.CONF.set_override('panko_url', 'http://event-endpoint:8009/', group='api') self.CONF.set_override('panko_is_enabled', None, group='api') self.CONF.set_override('panko_url', None, group='api') elif service_type == 'events': return 'http://event-endpoint:8009/' def _do_test_event_redirect(self): response = self.app.get(self.PATH_PREFIX + '/events', expect_errors=True) self.assertEqual(307, response.status_code) self.assertEqual(""http://event-endpoint:8009/v2/events"", response.headers['Location']) response = self.app.get(self.PATH_PREFIX + '/events/uuid', expect_errors=True) self.assertEqual(307, response.status_code) self.assertEqual(""http://event-endpoint:8009/v2/events/uuid"", response.headers['Location']) response = self.app.delete(self.PATH_PREFIX + '/events/uuid', expect_errors=True) self.assertEqual(307, response.status_code) self.assertEqual(""http://event-endpoint:8009/v2/events/uuid"", response.headers['Location']) response = self.app.get(self.PATH_PREFIX + '/event_types', expect_errors=True) self.assertEqual(307, response.status_code) self.assertEqual(""http://event-endpoint:8009/v2/event_types"", response.headers['Location']) def test_event_redirect_keystone(self): self._setup_keystone_mock() self._do_test_event_redirect() self.assertEqual([mock.call(service_type=""events"")], self.catalog.url_for.mock_calls) def test_event_redirect_configoptions(self): self._setup_osloconfig_options() self._do_test_event_redirect()",,95,6
openstack%2Fnova-powervm~stable%2Fmitaka~Ic2c634ed6860c11266e361e69dae88f70ac05425,openstack/nova-powervm,stable/mitaka,Ic2c634ed6860c11266e361e69dae88f70ac05425,stable/mitaka using pypowervm 1.0.0.3,MERGED,2016-08-24 06:27:28.000000000,2016-08-29 14:46:31.000000000,2016-08-29 14:46:31.000000000,"[{'_account_id': 3}, {'_account_id': 8190}, {'_account_id': 13883}, {'_account_id': 14070}, {'_account_id': 16128}, {'_account_id': 18549}]","[{'number': 1, 'created': '2016-08-24 06:27:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-powervm/commit/ff8443db78ff873f915d22eb6a05f49d884dfe47', 'message': 'stable/mitaka using pypowervm 1.0.0.3\n\nstable/mitaka branch point to pypowervm 1.0.0.3\n\nChange-Id: Ic2c634ed6860c11266e361e69dae88f70ac05425\n'}, {'number': 2, 'created': '2016-08-24 08:00:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-powervm/commit/a75ea0fd768e526207b46bb40bf55ef595d1d4c7', 'message': 'stable/mitaka using pypowervm 1.0.0.3\n\nstable/mitaka branch point to pypowervm 1.0.0.3\n\nChange-Id: Ic2c634ed6860c11266e361e69dae88f70ac05425\n'}, {'number': 3, 'created': '2016-08-27 09:07:30.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/nova-powervm/commit/b2f2dbd77b40026f7e31cf9c46fcd606a53464a8', 'message': 'stable/mitaka using pypowervm 1.0.0.3\n\nstable/mitaka branch point to pypowervm 1.0.0.3\n\nCloses-Bug: 1617533\n\nChange-Id: Ic2c634ed6860c11266e361e69dae88f70ac05425\n'}]",0,359615,b2f2dbd77b40026f7e31cf9c46fcd606a53464a8,18,6,3,18549,,,0,"stable/mitaka using pypowervm 1.0.0.3

stable/mitaka branch point to pypowervm 1.0.0.3

Closes-Bug: 1617533

Change-Id: Ic2c634ed6860c11266e361e69dae88f70ac05425
",git fetch https://review.opendev.org/openstack/nova-powervm refs/changes/15/359615/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,ff8443db78ff873f915d22eb6a05f49d884dfe47,bug/1617533, -egit+https://github.com/powervm/pypowervm@release/1.0.0.3#egg=pypowervm , -egit+https://github.com/powervm/pypowervm@develop#egg=pypowervm,2,1
openstack%2Fwatcher~master~I0f30a056c3efa49faed857b6d1001a2367d384ac,openstack/watcher,master,I0f30a056c3efa49faed857b6d1001a2367d384ac,TrivialFix: Remove cfg import unused,MERGED,2016-08-29 06:00:19.000000000,2016-08-29 14:44:40.000000000,2016-08-29 14:44:40.000000000,"[{'_account_id': 3}, {'_account_id': 12394}, {'_account_id': 15905}]","[{'number': 1, 'created': '2016-08-29 06:00:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/7516c60ff72b785ccd92e28e478eca523dc322fc', 'message': 'TrivialFix: Remove cfg import unused\n\nThis patch removes cfg import unused in\nwatcher/api/controllers/v1/goal.py\nwatcher/api/controllers/v1/strategy.py\nwatcher/decision_engine/cluster/history/ceilometer.py\nwatcher/decision_engine/model/collector/manager.py\nwatcher/decision_engine/strategy/selection/default.py\nwatcher/tests/decision_engine/fake_strategies.py\nwatcher/tests/decision_engine/strategy/selector/test_strategy_selector.py\n\nChange-Id: I0f30a056c3efa49faed857b6d1001a2367d384ac\n'}, {'number': 2, 'created': '2016-08-29 08:04:45.000000000', 'files': ['watcher/tests/decision_engine/fake_strategies.py', 'watcher/api/controllers/v1/goal.py', 'watcher/decision_engine/model/collector/manager.py', 'watcher/tests/decision_engine/strategy/selector/test_strategy_selector.py', 'watcher/api/controllers/v1/strategy.py', 'watcher/decision_engine/cluster/history/ceilometer.py', 'watcher/tests/common/test_ceilometer_helper.py', 'watcher/decision_engine/strategy/selection/default.py'], 'web_link': 'https://opendev.org/openstack/watcher/commit/deb5cb3fc206a3468ca3c3cadec93b72adeb0355', 'message': 'TrivialFix: Remove cfg import unused\n\nThis patch removes cfg import unused in\nwatcher/api/controllers/v1/goal.py\nwatcher/api/controllers/v1/strategy.py\nwatcher/decision_engine/cluster/history/ceilometer.py\nwatcher/decision_engine/model/collector/manager.py\nwatcher/decision_engine/strategy/selection/default.py\nwatcher/tests/common/test_ceilometer_helper.py\nwatcher/tests/decision_engine/fake_strategies.py\nwatcher/tests/decision_engine/strategy/selector/test_strategy_selector.py\n\nChange-Id: I0f30a056c3efa49faed857b6d1001a2367d384ac\n'}]",0,361850,deb5cb3fc206a3468ca3c3cadec93b72adeb0355,11,3,2,15905,,,0,"TrivialFix: Remove cfg import unused

This patch removes cfg import unused in
watcher/api/controllers/v1/goal.py
watcher/api/controllers/v1/strategy.py
watcher/decision_engine/cluster/history/ceilometer.py
watcher/decision_engine/model/collector/manager.py
watcher/decision_engine/strategy/selection/default.py
watcher/tests/common/test_ceilometer_helper.py
watcher/tests/decision_engine/fake_strategies.py
watcher/tests/decision_engine/strategy/selector/test_strategy_selector.py

Change-Id: I0f30a056c3efa49faed857b6d1001a2367d384ac
",git fetch https://review.opendev.org/openstack/watcher refs/changes/50/361850/2 && git format-patch -1 --stdout FETCH_HEAD,"['watcher/tests/decision_engine/fake_strategies.py', 'watcher/api/controllers/v1/goal.py', 'watcher/decision_engine/model/collector/manager.py', 'watcher/tests/decision_engine/strategy/selector/test_strategy_selector.py', 'watcher/api/controllers/v1/strategy.py', 'watcher/decision_engine/cluster/history/ceilometer.py', 'watcher/decision_engine/strategy/selection/default.py']",7,7516c60ff72b785ccd92e28e478eca523dc322fc,bug/remove-cfg-unused,,from oslo_config import cfgCONF = cfg.CONF,0,24
openstack%2Fdeb-auto-backports~debian%2Fnewton~I199f0191f5a4e53b00ff524255108974af991743,openstack/deb-auto-backports,debian/newton,I199f0191f5a4e53b00ff524255108974af991743,Build contextlib2,MERGED,2016-08-25 14:34:42.000000000,2016-08-29 14:43:44.000000000,2016-08-29 14:43:44.000000000,"[{'_account_id': 3}, {'_account_id': 6476}]","[{'number': 1, 'created': '2016-08-25 14:34:42.000000000', 'files': ['packages-list'], 'web_link': 'https://opendev.org/openstack/deb-auto-backports/commit/887b23d638c17b7f3fa37d98e4c14de304d20eca', 'message': 'Build contextlib2\n\nChange-Id: I199f0191f5a4e53b00ff524255108974af991743\n'}]",0,360595,887b23d638c17b7f3fa37d98e4c14de304d20eca,27,2,1,6476,,,0,"Build contextlib2

Change-Id: I199f0191f5a4e53b00ff524255108974af991743
",git fetch https://review.opendev.org/openstack/deb-auto-backports refs/changes/95/360595/1 && git format-patch -1 --stdout FETCH_HEAD,['packages-list'],1,887b23d638c17b7f3fa37d98e4c14de304d20eca,contextlib2,contextlib2,#contextlib2,1,1
openstack%2Ffuel-nailgun-extension-cluster-upgrade~master~Ia3b29f3f6d36442d5980e9fdff951bfcc3ad814f,openstack/fuel-nailgun-extension-cluster-upgrade,master,Ia3b29f3f6d36442d5980e9fdff951bfcc3ad814f,Fixes in CreateUpgradeReleaseHandler,MERGED,2016-08-25 15:45:15.000000000,2016-08-29 14:40:43.000000000,2016-08-29 14:38:57.000000000,"[{'_account_id': 3}, {'_account_id': 708}, {'_account_id': 1531}, {'_account_id': 19157}, {'_account_id': 20384}, {'_account_id': 20656}]","[{'number': 1, 'created': '2016-08-25 15:45:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-nailgun-extension-cluster-upgrade/commit/020dc53cc0c6505200c756967c22f5439c37353b', 'message': 'Fix typo and copy on release clone\n\nChange-Id: Ia3b29f3f6d36442d5980e9fdff951bfcc3ad814f\n'}, {'number': 2, 'created': '2016-08-25 16:30:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-nailgun-extension-cluster-upgrade/commit/7ac8fc3d711b841b603cc594eb96303909ea2fa5', 'message': 'Fix typo and copy on release clone\n\nChange-Id: Ia3b29f3f6d36442d5980e9fdff951bfcc3ad814f\n'}, {'number': 3, 'created': '2016-08-26 08:34:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-nailgun-extension-cluster-upgrade/commit/144f52482caf76b26036440f210e5c866d3dbdb0', 'message': 'Fix typo and copy on release clone\n\nChange-Id: Ia3b29f3f6d36442d5980e9fdff951bfcc3ad814f\n'}, {'number': 4, 'created': '2016-08-26 08:46:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-nailgun-extension-cluster-upgrade/commit/711ecd6e00153d4045dd7e9ba819450002007749', 'message': 'Fix typo and copy on release clone\n\nChange-Id: Ia3b29f3f6d36442d5980e9fdff951bfcc3ad814f\n'}, {'number': 5, 'created': '2016-08-26 09:43:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-nailgun-extension-cluster-upgrade/commit/59a19ced3b0db812f32b0dbdc3db56ab0eb1f5d2', 'message': 'Fix typo and copy on release clone\n\nChange-Id: Ia3b29f3f6d36442d5980e9fdff951bfcc3ad814f\n'}, {'number': 6, 'created': '2016-08-26 09:46:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-nailgun-extension-cluster-upgrade/commit/df2caad3e45596fb6e4215abaa727fd7219e9bc2', 'message': 'Fixes in CreateUpgradeReleaseHandler\n\n* add deployment_tasks in clone release\n* fix typo\n* copy net_roles_metadata on src releases\n\nChange-Id: Ia3b29f3f6d36442d5980e9fdff951bfcc3ad814f\n'}, {'number': 7, 'created': '2016-08-26 10:05:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-nailgun-extension-cluster-upgrade/commit/106eb078827155344342dbbadcbfc7e2378df43d', 'message': 'Fixes in CreateUpgradeReleaseHandler\n\n* add deployment_tasks in clone release\n* fix typo\n* copy net_roles_metadata on src releases\n\nChange-Id: Ia3b29f3f6d36442d5980e9fdff951bfcc3ad814f\nCloses-bug: 1617247\n'}, {'number': 8, 'created': '2016-08-29 09:06:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-nailgun-extension-cluster-upgrade/commit/f0b2a5d0cdf7c9aea9be3cb98177f05890cd2f36', 'message': 'Fixes in CreateUpgradeReleaseHandler\n\n* add deployment_tasks in clone release\n* fix typo\n* copy net_roles_metadata on src releases\n\nChange-Id: Ia3b29f3f6d36442d5980e9fdff951bfcc3ad814f\nCloses-bug: 1617247\n'}, {'number': 9, 'created': '2016-08-29 11:35:52.000000000', 'files': ['cluster_upgrade/handlers.py', 'cluster_upgrade/tests/test_handlers.py'], 'web_link': 'https://opendev.org/openstack/fuel-nailgun-extension-cluster-upgrade/commit/8147718cf776dc287b4952cb24f067f0c47991ac', 'message': 'Fixes in CreateUpgradeReleaseHandler\n\n* add deployment_tasks in clone release\n* fix typo\n* copy net_roles_metadata on src releases\n\nChange-Id: Ia3b29f3f6d36442d5980e9fdff951bfcc3ad814f\nCloses-bug: 1617247\n'}]",11,360645,8147718cf776dc287b4952cb24f067f0c47991ac,50,6,9,19157,,,0,"Fixes in CreateUpgradeReleaseHandler

* add deployment_tasks in clone release
* fix typo
* copy net_roles_metadata on src releases

Change-Id: Ia3b29f3f6d36442d5980e9fdff951bfcc3ad814f
Closes-bug: 1617247
",git fetch https://review.opendev.org/openstack/fuel-nailgun-extension-cluster-upgrade refs/changes/45/360645/1 && git format-patch -1 --stdout FETCH_HEAD,['cluster_upgrade/handlers.py'],1,020dc53cc0c6505200c756967c22f5439c37353b,bug/1617247,"import copy return base_nets copy.deepcopy(base_release.network_roles_metadata), copy.deepcopy(orig_release.network_roles_metadata)) return objects.Release.to_dict(new_release)"," return base_net base_release.network_roles_metadata, orig_release.network_roles_metadata) return new_release.to_dict()",5,6
openstack%2Ftempest~master~Id610479b59b0a6756b4b745683bd5d004c36e4a0,openstack/tempest,master,Id610479b59b0a6756b4b745683bd5d004c36e4a0,"Revert ""skip get-me-a-network tests""",MERGED,2016-08-27 21:38:36.000000000,2016-08-29 14:37:48.000000000,2016-08-29 14:37:47.000000000,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 2750}, {'_account_id': 5689}]","[{'number': 1, 'created': '2016-08-27 21:38:36.000000000', 'files': ['tempest/api/compute/admin/test_auto_allocate_network.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/707f9369342f66d17ecfcfcfc35542855cbd4bb3', 'message': 'Revert ""skip get-me-a-network tests""\n\nThis reverts commit e87e612144003c6a05549fa345999ad8058ad94c.\n\nNeutron pushed the fix in change:\n\nI3d62af3018fb834ec85771d8bc8e7379cc80b72a\n\nChange-Id: Id610479b59b0a6756b4b745683bd5d004c36e4a0\nRelated-Bug: #1615710\n'}]",0,361671,707f9369342f66d17ecfcfcfc35542855cbd4bb3,17,4,1,6873,,,0,"Revert ""skip get-me-a-network tests""

This reverts commit e87e612144003c6a05549fa345999ad8058ad94c.

Neutron pushed the fix in change:

I3d62af3018fb834ec85771d8bc8e7379cc80b72a

Change-Id: Id610479b59b0a6756b4b745683bd5d004c36e4a0
Related-Bug: #1615710
",git fetch https://review.opendev.org/openstack/tempest refs/changes/71/361671/1 && git format-patch -1 --stdout FETCH_HEAD,['tempest/api/compute/admin/test_auto_allocate_network.py'],1,707f9369342f66d17ecfcfcfc35542855cbd4bb3,auto_allocate_fail,," raise cls.skipException(""Disabled until bug #1616498 is fixed"")",0,1
openstack%2Fmurano~stable%2Fliberty~I06babce38bd90550f3d5d169e424209bc10ab11f,openstack/murano,stable/liberty,I06babce38bd90550f3d5d169e424209bc10ab11f,Use upper constraints for all jobs in tox.ini,ABANDONED,2016-08-23 11:16:32.000000000,2016-08-29 14:34:26.000000000,,"[{'_account_id': 3}, {'_account_id': 7821}, {'_account_id': 15168}, {'_account_id': 22020}]","[{'number': 1, 'created': '2016-08-23 11:16:32.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/murano/commit/0731d66e2608aaaed9f7811b3694571dbd2b6725', 'message': 'Use upper constraints for all jobs in tox.ini\n\nOpenstack infra now supports upper constraints for\nall jobs. Updated tox.ini to use upper constraints\nfor all jobs\n\nChange-Id: I06babce38bd90550f3d5d169e424209bc10ab11f\nCloses-Bug: #1614361\n(cherry picked from commit 5ff901ba1f2353fa783fb7318de2460a4fa722f0)\n'}]",0,359129,0731d66e2608aaaed9f7811b3694571dbd2b6725,16,4,1,22020,,,0,"Use upper constraints for all jobs in tox.ini

Openstack infra now supports upper constraints for
all jobs. Updated tox.ini to use upper constraints
for all jobs

Change-Id: I06babce38bd90550f3d5d169e424209bc10ab11f
Closes-Bug: #1614361
(cherry picked from commit 5ff901ba1f2353fa783fb7318de2460a4fa722f0)
",git fetch https://review.opendev.org/openstack/murano refs/changes/29/359129/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,0731d66e2608aaaed9f7811b3694571dbd2b6725,bug/1614361,,"# NOTE(from nova tox.ini by jaegerandi): This target does not use constraints # because upstream infra does not yet support it. Once that's fixed, we can # drop the install_command. install_command = pip install -U --force-reinstall {opts} {packages}# NOTE(from nova tox.ini by jaegerandi): This target does not use constraints # because upstream infra does not yet support it. Once that's fixed, we can # drop the install_command. install_command = pip install -U --force-reinstall {opts} {packages}# NOTE(from nova tox.ini by jaegerandi): This target does not use constraints # because upstream infra does not yet support it. Once that's fixed, we can # drop the install_command. install_command = pip install -U --force-reinstall {opts} {packages}",0,12
openstack%2Fdeb-python-linecache2~debian%2Fnewton~I336e1dc831b889b8ab638b7f2d82a2ea2e391b8f,openstack/deb-python-linecache2,debian/newton,I336e1dc831b889b8ab638b7f2d82a2ea2e391b8f,Re-enable tests,MERGED,2016-08-29 13:30:35.000000000,2016-08-29 14:32:44.000000000,2016-08-29 14:32:43.000000000,"[{'_account_id': 3}, {'_account_id': 6476}]","[{'number': 1, 'created': '2016-08-29 13:30:35.000000000', 'files': ['debian/rules', 'debian/control'], 'web_link': 'https://opendev.org/openstack/deb-python-linecache2/commit/8fcbe2b2882721981988d31dd7cfb293c8d92138', 'message': 'Re-enable tests\n\nChange-Id: I336e1dc831b889b8ab638b7f2d82a2ea2e391b8f\n'}]",0,362114,8fcbe2b2882721981988d31dd7cfb293c8d92138,6,2,1,6476,,,0,"Re-enable tests

Change-Id: I336e1dc831b889b8ab638b7f2d82a2ea2e391b8f
",git fetch https://review.opendev.org/openstack/deb-python-linecache2 refs/changes/14/362114/1 && git format-patch -1 --stdout FETCH_HEAD,"['debian/rules', 'debian/control']",2,8fcbe2b2882721981988d31dd7cfb293c8d92138,,"Build-Depends-Indep: python-fixtures, python-unittest2, python3-fixtures, python3-unittest2,","#Build-Depends-Indep: python-fixtures, # python-unittest2, # python3-fixtures, # python3-unittest2,",10,11
openstack%2Ftempest~master~Ia264c47ef38f055288a1df58eb94f327693cd3b4,openstack/tempest,master,Ia264c47ef38f055288a1df58eb94f327693cd3b4,"Revert ""skip get-me-a-network tests""",ABANDONED,2016-08-29 12:30:03.000000000,2016-08-29 14:29:50.000000000,,"[{'_account_id': 3}, {'_account_id': 10385}]","[{'number': 1, 'created': '2016-08-29 12:30:03.000000000', 'files': ['tempest/api/compute/admin/test_auto_allocate_network.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/8ab08561f8495b47f06c3367a303148aa639c693', 'message': 'Revert ""skip get-me-a-network tests""\n\nThis reverts commit e87e612144003c6a05549fa345999ad8058ad94c.\n\nChange-Id: Ia264c47ef38f055288a1df58eb94f327693cd3b4\n'}]",0,362075,8ab08561f8495b47f06c3367a303148aa639c693,3,2,1,2750,,,0,"Revert ""skip get-me-a-network tests""

This reverts commit e87e612144003c6a05549fa345999ad8058ad94c.

Change-Id: Ia264c47ef38f055288a1df58eb94f327693cd3b4
",git fetch https://review.opendev.org/openstack/tempest refs/changes/75/362075/1 && git format-patch -1 --stdout FETCH_HEAD,['tempest/api/compute/admin/test_auto_allocate_network.py'],1,8ab08561f8495b47f06c3367a303148aa639c693,auto_allocate_fail,," raise cls.skipException(""Disabled until bug #1616498 is fixed"")",0,1
openstack%2Fpython-mistralclient~master~I9b29ece2d04cdadc1d2e6cf51a594ab0e9a3fa74,openstack/python-mistralclient,master,I9b29ece2d04cdadc1d2e6cf51a594ab0e9a3fa74,Clean imports in code,MERGED,2016-08-29 06:58:57.000000000,2016-08-29 14:29:14.000000000,2016-08-29 14:29:14.000000000,"[{'_account_id': 3}, {'_account_id': 8731}, {'_account_id': 18238}]","[{'number': 1, 'created': '2016-08-29 06:58:57.000000000', 'files': ['mistralclient/tests/unit/v2/test_environments.py'], 'web_link': 'https://opendev.org/openstack/python-mistralclient/commit/227c429a77004baf6ca95d1b9167d1222eb1388f', 'message': 'Clean imports in code\n\nThis patch set modifies lines which are importing objects\ninstead of modules. As per openstack import guide lines, user should\nimport modules in a file not objects.\n\nhttp://docs.openstack.org/developer/hacking/#imports\n\nChange-Id: I9b29ece2d04cdadc1d2e6cf51a594ab0e9a3fa74\n'}]",0,361889,227c429a77004baf6ca95d1b9167d1222eb1388f,11,3,1,15905,,,0,"Clean imports in code

This patch set modifies lines which are importing objects
instead of modules. As per openstack import guide lines, user should
import modules in a file not objects.

http://docs.openstack.org/developer/hacking/#imports

Change-Id: I9b29ece2d04cdadc1d2e6cf51a594ab0e9a3fa74
",git fetch https://review.opendev.org/openstack/python-mistralclient refs/changes/89/361889/1 && git format-patch -1 --stdout FETCH_HEAD,['mistralclient/tests/unit/v2/test_environments.py'],1,227c429a77004baf6ca95d1b9167d1222eb1388f,cleancode,import collections data = collections.OrderedDict( data = collections.OrderedDict(,from collections import OrderedDict data = OrderedDict( data = OrderedDict(,3,3
openstack%2Fceilometer~master~Ic663d229990c028888f0ecd7f7b85561ad618bf4,openstack/ceilometer,master,Ic663d229990c028888f0ecd7f7b85561ad618bf4,Fix a warning when running `tox -e api-ref`,MERGED,2016-08-22 20:57:18.000000000,2016-08-29 14:28:13.000000000,2016-08-29 14:28:13.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 6537}, {'_account_id': 18802}, {'_account_id': 22779}]","[{'number': 1, 'created': '2016-08-22 20:57:18.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/5684aa0d1dfa2d3b0488c73f79c0d9107c6fc672', 'message': 'Fix a warning when running `tox -e api-ref`\n\nWhen executing `tox -e api-ref`, the following warning appears.\n\n    WARNING:test command found but not installed in testenv\n      cmd: /bin/rm\n      env: /Users/tl3438/oss/ceilometer/.tox/api-ref\n    Maybe you forgot to specify a dependency? See also ...\n\nThis patch set adds the whitelist_externals to api-ref.\n\nChange-Id: Ic663d229990c028888f0ecd7f7b85561ad618bf4\n'}]",1,358859,5684aa0d1dfa2d3b0488c73f79c0d9107c6fc672,12,5,1,20466,,,0,"Fix a warning when running `tox -e api-ref`

When executing `tox -e api-ref`, the following warning appears.

    WARNING:test command found but not installed in testenv
      cmd: /bin/rm
      env: /Users/tl3438/oss/ceilometer/.tox/api-ref
    Maybe you forgot to specify a dependency? See also ...

This patch set adds the whitelist_externals to api-ref.

Change-Id: Ic663d229990c028888f0ecd7f7b85561ad618bf4
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/59/358859/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,5684aa0d1dfa2d3b0488c73f79c0d9107c6fc672,fix/api-ref-warning,whitelist_externals = rm,,1,0
openstack%2Fironic~master~Ia06a6f33dcd848b761d1465b12175d3ba9621e4a,openstack/ironic,master,Ia06a6f33dcd848b761d1465b12175d3ba9621e4a,Add metrics for the ipminative driver,MERGED,2016-08-09 10:20:55.000000000,2016-08-29 14:27:29.000000000,2016-08-29 14:27:29.000000000,"[{'_account_id': 3}, {'_account_id': 8125}, {'_account_id': 10239}, {'_account_id': 10343}]","[{'number': 1, 'created': '2016-08-09 10:20:55.000000000', 'files': ['ironic/drivers/modules/ipminative.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/fc08c9a6f1aa70a34a61340d9543eb56eb72561c', 'message': 'Add metrics for the ipminative driver\n\nAdd timing metrics for the methods in the ipminative driver.\n\nChange-Id: Ia06a6f33dcd848b761d1465b12175d3ba9621e4a\nRelated-Bug: #1526219\n'}]",0,352829,fc08c9a6f1aa70a34a61340d9543eb56eb72561c,10,4,1,20522,,,0,"Add metrics for the ipminative driver

Add timing metrics for the methods in the ipminative driver.

Change-Id: Ia06a6f33dcd848b761d1465b12175d3ba9621e4a
Related-Bug: #1526219
",git fetch https://review.opendev.org/openstack/ironic refs/changes/29/352829/1 && git format-patch -1 --stdout FETCH_HEAD,['ironic/drivers/modules/ipminative.py'],1,fc08c9a6f1aa70a34a61340d9543eb56eb72561c,bug/1526219,from ironic_lib import metrics_utilsMETRICS = metrics_utils.get_metrics_logger(__name__) @METRICS.timer('NativeIPMIPower.validate') @METRICS.timer('NativeIPMIPower.get_power_state') @METRICS.timer('NativeIPMIPower.set_power_state') @METRICS.timer('NativeIPMIPower.reboot') @METRICS.timer('NativeIPMIManagement.validate') @METRICS.timer('NativeIPMIManagement.set_boot_device') @METRICS.timer('NativeIPMIManagement.get_boot_device') @METRICS.timer('NativeIPMIManagement.get_sensors_data') @METRICS.timer('NativeIPMIShellinaboxConsole.validate') @METRICS.timer('NativeIPMIShellinaboxConsole.start_console') @METRICS.timer('NativeIPMIShellinaboxConsole.stop_console') @METRICS.timer('NativeIPMIShellinaboxConsole.get_console') @METRICS.timer('VendorPassthru.validate') @METRICS.timer('VendorPassthru.send_raw') @METRICS.timer('VendorPassthru.bmc_reset'),,18,0
openstack%2Ffuel-plugin-murano-tests~master~I40c76144e7dd34a159a1fa863152f6ce0047c604,openstack/fuel-plugin-murano-tests,master,I40c76144e7dd34a159a1fa863152f6ce0047c604,Add system tests for deployment murano to controllers via plugin,MERGED,2016-08-29 14:07:09.000000000,2016-08-29 14:27:02.000000000,2016-08-29 14:27:02.000000000,"[{'_account_id': 3}, {'_account_id': 13962}, {'_account_id': 15168}]","[{'number': 1, 'created': '2016-08-29 14:07:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-plugin-murano-tests/commit/9f7ca30266d5d2bdc67f3d93818edeca870d424e', 'message': 'Add system tests for deployment murano to controllers via plugin\n\n- Added HA and non-HA system tests for deployment murano via plugin to controllers\n- Fixed test names in murano upgrade tests\n\nChange-Id: I40c76144e7dd34a159a1fa863152f6ce0047c604\n'}, {'number': 2, 'created': '2016-08-29 14:14:59.000000000', 'files': ['murano_plugin_tests/murano_plugin/test_murano_plugin_bvt.py', 'murano_plugin_tests/murano_plugin/test_murano_plugin_update.py', 'murano_plugin_tests/run_tests.py', 'murano_plugin_tests/murano_plugin/api.py'], 'web_link': 'https://opendev.org/openstack/fuel-plugin-murano-tests/commit/0ee35e5e89d5381f155ee9fec1658a3eb89c241a', 'message': 'Add system tests for deployment murano to controllers via plugin\n\n- Added HA and non-HA system tests for deployment murano via plugin to controllers\n- Fixed test names in murano upgrade tests\n\nChange-Id: I40c76144e7dd34a159a1fa863152f6ce0047c604\n'}]",0,362139,0ee35e5e89d5381f155ee9fec1658a3eb89c241a,10,3,2,13962,,,0,"Add system tests for deployment murano to controllers via plugin

- Added HA and non-HA system tests for deployment murano via plugin to controllers
- Fixed test names in murano upgrade tests

Change-Id: I40c76144e7dd34a159a1fa863152f6ce0047c604
",git fetch https://review.opendev.org/openstack/fuel-plugin-murano-tests refs/changes/39/362139/2 && git format-patch -1 --stdout FETCH_HEAD,"['murano_plugin_tests/murano_plugin/test_murano_plugin_bvt.py', 'murano_plugin_tests/murano_plugin/test_murano_plugin_update.py', 'murano_plugin_tests/murano_plugin/api.py']",3,9f7ca30266d5d2bdc67f3d93818edeca870d424e,," def only_controllers_ha(self): """"""Return a dict mapping nodes to Fuel roles without HA and without murano-node"""""" return { 'slave-01': ['controller'], 'slave-02': ['controller'], 'slave-03': ['controller'], 'slave-04': ['compute', 'cinder'] } @property def only_controllers(self): """"""Return a dict mapping nodes to Fuel roles without HA and without murano-node"""""" return { 'slave-01': ['controller'], 'slave-02': ['compute', 'cinder'] } @property",,95,5
openstack%2Fopenstack-manuals~master~I5331a06907660684da741d234ab78b44c11c7769,openstack/openstack-manuals,master,I5331a06907660684da741d234ab78b44c11c7769,"[user-guide]Reorganize the steps in ""Create Instance"" form",MERGED,2016-08-28 14:21:10.000000000,2016-08-29 14:23:47.000000000,2016-08-29 14:23:47.000000000,"[{'_account_id': 3}, {'_account_id': 964}, {'_account_id': 9162}, {'_account_id': 10497}, {'_account_id': 14947}, {'_account_id': 21486}, {'_account_id': 22165}, {'_account_id': 23058}, {'_account_id': 23308}]","[{'number': 1, 'created': '2016-08-28 14:21:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/d24b386c57dedc84bb8529b324a4395866bedcc5', 'message': '[user-guide]Reorganize the steps in ""Create Instance"" form\n\nAdd some "":guilabel:"" markup and fix some "":guilabel:"" markup value\n\nChange-Id: I5331a06907660684da741d234ab78b44c11c7769\n'}, {'number': 2, 'created': '2016-08-29 11:12:53.000000000', 'files': ['doc/user-guide/source/dashboard-launch-instances.rst'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/b9568f8471a9875dd0e638a176e3582dd1bf4814', 'message': '[user-guide]Reorganize the steps in ""Create Instance"" form\n\nAdd some "":guilabel:"" markup and fix some "":guilabel:"" markup value\n\nChange-Id: I5331a06907660684da741d234ab78b44c11c7769\n'}]",2,361752,b9568f8471a9875dd0e638a176e3582dd1bf4814,15,9,2,14151,,,0,"[user-guide]Reorganize the steps in ""Create Instance"" form

Add some "":guilabel:"" markup and fix some "":guilabel:"" markup value

Change-Id: I5331a06907660684da741d234ab78b44c11c7769
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/52/361752/2 && git format-patch -1 --stdout FETCH_HEAD,['doc/user-guide/source/dashboard-launch-instances.rst'],1,d24b386c57dedc84bb8529b324a4395866bedcc5,," Instance Name Assign a name to the virtual machine. Count :guilabel:`Source` tab :guilabel:`Flavor` tab Flavor Specify the size of the instance to launch. .. note:: The flavor is selected based on the size of the image selected for launching an instance. For example, while creating an image, if you have entered the value in the :guilabel:`Minimum RAM (MB)` field as 2048, then on selecting the image, the default flavor is ``m1.small``. :guilabel:`Networks` tab Selected Networks To add a network to the instance, click the :guilabel:`+` in the :guilabel:`Available` field. :guilabel:`Network Ports` tab Ports Activate the ports that you want to assign to the instance. :guilabel:`Security Groups` tab :guilabel:`Key Pair` tab Key Pair Specify a key pair. If the image uses a static root password or a static key set (neither is recommended), you do not need to provide a key pair to launch the instance. :guilabel:`Configuration` tab :guilabel:`Metadata` tab Available Metadata Add Metadata items to your instance. #. Click :guilabel:`Launch Instance`."," Instance Name Assign a name to the virtual machine. Flavor Specify the size of the instance to launch. .. note:: The flavor is selected based on the size of the image selected for launching an instance. For example, while creating an image, if you have entered the value in the :guilabel:`Minimum RAM (MB)` field as 2048, then on selecting the image, the default flavor is ``m1.small``. Instance Count :guilabel:`Access & Security` tab Key Pair Specify a key pair. If the image uses a static root password or a static key set (neither is recommended), you do not need to provide a key pair to launch the instance. :guilabel:`Networking` tab Selected Networks To add a network to the instance, click the :guilabel:`+` in the :guilabel:`Available Networks` field. :guilabel:`Network Ports` tab Ports Activate the ports that you want to assign to the instance. :guilabel:`Post-Creation` tab :guilabel:`Advanced Options` tab Disk Partition Select the type of disk partition from the dropdown list: Automatic Entire disk is single partition and automatically resizes. Manual Faster build times but requires manual partitioning. #. Click :guilabel:`Launch`.",40,41
openstack%2Fheat~master~I0e8f99db73b07b8bd6914e37e2688f06432dab9b,openstack/heat,master,I0e8f99db73b07b8bd6914e37e2688f06432dab9b,Add new resource l7rule,MERGED,2016-06-02 11:20:31.000000000,2016-08-29 14:21:43.000000000,2016-08-29 14:21:43.000000000,"[{'_account_id': 3}, {'_account_id': 4257}, {'_account_id': 12363}, {'_account_id': 13009}, {'_account_id': 13323}, {'_account_id': 20559}]","[{'number': 1, 'created': '2016-06-02 11:20:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/89d0933d1c236de54d4bd79568b28476421e8bd5', 'message': ""Add new resources l7policy and l7rule\n\nAdd support of new neutron lbaas resources.\nFew notes:\n1. We need to check loadbalancer status to correctly\ncreate, update and delete resources in lbaas. But now\nthere is no way to get loadbalancer id while we are\nin l7rule. So I used exception message parsing to get\nloadbalancer id. It looks bad, but I couldn't figure\nout a better way.\n2. In l7policy there is a property redirect url which\nis being validated in neutron (actually in octavia).\nI can add such validation in Heat but it is using\nmodule rfc3986 which we are not using now. So if we\nwant to add exactly same validation, we need to add\nrfc3986 into requirements. I don't know if this is good\nidea or is it better to just let it fail on neutron\nlevel. Is there any other resources using url properties\nthat would benefit from validation?\n\nChange-Id: I0e8f99db73b07b8bd6914e37e2688f06432dab9b\nCloses-Bug: #1563041\n""}, {'number': 2, 'created': '2016-06-03 10:31:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/f7e3c685166b4341faf6b2348400a56955c15466', 'message': ""Add new resources l7policy and l7rule\n\nAdd support of new neutron lbaas resources.\nFew notes:\n1. We need to check loadbalancer status to correctly\ncreate, update and delete resources in lbaas. But now\nthere is no way to get loadbalancer id while we are\nin l7rule. So I used exception message parsing to get\nloadbalancer id. It looks bad, but I couldn't figure\nout a better way.\n2. In l7policy there is a property redirect url which\nis being validated in neutron (actually in octavia).\nI can add such validation in Heat but it is using\nmodule rfc3986 which we are not using now. So if we\nwant to add exactly same validation, we need to add\nrfc3986 into requirements. I don't know if this is good\nidea or is it better to just let it fail on neutron\nlevel. Is there any other resources using url properties\nthat would benefit from validation?\n\nChange-Id: I0e8f99db73b07b8bd6914e37e2688f06432dab9b\nCloses-Bug: #1563041\n""}, {'number': 3, 'created': '2016-06-07 14:47:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/7a583f55c702d094ca39b6d714b6344d00c58bfa', 'message': ""Add new resources l7policy and l7rule\n\nAdd support of new neutron lbaas resources.\nAlso, a note:\nIn l7policy there is a property redirect url which\nis being validated in neutron (actually in octavia).\nI can add such validation in Heat but it is using\nmodule rfc3986 which we are not using now. So if we\nwant to add exactly same validation, we need to add\nrfc3986 into requirements. I don't know if this is good\nidea or is it better to just let it fail on neutron\nlevel. Is there any other resources using url properties\nthat would benefit from validation?\n\nChange-Id: I0e8f99db73b07b8bd6914e37e2688f06432dab9b\nDepends-On: I1e7a173642f87851c35dd8b644d1f06653d7776a\nCloses-Bug: #1563041\n""}, {'number': 4, 'created': '2016-06-09 14:03:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/ed47b89abb64ce89eb63d1edc5fe4dfad5378775', 'message': 'Add new resources l7policy and l7rule\n\nAdd support of new neutron lbaas resources.\n\nChange-Id: I0e8f99db73b07b8bd6914e37e2688f06432dab9b\nDepends-On: I1e7a173642f87851c35dd8b644d1f06653d7776a\nCloses-Bug: #1563041\n'}, {'number': 5, 'created': '2016-06-09 17:09:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/f7949b70f9e96e6eb91042fb409c306c0c8bd0ae', 'message': 'Add new resources l7policy and l7rule\n\nAdd support of new neutron lbaas resources.\n\nChange-Id: I0e8f99db73b07b8bd6914e37e2688f06432dab9b\nDepends-On: I1e7a173642f87851c35dd8b644d1f06653d7776a\nCloses-Bug: #1563041\n'}, {'number': 6, 'created': '2016-06-10 09:02:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/f6c9d0e8ebed62691380e6ae1547ac1e0ebf84b0', 'message': 'Add new resources l7policy and l7rule\n\nAdd support of new neutron lbaas resources.\n\nChange-Id: I0e8f99db73b07b8bd6914e37e2688f06432dab9b\nDepends-On: I1e7a173642f87851c35dd8b644d1f06653d7776a\nCloses-Bug: #1563041\n'}, {'number': 7, 'created': '2016-07-06 15:21:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/18d58e103b685b3dc5b0508436ea36a000cbcca6', 'message': 'Add new resource l7rule\n\nAdd support of new neutron lbaas l7rule resource.\n\nChange-Id: I0e8f99db73b07b8bd6914e37e2688f06432dab9b\nDepends-On: I1e7a173642f87851c35dd8b644d1f06653d7776a\nImplements: bp lbaas-l7-rules-support\nPartially fixes: #1563041\n'}, {'number': 8, 'created': '2016-08-26 08:42:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/0558f7a1a65b424683260a952d4bef923f78debe', 'message': 'Add new resource l7rule\n\nAdd support of new neutron lbaas l7rule resource.\n\nImplements: bp lbaas-l7-rules-support\nPartially fixes: #1563041\n\nChange-Id: I0e8f99db73b07b8bd6914e37e2688f06432dab9b\n'}, {'number': 9, 'created': '2016-08-26 10:24:26.000000000', 'files': ['heat/tests/openstack/neutron/inline_templates.py', 'heat/tests/openstack/neutron/lbaas/test_l7rule.py', 'heat/engine/resources/openstack/neutron/lbaas/l7rule.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/b5a7d143dd84c8e5949784aef73656bb24d25787', 'message': 'Add new resource l7rule\n\nAdd support of new neutron lbaas l7rule resource.\n\nImplements: bp lbaas-l7-rules-support\nPartial-bug: #1563041\n\nChange-Id: I0e8f99db73b07b8bd6914e37e2688f06432dab9b\n'}]",24,324375,b5a7d143dd84c8e5949784aef73656bb24d25787,49,6,9,20559,,,0,"Add new resource l7rule

Add support of new neutron lbaas l7rule resource.

Implements: bp lbaas-l7-rules-support
Partial-bug: #1563041

Change-Id: I0e8f99db73b07b8bd6914e37e2688f06432dab9b
",git fetch https://review.opendev.org/openstack/heat refs/changes/75/324375/5 && git format-patch -1 --stdout FETCH_HEAD,"['heat/tests/openstack/neutron/inline_templates.py', 'heat/tests/openstack/neutron/lbaas/test_l7rule.py', 'heat/engine/resources/openstack/neutron/lbaas/l7rule.py', 'heat/engine/resources/openstack/neutron/lbaas/l7policy.py', 'heat/tests/openstack/neutron/lbaas/test_l7policy.py']",5,89d0933d1c236de54d4bd79568b28476421e8bd5,bp/lbaas-l7-rules-support,"# # Copyright 2015 IBM Corp. # # All Rights Reserved. # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import mock import yaml from neutronclient.common import exceptions from heat.common import exception from heat.common.i18n import _ from heat.common import template_format from heat.engine.resources.openstack.neutron.lbaas import l7policy from heat.tests import common from heat.tests.openstack.neutron import inline_templates from heat.tests import utils class L7PolicyTest(common.HeatTestCase): def setUp(self): super(L7PolicyTest, self).setUp() def test_resource_mapping(self): mapping = l7policy.resource_mapping() self.assertEqual(l7policy.L7Policy, mapping['OS::Neutron::LBaaS::L7Policy']) @mock.patch('heat.engine.clients.os.neutron.' 'NeutronClientPlugin.has_extension', return_value=True) def _create_stack(self, ext_func, tmpl=inline_templates.L7POLICY_TEMPLATE): self.t = template_format.parse(tmpl) self.stack = utils.parse_stack(self.t) self.l7policy = self.stack['l7policy'] self.neutron_client = mock.MagicMock() self.l7policy.client = mock.MagicMock(return_value=self.neutron_client) self.l7policy.client_plugin().find_resourceid_by_name_or_id = ( mock.MagicMock(return_value='123')) self.l7policy.client_plugin().client = mock.MagicMock( return_value=self.neutron_client) self.neutron_client.show_loadbalancer.side_effect = [ {'loadbalancer': {'provisioning_status': 'PENDING_UPDATE'}}, {'loadbalancer': {'provisioning_status': 'PENDING_UPDATE'}}, {'loadbalancer': {'provisioning_status': 'ACTIVE'}}, ] def test_validate_reject_action_with_conflicting_props(self): tmpl = yaml.load(inline_templates.L7POLICY_TEMPLATE) props = tmpl['resources']['l7policy']['properties'] props['action'] = 'REJECT' self._create_stack(tmpl=yaml.dump(tmpl)) msg = _('Properties redirect_pool and redirect_url are not ' 'required when action type is set to REJECT.') with mock.patch('heat.engine.clients.os.neutron.NeutronClientPlugin.' 'has_extension', return_value=True): self.assertRaisesRegexp(exception.StackValidationFailed, msg, self.l7policy.validate) def test_validate_redirect_pool_action_with_url(self): tmpl = yaml.load(inline_templates.L7POLICY_TEMPLATE) props = tmpl['resources']['l7policy']['properties'] props['action'] = 'REDIRECT_TO_POOL' props['redirect_pool'] = '123' self._create_stack(tmpl=yaml.dump(tmpl)) msg = _('redirect_url property should only be specified ' 'for action with value REDIRECT_TO_URL.') with mock.patch('heat.engine.clients.os.neutron.NeutronClientPlugin.' 'has_extension', return_value=True): self.assertRaisesRegexp(exception.ResourcePropertyValueDependency, msg, self.l7policy.validate) def test_validate_redirect_pool_action_without_pool(self): tmpl = yaml.load(inline_templates.L7POLICY_TEMPLATE) props = tmpl['resources']['l7policy']['properties'] props['action'] = 'REDIRECT_TO_POOL' del props['redirect_url'] self._create_stack(tmpl=yaml.dump(tmpl)) msg = _('Property redirect_pool is required when action type ' 'is set to REDIRECT_TO_POOL.') with mock.patch('heat.engine.clients.os.neutron.NeutronClientPlugin.' 'has_extension', return_value=True): self.assertRaisesRegexp(exception.StackValidationFailed, msg, self.l7policy.validate) def test_validate_redirect_url_action_with_pool(self): tmpl = yaml.load(inline_templates.L7POLICY_TEMPLATE) props = tmpl['resources']['l7policy']['properties'] props['redirect_pool'] = '123' self._create_stack(tmpl=yaml.dump(tmpl)) msg = _('redirect_pool property should only be specified ' 'for action with value REDIRECT_TO_POOL.') with mock.patch('heat.engine.clients.os.neutron.NeutronClientPlugin.' 'has_extension', return_value=True): self.assertRaisesRegexp(exception.ResourcePropertyValueDependency, msg, self.l7policy.validate) def test_validate_redirect_url_action_without_url(self): tmpl = yaml.load(inline_templates.L7POLICY_TEMPLATE) props = tmpl['resources']['l7policy']['properties'] del props['redirect_url'] self._create_stack(tmpl=yaml.dump(tmpl)) msg = _('Property redirect_url is required when action type ' 'is set to REDIRECT_TO_URL.') with mock.patch('heat.engine.clients.os.neutron.NeutronClientPlugin.' 'has_extension', return_value=True): self.assertRaisesRegexp(exception.StackValidationFailed, msg, self.l7policy.validate) def test_create(self): self._create_stack() self.neutron_client.create_lbaas_l7policy.side_effect = [ exceptions.StateInvalidClient, {'l7policy': {'id': '1234'}} ] expected = { 'l7policy': { 'name': u'test_l7policy', 'description': u'test l7policy resource', 'action': u'REDIRECT_TO_URL', 'listener_id': u'123', 'redirect_url': u'http://www.mirantis.com', 'position': 1, 'admin_state_up': True } } props = self.l7policy.handle_create() self.assertFalse(self.l7policy.check_create_complete(props)) self.neutron_client.create_lbaas_l7policy.assert_called_with(expected) self.assertFalse(self.l7policy.check_create_complete(props)) self.neutron_client.create_lbaas_l7policy.assert_called_with(expected) self.assertFalse(self.l7policy.check_create_complete(props)) self.assertTrue(self.l7policy.check_create_complete(props)) def test_create_missing_properties(self): for prop in ('action', 'listener'): tmpl = yaml.load(inline_templates.L7POLICY_TEMPLATE) del tmpl['resources']['l7policy']['properties'][prop] self._create_stack(tmpl=yaml.dump(tmpl)) self.assertRaises(exception.StackValidationFailed, self.l7policy.validate) def test_show_resource(self): self._create_stack() self.l7policy.resource_id_set('1234') self.neutron_client.show_lbaas_l7policy.return_value = { 'l7policy': {'id': '1234'} } self.assertEqual(self.l7policy._show_resource(), {'id': '1234'}) self.neutron_client.show_lbaas_l7policy.assert_called_with('1234') def test_update(self): self._create_stack() self.l7policy.resource_id_set('1234') self.neutron_client.update_lbaas_l7policy.side_effect = [ exceptions.StateInvalidClient, None] prop_diff = { 'admin_state_up': False, 'name': 'your_l7policy', 'redirect_url': 'http://www.google.com' } prop_diff = self.l7policy.handle_update(None, None, prop_diff) self.assertFalse(self.l7policy.check_update_complete(prop_diff)) self.assertFalse(self.l7policy._update_called) self.neutron_client.update_lbaas_l7policy.assert_called_with( '1234', {'l7policy': prop_diff}) self.assertFalse(self.l7policy.check_update_complete(prop_diff)) self.assertTrue(self.l7policy._update_called) self.neutron_client.update_lbaas_l7policy.assert_called_with( '1234', {'l7policy': prop_diff}) self.assertFalse(self.l7policy.check_update_complete(prop_diff)) self.assertTrue(self.l7policy.check_update_complete(prop_diff)) def test_update_redirect_pool_prop_name(self): self._create_stack() self.l7policy.resource_id_set('1234') self.neutron_client.update_lbaas_l7policy.side_effect = [ exceptions.StateInvalidClient, None] unresolved_diff = { 'redirect_url': None, 'action': 'REDIRECT_TO_POOL', 'redirect_pool': 'UNRESOLVED_POOL' } resolved_diff = { 'redirect_url': None, 'action': 'REDIRECT_TO_POOL', 'redirect_pool_id': '123' } self.l7policy.handle_update(None, None, unresolved_diff) self.assertFalse(self.l7policy.check_update_complete(resolved_diff)) self.assertFalse(self.l7policy._update_called) self.neutron_client.update_lbaas_l7policy.assert_called_with( '1234', {'l7policy': resolved_diff}) self.assertFalse(self.l7policy.check_update_complete(resolved_diff)) self.assertTrue(self.l7policy._update_called) self.neutron_client.update_lbaas_l7policy.assert_called_with( '1234', {'l7policy': resolved_diff}) self.assertFalse(self.l7policy.check_update_complete(resolved_diff)) self.assertTrue(self.l7policy.check_update_complete(resolved_diff)) def test_delete(self): self._create_stack() self.l7policy.resource_id_set('1234') self.neutron_client.delete_lbaas_l7policy.side_effect = [ exceptions.StateInvalidClient, None] self.l7policy.handle_delete() self.assertFalse(self.l7policy.check_delete_complete(None)) self.assertFalse(self.l7policy._delete_called) self.assertFalse(self.l7policy.check_delete_complete(None)) self.assertTrue(self.l7policy._delete_called) self.neutron_client.delete_lbaas_l7policy.assert_called_with('1234') self.assertFalse(self.l7policy.check_delete_complete(None)) self.assertTrue(self.l7policy.check_delete_complete(None)) def test_delete_already_gone(self): self._create_stack() self.l7policy.resource_id_set('1234') self.neutron_client.delete_lbaas_l7policy.side_effect = ( exceptions.NotFound) self.l7policy.handle_delete() self.assertTrue(self.l7policy.check_delete_complete(None)) def test_delete_failed(self): self._create_stack() self.l7policy.resource_id_set('1234') self.neutron_client.delete_lbaas_l7policy.side_effect = ( exceptions.Unauthorized) self.l7policy.handle_delete() self.assertRaises(exceptions.Unauthorized, self.l7policy.check_delete_complete, None) ",,992,0
openstack%2Fpuppet-ironic~master~Ic6844bf313a08b8481d3474185d08d878ff52b5a,openstack/puppet-ironic,master,Ic6844bf313a08b8481d3474185d08d878ff52b5a,Clean up ironic::drivers::pxe,MERGED,2016-08-26 12:39:22.000000000,2016-08-29 14:21:33.000000000,2016-08-29 14:21:33.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 7745}, {'_account_id': 8971}]","[{'number': 1, 'created': '2016-08-26 12:39:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-ironic/commit/66bcafd8ca928f0b2e7a779afed70c669518633c', 'message': ""[WIP] Clean up ironic::drivers::pxe\n\nDetect boot file name and boot templates based on ipxe_enabled (unfortunately,\nthat required an explicit default for ipxe_enabled instead of os_service_default).\n\nSwitch quite a few parameters to os_service_default, where our defaults don't differ\nfrom upstream defaults. TFTP root path is left alone, as it will be refactored soon.\n\nDeprecate three parameters that do not exist in ironic (at least now).\n\nChange-Id: Ic6844bf313a08b8481d3474185d08d878ff52b5a\n""}, {'number': 2, 'created': '2016-08-26 13:06:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-ironic/commit/3e11b8e55d93c8f179d4acb5ab13daee5e1c40bd', 'message': ""Clean up ironic::drivers::pxe\n\nDetect boot file name and boot templates based on ipxe_enabled (unfortunately,\nthat required an explicit default for ipxe_enabled instead of os_service_default).\n\nSwitch quite a few parameters to os_service_default, where our defaults don't differ\nfrom upstream defaults. TFTP root path is left alone, as it will be refactored soon.\n\nDeprecate three parameters that do not exist in ironic (at least now).\n\nChange-Id: Ic6844bf313a08b8481d3474185d08d878ff52b5a\n""}, {'number': 3, 'created': '2016-08-26 16:54:22.000000000', 'files': ['manifests/drivers/pxe.pp', 'spec/classes/ironic_drivers_pxe_spec.rb', 'releasenotes/notes/drivers-pxe-5ced870285f654ad.yaml'], 'web_link': 'https://opendev.org/openstack/puppet-ironic/commit/b5d2769041fc6787d88e34331b09701c285131a2', 'message': ""Clean up ironic::drivers::pxe\n\nDetect boot file name and boot templates based on ipxe_enabled (unfortunately,\nthat required an explicit default for ipxe_enabled instead of os_service_default).\n\nSwitch quite a few parameters to os_service_default, where our defaults don't differ\nfrom upstream defaults. TFTP root path is left alone, as it will be refactored soon.\n\nDeprecate three parameters that do not exist in ironic (at least now).\n\nChange-Id: Ic6844bf313a08b8481d3474185d08d878ff52b5a\n""}]",0,361145,b5d2769041fc6787d88e34331b09701c285131a2,14,4,3,10239,,,0,"Clean up ironic::drivers::pxe

Detect boot file name and boot templates based on ipxe_enabled (unfortunately,
that required an explicit default for ipxe_enabled instead of os_service_default).

Switch quite a few parameters to os_service_default, where our defaults don't differ
from upstream defaults. TFTP root path is left alone, as it will be refactored soon.

Deprecate three parameters that do not exist in ironic (at least now).

Change-Id: Ic6844bf313a08b8481d3474185d08d878ff52b5a
",git fetch https://review.opendev.org/openstack/puppet-ironic refs/changes/45/361145/1 && git format-patch -1 --stdout FETCH_HEAD,['manifests/drivers/pxe.pp'],1,66bcafd8ca928f0b2e7a779afed70c669518633c,ipxe-enabled,"# [*ipxe_enabled*] # (optional) Enable ipxe support # Defaults to false. # # [*pxe_append_params*] # (optional) Additional append parameters for baremetal PXE boot. # Should be valid pxe parameters # Defaults to $::os_service_default # # [*pxe_bootfile_name*] # (optional) Bootfile DHCP parameter. # If not set, its value is detected based on ipxe_enabled. # Defaults to undef. # # [*pxe_config_template*] # (optional) Template file for PXE configuration. # If set, should be an valid template file. Otherwise, its value is detected # based on ipxe_enabled. # Defaults to undef. # # [*tftp_server*] # (optional) IP address of Ironic compute node's tftp server. # Should be an valid IP address # Defaults to $::os_service_default. # # [*tftp_root*] # (optional) Ironic compute node's tftp root path. # Should be an valid path # Defaults to '/tftpboot'. # # [*images_path*] # (optional) Directory where images are stored on disk. # Should be an valid directory # Defaults to $::os_service_default. # # [*tftp_master_path*] # (optional) Directory where master tftp images are stored on disk. # Should be an valid directory # Defaults to '/tftpboot/master_images'. # # [*instance_master_path*] # (optional) Directory where master tftp images are stored on disk. # Should be an valid directory # Defaults to $::os_service_default. # # [*uefi_pxe_bootfile_name*] # (optional) Bootfile DHCP parameter for UEFI boot mode. # Defaults to $::os_service_default. # # [*uefi_pxe_config_template*] # (optional) Template file for PXE configuration for UEFI boot loader. # Defaults to $::os_service_default. # # [*ipxe_timeout*] # (optional) ipxe timeout in second. # Should be an valid integer # Defaults to $::os_service_default. # # DEPRECATED ## Defaults to undef $ipxe_enabled = false, $pxe_append_params = $::os_service_default, $pxe_bootfile_name = undef, $pxe_config_template = undef, $tftp_server = $::os_service_default, $tftp_root = '/tftpboot', $images_path = $::os_service_default, $tftp_master_path = '/tftpboot/master_images', $instance_master_path = $::os_service_default, $uefi_pxe_bootfile_name = $::os_service_default, $uefi_pxe_config_template = $::os_service_default, $ipxe_timeout = $::os_service_default, # Deprecated $pxe_deploy_timeout = undef, if $ipxe_enabled { $pxe_bootfile_name_real = pick($pxe_bootfile_name, 'undionly.kpxe') $pxe_config_template_real = pick($pxe_config_template, '$pybasedir/drivers/modules/ipxe_config.template') } else { $pxe_bootfile_name_real = pick($pxe_bootfile_name, 'pxelinux.0') $pxe_config_template_real = pick($pxe_config_template, '$pybasedir/drivers/modules/pxe_config.template') } 'pxe/ipxe_enabled': value => $ipxe_enabled; 'pxe/pxe_bootfile_name': value => $pxe_bootfile_name_real; 'pxe/pxe_config_template': value => $pxe_config_template_real; warning('deploy_kernel option does nothing and will be removed soon') warning('deploy_ramdisk option does nothing and will be removed soon') } if $pxe_deploy_timeout { warning('deploy_ramdisk option does nothing and will be removed soon')","# [*pxe_append_params*] # (optional) Additional append parameters for baremetal PXE boot. # Should be valid pxe parameters # Defaults to 'nofb nomodeset vga=normal'. # # [*pxe_config_template*] # (optional) Template file for PXE configuration. # Should be an valid template file # Defaults to '$pybasedir/drivers/modules/pxe_config.template'. ## Defaults to '0' for unlimited. # # [*tftp_server*] # (optional) IP address of Ironic compute node's tftp server. # Should be an valid IP address # Defaults to '$my_ip'. # # [*tftp_root*] # (optional) Ironic compute node's tftp root path. # Should be an valid path # Defaults to '/tftpboot'. # # [*images_path*] # (optional) Directory where images are stored on disk. # Should be an valid directory # Defaults to '/tftpboot'. # # [*tftp_master_path*] # (optional) Directory where master tftp images are stored on disk. # Should be an valid directory # Defaults to '/tftpboot/master_images'. # # [*instance_master_path*] # (optional) Directory where master tftp images are stored on disk. # Should be an valid directory # Defaults to '/var/lib/ironic/master_images'. # # [*uefi_pxe_bootfile_name*] # (optional) Bootfile DHCP parameter for UEFI boot mode. # Defaults to 'elilo.efi'. # # [*uefi_pxe_config_template*] # (optional) Template file for PXE configuration for UEFI boot loader. # Defaults to '$pybasedir/drivers/modules/elilo_efi_pxe_config.template'. # # [*ipxe_timeout*] # (optional) ipxe timeout in second. # Should be an valid integer # Defaults to '0' for unlimited. # # [*ipxe_enabled*] # (optional) Enable ipxe support # Defaults to $::os_service_default. # # [*pxe_bootfile_name*] # (optional) Bootfile DHCP parameter # Defaults to $::os_service_default. $pxe_append_params = 'nofb nomodeset vga=normal', $pxe_config_template = '$pybasedir/drivers/modules/pxe_config.template', $pxe_deploy_timeout = '0', $tftp_server = '$my_ip', $tftp_root = '/tftpboot', $images_path = '/var/lib/ironic/images/', $tftp_master_path = '/tftpboot/master_images', $instance_master_path = '/var/lib/ironic/master_images', $uefi_pxe_bootfile_name = 'elilo.efi', $uefi_pxe_config_template = '$pybasedir/drivers/modules/elilo_efi_pxe_config.template', $ipxe_timeout = '0', $ipxe_enabled = $::os_service_default, $pxe_bootfile_name = $::os_service_default, 'pxe/pxe_config_template': value => $pxe_config_template; 'pxe/pxe_deploy_timeout': value => $pxe_deploy_timeout; 'pxe/ipxe_enabled': value => $ipxe_enabled; 'pxe/pxe_bootfile_name': value => $pxe_bootfile_name; ironic_config { 'pxe/deploy_kernel': value => $deploy_kernel; } ironic_config { 'pxe/deploy_ramdisk': value => $deploy_ramdisk; }",92,80
openstack%2Fcinder~master~I0e2a8f2f43ccf06c1e676a52a3843c04056c050a,openstack/cinder,master,I0e2a8f2f43ccf06c1e676a52a3843c04056c050a,Add functional-py35 to tox,MERGED,2016-08-10 14:13:05.000000000,2016-08-29 14:20:48.000000000,2016-08-28 19:23:47.000000000,"[{'_account_id': 3}, {'_account_id': 4523}, {'_account_id': 9535}, {'_account_id': 9732}, {'_account_id': 10621}, {'_account_id': 10622}, {'_account_id': 11904}, {'_account_id': 12033}, {'_account_id': 13394}, {'_account_id': 14305}, {'_account_id': 14384}, {'_account_id': 15249}, {'_account_id': 15374}, {'_account_id': 15386}, {'_account_id': 16422}, {'_account_id': 16708}, {'_account_id': 16834}, {'_account_id': 16862}, {'_account_id': 16941}, {'_account_id': 17852}, {'_account_id': 18026}, {'_account_id': 18752}, {'_account_id': 19852}, {'_account_id': 21863}, {'_account_id': 21976}, {'_account_id': 22126}, {'_account_id': 22248}, {'_account_id': 22510}]","[{'number': 1, 'created': '2016-08-10 14:13:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/7ab4acd6c2ff1ead9ebde447481f65501595db9a', 'message': 'Add functional-py35 to tox\n\nThis allows running functional tests in a py35\nenvironment with ""tox -e functional-py35"".\n\nChange-Id: I0e2a8f2f43ccf06c1e676a52a3843c04056c050a\n'}, {'number': 2, 'created': '2016-08-11 14:19:54.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/cinder/commit/20d8ff5545f577fc794552fb0b8383e7ad935768', 'message': 'Add functional-py35 to tox\n\nThis allows running functional tests in a py35\nenvironment with ""tox -e functional-py35"".\n\nChange-Id: I0e2a8f2f43ccf06c1e676a52a3843c04056c050a\n'}]",1,353521,20d8ff5545f577fc794552fb0b8383e7ad935768,63,28,2,4523,,,0,"Add functional-py35 to tox

This allows running functional tests in a py35
environment with ""tox -e functional-py35"".

Change-Id: I0e2a8f2f43ccf06c1e676a52a3843c04056c050a
",git fetch https://review.opendev.org/openstack/cinder refs/changes/21/353521/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,7ab4acd6c2ff1ead9ebde447481f65501595db9a,353521,[testenv:functional-py35] basepython=python3.5 setenv = {[testenv:functional]setenv} ,,6,0
openstack%2Ftripleo-heat-templates~master~Ic5e099fe788046363536f913272b2814abe165fa,openstack/tripleo-heat-templates,master,Ic5e099fe788046363536f913272b2814abe165fa,Configure the pci_passthrough_whitelist via THT,MERGED,2016-06-14 12:20:27.000000000,2016-08-29 14:20:45.000000000,2016-08-29 14:20:45.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 4328}, {'_account_id': 6681}, {'_account_id': 6796}, {'_account_id': 10034}, {'_account_id': 10873}, {'_account_id': 15335}, {'_account_id': 18575}, {'_account_id': 18904}, {'_account_id': 20171}]","[{'number': 1, 'created': '2016-06-14 12:20:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/9cf5b4e37c67060375b9272dbc9f24e75c3ddf22', 'message': 'Configure the pci_passthrough_whitelist via THT\n\nIt allows the operator to configure pci_passthrough_whitelist\nin nova.conf for each of the compute nodes.\n\nimplements: blueprint tripleo-sriov\n\nChange-Id: Ic5e099fe788046363536f913272b2814abe165fa\nSigned-off-by: karthik s <ksundara@redhat.com>\n'}, {'number': 2, 'created': '2016-07-04 13:37:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/8f6f08e1346c979aecc23c87903334cb50a2c175', 'message': 'Configure the pci_passthrough_whitelist via THT\n\nIt allows the operator to configure pci_passthrough_whitelist\nin nova.conf for each of the compute nodes.\n\nimplements: blueprint tripleo-sriov\n\nChange-Id: Ic5e099fe788046363536f913272b2814abe165fa\nSigned-off-by: karthik s <ksundara@redhat.com>\n'}, {'number': 3, 'created': '2016-07-04 13:41:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/5cb85fac1db447f77569540bb6ee65d65c30faf6', 'message': 'Configure the pci_passthrough_whitelist via THT\n\nIt allows the operator to configure pci_passthrough_whitelist\nin nova.conf for each of the compute nodes.\n\nimplements: blueprint tripleo-sriov\n\nChange-Id: Ic5e099fe788046363536f913272b2814abe165fa\nSigned-off-by: karthik s <ksundara@redhat.com>\n'}, {'number': 4, 'created': '2016-07-27 09:11:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/8eb5344c4e411f3ff115996ada3089a1284f1620', 'message': 'Configure the pci_passthrough_whitelist via THT\n\nIt allows the operator to configure pci_passthrough_whitelist\nin nova.conf for each of the compute nodes.\n\nimplements: blueprint tripleo-sriov\n\nChange-Id: Ic5e099fe788046363536f913272b2814abe165fa\nSigned-off-by: karthik s <ksundara@redhat.com>\n'}, {'number': 5, 'created': '2016-07-28 06:55:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/d618a2f3d0347fea2f44c82ff83129d6abd4c055', 'message': 'Configure the pci_passthrough_whitelist via THT\n\nIt allows the operator to configure pci_passthrough_whitelist\nin nova.conf for each of the compute nodes.\n\nimplements: blueprint tripleo-sriov\n\nChange-Id: Ic5e099fe788046363536f913272b2814abe165fa\nSigned-off-by: karthik s <ksundara@redhat.com>\n'}, {'number': 6, 'created': '2016-07-28 14:34:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/09a8650d73bc2b8c29029052525cfb43029e6b51', 'message': 'Configure the pci_passthrough_whitelist via THT\n\nIt allows the operator to configure pci_passthrough_whitelist\nin nova.conf for each of the compute nodes.\n\nimplements: blueprint tripleo-sriov\n\nChange-Id: Ic5e099fe788046363536f913272b2814abe165fa\nSigned-off-by: karthik s <ksundara@redhat.com>\n'}, {'number': 7, 'created': '2016-08-03 13:33:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/d3b07678d398f99c2e371ae260a8dd00398c650e', 'message': 'Configure the pci_passthrough_whitelist via THT\n\nIt allows the operator to configure pci_passthrough_whitelist\nin nova.conf for each of the compute nodes.\n\nimplements: blueprint tripleo-sriov\n\nChange-Id: Ic5e099fe788046363536f913272b2814abe165fa\nSigned-off-by: karthik s <ksundara@redhat.com>\n'}, {'number': 8, 'created': '2016-08-17 06:03:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/3b394a7ac393699b5bd48e5d58df555d5dfb2a70', 'message': 'Configure the pci_passthrough_whitelist via THT\n\nIt allows the operator to configure pci_passthrough_whitelist\nin nova.conf for each of the compute nodes.\n\nimplements: blueprint tripleo-sriov\n\nChange-Id: Ic5e099fe788046363536f913272b2814abe165fa\nSigned-off-by: karthik s <ksundara@redhat.com>\n'}, {'number': 9, 'created': '2016-08-25 17:48:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/3b7b17a4a950157007b1a21d3f0221fb0d93f336', 'message': 'Configure the pci_passthrough_whitelist via THT\n\nIt allows the operator to configure pci_passthrough_whitelist\nin nova.conf for each of the compute nodes.\n\nimplements: blueprint tripleo-sriov\n\nChange-Id: Ic5e099fe788046363536f913272b2814abe165fa\nSigned-off-by: karthik s <ksundara@redhat.com>\n'}, {'number': 10, 'created': '2016-08-26 13:21:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/c710323337b3036499a6854dd5a8c512bf74f6a8', 'message': 'Configure the pci_passthrough_whitelist via THT\n\nIt allows the operator to configure pci_passthrough_whitelist\nin nova.conf for each of the compute nodes.\n\nimplements: blueprint tripleo-sriov\n\nChange-Id: Ic5e099fe788046363536f913272b2814abe165fa\nSigned-off-by: karthik s <ksundara@redhat.com>\n'}, {'number': 11, 'created': '2016-08-26 19:13:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/996f402c6af00a1a4e15ec057fcf7172c7c75254', 'message': 'Configure the pci_passthrough_whitelist via THT\n\nIt allows the operator to configure pci_passthrough_whitelist\nin nova.conf for each of the compute nodes.\n\nimplements: blueprint tripleo-sriov\n\nChange-Id: Ic5e099fe788046363536f913272b2814abe165fa\nSigned-off-by: karthik s <ksundara@redhat.com>\n'}, {'number': 12, 'created': '2016-08-26 19:16:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/b16cde8e0582aa204853af2fc4823af668cc0cb3', 'message': 'Configure the pci_passthrough_whitelist via THT\n\nIt allows the operator to configure pci_passthrough_whitelist\nin nova.conf for each of the compute nodes.\n\nimplements: blueprint tripleo-sriov\n\nChange-Id: Ic5e099fe788046363536f913272b2814abe165fa\nSigned-off-by: karthik s <ksundara@redhat.com>\n'}, {'number': 13, 'created': '2016-08-26 19:35:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/107fbfc2f98004f22400c79587165f07943f9721', 'message': 'Configure the pci_passthrough_whitelist via THT\n\nIt allows the operator to configure pci_passthrough_whitelist\nin nova.conf for each of the compute nodes.\n\nimplements: blueprint tripleo-sriov\n\nDepends-On: I5ed53cfffe80dbbbb9dcee7c2ea6037afbed2382\nChange-Id: Ic5e099fe788046363536f913272b2814abe165fa\nSigned-off-by: karthik s <ksundara@redhat.com>\n'}, {'number': 14, 'created': '2016-08-27 02:56:22.000000000', 'files': ['puppet/services/nova-compute.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/67d3a774e55a6c27aa19d1f00de9cec4a02e7866', 'message': 'Configure the pci_passthrough_whitelist via THT\n\nIt allows the operator to configure pci_passthrough_whitelist\nin nova.conf for each of the compute nodes.\n\nimplements: blueprint tripleo-sriov\n\nDepends-On: I5ed53cfffe80dbbbb9dcee7c2ea6037afbed2382\nChange-Id: Ic5e099fe788046363536f913272b2814abe165fa\nSigned-off-by: karthik s <ksundara@redhat.com>\n'}]",9,329415,67d3a774e55a6c27aa19d1f00de9cec4a02e7866,73,11,14,18904,,,0,"Configure the pci_passthrough_whitelist via THT

It allows the operator to configure pci_passthrough_whitelist
in nova.conf for each of the compute nodes.

implements: blueprint tripleo-sriov

Depends-On: I5ed53cfffe80dbbbb9dcee7c2ea6037afbed2382
Change-Id: Ic5e099fe788046363536f913272b2814abe165fa
Signed-off-by: karthik s <ksundara@redhat.com>
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/15/329415/12 && git format-patch -1 --stdout FETCH_HEAD,"['overcloud.yaml', 'puppet/compute.yaml']",2,9cf5b4e37c67060375b9272dbc9f24e75c3ddf22,bp/tripleo-sriov," NovaPCIPassthrough: description: > ""\""[{'vendor_id': '<id>','product_id': '<id>', 'address': '<domain>:<bus>:<slot>.<function>', 'devname': 'Ethernet Interface Name' 'physical_network':'name string of the physical network'}]\"""" <id> can be an asterisk (*) or a valid vendor/product ID as displayed by the Linux utility lspci. The address uses the same syntax as in lspci. The devname can be a valid PCI device name. The only device names that are supported are those displayed by the Linux utility ifconfig -a and correspond to either a PF or a VF on a vNIC. If the device defined by the address or devname corresponds to a SR-IOV PF, all VFs under the PF will match the entry. Multiple whitelist entries per host are supported type: string default: """" nova::compute::pci_passthrough: {get_input: nova_pci_passthrough} nova_pci_passthrough: {get_param: NovaPCIPassthrough}",,33,0
openstack%2Fpuppet-heat~master~I0afa325735db9510aefb17bcfcff7b8ae9c4591f,openstack/puppet-heat,master,I0afa325735db9510aefb17bcfcff7b8ae9c4591f,authtoken: add missing doc,MERGED,2016-08-26 18:21:54.000000000,2016-08-29 14:20:39.000000000,2016-08-29 14:20:39.000000000,"[{'_account_id': 3}, {'_account_id': 1607}, {'_account_id': 3153}, {'_account_id': 7745}, {'_account_id': 23327}]","[{'number': 1, 'created': '2016-08-26 18:21:54.000000000', 'files': ['manifests/init.pp'], 'web_link': 'https://opendev.org/openstack/puppet-heat/commit/1d95c04dba02d9f931247824e3981190ecd984d5', 'message': 'authtoken: add missing doc\n\nChange-Id: I0afa325735db9510aefb17bcfcff7b8ae9c4591f\n'}]",0,361408,1d95c04dba02d9f931247824e3981190ecd984d5,17,5,1,3153,,,0,"authtoken: add missing doc

Change-Id: I0afa325735db9510aefb17bcfcff7b8ae9c4591f
",git fetch https://review.opendev.org/openstack/puppet-heat refs/changes/08/361408/1 && git format-patch -1 --stdout FETCH_HEAD,['manifests/init.pp'],1,1d95c04dba02d9f931247824e3981190ecd984d5,fix/doc,# (Optional) Deprecated. Use heat::keystone::authtoken::project_name,# (Optional) Deprecated. Use heat::keystone::authtoken::,1,1
openstack%2Ftripleo-common~master~Ica936fb96cfca025b3cc29edb2cc81f2170ae4ed,openstack/tripleo-common,master,Ica936fb96cfca025b3cc29edb2cc81f2170ae4ed,Add Mistral action for boot configuration,MERGED,2016-08-11 15:47:16.000000000,2016-08-29 14:20:27.000000000,2016-08-29 14:20:27.000000000,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 4978}, {'_account_id': 7065}, {'_account_id': 8532}, {'_account_id': 9712}]","[{'number': 1, 'created': '2016-08-11 15:47:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/82f6a9a9590a904a9a9d1777c3cc2710b2d958ac', 'message': '[WIP] Add Mistral actions for boot & root device configuration\n\nTODO:\n - Unit tests\n - ""All manageable nodes"" workflow\n - Break down the patch for each action\n\nChange-Id: Ica936fb96cfca025b3cc29edb2cc81f2170ae4ed\n'}, {'number': 2, 'created': '2016-08-15 14:51:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/520a329ccd62460e9bea5de56e5c10e5a936b1d1', 'message': 'Add Mistral actions for boot & root device configuration\n\nThe boot configuration code, and root device configuration code and\nunit tests come from the python-tripleoclient project. By moving them\ninto common Mistral actions, they can be reused by other clients like\nthe UI.\n\nTODO:\n - ""All manageable nodes"" workflow\n - Break down the patch for each action\n\nChange-Id: Ica936fb96cfca025b3cc29edb2cc81f2170ae4ed\n'}, {'number': 3, 'created': '2016-08-16 13:54:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/9199070db74cf0059b5bc55edd7b36c8600dc810', 'message': ""Add Mistral action for boot configuration\n\nThe boot configuration code mainly comes from the python-tripleoclient\nproject. By moving it into a common Mistral action, it can be reused by\nother clients like the UI. This will also be used for the new\n'overcloud node configure' command in the client.\n\nChange-Id: Ica936fb96cfca025b3cc29edb2cc81f2170ae4ed\nRelated-Bug: #1595205\n""}, {'number': 4, 'created': '2016-08-16 16:24:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/3482a22678041dba61f5ec633abe8c6ef7de1833', 'message': ""Add Mistral action for boot configuration\n\nThe boot configuration code mainly comes from the python-tripleoclient\nproject. By moving it into a common Mistral action, it can be reused by\nother clients like the UI. This will also be used for the new\n'overcloud node configure' command in the client.\n\nChange-Id: Ica936fb96cfca025b3cc29edb2cc81f2170ae4ed\nRelated-Bug: #1595205\n""}, {'number': 5, 'created': '2016-08-19 11:16:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/c99f7d5b4942b29c53be1f4c9a7b9cf4d8594b13', 'message': ""Add Mistral action for boot configuration\n\nThe boot configuration code mainly comes from the python-tripleoclient\nproject. By moving it into a common Mistral action, it can be reused by\nother clients like the UI. This will also be used for the new\n'overcloud node configure' command in the client.\n\nChange-Id: Ica936fb96cfca025b3cc29edb2cc81f2170ae4ed\nRelated-Bug: #1595205\n""}, {'number': 6, 'created': '2016-08-24 07:49:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/8b10a99fd0c97fa173547a2bd55e2a1eeb750db0', 'message': ""Add Mistral action for boot configuration\n\nThe boot configuration code mainly comes from the python-tripleoclient\nproject. By moving it into a common Mistral action, it can be reused by\nother clients like the UI. This will also be used for the new\n'overcloud node configure' command in the client.\n\nChange-Id: Ica936fb96cfca025b3cc29edb2cc81f2170ae4ed\nRelated-Bug: #1595205\n""}, {'number': 7, 'created': '2016-08-25 19:12:58.000000000', 'files': ['tripleo_common/actions/baremetal.py', 'setup.cfg', 'tripleo_common/tests/actions/test_baremetal.py'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/a9c8ffb655168ab8d0eed1f2d158c02033ee2b54', 'message': ""Add Mistral action for boot configuration\n\nThe boot configuration code mainly comes from the python-tripleoclient\nproject. By moving it into a common Mistral action, it can be reused by\nother clients like the UI. This will also be used for the new\n'overcloud node configure' command in the client.\n\nChange-Id: Ica936fb96cfca025b3cc29edb2cc81f2170ae4ed\nRelated-Bug: #1595205\n""}]",5,354174,a9c8ffb655168ab8d0eed1f2d158c02033ee2b54,45,6,7,4978,,,0,"Add Mistral action for boot configuration

The boot configuration code mainly comes from the python-tripleoclient
project. By moving it into a common Mistral action, it can be reused by
other clients like the UI. This will also be used for the new
'overcloud node configure' command in the client.

Change-Id: Ica936fb96cfca025b3cc29edb2cc81f2170ae4ed
Related-Bug: #1595205
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/74/354174/1 && git format-patch -1 --stdout FETCH_HEAD,"['tripleo_common/actions/baremetal.py', 'requirements.txt', 'workbooks/baremetal.yaml', 'tripleo_common/actions/base.py', 'tripleo_common/exception.py', 'setup.cfg']",6,82f6a9a9590a904a9a9d1777c3cc2710b2d958ac,bug/1595205, tripleo.configure_boot = tripleo_common.actions.baremetal:ConfigureBootAction tripleo.configure_root_device = tripleo_common.actions.baremetal:ConfigureRootDeviceAction,,267,0
openstack%2Fpuppet-tripleo~master~I36e1c478e7c92be61da6a0d710e9025d4d354072,openstack/puppet-tripleo,master,I36e1c478e7c92be61da6a0d710e9025d4d354072,Configure keystone endpoints in service profile,MERGED,2016-08-24 08:20:11.000000000,2016-08-29 14:20:02.000000000,2016-08-29 14:20:02.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 6796}, {'_account_id': 10873}]","[{'number': 1, 'created': '2016-08-24 08:20:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/4494e2b2c231e7fc0f80c8f45e4aafb06d354330', 'message': ""Configure keystone endpoints in service profile\n\nThis commit enables the configuration of the service users and\nkeystone endpoints in the keystone profile. Since with the\ncomposable services work, we can't assure that the APIs will be in\nthe same node as keystone, this needs to be done from the keystone\nprofile.\n\nChange-Id: I36e1c478e7c92be61da6a0d710e9025d4d354072\n""}, {'number': 2, 'created': '2016-08-24 08:22:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/a11e52e9ddad630cb1f3b1560ee707b5c4671e5b', 'message': ""Configure keystone endpoints in service profile\n\nThis commit enables the configuration of the service users and\nkeystone endpoints in the keystone profile. Since with the\ncomposable services work, we can't assure that the APIs will be in\nthe same node as keystone, this needs to be done from the keystone\nprofile.\n\nDepends-On: I379932df096c393161c795cae8daf8970168bd90\nChange-Id: I36e1c478e7c92be61da6a0d710e9025d4d354072\n""}, {'number': 3, 'created': '2016-08-26 09:35:41.000000000', 'files': ['manifests/profile/base/keystone.pp'], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/5c38dbd71941a028f0f13e7ddf40392f539889f3', 'message': ""Configure keystone endpoints in service profile\n\nThis commit enables the configuration of the service users and\nkeystone endpoints in the keystone profile. Since with the\ncomposable services work, we can't assure that the APIs will be in\nthe same node as keystone, this needs to be done from the keystone\nprofile.\n\nDepends-On: I62273f403838893602816204d9bc50d516c0057f\nChange-Id: I36e1c478e7c92be61da6a0d710e9025d4d354072\n""}]",0,359680,5c38dbd71941a028f0f13e7ddf40392f539889f3,21,4,3,10873,,,0,"Configure keystone endpoints in service profile

This commit enables the configuration of the service users and
keystone endpoints in the keystone profile. Since with the
composable services work, we can't assure that the APIs will be in
the same node as keystone, this needs to be done from the keystone
profile.

Depends-On: I62273f403838893602816204d9bc50d516c0057f
Change-Id: I36e1c478e7c92be61da6a0d710e9025d4d354072
",git fetch https://review.opendev.org/openstack/puppet-tripleo refs/changes/80/359680/1 && git format-patch -1 --stdout FETCH_HEAD,['manifests/profile/base/keystone.pp'],1,4494e2b2c231e7fc0f80c8f45e4aafb06d354330,keystone_endpoints," if $step >= 5 and $manage_endpoint{ if hiera('aodh_api_enabled', false) { include ::aodh::keystone::auth } if hiera('ceilometer_api_enabled', false) { include ::ceilometer::keystone::auth } if hiera('cinder_api_enabled', false) { include ::cinder::keystone::auth } if hiera('glance_api_enabled', false) { include ::glance::keystone::auth } if hiera('gnocchi_api_enabled', false) { include ::gnocchi::keystone::auth } if hiera('heat_api_enabled', false) { include ::heat::keystone::auth } if hiera('heat_api_cfn_enabled', false) { include ::heat::keystone::auth_cfn } if hiera('ironic_api_enabled', false) { include ::ironic::keystone::auth } if hiera('manila_api_enabled', false) { include ::manila::keystone::auth } if hiera('mistral_api_enabled', false) { include ::mistral::keystone::auth } if hiera('neutron_api_enabled', false) { include ::neutron::keystone::auth } if hiera('nova_api_enabled', false) { include ::nova::keystone::auth } if hiera('sahara_api_enabled', false) { include ::sahara::keystone::auth } if hiera('swift_proxy_enabled', false) { include ::swift::keystone::auth } if hiera('trove_api_enabled', false) { include ::trove::keystone::auth } }",,48,0
openstack%2Fapi-site~master~Ic63313b8b30011ddcc9a307737116b74fd55dc95,openstack/api-site,master,Ic63313b8b30011ddcc9a307737116b74fd55dc95,Update reference link for compute api,MERGED,2016-08-29 08:53:09.000000000,2016-08-29 14:19:03.000000000,2016-08-29 14:19:03.000000000,"[{'_account_id': 3}, {'_account_id': 964}, {'_account_id': 10497}, {'_account_id': 15471}]","[{'number': 1, 'created': '2016-08-29 08:53:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/api-site/commit/7c615df716b667085633db7d6a8c3b9050869e07', 'message': 'Update reference link for compute api\n\nThis patch updates reference link for compute api in\nhttp://developer.openstack.org/api-guide/quick-start/api-quick-start.html#launch-an-instance/\n\nChange-Id: Ic63313b8b30011ddcc9a307737116b74fd55dc95\n'}, {'number': 2, 'created': '2016-08-29 09:09:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/api-site/commit/cc29810fefc1d6cac1db2ba8b8cd4ece31122264', 'message': 'Update reference link for compute api\n\nThis patch updates reference link for compute api in\nhttp://developer.openstack.org/api-guide/quick-start/api-quick-start.html#launch-an-instance/\n\nChange-Id: Ic63313b8b30011ddcc9a307737116b74fd55dc95\n'}, {'number': 3, 'created': '2016-08-29 10:54:33.000000000', 'files': ['api-quick-start/source/api-quick-start.rst'], 'web_link': 'https://opendev.org/openstack/api-site/commit/8699671d1262f63f43d5502680c81de7a7dbf084', 'message': 'Update reference link for compute api\n\nThis patch updates reference link for compute api in\nhttp://developer.openstack.org/api-guide/quick-start/api-quick-start.html#launch-an-instance/\n\nChange-Id: Ic63313b8b30011ddcc9a307737116b74fd55dc95\n'}]",2,361949,8699671d1262f63f43d5502680c81de7a7dbf084,14,4,3,15471,,,0,"Update reference link for compute api

This patch updates reference link for compute api in
http://developer.openstack.org/api-guide/quick-start/api-quick-start.html#launch-an-instance/

Change-Id: Ic63313b8b30011ddcc9a307737116b74fd55dc95
",git fetch https://review.opendev.org/openstack/api-site refs/changes/49/361949/3 && git format-patch -1 --stdout FETCH_HEAD,['api-quick-start/source/api-quick-start.rst'],1,7c615df716b667085633db7d6a8c3b9050869e07,update_refer_link,`Compute API (CURRENT) http://developer.openstack.org/api-ref/compute/`__.,`Compute API (CURRENT) <http://developer.openstack.org/api-ref-compute-v2.1.html>`__.,1,1
openstack%2Fceilometer~master~Ife7fbad117f65541e49ede70085f08e1305c4337,openstack/ceilometer,master,Ife7fbad117f65541e49ede70085f08e1305c4337,Gnocchi dispatcher fails on skipped metric,MERGED,2016-08-18 15:36:37.000000000,2016-08-29 14:12:57.000000000,2016-08-29 14:12:57.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 6537}, {'_account_id': 10068}, {'_account_id': 15843}, {'_account_id': 22775}, {'_account_id': 22779}]","[{'number': 1, 'created': '2016-08-18 15:36:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/b6bdc7d582204f88e8dbe7f25e96fb0fac253a95', 'message': 'Gnocchi dispatcher fails on skipped metric\n\nWhen a metric is not handled by Gnocchi, the dispatcher fails to anticipate\nthat the metric is to be skipped\nCloses-Bug: #1614567\n\nChange-Id: Ife7fbad117f65541e49ede70085f08e1305c4337\n'}, {'number': 2, 'created': '2016-08-18 18:00:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/c2b97b459871ccba71f3825faa4c3954456875e7', 'message': 'Gnocchi dispatcher fails on skipped metric\n\nWhen a metric is not handled by Gnocchi, the dispatcher fails to anticipate\nthat the metric is to be skipped\nCloses-Bug: #1614567\n\nChange-Id: Ife7fbad117f65541e49ede70085f08e1305c4337\n'}, {'number': 3, 'created': '2016-08-19 22:11:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/2cd4787ce05852f011ef4cb2cc17215c1b30b7e6', 'message': 'Gnocchi dispatcher fails on skipped metric\n\nWhen a metric is not handled by Gnocchi, the dispatcher fails to anticipate\nthat the metric is to be skipped\n\nCloses-Bug: #1614567\nChange-Id: Ife7fbad117f65541e49ede70085f08e1305c4337\n'}, {'number': 4, 'created': '2016-08-19 22:21:08.000000000', 'files': ['ceilometer/tests/unit/dispatcher/test_gnocchi.py', 'ceilometer/dispatcher/gnocchi.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/d298fad607d05fb6c1b26140eee02e17f6458751', 'message': 'Gnocchi dispatcher fails on skipped metric\n\nWhen a metric is not handled by Gnocchi, the dispatcher fails to anticipate\nthat the metric is to be skipped\n\nCloses-Bug: #1614567\nChange-Id: Ife7fbad117f65541e49ede70085f08e1305c4337\n'}]",2,357313,d298fad607d05fb6c1b26140eee02e17f6458751,23,7,4,20293,,,0,"Gnocchi dispatcher fails on skipped metric

When a metric is not handled by Gnocchi, the dispatcher fails to anticipate
that the metric is to be skipped

Closes-Bug: #1614567
Change-Id: Ife7fbad117f65541e49ede70085f08e1305c4337
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/13/357313/4 && git format-patch -1 --stdout FETCH_HEAD,['ceilometer/dispatcher/gnocchi.py'],1,b6bdc7d582204f88e8dbe7f25e96fb0fac253a95,bug/1614567," if ""resource"" not in info: continue",,2,0
openstack%2Fceilometer~master~Ie67f86ff5bda0fc972dc3e259896259cad7fe06f,openstack/ceilometer,master,Ie67f86ff5bda0fc972dc3e259896259cad7fe06f,[install] Create endpoint in one command,MERGED,2016-08-26 15:34:02.000000000,2016-08-29 14:12:40.000000000,2016-08-29 14:12:40.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 6537}, {'_account_id': 22779}]","[{'number': 1, 'created': '2016-08-26 15:34:02.000000000', 'files': ['install-guide/source/install-base-prereq-common.rst'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/96adfd52c7475140eae05c2819217de8a3c064b5', 'message': '[install] Create endpoint in one command\n\nbackport: mitaka\n\nChange-Id: Ie67f86ff5bda0fc972dc3e259896259cad7fe06f\nCloses-Bug: #1616983\n'}]",0,361313,96adfd52c7475140eae05c2819217de8a3c064b5,9,4,1,19779,,,0,"[install] Create endpoint in one command

backport: mitaka

Change-Id: Ie67f86ff5bda0fc972dc3e259896259cad7fe06f
Closes-Bug: #1616983
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/13/361313/1 && git format-patch -1 --stdout FETCH_HEAD,['install-guide/source/install-base-prereq-common.rst'],1,96adfd52c7475140eae05c2819217de8a3c064b5,bug/1616983, --publicurl http://controller:8777 \ --internalurl http://controller:8777 \ --adminurl http://controller:8777 metering | adminurl | http://controller:8777 | | internalurl | http://controller:8777 | | publicurl | http://controller:8777 |, metering public http://controller:8777 | enabled | True | | interface | public | | region_id | RegionOne | | url | http://controller:8777 | +--------------+----------------------------------+ $ openstack endpoint create --region RegionOne \ metering internal http://controller:8777 +--------------+----------------------------------+ | Field | Value | +--------------+----------------------------------+ | enabled | True | | id | c7009b1c2ee54b71b771fa3d0ae4f948 | | interface | internal | | region | RegionOne | | region_id | RegionOne | | service_id | 5fb7fd1bb2954fddb378d4031c28c0e4 | | service_name | ceilometer | | service_type | metering | | url | http://controller:8777 | +--------------+----------------------------------+ $ openstack endpoint create --region RegionOne \ metering admin http://controller:8777 +--------------+----------------------------------+ | Field | Value | +--------------+----------------------------------+ | enabled | True | | id | b2c00566d0604551b5fe1540c699db3d | | interface | admin | | region | RegionOne | | region_id | RegionOne | | service_id | 5fb7fd1bb2954fddb378d4031c28c0e4 | | service_name | ceilometer | | service_type | metering | | url | http://controller:8777 |,6,37
openstack%2Fmurano-dashboard~master~I600f32a02814eacf2a920763ee9f70ce37b57ab8,openstack/murano-dashboard,master,I600f32a02814eacf2a920763ee9f70ce37b57ab8,Separate internal MURANO_REPO_URL and DISPLAY_MURANO_REPO_URL,MERGED,2016-08-15 06:40:01.000000000,2016-08-29 14:12:24.000000000,2016-08-29 14:12:24.000000000,"[{'_account_id': 3}, {'_account_id': 7821}, {'_account_id': 13149}, {'_account_id': 14107}, {'_account_id': 15168}]","[{'number': 1, 'created': '2016-08-15 06:40:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/8d0306f8503789ce18cf456533a5f85cc4646ccc', 'message': ""Fix the default MURANO_REPO_URL\n\nDefault MURANO_REPO_URL now is not found, this patch changes it\nfrom 'http://apps.openstack.org/api/v1/murano_repo/liberty/' to\n'http://apps.openstack.org/#tab=murano-apps'.\n\nChange-Id: I600f32a02814eacf2a920763ee9f70ce37b57ab8\n""}, {'number': 2, 'created': '2016-08-15 08:03:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/2932417b202c1b51d65c3042ba1e8b135516b1b3', 'message': ""Fix the default MURANO_REPO_URL\n\nDefault MURANO_REPO_URL now is not found, this patch changes it\nfrom 'http://apps.openstack.org/api/v1/murano_repo/liberty/' to\n'http://apps.openstack.org/#tab=murano-apps'.\n\nChange-Id: I600f32a02814eacf2a920763ee9f70ce37b57ab8\nCloses-Bug: #1542776\n""}, {'number': 3, 'created': '2016-08-16 08:51:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/e95c4aece38421e8207dc6fe716f7856d8997bb2', 'message': 'Separate internal MURANO_REPO_URL and display MURANO_REPO_URL\n\nThe repo url in dashboard is not found, since it used the same url with\ninternal repo_url. This patch separates internal repo_url and display\nrepo_url.\n\nChange-Id: I600f32a02814eacf2a920763ee9f70ce37b57ab8\nCloses-Bug: #1542776\n'}, {'number': 4, 'created': '2016-08-17 00:43:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/2e92463f0ee35a292652a5c9e1d98177284d8a83', 'message': 'Separate internal MURANO_REPO_URL and display MURANO_REPO_URL\n\nThe repo url in dashboard is not found, since it used the same url with\ninternal repo_url. This patch separates internal repo_url and display\nrepo_url.\n\nChange-Id: I600f32a02814eacf2a920763ee9f70ce37b57ab8\nCloses-Bug: #1542776\n'}, {'number': 5, 'created': '2016-08-29 00:45:45.000000000', 'files': ['muranodashboard/templates/catalog/index.html', 'muranodashboard/local/local_settings.d/_50_murano.py', 'muranodashboard/environments/tables.py', 'muranodashboard/packages/consts.py', 'muranodashboard/catalog/views.py', 'muranodashboard/templates/services/_data_table.html', 'muranodashboard/tests/releasenotes/notes/display_repo_url-47c3cb0b45c2d68d.yaml'], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/0eceafb448ee79bb6c19e920118d4316e339ba0e', 'message': 'Separate internal MURANO_REPO_URL and DISPLAY_MURANO_REPO_URL\n\nThe repo url in dashboard is not found, since it used the same url with\ninternal repo_url. This patch separates internal repo_url and display\nrepo_url.\n\nChange-Id: I600f32a02814eacf2a920763ee9f70ce37b57ab8\nCloses-Bug: #1542776\n'}]",0,355325,0eceafb448ee79bb6c19e920118d4316e339ba0e,31,5,5,9323,,,0,"Separate internal MURANO_REPO_URL and DISPLAY_MURANO_REPO_URL

The repo url in dashboard is not found, since it used the same url with
internal repo_url. This patch separates internal repo_url and display
repo_url.

Change-Id: I600f32a02814eacf2a920763ee9f70ce37b57ab8
Closes-Bug: #1542776
",git fetch https://review.opendev.org/openstack/murano-dashboard refs/changes/25/355325/2 && git format-patch -1 --stdout FETCH_HEAD,"['muranodashboard/local/local_settings.d/_50_murano.py', 'muranodashboard/packages/consts.py']",2,8d0306f8503789ce18cf456533a5f85cc4646ccc,fix_murano_repo_url," ""http://apps.openstack.org/#tab=murano-apps"")"," ""http://apps.openstack.org/api/v1/murano_repo/liberty/"")",2,2
openstack%2Fopenstack-ansible-security~liberty~I1ea1163034969da7325fc519e3f39187d0a04755,openstack/openstack-ansible-security,liberty,I1ea1163034969da7325fc519e3f39187d0a04755,Fix numbering on V-38583,MERGED,2016-08-26 14:24:05.000000000,2016-08-29 14:11:08.000000000,2016-08-29 14:11:08.000000000,"[{'_account_id': 3}, {'_account_id': 6816}, {'_account_id': 7353}]","[{'number': 1, 'created': '2016-08-26 14:24:05.000000000', 'files': ['tasks/boot.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-security/commit/23fe90bc7129373224c522a261c983abcf7b02cd', 'message': 'Fix numbering on V-38583\n\nThe boot loader file permissions fix is V-38583, not V-38582.\n\nChange-Id: I1ea1163034969da7325fc519e3f39187d0a04755\n(cherry picked from commit a189e057dfe548e7906125d94f2da745e9683548)\n'}]",0,361244,23fe90bc7129373224c522a261c983abcf7b02cd,7,3,1,538,,,0,"Fix numbering on V-38583

The boot loader file permissions fix is V-38583, not V-38582.

Change-Id: I1ea1163034969da7325fc519e3f39187d0a04755
(cherry picked from commit a189e057dfe548e7906125d94f2da745e9683548)
",git fetch https://review.opendev.org/openstack/openstack-ansible-security refs/changes/44/361244/1 && git format-patch -1 --stdout FETCH_HEAD,['tasks/boot.yml'],1,23fe90bc7129373224c522a261c983abcf7b02cd,fix-38583-numbering,- name: V-38583 - Bootloader configuration files must have mode 0644 or less - V-38583,- name: V-38582 - Bootloader configuration files must have mode 0644 or less - V-38582,2,2
openstack%2Fdeb-auto-backports~debian%2Fnewton~I0a5f3f644ef76dd26379f4ac7b441005ebbef789,openstack/deb-auto-backports,debian/newton,I0a5f3f644ef76dd26379f4ac7b441005ebbef789,Dumb commit to rebuild,ABANDONED,2016-08-29 13:33:47.000000000,2016-08-29 14:07:58.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2016-08-29 13:33:47.000000000', 'files': ['packages-list'], 'web_link': 'https://opendev.org/openstack/deb-auto-backports/commit/ba1e71099f2b2653a6cd2ec43ea525d3153914fa', 'message': 'Dumb commit to rebuild\n\nChange-Id: I0a5f3f644ef76dd26379f4ac7b441005ebbef789\n'}]",0,362116,ba1e71099f2b2653a6cd2ec43ea525d3153914fa,3,1,1,6476,,,0,"Dumb commit to rebuild

Change-Id: I0a5f3f644ef76dd26379f4ac7b441005ebbef789
",git fetch https://review.opendev.org/openstack/deb-auto-backports refs/changes/16/362116/1 && git format-patch -1 --stdout FETCH_HEAD,['packages-list'],1,ba1e71099f2b2653a6cd2ec43ea525d3153914fa,,# Dumb commit to rebuild,,1,0
openstack%2Fdeb-auto-backports~debian%2Fnewton~Ic0609f3f03e93ac196d57698cecfa4f6263c2aa6,openstack/deb-auto-backports,debian/newton,Ic0609f3f03e93ac196d57698cecfa4f6263c2aa6,Build python-git,MERGED,2016-08-25 14:36:03.000000000,2016-08-29 14:07:27.000000000,2016-08-29 14:07:27.000000000,"[{'_account_id': 3}, {'_account_id': 12841}]","[{'number': 1, 'created': '2016-08-25 14:36:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/deb-auto-backports/commit/8da3f847f846a308bb47534c31eceb2707a03538', 'message': 'Build python-git python-gitdb\n\nChange-Id: Ic0609f3f03e93ac196d57698cecfa4f6263c2aa6\n'}, {'number': 2, 'created': '2016-08-29 09:53:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/deb-auto-backports/commit/7cb13642f9c55c193457c7fa2f4be051258fcbfc', 'message': 'Build python-git python-gitdb\n\nChange-Id: Ic0609f3f03e93ac196d57698cecfa4f6263c2aa6\n'}, {'number': 3, 'created': '2016-08-29 12:16:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/deb-auto-backports/commit/f7daa0fa58e930588462f3d5bf424dadc00aa7a7', 'message': 'Build python-git\n\nChange-Id: Ic0609f3f03e93ac196d57698cecfa4f6263c2aa6\n'}, {'number': 4, 'created': '2016-08-29 12:28:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/deb-auto-backports/commit/4a2761a537b81866d69f637ce6b2d109bb9c7f54', 'message': 'Build python-git\n\nChange-Id: Ic0609f3f03e93ac196d57698cecfa4f6263c2aa6\n'}, {'number': 5, 'created': '2016-08-29 12:35:11.000000000', 'files': ['packages-list'], 'web_link': 'https://opendev.org/openstack/deb-auto-backports/commit/b8493ed3f3c29efcc35caa3b832c286e90ca0963', 'message': 'Build python-git\n\nChange-Id: Ic0609f3f03e93ac196d57698cecfa4f6263c2aa6\n'}]",0,360597,b8493ed3f3c29efcc35caa3b832c286e90ca0963,22,2,5,6476,,,0,"Build python-git

Change-Id: Ic0609f3f03e93ac196d57698cecfa4f6263c2aa6
",git fetch https://review.opendev.org/openstack/deb-auto-backports refs/changes/97/360597/5 && git format-patch -1 --stdout FETCH_HEAD,['packages-list'],1,8da3f847f846a308bb47534c31eceb2707a03538,python-git,python-git python-gitdb,#python-git #python-gitdb,2,2
openstack%2Fironic~master~I48493c53971cdab3b9122897e51322e19ce2f600,openstack/ironic,master,I48493c53971cdab3b9122897e51322e19ce2f600,Mask instance secrets in API responses,MERGED,2016-06-08 00:26:46.000000000,2016-08-29 14:05:41.000000000,2016-08-29 14:05:41.000000000,"[{'_account_id': 3}, {'_account_id': 2889}, {'_account_id': 6618}, {'_account_id': 6773}, {'_account_id': 10118}, {'_account_id': 10239}, {'_account_id': 10342}, {'_account_id': 11297}, {'_account_id': 12356}, {'_account_id': 14525}, {'_account_id': 14629}, {'_account_id': 14760}, {'_account_id': 17998}, {'_account_id': 19003}, {'_account_id': 19339}, {'_account_id': 20311}]","[{'number': 1, 'created': '2016-06-08 00:26:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/1ec2feb00c03d1d18b307e5c992230bb9b5411f9', 'message': '[WIP] Mask configdrive contents in API responses\n\nThis change adds a new policy setting, ""show_configdrive"", that defaults\nto masking instance_info[\'configdrive\'] when it is present in an API\nresponse. This policy check works the same way as the existing\n""show_password"" check.\n\nNOTE: needs unit tests\n\nChange-Id: I48493c53971cdab3b9122897e51322e19ce2f600\n'}, {'number': 2, 'created': '2016-06-08 00:49:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/026f428b977a7fea7fee4d1457857410715b568f', 'message': '[WIP] Mask configdrive contents in API responses\n\nThis change adds a new policy setting, ""show_configdrive"", that defaults\nto masking instance_info[\'configdrive\'] when it is present in an API\nresponse. This policy check works the same way as the existing\n""show_password"" check.\n\nNote that this change moves the policy.check(""show_password"") call from\nthe Pecan hook into the API\'s Nodes() class, where the\npolicy.check(""show_configdrive"") is also added. This makes the code a\nlittle cleaner and more maintainable, especially if we want to add any\nmore checks like this in the future.\n\nalso removes the ironic-specific ""show_password"" property\nfrom the ironic.common.context.RequestContext class.  The\nNOTE: needs unit tests\n\nChange-Id: I48493c53971cdab3b9122897e51322e19ce2f600\n'}, {'number': 3, 'created': '2016-06-08 00:50:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/5d2211c9b9932cf5f1114f8d0e929546cab6819a', 'message': '[WIP] Mask configdrive contents in API responses\n\nThis change adds a new policy setting, ""show_configdrive"", that defaults\nto masking instance_info[\'configdrive\'] when it is present in an API\nresponse. This policy check works the same way as the existing\n""show_password"" check.\n\nNote that this change moves the policy.check(""show_password"") call from\nthe Pecan hook into the API\'s Nodes() class, where the\npolicy.check(""show_configdrive"") is also added. This makes the code a\nlittle cleaner and more maintainable, especially if we want to add any\nmore checks like this in the future.\n\nalso removes the ironic-specific ""show_password"" property\nfrom the ironic.common.context.RequestContext class.  The\nNOTE: needs unit tests\n\nChange-Id: I48493c53971cdab3b9122897e51322e19ce2f600\n'}, {'number': 4, 'created': '2016-07-20 22:18:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/5d52cde1d4b621b2438ad64d612acc06700c9693', 'message': 'Mask configdrive contents in API responses\n\nThis change adds a new policy setting, ""show_configdrive"", that defaults\nto masking instance_info[\'configdrive\'] when it is present in an API\nresponse. This policy check works the same way as the existing\n""show_password"" check, and also defaults to mask the response.\n\nNote that this change moves the policy.check(""show_password"") call from\nthe Pecan hook into the API\'s Nodes() class, where the\npolicy.check(""show_configdrive"") is also added. This makes the code a\nlittle cleaner and more maintainable, especially if we want to add any\nmore checks like this in the future.\n\nAs a result of this cleanup, the ironic-specific\nRequestContext.show_password property is removed.\n\nPartial-bug: #1526752\nChange-Id: I48493c53971cdab3b9122897e51322e19ce2f600\n'}, {'number': 5, 'created': '2016-07-20 22:39:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/861288db5ad46a7b54fe122c7961308fc757908a', 'message': 'Mask configdrive contents in API responses\n\nThis change adds a new policy setting, ""show_configdrive"", that defaults\nto masking instance_info[\'configdrive\'] when it is present in an API\nresponse. This policy check works the same way as the existing\n""show_password"" check, and also defaults to mask the response.\n\nNote that this change moves the policy.check(""show_password"") call from\nthe Pecan hook into the API\'s Nodes() class, where the\npolicy.check(""show_configdrive"") is also added. This makes the code a\nlittle cleaner and more maintainable, especially if we want to add any\nmore checks like this in the future.\n\nAs a result of this cleanup, the ironic-specific\nRequestContext.show_password property is removed.\n\nPartial-bug: #1526752\nChange-Id: I48493c53971cdab3b9122897e51322e19ce2f600\n'}, {'number': 6, 'created': '2016-07-21 19:04:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/e69b0479a335a87a70f860c38088bd3041c9c444', 'message': 'Mask configdrive contents in API responses\n\nThis change adds a new policy setting, ""show_configdrive"", that defaults\nto masking instance_info[\'configdrive\'] when it is present in an API\nresponse. This policy check works the same way as the existing\n""show_password"" check, and also defaults to mask the response.\n\nNote that this change moves the policy.check(""show_password"") call from\nthe Pecan hook into the API\'s Nodes() class, where the\npolicy.check(""show_configdrive"") is also added. This makes the code a\nlittle cleaner and more maintainable, especially if we want to add any\nmore checks like this in the future.\n\nAs a result of this cleanup, the ironic-specific\nRequestContext.show_password property is removed.\n\nPartial-bug: #1526752\nChange-Id: I48493c53971cdab3b9122897e51322e19ce2f600\n'}, {'number': 7, 'created': '2016-07-21 21:23:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/c0aebd83ac1e51387b9fa2be85b851e804ab15e6', 'message': 'Mask configdrive contents in API responses\n\nThis change adds a new policy setting, ""show_configdrive"", that defaults\nto masking instance_info[\'configdrive\'] when it is present in an API\nresponse. This policy check works the same way as the existing\n""show_password"" check, and also defaults to mask the response.\n\nNote that this change moves the policy.check(""show_password"") call from\nthe Pecan hook into the API\'s Nodes() class, where the\npolicy.check(""show_configdrive"") is also added. This makes the code a\nlittle cleaner and more maintainable, especially if we want to add any\nmore checks like this in the future.\n\nAs a result of this cleanup, the ironic-specific\nRequestContext.show_password property is removed.\n\nPartial-bug: #1526752\nChange-Id: I48493c53971cdab3b9122897e51322e19ce2f600\n'}, {'number': 8, 'created': '2016-07-22 18:09:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/6c108d2e45cb801a8a0c5d82acbbdcb38811c2d8', 'message': 'Mask configdrive contents in API responses\n\nThis change adds a new policy setting, ""show_configdrive"", that defaults\nto masking instance_info[\'configdrive\'] when it is present in an API\nresponse. This policy check works the same way as the existing\n""show_password"" check, and also defaults to mask the response.\n\nNote that this change moves the policy.check(""show_password"") call from\nthe Pecan hook into the API\'s Nodes() class, where the\npolicy.check(""show_configdrive"") is also added. This makes the code a\nlittle cleaner and more maintainable, especially if we want to add any\nmore checks like this in the future.\n\nAs a result of this cleanup, the ironic-specific\nRequestContext.show_password property is removed.\n\nPartial-bug: #1526752\nChange-Id: I48493c53971cdab3b9122897e51322e19ce2f600\n'}, {'number': 9, 'created': '2016-07-29 16:12:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/ae4b194e2078f60952c87018a8b120b13aabdf2d', 'message': 'Mask configdrive contents in API responses\n\nThis change adds a new policy setting, ""show_configdrive"", that defaults\nto masking instance_info[\'configdrive\'] when it is present in an API\nresponse. This policy check works the same way as the existing\n""show_password"" check, and also defaults to mask the response.\n\nNote that this change moves the policy.check(""show_password"") call from\nthe Pecan hook into the API\'s Nodes() class, where the\npolicy.check(""show_configdrive"") is also added. This makes the code a\nlittle cleaner and more maintainable, especially if we want to add any\nmore checks like this in the future.\n\nAs a result of this cleanup, the ironic-specific\nRequestContext.show_password property is removed.\n\nPartial-bug: #1526752\nChange-Id: I48493c53971cdab3b9122897e51322e19ce2f600\n'}, {'number': 10, 'created': '2016-07-29 20:34:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/6b1dd461541c2e3dd8646ad5d3efb19b3471ed1b', 'message': 'Mask configdrive contents in API responses\n\nThis change adds a new policy setting, ""show_configdrive"", that defaults\nto masking instance_info[\'configdrive\'] when it is present in an API\nresponse. This policy check works the same way as the existing\n""show_password"" check, and also defaults to mask the response.\n\nNote that this change moves the policy.check(""show_password"") call from\nthe Pecan hook into the API\'s Nodes() class, where the\npolicy.check(""show_configdrive"") is also added. This makes the code a\nlittle cleaner and more maintainable, especially if we want to add any\nmore checks like this in the future.\n\nAs a result of this cleanup, the ironic-specific\nRequestContext.show_password property is removed.\n\nPartial-bug: #1526752\nChange-Id: I48493c53971cdab3b9122897e51322e19ce2f600\n'}, {'number': 11, 'created': '2016-08-01 22:53:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/7bac0f408323c8cccee578242966dfb7127b2557', 'message': 'Mask configdrive contents in API responses\n\nThis change adds a new policy setting, ""show_configdrive"", that defaults\nto masking instance_info[\'configdrive\'] when it is present in an API\nresponse. This policy check works the same way as the existing\n""show_password"" check, and also defaults to mask the response.\n\nNote that this change moves the policy.check(""show_password"") call from\nthe Pecan hook into the API\'s Nodes() class, where the\npolicy.check(""show_configdrive"") is also added. This makes the code a\nlittle cleaner and more maintainable, especially if we want to add any\nmore checks like this in the future.\n\nAs a result of this cleanup, the ironic-specific\nRequestContext.show_password property is removed.\n\nPartial-bug: #1526752\nChange-Id: I48493c53971cdab3b9122897e51322e19ce2f600\n'}, {'number': 12, 'created': '2016-08-03 02:44:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/6ee4926b6797da57c1148f1e81bc77e53bc2e322', 'message': 'Mask configdrive contents in API responses\n\nThis change adds a new policy setting, ""show_configdrive"", that defaults\nto masking instance_info[\'configdrive\'] when it is present in an API\nresponse. This policy check works the same way as the existing\n""show_password"" check, and also defaults to mask the response.\n\nNote that this change moves the policy.check(""show_password"") call from\nthe Pecan hook into the API\'s Nodes() class, where the\npolicy.check(""show_configdrive"") is also added. This makes the code a\nlittle cleaner and more maintainable, especially if we want to add any\nmore checks like this in the future.\n\nAs a result of this cleanup, the ironic-specific\nRequestContext.show_password property is removed.\n\nPartial-bug: #1526752\nChange-Id: I48493c53971cdab3b9122897e51322e19ce2f600\n'}, {'number': 13, 'created': '2016-08-10 23:30:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/ae72d9512e96ce49d645ebabc696ebef45709875', 'message': 'Mask configdrive contents in API responses\n\nThis change adds a new policy setting, ""show_configdrive"", that defaults\nto masking instance_info[\'configdrive\'] when it is present in an API\nresponse. This policy check works the same way as the existing\n""show_password"" check, and also defaults to mask the response.\n\nNote that this change moves the policy.check(""show_password"") call from\nthe Pecan hook into the API\'s Nodes() class, where the\npolicy.check(""show_configdrive"") is also added. This makes the code a\nlittle cleaner and more maintainable, especially if we want to add any\nmore checks like this in the future.\n\nAs a result of this cleanup, the ironic-specific\nRequestContext.show_password property is removed.\n\nPartial-bug: #1526752\nChange-Id: I48493c53971cdab3b9122897e51322e19ce2f600\n'}, {'number': 14, 'created': '2016-08-16 22:34:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/c11bb036e661b1e959d68460d24a5245275cdc68', 'message': 'Mask instance secrets in API responses\n\nThis change adds a new policy setting, ""show_instance_secrets"", whose\nbehavior mirrors that of the existing ""show_passwords"" policy setting.\n\nWhereas ""show_passwords"" has historically blocked all sensitive\ninformation from the node\'s driver_info field, the new setting blocks\nall sensitive information from the node\'s instance_info field.\n\nThe name of the old setting, ""show_passwords"", is not being changed at\nthis time because such a change is not backwards-compatible. Instead,\nthe documentation string for this setting has been changed to clarify\nwhat it does. Note that the behavior has not actually changed.\n\nNote that this change moves the policy.check(""show_password"") call from\nthe Pecan hook into the API\'s Nodes() class, where the\npolicy.check(""show_instance_secrets"") is also added. This makes the code\na little cleaner and more maintainable, especially if we want to add any\nmore checks like this in the future.\n\nAs a result of this cleanup, the ironic-specific\nRequestContext.show_password property is removed.\n\nPartial-bug: #1530972\nPartial-bug: #1526752\n\nChange-Id: I48493c53971cdab3b9122897e51322e19ce2f600\n'}, {'number': 15, 'created': '2016-08-16 23:50:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/00d93d7c010316d5369ce14f95a51454249d8c2a', 'message': 'ask instance secrets in API responses\n\nThis change adds a new policy setting, ""show_instance_secrets"", whose\nbehavior mirrors that of the existing ""show_passwords"" policy setting.\n\nWhereas ""show_passwords"" has historically blocked all sensitive\ninformation from the node\'s driver_info field, the new setting blocks\nall sensitive information from the node\'s instance_info field, including\nimage_url.\n\nThe name of the old setting, ""show_passwords"", is not being changed at\nthis time because such a change is not backwards-compatible. Instead,\nthe documentation string for this setting has been changed to clarify\nwhat it does. Note that the behavior has not actually changed.\n\nNote that this change moves the policy.check(""show_password"") call from\nthe Pecan hook into the API\'s Nodes() class, where the\npolicy.check(""show_instance_secrets"") is also added. This makes the code\na little cleaner and more maintainable, especially if we want to add any\nmore checks like this in the future.\n\nAs a result of this cleanup, the ironic-specific\nRequestContext.show_password property is removed.\n\nPartial-bug: #1530972\nPartial-bug: #1526752\nRelated-bug: #1613903\n\nChange-Id: I48493c53971cdab3b9122897e51322e19ce2f600\n'}, {'number': 16, 'created': '2016-08-17 16:16:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/1bd21656b341b1b8980375826f9b1f81530063ac', 'message': 'Mask instance secrets in API responses\n\nThis change adds a new policy setting, ""show_instance_secrets"", whose\nbehavior mirrors that of the existing ""show_passwords"" policy setting.\n\nWhereas ""show_passwords"" has historically blocked all sensitive\ninformation from the node\'s driver_info field, the new setting blocks\nall sensitive information from the node\'s instance_info field, including\nimage_url.\n\nThe name of the old setting, ""show_passwords"", is not being changed at\nthis time because such a change is not backwards-compatible. Instead,\nthe documentation string for this setting has been changed to clarify\nwhat it does. Note that the behavior has not actually changed.\n\nNote that this change moves the policy.check(""show_password"") call from\nthe Pecan hook into the API\'s Nodes() class, where the\npolicy.check(""show_instance_secrets"") is also added. This makes the code\na little cleaner and more maintainable, especially if we want to add any\nmore checks like this in the future.\n\nAs a result of this cleanup, the ironic-specific\nRequestContext.show_password property is removed.\n\nPartial-bug: #1530972\nPartial-bug: #1526752\nRelated-bug: #1613903\n\nChange-Id: I48493c53971cdab3b9122897e51322e19ce2f600\n'}, {'number': 17, 'created': '2016-08-26 15:32:01.000000000', 'files': ['ironic/tests/unit/common/test_context.py', 'releasenotes/notes/mask-configdrive-contents-77fc557d6bc63b2b.yaml', 'ironic/common/context.py', 'ironic/tests/unit/api/test_hooks.py', 'ironic/tests/unit/drivers/modules/test_agent_base_vendor.py', 'etc/ironic/policy.json.sample', 'ironic/drivers/modules/agent_base_vendor.py', 'ironic/tests/unit/api/v1/test_nodes.py', 'ironic/api/hooks.py', 'ironic/tests/unit/db/utils.py', 'ironic/common/policy.py', 'ironic/tests/unit/drivers/modules/test_agent.py', 'ironic/api/controllers/v1/node.py', 'ironic/tests/unit/objects/test_node.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/dc0dad97737dcd0dadd1a56eb094cd76207229f0', 'message': 'Mask instance secrets in API responses\n\nThis change adds a new policy setting, ""show_instance_secrets"", whose\nbehavior mirrors that of the existing ""show_passwords"" policy setting.\n\nWhereas ""show_passwords"" has historically blocked all sensitive\ninformation from the node\'s driver_info field, the new setting blocks\nall sensitive information from the node\'s instance_info field, including\nimage_url.\n\nThe name of the old setting, ""show_passwords"", is not being changed at\nthis time because such a change is not backwards-compatible. Instead,\nthe documentation string for this setting has been changed to clarify\nwhat it does. Note that the behavior has not actually changed.\n\nNote that this change moves the policy.check(""show_password"") call from\nthe Pecan hook into the API\'s Nodes() class, where the\npolicy.check(""show_instance_secrets"") is also added. This makes the code\na little cleaner and more maintainable, especially if we want to add any\nmore checks like this in the future.\n\nAs a result of this cleanup, the ironic-specific\nRequestContext.show_password property is removed.\n\nPartial-bug: #1530972\nPartial-bug: #1526752\nRelated-bug: #1613903\n\nChange-Id: I48493c53971cdab3b9122897e51322e19ce2f600\n'}]",34,326768,dc0dad97737dcd0dadd1a56eb094cd76207229f0,101,16,17,2889,,,0,"Mask instance secrets in API responses

This change adds a new policy setting, ""show_instance_secrets"", whose
behavior mirrors that of the existing ""show_passwords"" policy setting.

Whereas ""show_passwords"" has historically blocked all sensitive
information from the node's driver_info field, the new setting blocks
all sensitive information from the node's instance_info field, including
image_url.

The name of the old setting, ""show_passwords"", is not being changed at
this time because such a change is not backwards-compatible. Instead,
the documentation string for this setting has been changed to clarify
what it does. Note that the behavior has not actually changed.

Note that this change moves the policy.check(""show_password"") call from
the Pecan hook into the API's Nodes() class, where the
policy.check(""show_instance_secrets"") is also added. This makes the code
a little cleaner and more maintainable, especially if we want to add any
more checks like this in the future.

As a result of this cleanup, the ironic-specific
RequestContext.show_password property is removed.

Partial-bug: #1530972
Partial-bug: #1526752
Related-bug: #1613903

Change-Id: I48493c53971cdab3b9122897e51322e19ce2f600
",git fetch https://review.opendev.org/openstack/ironic refs/changes/68/326768/2 && git format-patch -1 --stdout FETCH_HEAD,"['ironic/common/context.py', 'etc/ironic/policy.json', 'ironic/api/controllers/v1/node.py']",3,1ec2feb00c03d1d18b307e5c992230bb9b5411f9,bug/1530972," def _convert_with_links(node, url, fields=None, show_states_links=True): show_password = policy.check(""show_password"", pecan.request.context.to_dict(), pecan.request.context.to_dict(), ) show_configdrive = policy.check(""show_configdrive"", pecan.request.context.to_dict(), pecan.request.context.to_dict(), ) if not show_configdrive and node.instance_info != wtypes.Unset: node.instance_info = ast.literal_eval(strutils.mask_password( node.instance_info, ""******"")) "," def _convert_with_links(node, url, fields=None, show_password=True, show_states_links=True): show_password = pecan.request.context.show_password show_password=show_password,",22,7
openstack%2Ffuel-ui~master~Ia96f9b92d1bb0164923ae84533eaf92247ee7e83,openstack/fuel-ui,master,Ia96f9b92d1bb0164923ae84533eaf92247ee7e83,[WIP] Enabling randomly failing tests,ABANDONED,2016-08-26 05:02:50.000000000,2016-08-29 14:03:06.000000000,,"[{'_account_id': 3}, {'_account_id': 8735}, {'_account_id': 8766}, {'_account_id': 8971}, {'_account_id': 9730}, {'_account_id': 15315}, {'_account_id': 20656}, {'_account_id': 21013}]","[{'number': 1, 'created': '2016-08-26 05:02:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-ui/commit/a7debd6bcabbd4c5e4ffeb23b0a3323116441a03', 'message': '[WIP] Enabling randomly failing tests\n\nChange-Id: Ia96f9b92d1bb0164923ae84533eaf92247ee7e83\n'}, {'number': 2, 'created': '2016-08-26 09:50:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-ui/commit/92985abce4b46543e9634c86b4fb1d7536e16685', 'message': '[WIP] Enabling randomly failing tests\n\nChange-Id: Ia96f9b92d1bb0164923ae84533eaf92247ee7e83\n'}, {'number': 3, 'created': '2016-08-29 06:25:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-ui/commit/32beed1c3d9d844d2ce9dab6aa5ec2628a1fe4bb', 'message': '[WIP] Enabling randomly failing tests\n\nChange-Id: Ia96f9b92d1bb0164923ae84533eaf92247ee7e83\n'}, {'number': 4, 'created': '2016-08-29 06:50:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-ui/commit/7cb39f5c29bbb224f88f4ebaa8d33716b7cd480b', 'message': '[WIP] Enabling randomly failing tests\n\nChange-Id: Ia96f9b92d1bb0164923ae84533eaf92247ee7e83\n'}, {'number': 5, 'created': '2016-08-29 07:00:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-ui/commit/cc9461e43079e869502fd8116bfe99ce41e24952', 'message': '[WIP] Enabling randomly failing tests\n\nChange-Id: Ia96f9b92d1bb0164923ae84533eaf92247ee7e83\n'}, {'number': 6, 'created': '2016-08-29 07:08:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-ui/commit/6afcaa799e848ad9d1edf8b468ee40391854c007', 'message': '[WIP] Enabling randomly failing tests\n\nChange-Id: Ia96f9b92d1bb0164923ae84533eaf92247ee7e83\n'}, {'number': 7, 'created': '2016-08-29 07:17:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-ui/commit/c88953edfc8d84a1ea6931973f27075fb3aff9c1', 'message': '[WIP] Enabling randomly failing tests\n\nChange-Id: Ia96f9b92d1bb0164923ae84533eaf92247ee7e83\n'}, {'number': 8, 'created': '2016-08-29 07:22:49.000000000', 'files': ['static/tests/functional/test_cluster_deployment.js', 'run_ui_func_tests.sh'], 'web_link': 'https://opendev.org/openstack/fuel-ui/commit/ea781cfe0779b9144954d5ad7ce7fffae545e523', 'message': '[WIP] Enabling randomly failing tests\n\nChange-Id: Ia96f9b92d1bb0164923ae84533eaf92247ee7e83\n'}]",0,360887,ea781cfe0779b9144954d5ad7ce7fffae545e523,59,8,8,21013,,,0,"[WIP] Enabling randomly failing tests

Change-Id: Ia96f9b92d1bb0164923ae84533eaf92247ee7e83
",git fetch https://review.opendev.org/openstack/fuel-ui refs/changes/87/360887/8 && git format-patch -1 --stdout FETCH_HEAD,['static/tests/functional/test_cluster_deployment.js'],1,a7debd6bcabbd4c5e4ffeb23b0a3323116441a03,bug/1615557,, // Uncomment after fix of #1615557 /**/,0,3
openstack%2Ffuel-web~master~I7092ae90a3a2ffcd6c840ad5802f918f9d532cbb,openstack/fuel-web,master,I7092ae90a3a2ffcd6c840ad5802f918f9d532cbb,Debug log level for nailgun tests by default,ABANDONED,2016-08-24 15:22:46.000000000,2016-08-29 14:02:57.000000000,,"[{'_account_id': 3}, {'_account_id': 8931}, {'_account_id': 8971}, {'_account_id': 10488}, {'_account_id': 10959}, {'_account_id': 11898}, {'_account_id': 12661}, {'_account_id': 14200}, {'_account_id': 19158}, {'_account_id': 20384}, {'_account_id': 20656}, {'_account_id': 21013}]","[{'number': 1, 'created': '2016-08-24 15:22:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/3317eb6e6d9ad310098abce51b5153171041034d', 'message': 'Debug log level for nailgun tests by default\n\nChange-Id: I7092ae90a3a2ffcd6c840ad5802f918f9d532cbb\nRelated-Bug: 1615557\n'}, {'number': 2, 'created': '2016-08-25 08:58:39.000000000', 'files': ['nailgun/tools/env_functions.sh'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/1e40f055b2061ac4d385cf0d0dcda836bc5afcec', 'message': 'Debug log level for nailgun tests by default\n\nChange-Id: I7092ae90a3a2ffcd6c840ad5802f918f9d532cbb\nRelated-Bug: 1615557\n'}]",0,359956,1e40f055b2061ac4d385cf0d0dcda836bc5afcec,57,12,2,21013,,,0,"Debug log level for nailgun tests by default

Change-Id: I7092ae90a3a2ffcd6c840ad5802f918f9d532cbb
Related-Bug: 1615557
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/56/359956/1 && git format-patch -1 --stdout FETCH_HEAD,['nailgun/tools/env_functions.sh'],1,3317eb6e6d9ad310098abce51b5153171041034d,bug/1615557,"APP_LOGLEVEL: ""DEBUG""","APP_LOGLEVEL: ""ERROR""",1,1
openstack%2Fos-api-ref~master~Ic5c61d286c071c2fc45a5d215bef4f7344d490f8,openstack/os-api-ref,master,Ic5c61d286c071c2fc45a5d215bef4f7344d490f8,Add color for COPY label,MERGED,2016-08-04 17:27:45.000000000,2016-08-29 14:01:30.000000000,2016-08-29 13:16:28.000000000,"[{'_account_id': 3}, {'_account_id': 964}, {'_account_id': 2750}, {'_account_id': 8099}, {'_account_id': 10497}, {'_account_id': 15293}]","[{'number': 1, 'created': '2016-08-04 17:27:45.000000000', 'files': ['os_api_ref/assets/api-site.css'], 'web_link': 'https://opendev.org/openstack/os-api-ref/commit/f9241b160eb8203d51146b0729dc29c4d58d020c', 'message': 'Add color for COPY label\n\nAdd colors in css for COPY label.\n\nChange-Id: Ic5c61d286c071c2fc45a5d215bef4f7344d490f8\n'}]",1,351297,f9241b160eb8203d51146b0729dc29c4d58d020c,11,6,1,15293,,,0,"Add color for COPY label

Add colors in css for COPY label.

Change-Id: Ic5c61d286c071c2fc45a5d215bef4f7344d490f8
",git fetch https://review.opendev.org/openstack/os-api-ref refs/changes/97/351297/1 && git format-patch -1 --stdout FETCH_HEAD,['os_api_ref/assets/api-site.css'],1,f9241b160eb8203d51146b0729dc29c4d58d020c,add-copy-label,".label-COPY { background-color: #6666ff; } .label-COPY[href]:hover, .label-COPY[href]:focus { background-color: #6699ff; }",,7,0
openstack%2Ftripleo-heat-templates~master~I6f14f1db8a8e6c1afa2729a779f0f72e00214de0,openstack/tripleo-heat-templates,master,I6f14f1db8a8e6c1afa2729a779f0f72e00214de0,WIP: Avoid using MysqlNetwork to set Ironic my_ip,ABANDONED,2016-08-26 20:49:05.000000000,2016-08-29 14:00:05.000000000,,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 6773}, {'_account_id': 10239}]","[{'number': 1, 'created': '2016-08-26 20:49:05.000000000', 'files': ['puppet/services/ironic-api.yaml', 'network/service_net_map.yaml', 'puppet/services/ironic-conductor.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/c276b457b02ba9875816ece13757dd37925b0978', 'message': 'WIP: Avoid using MysqlNetwork to set Ironic my_ip\n\nThis patch adds a new IronicNetwork setting which is used\nto control which network Ironic will use for its PXE network\ntraffic.\n\nChange-Id: I6f14f1db8a8e6c1afa2729a779f0f72e00214de0\n'}]",1,361464,c276b457b02ba9875816ece13757dd37925b0978,6,4,1,360,,,0,"WIP: Avoid using MysqlNetwork to set Ironic my_ip

This patch adds a new IronicNetwork setting which is used
to control which network Ironic will use for its PXE network
traffic.

Change-Id: I6f14f1db8a8e6c1afa2729a779f0f72e00214de0
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/64/361464/1 && git format-patch -1 --stdout FETCH_HEAD,"['puppet/services/ironic-api.yaml', 'network/service_net_map.yaml', 'puppet/services/ironic-conductor.yaml']",3,c276b457b02ba9875816ece13757dd37925b0978,fix_ironic_bind_ips," ironic::drivers::pxe::tftp_server: {get_param: [ServiceNetMap, IronicNetwork]}"," ironic::drivers::pxe::tftp_server: {get_param: [ServiceNetMap, IronicApiNetwork]}",3,2
openstack%2Fsahara~master~I8683176685ba531eeda2e10be782475e4af4d4fa,openstack/sahara,master,I8683176685ba531eeda2e10be782475e4af4d4fa,replace assertListEqual() to assertEqual(),MERGED,2016-08-25 02:56:42.000000000,2016-08-29 13:59:48.000000000,2016-08-29 13:59:48.000000000,"[{'_account_id': 3}, {'_account_id': 7213}, {'_account_id': 12038}]","[{'number': 1, 'created': '2016-08-25 02:56:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/edfdbacf8ea5d9c0aff27e0d20fa0444d67554de', 'message': 'replace assertListEqual() to assertEqual()\n\nIn unittest2, assertListEqual() is implemented by\nusing != operator to compare two lists.\nassert{List/Set/Dict/Tuple}Equal(), these methods are used by default\nwhen comparing dicts, sets, lists or tuples with assertEqual().\nSo we just call assertEqual() to make the unit tests simpler.\n\nChange-Id: I8683176685ba531eeda2e10be782475e4af4d4fa\n'}, {'number': 2, 'created': '2016-08-25 04:20:40.000000000', 'files': ['sahara/tests/unit/plugins/mapr/test_cluster_context.py'], 'web_link': 'https://opendev.org/openstack/sahara/commit/2d54607c151fde3fc66cd2cfeb8cbab5672dee57', 'message': 'replace assertListEqual() to assertEqual()\n\nIn unittest2, assertListEqual() is implemented by\nusing != operator to compare two lists.\nassert{List/Set/Dict/Tuple}Equal(), these methods are used by default\nwhen comparing dicts, sets, lists or tuples with assertEqual().\nSo we just call assertEqual() to make the unit tests simpler.\n\nChange-Id: I8683176685ba531eeda2e10be782475e4af4d4fa\n'}]",0,360193,2d54607c151fde3fc66cd2cfeb8cbab5672dee57,11,3,2,22689,,,0,"replace assertListEqual() to assertEqual()

In unittest2, assertListEqual() is implemented by
using != operator to compare two lists.
assert{List/Set/Dict/Tuple}Equal(), these methods are used by default
when comparing dicts, sets, lists or tuples with assertEqual().
So we just call assertEqual() to make the unit tests simpler.

Change-Id: I8683176685ba531eeda2e10be782475e4af4d4fa
",git fetch https://review.opendev.org/openstack/sahara refs/changes/93/360193/2 && git format-patch -1 --stdout FETCH_HEAD,['sahara/tests/unit/plugins/mapr/test_cluster_context.py'],1,edfdbacf8ea5d9c0aff27e0d20fa0444d67554de,unify_assert_in_test," self.assertEqual(sorted(actual_services_names),"," self.assertListEqual(sorted(actual_services_names),",1,1
openstack%2Fproject-config~master~I1126b0e5c8ba43c11a3ab04ede6dc8cdb8a31a1a,openstack/project-config,master,I1126b0e5c8ba43c11a3ab04ede6dc8cdb8a31a1a,Introduce functional/fullstack Neutron Xenial jobs,ABANDONED,2016-08-29 13:53:17.000000000,2016-08-29 13:59:08.000000000,,[],"[{'number': 1, 'created': '2016-08-29 13:53:17.000000000', 'files': ['jenkins/jobs/projects.yaml', 'jenkins/jobs/neutron.yaml', 'zuul/layout.yaml', 'grafana/neutron.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/0ac96b8b26a0c35da52a462c3f325ff5fedc3a81', 'message': 'Introduce functional/fullstack Neutron Xenial jobs\n\nThese jobs are part of experimental queue for now, until we are confident\nenough to switch check queue for using Xenial as well.\n\nChange-Id: I1126b0e5c8ba43c11a3ab04ede6dc8cdb8a31a1a\n'}]",0,362127,0ac96b8b26a0c35da52a462c3f325ff5fedc3a81,2,0,1,8655,,,0,"Introduce functional/fullstack Neutron Xenial jobs

These jobs are part of experimental queue for now, until we are confident
enough to switch check queue for using Xenial as well.

Change-Id: I1126b0e5c8ba43c11a3ab04ede6dc8cdb8a31a1a
",git fetch https://review.opendev.org/openstack/project-config refs/changes/27/362127/1 && git format-patch -1 --stdout FETCH_HEAD,"['jenkins/jobs/projects.yaml', 'jenkins/jobs/neutron.yaml', 'zuul/layout.yaml', 'grafana/neutron.yaml']",4,0ac96b8b26a0c35da52a462c3f325ff5fedc3a81,functional-fullstack-xenial," - target: alias(movingAverage(asPercent(transformNull(stats_counts.zuul.pipeline.check.job.gate-neutron-dsvm-functional-ubuntu-trusty.FAILURE),sum(stats_counts.zuul.pipeline.check.job.gate-neutron-dsvm-functional-ubuntu-trusty.{SUCCESS,FAILURE})),'24hours'), 'gate-neutron-dsvm-functional-ubuntu-trusty') - target: alias(movingAverage(asPercent(transformNull(stats_counts.zuul.pipeline.check.job.gate-neutron-dsvm-fullstack-ubuntu.trusty.FAILURE),sum(stats_counts.zuul.pipeline.check.job.gate-neutron-dsvm-fullstack-ubuntu-trusty.{SUCCESS,FAILURE})),'24hours'), 'gate-neutron-dsvm-fullstack-ubuntu-trusty')"," - target: alias(movingAverage(asPercent(transformNull(stats_counts.zuul.pipeline.check.job.gate-neutron-dsvm-functional.FAILURE),sum(stats_counts.zuul.pipeline.check.job.gate-neutron-dsvm-functional.{SUCCESS,FAILURE})),'24hours'), 'gate-neutron-dsvm-functional') - target: alias(movingAverage(asPercent(transformNull(stats_counts.zuul.pipeline.check.job.gate-neutron-dsvm-fullstack.FAILURE),sum(stats_counts.zuul.pipeline.check.job.gate-neutron-dsvm-fullstack.{SUCCESS,FAILURE})),'24hours'), 'gate-neutron-dsvm-fullstack')",28,15
openstack%2Fneutron-vpnaas~master~I55a4cb635fc91d6c853b189b08ee5687712d9ccc,openstack/neutron-vpnaas,master,I55a4cb635fc91d6c853b189b08ee5687712d9ccc,Fix DeprecationWarnings part II,MERGED,2016-08-10 11:35:07.000000000,2016-08-29 13:59:03.000000000,2016-08-29 13:59:03.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 6659}, {'_account_id': 11682}]","[{'number': 1, 'created': '2016-08-10 11:35:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-vpnaas/commit/2d58be3cc1c12181e71e2f730778e65107fd76fb', 'message': 'Fix DeprecationWarnings part II\n\nWhile gate tests are currently passing, the console indicates\nthat there are multiple deprecation warnings that will break\nin Ocata.  This patch continues the process of fixing them.\n\nChange-Id: I55a4cb635fc91d6c853b189b08ee5687712d9ccc\n'}, {'number': 2, 'created': '2016-08-10 11:56:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-vpnaas/commit/8c366dbfc4a5023b7ce13e8c8fe1e111c780a90e', 'message': 'Fix DeprecationWarnings part II\n\nWhile gate tests are currently passing, the console indicates\nthat there are multiple deprecation warnings that will break\nin Ocata.  This patch continues the process of fixing them.\n\nChange-Id: I55a4cb635fc91d6c853b189b08ee5687712d9ccc\n'}, {'number': 3, 'created': '2016-08-10 12:17:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-vpnaas/commit/bca8311b9c995766318d1d8a7b75c372196224e1', 'message': 'Fix DeprecationWarnings part II\n\nWhile gate tests are currently passing, the console indicates\nthat there are multiple deprecation warnings that will break\nin Ocata.  This patch continues the process of fixing them.\n\nChange-Id: I55a4cb635fc91d6c853b189b08ee5687712d9ccc\n'}, {'number': 4, 'created': '2016-08-11 14:52:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-vpnaas/commit/48be62d68824f611133d1951cfd0a3d7f9eba52c', 'message': 'Fix DeprecationWarnings part II\n\nWhile gate tests are currently passing, the console indicates\nthat there are multiple deprecation warnings that will break\nin Ocata.  This patch continues the process of fixing them.\n\nChange-Id: I55a4cb635fc91d6c853b189b08ee5687712d9ccc\n'}, {'number': 5, 'created': '2016-08-11 17:26:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-vpnaas/commit/9a0d8c62581fd788f6cf8781220b72d466833762', 'message': 'Fix DeprecationWarnings part II\n\nWhile gate tests are currently passing, the console indicates\nthat there are multiple deprecation warnings that will break\nin Ocata.  This patch continues the process of fixing them.\n\nChange-Id: I55a4cb635fc91d6c853b189b08ee5687712d9ccc\n'}, {'number': 6, 'created': '2016-08-25 16:52:59.000000000', 'files': ['neutron_vpnaas/extensions/vpnaas.py'], 'web_link': 'https://opendev.org/openstack/neutron-vpnaas/commit/453dbf4dd97f9cc217bfd754f98c5e08d2bee59b', 'message': 'Fix DeprecationWarnings part II\n\nWhile gate tests are currently passing, the console indicates\nthat there are multiple deprecation warnings that will break\nin Ocata.  This patch continues the process of fixing them.\n\nChange-Id: I55a4cb635fc91d6c853b189b08ee5687712d9ccc\n'}]",2,353397,453dbf4dd97f9cc217bfd754f98c5e08d2bee59b,18,4,6,11682,,,0,"Fix DeprecationWarnings part II

While gate tests are currently passing, the console indicates
that there are multiple deprecation warnings that will break
in Ocata.  This patch continues the process of fixing them.

Change-Id: I55a4cb635fc91d6c853b189b08ee5687712d9ccc
",git fetch https://review.opendev.org/openstack/neutron-vpnaas refs/changes/97/353397/5 && git format-patch -1 --stdout FETCH_HEAD,['neutron_vpnaas/extensions/vpnaas.py'],1,2d58be3cc1c12181e71e2f730778e65107fd76fb,fix_deprecations_1,,attr.validators['type:subnet_list_or_none'] = _validate_subnet_list_or_none ,0,2
openstack%2Fceilometer~master~I32e70bfb7d6fbea498647589a33a5a7ee41bc9a0,openstack/ceilometer,master,I32e70bfb7d6fbea498647589a33a5a7ee41bc9a0,Small twist to _get_sample for documentation purposes,ABANDONED,2016-07-07 08:10:25.000000000,2016-08-29 13:58:47.000000000,,"[{'_account_id': 3}, {'_account_id': 2813}, {'_account_id': 6537}, {'_account_id': 8358}, {'_account_id': 15843}, {'_account_id': 15857}]","[{'number': 1, 'created': '2016-07-07 08:10:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/9b2b18d66396e2d668cedaa726c644c283dbe01c', 'message': 'Small twist to _get_sample for documentation purposes\n\nThis patch makes a small change to the _get_sample method of\n_LBStatsPollster to annoate it as both static and abstract, in order\nto help documentation purpose and keep consistency when add new\ninhetriant implements in future.\n\nChange-Id: I32e70bfb7d6fbea498647589a33a5a7ee41bc9a0\n'}, {'number': 2, 'created': '2016-07-07 08:35:00.000000000', 'files': ['ceilometer/network/services/lbaas.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/e2553150445ad70256f262d12091e05989d630ad', 'message': 'Small twist to _get_sample for documentation purposes\n\nThis patch makes a small change to the _get_sample method of\n_LBStatsPollster to annoate it as both static and abstract, in order\nto help documentation purpose and keep consistency when add new\ninhetriant implements in future.\n\nChange-Id: I32e70bfb7d6fbea498647589a33a5a7ee41bc9a0\n'}]",0,338751,e2553150445ad70256f262d12091e05989d630ad,16,6,2,15857,,,0,"Small twist to _get_sample for documentation purposes

This patch makes a small change to the _get_sample method of
_LBStatsPollster to annoate it as both static and abstract, in order
to help documentation purpose and keep consistency when add new
inhetriant implements in future.

Change-Id: I32e70bfb7d6fbea498647589a33a5a7ee41bc9a0
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/51/338751/1 && git format-patch -1 --stdout FETCH_HEAD,['ceilometer/network/services/lbaas.py'],1,9b2b18d66396e2d668cedaa726c644c283dbe01c,twist-lbaasv2,abstractstaticmethod = abc.abstractmethod @abstractstaticmethod, @abc.abstractmethod,3,1
openstack%2Fmanila~master~I1c13e4d92d0629361affb5dcd8ae793b33b33c9b,openstack/manila,master,I1c13e4d92d0629361affb5dcd8ae793b33b33c9b,Get ready for os-api-ref sphinx theme change,MERGED,2016-08-19 14:33:17.000000000,2016-08-29 13:58:28.000000000,2016-08-23 19:33:57.000000000,"[{'_account_id': 3}, {'_account_id': 2417}, {'_account_id': 7102}, {'_account_id': 8099}, {'_account_id': 13144}, {'_account_id': 13998}, {'_account_id': 16643}, {'_account_id': 18128}]","[{'number': 1, 'created': '2016-08-19 14:33:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/a753a9a29235ea246cda945cb86f5b810e2c5b7d', 'message': 'Get ready for os-api-ref sphinx theme change\n\nChange-Id: I1c13e4d92d0629361affb5dcd8ae793b33b33c9b\n'}, {'number': 2, 'created': '2016-08-19 15:54:47.000000000', 'files': ['api-ref/source/conf.py'], 'web_link': 'https://opendev.org/openstack/manila/commit/8210bf5310c203936968eb3701b9dd769688753c', 'message': 'Get ready for os-api-ref sphinx theme change\n\nChange-Id: I1c13e4d92d0629361affb5dcd8ae793b33b33c9b\n'}]",0,357924,8210bf5310c203936968eb3701b9dd769688753c,25,8,2,8099,,,0,"Get ready for os-api-ref sphinx theme change

Change-Id: I1c13e4d92d0629361affb5dcd8ae793b33b33c9b
",git fetch https://review.opendev.org/openstack/manila refs/changes/24/357924/2 && git format-patch -1 --stdout FETCH_HEAD,['api-ref/source/conf.py'],1,a753a9a29235ea246cda945cb86f5b810e2c5b7d,os-api-ref-1.0.0-prep,"# TODO(Graham Hayes): Remove the following block of code when os-api-ref is # using openstackdocstheme (in the 0.5.x release series) CUT_OVER_MINOR = 9 CUT_OVER_MAJOR = 0 import os_api_ref from oslo_utils import versionutils major, minor, _ = versionutils.convert_version_to_tuple(os_api_ref.__version__) if major > CUT_OVER_MAJOR or minor > CUT_OVER_MINOR: # We are on the new version with openstackdocstheme support extensions = [ 'os_api_ref', ] import openstackdocstheme # noqa html_theme = 'openstackdocs' html_theme_path = [openstackdocstheme.get_html_theme_path()] html_theme_options = { ""sidebar_mode"": ""toc"", } else: # We are on the old version without openstackdocstheme support extensions = [ 'os_api_ref', 'oslosphinx', ] # End temporary block ","extensions = [ 'os_api_ref', 'oslosphinx', ]",35,4
openstack%2Ffuel-library~master~I2e471cdc2520337921e84035f9a4f0f54adfba07,openstack/fuel-library,master,I2e471cdc2520337921e84035f9a4f0f54adfba07,Fix keystone_authtoken middleware for glance,MERGED,2016-08-17 16:23:51.000000000,2016-08-29 13:56:48.000000000,2016-08-29 13:51:55.000000000,"[{'_account_id': 3}, {'_account_id': 7468}, {'_account_id': 7604}, {'_account_id': 7732}, {'_account_id': 7745}, {'_account_id': 8971}, {'_account_id': 9037}, {'_account_id': 11090}, {'_account_id': 11827}, {'_account_id': 13344}, {'_account_id': 13752}, {'_account_id': 14200}, {'_account_id': 14985}, {'_account_id': 16771}, {'_account_id': 18290}, {'_account_id': 20517}, {'_account_id': 20656}]","[{'number': 1, 'created': '2016-08-17 16:23:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/1ac14c6faae929e7252f80ac0506b79a92844a9b', 'message': ""Fix keystone_authtoken middleware for glance\n\nAs PKI tokens are not supported 'signing_dir' was\nremoved for glance.\n\nChange-Id: I2e471cdc2520337921e84035f9a4f0f54adfba07\nRelated-Bug: #1600276\n""}, {'number': 2, 'created': '2016-08-18 10:44:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/8819d135fbbb390b6dbe380956baf626383c8e74', 'message': 'Fix keystone_authtoken middleware for glance\n\nWe need to resolve conflicts to unlock\nhttps://review.openstack.org/#/c/348826/\n\n - Remove conflicting authtoken parameters\n - Temporarily disable noop test\n\nChange-Id: I2e471cdc2520337921e84035f9a4f0f54adfba07\nRelated-Bug: #1600276\n'}, {'number': 3, 'created': '2016-08-23 11:37:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/4dbe6c4cba1f744c5f5edffbfc4224b4fb7a7dd3', 'message': 'Fix keystone_authtoken middleware for glance\n\nWe need to resolve conflicts to unlock\nhttps://review.openstack.org/#/c/348826/\n\n - Remove conflicting authtoken parameters\n - Temporarily disable noop test\n\nChange-Id: I2e471cdc2520337921e84035f9a4f0f54adfba07\nRelated-Bug: #1600276\n'}, {'number': 4, 'created': '2016-08-23 15:06:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/dd8439d8dd8714a834189065610f5987587e8f81', 'message': 'Fix keystone_authtoken middleware for glance\n\nWe need to resolve conflicts to unlock\nhttps://review.openstack.org/#/c/348826/\n\n - Remove conflicting authtoken parameters\n - Temporarily disable noop test\n\nChange-Id: I2e471cdc2520337921e84035f9a4f0f54adfba07\nRelated-Bug: #1600276\n'}, {'number': 5, 'created': '2016-08-23 15:57:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/3ebf2ced1be547f6e6e9ec71b9de3d71480998a2', 'message': 'Fix keystone_authtoken middleware for glance\n\nWe need to resolve conflicts to unlock\nhttps://review.openstack.org/#/c/348826/\n\n - Remove conflicting authtoken parameters\n - Temporarily disable noop test\n\nChange-Id: I2e471cdc2520337921e84035f9a4f0f54adfba07\nRelated-Bug: #1600276\n'}, {'number': 6, 'created': '2016-08-24 12:00:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/171512cbce3906537f3feee83c0204aab4f2060d', 'message': 'Fix keystone_authtoken middleware for glance\n\nWe need to resolve conflicts to unlock\nhttps://review.openstack.org/#/c/348826/\n\n - Remove conflicting authtoken parameters\n - Temporarily disable noop test\n\nChange-Id: I2e471cdc2520337921e84035f9a4f0f54adfba07\nRelated-Bug: #1600276\n'}, {'number': 7, 'created': '2016-08-29 09:37:53.000000000', 'files': ['tests/noop/spec/hosts/glance/glance_spec.rb', 'deployment/puppet/openstack_tasks/manifests/glance/glance.pp'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/26c6361e287782bd00ee924b648959e24db49ae6', 'message': 'Fix keystone_authtoken middleware for glance\n\nWe need to resolve conflicts to unlock\nhttps://review.openstack.org/#/c/348826/\n\n - Remove conflicting authtoken parameters\n - Temporarily disable noop test\n\nChange-Id: I2e471cdc2520337921e84035f9a4f0f54adfba07\nRelated-Bug: #1600276\n'}]",2,356583,26c6361e287782bd00ee924b648959e24db49ae6,179,17,7,13752,,,0,"Fix keystone_authtoken middleware for glance

We need to resolve conflicts to unlock
https://review.openstack.org/#/c/348826/

 - Remove conflicting authtoken parameters
 - Temporarily disable noop test

Change-Id: I2e471cdc2520337921e84035f9a4f0f54adfba07
Related-Bug: #1600276
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/83/356583/4 && git format-patch -1 --stdout FETCH_HEAD,['deployment/puppet/openstack_tasks/manifests/glance/glance.pp'],1,1ac14c6faae929e7252f80ac0506b79a92844a9b,bug/1600276,, # TODO (dmburmistrov): remove this workaround after puppet-glance # will migrate to keystone auth_plugin usage (CR #313545) glance_api_config { 'keystone_authtoken/auth_type': value => 'password'; 'keystone_authtoken/auth_url': value => $identity_uri; 'keystone_authtoken/username': value => $glance_user; 'keystone_authtoken/password': value => $glance_user_password; 'keystone_authtoken/project_name': value => $glance_tenant; } ,0,10
openstack%2Fkolla~master~Ib570bf71a2567653f4643adb3670ecf824d83e61,openstack/kolla,master,Ib570bf71a2567653f4643adb3670ecf824d83e61,Add missing container image names to build config file,MERGED,2016-08-18 04:09:31.000000000,2016-08-29 13:54:56.000000000,2016-08-29 13:54:56.000000000,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 1390}, {'_account_id': 7488}, {'_account_id': 11105}, {'_account_id': 14103}, {'_account_id': 16993}, {'_account_id': 19316}]","[{'number': 1, 'created': '2016-08-18 04:09:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/cb8110271bbd493ba491de59443abadf0b97a43b', 'message': 'Add performance monitoring container to build config file\n\nChange-Id: Ib570bf71a2567653f4643adb3670ecf824d83e61\ncloses-Bug: #1614354\n'}, {'number': 2, 'created': '2016-08-19 05:31:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/df26b9737b73c26c4d4d7f64be5ddec7e14daa40', 'message': 'Add missing container image names to build config file\n\nChange-Id: Ib570bf71a2567653f4643adb3670ecf824d83e61\ncloses-Bug: #1614354\n'}, {'number': 3, 'created': '2016-08-19 05:41:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/d4afc82f512709f6326686d7efab8587894eb131', 'message': 'Add missing container image names to build config file\n\nChange-Id: Ib570bf71a2567653f4643adb3670ecf824d83e61\ncloses-Bug: #1614354\n'}, {'number': 4, 'created': '2016-08-19 15:03:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/2c26dd04897aca1d9f8670acbd947d13375983c6', 'message': 'Add missing container image names to build config file\n\nChange-Id: Ib570bf71a2567653f4643adb3670ecf824d83e61\ncloses-Bug: #1614354\n'}, {'number': 5, 'created': '2016-08-24 04:04:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/bb6b9a617607a73fdf74265d4246550c0344d4c5', 'message': 'Add missing container image names to build config file\n\nChange-Id: Ib570bf71a2567653f4643adb3670ecf824d83e61\ncloses-Bug: #1614354\n'}, {'number': 6, 'created': '2016-08-29 03:51:16.000000000', 'files': ['kolla/common/config.py'], 'web_link': 'https://opendev.org/openstack/kolla/commit/2973bc7dc52a22bd978c6cc00e8dd332c4e1a2d9', 'message': 'Add missing container image names to build config file\n\nChange-Id: Ib570bf71a2567653f4643adb3670ecf824d83e61\ncloses-Bug: #1614354\n'}]",4,356854,2973bc7dc52a22bd978c6cc00e8dd332c4e1a2d9,40,8,6,16993,,,0,"Add missing container image names to build config file

Change-Id: Ib570bf71a2567653f4643adb3670ecf824d83e61
closes-Bug: #1614354
",git fetch https://review.opendev.org/openstack/kolla refs/changes/54/356854/2 && git format-patch -1 --stdout FETCH_HEAD,['kolla/common/config.py'],1,cb8110271bbd493ba491de59443abadf0b97a43b,etcd-dockerfile," default=['aodh', 'designate', 'gnocchi', 'influxdb', 'ironic', 'magnum', 'mistral', 'telegraf', 'trove,' 'zaqar', 'zookeeper'],"," default=['aodh', 'designate', 'gnocchi', 'ironic', 'magnum', 'mistral', 'trove,' 'zaqar', 'zookeeper'],",3,2
openstack%2Fpython-aodhclient~master~Ib9920a1f21885917fe7bc4562f1b54602112a473,openstack/python-aodhclient,master,Ib9920a1f21885917fe7bc4562f1b54602112a473,add default value for http_status in ClientException,MERGED,2016-05-30 11:11:43.000000000,2016-08-29 13:54:42.000000000,2016-08-29 13:54:42.000000000,"[{'_account_id': 3}, {'_account_id': 6537}, {'_account_id': 8290}]","[{'number': 1, 'created': '2016-05-30 11:11:43.000000000', 'files': ['aodhclient/exceptions.py', 'aodhclient/tests/unit/test_exceptions.py'], 'web_link': 'https://opendev.org/openstack/python-aodhclient/commit/d75a8e83bb4a17286b34daadb1322d881c07f274', 'message': ""add default value for http_status in ClientException\n\nClientException is not a virtual base class, hence it can be\ninitialized and string formatted, but the required property\n'http_status' is not set by defaut, which will cause AttributeError\nif we cannot convert a dedicate exception from response.\n\nThis patch fixes it by adding default value 'N/A' for http_status,\nand set it with response.status_code when it is a ClientException\ninstance.\n\nChange-Id: Ib9920a1f21885917fe7bc4562f1b54602112a473\nCloses-Bug: #1586994\n""}]",3,322768,d75a8e83bb4a17286b34daadb1322d881c07f274,9,3,1,6676,,,0,"add default value for http_status in ClientException

ClientException is not a virtual base class, hence it can be
initialized and string formatted, but the required property
'http_status' is not set by defaut, which will cause AttributeError
if we cannot convert a dedicate exception from response.

This patch fixes it by adding default value 'N/A' for http_status,
and set it with response.status_code when it is a ClientException
instance.

Change-Id: Ib9920a1f21885917fe7bc4562f1b54602112a473
Closes-Bug: #1586994
",git fetch https://review.opendev.org/openstack/python-aodhclient refs/changes/68/322768/1 && git format-patch -1 --stdout FETCH_HEAD,"['aodhclient/exceptions.py', 'aodhclient/tests/unit/test_exceptions.py']",2,d75a8e83bb4a17286b34daadb1322d881c07f274,bug/1586994,"# Copyright 2016 Hewlett Packard Enterprise Development Company, L.P. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import mock from oslotest import base from aodhclient import exceptions class AodhclientExceptionsTest(base.BaseTestCase): def test_string_format_base_exception(self): # ensure http_status has initial value N/A self.assertEqual('Unknown Error (HTTP N/A)', '%s' % exceptions.ClientException()) def test_no_match_exception_from_response(self): resp = mock.MagicMock(status_code=520) resp.headers = { 'Content-Type': 'text/plain', 'x-openstack-request-id': 'fake-request-id' } resp.text = 'Of course I still love you' e = exceptions.from_response(resp, 'http://no.where:2333/v2/alarms') self.assertIsInstance(e, exceptions.ClientException) self.assertEqual('Of course I still love you (HTTP 520) ' '(Request-ID: fake-request-id)', '%s' % e) ",,45,3
openstack%2Ftripleo-quickstart~master~Ie7c113b18f8850328f92fadb6a960074df4fb470,openstack/tripleo-quickstart,master,Ie7c113b18f8850328f92fadb6a960074df4fb470,Add ci-script to upload images in OVB,MERGED,2016-08-15 13:55:41.000000000,2016-08-29 13:52:32.000000000,2016-08-29 13:52:32.000000000,"[{'_account_id': 3}, {'_account_id': 8652}, {'_account_id': 8745}, {'_account_id': 9592}, {'_account_id': 9976}, {'_account_id': 11105}, {'_account_id': 12715}, {'_account_id': 18846}, {'_account_id': 21686}]","[{'number': 1, 'created': '2016-08-15 13:55:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/7a6287d791b0a4f0adb08f3f838b06ef80c8724b', 'message': 'Adds option to ci-script to mange image in OVB\n\nThe OVB code offers two options:\n - to use an image already exsiting in the hosr cloud\n - to upload a new image\nThis option was always controlled by settings but this\ncommit adds the setting to the ci-script so that it\ncan be changed per job without adjusting the settings.\n\nThere is a need to run most jobs with an already\nuploaded image but to run a periodic job to upload new images.\n\nChange-Id: Ie7c113b18f8850328f92fadb6a960074df4fb470\n'}, {'number': 2, 'created': '2016-08-22 14:20:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/11605c435604f0b40c7fee6444a261677c72341e', 'message': 'Adds option to ci-script to mange image in OVB\n\nThe OVB code offers two options:\n - to use an image already exsiting in the hosr cloud\n - to upload a new image\nThis option was always controlled by settings but this\ncommit adds the setting to the ci-script so that it\ncan be changed per job without adjusting the settings.\n\nThere is a need to run most jobs with an already\nuploaded image but to run a periodic job to upload new images.\n\nChange-Id: Ie7c113b18f8850328f92fadb6a960074df4fb470\n'}, {'number': 3, 'created': '2016-08-22 14:32:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/03266dfb53d0feab1cfca2f954488c2f182e51e6', 'message': 'Adds option to ci-script to mange image in OVB\n\nThe OVB code offers two options:\n - to use an image already exsiting in the hosr cloud\n - to upload a new image\nThis option was always controlled by settings but this\ncommit adds the setting to the ci-script so that it\ncan be changed per job without adjusting the settings.\n\nThere is a need to run most jobs with an already\nuploaded image but to run a periodic job to upload new images.\n\nChange-Id: Ie7c113b18f8850328f92fadb6a960074df4fb470\n'}, {'number': 4, 'created': '2016-08-22 15:05:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/42c0170b705f211c70839e394c68bd38068d7c40', 'message': 'Adds option to ci-script to manage image in OVB\n\nThe OVB code offers two options:\n - to use an image already exsiting in the hosr cloud\n - to upload a new image\nThis option was always controlled by settings but this\ncommit adds the setting to the ci-script so that it\ncan be changed per job without adjusting the settings.\n\nThere is a need to run most jobs with an already\nuploaded image but to run a periodic job to upload new images.\n\nChange-Id: Ie7c113b18f8850328f92fadb6a960074df4fb470\n'}, {'number': 5, 'created': '2016-08-22 15:18:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/bb3539af95e0bc707736652b501fb88257d7531d', 'message': 'Add option to ci-script to manage image in OVB\n\nThe OVB code offers two options:\n - to use an image already exsiting in the hosr cloud\n - to upload a new image\nThis option was always controlled by settings but this\ncommit adds the setting to the ci-script so that it\ncan be changed per job without adjusting the settings.\n\nThere is a need to run most jobs with an already\nuploaded image but to run a periodic job to upload new images.\n\nChange-Id: Ie7c113b18f8850328f92fadb6a960074df4fb470\n'}, {'number': 6, 'created': '2016-08-24 16:12:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/ae01fd0818f3f0c4108f01a836cbcbd884c9081d', 'message': 'Add options to ci-script to manage images in OVB\n\nThe OVB code offers two options:\n - to use an image already exsiting in the host cloud\n - to upload a new image\nThis option was always controlled by settings but this\ncommit adds the setting to the ci-script so that it\ncan be changed per job without adjusting the settings.\n\nThere is a need to run most jobs with an already\nuploaded image but to run a periodic job to upload new images.\n\nAlso adds an option to the cleanup scripts as whether to\nremove the image from the host cloud.\n\nChange-Id: Ie7c113b18f8850328f92fadb6a960074df4fb470\n'}, {'number': 7, 'created': '2016-08-24 20:37:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/0ec5eaf133d1729229ff869367b6f902e7d44ef9', 'message': 'Add options to ci-script to manage images in OVB\n\nThe OVB code offers two options:\n - to use an image already exsiting in the host cloud\n - to upload a new image\nThis option was always controlled by settings but this\ncommit adds the setting to the ci-script so that it\ncan be changed per job without adjusting the settings.\n\nThere is a need to run most jobs with an already\nuploaded image but to run a periodic job to upload new images.\n\nAlso adds an option to the cleanup scripts as whether to\nremove the image from the host cloud.\n\nChange-Id: Ie7c113b18f8850328f92fadb6a960074df4fb470\n'}, {'number': 8, 'created': '2016-08-26 16:22:21.000000000', 'files': ['ci-scripts/ovb-image-upload.sh'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/1e6c98511d9154bfdc49a31fd26229953df0bd70', 'message': 'Add ci-script to upload images in OVB\n\nThe OVB code offers two options:\n - to use an image already exsiting in the host cloud\n - to upload a new image\n\nThere is a need to run most jobs with an already\nuploaded image but to run a periodic job to upload new images.\n\nChange-Id: Ie7c113b18f8850328f92fadb6a960074df4fb470\n'}]",4,355476,1e6c98511d9154bfdc49a31fd26229953df0bd70,38,9,8,9976,,,0,"Add ci-script to upload images in OVB

The OVB code offers two options:
 - to use an image already exsiting in the host cloud
 - to upload a new image

There is a need to run most jobs with an already
uploaded image but to run a periodic job to upload new images.

Change-Id: Ie7c113b18f8850328f92fadb6a960074df4fb470
",git fetch https://review.opendev.org/openstack/tripleo-quickstart refs/changes/76/355476/8 && git format-patch -1 --stdout FETCH_HEAD,['ci-scripts/full-deploy-ovb.sh'],1,7a6287d791b0a4f0adb08f3f838b06ef80c8724b,add-ovb-image-option,# $GET_IMAGE defaults to 'use_existing'.# <playbook> \ # <get_image>GET_IMAGE=$9--get_latest_image ${GET_IMAGE:-'upload'} \,# <playbook>,5,1
openstack%2Fsenlin~master~I774938f5f88932983656e4df64de07f4f26a1880,openstack/senlin,master,I774938f5f88932983656e4df64de07f4f26a1880,Fix oslo.i18n in senlin project,MERGED,2016-08-29 12:18:12.000000000,2016-08-29 13:51:34.000000000,2016-08-29 13:51:34.000000000,"[{'_account_id': 3}, {'_account_id': 8246}]","[{'number': 1, 'created': '2016-08-29 12:18:12.000000000', 'files': ['senlin/tests/tempest/config.py'], 'web_link': 'https://opendev.org/openstack/senlin/commit/36824064dfb24fd502abab43464ba314a07dce3b', 'message': 'Fix oslo.i18n in senlin project\n\nHelp messages and output info should support oslo.i18n.\n\nChange-Id: I774938f5f88932983656e4df64de07f4f26a1880\n'}]",0,362064,36824064dfb24fd502abab43464ba314a07dce3b,6,2,1,22132,,,0,"Fix oslo.i18n in senlin project

Help messages and output info should support oslo.i18n.

Change-Id: I774938f5f88932983656e4df64de07f4f26a1880
",git fetch https://review.opendev.org/openstack/senlin refs/changes/64/362064/1 && git format-patch -1 --stdout FETCH_HEAD,['senlin/tests/tempest/config.py'],1,36824064dfb24fd502abab43464ba314a07dce3b,fix_oslo.i18n,"from senlin.common.i18n import _ help=_(""Whether or not senlin is expected to be available"")), help=_(""Catalog type of the clustering service."")), help=_(""Waiting time for a specific status, in seconds.""))"," help=""Whether or not senlin is expected to be available""), help=""Catalog type of the clustering service.""), help=""Waiting time for a specific status, in seconds."")",4,4
openstack%2Fkuryr-kubernetes~master~I7e52aef8fb2767dcc46317f2212f4285a17b11da,openstack/kuryr-kubernetes,master,I7e52aef8fb2767dcc46317f2212f4285a17b11da,Introduce `kuryr-k8s` service,MERGED,2016-08-24 11:33:55.000000000,2016-08-29 13:48:30.000000000,2016-08-29 13:43:22.000000000,"[{'_account_id': 3}, {'_account_id': 6598}, {'_account_id': 7505}, {'_account_id': 9820}, {'_account_id': 14352}, {'_account_id': 15967}, {'_account_id': 23291}]","[{'number': 1, 'created': '2016-08-24 11:33:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/9c0a892fabd49f6be08a1a6262f9f8b24fe12782', 'message': 'Introduce `kuryr-k8s` service\n\nThis commit introduces the `kuryr-k8s` service by adding the service\nbinary and focusing on loading configuration options.\n\nThe configuration options are inherited from kuryr-lib project\n(http://github.com/openstack/kuryr) and loaded at runtime, together with\nthe project ones.\n\nThese configuration options can be also generated using the\n`oslo-config-generator` utility by using:\n\n    tox -e genconfig\n\nThe service runs as any other OpenStack-based service:\n\n    kuryr-k8s [--debug] [--config-file foo] ...\n\nChange-Id: I7e52aef8fb2767dcc46317f2212f4285a17b11da\nSigned-off-by: Jaume Devesa <devvesa@gmail.com>\nCo-Authored-By: Taku Fukushima <f.tac.mac@gmail.com>\n'}, {'number': 2, 'created': '2016-08-24 13:36:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/171229518260c482f7b56c38ed415ec0ea258074', 'message': 'Introduce `kuryr-k8s` service\n\nThis commit introduces the `kuryr-k8s` service by adding the service\nbinary and focusing on loading configuration options.\n\nThe configuration options are inherited from kuryr-lib project\n(http://github.com/openstack/kuryr) and loaded at runtime, together with\nthe project ones.\n\nThese configuration options can be also generated using the\n`oslo-config-generator` utility by using:\n\n    tox -e genconfig\n\nThe service runs as any other OpenStack-based service:\n\n    kuryr-k8s [--debug] [--config-file foo] ...\n\nChange-Id: I7e52aef8fb2767dcc46317f2212f4285a17b11da\nSigned-off-by: Jaume Devesa <devvesa@gmail.com>\nCo-Authored-By: Taku Fukushima <f.tac.mac@gmail.com>\n'}, {'number': 3, 'created': '2016-08-24 13:59:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/ec46ce00f539cc98adb8432010c504138d381e63', 'message': 'Introduce `kuryr-k8s` service\n\nThis commit introduces the `kuryr-k8s` service by adding the service\nbinary and focusing on loading configuration options.\n\nThe configuration options are inherited from kuryr-lib project\n(http://github.com/openstack/kuryr) and loaded at runtime, together with\nthe project ones.\n\nThese configuration options can be also generated using the\n`oslo-config-generator` utility by using:\n\n    tox -e genconfig\n\nThe service runs as any other OpenStack-based service:\n\n    kuryr-k8s [--debug] [--config-file foo] ...\n\nChange-Id: I7e52aef8fb2767dcc46317f2212f4285a17b11da\nSigned-off-by: Jaume Devesa <devvesa@gmail.com>\nCo-Authored-By: Taku Fukushima <f.tac.mac@gmail.com>\n'}, {'number': 4, 'created': '2016-08-25 09:39:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/2743e1d5a7f650696718ac85b454a861ec40ab30', 'message': 'Introduce `kuryr-k8s` service\n\nThis commit introduces the `kuryr-k8s` service by adding the service\nbinary and focusing on loading configuration options.\n\nThe configuration options are inherited from kuryr-lib project\n(http://github.com/openstack/kuryr) and loaded at runtime, together with\nthe project ones.\n\nThese configuration options can be also generated using the\n`oslo-config-generator` utility by using:\n\n    tox -e genconfig\n\nThe service runs as any other OpenStack-based service:\n\n    kuryr-k8s [--debug] [--config-file foo] ...\n\nChange-Id: I7e52aef8fb2767dcc46317f2212f4285a17b11da\nSigned-off-by: Jaume Devesa <devvesa@gmail.com>\nCo-Authored-By: Taku Fukushima <f.tac.mac@gmail.com>\n'}, {'number': 5, 'created': '2016-08-25 10:13:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/fa04d4e3a1903c8884d1d857f7291a16d4eb2f98', 'message': 'Introduce `kuryr-k8s` service\n\nThis commit introduces the `kuryr-k8s` service by adding the service\nbinary and focusing on loading configuration options.\n\nThe configuration options are inherited from kuryr-lib project\n(http://github.com/openstack/kuryr) and loaded at runtime, together with\nthe project ones.\n\nThese configuration options can be also generated using the\n`oslo-config-generator` utility by using:\n\n    tox -e genconfig\n\nThe service runs as any other OpenStack-based service:\n\n    kuryr-k8s [--debug] [--config-file foo] ...\n\nChange-Id: I7e52aef8fb2767dcc46317f2212f4285a17b11da\nSigned-off-by: Jaume Devesa <devvesa@gmail.com>\nCo-Authored-By: Taku Fukushima <f.tac.mac@gmail.com>\n'}, {'number': 6, 'created': '2016-08-25 12:10:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/ed322f720fddc1fb7a6f57f267c411836e815014', 'message': 'Introduce `kuryr-k8s` service\n\nThis commit introduces the `kuryr-k8s` service by adding the service\nbinary and focusing on loading configuration options.\n\nThe configuration options are inherited from kuryr-lib project\n(http://github.com/openstack/kuryr) and loaded at runtime, together with\nthe project ones.\n\nThese configuration options can be also generated using the\n`oslo-config-generator` utility by using:\n\n    tox -e genconfig\n\nThe service runs as any other OpenStack-based service:\n\n    kuryr-k8s [--debug] [--config-file foo] ...\n\nPartial-Implements: blueprint kuryr-k8s-integration\nChange-Id: I7e52aef8fb2767dcc46317f2212f4285a17b11da\nSigned-off-by: Jaume Devesa <devvesa@gmail.com>\nCo-Authored-By: Taku Fukushima <f.tac.mac@gmail.com>\n'}, {'number': 7, 'created': '2016-08-29 09:03:38.000000000', 'files': ['requirements.txt', '.gitignore', 'etc/kuryr-k8s-config-generator.conf', 'kuryr_kubernetes/opts.py', 'kuryr_kubernetes/server.py', 'etc/README-config.txt', 'kuryr_kubernetes/config.py', 'setup.cfg', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/86e35666c4d523352d6b55412a2536738b4f867b', 'message': 'Introduce `kuryr-k8s` service\n\nThis commit introduces the `kuryr-k8s` service by adding the service\nbinary and focusing on loading configuration options.\n\nThe configuration options are inherited from kuryr-lib project\n(http://github.com/openstack/kuryr) and loaded at runtime, together with\nthe project ones.\n\nThese configuration options can be also generated using the\n`oslo-config-generator` utility by using:\n\n    tox -e genconfig\n\nThe service runs as any other OpenStack-based service:\n\n    kuryr-k8s [--debug] [--config-file foo] ...\n\nPartial-Implements: blueprint kuryr-k8s-integration\nChange-Id: I7e52aef8fb2767dcc46317f2212f4285a17b11da\nSigned-off-by: Jaume Devesa <devvesa@gmail.com>\nCo-Authored-By: Taku Fukushima <f.tac.mac@gmail.com>\n'}]",30,359811,86e35666c4d523352d6b55412a2536738b4f867b,41,7,7,7505,,,0,"Introduce `kuryr-k8s` service

This commit introduces the `kuryr-k8s` service by adding the service
binary and focusing on loading configuration options.

The configuration options are inherited from kuryr-lib project
(http://github.com/openstack/kuryr) and loaded at runtime, together with
the project ones.

These configuration options can be also generated using the
`oslo-config-generator` utility by using:

    tox -e genconfig

The service runs as any other OpenStack-based service:

    kuryr-k8s [--debug] [--config-file foo] ...

Partial-Implements: blueprint kuryr-k8s-integration
Change-Id: I7e52aef8fb2767dcc46317f2212f4285a17b11da
Signed-off-by: Jaume Devesa <devvesa@gmail.com>
Co-Authored-By: Taku Fukushima <f.tac.mac@gmail.com>
",git fetch https://review.opendev.org/openstack/kuryr-kubernetes refs/changes/11/359811/1 && git format-patch -1 --stdout FETCH_HEAD,"['kuryr_kubernetes/common/__init__.py', 'requirements.txt', '.gitignore', 'etc/kuryr-k8s-config-generator.conf', 'kuryr_kubernetes/opts.py', 'etc/README-config.txt', 'kuryr_kubernetes/server.py', 'kuryr_kubernetes/common/config.py', 'setup.cfg', 'tox.ini']",10,9c0a892fabd49f6be08a1a6262f9f8b24fe12782,bp/kuryr-k8s-integration,commands = oslo-config-generator --config-file=etc/kuryr-k8s-config-generator.conf,commands = oslo-config-generator --config-file=etc/kuryr-config-generator.conf,174,19
openstack%2Fpuppet-congress~master~Ie30393e00dc37fddfaffad1159e6789c87b019ac,openstack/puppet-congress,master,Ie30393e00dc37fddfaffad1159e6789c87b019ac,Fix authtoken,MERGED,2016-08-27 03:39:55.000000000,2016-08-29 13:45:40.000000000,2016-08-29 13:45:40.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 7732}, {'_account_id': 23294}]","[{'number': 1, 'created': '2016-08-27 03:39:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-congress/commit/ba0b4ce102d07b3824e2e0fc5234cb8ccb7816e5', 'message': 'Fix authtoken\n\n- Fix doc in authtoken class\n- Fix metadata dependencies\n\nChange-Id: Ie30393e00dc37fddfaffad1159e6789c87b019ac\n'}, {'number': 2, 'created': '2016-08-27 03:50:56.000000000', 'files': ['metadata.json', 'manifests/keystone/authtoken.pp'], 'web_link': 'https://opendev.org/openstack/puppet-congress/commit/c54f274d62e4b1afd609ad2a47ab3b0b15d27926', 'message': 'Fix authtoken\n\n- Fix doc in authtoken class\n- Fix metadata dependencies\n\nChange-Id: Ie30393e00dc37fddfaffad1159e6789c87b019ac\n'}]",0,361547,c54f274d62e4b1afd609ad2a47ab3b0b15d27926,10,4,2,15519,,,0,"Fix authtoken

- Fix doc in authtoken class
- Fix metadata dependencies

Change-Id: Ie30393e00dc37fddfaffad1159e6789c87b019ac
",git fetch https://review.opendev.org/openstack/puppet-congress refs/changes/47/361547/1 && git format-patch -1 --stdout FETCH_HEAD,"['metadata.json', 'manifests/keystone/authtoken.pp']",2,ba0b4ce102d07b3824e2e0fc5234cb8ccb7816e5,fix_authtoken,"# (Optional) If true, explicitly allow TLS without checking server cert # against any certificate authorities. WARNING: not recommended. Use with # caution. # Defaults to $::os_service_default# (Optional) Config Section from which to load plugin specific options # Defaults to $::os_service_default.# (Optional) Authentication type to load # Defaults to 'password'# (Optional) Complete public Identity API endpoint. # Defaults to 'http://localhost:5000'.# (Optional) API version of the admin Identity API endpoint. # Defaults to $::os_service_default.# (Optional) Env key for the swift cache. # Defaults to $::os_service_default.# (Optional) A PEM encoded Certificate Authority to use when verifying HTTPs # connections. # Defaults to $::os_service_default.# (Optional) Required if identity server requires client certificate # Defaults to $::os_service_default.# (Optional) If true, the revocation list will be checked for cached tokens. # This requires that PKI tokens are configured on the identity server. # boolean value. # Defaults to $::os_service_default.# (Optional) Do not handle authorization requests within the middleware, but # delegate the authorization decision to downstream WSGI components. Boolean # value # Defaults to $::os_service_default.# (Optional) Used to control the use and type of token binding. Can be set # to: ""disabled"" to not check token binding. ""permissive"" (default) to # validate binding information if the bind type is of a form known to the # server and ignore it if not. ""strict"" like ""permissive"" but if the bind # type is unknown the token will be rejected. ""required"" any form of token # binding is needed to be allowed. Finally the name of a binding method that # must be present in tokens. String value. # Defaults to $::os_service_default.# (Optional) Hash algorithms to use for hashing PKI tokens. This may be a # single algorithm or multiple. The algorithms are those supported by Python # standard hashlib.new(). The hashes will be tried in the order given, so put # the preferred one first for performance. The result of the first hash will # be stored in the cache. This will typically be set to multiple values only # while migrating from a less secure algorithm to a more secure one. Once all # the old tokens are expired this option should be set to a single value for # better performance. List value. # Defaults to $::os_service_default.# (Optional) Request timeout value for communicating with Identity API # server. # Defaults to $::os_service_default.# (Optional) How many times are we trying to reconnect when communicating # with Identity API Server. Integer value # Defaults to $::os_service_default.# (Optional) Indicate whether to set the X-Service-Catalog header. If False, # middleware will not ask for service catalog on token validation and will # not set the X-Service-Catalog header. Boolean value. # Defaults to $::os_service_default.# (Optional) Required if identity server requires client certificate # Defaults to $::os_service_default.# (Optional) Number of seconds that an operation will wait to get a memcached # client connection from the pool. Integer value # Defaults to $::os_service_default.# (Optional) Number of seconds memcached server is considered dead before it # is tried again. Integer value # Defaults to $::os_service_default.# (Optional) Maximum total number of open connections to every memcached # server. Integer value # Defaults to $::os_service_default.# (Optional) Number of seconds a connection to memcached is held unused in # the pool before it is closed. Integer value # Defaults to $::os_service_default.# (Optional) Number of seconds a connection to memcached is held unused in # the pool before it is closed. Integer value # Defaults to $::os_service_default.# (Optional, mandatory if memcache_security_strategy is defined) This string # is used for key derivation. # Defaults to $::os_service_default.# or authenticated and encrypted. If MAC, token data is authenticated (with # HMAC) in the cache. If ENCRYPT, token data is encrypted and authenticated in the # cache. If the value is not one of these options or empty, auth_token will # raise an exception on initialization. # Defaults to $::os_service_default.# (Optional) Use the advanced (eventlet safe) memcached client pool. The # advanced pool will only work under python 2.x Boolean value # Defaults to $::os_service_default.# (Optional) Optionally specify a list of memcached server(s) to use for # caching. If left undefined, tokens will instead be cached in-process. # Defaults to $::os_service_default.# (Optional) The region in which the identity server can be found. # Defaults to $::os_service_default.# (Optional) Determines the frequency at which the list of revoked tokens is # retrieved from the Identity service (in seconds). A high number of # revocation events combined with a low cache duration may significantly # reduce performance. Only valid for PKI tokens. Integer value # Defaults to $::os_service_default.# (Optional) Directory used to cache files related to PKI tokens. # Defaults to $::os_service_default.# (Optional) In order to prevent excessive effort spent validating tokens, # the middleware caches previously-seen tokens for a configurable duration # (in seconds). Set to -1 to disable caching completely. Integer value # Defaults to $::os_service_default.","# (Optional) If true, explicitly allow TLS without checking server cert # against any certificate authorities. WARNING: not recommended. Use with # caution. # Defaults to $::os_service_default# (Optional) Config Section from which to load plugin specific options # Defaults to $::os_service_default.# (Optional) Authentication type to load # Defaults to 'password'# (Optional) Complete public Identity API endpoint. # Defaults to 'http://localhost:5000'.# (Optional) API version of the admin Identity API endpoint. # Defaults to $::os_service_default.# (Optional) Env key for the swift cache. # Defaults to $::os_service_default.# (Optional) A PEM encoded Certificate Authority to use when verifying HTTPs # connections. # Defaults to $::os_service_default.# (Optional) Required if identity server requires client certificate # Defaults to $::os_service_default.# (Optional) If true, the revocation list will be checked for cached tokens. # This requires that PKI tokens are configured on the identity server. # boolean value. # Defaults to $::os_service_default.# (Optional) Do not handle authorization requests within the middleware, but # delegate the authorization decision to downstream WSGI components. Boolean # value # Defaults to $::os_service_default.# (Optional) Used to control the use and type of token binding. Can be set # to: ""disabled"" to not check token binding. ""permissive"" (default) to # validate binding information if the bind type is of a form known to the # server and ignore it if not. ""strict"" like ""permissive"" but if the bind # type is unknown the token will be rejected. ""required"" any form of token # binding is needed to be allowed. Finally the name of a binding method that # must be present in tokens. String value. # Defaults to $::os_service_default.# (Optional) Hash algorithms to use for hashing PKI tokens. This may be a # single algorithm or multiple. The algorithms are those supported by Python # standard hashlib.new(). The hashes will be tried in the order given, so put # the preferred one first for performance. The result of the first hash will # be stored in the cache. This will typically be set to multiple values only # while migrating from a less secure algorithm to a more secure one. Once all # the old tokens are expired this option should be set to a single value for # better performance. List value. # Defaults to $::os_service_default.# (Optional) Request timeout value for communicating with Identity API # server. # Defaults to $::os_service_default.# (Optional) How many times are we trying to reconnect when communicating # with Identity API Server. Integer value # Defaults to $::os_service_default.# (Optional) Indicate whether to set the X-Service-Catalog header. If False, # middleware will not ask for service catalog on token validation and will # not # set the X-Service-Catalog header. Boolean value. # Defaults to $::os_service_default.# (Optional) Required if identity server requires client certificate # Defaults to $::os_service_default.# (Optional) Number of seconds that an operation will wait to get a memcached # client connection from the pool. Integer value # Defaults to $::os_service_default.# (Optional) Number of seconds memcached server is considered dead before it # is tried again. Integer value # Defaults to $::os_service_default.# (Optional) Maximum total number of open connections to every memcached # server. Integer value # Defaults to $::os_service_default.# (Optional) Number of seconds a connection to memcached is held unused in # the # pool before it is closed. Integer value # Defaults to $::os_service_default.# (Optional) Number of seconds a connection to memcached is held unused in # the # pool before it is closed. Integer value # Defaults to $::os_service_default.# (Optional, mandatory if memcache_security_strategy is defined) This string # is used for key derivation. # Defaults to $::os_service_default.# or # authenticated and encrypted. If MAC, token data is authenticated (with # HMAC) # in the cache. If ENCRYPT, token data is encrypted and authenticated in the # cache. If the value is not one of these options or empty, auth_token will # raise an exception on initialization. # Defaults to $::os_service_default.# (Optional) Use the advanced (eventlet safe) memcached client pool. The # advanced pool will only work under python 2.x Boolean value # Defaults to $::os_service_default.# (Optional) Optionally specify a list of memcached server(s) to use for # caching. If left undefined, tokens will instead be cached in-process. # Defaults to $::os_service_default.# (Optional) The region in which the identity server can be found. # Defaults to $::os_service_default.# (Optional) Determines the frequency at which the list of revoked tokens is # retrieved from the Identity service (in seconds). A high number of # revocation events combined with a low cache duration may significantly # reduce performance. Only valid for PKI tokens. Integer value # Defaults to $::os_service_default.# (Optional) Directory used to cache files related to PKI tokens. # Defaults to $::os_service_default.# (Optional) In order to prevent excessive effort spent validating tokens, # the middleware caches previously-seen tokens for a configurable duration # (in seconds). Set to -1 to disable caching completely. Integer value # Defaults to $::os_service_default.",101,105
openstack%2Fopenstack-ansible-security~master~I60aa62ff688d32c14031773d35af29b3cf6b6fd6,openstack/openstack-ansible-security,master,I60aa62ff688d32c14031773d35af29b3cf6b6fd6,Remove extra AIDE tasks,MERGED,2016-08-26 20:44:42.000000000,2016-08-29 13:43:57.000000000,2016-08-29 13:43:57.000000000,"[{'_account_id': 3}, {'_account_id': 6816}, {'_account_id': 7353}]","[{'number': 1, 'created': '2016-08-26 20:44:42.000000000', 'files': ['tasks/misc.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-security/commit/1fdd5b41f1eb99df1d1de436fa98ee1d72407e1f', 'message': ""Remove extra AIDE tasks\n\nThe AIDE tasks were copied to aide.yml in\nchange I85d65738fde064b06b1147c529b22c3f44a33e94, but they\nweren't removed from misc.yml. This patch cleans up misc.yml.\n\nChange-Id: I60aa62ff688d32c14031773d35af29b3cf6b6fd6\n""}]",0,361460,1fdd5b41f1eb99df1d1de436fa98ee1d72407e1f,7,3,1,538,,,0,"Remove extra AIDE tasks

The AIDE tasks were copied to aide.yml in
change I85d65738fde064b06b1147c529b22c3f44a33e94, but they
weren't removed from misc.yml. This patch cleans up misc.yml.

Change-Id: I60aa62ff688d32c14031773d35af29b3cf6b6fd6
",git fetch https://review.opendev.org/openstack/openstack-ansible-security refs/changes/60/361460/1 && git format-patch -1 --stdout FETCH_HEAD,['tasks/misc.yml'],1,1fdd5b41f1eb99df1d1de436fa98ee1d72407e1f,remove-extra-aide,,"- name: V-38489 - Install AIDE (with apt) apt: name: ""{{ item }}"" state: ""{{ security_package_state }}"" with_items: - aide - aide-common when: ansible_pkg_mgr == 'apt' tags: - cat2 - V-38489 - name: V-38489 - Install AIDE (with yum) yum: name: aide state: ""{{ security_package_state }}"" when: ansible_pkg_mgr == 'yum' tags: - cat2 - V-38489 - name: Verify that AIDE configuration directory exists stat: path: /etc/aide/aide.conf.d register: aide_conf always_run: true tags: - always - name: V-38489 - Exclude certain directories from AIDE template: src: ZZ_aide_exclusions.j2 dest: /etc/aide/aide.conf.d/ZZ_aide_exclusions when: aide_conf.stat.exists | bool tags: - cat2 - V-38489 - name: Check to see if AIDE database is already in place stat: path: ""{{ aide_database_file }}"" register: aide_database always_run: True tags: - always - name: V-38489 - Initialize AIDE (this will take a few minutes) shell: ""aideinit"" register: aide_init when: - aide_conf.stat.exists | bool - not aide_database.stat.exists | bool - security_initialize_aide | bool tags: - cat2 - V-38489 - name: V-38489 - Move AIDE database into place shell: ""mv /var/lib/aide/aide.db.new.gz {{ aide_database_file }}"" when: - aide_init | changed - ansible_os_family == 'RedHat' tags: - cat2 - V-38489 - name: Create AIDE cron job (for V-38670) cron: name: aide cron_file: aide user: root special_time: daily job: ""aide --check"" when: - ansible_os_family == 'RedHat' tags: - cat2 - V-38670 - name: Check for AIDE cron job (for V-38670) stat: path: ""{{ aide_cron_job_path }}"" register: v38670_result changed_when: False tags: - cat2 - V-38670 ",0,88
openstack%2Fneutron-fwaas~master~I9a64db228bcd9313c04d238c39ae1c53be89e339,openstack/neutron-fwaas,master,I9a64db228bcd9313c04d238c39ae1c53be89e339,Remove vendor driver: vyatta from community repo,MERGED,2016-08-26 16:32:02.000000000,2016-08-29 13:43:50.000000000,2016-08-29 13:43:50.000000000,"[{'_account_id': 3}, {'_account_id': 6995}, {'_account_id': 10182}, {'_account_id': 10850}, {'_account_id': 13702}, {'_account_id': 13995}]","[{'number': 1, 'created': '2016-08-26 16:32:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-fwaas/commit/5e5b4aca71d7d25e592e2a25d581944031f43c93', 'message': 'Remove vendor driver: vyatta from community repo\n\nVendor drivers are being removed from the community repo and\nthey can continue to be hosted in respective vendor repos. This\nhas been discussed and communicated during the Mitaka release\nand time given until the Newton release.\n\nChange-Id: I9a64db228bcd9313c04d238c39ae1c53be89e339\n'}, {'number': 2, 'created': '2016-08-29 05:23:06.000000000', 'files': ['neutron_fwaas/services/firewall/agents/vyatta/firewall_service.py', 'neutron_fwaas/services/firewall/agents/vyatta/fwaas_agent.py', 'neutron_fwaas/tests/unit/services/firewall/agents/vyatta/__init__.py', 'neutron_fwaas/services/firewall/agents/vyatta/vyatta_utils.py', 'neutron_fwaas/tests/unit/services/firewall/drivers/vyatta/__init__.py', 'neutron_fwaas/tests/unit/services/firewall/agents/vyatta/test_vyatta_utils.py', 'releasenotes/notes/vyatta-fwaas-driver-removal-e38e6ecde5105084.yaml', 'neutron_fwaas/services/firewall/drivers/vyatta/vyatta_fwaas.py', 'neutron_fwaas/services/firewall/agents/vyatta/__init__.py', 'neutron_fwaas/tests/unit/services/firewall/agents/vyatta/test_firewall_service.py', 'neutron_fwaas/services/firewall/drivers/vyatta/__init__.py', 'neutron_fwaas/tests/unit/services/firewall/drivers/vyatta/test_vyatta_fwaas.py', 'neutron_fwaas/services/firewall/drivers/vyatta/README.rst'], 'web_link': 'https://opendev.org/openstack/neutron-fwaas/commit/f6aed8b66ac33fdbed60925567fe5d02ba3bad29', 'message': 'Remove vendor driver: vyatta from community repo\n\nVendor drivers are being removed from the community repo and\nthey can continue to be hosted in respective vendor repos. This\nhas been discussed and communicated during the Mitaka release\nand time given until the Newton release.\n\nChange-Id: I9a64db228bcd9313c04d238c39ae1c53be89e339\n'}]",0,361354,f6aed8b66ac33fdbed60925567fe5d02ba3bad29,10,6,2,6995,,,0,"Remove vendor driver: vyatta from community repo

Vendor drivers are being removed from the community repo and
they can continue to be hosted in respective vendor repos. This
has been discussed and communicated during the Mitaka release
and time given until the Newton release.

Change-Id: I9a64db228bcd9313c04d238c39ae1c53be89e339
",git fetch https://review.opendev.org/openstack/neutron-fwaas refs/changes/54/361354/2 && git format-patch -1 --stdout FETCH_HEAD,"['neutron_fwaas/services/firewall/agents/vyatta/firewall_service.py', 'neutron_fwaas/services/firewall/agents/vyatta/fwaas_agent.py', 'neutron_fwaas/services/firewall/drivers/fwaas_base_v2.py', 'neutron_fwaas/tests/unit/services/firewall/agents/vyatta/__init__.py', 'neutron_fwaas/services/firewall/agents/vyatta/vyatta_utils.py', 'neutron_fwaas/services/firewall/drivers/varmour/__init__.py', 'neutron_fwaas/services/firewall/drivers/cisco/__init__.py', 'neutron_fwaas/services/firewall/drivers/cisco/csr_acl_driver.py', 'neutron_fwaas/services/firewall/drivers/linux/iptables_fwaas.py', 'neutron_fwaas/services/firewall/agents/vyatta/__init__.py', 'neutron_fwaas/tests/unit/services/firewall/agents/vyatta/test_firewall_service.py', 'neutron_fwaas/services/firewall/drivers/vyatta/__init__.py', 'neutron_fwaas/tests/unit/services/firewall/drivers/vyatta/test_vyatta_fwaas.py', 'neutron_fwaas/services/firewall/drivers/__init__.py', 'neutron_fwaas/services/firewall/drivers/cisco/csr_firewall_svc_helper.py', 'neutron_fwaas/tests/unit/services/firewall/drivers/vyatta/__init__.py', 'neutron_fwaas/tests/unit/services/firewall/agents/vyatta/test_vyatta_utils.py', 'releasenotes/notes/vyatta-fwaas-driver-removal-e38e6ecde5105084.yaml', 'neutron_fwaas/services/firewall/drivers/linux/iptables_fwaas_v2.py', 'neutron_fwaas/services/firewall/drivers/linux/__init__.py', 'neutron_fwaas/services/firewall/drivers/vyatta/vyatta_fwaas.py', 'neutron_fwaas/services/firewall/drivers/varmour/varmour_fwaas.py', 'neutron_fwaas/services/firewall/drivers/fwaas_base.py', 'neutron_fwaas/services/firewall/drivers/vyatta/README.rst']",24,5e5b4aca71d7d25e592e2a25d581944031f43c93,vyatta,,"Brocade Firewall as a Service Driver * For more information, refer to: https://wiki.openstack.org/wiki/Brocade_Vyatta_Firewall_driver * For information on Brocade Vyatta CI, refer to: https://wiki.openstack.org/wiki/ThirdPartySystems/Brocade_Vyatta_CI * Brocade Vyatta CI contact: - DL-GRP-VYATTA-OSS@Brocade.com - vjayara@Brocade.com ",7,2752
openstack%2Fpuppet-openstack-cookiecutter~master~Icb1b9551a73d2d5d895e121422ccf87cadcf30e2,openstack/puppet-openstack-cookiecutter,master,Icb1b9551a73d2d5d895e121422ccf87cadcf30e2,Fix authtoken,MERGED,2016-08-27 05:44:21.000000000,2016-08-29 13:43:40.000000000,2016-08-29 13:43:40.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 7745}]","[{'number': 1, 'created': '2016-08-27 05:44:21.000000000', 'files': ['puppet-{{cookiecutter.project_name}}/metadata.json', 'puppet-{{cookiecutter.project_name}}/manifests/keystone/authtoken.pp'], 'web_link': 'https://opendev.org/openstack/puppet-openstack-cookiecutter/commit/c9943227cb4ee487199f1180884f29271ac57228', 'message': 'Fix authtoken\n\n- Fix documentation in class\n- Fix metadata dependencies\n\nChange-Id: Icb1b9551a73d2d5d895e121422ccf87cadcf30e2\n'}]",0,361559,c9943227cb4ee487199f1180884f29271ac57228,7,3,1,15519,,,0,"Fix authtoken

- Fix documentation in class
- Fix metadata dependencies

Change-Id: Icb1b9551a73d2d5d895e121422ccf87cadcf30e2
",git fetch https://review.opendev.org/openstack/puppet-openstack-cookiecutter refs/changes/59/361559/1 && git format-patch -1 --stdout FETCH_HEAD,"['puppet-{{cookiecutter.project_name}}/metadata.json', 'puppet-{{cookiecutter.project_name}}/manifests/keystone/authtoken.pp']",2,c9943227cb4ee487199f1180884f29271ac57228,fix_authtoken,"# (Optional) If true, explicitly allow TLS without checking server cert # against any certificate authorities. WARNING: not recommended. Use with # caution. # Defaults to $:os_service_default# (Optional) Config Section from which to load plugin specific options # Defaults to $::os_service_default.# (Optional) Authentication type to load # Defaults to 'password'.# (Optional) Complete public Identity API endpoint. # Defaults to 'http://localhost:5000'.# (Optional) API version of the admin Identity API endpoint. # Defaults to $::os_service_default.# (Optional) Env key for the swift cache. # Defaults to $::os_service_default.# (Optional) A PEM encoded Certificate Authority to use when verifying HTTPs # connections. # Defaults to $::os_service_default.# (Optional) Required if identity server requires client certificate # Defaults to $::os_service_default.# (Optional) If true, the revocation list will be checked for cached tokens. # This requires that PKI tokens are configured on the identity server. # boolean value. # Defaults to $::os_service_default.# (Optional) Do not handle authorization requests within the middleware, but # delegate the authorization decision to downstream WSGI components. Boolean # value # Defaults to $::os_service_default.# (Optional) Used to control the use and type of token binding. Can be set # to: ""disabled"" to not check token binding. ""permissive"" (default) to # validate binding information if the bind type is of a form known to the # server and ignore it if not. ""strict"" like ""permissive"" but if the bind # type is unknown the token will be rejected. ""required"" any form of token # binding is needed to be allowed. Finally the name of a binding method that # must be present in tokens. String value. # Defaults to $::os_service_default.# (Optional) Hash algorithms to use for hashing PKI tokens. This may be a # single algorithm or multiple. The algorithms are those supported by Python # standard hashlib.new(). The hashes will be tried in the order given, so put # the preferred one first for performance. The result of the first hash will # be stored in the cache. This will typically be set to multiple values only # while migrating from a less secure algorithm to a more secure one. Once all # the old tokens are expired this option should be set to a single value for # better performance. List value. # Defaults to $::os_service_default.# (Optional) Request timeout value for communicating with Identity API # server. # Defaults to $::os_service_default.# (Optional) How many times are we trying to reconnect when communicating # with Identity API Server. Integer value # Defaults to $::os_service_default.# (Optional) Indicate whether to set the X-Service-Catalog header. If False, # middleware will not ask for service catalog on token validation and will # not set the X-Service-Catalog header. Boolean value. # Defaults to $::os_service_default.# (Optional) Required if identity server requires client certificate # Defaults to $::os_service_default.# (Optional) Number of seconds that an operation will wait to get a memcached # client connection from the pool. Integer value # Defaults to $::os_service_default.# (Optional) Number of seconds memcached server is considered dead before it # is tried again. Integer value # Defaults to $::os_service_default.# (Optional) Maximum total number of open connections to every memcached # server. Integer value # Defaults to $::os_service_default.# (Optional) Number of seconds a connection to memcached is held unused in # the pool before it is closed. Integer value # Defaults to $::os_service_default.# (Optional) Number of seconds a connection to memcached is held unused in # the pool before it is closed. Integer value # Defaults to $::os_service_default.# (Optional, mandatory if memcache_security_strategy is defined) This string # is used for key derivation. # Defaults to $::os_service_default.# (Optional) If defined, indicate whether token data should be authenticated # or authenticated and encrypted. If MAC, token data is authenticated (with # HMAC) in the cache. If ENCRYPT, token data is encrypted and authenticated in the # cache. If the value is not one of these options or empty, auth_token will # raise an exception on initialization. # Defaults to $::os_service_default.# (Optional) Use the advanced (eventlet safe) memcached client pool. The # advanced pool will only work under python 2.x Boolean value # Defaults to $::os_service_default.# (Optional) Optionally specify a list of memcached server(s) to use for # caching. If left undefined, tokens will instead be cached in-process. # Defaults to $::os_service_default.# (Optional) The region in which the identity server can be found. # Defaults to $::os_service_default.# (Optional) Determines the frequency at which the list of revoked tokens is # retrieved from the Identity service (in seconds). A high number of # revocation events combined with a low cache duration may significantly # reduce performance. Only valid for PKI tokens. Integer value # Defaults to $::os_service_default.# (Optional) Directory used to cache files related to PKI tokens. # Defaults to $::os_service_default.# (Optional) In order to prevent excessive effort spent validating tokens, # the middleware caches previously-seen tokens for a configurable duration # (in seconds). Set to -1 to disable caching completely. Integer value # Defaults to $::os_service_default.","# (Optional) If true, explicitly allow TLS without checking server cert # against any certificate authorities. WARNING: not recommended. Use with # caution. # Defaults to $:os_service_default# (Optional) Config Section from which to load plugin specific options # Defaults to $::os_service_default.# (Optional) Authentication type to load # Defaults to 'password'.# (Optional) Complete public Identity API endpoint. # Defaults to 'http://localhost:5000'.# (Optional) API version of the admin Identity API endpoint. # Defaults to $::os_service_default.# (Optional) Env key for the swift cache. # Defaults to $::os_service_default.# (Optional) A PEM encoded Certificate Authority to use when verifying HTTPs # connections. # Defaults to $::os_service_default.# (Optional) Required if identity server requires client certificate # Defaults to $::os_service_default.# (Optional) If true, the revocation list will be checked for cached tokens. # This requires that PKI tokens are configured on the identity server. # boolean value. # Defaults to $::os_service_default.# (Optional) Do not handle authorization requests within the middleware, but # delegate the authorization decision to downstream WSGI components. Boolean # value # Defaults to $::os_service_default.# (Optional) Used to control the use and type of token binding. Can be set # to: ""disabled"" to not check token binding. ""permissive"" (default) to # validate binding information if the bind type is of a form known to the # server and ignore it if not. ""strict"" like ""permissive"" but if the bind # type is unknown the token will be rejected. ""required"" any form of token # binding is needed to be allowed. Finally the name of a binding method that # must be present in tokens. String value. # Defaults to $::os_service_default.# (Optional) Hash algorithms to use for hashing PKI tokens. This may be a # single algorithm or multiple. The algorithms are those supported by Python # standard hashlib.new(). The hashes will be tried in the order given, so put # the preferred one first for performance. The result of the first hash will # be stored in the cache. This will typically be set to multiple values only # while migrating from a less secure algorithm to a more secure one. Once all # the old tokens are expired this option should be set to a single value for # better performance. List value. # Defaults to $::os_service_default.# (Optional) Request timeout value for communicating with Identity API # server. # Defaults to $::os_service_default.# (Optional) How many times are we trying to reconnect when communicating # with Identity API Server. Integer value # Defaults to $::os_service_default.# (Optional) Indicate whether to set the X-Service-Catalog header. If False, # middleware will not ask for service catalog on token validation and will # not # set the X-Service-Catalog header. Boolean value. # Defaults to $::os_service_default.# (Optional) Required if identity server requires client certificate # Defaults to $::os_service_default.# (Optional) Number of seconds that an operation will wait to get a memcached # client connection from the pool. Integer value # Defaults to $::os_service_default.# (Optional) Number of seconds memcached server is considered dead before it # is tried again. Integer value # Defaults to $::os_service_default.# (Optional) Maximum total number of open connections to every memcached # server. Integer value # Defaults to $::os_service_default.# (Optional) Number of seconds a connection to memcached is held unused in # the # pool before it is closed. Integer value # Defaults to $::os_service_default.# (Optional) Number of seconds a connection to memcached is held unused in # the # pool before it is closed. Integer value # Defaults to $::os_service_default.# (Optional, mandatory if memcache_security_strategy is defined) This string # is used for key derivation. # Defaults to $::os_service_default.# (Optional) If defined, indicate whether token data should be authenticated # or # authenticated and encrypted. If MAC, token data is authenticated (with # HMAC) # in the cache. If ENCRYPT, token data is encrypted and authenticated in the # cache. If the value is not one of these options or empty, auth_token will # raise an exception on initialization. # Defaults to $::os_service_default.# (Optional) Use the advanced (eventlet safe) memcached client pool. The # advanced pool will only work under python 2.x Boolean value # Defaults to $::os_service_default.# (Optional) Optionally specify a list of memcached server(s) to use for # caching. If left undefined, tokens will instead be cached in-process. # Defaults to $::os_service_default.# (Optional) The region in which the identity server can be found. # Defaults to $::os_service_default.# (Optional) Determines the frequency at which the list of revoked tokens is # retrieved from the Identity service (in seconds). A high number of # revocation events combined with a low cache duration may significantly # reduce performance. Only valid for PKI tokens. Integer value # Defaults to $::os_service_default.# (Optional) Directory used to cache files related to PKI tokens. # Defaults to $::os_service_default.# (Optional) In order to prevent excessive effort spent validating tokens, # the middleware caches previously-seen tokens for a configurable duration # (in seconds). Set to -1 to disable caching completely. Integer value # Defaults to $::os_service_default.",102,107
openstack%2Fceilometer~master~I1cee3327b34f76c2773a11b926c79059e2a6cb13,openstack/ceilometer,master,I1cee3327b34f76c2773a11b926c79059e2a6cb13,Tests for inconsistency during pipeline processing,ABANDONED,2016-05-26 12:28:02.000000000,2016-08-29 13:40:30.000000000,,"[{'_account_id': 3}, {'_account_id': 6537}, {'_account_id': 15843}]","[{'number': 1, 'created': '2016-05-26 12:28:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/8d8f3a52bc90f0997a5e0fabf27c28f83338c0f8', 'message': 'Tests for inconsistency during pipeline processing\n\nThis tests show bug that described in https://bugs.launchpad.net/ceilometer/+bug/1586001\npipeline.yaml attached to bug description\n\nChange-Id: I1cee3327b34f76c2773a11b926c79059e2a6cb13\n'}, {'number': 2, 'created': '2016-05-26 12:35:07.000000000', 'files': ['etc/ceilometer/pipeline.yaml', 'ceilometer/tests/integration/gabbi/transform/create_instance.json', 'ceilometer/tests/integration/gabbi/transform/samples.yaml', 'ceilometer/tests/integration/gabbi/transform/transformation.yaml', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/7f5b4d6b1fbc5933c98ce6e200b7f320039fc31c', 'message': 'Tests for inconsistency during pipeline processing\n\nThis tests show bug that described in\nhttps://bugs.launchpad.net/ceilometer/+bug/1586001\npipeline.yaml attached to bug description\n\nThis patch done for demonstration of inconsistency during\npipeline processing, not for merge.\nChange-Id: I1cee3327b34f76c2773a11b926c79059e2a6cb13\n'}]",0,321509,7f5b4d6b1fbc5933c98ce6e200b7f320039fc31c,8,3,2,21356,,,0,"Tests for inconsistency during pipeline processing

This tests show bug that described in
https://bugs.launchpad.net/ceilometer/+bug/1586001
pipeline.yaml attached to bug description

This patch done for demonstration of inconsistency during
pipeline processing, not for merge.
Change-Id: I1cee3327b34f76c2773a11b926c79059e2a6cb13
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/09/321509/2 && git format-patch -1 --stdout FETCH_HEAD,"['etc/ceilometer/pipeline.yaml', 'ceilometer/tests/integration/gabbi/transform/create_instance.json', 'ceilometer/tests/integration/gabbi/transform/samples.yaml', 'ceilometer/tests/integration/gabbi/transform/transformation.yaml', 'tox.ini']",5,8d8f3a52bc90f0997a5e0fabf27c28f83338c0f8,bug/1586001,[testenv:transform] setenv = VIRTUAL_ENV={envdir} OS_TEST_PATH=./ceilometer/tests/integration OS_TEST_TIMEOUT=600 GABBI_LIVE_FAIL_IF_NO_TEST=1 passenv = {[testenv]passenv} HEAT_* CEILOMETER_* GNOCCHI_* AODH_* GLANCE_* NOVA_* ADMIN_* commands = bash -c 'cd ceilometer/tests/integration/gabbi/transform && gabbi-run -x < transformation.yaml' [testenv:samples] setenv = VIRTUAL_ENV={envdir} OS_TEST_PATH=./ceilometer/tests/integration OS_TEST_TIMEOUT=600 GABBI_LIVE_FAIL_IF_NO_TEST=1 passenv = {[testenv]passenv} HEAT_* CEILOMETER_* GNOCCHI_* AODH_* GLANCE_* NOVA_* ADMIN_* commands = bash -c 'cd ceilometer/tests/integration/gabbi/transform && gabbi-run -x < samples.yaml' ,,174,1
openstack%2Fstorlets~master~I3fb9734f2066608e82f9275be7d3acf607e28b99,openstack/storlets,master,I3fb9734f2066608e82f9275be7d3acf607e28b99,Refactor process starting functions,MERGED,2016-08-22 17:23:53.000000000,2016-08-29 13:35:39.000000000,2016-08-29 13:35:39.000000000,"[{'_account_id': 3}, {'_account_id': 11317}]","[{'number': 1, 'created': '2016-08-22 17:23:53.000000000', 'files': ['tests/unit/agent/storlet_daemon_factory/test_daemon_factory.py', 'Engine/agent/storlet_daemon_factory/daemon_factory.py'], 'web_link': 'https://opendev.org/openstack/storlets/commit/15d2ad832574cb12d5985c8498a2a7b37276e6b2', 'message': 'Refactor process starting functions\n\nThis patch refactors functions related to process launching\n(spawn_subprocess, wait_for_daemon_to_initialize and\nprocess_start_daemon), so that they can be just utility\nfunctions to manage storlet daemon.\n\nChange-Id: I3fb9734f2066608e82f9275be7d3acf607e28b99\n'}]",0,358783,15d2ad832574cb12d5985c8498a2a7b37276e6b2,6,2,1,9816,,,0,"Refactor process starting functions

This patch refactors functions related to process launching
(spawn_subprocess, wait_for_daemon_to_initialize and
process_start_daemon), so that they can be just utility
functions to manage storlet daemon.

Change-Id: I3fb9734f2066608e82f9275be7d3acf607e28b99
",git fetch https://review.opendev.org/openstack/storlets refs/changes/83/358783/1 && git format-patch -1 --stdout FETCH_HEAD,"['tests/unit/agent/storlet_daemon_factory/test_daemon_factory.py', 'Engine/agent/storlet_daemon_factory/daemon_factory.py']",2,15d2ad832574cb12d5985c8498a2a7b37276e6b2,refactor-dfactory," def spawn_subprocess(self, pargs, env, storlet_name): :param storlet_name: Name of the storlet to be executed dn = open(os.devnull, 'w') daemon_p = subprocess.Popen( pargs, stdout=dn, stderr=subprocess.PIPE, close_fds=True, shell=False, env=env) logger_p = subprocess.Popen( 'logger', stdin=daemon_p.stderr, stdout=dn, stderr=dn, close_fds=True, shell=False) status = self.get_process_status_by_pid(jvm_pid, storlet_name) if status: self.logger.debug('START_DAEMON: just occurred') else: self.logger.error('Started the storlet daemon for {0}, but ' 'can not check its status'. format(storlet_name)) raise SDaemonError('Failed to start the sdaemon for {0}'. format(storlet_name)) except Exception: self.logger.exception('Failed to start subprocess %s' % str(pargs)) raise SDaemonError('Failed to start the sdaemon for {0}' .format(storlet_name)) :returns: True if it starts a new subprocess False if there already exists a running process raise SDaemonError( 'Got unsupported daemon language: %s' % daemon_language) self.logger.debug('the storlet daemon for {0} is already running'. format(storlet_name)) return False self.spawn_subprocess(pargs, env, storlet_name) return True storlet_name = prms['storlet_name'] try: if self.process_start_daemon( prms['daemon_language'], prms['storlet_path'], storlet_name, prms['pool_size'], prms['uds_path'], prms['log_level'], container_id): msg = 'OK' else: msg = '{0} is already running'.format(storlet_name) return CommandSuccess(msg) except SDaemonError as e: self.logger.exception('Failed to start the sdaemon for {0}' .format(storlet_name)) return CommandFailure(str(e))"," def spawn_subprocess(self, pargs, env): :returns: (Status, Description text of possible error) b_status = True error_text = '' dn = open('/dev/null', 'w') daemon_p = subprocess.Popen(pargs, stdout=dn, stderr=subprocess.PIPE, shell=False, env=env) logger_p = subprocess.Popen('logger', stdin=daemon_p.stderr, stdout=dn, stderr=dn, shell=False) storlet_name = pargs[2] b_status = self.get_process_status_by_pid( jvm_pid, storlet_name) if b_status: self.logger.debug('START_DAEMON: just occurred') error_text = 'OK' except Exception: b_status = False error_text = 'Failed to start subprocess %s' % str(pargs) self.logger.exception(error_text) # TODO(takashi): Now we return error text in tuple, but I think we had # better make this raise Exception including message return b_status, error_text :returns: (Status, Description text of possible error) error_txt = 'Got unsupported daemon language: %s' % daemon_language self.logger.error(error_txt) return False, error_txt error_text = '{0} is already running'.format(storlet_name) self.logger.debug(error_text) b_status, error_text = self.spawn_subprocess(pargs, env) return b_status, error_text b_status, error_text = self.process_start_daemon( prms['daemon_language'], prms['storlet_path'], prms['storlet_name'], prms['pool_size'], prms['uds_path'], prms['log_level'], container_id) return CommandResponse(b_status, error_text, True)",249,60
openstack%2Fopenstack-ansible-os_trove~master~I8d064d4c9a38db020620a27184e8adeb6446ca1a,openstack/openstack-ansible-os_trove,master,I8d064d4c9a38db020620a27184e8adeb6446ca1a,Updated from global requirements,MERGED,2016-08-29 07:08:26.000000000,2016-08-29 13:35:34.000000000,2016-08-29 13:35:34.000000000,"[{'_account_id': 3}, {'_account_id': 7353}, {'_account_id': 22981}]","[{'number': 1, 'created': '2016-08-29 07:08:26.000000000', 'files': ['test-requirements.txt', 'setup.py'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_trove/commit/718eab30bf29ce737f6e8a9663d9fe348fbbb3ca', 'message': 'Updated from global requirements\n\nChange-Id: I8d064d4c9a38db020620a27184e8adeb6446ca1a\n'}]",0,361896,718eab30bf29ce737f6e8a9663d9fe348fbbb3ca,7,3,1,11131,,,0,"Updated from global requirements

Change-Id: I8d064d4c9a38db020620a27184e8adeb6446ca1a
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_trove refs/changes/96/361896/1 && git format-patch -1 --stdout FETCH_HEAD,"['test-requirements.txt', 'setup.py']",2,718eab30bf29ce737f6e8a9663d9fe348fbbb3ca,openstack/requirements,"# Copyright (c) 2013 Hewlett-Packard Development Company, L.P.# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or # implied.# In python < 2.7.4, a lazy loading of package `pbr` will break # setuptools if some other modules registered functions in `atexit`. # solution from: http://bugs.python.org/issue15881#msg170215 try: import multiprocessing # noqa except ImportError: pass setup_requires=['pbr>=1.8'],","#!/usr/bin/env python # # Copyright 2016 Internet Solutions (Pty) Ltd# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.# # (c) 2016 Donovan Francesco <donovan.francesco@is.co.za> # (c) 2016 Paul Stevens <paul.stevens@is.co.za> # setup_requires=['pbr'],",13,9
openstack%2Fdeb-python-oslotest~debian%2Fnewton~Ib71c675c43d5605f7b77142cf9322bbb544fcede,openstack/deb-python-oslotest,debian/newton,Ib71c675c43d5605f7b77142cf9322bbb544fcede,Dump commit to rebuild,MERGED,2016-08-29 12:32:30.000000000,2016-08-29 13:35:29.000000000,2016-08-29 13:35:29.000000000,"[{'_account_id': 3}, {'_account_id': 6476}]","[{'number': 1, 'created': '2016-08-29 12:32:30.000000000', 'files': ['.gitreview'], 'web_link': 'https://opendev.org/openstack/deb-python-oslotest/commit/6ab75204690632e8a3c46c1eaac7dbac613e7313', 'message': 'Dump commit to rebuild\n\nChange-Id: Ib71c675c43d5605f7b77142cf9322bbb544fcede\n'}]",0,362076,6ab75204690632e8a3c46c1eaac7dbac613e7313,6,2,1,6476,,,0,"Dump commit to rebuild

Change-Id: Ib71c675c43d5605f7b77142cf9322bbb544fcede
",git fetch https://review.opendev.org/openstack/deb-python-oslotest refs/changes/76/362076/1 && git format-patch -1 --stdout FETCH_HEAD,['.gitreview'],1,6ab75204690632e8a3c46c1eaac7dbac613e7313,,,,1,0
openstack%2Fneutron-fwaas~master~I5528dd871d6795a014fec8ffa841d456b70bcb84,openstack/neutron-fwaas,master,I5528dd871d6795a014fec8ffa841d456b70bcb84,Fix path for l3 config,ABANDONED,2016-08-29 11:59:24.000000000,2016-08-29 13:30:53.000000000,,"[{'_account_id': 3}, {'_account_id': 13702}]","[{'number': 1, 'created': '2016-08-29 11:59:24.000000000', 'files': ['neutron_fwaas/cmd/eventlet/agents/fw.py'], 'web_link': 'https://opendev.org/openstack/neutron-fwaas/commit/30db3bfd99109e24f2160b88ed94ee65b7ddb177', 'message': 'Fix path for l3 config\n\nChange-Id: I5528dd871d6795a014fec8ffa841d456b70bcb84\n'}]",0,362050,30db3bfd99109e24f2160b88ed94ee65b7ddb177,4,2,1,13702,,,0,"Fix path for l3 config

Change-Id: I5528dd871d6795a014fec8ffa841d456b70bcb84
",git fetch https://review.opendev.org/openstack/neutron-fwaas refs/changes/50/362050/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron_fwaas/cmd/eventlet/agents/fw.py'],1,30db3bfd99109e24f2160b88ed94ee65b7ddb177,fix-config-file-path,from neutron.agent.l3 import config as l3_config,from neutron.conf.agent.l3 import config as l3_config,1,1
openstack%2Fpython-magnumclient~master~I971ef74f0cc79346a76c1faba55777b0a44465da,openstack/python-magnumclient,master,I971ef74f0cc79346a76c1faba55777b0a44465da,Add floating_ip_enabled attributes to baymodel,MERGED,2016-08-05 07:13:55.000000000,2016-08-29 13:29:26.000000000,2016-08-29 13:29:26.000000000,"[{'_account_id': 3}, {'_account_id': 9591}, {'_account_id': 10206}, {'_account_id': 11536}, {'_account_id': 12385}, {'_account_id': 16352}, {'_account_id': 20498}]","[{'number': 1, 'created': '2016-08-05 07:13:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-magnumclient/commit/77132b6969bd3046ce6c2bb43a0919138d84884b', 'message': 'Add floating_ip_enabled attributes to baymodel\n\nfloating_ip_enabled option is added by server, so we should add\nthis option to client too.\n\nChange-Id: I971ef74f0cc79346a76c1faba55777b0a44465da\nPartial-Implements: blueprint bay-with-no-floating-ips\nDepends-On: I99677221250480b43a4b95ebf460c43bc77090ad\n'}, {'number': 2, 'created': '2016-08-24 23:33:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-magnumclient/commit/1da05dc8e73ceb782cd32641de84112cdb7d3b31', 'message': 'Add floating_ip_enabled attributes to baymodel\n\nfloating_ip_enabled option is added by server, so we should add\nthis option to client too.\n\nChange-Id: I971ef74f0cc79346a76c1faba55777b0a44465da\nPartial-Implements: blueprint bay-with-no-floating-ips\nDepends-On: I99677221250480b43a4b95ebf460c43bc77090ad\n'}, {'number': 3, 'created': '2016-08-29 05:18:33.000000000', 'files': ['magnumclient/v1/basemodels.py', 'magnumclient/tests/v1/test_clustertemplates.py', 'magnumclient/v1/baymodels_shell.py', 'magnumclient/tests/v1/test_baymodels_shell.py', 'magnumclient/v1/cluster_templates_shell.py', 'magnumclient/tests/v1/test_baymodels.py', 'magnumclient/tests/v1/test_clustertemplates_shell.py'], 'web_link': 'https://opendev.org/openstack/python-magnumclient/commit/3652bbea60a6657dfd5e9e6634fbd65426dcf00a', 'message': 'Add floating_ip_enabled attributes to baymodel\n\nfloating_ip_enabled option is added by server, so we should add\nthis option to client too.\n\nChange-Id: I971ef74f0cc79346a76c1faba55777b0a44465da\nPartial-Implements: blueprint bay-with-no-floating-ips\nDepends-On: I99677221250480b43a4b95ebf460c43bc77090ad\n'}]",5,351529,3652bbea60a6657dfd5e9e6634fbd65426dcf00a,20,7,3,12385,,,0,"Add floating_ip_enabled attributes to baymodel

floating_ip_enabled option is added by server, so we should add
this option to client too.

Change-Id: I971ef74f0cc79346a76c1faba55777b0a44465da
Partial-Implements: blueprint bay-with-no-floating-ips
Depends-On: I99677221250480b43a4b95ebf460c43bc77090ad
",git fetch https://review.opendev.org/openstack/python-magnumclient refs/changes/29/351529/1 && git format-patch -1 --stdout FETCH_HEAD,"['magnumclient/v1/baymodels_shell.py', 'magnumclient/tests/v1/test_baymodels_shell.py', 'magnumclient/v1/baymodels.py', 'magnumclient/tests/v1/test_baymodels.py']",4,77132b6969bd3046ce6c2bb43a0919138d84884b,bp/bay-with-no-floating-ips," 'master_lb_enabled': True, 'floating_ip_enabled': True, } self.assertEqual(BAYMODEL1['floating_ip_enabled'], baymodel.floating_ip_enabled) self.assertEqual(BAYMODEL1['floating_ip_enabled'], baymodel.floating_ip_enabled)", 'master_lb_enabled': True},16,3
openstack%2Fnetworking-ovn~master~If89325c92f7e79791dd6ca93f16f7d865b010dbf,openstack/networking-ovn,master,If89325c92f7e79791dd6ca93f16f7d865b010dbf,Updated from global requirements,MERGED,2016-08-26 22:08:21.000000000,2016-08-29 13:24:15.000000000,2016-08-29 13:24:15.000000000,"[{'_account_id': 3}, {'_account_id': 8410}, {'_account_id': 10980}]","[{'number': 1, 'created': '2016-08-26 22:08:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/267edddbd91d18c886dc3f31417e578620fe92be', 'message': 'Updated from global requirements\n\nChange-Id: If89325c92f7e79791dd6ca93f16f7d865b010dbf\n'}, {'number': 2, 'created': '2016-08-27 00:36:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/ecb2ef229d952d986928192506f8d7b3a002b0de', 'message': 'Updated from global requirements\n\nChange-Id: If89325c92f7e79791dd6ca93f16f7d865b010dbf\n'}, {'number': 3, 'created': '2016-08-29 05:41:45.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/c971a24d353d6cb860762e1b0835723d428dd7ba', 'message': 'Updated from global requirements\n\nChange-Id: If89325c92f7e79791dd6ca93f16f7d865b010dbf\n'}]",0,361492,c971a24d353d6cb860762e1b0835723d428dd7ba,11,3,3,11131,,,0,"Updated from global requirements

Change-Id: If89325c92f7e79791dd6ca93f16f7d865b010dbf
",git fetch https://review.opendev.org/openstack/networking-ovn refs/changes/92/361492/2 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,267edddbd91d18c886dc3f31417e578620fe92be,openstack/requirements,neutron-lib>=0.4.0 # Apache-2.0,neutron-lib>=0.3.0 # Apache-2.0,1,1
openstack%2Ffuel-web~stable%2Fmitaka~I3b294def77ef98289ec32196c3b7676ddfb782f0,openstack/fuel-web,stable/mitaka,I3b294def77ef98289ec32196c3b7676ddfb782f0,Fix deployment tasks history API breakage,MERGED,2016-08-19 18:47:34.000000000,2016-08-29 13:23:59.000000000,2016-08-29 13:20:41.000000000,"[{'_account_id': 3}, {'_account_id': 1531}, {'_account_id': 8971}, {'_account_id': 10391}, {'_account_id': 12661}, {'_account_id': 16518}, {'_account_id': 18205}, {'_account_id': 18446}, {'_account_id': 20656}]","[{'number': 1, 'created': '2016-08-19 18:47:34.000000000', 'files': ['nailgun/nailgun/api/v1/handlers/deployment_history.py'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/4be0430c94616307ad88fda59dad81f3d18c8fec', 'message': 'Fix deployment tasks history API breakage\n\nThis is a partial revert of a regression caused by\nc179e5d0b4b8a5b4566120eceb81a1d0ed9577c8\nand\necef951437fa694d59fff418c68d45e78dc30aa8\n\nChange-Id: I3b294def77ef98289ec32196c3b7676ddfb782f0\nCloses-bug: #1615083\n'}]",0,358047,4be0430c94616307ad88fda59dad81f3d18c8fec,36,9,1,8786,,,0,"Fix deployment tasks history API breakage

This is a partial revert of a regression caused by
c179e5d0b4b8a5b4566120eceb81a1d0ed9577c8
and
ecef951437fa694d59fff418c68d45e78dc30aa8

Change-Id: I3b294def77ef98289ec32196c3b7676ddfb782f0
Closes-bug: #1615083
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/47/358047/1 && git format-patch -1 --stdout FETCH_HEAD,['nailgun/nailgun/api/v1/handlers/deployment_history.py'],1,4be0430c94616307ad88fda59dad81f3d18c8fec,, nodes_ids = self.get_param_as_set('nodes'), nodes_ids = self.get_param_as_set('nodes_ids'),1,1
openstack%2Ffuel-web~stable%2Fmitaka~Ibf211adf4b9b111e143b4dc5512fe9c1998c3927,openstack/fuel-web,stable/mitaka,Ibf211adf4b9b111e143b4dc5512fe9c1998c3927,Add fuyaql to allow debug expressions on master node,MERGED,2016-06-29 11:46:17.000000000,2016-08-29 13:23:50.000000000,2016-08-29 13:20:48.000000000,"[{'_account_id': 3}, {'_account_id': 8971}, {'_account_id': 11827}, {'_account_id': 16518}, {'_account_id': 18205}, {'_account_id': 19158}, {'_account_id': 20656}]","[{'number': 1, 'created': '2016-06-29 11:46:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/84527c5aed254a62132492e31363122c6134d9a4', 'message': 'Add fuyaql to allow debug expressions on master node\n\nSometimes there is needed to test new YAQL expression.\nTo allow do it easier, include new YAQL shell as a part\nof nailgun.\n\nChange-Id: Ibf211adf4b9b111e143b4dc5512fe9c1998c3927\nCloses-Bug: #1590007\n(cherry picked from commit 529076b04364fc27546949cfc6389a28168b3c4d)\n'}, {'number': 2, 'created': '2016-08-10 07:40:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/5db767ff191b3459de5ec6a027b6e7ea31aa6724', 'message': 'Add fuyaql to allow debug expressions on master node\n\nSometimes there is needed to test new YAQL expression.\nTo allow do it easier, include new YAQL shell as a part\nof nailgun.\n\nChange-Id: Ibf211adf4b9b111e143b4dc5512fe9c1998c3927\nCloses-Bug: #1590007\n(cherry picked from commit 529076b04364fc27546949cfc6389a28168b3c4d)\n'}, {'number': 3, 'created': '2016-08-11 17:33:21.000000000', 'files': ['nailgun/nailgun/test/unit/fuyaql_tests/test_fuyaql.py', 'nailgun/manage.py', 'nailgun/nailgun/fuyaql/__init__.py', 'nailgun/nailgun/fuyaql/completion.py', 'nailgun/nailgun/fuyaql/README.md', 'nailgun/nailgun/fuyaql/fuyaql.py'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/28367da271e648c650e6d7f7033101abf2d2627e', 'message': 'Add fuyaql to allow debug expressions on master node\n\nSometimes there is needed to test new YAQL expression.\nTo allow do it easier, include new YAQL shell as a part\nof nailgun.\n\nChange-Id: Ibf211adf4b9b111e143b4dc5512fe9c1998c3927\nCloses-Bug: #1590007\n(cherry picked from commit 529076b04364fc27546949cfc6389a28168b3c4d)\n'}]",0,335451,28367da271e648c650e6d7f7033101abf2d2627e,63,7,3,8786,,,0,"Add fuyaql to allow debug expressions on master node

Sometimes there is needed to test new YAQL expression.
To allow do it easier, include new YAQL shell as a part
of nailgun.

Change-Id: Ibf211adf4b9b111e143b4dc5512fe9c1998c3927
Closes-Bug: #1590007
(cherry picked from commit 529076b04364fc27546949cfc6389a28168b3c4d)
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/51/335451/2 && git format-patch -1 --stdout FETCH_HEAD,"['nailgun/manage.py', 'nailgun/nailgun/test/unit/fuyaql_tests/test_fuyaql.py', 'nailgun/nailgun/fuyaql/__init__.py', 'nailgun/nailgun/fuyaql/completion.py', 'nailgun/nailgun/fuyaql/README.md', 'nailgun/nailgun/fuyaql/fuyaql.py']",6,84527c5aed254a62132492e31363122c6134d9a4,add_fuyaql,"#!/usr/bin/env python # # Copyright 2016 Mirantis, Inc. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. """"""Fuel YAQL real-time console. Allow fast and easy test your YAQL expressions on live cluster."""""" from __future__ import print_function import inspect import json import readline import sys import traceback from nailgun import consts from nailgun.fuyaql import completion from nailgun.logger import logger from nailgun import objects from nailgun.orchestrator import deployment_serializers from nailgun import yaql_ext logger.disabled = True class FuYaqlController(object): CURRENT = 0 EXPECTED = 1 def __init__(self): self._cluster = None self._node_id = None self._tasks = [None, None] self._infos = [None, None] self._yaql_context = yaql_ext.create_context( add_serializers=True, add_datadiff=True ) self._yaql_engine = yaql_ext.create_engine() @property def cluster(self): return self._cluster @property def node_id(self): return self._node_id @property def selected_tasks(self): return self._tasks def set_cluster(self, cluster_id=None): """"""Load the cluster object. :param cluster_id: id of a cluster """""" cluster = objects.Cluster.get_by_uid( cluster_id, fail_if_not_found=False ) if cluster: self._cluster = cluster self._set_task(self.EXPECTED, None) self._set_task( self.CURRENT, objects.TransactionCollection.get_last_succeed_run(cluster) ) return True return False def set_task(self, state, task_id=None): """"""Sets the task, which is used to get new state."""""" assert self._cluster task = self._get_task(task_id) if task is not False: self._set_task(state, task) return True return False def set_node(self, node_id): """"""Sets the node id."""""" info = self._get_info(self.EXPECTED) if node_id in info: self._node_id = node_id return True return False def get_node(self): """"""Gets the full information about node."""""" assert self._node_id is not None return self._get_info(self.EXPECTED)[self._node_id] @staticmethod def get_clusters(): """"""Gets list of all clusters."""""" return objects.ClusterCollection.order_by( objects.ClusterCollection.all(), 'id' ) def get_tasks(self): """"""Gets all deployment tasks for current cluster."""""" assert self.cluster query = objects.TransactionCollection.filter_by( None, cluster_id=self.cluster.id, name=consts.TASK_NAMES.deployment ) query = objects.TransactionCollection.filter_by_not( query, deployment_info=None ) return objects.TransactionCollection.order_by(query, 'id') def get_nodes(self): info = self._get_info(self.EXPECTED) for node_id in sorted(info): yield info[node_id] def evaluate(self, expression): """"""Evaluate given YAQL expression :param expression: YAQL expression which needed to be evaluated :return: result of evaluation as a string """""" assert self.cluster assert self.node_id context = self._yaql_context.create_child_context() context['$%new'] = self._get_info(self.EXPECTED)[self._node_id] context['$%old'] = self._get_info(self.CURRENT).get(self._node_id, {}) parsed_exp = self._yaql_engine(expression) return parsed_exp.evaluate(data=context['$%new'], context=context) def _get_task(self, task_id): """"""Gets task by id and checks that it belongs to cluster."""""" if not task_id: return None task = objects.Transaction.get_by_uid(task_id, fail_if_not_found=False) if task and task.cluster_id == self.cluster.id: return task return False def _set_task(self, state, task): self._tasks[state] = task self._set_info( state, objects.Transaction.get_deployment_info(task) ) def _set_info(self, state, info): if state == self.EXPECTED: self._node_id = None if info is None: serialized = deployment_serializers.serialize_for_lcm( self._cluster, objects.Cluster.get_nodes_not_for_deletion(self._cluster) ) info = {node['uid']: node for node in serialized} self._infos[state] = info or {} def _get_info(self, state): return self._infos[state] class FuyaqlInterpreter(object): COMMANDS = { ':show clusters': 'show_clusters', ':show cluster': 'show_cluster', ':use cluster': 'set_cluster', ':show tasks': 'show_tasks', ':use task2': 'set_task2', ':use task1': 'set_task1', ':show nodes': 'show_nodes', ':show node': 'show_node', ':use node': 'set_node', ':help': 'show_help', ':exit': 'shutdown', ':q': 'shutdown', } def __init__(self, cluster_id=None, node_id=None, controller=None): self.controller = controller or FuYaqlController() if cluster_id is not None: self.set_cluster(cluster_id) if node_id is not None: self.set_node(node_id) def show_help(self): """"""Shows this help."""""" for cmd in sorted(self.COMMANDS): doc = getattr(self, self.COMMANDS[cmd]).__doc__ print(cmd, '-', doc) def show_clusters(self): """"""Shows all clusters which is available for choose."""""" cluster_ids = [ self.controller.cluster and self.controller.cluster['id'] ] self.print_list( ('id', 'name', 'status'), self.controller.get_clusters(), lambda x: cluster_ids.index(x['id']) ) def show_tasks(self): """"""Shows all tasks which is available for choose."""""" task_ids = [ t and t['id'] for t in self.controller.selected_tasks ] if self._check_cluster(): self.print_list( ('id', 'status'), self.controller.get_tasks(), lambda x: task_ids.index(x['id']) ) def show_nodes(self): """"""Shows all tasks which is available for choose."""""" node_ids = [self.controller.node_id] if self._check_cluster(): self.print_list( ('uid', 'status', 'roles'), self.controller.get_nodes(), lambda x: node_ids.index(x['uid']) ) def show_cluster(self): """"""Shows details of selected cluster."""""" if self.controller.cluster: self.print_object( 'cluster', ('id', 'name', 'status'), self.controller.cluster ) else: print(""There is no cluster."") def show_task2(self): """"""Shows details of task, which belongs to new state of cluster."""""" self._show_task(self.controller.EXPECTED) def show_task1(self): """"""Shows details of task, which belongs to old state of cluster."""""" self._show_task(self.controller.CURRENT) def show_node(self): """"""Shows details of selected node."""""" if self.controller.node_id: self.print_object( 'node', ('uid', 'status', 'roles'), self.controller.get_node() ) else: print(""Please select node at first."") def set_cluster(self, cluster_id): """"""Select the cluster."""""" if not self.controller.set_cluster(cluster_id): print(""There is no cluster with id:"", cluster_id) def set_node(self, node_id): """"""Select the node."""""" if self._check_cluster(): if not self.controller.set_node(node_id): print(""There is no node with id:"", node_id) def set_task2(self, task_id): """"""Select the task which will belong to state new."""""" self._set_task(self.controller.EXPECTED, task_id) def set_task1(self, task_id): """"""Select the task which will belong to state old."""""" self._set_task(self.controller.CURRENT, task_id) def evaluate_expression(self, exp): if self._check_node(): return self.controller.evaluate(exp) def execute_command(self, cmdline): for cmd in self.COMMANDS: if (cmdline.startswith(cmd) and (len(cmdline) == len(cmd) or cmdline[len(cmd)].isspace())): break else: print(""Unknown command:"", cmdline) print(""Please use :help to see list of available commands"") return f = getattr(self, self.COMMANDS[cmd]) args = cmdline[len(cmd):].split() try: inspect.getcallargs(f, *args) except (ValueError, TypeError): print(""Not enough arguments for a command were given."") return return f(*args) @staticmethod def shutdown(): """"""Exits."""""" sys.exit(0) def run_loop(self): """"""Create a loop for user input"""""" while True: try: command = raw_input('fuel-yaql> ').strip() except EOFError: return if not command: continue try: if command.startswith(':'): # Check for internal command r = self.execute_command(command) else: r = self.evaluate_expression(command) if isinstance(r, (list, dict)): print(json.dumps(r, indent=4)) elif r is not None: print(r) except Exception as e: print(""Unexpected error: {0}"".format(e)) traceback.print_exc(sys.stdout) def _show_task(self, state): task = self.controller.selected_tasks[state] if task: self.print_object('task', ('id', 'status'), task) else: print(""Please select task at first."") def _set_task(self, state, task_id): if self._check_cluster(): next_state = (state + 1) % len(self.controller.selected_tasks) next_task = self.controller.selected_tasks[next_state] task_id = int(task_id or 0) if task_id and next_task: if next_state > state and task_id > next_task['id']: print(""The task, which belongs to state old cannot be"" "" under than task which belongs to state new."") return elif next_state < state and task_id < next_task['id']: print(""The task, which belongs to state new cannot be"" "" older than task which belongs to state old."") return self.controller.set_task(state, task_id) def _check_cluster(self): if self.controller.cluster is None: print(""Select cluster at first."") return False return True def _check_node(self): if self.controller.node_id is None: print(""Select node at first."") return False return True @staticmethod def print_list(column_names, iterable, get_selected_index=None): template = '\t|\t'.join('{%d}' % x for x in range(len(column_names))) print(template.format(*column_names)) print('-' * (sum(len(x) + 5 for x in column_names))) for column in iterable: if get_selected_index is not None: try: print('*' * (get_selected_index(column) + 1), end=' ') except ValueError: pass print(template.format(*(column.get(x, '-') for x in column_names))) @staticmethod def print_object(name, properties, obj): print(name.title() + ':') for p in properties: print(""\t{0}:\t{1}"".format(p, obj.get(p, '-'))) def main(cluster_id=None, node_id=None): # set up command history and completion readline.set_completer_delims(r'''`~!@#$%^&*()-=+[{]}\|;'"",<>/?''') readline.set_completer(completion.FuCompleter( list(FuyaqlInterpreter.COMMANDS) ).complete) readline.parse_and_bind('tab: complete') interpret = FuyaqlInterpreter(cluster_id, node_id) interpret.run_loop() if __name__ == '__main__': main() ",,1149,0
openstack%2Ffuel-web~master~I3b294def77ef98289ec32196c3b7676ddfb782f0,openstack/fuel-web,master,I3b294def77ef98289ec32196c3b7676ddfb782f0,Fix deployment tasks history API breakage,MERGED,2016-08-19 18:47:14.000000000,2016-08-29 13:23:10.000000000,2016-08-29 13:20:06.000000000,"[{'_account_id': 3}, {'_account_id': 8786}, {'_account_id': 8931}, {'_account_id': 8971}, {'_account_id': 10391}, {'_account_id': 10488}, {'_account_id': 10959}, {'_account_id': 11898}, {'_account_id': 12661}, {'_account_id': 16518}, {'_account_id': 18205}, {'_account_id': 18446}, {'_account_id': 19158}, {'_account_id': 20384}, {'_account_id': 20656}, {'_account_id': 21013}]","[{'number': 1, 'created': '2016-08-19 18:47:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/49427c54ec2c666d00892feed5211f2290f3b8b0', 'message': 'Fix deployment tasks history API breakage\n\nThis is a partial revert of a regression caused by\nc179e5d0b4b8a5b4566120eceb81a1d0ed9577c8\nand\necef951437fa694d59fff418c68d45e78dc30aa8\n\nChange-Id: I3b294def77ef98289ec32196c3b7676ddfb782f0\nCloses-bug: #1615083\n'}, {'number': 2, 'created': '2016-08-21 16:05:17.000000000', 'files': ['nailgun/nailgun/api/v1/handlers/deployment_history.py'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/11620ca522ec8ed7e1b9054fc60d883ce99fd5a2', 'message': 'Fix deployment tasks history API breakage\n\nThis is a partial revert of a regression caused by\nc179e5d0b4b8a5b4566120eceb81a1d0ed9577c8\nand\necef951437fa694d59fff418c68d45e78dc30aa8\n\nChange-Id: I3b294def77ef98289ec32196c3b7676ddfb782f0\nCloses-bug: #1615083\n'}]",0,358046,11620ca522ec8ed7e1b9054fc60d883ce99fd5a2,48,16,2,8786,,,0,"Fix deployment tasks history API breakage

This is a partial revert of a regression caused by
c179e5d0b4b8a5b4566120eceb81a1d0ed9577c8
and
ecef951437fa694d59fff418c68d45e78dc30aa8

Change-Id: I3b294def77ef98289ec32196c3b7676ddfb782f0
Closes-bug: #1615083
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/46/358046/2 && git format-patch -1 --stdout FETCH_HEAD,['nailgun/nailgun/api/v1/handlers/deployment_history.py'],1,49427c54ec2c666d00892feed5211f2290f3b8b0,, nodes_ids = self.get_param_as_set('nodes'), nodes_ids = self.get_param_as_set('nodes_ids'),1,1
openstack%2Fkarbor-dashboard~master~I626c5937abff0f0ebdb1fbc91b72053f92f4390f,openstack/karbor-dashboard,master,I626c5937abff0f0ebdb1fbc91b72053f92f4390f,Rename Smaug Dashboard to Karbor,MERGED,2016-08-17 07:26:12.000000000,2016-08-29 13:22:40.000000000,2016-08-29 13:22:40.000000000,"[{'_account_id': 3}, {'_account_id': 2023}, {'_account_id': 17151}, {'_account_id': 17192}, {'_account_id': 19346}, {'_account_id': 20883}, {'_account_id': 21648}]","[{'number': 1, 'created': '2016-08-17 07:26:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/karbor-dashboard/commit/cd187cefa5a576b6a77ce12beb81b392e0e11d21', 'message': 'Rename Smaug Dashboard to Karbor\n\nSmaug has been renamed to Karbor.\nAdjust Dashboard accordingly.\n\nChange-Id: I626c5937abff0f0ebdb1fbc91b72053f92f4390f\n'}, {'number': 2, 'created': '2016-08-29 08:11:49.000000000', 'files': ['test-requirements.txt', 'karbor_dashboard/templates/checkpoints/_index.html', 'karbor_dashboard/triggers/tables.py', 'smaug_dashboard/test/api_tests/api_tests.py', 'karbor_dashboard/templates/protectionproviders/index.html', 'karbor_dashboard/api/rest/__init__.py', 'karbor_dashboard/protectionplans/tables.py', 'karbor_dashboard/views.py', 'karbor_dashboard/protectionproviders/__init__.py', 'karbor_dashboard/templates/protectionproviders/_detail.html', 'karbor_dashboard/test/urls.py', 'karbor_dashboard/operationlogs/views.py', 'run_tests.sh', 'karbor_dashboard/test/integration_tests/__init__.py', 'karbor_dashboard/models.py', 'karbor_dashboard/triggers/views.py', 'karbor_dashboard/static/karbordashboard/images/expand.png', 'karbor_dashboard/static/karbordashboard/js/jquery.treetable.js', 'karbor_dashboard/test/api_tests/api_tests.py', 'karbor_dashboard/templates/triggers/_detail.html', 'karbor_dashboard/enabled/_6020_data_protection_protection_providers_panel.py', 'karbor_dashboard/templates/protectionplans/create.html', 'karbor_dashboard/enabled/_6030_data_protection_checkpoints_panel.py', 'karbor_dashboard/templates/triggers/index.html', 'karbor_dashboard/operationlogs/__init__.py', 'karbor_dashboard/checkpoints/__init__.py', 'karbor_dashboard/protectionplans/__init__.py', 'karbor_dashboard/templates/checkpoints/index.html', 'karbor_dashboard/protectionplans/forms.py', 'karbor_dashboard/api/__init__.py', 'karbor_dashboard/static/karbordashboard/css/jquery.treetable.css', 'karbor_dashboard/checkpoints/urls.py', 'requirements.txt', 'karbor_dashboard/templates/checkpoints/detail.html', 'karbor_dashboard/templates/operationlogs/_index.html', 'karbor_dashboard/triggers/urls.py', 'karbor_dashboard/templates/protectionplans/_detail.html', 'karbor_dashboard/checkpoints/forms.py', 'karbor_dashboard/templates/protectionplans/scheduleprotect.html', 'karbor_dashboard/templates/checkpoints/_detail.html', 'karbor_dashboard/test/__init__.py', 'karbor_dashboard/templates/protectionplans/index.html', 'karbor_dashboard/static/karbordashboard/js/checkpoints.restore.js', 'karbor_dashboard/templates/protectionplans/_create.html', 'karbor_dashboard/version.py', 'karbor_dashboard/enabled/_6010_data_protection_protection_plans_panel.py', 'karbor_dashboard/enabled/__init__.py', 'karbor_dashboard/protectionproviders/panel.py', 'HACKING.rst', 'karbor_dashboard/operationlogs/tables.py', 'karbor_dashboard/operationlogs/utils.py', 'README.rst', 'karbor_dashboard/static/karbordashboard/js/checkpoints.detail.js', 'karbor_dashboard/test/helpers.py', 'karbor_dashboard/protectionproviders/tables.py', 'karbor_dashboard/templates/operationlogs/index.html', 'karbor_dashboard/checkpoints/panel.py', 'karbor_dashboard/templates/protectionplans/_scheduleprotect.html', 'CONTRIBUTING.rst', 'karbor_dashboard/triggers/utils.py', 'karbor_dashboard/test/settings.py', 'karbor_dashboard/triggers/panel.py', 'karbor_dashboard/static/karbordashboard/images/logoicon.png', 'karbor_dashboard/templates/checkpoints/_restore.html', 'karbor_dashboard/protectionplans/views.py', 'karbor_dashboard/triggers/forms.py', 'karbor_dashboard/protectionplans/urls.py', 'karbor_dashboard/operationlogs/panel.py', 'karbor_dashboard/enabled/_6000_data_protection.py', 'karbor_dashboard/api/karbor.py', 'karbor_dashboard/protectionplans/panel.py', 'karbor_dashboard/checkpoints/tables.py', 'karbor_dashboard/static/karbordashboard/js/jquery.karbor.js', 'karbor_dashboard/templates/triggers/_create.html', 'karbor_dashboard/test/test_data.py', 'MANIFEST.in', 'karbor_dashboard/templates/protectionproviders/_schema_contents.html', 'karbor_dashboard/protectionproviders/tabs.py', 'karbor_dashboard/static/karbordashboard/images/collapse.png', 'karbor_dashboard/triggers/__init__.py', 'karbor_dashboard/templates/checkpoints/restore.html', 'setup.cfg', 'karbor_dashboard/test/api_tests/__init__.py', 'karbor_dashboard/templates/protectionplans/detail.html', 'karbor_dashboard/enabled/_6040_data_protection_operation_logs_panel.py', 'karbor_dashboard/static/karbordashboard/js/protectionplans.detail.js', 'smaug_dashboard/test/helpers.py', 'karbor_dashboard/enabled/_6050_data_protection_triggers_panel.py', 'karbor_dashboard/templates/protectionproviders/detail.html', 'karbor_dashboard/__init__.py', 'karbor_dashboard/checkpoints/utils.py', 'karbor_dashboard/dashboard.py', 'devstack/plugin.sh', 'doc/source/conf.py', 'karbor_dashboard/static/karbordashboard/js/protectionplans.create.js', 'manage.py', 'karbor_dashboard/operationlogs/urls.py', 'karbor_dashboard/templates/triggers/detail.html', 'karbor_dashboard/protectionproviders/urls.py', 'karbor_dashboard/checkpoints/views.py', 'karbor_dashboard/protectionproviders/views.py', 'karbor_dashboard/templates/triggers/create.html'], 'web_link': 'https://opendev.org/openstack/karbor-dashboard/commit/0914f30a0499b9318da52fcbde064a095d651b9e', 'message': 'Rename Smaug Dashboard to Karbor\n\nSmaug has been renamed to Karbor.\nAdjust Dashboard accordingly.\n\nChange-Id: I626c5937abff0f0ebdb1fbc91b72053f92f4390f\n'}]",3,356279,0914f30a0499b9318da52fcbde064a095d651b9e,18,7,2,17192,,,0,"Rename Smaug Dashboard to Karbor

Smaug has been renamed to Karbor.
Adjust Dashboard accordingly.

Change-Id: I626c5937abff0f0ebdb1fbc91b72053f92f4390f
",git fetch https://review.opendev.org/openstack/karbor-dashboard refs/changes/79/356279/2 && git format-patch -1 --stdout FETCH_HEAD,"['karbor_dashboard/templates/checkpoints/_index.html', 'karbor_dashboard/triggers/tables.py', 'smaug_dashboard/test/api_tests/api_tests.py', 'karbor_dashboard/templates/protectionproviders/index.html', 'karbor_dashboard/api/rest/__init__.py', 'karbor_dashboard/protectionplans/tables.py', 'karbor_dashboard/views.py', 'karbor_dashboard/protectionproviders/__init__.py', 'karbor_dashboard/templates/protectionproviders/_detail.html', 'karbor_dashboard/test/urls.py', 'karbor_dashboard/operationlogs/views.py', 'run_tests.sh', 'karbor_dashboard/test/integration_tests/__init__.py', 'karbor_dashboard/models.py', 'karbor_dashboard/triggers/views.py', 'karbor_dashboard/static/karbordashboard/images/expand.png', 'karbor_dashboard/static/karbordashboard/js/jquery.treetable.js', 'karbor_dashboard/test/api_tests/api_tests.py', 'karbor_dashboard/templates/triggers/_detail.html', 'karbor_dashboard/enabled/_6020_data_protection_protection_providers_panel.py', 'karbor_dashboard/templates/protectionplans/create.html', 'karbor_dashboard/enabled/_6030_data_protection_checkpoints_panel.py', 'karbor_dashboard/templates/triggers/index.html', 'karbor_dashboard/operationlogs/__init__.py', 'karbor_dashboard/checkpoints/__init__.py', 'karbor_dashboard/protectionplans/__init__.py', 'karbor_dashboard/templates/checkpoints/index.html', 'karbor_dashboard/protectionplans/forms.py', 'karbor_dashboard/api/__init__.py', 'karbor_dashboard/static/karbordashboard/css/jquery.treetable.css', 'karbor_dashboard/checkpoints/urls.py', 'requirements.txt', 'karbor_dashboard/templates/checkpoints/detail.html', 'karbor_dashboard/templates/operationlogs/_index.html', 'karbor_dashboard/triggers/urls.py', 'karbor_dashboard/templates/protectionplans/_detail.html', 'karbor_dashboard/checkpoints/forms.py', 'karbor_dashboard/templates/protectionplans/scheduleprotect.html', 'karbor_dashboard/templates/checkpoints/_detail.html', 'karbor_dashboard/test/__init__.py', 'karbor_dashboard/templates/protectionplans/index.html', 'karbor_dashboard/static/karbordashboard/js/checkpoints.restore.js', 'karbor_dashboard/templates/protectionplans/_create.html', 'karbor_dashboard/version.py', 'karbor_dashboard/enabled/_6010_data_protection_protection_plans_panel.py', 'karbor_dashboard/enabled/__init__.py', 'karbor_dashboard/protectionproviders/panel.py', 'HACKING.rst', 'karbor_dashboard/operationlogs/tables.py', 'karbor_dashboard/operationlogs/utils.py', 'README.rst', 'karbor_dashboard/static/karbordashboard/js/checkpoints.detail.js', 'karbor_dashboard/test/helpers.py', 'karbor_dashboard/protectionproviders/tables.py', 'karbor_dashboard/templates/operationlogs/index.html', 'karbor_dashboard/checkpoints/panel.py', 'karbor_dashboard/templates/protectionplans/_scheduleprotect.html', 'CONTRIBUTING.rst', 'karbor_dashboard/triggers/utils.py', 'karbor_dashboard/test/settings.py', 'karbor_dashboard/triggers/panel.py', 'karbor_dashboard/static/karbordashboard/images/logoicon.png', 'karbor_dashboard/templates/checkpoints/_restore.html', 'karbor_dashboard/protectionplans/views.py', 'karbor_dashboard/triggers/forms.py', 'karbor_dashboard/protectionplans/urls.py', 'karbor_dashboard/operationlogs/panel.py', 'karbor_dashboard/enabled/_6000_data_protection.py', 'karbor_dashboard/api/karbor.py', 'karbor_dashboard/protectionplans/panel.py', 'karbor_dashboard/checkpoints/tables.py', 'karbor_dashboard/static/karbordashboard/js/jquery.karbor.js', 'karbor_dashboard/templates/triggers/_create.html', 'karbor_dashboard/test/test_data.py', 'MANIFEST.in', 'karbor_dashboard/templates/protectionproviders/_schema_contents.html', 'karbor_dashboard/protectionproviders/tabs.py', 'karbor_dashboard/static/karbordashboard/images/collapse.png', 'karbor_dashboard/triggers/__init__.py', 'karbor_dashboard/templates/checkpoints/restore.html', 'setup.cfg', 'karbor_dashboard/test/api_tests/__init__.py', 'karbor_dashboard/templates/protectionplans/detail.html', 'karbor_dashboard/enabled/_6040_data_protection_operation_logs_panel.py', 'karbor_dashboard/static/karbordashboard/js/protectionplans.detail.js', 'smaug_dashboard/test/helpers.py', 'karbor_dashboard/enabled/_6050_data_protection_triggers_panel.py', 'karbor_dashboard/templates/protectionproviders/detail.html', 'karbor_dashboard/__init__.py', 'karbor_dashboard/checkpoints/utils.py', 'karbor_dashboard/dashboard.py', 'devstack/plugin.sh', 'doc/source/conf.py', 'karbor_dashboard/static/karbordashboard/js/protectionplans.create.js', 'manage.py', 'karbor_dashboard/operationlogs/urls.py', 'karbor_dashboard/templates/triggers/detail.html', 'karbor_dashboard/protectionproviders/urls.py', 'karbor_dashboard/checkpoints/views.py', 'karbor_dashboard/protectionproviders/views.py', 'karbor_dashboard/templates/triggers/create.html']",101,cd187cefa5a576b6a77ce12beb81b392e0e11d21,smaug-dashboard-rename,,,1389,1388
openstack%2Fheat-translator~master~I82e287aa77d6e54109cc8224046221e808e389c8,openstack/heat-translator,master,I82e287aa77d6e54109cc8224046221e808e389c8,Updated from global requirements,MERGED,2016-08-29 06:10:50.000000000,2016-08-29 13:18:58.000000000,2016-08-29 13:18:58.000000000,"[{'_account_id': 3}, {'_account_id': 6456}]","[{'number': 1, 'created': '2016-08-29 06:10:50.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/537fd339022e9144781442786c52e12f98a10c49', 'message': 'Updated from global requirements\n\nChange-Id: I82e287aa77d6e54109cc8224046221e808e389c8\n'}]",0,361862,537fd339022e9144781442786c52e12f98a10c49,6,2,1,11131,,,0,"Updated from global requirements

Change-Id: I82e287aa77d6e54109cc8224046221e808e389c8
",git fetch https://review.opendev.org/openstack/heat-translator refs/changes/62/361862/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,537fd339022e9144781442786c52e12f98a10c49,openstack/requirements,python-heatclient>=1.4.0 # Apache-2.0,python-heatclient>=1.1.0 # Apache-2.0,1,1
openstack%2Faodh~master~I1f50db4d0c82bedc7803160908b714e174746e43,openstack/aodh,master,I1f50db4d0c82bedc7803160908b714e174746e43,inmemory: add % parameter to formating string,MERGED,2016-08-29 12:00:08.000000000,2016-08-29 13:18:37.000000000,2016-08-29 13:18:37.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2813}, {'_account_id': 22752}]","[{'number': 1, 'created': '2016-08-29 12:00:08.000000000', 'files': ['aodh/storage/hbase/inmemory.py'], 'web_link': 'https://opendev.org/openstack/aodh/commit/25d53a9b48f111e7982858efde745c650f686690', 'message': 'inmemory: add % parameter to formating string\n\nChange-Id: I1f50db4d0c82bedc7803160908b714e174746e43\n'}]",0,362051,25d53a9b48f111e7982858efde745c650f686690,8,4,1,22739,,,0,"inmemory: add % parameter to formating string

Change-Id: I1f50db4d0c82bedc7803160908b714e174746e43
",git fetch https://review.opendev.org/openstack/aodh refs/changes/51/362051/1 && git format-patch -1 --stdout FETCH_HEAD,['aodh/storage/hbase/inmemory.py'],1,25d53a9b48f111e7982858efde745c650f686690,20160829," ""you may want to add it!"" % filter)"," ""you may want to add it!"")",1,1
openstack%2Fwatcher~master~I5cada2c9f7832827c1bccfdea1b0a2138b18bfc9,openstack/watcher,master,I5cada2c9f7832827c1bccfdea1b0a2138b18bfc9,Merge scoring base files,MERGED,2016-08-29 09:39:25.000000000,2016-08-29 13:18:03.000000000,2016-08-29 13:18:03.000000000,"[{'_account_id': 3}, {'_account_id': 12394}, {'_account_id': 19055}, {'_account_id': 20515}]","[{'number': 1, 'created': '2016-08-29 09:39:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/ec6edc523e4a2bd3dcab5fca99ea91494afb2803', 'message': 'Merge scoring base files\n\nMerge scoring_engine.py and scoring_container.py to base.py\n\nChange-Id: I5cada2c9f7832827c1bccfdea1b0a2138b18bfc9\nCloses-Bug: #1617376\n'}, {'number': 2, 'created': '2016-08-29 12:00:10.000000000', 'files': ['watcher/decision_engine/scoring/dummy_scorer.py', 'watcher/decision_engine/scoring/dummy_scoring_container.py', 'watcher/decision_engine/scoring/scoring_container.py', 'watcher/decision_engine/scoring/base.py'], 'web_link': 'https://opendev.org/openstack/watcher/commit/6e8dc5297e9f900bdc5d92ba10617464e85de1a1', 'message': 'Merge scoring base files\n\nMerge scoring_engine.py and scoring_container.py to base.py\n\nChange-Id: I5cada2c9f7832827c1bccfdea1b0a2138b18bfc9\nCloses-Bug: #1617376\n'}]",0,361968,6e8dc5297e9f900bdc5d92ba10617464e85de1a1,10,4,2,16666,,,0,"Merge scoring base files

Merge scoring_engine.py and scoring_container.py to base.py

Change-Id: I5cada2c9f7832827c1bccfdea1b0a2138b18bfc9
Closes-Bug: #1617376
",git fetch https://review.opendev.org/openstack/watcher refs/changes/68/361968/1 && git format-patch -1 --stdout FETCH_HEAD,"['watcher/decision_engine/scoring/dummy_scorer.py', 'watcher/decision_engine/scoring/dummy_scoring_container.py', 'watcher/decision_engine/scoring/scoring_container.py', 'watcher/decision_engine/scoring/base.py']",4,ec6edc523e4a2bd3dcab5fca99ea91494afb2803,bug/1617376," @six.add_metaclass(abc.ABCMeta) class ScoringEngineContainer(loadable.Loadable): """"""A base class for all the Scoring Engines Containers. A Scoring Engine Container is an abstraction which allows to plugin multiple Scoring Engines as a single Stevedore plugin. This enables some more advanced scenarios like dynamic reloading of Scoring Engine implementations without having to restart any Watcher services. """""" @classmethod @abc.abstractmethod def get_scoring_engine_list(self): """"""Returns a list of Scoring Engine instances. :return: A list of Scoring Engine instances :rtype: :class: `~.scoring_engine.ScoringEngine` """""" @classmethod def get_config_opts(cls): """"""Defines the configuration options to be associated to this loadable :return: A list of configuration options relative to this Loadable :rtype: list of :class:`oslo_config.cfg.Opt` instances """""" return []",,34,57
openstack%2Fpython-openstackclient~master~I36ae2cf922836cff42653283c0a683359bd91344,openstack/python-openstackclient,master,I36ae2cf922836cff42653283c0a683359bd91344,[docs] fix incorrect rst markups,MERGED,2016-08-24 07:38:23.000000000,2016-08-29 13:17:56.000000000,2016-08-29 13:17:56.000000000,"[{'_account_id': 3}, {'_account_id': 6482}, {'_account_id': 14937}]","[{'number': 1, 'created': '2016-08-24 07:38:23.000000000', 'files': ['doc/source/plugin-commands.rst'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/50a5c2a1636c58fb5fa608fa0c2493ab960ba0ff', 'message': '[docs] fix incorrect rst markups\n\nThe incorrect md-style markups break Sphinx builds,\nwhich do not properly generate web page.\n\nhttp://docs.openstack.org/developer/python-openstackclient/plugin-commands.html\n\nChange-Id: I36ae2cf922836cff42653283c0a683359bd91344\n'}]",0,359649,50a5c2a1636c58fb5fa608fa0c2493ab960ba0ff,7,3,1,10497,,,0,"[docs] fix incorrect rst markups

The incorrect md-style markups break Sphinx builds,
which do not properly generate web page.

http://docs.openstack.org/developer/python-openstackclient/plugin-commands.html

Change-Id: I36ae2cf922836cff42653283c0a683359bd91344
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/49/359649/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/plugin-commands.rst'],1,50a5c2a1636c58fb5fa608fa0c2493ab960ba0ff,docs,=============== Plugin Commands ===============aodh ---- barbican -------- congress -------- .. cuedesignate --------- .. gnocchiheat ---- ironic ------ ironic-inspector ---------------- mistral ------- murano ------ neutron ------- sahara ------ searchlight ----------- senlin ------ .. tripleo.. watcherzaqar ----- .. _CLI_Ref: http://docs.openstack.org/cli-reference/openstack.html ,================= Plugin Commands =================# aodh# barbican# congress# cue# designate# gnocchi# heat# ironic# ironic-inspector# mistral# murano# neutron# sahara# searchlight# senlin# tripleo# watcher# zaqar.. _CLI_Ref: http://docs.openstack.org/cli-reference/openstack.html,50,22
openstack%2Fos-api-ref~master~I32fc524c87fa7ea90c86e749b7791c10bd1665ac,openstack/os-api-ref,master,I32fc524c87fa7ea90c86e749b7791c10bd1665ac,Adds more info to the README to instruct authors,MERGED,2016-08-05 15:17:37.000000000,2016-08-29 13:16:22.000000000,2016-08-29 13:16:22.000000000,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 8099}]","[{'number': 1, 'created': '2016-08-05 15:17:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-api-ref/commit/8a42069f041eede4272bde92e115ddc574bfe3c5', 'message': 'Adds more info to the README to instruct authors\n\nChange-Id: I32fc524c87fa7ea90c86e749b7791c10bd1665ac\n'}, {'number': 2, 'created': '2016-08-25 02:26:30.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/os-api-ref/commit/bab707c2397606fc5a4167d2b9b9375c89da0a23', 'message': 'Adds more info to the README to instruct authors\n\nChange-Id: I32fc524c87fa7ea90c86e749b7791c10bd1665ac\n'}]",0,351794,bab707c2397606fc5a4167d2b9b9375c89da0a23,10,3,2,964,,,0,"Adds more info to the README to instruct authors

Change-Id: I32fc524c87fa7ea90c86e749b7791c10bd1665ac
",git fetch https://review.opendev.org/openstack/os-api-ref refs/changes/94/351794/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,8a42069f041eede4272bde92e115ddc574bfe3c5,example-http-status,"repetitive) data in tables is not its strength. This provides toolingparameters and status or error messages, and turn those into nice tables.expected to layer on top of a Sphinx theme base. This* Sphinx stanza ``rest_method`` describing the method and resource for a REST API call. Lets authors write simply and also gives readers a clean way to scan all methods then click a button to get more information about a method. * Sphinx stanza ``rest_parameters`` used to insert semi-structured data into the RST files describing the parameters users can send with the request. The stanza points to a structured YAML file, ``parameters.yaml``. * Sphinx stanza ``rest_status_code`` used to insert pointers to error or status codes returned by the service. Points to a structured YAML file, ``http_codes.yaml``.* Make a microversion selector, so that you can get a version of the api-ref (this one is going to be a bit of complex javascript), in progress. * Make output compatible with openstackdocstheme (which is equal parts work here and with the openstack docs theme), in progress.**rest_method**: Enter the REST method, such as GET, PUT, POST, DELETE, followed by the resource (not including an endpoint) for the call. For example:: .. rest_method:: PUT /v2/images/{image_id}/file **rest_parameters**: Enter a reference to a ``parameters.yaml`` file and indicate which parameter you want to document. For example:: .. rest_parameters:: images-parameters.yaml - Content-type: Content-Type-data - image_id: image_id-in-path Where the ``images-parameters.yaml`` file contains pointers named ``Content-type`` and ``image_id`` and descriptions for each. **rest_status_code**: Enter a reference to a ``http-status.yaml`` file and indicate which errors or status codes you want to document. You can also add a pointer to more precise descriptions for each code. For example:: .. rest_status_code:: success http-codes.yaml - 204 .. rest_status_code:: error http-codes.yaml - 400: informal - 401 - 403 - 404 - 409 - 410: image-data-410 - 413: image-data-413 - 415: image-data-415 - 500: informal - 503: image-data-503","repetitive) data in tables is not it's strength. This provides toolingparameters, and turn those into nice tables.expected to layer on top of an ``oslosphinx`` theme base. This* 2 new sphinx stanzas ``rest_method`` and ``rest_parameters`` which support putting semi-structured data into the RST files.* microversion selector, so that you can get a version of the api-ref (this one is going to be a bit of complex javascript) * make this compatible with openstackdocstheme (which is equal parts work here and with the openstack docs theme).TODO: document the details of the stanzas",53,10
openstack%2Fpuppet-neutron~master~Iff4189c27637caf9d7645599649f832d41bc9563,openstack/puppet-neutron,master,Iff4189c27637caf9d7645599649f832d41bc9563,Prepare 9.2.0 (newton b3),MERGED,2016-08-26 13:55:45.000000000,2016-08-29 13:16:00.000000000,2016-08-29 13:16:00.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 6681}, {'_account_id': 7745}, {'_account_id': 8971}, {'_account_id': 14985}, {'_account_id': 22041}]","[{'number': 1, 'created': '2016-08-26 13:55:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/a9a3ed7ea477c11290ac70fe7a55f6394114b7d7', 'message': 'Prepare 9.2.0 (newton b3)\n\nPreparing Newton b3 release.\n\nChange-Id: Iff4189c27637caf9d7645599649f832d41bc9563\n'}, {'number': 2, 'created': '2016-08-26 14:21:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/450d24f15c4483c61ababbca28a676ba2d324e66', 'message': 'Prepare 9.2.0 (newton b3)\n\nPreparing Newton b3 release.\n\nChange-Id: Iff4189c27637caf9d7645599649f832d41bc9563\n'}, {'number': 3, 'created': '2016-08-26 15:46:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/bcd8e2d228f8dbe8339fcd1e740a30657a621bc8', 'message': 'Prepare 9.2.0 (newton b3)\n\nPreparing Newton b3 release.\n\nChange-Id: Iff4189c27637caf9d7645599649f832d41bc9563\n'}, {'number': 4, 'created': '2016-08-26 18:12:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/1866ce807958f10b51c04564f28520e1b42a3569', 'message': 'Prepare 9.2.0 (newton b3)\n\nPreparing Newton b3 release.\n\nChange-Id: Iff4189c27637caf9d7645599649f832d41bc9563\n'}, {'number': 5, 'created': '2016-08-26 18:58:33.000000000', 'files': ['metadata.json', 'releasenotes/source/conf.py'], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/0864d4f306d37d5fc6d60b5f851eff9f305803c9', 'message': 'Prepare 9.2.0 (newton b3)\n\nPreparing Newton b3 release.\n\nChange-Id: Iff4189c27637caf9d7645599649f832d41bc9563\n'}]",1,361212,0864d4f306d37d5fc6d60b5f851eff9f305803c9,27,7,5,3153,,,0,"Prepare 9.2.0 (newton b3)

Preparing Newton b3 release.

Change-Id: Iff4189c27637caf9d7645599649f832d41bc9563
",git fetch https://review.opendev.org/openstack/puppet-neutron refs/changes/12/361212/4 && git format-patch -1 --stdout FETCH_HEAD,"['metadata.json', 'releasenotes/source/conf.py']",2,a9a3ed7ea477c11290ac70fe7a55f6394114b7d7,puppet/9.2.0,version = '9.2.0'release = '9.2.0',version = '9.1.0'release = '9.1.0',7,7
openstack%2Fsolum~master~I7f969696faf9b28149a160e2730fb6072325de21,openstack/solum,master,I7f969696faf9b28149a160e2730fb6072325de21,Updated from global requirements,MERGED,2016-08-25 05:06:05.000000000,2016-08-29 13:13:39.000000000,2016-08-29 13:13:39.000000000,"[{'_account_id': 3}, {'_account_id': 2506}]","[{'number': 1, 'created': '2016-08-25 05:06:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/261563252651a36812083369b44a3ac3a9a5bd3a', 'message': 'Updated from global requirements\n\nChange-Id: I7f969696faf9b28149a160e2730fb6072325de21\n'}, {'number': 2, 'created': '2016-08-29 06:18:01.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/solum/commit/2cebc0c0f0271ad12570c383a4a30369f3588edf', 'message': 'Updated from global requirements\n\nChange-Id: I7f969696faf9b28149a160e2730fb6072325de21\n'}]",0,360241,2cebc0c0f0271ad12570c383a4a30369f3588edf,8,2,2,11131,,,0,"Updated from global requirements

Change-Id: I7f969696faf9b28149a160e2730fb6072325de21
",git fetch https://review.opendev.org/openstack/solum refs/changes/41/360241/2 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,261563252651a36812083369b44a3ac3a9a5bd3a,openstack/requirements,"python-glanceclient!=2.4.0,>=2.3.0 # Apache-2.0","python-glanceclient!=2.4.0,>=2.0.0 # Apache-2.0",1,1
openstack%2Fpython-openstackclient~master~I2eb35dc53f0fdb61c31022bb70293d1df8aaf482,openstack/python-openstackclient,master,I2eb35dc53f0fdb61c31022bb70293d1df8aaf482,Clean imports in code,MERGED,2016-08-25 06:53:38.000000000,2016-08-29 13:13:32.000000000,2016-08-29 13:13:32.000000000,"[{'_account_id': 3}, {'_account_id': 6482}, {'_account_id': 14937}]","[{'number': 1, 'created': '2016-08-25 06:53:38.000000000', 'files': ['openstackclient/common/client_config.py'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/f854b7d6ea1c67cf7f313e039691c4cb40ff1236', 'message': 'Clean imports in code\n\nIn some part in the code we import objects.\nIn the Openstack style guidelines they recommend to import only modules.\n\nhttp://docs.openstack.org/developer/hacking/#imports\n\nChange-Id: I2eb35dc53f0fdb61c31022bb70293d1df8aaf482\n'}]",0,360277,f854b7d6ea1c67cf7f313e039691c4cb40ff1236,8,3,1,15905,,,0,"Clean imports in code

In some part in the code we import objects.
In the Openstack style guidelines they recommend to import only modules.

http://docs.openstack.org/developer/hacking/#imports

Change-Id: I2eb35dc53f0fdb61c31022bb70293d1df8aaf482
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/77/360277/1 && git format-patch -1 --stdout FETCH_HEAD,['openstackclient/common/client_config.py'],1,f854b7d6ea1c67cf7f313e039691c4cb40ff1236,cleancode,from os_client_config import configclass OSC_Config(config.OpenStackConfig):,from os_client_config.config import OpenStackConfigclass OSC_Config(OpenStackConfig):,2,2
openstack%2Fheat~master~I55e08fbbc6e485808f89375cb0e114f6d6795980,openstack/heat,master,I55e08fbbc6e485808f89375cb0e114f6d6795980,Aodh::Alarm observe reality implementation,MERGED,2016-05-06 10:49:49.000000000,2016-08-29 13:12:09.000000000,2016-08-29 13:12:09.000000000,"[{'_account_id': 3}, {'_account_id': 6577}, {'_account_id': 8289}, {'_account_id': 12363}, {'_account_id': 13009}]","[{'number': 1, 'created': '2016-05-06 10:49:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/7c6da9fd7a3311ca6c8464f7b295982fd06751d5', 'message': 'Ceilometer::Alarm observe reality implementation\n\nOverride parse_live_resource_data method for Ceilometer::Alarm\nresource to observe and update resource plugin with live state.\n\nimplements bp get-reality-for-resources\n\nChange-Id: I55e08fbbc6e485808f89375cb0e114f6d6795980\n'}, {'number': 2, 'created': '2016-07-07 15:08:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/313dff2a622e666e7e911bb5874d9b7dd4e260de', 'message': 'Ceilometer::Alarm observe reality implementation\n\nOverride parse_live_resource_data method for Ceilometer::Alarm\nresource to observe and update resource plugin with live state.\n\nimplements bp get-reality-for-resources\n\nChange-Id: I55e08fbbc6e485808f89375cb0e114f6d6795980\n'}, {'number': 3, 'created': '2016-07-08 08:38:16.000000000', 'files': ['heat/tests/openstack/aodh/test_alarm.py', 'heat/engine/resources/openstack/aodh/alarm.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/7f8e3ff4c1b4ab1f5fe36ced62f98b0d821a160a', 'message': 'Aodh::Alarm observe reality implementation\n\nOverride parse_live_resource_data method for Aodh::Alarm\nresource to observe and update resource plugin with live state.\n\nimplements bp get-reality-for-resources\n\nChange-Id: I55e08fbbc6e485808f89375cb0e114f6d6795980\n'}]",4,313499,7f8e3ff4c1b4ab1f5fe36ced62f98b0d821a160a,15,5,3,20559,,,0,"Aodh::Alarm observe reality implementation

Override parse_live_resource_data method for Aodh::Alarm
resource to observe and update resource plugin with live state.

implements bp get-reality-for-resources

Change-Id: I55e08fbbc6e485808f89375cb0e114f6d6795980
",git fetch https://review.opendev.org/openstack/heat refs/changes/99/313499/1 && git format-patch -1 --stdout FETCH_HEAD,"['heat/tests/openstack/ceilometer/test_ceilometer_alarm.py', 'heat/engine/resources/openstack/ceilometer/alarm.py']",2,7c6da9fd7a3311ca6c8464f7b295982fd06751d5,bp/get-reality-for-resources," def parse_live_resource_data(self, resource_properties, resource_data): record_reality = {} threshold_data = resource_data.get('threshold_rule').copy() threshold_data.update(resource_data) props_upd_allowed = set(self.PROPERTIES + COMMON_PROPERTIES) - { self.METER_NAME, TIME_CONSTRAINTS} for key in props_upd_allowed: record_reality.update({key: threshold_data.get(key)}) return record_reality ",,58,0
openstack%2Fpython-muranoclient~master~I2aa78f02ede593edbf7f159babbb60b9238bf373,openstack/python-muranoclient,master,I2aa78f02ede593edbf7f159babbb60b9238bf373,Replace functions 'Dict.get' and 'del' with 'Dict.pop',MERGED,2016-08-29 06:03:39.000000000,2016-08-29 13:11:49.000000000,2016-08-29 13:11:49.000000000,"[{'_account_id': 3}, {'_account_id': 7821}, {'_account_id': 14107}, {'_account_id': 15168}]","[{'number': 1, 'created': '2016-08-29 06:03:39.000000000', 'files': ['muranoclient/openstack/common/apiclient/client.py'], 'web_link': 'https://opendev.org/openstack/python-muranoclient/commit/5d0e9e6858ceda47c19d8126481634b99f462e9c', 'message': ""Replace functions 'Dict.get' and 'del' with 'Dict.pop'\n\nRefactoring code: Making 'kwargs' to use single instruction: pop()\nrather than two instructions: get() and del, giving the codes a\nformat that carries through.\n\nTrivialFix\n\nChange-Id: I2aa78f02ede593edbf7f159babbb60b9238bf373\n""}]",0,361852,5d0e9e6858ceda47c19d8126481634b99f462e9c,9,4,1,20182,,,0,"Replace functions 'Dict.get' and 'del' with 'Dict.pop'

Refactoring code: Making 'kwargs' to use single instruction: pop()
rather than two instructions: get() and del, giving the codes a
format that carries through.

TrivialFix

Change-Id: I2aa78f02ede593edbf7f159babbb60b9238bf373
",git fetch https://review.opendev.org/openstack/python-muranoclient refs/changes/52/361852/1 && git format-patch -1 --stdout FETCH_HEAD,['muranoclient/openstack/common/apiclient/client.py'],1,5d0e9e6858ceda47c19d8126481634b99f462e9c,use_dict.pop, kwargs['data'] = json.dumps(kwargs.pop('json')), kwargs['data'] = json.dumps(kwargs['json']) try: del kwargs['json'] except KeyError: pass,1,5
openstack%2Fheat~master~I15b9295f631615c1d98d7872fb973d5e8ca226da,openstack/heat,master,I15b9295f631615c1d98d7872fb973d5e8ca226da,Add v2 glance image props,MERGED,2016-08-08 15:43:12.000000000,2016-08-29 13:11:41.000000000,2016-08-29 13:11:41.000000000,"[{'_account_id': 3}, {'_account_id': 12363}, {'_account_id': 13009}, {'_account_id': 20158}, {'_account_id': 20559}]","[{'number': 1, 'created': '2016-08-08 15:43:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/6d9d977f92e0ef8751a69c040e6a7f07d655c8ac', 'message': 'Add v2 glance image props\n\nAdded properties, supported by glanceclient v2:\narchitecture\nkernel_id\nos_distro\nramdisk_id\nand also owner property, supported by\nglanceclient v1.\n\nCloses-Bug: #1606150\nChange-Id: I15b9295f631615c1d98d7872fb973d5e8ca226da\n'}, {'number': 2, 'created': '2016-08-09 12:28:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/355e82efd9df9266f57602fafd072dbeb513115c', 'message': 'Add v2 glance image props\n\nAdded properties, supported by glanceclient v2:\narchitecture\nkernel_id\nos_distro\nramdisk_id\nand also owner property, supported by\nglanceclient v1.\n\nCloses-Bug: #1606150\nChange-Id: I15b9295f631615c1d98d7872fb973d5e8ca226da\n'}, {'number': 3, 'created': '2016-08-18 13:55:49.000000000', 'files': ['heat/tests/openstack/glance/test_image.py', 'heat/engine/resources/openstack/glance/image.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/652a1a8b33246beb5fa18692f614274c2a03b841', 'message': 'Add v2 glance image props\n\nAdded properties, supported by glanceclient v2:\narchitecture\nkernel_id\nos_distro\nramdisk_id\nand also owner property, supported by glanceclient v1.\n\nCloses-Bug: #1606150\nChange-Id: I15b9295f631615c1d98d7872fb973d5e8ca226da\n'}]",17,352487,652a1a8b33246beb5fa18692f614274c2a03b841,23,5,3,20559,,,0,"Add v2 glance image props

Added properties, supported by glanceclient v2:
architecture
kernel_id
os_distro
ramdisk_id
and also owner property, supported by glanceclient v1.

Closes-Bug: #1606150
Change-Id: I15b9295f631615c1d98d7872fb973d5e8ca226da
",git fetch https://review.opendev.org/openstack/heat refs/changes/87/352487/1 && git format-patch -1 --stdout FETCH_HEAD,"['heat/tests/openstack/glance/test_image.py', 'heat/engine/resources/openstack/glance/image.py']",2,6d9d977f92e0ef8751a69c040e6a7f07d655c8ac,glance_image_props," DISK_FORMAT, CONTAINER_FORMAT, LOCATION, TAGS, ARCHITECTURE, KERNEL_ID, OS_DISTRO, OWNER, RAMDISK_ID 'disk_format', 'container_format', 'location', 'tags', 'architecture', 'kernel_id', 'os_distro', 'owner', 'ramdisk_id' glance_id_pattern = ('^([0-9a-fA-F]){8}-([0-9a-fA-F]){4}-([0-9a-fA-F])' '{4}-([0-9a-fA-F]){4}-([0-9a-fA-F]){12}$') ), ARCHITECTURE: properties.Schema( properties.Schema.STRING, _('Operating system architecture.'), update_allowed=True, support_status=support.SupportStatus(version='7.0.0') ), KERNEL_ID: properties.Schema( properties.Schema.STRING, _('ID of image stored in Glance that should be used as ' 'the kernel when booting an AMI-style image.'), update_allowed=True, support_status=support.SupportStatus(version='7.0.0'), constraints=[ constraints.AllowedPattern(glance_id_pattern) ] ), OS_DISTRO: properties.Schema( properties.Schema.STRING, _('ID of image stored in Glance that should be used as ' 'the kernel when booting an AMI-style image.'), update_allowed=True, support_status=support.SupportStatus(version='7.0.0') ), OWNER: properties.Schema( properties.Schema.STRING, _('Owner of the image.'), update_allowed=True, support_status=support.SupportStatus(version='7.0.0') ), RAMDISK_ID: properties.Schema( properties.Schema.STRING, _('ID of image stored in Glance that should be used as ' 'the ramdisk when booting an AMI-style image.'), update_allowed=True, support_status=support.SupportStatus(version='7.0.0'), constraints=[ constraints.AllowedPattern(glance_id_pattern) ] architecture = args.pop(self.ARCHITECTURE, None) kernel_id = args.pop(self.KERNEL_ID, None) os_distro = args.pop(self.OS_DISTRO, None) ramdisk_id = args.pop(self.RAMDISK_ID, None) v2_images = self.client(version=self.client_plugin().V2).images if architecture is not None: v2_images.update(image_id, architecture=architecture) if kernel_id is not None: v2_images.update(image_id, kernel_id=kernel_id) if os_distro is not None: v2_images.update(image_id, os_distro=os_distro) if ramdisk_id is not None: v2_images.update(image_id, ramdisk_id=ramdisk_id) diff_tags = prop_diff.pop(self.TAGS) or [] v2_images = self.client(version=self.client_plugin().V2).images v2_images.update(self.resource_id, **prop_diff) "," DISK_FORMAT, CONTAINER_FORMAT, LOCATION, TAGS 'disk_format', 'container_format', 'location', 'tags' diff_tags = prop_diff[self.TAGS] or []",117,7
openstack%2Fheat~master~Ibd94532fad216516e98bbd859547f8d8f8f851fa,openstack/heat,master,Ibd94532fad216516e98bbd859547f8d8f8f851fa,Add functional test coverage for files API,MERGED,2016-07-12 13:06:04.000000000,2016-08-29 13:10:46.000000000,2016-08-29 13:10:46.000000000,"[{'_account_id': 3}, {'_account_id': 4328}, {'_account_id': 4571}, {'_account_id': 8833}, {'_account_id': 12363}]","[{'number': 1, 'created': '2016-07-12 13:06:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/b473a8a0b47c908c6df4a8dec84c1560202f5d03', 'message': 'Add functional test coverage for files API\n\nAdds simple validation of the new files API to an existing\ntest\n\nChange-Id: Ibd94532fad216516e98bbd859547f8d8f8f851fa\nblueprint: files-show\nDepends-On: Ib7d033a660fe294bf3f7b42e4aa7020149ce24c1\n'}, {'number': 2, 'created': '2016-08-24 14:22:36.000000000', 'files': ['heat_integrationtests/functional/test_resource_group.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/af62cba8ed6f7d53c70ecd7ecadb30aa5d7feaa0', 'message': 'Add functional test coverage for files API\n\nAdds simple validation of the new files API to an existing\ntest\n\nChange-Id: Ibd94532fad216516e98bbd859547f8d8f8f851fa\nblueprint: files-show\nDepends-On: Ib7d033a660fe294bf3f7b42e4aa7020149ce24c1\n'}]",0,340932,af62cba8ed6f7d53c70ecd7ecadb30aa5d7feaa0,18,5,2,4328,,,0,"Add functional test coverage for files API

Adds simple validation of the new files API to an existing
test

Change-Id: Ibd94532fad216516e98bbd859547f8d8f8f851fa
blueprint: files-show
Depends-On: Ib7d033a660fe294bf3f7b42e4aa7020149ce24c1
",git fetch https://review.opendev.org/openstack/heat refs/changes/32/340932/1 && git format-patch -1 --stdout FETCH_HEAD,['heat_integrationtests/functional/test_resource_group.py'],1,b473a8a0b47c908c6df4a8dec84c1560202f5d03,bp/files-show," self.assertEqual(files1, self.client.stacks.files(stack_identifier)) self.assertEqual(files2, self.client.stacks.files(stack_identifier))",,2,0
openstack%2Fmurano~master~I6d1d8c99aecf10567608d0c96de69a5309e706e3,openstack/murano,master,I6d1d8c99aecf10567608d0c96de69a5309e706e3,Install all dashboard/panel files from murano-dashboard,MERGED,2016-08-22 17:40:27.000000000,2016-08-29 13:09:46.000000000,2016-08-29 13:09:46.000000000,"[{'_account_id': 3}, {'_account_id': 7535}, {'_account_id': 7821}, {'_account_id': 13149}, {'_account_id': 13323}, {'_account_id': 14107}, {'_account_id': 15168}, {'_account_id': 20364}, {'_account_id': 21649}]","[{'number': 1, 'created': '2016-08-22 17:40:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/f21ed0c20958983e8bc47672a095ad38bce11713', 'message': '[devstack] Install all dashboard/panel files from murano-dashboard\n\nPreviously murano only had _50_murano.py dashboard file. This is about\nto change, to allow more granular configuration of murano and\napp-catalog panels/dashboards. This commit prepares devstack to\naccommodate upcoming change.\n\nTargets bp: catalog-dashboard-reorg\n\nChange-Id: I6d1d8c99aecf10567608d0c96de69a5309e706e3\n'}, {'number': 2, 'created': '2016-08-23 14:46:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/893cdcb9d998927c7d786a09dc501c75f2a2fd2c', 'message': 'Install all dashboard/panel files from murano-dashboard\n\nPreviously murano only had _50_murano.py dashboard file. This is about\nto change, to allow more granular configuration of murano and\napp-catalog panels/dashboards. This commit prepares devstack to\naccommodate upcoming change.\nThis commit also rewrites install section of murano-dashboard, to group\nall copy commands under the same code block while also grouping pre/post\nNewton installation instructions and removing some of the redundant code\n(some of the local settings are already present in _50_murano.py in\nNewton)\n\nTargets bp: catalog-dashboard-reorg\n\nChange-Id: I6d1d8c99aecf10567608d0c96de69a5309e706e3\n'}, {'number': 3, 'created': '2016-08-26 13:13:10.000000000', 'files': ['doc/source/draft/admin-guide/deploy_murano/install_manually.rst', 'devstack/plugin.sh'], 'web_link': 'https://opendev.org/openstack/murano/commit/0d1c6bdaa950ea3f615a44557ec04728d464fb38', 'message': 'Install all dashboard/panel files from murano-dashboard\n\nPreviously murano only had _50_murano.py dashboard file. This is about\nto change, to allow more granular configuration of murano and\napp-catalog panels/dashboards. This commit prepares devstack to\naccommodate upcoming change.\nThis commit also rewrites install section of murano-dashboard, to group\nall copy commands under the same code block while also grouping pre/post\nNewton installation instructions and removing some of the redundant code\n(some of the local settings are already present in _50_murano.py in\nNewton)\n\nTargets bp: catalog-dashboard-reorg\n\nChange-Id: I6d1d8c99aecf10567608d0c96de69a5309e706e3\n'}]",2,358792,0d1c6bdaa950ea3f615a44557ec04728d464fb38,32,9,3,15168,,,0,"Install all dashboard/panel files from murano-dashboard

Previously murano only had _50_murano.py dashboard file. This is about
to change, to allow more granular configuration of murano and
app-catalog panels/dashboards. This commit prepares devstack to
accommodate upcoming change.
This commit also rewrites install section of murano-dashboard, to group
all copy commands under the same code block while also grouping pre/post
Newton installation instructions and removing some of the redundant code
(some of the local settings are already present in _50_murano.py in
Newton)

Targets bp: catalog-dashboard-reorg

Change-Id: I6d1d8c99aecf10567608d0c96de69a5309e706e3
",git fetch https://review.opendev.org/openstack/murano refs/changes/92/358792/3 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/draft/admin-guide/deploy_murano/install_manually.rst', 'devstack/plugin.sh']",2,f21ed0c20958983e8bc47672a095ad38bce11713,bp/catalog-dashboard-reorg, ln -sf $MURANO_DASHBOARD_DIR/muranodashboard/local/enabled/*.py $HORIZON_DIR/openstack_dashboard/local/enabled/, ln -sf $MURANO_DASHBOARD_DIR/muranodashboard/local/enabled/_50_murano.py $HORIZON_DIR/openstack_dashboard/local/enabled/,2,2
openstack%2Fmurano~master~I92c672ef14cf0a75a619b9d73865c49bf398fc91,openstack/murano,master,I92c672ef14cf0a75a619b9d73865c49bf398fc91,Replace functions 'Dict.get' and 'del' with 'Dict.pop',MERGED,2016-08-29 06:19:24.000000000,2016-08-29 13:09:40.000000000,2016-08-29 13:09:40.000000000,"[{'_account_id': 3}, {'_account_id': 7821}, {'_account_id': 14107}, {'_account_id': 15168}]","[{'number': 1, 'created': '2016-08-29 06:19:24.000000000', 'files': ['murano/common/server.py'], 'web_link': 'https://opendev.org/openstack/murano/commit/7f21be290d3590d146e79e1d383d38c71c721391', 'message': ""Replace functions 'Dict.get' and 'del' with 'Dict.pop'\n\nRefactoring code: Making 'report' dict to use single instruction: pop()\nrather than two instructions: get() and del, giving the codes a format\nthat carries through.\n\nTrivialFix\n\nChange-Id: I92c672ef14cf0a75a619b9d73865c49bf398fc91\n""}]",0,361879,7f21be290d3590d146e79e1d383d38c71c721391,9,4,1,20182,,,0,"Replace functions 'Dict.get' and 'del' with 'Dict.pop'

Refactoring code: Making 'report' dict to use single instruction: pop()
rather than two instructions: get() and del, giving the codes a format
that carries through.

TrivialFix

Change-Id: I92c672ef14cf0a75a619b9d73865c49bf398fc91
",git fetch https://review.opendev.org/openstack/murano refs/changes/79/361879/1 && git format-patch -1 --stdout FETCH_HEAD,['murano/common/server.py'],1,7f21be290d3590d146e79e1d383d38c71c721391,use_dict.pop, report['entity_id'] = report.pop('id'), report['entity_id'] = report['id'] del report['id'],1,2
openstack%2Fcliff~master~I6a53d294a730a71599211b4048d0383d563c2203,openstack/cliff,master,I6a53d294a730a71599211b4048d0383d563c2203,Fix command order,ABANDONED,2016-08-29 12:29:26.000000000,2016-08-29 13:02:11.000000000,,"[{'_account_id': 20354}, {'_account_id': 20424}, {'_account_id': 23372}]","[{'number': 1, 'created': '2016-08-29 12:29:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cliff/commit/5d5289f857a1ad151eff69731ad6b9f9181758db', 'message': ""Fix command order\n\nWhen there are two commands: one 'foo', that expect a positional\nargument, and a second command 'foo bar'. If the hash of the first\nis smaller than the hash of the second, the dict iteration\nwill insert it first to the cmd parsing list.\nWhen this happends, trying to enter the command 'foo bar' will\nenvoke the command 'foo' with position argument 'bar', and not\nthe scond command 'foo bar'.\nBy iterating over the dict in a sorted fashion, 'foo bar' will\nbe parsed before the 'foo' command and the right command will be\nenvoked.\n\nChange-Id: I6a53d294a730a71599211b4048d0383d563c2203\n""}, {'number': 2, 'created': '2016-08-29 12:42:50.000000000', 'files': ['cliff/commandmanager.py'], 'web_link': 'https://opendev.org/openstack/cliff/commit/6fa9ea8d44f2ea179fd951dc69dc36dbb87ad9b0', 'message': ""Fix command order\n\nWhen there are two commands: one 'foo', that expect a positional\nargument, and a second command 'foo bar'. If the hash of the first\nis smaller than the hash of the second, the dict iteration\nwill insert it first to the cmd parsing list.\nWhen this happends, trying to enter the command 'foo bar' will\nenvoke the command 'foo' with position argument 'bar', and not\nthe second command 'foo bar'.\nBy iterating over the dict in a sorted fashion, 'foo bar' will\nbe parsed before the 'foo' command and the right command will be\nenvoked.\n\nChange-Id: I6a53d294a730a71599211b4048d0383d563c2203\n""}]",7,362073,6fa9ea8d44f2ea179fd951dc69dc36dbb87ad9b0,12,3,2,20424,,,0,"Fix command order

When there are two commands: one 'foo', that expect a positional
argument, and a second command 'foo bar'. If the hash of the first
is smaller than the hash of the second, the dict iteration
will insert it first to the cmd parsing list.
When this happends, trying to enter the command 'foo bar' will
envoke the command 'foo' with position argument 'bar', and not
the second command 'foo bar'.
By iterating over the dict in a sorted fashion, 'foo bar' will
be parsed before the 'foo' command and the right command will be
envoked.

Change-Id: I6a53d294a730a71599211b4048d0383d563c2203
",git fetch https://review.opendev.org/openstack/cliff refs/changes/73/362073/2 && git format-patch -1 --stdout FETCH_HEAD,['cliff/commandmanager.py'],1,5d5289f857a1ad151eff69731ad6b9f9181758db,," if name in sorted(self.commands, key=len, reverse=True):", if name in self.commands:,1,1
openstack%2Fcinder~master~I321f8339033b5a2f42edf42ec72f529baaec0365,openstack/cinder,master,I321f8339033b5a2f42edf42ec72f529baaec0365,Resize ploop disk from glance,ABANDONED,2016-07-14 18:15:18.000000000,2016-08-29 13:01:19.000000000,,"[{'_account_id': 3}, {'_account_id': 4523}, {'_account_id': 9008}, {'_account_id': 9732}, {'_account_id': 10621}, {'_account_id': 10622}, {'_account_id': 12017}, {'_account_id': 12032}, {'_account_id': 12033}, {'_account_id': 12369}, {'_account_id': 12408}, {'_account_id': 12778}, {'_account_id': 12822}, {'_account_id': 13394}, {'_account_id': 14384}, {'_account_id': 14797}, {'_account_id': 15249}, {'_account_id': 15296}, {'_account_id': 15374}, {'_account_id': 15386}, {'_account_id': 15847}, {'_account_id': 15941}, {'_account_id': 16269}, {'_account_id': 16595}, {'_account_id': 16660}, {'_account_id': 16834}, {'_account_id': 16862}, {'_account_id': 16897}, {'_account_id': 16898}, {'_account_id': 16941}, {'_account_id': 17852}, {'_account_id': 18120}, {'_account_id': 18402}, {'_account_id': 18444}, {'_account_id': 18752}, {'_account_id': 19146}, {'_account_id': 19852}, {'_account_id': 19933}, {'_account_id': 21193}, {'_account_id': 21863}, {'_account_id': 21976}, {'_account_id': 22126}, {'_account_id': 22510}]","[{'number': 1, 'created': '2016-07-14 18:15:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/15a06264ac452bf4ec1706c869dc811a16c6d610', 'message': ""Resize ploop disk from glance\n\nVirtuozzo doesn't allow to resize filesystem inside container.\nSo we can't use cloud init and we should resize filesystem after\nwe copy image from glance to LVM. If we don't do this, then\nwe see the available disk space equal to the space of the original\nimage from glance.\nPloop disks always have only one partition and GPT table.\nSo we resize first partition to the end of disk.\n\nChange-Id: I321f8339033b5a2f42edf42ec72f529baaec0365\n""}, {'number': 2, 'created': '2016-07-15 13:48:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/0b240f910885baee91c0333a9e9221beec9f3bc8', 'message': ""Resize ploop disk from glance\n\nVirtuozzo doesn't allow to resize filesystem inside container.\nSo we can't use cloud init and we should resize filesystem after\nwe copy image from glance to LVM. If we don't do this, then\nwe see the available disk space equal to the space of the original\nimage from glance.\nPloop disks always have only one partition and GPT table.\nSo we resize first partition to the end of disk.\n\nChange-Id: I321f8339033b5a2f42edf42ec72f529baaec0365\n""}, {'number': 3, 'created': '2016-08-08 14:24:05.000000000', 'files': ['etc/cinder/rootwrap.d/volume.filters', 'cinder/exception.py', 'cinder/tests/unit/volume/drivers/test_lvm_driver.py', 'cinder/volume/drivers/lvm.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/8ee56bba9706c65d35bec974270e5cc4ff534498', 'message': ""Resize ploop disk from glance\n\nVirtuozzo doesn't allow to resize filesystem inside container.\nSo we can't use cloud init and we should resize filesystem after\nwe copy image from glance to LVM. If we don't do this, then\nwe see the available disk space equal to the space of the original\nimage from glance.\nPloop disks always have only one partition and GPT table.\nSo we resize first partition to the end of disk.\n\nChange-Id: I321f8339033b5a2f42edf42ec72f529baaec0365\n""}]",1,342328,8ee56bba9706c65d35bec974270e5cc4ff534498,77,43,3,15847,,,0,"Resize ploop disk from glance

Virtuozzo doesn't allow to resize filesystem inside container.
So we can't use cloud init and we should resize filesystem after
we copy image from glance to LVM. If we don't do this, then
we see the available disk space equal to the space of the original
image from glance.
Ploop disks always have only one partition and GPT table.
So we resize first partition to the end of disk.

Change-Id: I321f8339033b5a2f42edf42ec72f529baaec0365
",git fetch https://review.opendev.org/openstack/cinder refs/changes/28/342328/2 && git format-patch -1 --stdout FETCH_HEAD,"['etc/cinder/rootwrap.d/volume.filters', 'cinder/tests/unit/test_lvm_driver.py', 'cinder/exception.py', 'cinder/volume/drivers/lvm.py']",4,15a06264ac452bf4ec1706c869dc811a16c6d610,resize_ploop," def _get_partition_path(self, volume_path): out, _ = self._execute('lsblk', '-l', '-o', 'NAME', '-n', volume_path, run_as_root=True) lines = out.split('\n') if len(lines) < 2: raise exception.InvalidVolumeInfo(volume_path) return os.path.join(os.path.dirname(volume_path), lines[1]) def _do_resize_partition(self, volume_path, size): partition_path = None try: self._execute('sgdisk', '-e', volume_path, run_as_root=True) self._execute('parted', '-s', volume_path, 'resizepart', '1', str(size) + 'G', run_as_root=True) partition_path = self._get_partition_path(volume_path) self._execute('e2fsck', '-p', '-f', partition_path, run_as_root=True) self._execute('resize2fs', partition_path, run_as_root=True) except processutils.ProcessExecutionError as exc: raise exception.VolumeResizeException(message=exc.stderr) finally: if partition_path is not None: self._execute('dmsetup', 'remove', partition_path, run_as_root=True) image_meta = image_service.show(context, image_id) if image_meta['disk_format'] == 'ploop': self._do_resize_partition(self.local_path(volume), volume['size']) ",,188,0
openstack%2Fmurano-apps~stable%2Fmitaka~Ie7e5c4aea3b0cee519ae5ed81cff0dcc3ab67562,openstack/murano-apps,stable/mitaka,Ie7e5c4aea3b0cee519ae5ed81cff0dcc3ab67562,[K8s] Fixing patchService.sh,MERGED,2016-08-29 08:09:52.000000000,2016-08-29 13:01:09.000000000,2016-08-29 13:01:09.000000000,"[{'_account_id': 3}, {'_account_id': 6577}, {'_account_id': 13149}]","[{'number': 1, 'created': '2016-08-29 08:09:52.000000000', 'files': ['Docker/Kubernetes/KubernetesCluster/package/Resources/scripts/patchService.sh'], 'web_link': 'https://opendev.org/openstack/murano-apps/commit/ebba7abe287b8199605239abcb977d926e3bd785', 'message': ""[K8s] Fixing patchService.sh\n\n * Since update command is replaced by replace here\n   https://review.openstack.org/#/c/358661/\n   for patching the resource it needs to use\n   'kubectl patch <type> <name> --patch <patch>'\n\nChange-Id: Ie7e5c4aea3b0cee519ae5ed81cff0dcc3ab67562\n(cherry picked from commit 94734974c62102cb4272cc75ce72b8ed039e83ef)\n""}]",0,361926,ebba7abe287b8199605239abcb977d926e3bd785,9,3,1,7700,,,0,"[K8s] Fixing patchService.sh

 * Since update command is replaced by replace here
   https://review.openstack.org/#/c/358661/
   for patching the resource it needs to use
   'kubectl patch <type> <name> --patch <patch>'

Change-Id: Ie7e5c4aea3b0cee519ae5ed81cff0dcc3ab67562
(cherry picked from commit 94734974c62102cb4272cc75ce72b8ed039e83ef)
",git fetch https://review.opendev.org/openstack/murano-apps refs/changes/26/361926/1 && git format-patch -1 --stdout FETCH_HEAD,['Docker/Kubernetes/KubernetesCluster/package/Resources/scripts/patchService.sh'],1,ebba7abe287b8199605239abcb977d926e3bd785,k8s_fix_patch,"/opt/bin/kubectl patch service ""$1"" --patch=""$2""","/opt/bin/kubectl replace service ""$1"" --patch=""$2""",1,1
openstack%2Fmurano~master~I0f12f15e4def84550ef5bde0840006211cac7809,openstack/murano,master,I0f12f15e4def84550ef5bde0840006211cac7809,TrivialFix: Remove cfg import unused,MERGED,2016-08-29 02:37:49.000000000,2016-08-29 12:53:28.000000000,2016-08-29 12:53:28.000000000,"[{'_account_id': 3}, {'_account_id': 7821}, {'_account_id': 14107}, {'_account_id': 15168}]","[{'number': 1, 'created': '2016-08-29 02:37:49.000000000', 'files': ['murano/api/middleware/version_negotiation.py', 'murano/tests/unit/cmd/test_api_workers.py', 'murano/engine/system/test_fixture.py', 'murano/db/catalog/api.py', 'murano/tests/unit/cmd/test_engine_workers.py', 'murano/api/versions.py', 'murano/policy/model_policy_enforcer.py'], 'web_link': 'https://opendev.org/openstack/murano/commit/688dcd0f884391401f3aa287fb391bdb24874dfc', 'message': 'TrivialFix: Remove cfg import unused\n\nThis patch removes cfg import unused in\nmurano/api/middleware/version_negotiation.py\nmurano/api/versions.py\nmurano/db/catalog/api.py\nmurano/engine/system/test_fixture.py\nmurano/policy/model_policy_enforcer.py\nmurano/tests/unit/cmd/test_api_workers.py\nmurano/tests/unit/cmd/test_engine_workers.py\n\nChange-Id: I0f12f15e4def84550ef5bde0840006211cac7809\n'}]",0,361798,688dcd0f884391401f3aa287fb391bdb24874dfc,9,4,1,15905,,,0,"TrivialFix: Remove cfg import unused

This patch removes cfg import unused in
murano/api/middleware/version_negotiation.py
murano/api/versions.py
murano/db/catalog/api.py
murano/engine/system/test_fixture.py
murano/policy/model_policy_enforcer.py
murano/tests/unit/cmd/test_api_workers.py
murano/tests/unit/cmd/test_engine_workers.py

Change-Id: I0f12f15e4def84550ef5bde0840006211cac7809
",git fetch https://review.opendev.org/openstack/murano refs/changes/98/361798/1 && git format-patch -1 --stdout FETCH_HEAD,"['murano/api/middleware/version_negotiation.py', 'murano/tests/unit/cmd/test_api_workers.py', 'murano/engine/system/test_fixture.py', 'murano/db/catalog/api.py', 'murano/tests/unit/cmd/test_engine_workers.py', 'murano/api/versions.py', 'murano/policy/model_policy_enforcer.py']",7,688dcd0f884391401f3aa287fb391bdb24874dfc,bug/remove-cfg-unused,,from oslo_config import cfgCONF = cfg.CONF,0,22
openstack%2Fproject-config~master~I5bfdb9211dc339f7ebb5ad154d3cf4dd86bb0a10,openstack/project-config,master,I5bfdb9211dc339f7ebb5ad154d3cf4dd86bb0a10,Fix BASE=/afs/.openstack.org/mirror/debian-openstack,MERGED,2016-08-29 09:55:51.000000000,2016-08-29 12:50:55.000000000,2016-08-29 12:50:55.000000000,"[{'_account_id': 3}, {'_account_id': 4162}, {'_account_id': 12841}]","[{'number': 1, 'created': '2016-08-29 09:55:51.000000000', 'files': ['jenkins/jobs/packaging-mirror.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/034cd887b0049bae40b2ea97fb7636ce1d32ae90', 'message': 'Fix BASE=/afs/.openstack.org/mirror/debian-openstack\n\nLast patch from Paul has wrong path.\n\nChange-Id: I5bfdb9211dc339f7ebb5ad154d3cf4dd86bb0a10\n'}]",0,361977,034cd887b0049bae40b2ea97fb7636ce1d32ae90,7,3,1,6476,,,0,"Fix BASE=/afs/.openstack.org/mirror/debian-openstack

Last patch from Paul has wrong path.

Change-Id: I5bfdb9211dc339f7ebb5ad154d3cf4dd86bb0a10
",git fetch https://review.opendev.org/openstack/project-config refs/changes/77/361977/1 && git format-patch -1 --stdout FETCH_HEAD,['jenkins/jobs/packaging-mirror.yaml'],1,034cd887b0049bae40b2ea97fb7636ce1d32ae90,, BASE=/afs/.openstack.org/mirror/debian-openstack, BASE=/afs/.openstack.org/mirror/deb-openstack,1,1
openstack%2Fpython-openstackclient~master~I84545bf46acfccc9dde3e85020700edb5a8375a6,openstack/python-openstackclient,master,I84545bf46acfccc9dde3e85020700edb5a8375a6,Fix six typos,MERGED,2016-08-25 10:54:35.000000000,2016-08-29 12:49:43.000000000,2016-08-29 12:49:43.000000000,"[{'_account_id': 3}, {'_account_id': 6482}, {'_account_id': 14937}]","[{'number': 1, 'created': '2016-08-25 10:54:35.000000000', 'files': ['doc/source/plugins.rst', 'doc/source/command-objects/volume-qos.rst', 'doc/source/commands.rst', 'doc/source/command-options.rst'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/c97e8187fef91627a1c55236a45eb5b1b8d92fc2', 'message': 'Fix six typos\n\ndisassoiate => disassociate\nnmaes       => names\nmutiually   => mutually\naviod       => avoid\nCLustering  => Clustering\navailble    => available\n\nChange-Id: I84545bf46acfccc9dde3e85020700edb5a8375a6\n'}]",0,360429,c97e8187fef91627a1c55236a45eb5b1b8d92fc2,7,3,1,17207,,,0,"Fix six typos

disassoiate => disassociate
nmaes       => names
mutiually   => mutually
aviod       => avoid
CLustering  => Clustering
availble    => available

Change-Id: I84545bf46acfccc9dde3e85020700edb5a8375a6
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/29/360429/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/command-objects/volume-qos.rst', 'doc/source/plugins.rst', 'doc/source/commands.rst', 'doc/source/command-options.rst']",4,c97e8187fef91627a1c55236a45eb5b1b8d92fc2,fix_typos," * Some global options may have short names, generally limited to those defineda mutually exclusive group, rather than the more common configuration ofRequired options must be validated by the CLI to avoid omissions. The CLI"," * Some global options may have short nmaes, generally limited to those defineda mutiually exclusive group, rather than the more common configuration ofRequired options must be validated by the CLI to aviod omissions. The CLI",6,6
openstack%2Ffuel-docs~master~I25ebf99722d7983e90d1c12f5530d764f5abce35,openstack/fuel-docs,master,I25ebf99722d7983e90d1c12f5530d764f5abce35,[RN] Add a note about Murano plugin,MERGED,2016-08-18 13:20:09.000000000,2016-08-29 12:43:51.000000000,2016-08-29 12:37:41.000000000,"[{'_account_id': 3}, {'_account_id': 7225}, {'_account_id': 8971}, {'_account_id': 14643}, {'_account_id': 14947}, {'_account_id': 14962}, {'_account_id': 15168}, {'_account_id': 17626}]","[{'number': 1, 'created': '2016-08-18 13:20:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/c6cd69692f0ef9af7bf989351b7f140c04fe482a', 'message': '[RN] Add a note about Murano plugin\n\nAdds a note about the Murano plugin to the release notes.\nRemoves Murano from the Install additional components section.\n\nChange-Id: I25ebf99722d7983e90d1c12f5530d764f5abce35\n'}, {'number': 2, 'created': '2016-08-29 09:28:51.000000000', 'files': ['userdocs/release-notes/new_features.rst', 'userdocs/fuel-user-guide/install-additional-components.rst'], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/c917b6fe303eb786eb4881e06296709b1ad5ac3b', 'message': '[RN] Add a note about Murano plugin\n\nAdds a note about the Murano plugin to the release notes.\nRemoves Murano from the Install additional components section.\n\nChange-Id: I25ebf99722d7983e90d1c12f5530d764f5abce35\n'}]",4,357208,c917b6fe303eb786eb4881e06296709b1ad5ac3b,28,8,2,14947,,,0,"[RN] Add a note about Murano plugin

Adds a note about the Murano plugin to the release notes.
Removes Murano from the Install additional components section.

Change-Id: I25ebf99722d7983e90d1c12f5530d764f5abce35
",git fetch https://review.opendev.org/openstack/fuel-docs refs/changes/08/357208/1 && git format-patch -1 --stdout FETCH_HEAD,"['userdocs/release-notes/new_features.rst', 'userdocs/fuel-user-guide/install-additional-components.rst']",2,c6cd69692f0ef9af7bf989351b7f140c04fe482a,rn_murano,"If you want to install additional components, such as the Telemetry service (Ceilometer), the Bare Metal service (Ironic), or the Hadoop cluster (Sahara), you must select a corresponding checkbox in the deployment wizard. However, some components require additional configuration before installation. This section describes the installation process for the OpenStack programs that require additional attention.","If you want to install additional components, such as the OpenStack Application Catalog service (Murano), the Telemetry service (Ceilometer), the Bare Metal service (Ironic), or the Hadoop cluster (Sahara), you must select a corresponding checkbox in the deployment wizard. However, some components require additional configuration before installation. This section describes the installation process for the OpenStack programs that require additional attention.",14,8
openstack%2Fsahara-dashboard~master~I22790e0a57f083d5d3712293555d20adc05bf634,openstack/sahara-dashboard,master,I22790e0a57f083d5d3712293555d20adc05bf634,Replace dict.iteritems() with dict.items(),ABANDONED,2016-08-29 12:33:19.000000000,2016-08-29 12:43:31.000000000,,"[{'_account_id': 12038}, {'_account_id': 22689}]","[{'number': 1, 'created': '2016-08-29 12:33:19.000000000', 'files': ['sahara_dashboard/content/data_processing/jobs/job_templates/workflows/launch.py', 'sahara_dashboard/content/data_processing/utils/workflow_helpers.py', 'sahara_dashboard/content/data_processing/data_plugins/tabs.py', 'sahara_dashboard/content/data_processing/data_plugins/workflows/update.py'], 'web_link': 'https://opendev.org/openstack/sahara-dashboard/commit/f779433397fcb5c361a98fc466d35676a1c4164e', 'message': 'Replace dict.iteritems() with dict.items()\n\nAccording to [1], replacing dict.iteritems() with dict.items()\nbecome a common pattern in Python 3, dict.iterms() returns an\niterator on all items(key/value pairs) in dict.\nIn Python 2 using dict.items(), the overload of creating a temporary\nlist is negligible. Test refers to link [2].\n[1]: https://wiki.openstack.org/wiki/Python3\n[2]: http://lists.openstack.org/pipermail/openstack-dev/2015-June/066391.html\n\nChange-Id: I22790e0a57f083d5d3712293555d20adc05bf634\n'}]",0,362077,f779433397fcb5c361a98fc466d35676a1c4164e,4,2,1,22689,,,0,"Replace dict.iteritems() with dict.items()

According to [1], replacing dict.iteritems() with dict.items()
become a common pattern in Python 3, dict.iterms() returns an
iterator on all items(key/value pairs) in dict.
In Python 2 using dict.items(), the overload of creating a temporary
list is negligible. Test refers to link [2].
[1]: https://wiki.openstack.org/wiki/Python3
[2]: http://lists.openstack.org/pipermail/openstack-dev/2015-June/066391.html

Change-Id: I22790e0a57f083d5d3712293555d20adc05bf634
",git fetch https://review.opendev.org/openstack/sahara-dashboard refs/changes/77/362077/1 && git format-patch -1 --stdout FETCH_HEAD,"['sahara_dashboard/content/data_processing/jobs/job_templates/workflows/launch.py', 'sahara_dashboard/content/data_processing/utils/workflow_helpers.py', 'sahara_dashboard/content/data_processing/data_plugins/tabs.py', 'sahara_dashboard/content/data_processing/data_plugins/workflows/update.py']",4,f779433397fcb5c361a98fc466d35676a1c4164e,," for name, label in labels.items(): for name, item in data.items(): for item, item_value in context.items():","import six for name, label in six.iteritems(labels): for name, item in six.iteritems(data): for item, item_value in six.iteritems(context):",9,12
openstack%2Ffuel-qa~master~Id5bb55faf34350cb4d7ae49ffaf62f5996a0a168,openstack/fuel-qa,master,Id5bb55faf34350cb4d7ae49ffaf62f5996a0a168,Temporary: flag check_tasks is set to False,MERGED,2016-05-11 10:31:11.000000000,2016-08-29 12:42:43.000000000,2016-05-12 05:43:10.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 7935}, {'_account_id': 8882}, {'_account_id': 8971}, {'_account_id': 9977}, {'_account_id': 10136}, {'_account_id': 11081}, {'_account_id': 11969}, {'_account_id': 12867}, {'_account_id': 13505}, {'_account_id': 16106}, {'_account_id': 16819}, {'_account_id': 19119}, {'_account_id': 20519}]","[{'number': 1, 'created': '2016-05-11 10:31:11.000000000', 'files': ['fuelweb_test/models/fuel_web_client.py'], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/752d9c556c9987815d43e7d93d9bf8212b5da851', 'message': 'Temporary: flag check_tasks is set to False\n\nRelated-bug: #1578218\nRelated-bug: #1578257\nChange-Id: Id5bb55faf34350cb4d7ae49ffaf62f5996a0a168\n'}]",0,314954,752d9c556c9987815d43e7d93d9bf8212b5da851,19,15,1,19119,,,0,"Temporary: flag check_tasks is set to False

Related-bug: #1578218
Related-bug: #1578257
Change-Id: Id5bb55faf34350cb4d7ae49ffaf62f5996a0a168
",git fetch https://review.opendev.org/openstack/fuel-qa refs/changes/54/314954/1 && git format-patch -1 --stdout FETCH_HEAD,['fuelweb_test/models/fuel_web_client.py'],1,752d9c556c9987815d43e7d93d9bf8212b5da851,bug/1578218,"from warnings import warn check_services=True, check_tasks=False): warn_txt = ('Temporary: flag check_tasks is set to False, ' 'until bugs LP#1578218 and LP#1578257 fixed') logger.warning(warn_txt) warn(warn_txt, UserWarning) "," check_services=True, check_tasks=True):",7,1
openstack%2Ftripleo-common~master~I8b6d8de8d7662604cdb871fa6a4fb872c7937e25,openstack/tripleo-common,master,I8b6d8de8d7662604cdb871fa6a4fb872c7937e25,Exclude more unneeded files from default plan,MERGED,2016-08-15 13:42:11.000000000,2016-08-29 12:40:56.000000000,2016-08-29 12:40:56.000000000,"[{'_account_id': 3}, {'_account_id': 4328}, {'_account_id': 4978}, {'_account_id': 8532}, {'_account_id': 9317}, {'_account_id': 9712}, {'_account_id': 10239}, {'_account_id': 17888}]","[{'number': 1, 'created': '2016-08-15 13:42:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/2ed727b4136ca3a4ce25782357c16da642573757', 'message': 'Exclude more unneeded files from default plan\n\nThis patch exludes more file types from the tarball uploaded to swift as\nthe default deployment plan.\n\nChange-Id: I8b6d8de8d7662604cdb871fa6a4fb872c7937e25\nCloses-Bug: #1613286\n'}, {'number': 2, 'created': '2016-08-23 15:52:51.000000000', 'files': ['tripleo_common/utils/tarball.py'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/b82fc6f21245cba7fadb35a6676433f015aad516', 'message': 'Exclude more unneeded files from default plan\n\nThis patch exludes more file types from the tarball uploaded to swift as\nthe default deployment plan.\n\nChange-Id: I8b6d8de8d7662604cdb871fa6a4fb872c7937e25\nCloses-Bug: #1613286\n'}]",2,355472,b82fc6f21245cba7fadb35a6676433f015aad516,17,8,2,17888,,,0,"Exclude more unneeded files from default plan

This patch exludes more file types from the tarball uploaded to swift as
the default deployment plan.

Change-Id: I8b6d8de8d7662604cdb871fa6a4fb872c7937e25
Closes-Bug: #1613286
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/72/355472/1 && git format-patch -1 --stdout FETCH_HEAD,['tripleo_common/utils/tarball.py'],1,2ed727b4136ca3a4ce25782357c16da642573757,bug/1613286," '--exclude', '.git', '--exclude', '.tox', '--exclude', '*.py', '--exclude', '*.pyc', '--exclude', '*.pyo', '--exclude', '*.pp', '--exclude', '*.sh', '.')"," '--exclude', '.git', '--exclude', '.tox', '.')",4,1
openstack%2Fcloudkitty~master~I4fe27a07e369728396d440b6b2f3462ee74d5f4d,openstack/cloudkitty,master,I4fe27a07e369728396d440b6b2f3462ee74d5f4d,Fix db api with hash rating,MERGED,2016-08-25 03:45:23.000000000,2016-08-29 12:37:30.000000000,2016-08-29 12:37:30.000000000,"[{'_account_id': 3}, {'_account_id': 2376}, {'_account_id': 7923}, {'_account_id': 9642}, {'_account_id': 23173}]","[{'number': 1, 'created': '2016-08-25 03:45:23.000000000', 'files': ['cloudkitty/rating/hash/db/sqlalchemy/api.py', 'cloudkitty/tests/test_hashmap.py'], 'web_link': 'https://opendev.org/openstack/cloudkitty/commit/bf3947982237b756be03621bf4f101e108a89962', 'message': 'Fix db api with hash rating\n\nFix the logic of specify either service_uuid, field_uuid\nor group_uuid when list_thresholds and list_mappings.\nAnd add the corresponding test cases.\n\nChange-Id: I4fe27a07e369728396d440b6b2f3462ee74d5f4d\nCloses-bug: #1615941\n'}]",0,360208,bf3947982237b756be03621bf4f101e108a89962,9,5,1,8358,,,0,"Fix db api with hash rating

Fix the logic of specify either service_uuid, field_uuid
or group_uuid when list_thresholds and list_mappings.
And add the corresponding test cases.

Change-Id: I4fe27a07e369728396d440b6b2f3462ee74d5f4d
Closes-bug: #1615941
",git fetch https://review.opendev.org/openstack/cloudkitty refs/changes/08/360208/1 && git format-patch -1 --stdout FETCH_HEAD,"['cloudkitty/rating/hash/db/sqlalchemy/api.py', 'cloudkitty/tests/test_hashmap.py']",2,bf3947982237b756be03621bf4f101e108a89962,bug/1615941," def test_list_mappings_from_only_group(self): service_db = self._db_api.create_service('compute') group_db = self._db_api.create_group('test_group') mapping_tiny = self._db_api.create_mapping( cost='1.337', map_type='flat', service_id=service_db.service_id, group_id=group_db.group_id) self._db_api.create_mapping( cost='42', map_type='flat', service_id=service_db.service_id) mappings = self._db_api.list_mappings(group_uuid=group_db.group_id) self.assertEqual([mapping_tiny.mapping_id], mappings) def test_list_thresholds_from_only_group(self): service_db = self._db_api.create_service('compute') group_db = self._db_api.create_group('test_group') threshold_db = self._db_api.create_threshold( level=10, cost='1.337', map_type='flat', service_id=service_db.service_id, group_id=group_db.group_id) thresholds = self._db_api.list_thresholds( group_uuid=group_db.group_id) self.assertEqual([threshold_db.threshold_id], thresholds) ",,31,2
openstack%2Fceilometer~master~I5257acc5eeace7f3ff38785223b1eaa7a3711d17,openstack/ceilometer,master,I5257acc5eeace7f3ff38785223b1eaa7a3711d17,API: add Keystone ACL and policy support,MERGED,2012-10-22 22:18:15.000000000,2016-08-29 12:37:17.000000000,2012-10-22 22:18:15.000000000,"[{'_account_id': 3}, {'_account_id': 595}, {'_account_id': 1669}, {'_account_id': 2472}, {'_account_id': 22752}]","[{'number': 1, 'created': '2012-10-22 22:18:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/a54a3bdd1e5c499b0d72e14bb2d1ed917c45c2c8', 'message': 'API: add Keystone ACL support\n\nThis fixes #1060919\n\nChange-Id: I5257acc5eeace7f3ff38785223b1eaa7a3711d17\nSigned-off-by: Julien Danjou <julien@danjou.info>\n'}, {'number': 2, 'created': '2012-10-22 22:18:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/bc80e4f4071f19e590099f72baf6cca56bd272bc', 'message': 'API: add Keystone ACL support\n\nThis fixes #1060919\n\nChange-Id: I5257acc5eeace7f3ff38785223b1eaa7a3711d17\nSigned-off-by: Julien Danjou <julien@danjou.info>\n'}, {'number': 3, 'created': '2012-10-22 22:18:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/a05cb887a7346e51a605215357bd190160cf1eb2', 'message': 'API: add Keystone ACL support\n\nThis fixes #1060919\n\nChange-Id: I5257acc5eeace7f3ff38785223b1eaa7a3711d17\nSigned-off-by: Julien Danjou <julien@danjou.info>\n'}, {'number': 4, 'created': '2012-10-22 22:18:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/42334af5d05e7bf97a912fde4f978dcb1959f311', 'message': 'API: add Keystone ACL and policy support\n\nThis fixes #1060919\n\nChange-Id: I5257acc5eeace7f3ff38785223b1eaa7a3711d17\nSigned-off-by: Julien Danjou <julien@danjou.info>\n'}, {'number': 5, 'created': '2012-10-22 22:18:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/f41bb4ed9da224098dc4888e633e0c92cbd82a93', 'message': 'API: add Keystone ACL and policy support\n\nThis fixes #1060919\n\nChange-Id: I5257acc5eeace7f3ff38785223b1eaa7a3711d17\nSigned-off-by: Julien Danjou <julien@danjou.info>\n'}, {'number': 6, 'created': '2012-10-22 22:18:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/b95dcca10b8430a16e0dc47d700001d84bf09d2c', 'message': 'API: add Keystone ACL and policy support\n\nThis fixes #1060919\n\nChange-Id: I5257acc5eeace7f3ff38785223b1eaa7a3711d17\nSigned-off-by: Julien Danjou <julien@danjou.info>\n'}, {'number': 7, 'created': '2012-10-22 22:18:15.000000000', 'files': ['tests/api/test_acl.py', 'etc/ceilometer/policy.json', 'tools/test-requires', 'ceilometer/api/acl.py', 'ceilometer/api/app.py', 'openstack-common.conf', 'tests/policy.json', 'ceilometer/policy.py', 'ceilometer/openstack/common/policy.py', 'ceilometer/utils.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/1f2f5dea5fef70fe688fab6bcd04f52eac89ca4c', 'message': 'API: add Keystone ACL and policy support\n\nThis fixes bug #1060919\n\nChange-Id: I5257acc5eeace7f3ff38785223b1eaa7a3711d17\nSigned-off-by: Julien Danjou <julien@danjou.info>\n'}]",4,13989,1f2f5dea5fef70fe688fab6bcd04f52eac89ca4c,27,5,7,1669,,,0,"API: add Keystone ACL and policy support

This fixes bug #1060919

Change-Id: I5257acc5eeace7f3ff38785223b1eaa7a3711d17
Signed-off-by: Julien Danjou <julien@danjou.info>
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/89/13989/1 && git format-patch -1 --stdout FETCH_HEAD,"['tests/api/test_acl.py', 'ceilometer/api/acl.py', 'ceilometer/api/app.py']",3,a54a3bdd1e5c499b0d72e14bb2d1ed917c45c2c8,bug/1060919,from ceilometer.api import acl acl.install(app),,120,0
openstack%2Fceilometer~master~Id68fe4945cf52e3c2c893c25671b871dafec7cdc,openstack/ceilometer,master,Id68fe4945cf52e3c2c893c25671b871dafec7cdc,remove database access from agent pollsters,ABANDONED,2012-11-02 02:47:58.000000000,2016-08-29 12:37:01.000000000,,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2472}, {'_account_id': 4277}, {'_account_id': 22752}]","[{'number': 5, 'created': '2012-11-02 02:47:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/2c74f2dc520558bad885b4addd1e2cc287d6c462', 'message': 'remove database access from agent pollsters\n\nfixes bug #1012242\n\nChange-Id: Id68fe4945cf52e3c2c893c25671b871dafec7cdc\n'}, {'number': 4, 'created': '2012-11-02 02:47:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/2b019db5d3e19ccfa2c3fbf03f2b7de9c60fc603', 'message': 'remove database access from agent pollsters\n\nfixes bug #1012242\n\nChange-Id: Id68fe4945cf52e3c2c893c25671b871dafec7cdc\n'}, {'number': 6, 'created': '2012-11-02 02:47:58.000000000', 'files': ['ceilometer/compute/nova_notifier.py', 'ceilometer/compute/libvirt.py', 'ceilometer/compute/manager.py', 'ceilometer/network/floatingip.py', 'tests/compute/test_nova_notifier.py', 'tests/network/test_floatingip.py', 'ceilometer/compute/instance.py', 'tests/compute/test_libvirt.py', 'tests/compute/test_instance.py', 'tests/compute/test_manager.py', 'tools/pip-requires', 'ceilometer/api/nova_client.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/35c75113d6871a2ba889b2b2b4307667586b9d76', 'message': 'remove database access from agent pollsters\n\nfixes bug #1012242\n\nChange-Id: Id68fe4945cf52e3c2c893c25671b871dafec7cdc\n'}, {'number': 1, 'created': '2012-11-02 02:47:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/ce59bd3eaa5b62071a02a7428deffe24cac27882', 'message': 'remove database access from agent pollsters\n\nfixes bug #1012242\n\nChange-Id: Id68fe4945cf52e3c2c893c25671b871dafec7cdc\n'}, {'number': 3, 'created': '2012-11-02 02:47:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/88efea93ed32f268da7c580633290610c91dfeaa', 'message': 'remove database access from agent pollsters\n\nfixes bug #1012242\n\nChange-Id: Id68fe4945cf52e3c2c893c25671b871dafec7cdc\n'}, {'number': 2, 'created': '2012-11-02 02:47:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/7797821d237c3b9e7decfcbf581c4fc6418812ba', 'message': 'remove database access from agent pollsters\n\nfixes bug #1012242\n\nChange-Id: Id68fe4945cf52e3c2c893c25671b871dafec7cdc\n'}]",13,14185,35c75113d6871a2ba889b2b2b4307667586b9d76,24,5,6,4277,,,0,"remove database access from agent pollsters

fixes bug #1012242

Change-Id: Id68fe4945cf52e3c2c893c25671b871dafec7cdc
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/85/14185/5 && git format-patch -1 --stdout FETCH_HEAD,"['ceilometer/compute/nova_notifier.py', 'ceilometer/compute/libvirt.py', 'ceilometer/compute/manager.py', 'ceilometer/network/floatingip.py', 'tests/compute/test_nova_notifier.py', 'tests/network/test_floatingip.py', 'ceilometer/compute/instance.py', 'tests/compute/test_libvirt.py', 'tests/compute/test_instance.py', 'tests/compute/test_manager.py', 'tools/pip-requires', 'ceilometer/api/nova_client.py']",12,2c74f2dc520558bad885b4addd1e2cc287d6c462,bug/1012242,"# -*- encoding: utf-8 -*- # # Author: John Tran <jhtran@att.com> # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import os from functools import wraps from novaclient.v1_1 import client as nova_client import ceilometer.service from ceilometer.openstack.common import cfg, log LOG = log.getLogger(__name__) def logged(func): @wraps(func) def with_logging(*args, **kwargs): try: return func(*args, **kwargs) except Exception, e: LOG.exception(e) raise return with_logging class Client(object): def __init__(self): """"""Returns nova client"""""" conf = cfg.CONF tenant = conf.os_tenant_id and conf.os_tenant_id or conf.os_tenant_name self.nova_client = nova_client.Client(username=cfg.CONF.os_username, api_key=cfg.CONF.os_password, project_id=tenant, auth_url=cfg.CONF.os_auth_url, no_cache=True) @logged def instance_get_all_by_host(self, hostname): """"""Returns list of instances on particular host"""""" search_opts = {'host': hostname, 'all_tenants': True} return self.nova_client.servers.list(detailed=True, search_opts=search_opts) @logged def floating_ip_get_all(self): """"""Returns all floating ips"""""" return self.nova_client.floating_ips.list() @logged def instance_get(self, instance_id): """"""Returns instance"""""" return self.nova_client.servers.get(instance_id) @logged def instance_get_by_uuid(self, uuid): """"""Returns instance by uuid"""""" try: return self.nova_client.servers.list(search_opts={'uuid': uuid})[0] except IndexError: return None ",,176,72
openstack%2Fhorizon~master~I5b73db259153eb28e7c3bd5259d5c99476694804,openstack/horizon,master,I5b73db259153eb28e7c3bd5259d5c99476694804,No lock required for reading secret key,MERGED,2016-04-19 14:56:21.000000000,2016-08-29 12:33:03.000000000,2016-08-29 12:33:03.000000000,"[{'_account_id': 3}, {'_account_id': 841}, {'_account_id': 4264}, {'_account_id': 8686}, {'_account_id': 12281}, {'_account_id': 12826}, {'_account_id': 14151}, {'_account_id': 17172}, {'_account_id': 20316}]","[{'number': 1, 'created': '2016-04-19 14:56:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/c29cbbb6d2ad24ae96b80e4b93b0a45245cf4447', 'message': 'No lock required for reading secret key\n\nChange-Id: I5b73db259153eb28e7c3bd5259d5c99476694804\nCloses-Bug: #1572187\n'}, {'number': 2, 'created': '2016-04-20 06:40:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/66c718c08a93a3bab02868b03e58a8d90b0d6d94', 'message': 'No lock required for reading secret key\n\nChange-Id: I5b73db259153eb28e7c3bd5259d5c99476694804\nCloses-Bug: #1572187\n'}, {'number': 3, 'created': '2016-04-27 21:06:34.000000000', 'files': ['horizon/utils/secret_key.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/3963f03f462aac92fa28d7cd224dc4db86ce9a95', 'message': 'No lock required for reading secret key\n\nChange-Id: I5b73db259153eb28e7c3bd5259d5c99476694804\nCloses-Bug: #1572187\n'}]",7,307859,3963f03f462aac92fa28d7cd224dc4db86ce9a95,37,9,3,4264,,,0,"No lock required for reading secret key

Change-Id: I5b73db259153eb28e7c3bd5259d5c99476694804
Closes-Bug: #1572187
",git fetch https://review.opendev.org/openstack/horizon refs/changes/59/307859/1 && git format-patch -1 --stdout FETCH_HEAD,['horizon/utils/secret_key.py'],1,c29cbbb6d2ad24ae96b80e4b93b0a45245cf4447,bug/1572187,"def read_from_file(key_file='.secret_key'): if (os.stat(key_file).st_mode & 0o777) != 0o600: raise FilePermissionError(""Insecure key file permissions!"") with open(key_file, 'r') as f: key = f.readline() return key # check, if key_file already exists # if yes, then just read and return key if os.path.exists(key_file): key = read_from_file(key_file) return key # otherwise, first lock to make sure only one process lock_path=os.path.dirname(abspath)) key = generate_key(key_length) old_umask = os.umask(0o177) # Use '0600' file permissions with open(key_file, 'w') as f: f.write(key) os.umask(old_umask) else: key = read_from_file(key_file)"," lock_path=os.path.dirname(abspath)) key = generate_key(key_length) old_umask = os.umask(0o177) # Use '0600' file permissions with open(key_file, 'w') as f: f.write(key) os.umask(old_umask) else: if (os.stat(key_file).st_mode & 0o777) != 0o600: raise FilePermissionError(""Insecure key file permissions!"") with open(key_file, 'r') as f: key = f.readline()",21,10
openstack%2Fdeb-auto-backports~debian%2Fnewton~Ie12f3009dbaff8281ecce01cdd53e08ee521e79b,openstack/deb-auto-backports,debian/newton,Ie12f3009dbaff8281ecce01cdd53e08ee521e79b,Build python-gitdb package,MERGED,2016-08-29 12:15:23.000000000,2016-08-29 12:32:17.000000000,2016-08-29 12:32:17.000000000,"[{'_account_id': 3}, {'_account_id': 6476}]","[{'number': 1, 'created': '2016-08-29 12:15:23.000000000', 'files': ['packages-list'], 'web_link': 'https://opendev.org/openstack/deb-auto-backports/commit/c0fb9c3c6f71b12f91ea866f3a88e7069dd4733d', 'message': 'Build python-gitdb package\n\nChange-Id: Ie12f3009dbaff8281ecce01cdd53e08ee521e79b\n'}]",0,362062,c0fb9c3c6f71b12f91ea866f3a88e7069dd4733d,6,2,1,12841,,,0,"Build python-gitdb package

Change-Id: Ie12f3009dbaff8281ecce01cdd53e08ee521e79b
",git fetch https://review.opendev.org/openstack/deb-auto-backports refs/changes/62/362062/1 && git format-patch -1 --stdout FETCH_HEAD,['packages-list'],1,c0fb9c3c6f71b12f91ea866f3a88e7069dd4733d,python-gitdb,python-gitdb,#python-gitdb,1,1
openstack%2Ftempest~master~I3bea364db266d90cc0fc19635e190807dfe980ac,openstack/tempest,master,I3bea364db266d90cc0fc19635e190807dfe980ac,skip get-me-a-network tests,MERGED,2016-08-24 15:02:42.000000000,2016-08-29 12:30:03.000000000,2016-08-24 16:46:31.000000000,"[{'_account_id': 3}, {'_account_id': 5196}, {'_account_id': 5263}, {'_account_id': 8871}, {'_account_id': 10385}]","[{'number': 1, 'created': '2016-08-24 15:02:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/595cc71e4dd97d2f4300c4f5498ed01ef278e7de', 'message': 'skip get-me-a-network tests\n\nThese have a really high fail rate right now and are blocking other\nchanges from landing.\n\nRelated-Bug: #1616498\n\nChange-Id: I3bea364db266d90cc0fc19635e190807dfe980ac\n'}, {'number': 2, 'created': '2016-08-24 15:03:13.000000000', 'files': ['tempest/api/compute/admin/test_auto_allocate_network.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/e87e612144003c6a05549fa345999ad8058ad94c', 'message': 'skip get-me-a-network tests\n\nThese have a really high fail rate right now and are blocking other\nchanges from landing.\n\nRelated-Bug: #1616498\n\nChange-Id: I3bea364db266d90cc0fc19635e190807dfe980ac\n'}]",1,359939,e87e612144003c6a05549fa345999ad8058ad94c,14,5,2,2750,,,0,"skip get-me-a-network tests

These have a really high fail rate right now and are blocking other
changes from landing.

Related-Bug: #1616498

Change-Id: I3bea364db266d90cc0fc19635e190807dfe980ac
",git fetch https://review.opendev.org/openstack/tempest refs/changes/39/359939/1 && git format-patch -1 --stdout FETCH_HEAD,['tempest/api/compute/admin/test_auto_allocate_network.py'],1,595cc71e4dd97d2f4300c4f5498ed01ef278e7de,auto_allocate_fail," cls.skipException(""Disabled until bug #1616498 is fixed"")",,1,0
openstack%2Fproject-config~master~Ic6f022a9d311280e19c729fbaeb37475f1352ad4,openstack/project-config,master,Ic6f022a9d311280e19c729fbaeb37475f1352ad4,Fuel-qa & fuel-devops: gates changes,MERGED,2016-08-29 05:37:34.000000000,2016-08-29 12:28:51.000000000,2016-08-29 12:28:51.000000000,"[{'_account_id': 3}, {'_account_id': 1106}, {'_account_id': 6547}, {'_account_id': 11969}, {'_account_id': 15984}, {'_account_id': 19119}]","[{'number': 1, 'created': '2016-08-29 05:37:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/c19df347f06b11f2b7cafbcf10139f5c93f941fe', 'message': 'Fuel-qa & fuel-devops: gates changes\n\nChange-Id: Ic6f022a9d311280e19c729fbaeb37475f1352ad4\nFuel-qa: coverage on mitaka and upper (helpers refactor)\nFuel-devops: py35 enable voting\n'}, {'number': 2, 'created': '2016-08-29 05:55:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/c1448880ac2c7c69c3a16f212c8b3b5080ff1cf7', 'message': 'Fuel-qa & fuel-devops: gates changes\n\nChange-Id: Ic6f022a9d311280e19c729fbaeb37475f1352ad4\nFuel-qa: coverage on mitaka and upper (helpers refactor)\nFuel-devops: py35 enable voting\n'}, {'number': 3, 'created': '2016-08-29 06:10:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/06c4042b843e7208f58545d97a6c7c0658ccdfe0', 'message': 'Fuel-qa & fuel-devops: gates changes\n\nChange-Id: Ic6f022a9d311280e19c729fbaeb37475f1352ad4\nFuel-qa: coverage on mitaka and upper (helpers refactor)\nFuel-devops: py35 enable voting\n'}, {'number': 4, 'created': '2016-08-29 06:21:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/33f37a1308f33a728352205cbdc85ee37c5d6cc8', 'message': 'Fuel-qa & fuel-devops: gates changes\n\nChange-Id: Ic6f022a9d311280e19c729fbaeb37475f1352ad4\nFuel-qa: coverage on mitaka and upper (helpers refactor)\nFuel-devops: py35 enable voting\n'}, {'number': 5, 'created': '2016-08-29 06:45:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/4c39e7326f540c265ca09007691c2d15e28532e5', 'message': 'Fuel-qa & fuel-devops: gates changes\n\nChange-Id: Ic6f022a9d311280e19c729fbaeb37475f1352ad4\nFuel-qa: coverage on mitaka and upper (helpers refactor)\nFuel-devops: py35 enable voting\n'}, {'number': 6, 'created': '2016-08-29 06:57:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/7982fcc3f5d4ea18678de8ed0d6552801604ef95', 'message': 'Fuel-qa & fuel-devops: gates changes\n\nChange-Id: Ic6f022a9d311280e19c729fbaeb37475f1352ad4\nFuel-qa: coverage on mitaka and upper (helpers refactor)\nFuel-devops: py35 enable voting\n'}, {'number': 7, 'created': '2016-08-29 07:41:00.000000000', 'files': ['jenkins/jobs/projects.yaml', 'zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/c0c36a9a7b9a05cbf64715a166e19c39eb5573c5', 'message': 'Fuel-qa & fuel-devops: gates changes\n\nChange-Id: Ic6f022a9d311280e19c729fbaeb37475f1352ad4\nFuel-qa: coverage on mitaka and upper (helpers refactor)\nFuel-devops: py35 enable voting\n'}]",2,361843,c0c36a9a7b9a05cbf64715a166e19c39eb5573c5,23,6,7,19119,,,0,"Fuel-qa & fuel-devops: gates changes

Change-Id: Ic6f022a9d311280e19c729fbaeb37475f1352ad4
Fuel-qa: coverage on mitaka and upper (helpers refactor)
Fuel-devops: py35 enable voting
",git fetch https://review.opendev.org/openstack/project-config refs/changes/43/361843/7 && git format-patch -1 --stdout FETCH_HEAD,['zuul/layout.yaml'],1,c19df347f06b11f2b7cafbcf10139f5c93f941fe,, - name: ^fuel-qa-coverage-ubuntu-trusty branch: ^(stable/mitaka).*$ - name: ^fuel-qa-coverage-ubuntu-xenial branch: ^(?!stable(-mu)?/(?:4\.0|4\.1|5\.0|5\.1|6\.0|6\.1|7\.0|8\.0|mitaka)).*$ - name: python35-jobs - fuel-qa-coverage-ubuntu-trusty - fuel-qa-coverage-ubuntu-xenial - fuel-qa-coverage-ubuntu-trusty - fuel-qa-coverage-ubuntu-xenial, - name: python35-jobs-nv,11,1
openstack%2Frally~master~Iba7bde0ec1ce9caed41cc123c24d278e62c9d127,openstack/rally,master,Iba7bde0ec1ce9caed41cc123c24d278e62c9d127,TrivialFix: Remove logging import unused,MERGED,2016-08-29 02:50:19.000000000,2016-08-29 12:27:27.000000000,2016-08-29 12:27:27.000000000,"[{'_account_id': 3}, {'_account_id': 6172}, {'_account_id': 9545}]","[{'number': 1, 'created': '2016-08-29 02:50:19.000000000', 'files': ['rally/plugins/openstack/scenarios/monasca/metrics.py'], 'web_link': 'https://opendev.org/openstack/rally/commit/1fa327d6b8765bfbaa945cb206d9229f6f2cb56b', 'message': 'TrivialFix: Remove logging import unused\n\nThis patch removes logging import unused in\nrally/plugins/openstack/scenarios/monasca/metrics.py\n\nChange-Id: Iba7bde0ec1ce9caed41cc123c24d278e62c9d127\n'}]",0,361801,1fa327d6b8765bfbaa945cb206d9229f6f2cb56b,12,3,1,15905,,,0,"TrivialFix: Remove logging import unused

This patch removes logging import unused in
rally/plugins/openstack/scenarios/monasca/metrics.py

Change-Id: Iba7bde0ec1ce9caed41cc123c24d278e62c9d127
",git fetch https://review.opendev.org/openstack/rally refs/changes/01/361801/1 && git format-patch -1 --stdout FETCH_HEAD,['rally/plugins/openstack/scenarios/monasca/metrics.py'],1,1fa327d6b8765bfbaa945cb206d9229f6f2cb56b,bug/remove-logging-unused,,from rally.common import loggingLOG = logging.getLogger(__name__) ,0,3
openstack%2Fcinder~master~Ic4cb24b1573ab06a90ba47479f69468c4adc3dcb,openstack/cinder,master,Ic4cb24b1573ab06a90ba47479f69468c4adc3dcb,Fix db purge for quality_of_service_specs FK constraint,MERGED,2016-07-19 06:42:34.000000000,2016-08-29 12:26:25.000000000,2016-08-28 19:23:38.000000000,"[{'_account_id': 3}, {'_account_id': 1736}, {'_account_id': 5997}, {'_account_id': 7244}, {'_account_id': 9008}, {'_account_id': 10621}, {'_account_id': 11904}, {'_account_id': 12016}, {'_account_id': 12778}, {'_account_id': 12822}, {'_account_id': 13394}, {'_account_id': 13628}, {'_account_id': 14384}, {'_account_id': 14732}, {'_account_id': 14797}, {'_account_id': 15249}, {'_account_id': 15941}, {'_account_id': 16269}, {'_account_id': 16595}, {'_account_id': 16660}, {'_account_id': 16708}, {'_account_id': 16862}, {'_account_id': 16897}, {'_account_id': 16898}, {'_account_id': 16941}, {'_account_id': 17852}, {'_account_id': 18026}, {'_account_id': 18120}, {'_account_id': 18402}, {'_account_id': 18444}, {'_account_id': 19852}, {'_account_id': 21976}, {'_account_id': 22510}]","[{'number': 1, 'created': '2016-07-19 06:42:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/30a1f9b435dbab78f7120d1e58dca11d2ebee4c5', 'message': 'Fix db purge for quality_of_service_specs FK constraint\n\ndb purge command raises FK constraint while purging\n1. quality_of_service_specs because the ""id"" of\nquality_of_service_specs is used as reference key in\nsame table as ""specs_id"".\n2. volume_types and quality_of_service_specs\ndeleted rows\n\nDelete\n1. reference/child records first  before deleting\nthe parent record from quality_of_service_specs.\n2. volume_types records before deleting quality_of_service_specs\nto solve this issue.\n\nCloses-Bug: #1599830\nChange-Id: Ic4cb24b1573ab06a90ba47479f69468c4adc3dcb\n'}, {'number': 2, 'created': '2016-07-25 11:56:12.000000000', 'files': ['cinder/tests/unit/db/test_purge.py', 'cinder/db/sqlalchemy/api.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/b392f8a8f6d5a704bd4e1321e48894077230d2e3', 'message': 'Fix db purge for quality_of_service_specs FK constraint\n\ndb purge command raises FK constraint while purging\n1. quality_of_service_specs because the ""id"" of\nquality_of_service_specs is used as reference key in\nsame table as ""specs_id"".\n2. volume_types and quality_of_service_specs\ndeleted rows\n\nDelete\n1. reference/child records first  before deleting\nthe parent record from quality_of_service_specs.\n2. volume_types records before deleting quality_of_service_specs\nto solve this issue.\n\nCloses-Bug: #1599830\nChange-Id: Ic4cb24b1573ab06a90ba47479f69468c4adc3dcb\n'}]",0,344049,b392f8a8f6d5a704bd4e1321e48894077230d2e3,74,33,2,20182,,,0,"Fix db purge for quality_of_service_specs FK constraint

db purge command raises FK constraint while purging
1. quality_of_service_specs because the ""id"" of
quality_of_service_specs is used as reference key in
same table as ""specs_id"".
2. volume_types and quality_of_service_specs
deleted rows

Delete
1. reference/child records first  before deleting
the parent record from quality_of_service_specs.
2. volume_types records before deleting quality_of_service_specs
to solve this issue.

Closes-Bug: #1599830
Change-Id: Ic4cb24b1573ab06a90ba47479f69468c4adc3dcb
",git fetch https://review.opendev.org/openstack/cinder refs/changes/49/344049/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/tests/unit/db/test_purge.py', 'cinder/db/sqlalchemy/api.py']",2,30a1f9b435dbab78f7120d1e58dca11d2ebee4c5,bug/1599830," for table in (""volume_types"", ""quality_of_service_specs"", ""snapshots"", ""volumes""): # Delete child records first from quality_of_service_specs # table to avoid FK constraints if table == ""quality_of_service_specs"": session.query(models.QualityOfServiceSpecs).filter( and_(models.QualityOfServiceSpecs.specs_id.isnot( None), models.QualityOfServiceSpecs.deleted == 1, models.QualityOfServiceSpecs.deleted_at < deleted_age)).delete()"," for table in (""volume_types"", ""snapshots"", ""volumes""):",60,3
openstack%2Ftempest~master~Icb02364e3860305327d2ac5eabc3713340983933,openstack/tempest,master,Icb02364e3860305327d2ac5eabc3713340983933,Enroll fake ironic node to enable ironic-compute host,ABANDONED,2016-08-11 16:34:44.000000000,2016-08-29 12:24:42.000000000,,"[{'_account_id': 3}, {'_account_id': 6849}, {'_account_id': 10385}, {'_account_id': 14525}]","[{'number': 1, 'created': '2016-08-11 16:34:44.000000000', 'files': ['tempest/api/compute/admin/test_hosts.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/06adaee49c78eeb9136f632814d938067597b65a', 'message': 'Enroll fake ironic node to enable ironic-compute host\n\nChange-Id: Icb02364e3860305327d2ac5eabc3713340983933\nCloses-Bug: #1570864\n'}]",3,354209,06adaee49c78eeb9136f632814d938067597b65a,7,4,1,14614,,,0,"Enroll fake ironic node to enable ironic-compute host

Change-Id: Icb02364e3860305327d2ac5eabc3713340983933
Closes-Bug: #1570864
",git fetch https://review.opendev.org/openstack/tempest refs/changes/09/354209/1 && git format-patch -1 --stdout FETCH_HEAD,['tempest/api/compute/admin/test_hosts.py'],1,06adaee49c78eeb9136f632814d938067597b65a,bug/1570864," cls.ir_client = cls.os_admin.baremetal_client _, chassis = self.ir_client.create_chassis() _, node = self.ir_client.create_node(chassis['uuid']) self.addCleanup(self.ir_client.delete_node, node['uuid']) self.addCleanup(self.ir_client.delete_chassis, chassis['uuid']) self.wait_for(self.ir_client.show_node(node['uuid'])[1]) ",,8,0
openstack%2Fkarbor~master~If0499ec5e103263048d10b9ece4884dd0e2e9b38,openstack/karbor,master,If0499ec5e103263048d10b9ece4884dd0e2e9b38,Fix Fullstack's devstack,MERGED,2016-08-24 10:16:17.000000000,2016-08-29 12:22:52.000000000,2016-08-29 12:22:52.000000000,"[{'_account_id': 3}, {'_account_id': 2023}, {'_account_id': 11343}, {'_account_id': 17151}, {'_account_id': 19346}]","[{'number': 1, 'created': '2016-08-24 10:16:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/karbor/commit/6bde45ad1187131208fe61584db344a71896cff5', 'message': ""Fix Fullstack's devstack\n\nFix leftovers of fullstack's devstack\n\nChange-Id: If0499ec5e103263048d10b9ece4884dd0e2e9b38\n""}, {'number': 2, 'created': '2016-08-24 11:18:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/karbor/commit/49162a28087caeb13890be0c9ca351b22c968965', 'message': ""Fix Fullstack's devstack\n\nFix leftovers of fullstack's devstack\n\nChange-Id: If0499ec5e103263048d10b9ece4884dd0e2e9b38\n""}, {'number': 3, 'created': '2016-08-25 06:26:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/karbor/commit/b4327e8bca84bce9f2c0aac87ef93936397ca37a', 'message': ""Fix Fullstack's devstack\n\nFix leftovers of fullstack's devstack\n\nChange-Id: If0499ec5e103263048d10b9ece4884dd0e2e9b38\n""}, {'number': 4, 'created': '2016-08-25 08:40:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/karbor/commit/87e0a0584136be17e161f010b5c7b639981dda70', 'message': ""Fix Fullstack's devstack\n\nFix leftovers of fullstack's devstack\n\nChange-Id: If0499ec5e103263048d10b9ece4884dd0e2e9b38\n""}, {'number': 5, 'created': '2016-08-25 13:12:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/karbor/commit/0d0285823267c2ca645375b6180f381e26072088', 'message': ""Fix Fullstack's devstack\n\nFix leftovers of fullstack's devstack\n\nChange-Id: If0499ec5e103263048d10b9ece4884dd0e2e9b38\n""}, {'number': 6, 'created': '2016-08-25 14:03:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/karbor/commit/5d642f0365a4048309d1feda39fda32040ad0168', 'message': ""Fix Fullstack's devstack\n\nFix leftovers of fullstack's devstack\n\nChange-Id: If0499ec5e103263048d10b9ece4884dd0e2e9b38\n""}, {'number': 7, 'created': '2016-08-29 09:05:46.000000000', 'files': ['devstack/devstackgaterc', 'requirements.txt', 'karbor/tests/contrib/post_test_hook.sh', 'devstack/settings'], 'web_link': 'https://opendev.org/openstack/karbor/commit/5b311eea8b664ef1bbdba226f1059ebf15d79c58', 'message': ""Fix Fullstack's devstack\n\nFix leftovers of fullstack's devstack\n\nChange-Id: If0499ec5e103263048d10b9ece4884dd0e2e9b38\n""}]",0,359766,5b311eea8b664ef1bbdba226f1059ebf15d79c58,20,5,7,20883,,,0,"Fix Fullstack's devstack

Fix leftovers of fullstack's devstack

Change-Id: If0499ec5e103263048d10b9ece4884dd0e2e9b38
",git fetch https://review.opendev.org/openstack/karbor refs/changes/66/359766/3 && git format-patch -1 --stdout FETCH_HEAD,['devstack/devstackgaterc'],1,6bde45ad1187131208fe61584db344a71896cff5,fullstack-fix,"DEVSTACK_LOCAL_CONFIG+=""enable_plugin smaug git://git.openstack.org/openstack/smaug""","DEVSTACK_LOCAL_CONFIG+=""enable_plugin karbor git://git.openstack.org/openstack/smaug""",1,1
openstack%2Fneutron~master~Ib09516379ef5d48bf723a9ba098d90bf6bf5a0eb,openstack/neutron,master,Ib09516379ef5d48bf723a9ba098d90bf6bf5a0eb,TrunkStub.trunk_deleted is called with NULL trunk object,MERGED,2016-08-17 11:02:37.000000000,2016-08-29 12:21:58.000000000,2016-08-26 05:04:22.000000000,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 4187}, {'_account_id': 5170}, {'_account_id': 7448}, {'_account_id': 9845}, {'_account_id': 10385}, {'_account_id': 13770}, {'_account_id': 14208}, {'_account_id': 15752}, {'_account_id': 16376}, {'_account_id': 16800}]","[{'number': 1, 'created': '2016-08-17 11:02:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/c578a4aad56c23586e42eea8541547ff4dd335cc', 'message': ""TrunkStub.trunk_deleted is called with NULL trunk object\n\nOn AFTER_DELETE event, the trunk object is set in payload.original_trunk,\nbut this is not used for calling TrunkStub.trunk_deleted(), instead it is\ncalled with payload.current_trunk which is 'None'.\n\nCloses-bug: #1614059\nChange-Id: Ib09516379ef5d48bf723a9ba098d90bf6bf5a0eb\n""}, {'number': 2, 'created': '2016-08-18 07:33:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/eb5a9d4fcf23820cde4ce1b9586ca658df054360', 'message': ""TrunkStub.trunk_deleted is called with NULL trunk object\n\nOn AFTER_DELETE event, the trunk object is set in payload.original_trunk,\nbut this is not used for calling TrunkStub.trunk_deleted(), instead it is\ncalled with payload.current_trunk which is 'None'.\n\nCloses-bug: #1614059\nChange-Id: Ib09516379ef5d48bf723a9ba098d90bf6bf5a0eb\n""}, {'number': 3, 'created': '2016-08-19 05:03:16.000000000', 'files': ['neutron/tests/unit/services/trunk/rpc/test_backend.py', 'neutron/services/trunk/rpc/backend.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/c5629e9734f566aaf1692ed3ae016951a62bebe0', 'message': ""TrunkStub.trunk_deleted is called with NULL trunk object\n\nOn AFTER_DELETE event, the trunk object is set in payload.original_trunk,\nbut this is not used for calling TrunkStub.trunk_deleted(), instead it is\ncalled with payload.current_trunk which is 'None'.\n\nCloses-bug: #1614059\nChange-Id: Ib09516379ef5d48bf723a9ba098d90bf6bf5a0eb\n""}]",10,356386,c5629e9734f566aaf1692ed3ae016951a62bebe0,50,12,3,8298,,,0,"TrunkStub.trunk_deleted is called with NULL trunk object

On AFTER_DELETE event, the trunk object is set in payload.original_trunk,
but this is not used for calling TrunkStub.trunk_deleted(), instead it is
called with payload.current_trunk which is 'None'.

Closes-bug: #1614059
Change-Id: Ib09516379ef5d48bf723a9ba098d90bf6bf5a0eb
",git fetch https://review.opendev.org/openstack/neutron refs/changes/86/356386/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/services/trunk/rpc/backend.py'],1,c578a4aad56c23586e42eea8541547ff4dd335cc,bug/1614059," # On AFTER_DELETE event, current_trunk will not be set payload = payload.current_trunk or payload.original_trunk", payload = payload.current_trunk,2,1
openstack%2Ftrove~master~I8c7fb4d245e7c4eebdd89d47573b4df01d5dd7e3,openstack/trove,master,I8c7fb4d245e7c4eebdd89d47573b4df01d5dd7e3,Updated from global requirements,MERGED,2016-08-29 06:18:40.000000000,2016-08-29 12:21:25.000000000,2016-08-29 12:21:25.000000000,"[{'_account_id': 3}, {'_account_id': 9664}]","[{'number': 1, 'created': '2016-08-29 06:18:40.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/trove/commit/e02e1616e253d14a096a2240ec67faf9c514cab9', 'message': 'Updated from global requirements\n\nChange-Id: I8c7fb4d245e7c4eebdd89d47573b4df01d5dd7e3\n'}]",0,361878,e02e1616e253d14a096a2240ec67faf9c514cab9,6,2,1,11131,,,0,"Updated from global requirements

Change-Id: I8c7fb4d245e7c4eebdd89d47573b4df01d5dd7e3
",git fetch https://review.opendev.org/openstack/trove refs/changes/78/361878/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,e02e1616e253d14a096a2240ec67faf9c514cab9,openstack/requirements,python-heatclient>=1.4.0 # Apache-2.0,python-heatclient>=1.1.0 # Apache-2.0,1,1
openstack%2Fpython-mistralclient~master~I9f1b30674ca070de44f69d8a20da3207cd0bcf6b,openstack/python-mistralclient,master,I9f1b30674ca070de44f69d8a20da3207cd0bcf6b,TrivialFix: Remove logging import unused,MERGED,2016-08-29 06:54:32.000000000,2016-08-29 12:20:11.000000000,2016-08-29 12:20:11.000000000,"[{'_account_id': 3}, {'_account_id': 8731}, {'_account_id': 18238}]","[{'number': 1, 'created': '2016-08-29 06:54:32.000000000', 'files': ['mistralclient/commands/v2/cron_triggers.py', 'mistralclient/commands/v2/actions.py', 'mistralclient/shell.py', 'mistralclient/commands/v2/services.py', 'mistralclient/commands/v2/environments.py', 'mistralclient/commands/v2/workflows.py', 'mistralclient/api/base.py', 'mistralclient/commands/v2/workbooks.py'], 'web_link': 'https://opendev.org/openstack/python-mistralclient/commit/c738c88d324fdc8d6c0d03fc5c78946a7af94afd', 'message': 'TrivialFix: Remove logging import unused\n\nThis patch removes logging import unused in mistralclient\n\nChange-Id: I9f1b30674ca070de44f69d8a20da3207cd0bcf6b\n'}]",0,361888,c738c88d324fdc8d6c0d03fc5c78946a7af94afd,7,3,1,15905,,,0,"TrivialFix: Remove logging import unused

This patch removes logging import unused in mistralclient

Change-Id: I9f1b30674ca070de44f69d8a20da3207cd0bcf6b
",git fetch https://review.opendev.org/openstack/python-mistralclient refs/changes/88/361888/1 && git format-patch -1 --stdout FETCH_HEAD,"['mistralclient/commands/v2/cron_triggers.py', 'mistralclient/commands/v2/actions.py', 'mistralclient/shell.py', 'mistralclient/commands/v2/services.py', 'mistralclient/commands/v2/environments.py', 'mistralclient/commands/v2/workflows.py', 'mistralclient/api/base.py', 'mistralclient/commands/v2/workbooks.py']",8,c738c88d324fdc8d6c0d03fc5c78946a7af94afd,bug/remove-logging-unused,,import loggingLOG = logging.getLogger(__name__) ,0,27
openstack%2Fhorizon~master~Idb48c3f68da43bba33033a71e6d69bdc112736de,openstack/horizon,master,Idb48c3f68da43bba33033a71e6d69bdc112736de,Fix various issues with compressed angular templates and plugins,MERGED,2016-08-24 12:47:30.000000000,2016-08-29 12:17:35.000000000,2016-08-29 12:17:35.000000000,"[{'_account_id': 3}, {'_account_id': 11778}, {'_account_id': 12038}, {'_account_id': 12071}, {'_account_id': 12826}, {'_account_id': 13325}, {'_account_id': 14107}, {'_account_id': 14151}, {'_account_id': 14307}, {'_account_id': 15168}, {'_account_id': 20509}, {'_account_id': 21287}]","[{'number': 1, 'created': '2016-08-24 12:47:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/61db07fb5e6257b65b24646db3629bce7526196f', 'message': '[WIP] Fix various issues with compressed angular templates\n\nRetrieve current theme only in cases when it already has been provided\nin the context.\n\nChange-Id: Idb48c3f68da43bba33033a71e6d69bdc112736de\n'}, {'number': 2, 'created': '2016-08-24 13:46:44.000000000', 'files': ['horizon/templatetags/angular.py', 'openstack_dashboard/templates/angular/angular_templates.html'], 'web_link': 'https://opendev.org/openstack/horizon/commit/9445d15cd133becf0137350ba843526d4548d4d0', 'message': ""Fix various issues with compressed angular templates and plugins\n\nFirst, retrieve current theme only in cases when it already has been\nprovided in the context. That should prevent missing 'THEME' errors\nwhen post_compress signal is being processed, for example inside\n_stylesheets.html which does not provide THEME var into the rendering\ncontext.\n\nSecond, under certain circumstances, offline compression was producing\na different hash for compressed angular templates than runtime\ntemplate renderer was expecting. Make the combined template with all\nangular templates be a deterministic - convert it from a dictionary to\na list of key-value tuples. Various order of dictionary entries in\noffline and online compress phases seemed to produce 'missing compress\nhash key' error.\n\nClosed-Bug: #1603307\nChange-Id: Idb48c3f68da43bba33033a71e6d69bdc112736de\n""}]",0,359850,9445d15cd133becf0137350ba843526d4548d4d0,16,12,2,8040,,,0,"Fix various issues with compressed angular templates and plugins

First, retrieve current theme only in cases when it already has been
provided in the context. That should prevent missing 'THEME' errors
when post_compress signal is being processed, for example inside
_stylesheets.html which does not provide THEME var into the rendering
context.

Second, under certain circumstances, offline compression was producing
a different hash for compressed angular templates than runtime
template renderer was expecting. Make the combined template with all
angular templates be a deterministic - convert it from a dictionary to
a list of key-value tuples. Various order of dictionary entries in
offline and online compress phases seemed to produce 'missing compress
hash key' error.

Closed-Bug: #1603307
Change-Id: Idb48c3f68da43bba33033a71e6d69bdc112736de
",git fetch https://review.opendev.org/openstack/horizon refs/changes/50/359850/1 && git format-patch -1 --stdout FETCH_HEAD,['horizon/templatetags/angular.py'],1,61db07fb5e6257b65b24646db3629bce7526196f,bug/1603307, theme = context['THEME'] # current theme being compressed, theme = context['THEME'] # current theme being compressed,1,1
openstack%2Fpuppet-neutron~master~I1c032c53b61face152bb37dfac4646db11403e4e,openstack/puppet-neutron,master,I1c032c53b61face152bb37dfac4646db11403e4e,lbaas: remove lbaasv1 and enable lbaasv2 by default,MERGED,2016-08-26 15:36:08.000000000,2016-08-29 12:15:43.000000000,2016-08-29 12:15:42.000000000,"[{'_account_id': 3}, {'_account_id': 6681}, {'_account_id': 7745}, {'_account_id': 8971}, {'_account_id': 9061}, {'_account_id': 14985}]","[{'number': 1, 'created': '2016-08-26 15:36:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/6133db8428fe92c9da00e5cea0abe7739c1ea410', 'message': ""lbaas: switch on lbaasv2 by default\n\nUpstream has just removed lbaasv1 from openstack-lbaas\n(https://review.openstack.org/286381).\n\nLet's follow them and provide a working lbaas deployment for our users\non Newton.\n\nChange-Id: I1c032c53b61face152bb37dfac4646db11403e4e\n""}, {'number': 2, 'created': '2016-08-26 15:37:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/5d4c031287114128af9ac28d545f6db9a788e4ac', 'message': ""lbaas: switch on lbaasv2 by default\n\nUpstream has just removed lbaasv1 from openstack-lbaas\n(https://review.openstack.org/286381).\n\nLet's follow them and provide a working lbaas deployment for our users\non Newton.\n\nChange-Id: I1c032c53b61face152bb37dfac4646db11403e4e\n""}, {'number': 3, 'created': '2016-08-26 15:45:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/2dbed0fe6a1e85954c9c093e8bea824a946d7fb9', 'message': ""lbaas: switch on lbaasv2 by default\n\nUpstream has just removed lbaasv1 from openstack-lbaas\n(https://review.openstack.org/286381).\n\nLet's follow them and provide a working lbaas deployment for our users\non Newton.\n\n- Switch-on lbaasv2 by default instead of lbaasv2 to follow what upstream Neutron is doing\n  in https://review.openstack.org/286381 and also switch default device_driver to be\n  neutron_lbaas.drivers.haproxy.namespace_driver.HaproxyNSDriver\n- enable_v1 and enable_v2 are deprecated in neutron::agents::lbaas. They can be used during\n  Newton and are effective but will be removed in Ocata. In Ocata, we'll remove lbaasv1 support.\n\nChange-Id: I1c032c53b61face152bb37dfac4646db11403e4e\n""}, {'number': 4, 'created': '2016-08-26 16:13:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/d9b7af4e544b956a24002b67001adacedce25786', 'message': ""lbaas: remove lbaasv1 and enable lbaasv2 by default\n\nUpstream has just removed lbaasv1 from openstack-lbaas\n(https://review.openstack.org/286381).\n\nLet's follow them and provide a working lbaas deployment for our users\non Newton.\n\n- Switch-on lbaasv2 by default instead of lbaasv1 to follow what upstream Neutron is doing\n  in https://review.openstack.org/286381 and also switch default device_driver to be\n  neutron_lbaas.drivers.haproxy.namespace_driver.HaproxyNSDriver\n- remove lbaasv1 support.\n- enable_v1 and enable_v2 are deprecated in neutron::agents::lbaas.\n\nChange-Id: I1c032c53b61face152bb37dfac4646db11403e4e\n""}, {'number': 5, 'created': '2016-08-26 18:03:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/985abe841e5456dd5757ea3f42c486d21a0f2189', 'message': ""lbaas: remove lbaasv1 and enable lbaasv2 by default\n\nUpstream has just removed lbaasv1 from openstack-lbaas\n(https://review.openstack.org/286381).\n\nLet's follow them and provide a working lbaas deployment for our users\non Newton.\n\n- Switch-on lbaasv2 by default instead of lbaasv1 to follow what upstream Neutron is doing\n  in https://review.openstack.org/286381 and also switch default device_driver to be\n  neutron_lbaas.drivers.haproxy.namespace_driver.HaproxyNSDriver\n- remove lbaasv1 support.\n- enable_v1 and enable_v2 are deprecated in neutron::agents::lbaas.\n\nChange-Id: I1c032c53b61face152bb37dfac4646db11403e4e\n""}, {'number': 6, 'created': '2016-08-26 18:58:28.000000000', 'files': ['spec/classes/neutron_agents_lbaas_spec.rb', 'spec/acceptance/basic_neutron_spec.rb', 'manifests/agents/lbaas.pp', 'releasenotes/notes/lbaasv2-default-066d13cf24fc4c49.yaml', 'manifests/services/lbaas.pp', 'manifests/params.pp', 'spec/classes/neutron_server_spec.rb', 'manifests/server.pp'], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/7b60d759fcc81113984f55d5820f1cc44195cf58', 'message': ""lbaas: remove lbaasv1 and enable lbaasv2 by default\n\nUpstream has just removed lbaasv1 from openstack-lbaas\n(https://review.openstack.org/286381).\n\nLet's follow them and provide a working lbaas deployment for our users\non Newton.\n\n- Switch-on lbaasv2 by default instead of lbaasv1 to follow what upstream Neutron is doing\n  in https://review.openstack.org/286381 and also switch default device_driver to be\n  neutron_lbaas.drivers.haproxy.namespace_driver.HaproxyNSDriver\n- remove lbaasv1 support.\n- enable_v1 and enable_v2 are deprecated in neutron::agents::lbaas.\n\nChange-Id: I1c032c53b61face152bb37dfac4646db11403e4e\n""}]",3,361315,7b60d759fcc81113984f55d5820f1cc44195cf58,23,6,6,3153,,,0,"lbaas: remove lbaasv1 and enable lbaasv2 by default

Upstream has just removed lbaasv1 from openstack-lbaas
(https://review.openstack.org/286381).

Let's follow them and provide a working lbaas deployment for our users
on Newton.

- Switch-on lbaasv2 by default instead of lbaasv1 to follow what upstream Neutron is doing
  in https://review.openstack.org/286381 and also switch default device_driver to be
  neutron_lbaas.drivers.haproxy.namespace_driver.HaproxyNSDriver
- remove lbaasv1 support.
- enable_v1 and enable_v2 are deprecated in neutron::agents::lbaas.

Change-Id: I1c032c53b61face152bb37dfac4646db11403e4e
",git fetch https://review.opendev.org/openstack/puppet-neutron refs/changes/15/361315/4 && git format-patch -1 --stdout FETCH_HEAD,"['spec/classes/neutron_agents_lbaas_spec.rb', 'manifests/agents/lbaas.pp']",2,6133db8428fe92c9da00e5cea0abe7739c1ea410,beaker-fix,"# Defaults to false# Defaults to true $device_driver = 'neutron_lbaas.drivers.haproxy.namespace_driver.HaproxyNSDriver', $enable_v1 = false, $enable_v2 = true,","# Defaults to true# Defaults to false $device_driver = 'neutron_lbaas.services.loadbalancer.drivers.haproxy.namespace_driver.HaproxyNSDriver', $enable_v1 = true, $enable_v2 = false,",12,12
openstack%2Ffuel-specs~master~I8fc89271e26168a256c726eb8f291e3aa3f24214,openstack/fuel-specs,master,I8fc89271e26168a256c726eb8f291e3aa3f24214,Spec for apply-mu-using-custom-deployment-graph,ABANDONED,2016-07-14 11:12:44.000000000,2016-08-29 12:13:44.000000000,,"[{'_account_id': 3}, {'_account_id': 3009}, {'_account_id': 6677}, {'_account_id': 7732}, {'_account_id': 7745}, {'_account_id': 8777}, {'_account_id': 8786}, {'_account_id': 8882}, {'_account_id': 9977}, {'_account_id': 12866}, {'_account_id': 14610}, {'_account_id': 14645}, {'_account_id': 14689}, {'_account_id': 16414}, {'_account_id': 16518}, {'_account_id': 18845}, {'_account_id': 19921}, {'_account_id': 20107}, {'_account_id': 20313}, {'_account_id': 20517}]","[{'number': 1, 'created': '2016-07-14 11:12:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/3fc5c160c3d9c77d14a2f27f7320146fdeb3280a', 'message': 'Spec for apply-mu-using-custom-deployment-graph\n\nChange-Id: I8fc89271e26168a256c726eb8f291e3aa3f24214\n'}, {'number': 2, 'created': '2016-07-14 11:36:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/4db74326606d802dedda4b6c4a27b9ab55890740', 'message': 'Spec for apply-mu-using-custom-deployment-graph\n\nChange-Id: I8fc89271e26168a256c726eb8f291e3aa3f24214\n'}, {'number': 3, 'created': '2016-07-14 11:38:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/40a7fb6f775750c41bbdd7a830dc00c19ae3c936', 'message': 'Spec for apply-mu-using-custom-deployment-graph\n\nChange-Id: I8fc89271e26168a256c726eb8f291e3aa3f24214\n'}, {'number': 4, 'created': '2016-07-14 11:53:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/5227aa07b9a1fe09fcb3b980c7dca3b6ad1e0867', 'message': 'Spec for apply-mu-using-custom-deployment-graph\n\nChange-Id: I8fc89271e26168a256c726eb8f291e3aa3f24214\n'}, {'number': 5, 'created': '2016-07-14 12:01:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/2f83f273f2ad1abdbf4d08ac73d3bd22cbbdc4af', 'message': 'Spec for apply-mu-using-custom-deployment-graph\n\nChange-Id: I8fc89271e26168a256c726eb8f291e3aa3f24214\n'}, {'number': 6, 'created': '2016-07-14 12:35:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/077a4c600def19b9c29f085b84ce38fb3d0d1e54', 'message': 'Spec for apply-mu-using-custom-deployment-graph\n\nChange-Id: I8fc89271e26168a256c726eb8f291e3aa3f24214\n'}, {'number': 7, 'created': '2016-07-18 15:50:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/a2c01bc0c4780852883aff02f943808ff56a9f03', 'message': 'Spec for apply-mu-using-custom-deployment-graph\n\nChange-Id: I8fc89271e26168a256c726eb8f291e3aa3f24214\n'}, {'number': 8, 'created': '2016-07-27 10:43:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/9144eb46795edc6ced4165ca9e730d2a76dd350d', 'message': 'Spec for apply-mu-using-custom-deployment-graph\n\nChange-Id: I8fc89271e26168a256c726eb8f291e3aa3f24214\n'}, {'number': 9, 'created': '2016-07-27 10:52:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/50710f2a40b0362869593fee2a0ce4215e2f7010', 'message': 'Spec for apply-mu-using-custom-deployment-graph\n\nChange-Id: I8fc89271e26168a256c726eb8f291e3aa3f24214\n'}, {'number': 10, 'created': '2016-07-27 14:23:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/fc519692aac6a383e605545fe2c6caf42dec677c', 'message': 'Spec for apply-mu-using-custom-deployment-graph\n\nChange-Id: I8fc89271e26168a256c726eb8f291e3aa3f24214\n'}, {'number': 11, 'created': '2016-08-09 15:42:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/5d2111265758fd9a62f7f921ba8e4f9f8e270d07', 'message': 'Spec for apply-mu-using-custom-deployment-graph\n\nChange-Id: I8fc89271e26168a256c726eb8f291e3aa3f24214\n'}, {'number': 12, 'created': '2016-08-12 15:02:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/ddc3ea9ca82757cf23facd1f8854d5810ba679dc', 'message': 'Spec for apply-mu-using-custom-deployment-graph\n\nChange-Id: I8fc89271e26168a256c726eb8f291e3aa3f24214\n'}, {'number': 13, 'created': '2016-08-15 16:11:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/351841209e59c871ad0b76200e0780361c9c33a9', 'message': 'Spec for apply-mu-using-custom-deployment-graph\n\nThe commit introduces the specification of updates using graph\nmechanism with the needed changes to the Fuel CLI.\n\nChange-Id: I8fc89271e26168a256c726eb8f291e3aa3f24214\n'}, {'number': 14, 'created': '2016-08-15 17:12:08.000000000', 'files': ['specs/10.0/apply-mu-using-custom-deployment-graph.rst'], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/344cd0cbd46602bd24966db7a2aa84adb61a7e32', 'message': 'Spec for apply-mu-using-custom-deployment-graph\n\nThe commit introduces the specification of updates using graph\nmechanism with the needed changes to the Fuel CLI.\n\nChange-Id: I8fc89271e26168a256c726eb8f291e3aa3f24214\n'}]",129,342110,344cd0cbd46602bd24966db7a2aa84adb61a7e32,56,20,14,18845,,,0,"Spec for apply-mu-using-custom-deployment-graph

The commit introduces the specification of updates using graph
mechanism with the needed changes to the Fuel CLI.

Change-Id: I8fc89271e26168a256c726eb8f291e3aa3f24214
",git fetch https://review.opendev.org/openstack/fuel-specs refs/changes/10/342110/13 && git format-patch -1 --stdout FETCH_HEAD,['specs/10.0/apply-mu-using-custom-deployment-graph.rtf'],1,3fc5c160c3d9c77d14a2f27f7320146fdeb3280a,mu-check-install,"{\rtf1\ansi\ansicpg1252\uc0\stshfdbch0\stshfloch0\stshfhich0\stshfbi0\deff0\adeff0{\fonttbl{\f0\froman\fcharset0\fprq2{\*\panose 02020603050405020304}Times New Roman;}{\f1\froman\fcharset2\fprq2{\*\panose 05050102010706020507}Symbol;}{\f2\fswiss\fcharset0\fprq2{\*\panose 020b0604020202020204}Arial;}}{\colortbl;\red0\green0\blue0;\red67\green67\blue67 ;\red102\green102\blue102;\red17\green85\blue204;}{\stylesheet{\s0\snext0\sqformat\spriority0\fi0\sb0\sa0\aspalpha\aspnum\adjustright\widctlpar\ltrpar\li0\lin0\ri0\rin0\ql\faauto\sl276\slmult1\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 Normal;}{\s1\sbasedon0\snext0\styrsid15694742 \sqformat\spriority0\keep\keepn\fi0\sb400\sa120\aspalpha\aspnum\adjustright\widctlpar\ltrpar\li0\lin0\ri0\rin0\ql\faauto\sl276\slmult1\rtlch\ab0\ai0\af2\afs40\ltrch\b0\i0\fs40\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 heading 1;}{\s2\sbasedon0\snext0\styrsid15694742 \sqformat\spriority0\keep\keepn\fi0\sb360\sa120\aspalpha\aspnum\adjustright\widctlpar\ltrpar\li0\lin0\ri0\rin0\ql\faauto\sl276\slmult1\rtlch\ab0\ai0\af2\afs32\ltrch\b0\i0\fs32\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 heading 2;}{\s3\sbasedon0\snext0\styrsid15694742 \sqformat\spriority0\keep\keepn\fi0\sb320\sa80\aspalpha\aspnum\adjustright\widctlpar\ltrpar\li0\lin0\ri0\rin0\ql\faauto\sl276\slmult1\rtlch\ab0\ai0\af2\afs28\ltrch\b0\i0\fs28\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf2 heading 3;}{\s4\sbasedon0\snext0\styrsid15694742 \sqformat\spriority0\keep\keepn\fi0\sb280\sa80\aspalpha\aspnum\adjustright\widctlpar\ltrpar\li0\lin0\ri0\rin0\ql\faauto\sl276\slmult1\rtlch\ab0\ai0\af2\afs24\ltrch\b0\i0\fs24\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf3 heading 4;}{\s5\sbasedon0\snext0\styrsid15694742 \sqformat\spriority0\keep\keepn\fi0\sb240\sa80\aspalpha\aspnum\adjustright\widctlpar\ltrpar\li0\lin0\ri0\rin0\ql\faauto\sl276\slmult1\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf3 heading 5;}{\s6\sbasedon0\snext0\styrsid15694742 \sqformat\spriority0\keep\keepn\fi0\sb240\sa80\aspalpha\aspnum\adjustright\widctlpar\ltrpar\li0\lin0\ri0\rin0\ql\faauto\sl276\slmult1\rtlch\ab0\ai\af2\afs22\ltrch\b0\i\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf3 heading 6;}{\*\cs10\additive\ssemihidden\spriority0 Default Paragraph Font ;}{\s15\sbasedon0\snext15\styrsid15694742\sqformat\spriority0\keep\keepn\fi0\sb0\sa60\aspalpha\aspnum\adjustright\widctlpar\ltrpar\li0\lin0\ri0\rin0\ql\faauto\sl276\slmult1\rtlch\ab0\ai0\af2\afs52\ltrch\b0\i0\fs52\loch\af2\dbch\af2\hich\f2\strike0 \ulnone\cf1 Title;}{\s16\sbasedon0\snext16\styrsid15694742\sqformat\spriority0\keep\keepn\fi0\sb0\sa320\aspalpha\aspnum\adjustright\widctlpar\ltrpar\li0\lin0\ri0\rin0\ql\faauto\sl276\slmult1\rtlch\ab0\ai0\af2\afs30\ltrch\b0\i0\fs30\loch\af2\dbch\af2\hich\f2\strike0 \ulnone\cf3 Subtitle;}}{\*\listtable{\list\listtemplateid1{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelstartat1{\leveltext \'01\u9679 ;}{\levelnumbers;}\levelfollow0\ulnone\jclisttab\tx360\fi-360\li720\lin720}{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelstartat1 {\leveltext \'01\u9675 ;}{\levelnumbers;}\levelfollow0\ulnone\jclisttab\tx1080\fi-360\li1440\lin1440}{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelstartat1{\leveltext \'01\u9632 ;}{\levelnumbers;}\levelfollow0\ulnone\jclisttab\tx1800\fi-180\li2160\lin2160} {\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelstartat1{\leveltext \'01\u9679 ;}{\levelnumbers;}\levelfollow0\ulnone\jclisttab\tx2520\fi-360\li2880\lin2880}{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelstartat1{\leveltext \'01\u9675 ;}{\levelnumbers;}\levelfollow0\ulnone\jclisttab\tx3240\fi-360\li3600\lin3600}{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelstartat1{\leveltext \'01\u9632 ;}{\levelnumbers;}\levelfollow0\ulnone\jclisttab\tx3960\fi-180\li4320\lin4320}{ \listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelstartat1{\leveltext \'01\u9679 ;}{\levelnumbers;}\levelfollow0\ulnone\jclisttab\tx4680\fi-360\li5040\lin5040}{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelstartat1{\leveltext \'01\u9675 ;}{ \levelnumbers;}\levelfollow0\ulnone\jclisttab\tx5400\fi-360\li5760\lin5760}{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelstartat1{\leveltext \'01\u9632 ;}{\levelnumbers;}\levelfollow0\ulnone\jclisttab\tx6120\fi-180\li6480\lin6480}\listid1}{\list\listtemplateid2 {\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelstartat1{\leveltext \'01\u9679 ;}{\levelnumbers;}\levelfollow0\ulnone\jclisttab\tx360\fi-360\li720\lin720}{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelstartat1{\leveltext \'01\u9675 ;}{\levelnumbers;}\levelfollow0\ulnone\jclisttab\tx1080\fi-360\li1440\lin1440}{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelstartat1{\leveltext \'01\u9632 ;}{\levelnumbers;}\levelfollow0\ulnone\jclisttab\tx1800\fi-180\li2160\lin2160}{ \listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelstartat1{\leveltext \'01\u9679 ;}{\levelnumbers;}\levelfollow0\ulnone\jclisttab\tx2520\fi-360\li2880\lin2880}{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelstartat1{\leveltext \'01\u9675 ;}{ \levelnumbers;}\levelfollow0\ulnone\jclisttab\tx3240\fi-360\li3600\lin3600}{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelstartat1{\leveltext \'01\u9632 ;}{\levelnumbers;}\levelfollow0\ulnone\jclisttab\tx3960\fi-180\li4320\lin4320}{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelstartat1 {\leveltext \'01\u9679 ;}{\levelnumbers;}\levelfollow0\ulnone\jclisttab\tx4680\fi-360\li5040\lin5040}{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelstartat1{\leveltext \'01\u9675 ;}{\levelnumbers;}\levelfollow0\ulnone\jclisttab\tx5400\fi-360\li5760\lin5760} {\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelstartat1{\leveltext \'01\u9632 ;}{\levelnumbers;}\levelfollow0\ulnone\jclisttab\tx6120\fi-180\li6480\lin6480}\listid2}}{\*\listoverridetable{\listoverride\listid1\listoverridecount0\ls1}{ \listoverride\listid2\listoverridecount0\ls2}}{\*\rsidtbl\rsid10976062}{\*\generator Aspose.Words for Java 13.10.0.0;}{\info\version1\edmins0\nofpages1\nofwords0\nofchars0\nofcharsws0}{\mmathPr\mbrkBin0\mbrkBinSub0\mdefJc1\mdispDef1\minterSp0\mintLim0\mintraSp0\mlMargin0\mmathFont0\mnaryLim1\mpostSp0\mpreSp0\mrMargin0\msmallFrac0\mwrapIndent1440\mwrapRight0} \deflang1033\deflangfe2052\adeflang1025\jexpand\showxmlerrors1\validatexml1{\*\wgrffmtfilter 013f}\viewkind1\viewscale100\fet0\ftnbj\aenddoc\ftnrstcont\aftnrstcont\ftnnar\aftnnrlc\widowctrl\nospaceforul\nolnhtadjtbl\alntblind\lyttblrtgr\dntblnsbdb\noxlattoyen \wrppunct\nobrkwrptbl\expshrtn\snaptogridincell\asianbrkrule\htmautsp\noultrlspc\useltbaln\splytwnine\ftnlytwnine\lytcalctblwd\allowfieldendsel\lnbrkrule\nouicompat\nofeaturethrottle1\formshade\nojkernpunct\dghspace180\dgvspace180\dghorigin1800\dgvorigin1440\dghshow1\dgvshow1 \dgmargin\pgbrdrhead\pgbrdrfoot\sectd\sectlinegrid360\pgwsxn12240\pghsxn15840\marglsxn1440\margrsxn1440\margtsxn1440\margbsxn1440\guttersxn0\headery708\footery708\colsx708\ltrsect\pard\plain\itap0\s1\ilvl0\fi0\sb480\sa120\aspalpha\aspnum\adjustright\brdrt\brdrl\brdrb\brdrr\brdrbtw \brdrbar\widctlpar\ltrpar\li0\lin0\ri0\rin0\ql\faauto\sl276\slmult1\rtlch\ab0\ai0\af2\afs40\ltrch\b0\i0\fs40\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1{\*\bkmkstart h.5v93qksk5fqv}{\*\bkmkend h.5v93qksk5fqv}{\rtlch\ab\ai0\af2\afs46\ltrch\b\i0\fs46\loch\af2 \dbch\af2\hich\f2\strike0\ulnone\cf1 Apply}{\rtlch\ab\ai0\af2\afs46\ltrch\b\i0\fs46\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab\ai0\af2\afs46\ltrch\b\i0\fs46\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 maintenance}{\rtlch\ab\ai0\af2\afs46 \ltrch\b\i0\fs46\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab\ai0\af2\afs46\ltrch\b\i0\fs46\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 updates}{\rtlch\ab\ai0\af2\afs46\ltrch\b\i0\fs46\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab\ai0\af2\afs46 \ltrch\b\i0\fs46\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 on}{\rtlch\ab\ai0\af2\afs46\ltrch\b\i0\fs46\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab\ai0\af2\afs46\ltrch\b\i0\fs46\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 slave}{\rtlch\ab\ai0\af2\afs46 \ltrch\b\i0\fs46\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab\ai0\af2\afs46\ltrch\b\i0\fs46\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 nodes}{\rtlch\ab\ai0\af2\afs46\ltrch\b\i0\fs46\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab\ai0\af2\afs46 \ltrch\b\i0\fs46\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 using}{\rtlch\ab\ai0\af2\afs46\ltrch\b\i0\fs46\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab\ai0\af2\afs46\ltrch\b\i0\fs46\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 custom}{\rtlch\ab\ai0\af2\afs46 \ltrch\b\i0\fs46\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab\ai0\af2\afs46\ltrch\b\i0\fs46\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 deployment}{\rtlch\ab\ai0\af2\afs46\ltrch\b\i0\fs46\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab\ai0\af2\afs46 \ltrch\b\i0\fs46\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 graph}{\rtlch\ab0\ai0\af2\afs40\ltrch\b0\i0\fs40\loch\af2\dbch\af2\hich\f2\insrsid10976062\strike0\ulnone\cf1\par}\pard\plain\itap0\s0\ilvl0\fi0\sb0\sa0\aspalpha\aspnum\adjustright\brdrt\brdrl \brdrb\brdrr\brdrbtw\brdrbar\widctlpar\ltrpar\li0\lin0\ri0\rin0\ql\faauto\sl276\slmult1\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 With} {\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 new}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0 \ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 Fuel}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2 \hich\f2\strike0\ulnone\cf1 capability}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 to}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22 \loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 execute}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 custom}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 deployment}{ \rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 graphs}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0 \ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 we}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0 \ulnone\cf1 could}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 improve}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2 \hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 process}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22 \loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 of}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 applying}{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 maintenance}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{ \rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 updates}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0 \ulnone\cf1 on}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 the}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2 \hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 slave}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22 \loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 nodes}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 of}{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 already}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 deployed}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 OpenStack} {\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 environment}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2 \hich\f2\strike0\ulnone\cf1 . }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 We}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22 \loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 can}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 use}{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 parallelisation}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{ \rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 and}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0 \ulnone\cf1 cross}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 -}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 node}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2 \hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 dependencies}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22 \loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 features}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 that}{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 will}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 allow}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 us}{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 to}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 apply}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 updates}{ \rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 on}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0 \ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 the}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2 \hich\f2\strike0\ulnone\cf1 slave}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 nodes}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22 \loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 faster}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 and}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 in}{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 more}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 automated}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 way}{ \rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 .}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\insrsid10976062\strike0\ulnone\cf1\par}\pard\plain\itap0\s0\ilvl0\fi0\sb0\sa0\aspalpha\aspnum \adjustright\brdrt\brdrl\brdrb\brdrr\brdrbtw\brdrbar\widctlpar\ltrpar\li0\lin0\ri0\rin0\ql\faauto\sl276\slmult1\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1{\rtlch\ab\ai0\af2\afs34\ltrch\b\i0\fs34\loch\af2\dbch\af2\hich\f2\insrsid10976062\strike0 \ulnone\cf1\par}\pard\plain\itap0\s0\ilvl0\fi0\sb0\sa0\aspalpha\aspnum\adjustright\brdrt\brdrl\brdrb\brdrr\brdrbtw\brdrbar\widctlpar\ltrpar\li0\lin0\ri0\rin0\ql\faauto\sl276\slmult1\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0 \ulnone\cf1{\rtlch\ab\ai0\af2\afs34\ltrch\b\i0\fs34\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 Problem}{\rtlch\ab\ai0\af2\afs34\ltrch\b\i0\fs34\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab\ai0\af2\afs34\ltrch\b\i0\fs34\loch\af2\dbch\af2\hich\f2\strike0 \ulnone\cf1 description}{\rtlch\ab\ai0\af2\afs34\ltrch\b\i0\fs34\loch\af2\dbch\af2\hich\f2\insrsid10976062\strike0\ulnone\cf1\par}\pard\plain\itap0\s0\ilvl0\fi0\sb0\sa0\aspalpha\aspnum\adjustright\brdrt\brdrl\brdrb\brdrr\brdrbtw\brdrbar\widctlpar\ltrpar\li0\lin0\ri0\rin0 \ql\faauto\sl276\slmult1\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 Currently}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2 \dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 we}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22 \loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 recommend}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 to}{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 install}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 maintenance}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 updates} {\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 on}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0 \ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 the}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2 \hich\f2\strike0\ulnone\cf1 slave}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 nodes}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22 \loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 using}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 mos}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 _}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 apply}{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 _}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 mu}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 .}{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 py}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 [1] }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 script}{ \rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 on}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0 \ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 Fuel}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2 \hich\f2\strike0\ulnone\cf1 master}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 node}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22 \loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 and}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 manually}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 restarting} {\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 all}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0 \ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 affected}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2 \hich\f2\strike0\ulnone\cf1 services}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 on}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22 \loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 all}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 slave}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 nodes}{ \rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 . }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 This}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0 \ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 process}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2 \hich\f2\strike0\ulnone\cf1 is}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 manual}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22 \loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 and}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 error}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 prone}{ \rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 . }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 Custom}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0 \ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 deployment}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2 \hich\f2\strike0\ulnone\cf1 graphs}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 feature}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22 \loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 could}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 be}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 used}{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 to}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 improve}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 and}{ \rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 automate}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0 \ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 this}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2 \hich\f2\strike0\ulnone\cf1 process}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 .}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\insrsid10976062\strike0\ulnone\cf1\par}\pard\plain\itap0\s2\ilvl0\fi0\sb360\sa80 \aspalpha\aspnum\adjustright\brdrt\brdrl\brdrb\brdrr\brdrbtw\brdrbar\widctlpar\ltrpar\li0\lin0\ri0\rin0\ql\faauto\sl276\slmult1\rtlch\ab0\ai0\af2\afs32\ltrch\b0\i0\fs32\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1{\*\bkmkstart h.lvljqrahbr0h}{\*\bkmkend h.lvljqrahbr0h} {\rtlch\ab\ai0\af2\afs34\ltrch\b\i0\fs34\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 Proposed}{\rtlch\ab\ai0\af2\afs34\ltrch\b\i0\fs34\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab\ai0\af2\afs34\ltrch\b\i0\fs34\loch\af2\dbch\af2\hich\f2\strike0 \ulnone\cf1 changes}{\rtlch\ab\ai0\af2\afs34\ltrch\b\i0\fs34\loch\af2\dbch\af2\hich\f2\insrsid10976062\strike0\ulnone\cf1\par}\pard\plain\itap0\s0\ilvl0\fi0\sb0\sa0\aspalpha\aspnum\adjustright\brdrt\brdrl\brdrb\brdrr\brdrbtw\brdrbar\widctlpar\ltrpar\li0\lin0\ri0\rin0 \ql\faauto\sl276\slmult1\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 Maintenance}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22 \loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 update}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 installation}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 could} {\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 be}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0 \ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 performed}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2 \hich\f2\strike0\ulnone\cf1 by}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 executing}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22 \loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 predefined}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 custom}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 graph}{ \rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 instead}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0 \ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 of}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0 \ulnone\cf1 using}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 mos}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2 \hich\f2\strike0\ulnone\cf1 _}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 apply}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 _}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22 \loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 mu}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 .}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 py}{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 script}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 and}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 restarting}{ \rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 services}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0 \ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 manually}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 . }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2 \hich\f2\strike0\ulnone\cf1 This}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 custom}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22 \loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 graph}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 needs}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 to}{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 be}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 developed}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 , }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 included} {\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 into}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0 \ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 some}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2 \hich\f2\strike0\ulnone\cf1 Fuel}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 package}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22 \loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 and}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 delivered}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 to}{ \rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 master}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0 \ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 node}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2 \hich\f2\strike0\ulnone\cf1 together}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 with}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22 \loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 some}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 maintenance}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 update} {\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 . }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\insrsid10976062\strike0\ulnone\cf1\par}\pard\plain\itap0\s0\ilvl0\fi0\sb0\sa0\aspalpha\aspnum \adjustright\brdrt\brdrl\brdrb\brdrr\brdrbtw\brdrbar\widctlpar\ltrpar\li0\lin0\ri0\rin0\ql\faauto\sl276\slmult1\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0 \ulnone\cf1 Limitation}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 : }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 this}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2 \dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 spec}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22 \loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 covers}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 only}{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 installation}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{ \rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 of}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0 \ulnone\cf1 the}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 latest}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2 \hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 available}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22 \loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 maintenance}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 update}{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 (}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 installation}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{ \rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 of}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0 \ulnone\cf1 specific}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 maintenance}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2 \dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 update}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22 \loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 requires}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 more}{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 work}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 and}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 is}{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 out}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 of}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 scope}{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 of}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 this}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 spec}{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 ).}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\insrsid10976062\strike0\ulnone\cf1\par}\pard\plain\itap0\s3\ilvl0\fi0\sb280\sa80\aspalpha\aspnum\adjustright\brdrt\brdrl \brdrb\brdrr\brdrbtw\brdrbar\widctlpar\ltrpar\li0\lin0\ri0\rin0\ql\faauto\sl276\slmult1\rtlch\ab0\ai0\af2\afs28\ltrch\b0\i0\fs28\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf2{\*\bkmkstart h.ksr3myatrmt6}{\*\bkmkend h.ksr3myatrmt6}{\rtlch\ab\ai0\af2\afs26\ltrch\b\i0\fs26 \loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 Web}{\rtlch\ab\ai0\af2\afs26\ltrch\b\i0\fs26\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab\ai0\af2\afs26\ltrch\b\i0\fs26\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 UI}{\rtlch\ab\ai0\af2\afs26\ltrch\b\i0\fs26 \loch\af2\dbch\af2\hich\f2\insrsid10976062\strike0\ulnone\cf1\par}\pard\plain\itap0\s0\ilvl0\fi0\sb0\sa0\aspalpha\aspnum\adjustright\brdrt\brdrl\brdrb\brdrr\brdrbtw\brdrbar\widctlpar\ltrpar\li0\lin0\ri0\rin0\ql\faauto\sl276\slmult1\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 None}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 .}{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\insrsid10976062\strike0\ulnone\cf1\par}\pard\plain\itap0\s3\ilvl0\fi0\sb280\sa80\aspalpha\aspnum\adjustright\brdrt\brdrl\brdrb\brdrr\brdrbtw\brdrbar\widctlpar\ltrpar\li0\lin0\ri0\rin0\ql\faauto\sl276\slmult1\rtlch\ab0\ai0\af2\afs28 \ltrch\b0\i0\fs28\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf2{\*\bkmkstart h.tjzyjekxmmgx}{\*\bkmkend h.tjzyjekxmmgx}{\rtlch\ab\ai0\af2\afs26\ltrch\b\i0\fs26\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 Nailgun}{\rtlch\ab\ai0\af2\afs26\ltrch\b\i0\fs26\loch\af2 \dbch\af2\hich\f2\insrsid10976062\strike0\ulnone\cf1\par}\pard\plain\itap0\s0\ilvl0\fi0\sb0\sa0\aspalpha\aspnum\adjustright\brdrt\brdrl\brdrb\brdrr\brdrbtw\brdrbar\widctlpar\ltrpar\li0\lin0\ri0\rin0\ql\faauto\sl276\slmult1\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22 \loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 None}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 .}{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\insrsid10976062\strike0\ulnone\cf1\par}\pard\plain\itap0\s4\ilvl0\fi0\sb240\sa40\aspalpha\aspnum\adjustright\brdrt\brdrl\brdrb\brdrr\brdrbtw\brdrbar\widctlpar\ltrpar\li0\lin0\ri0\rin0\ql\faauto\sl276\slmult1\rtlch\ab0\ai0\af2\afs24 \ltrch\b0\i0\fs24\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf3{\*\bkmkstart h.ogo1ekwh871p}{\*\bkmkend h.ogo1ekwh871p}{\rtlch\ab\ai0\af2\afs22\ltrch\b\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 Data}{\rtlch\ab\ai0\af2\afs22\ltrch\b\i0\fs22\loch\af2 \dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab\ai0\af2\afs22\ltrch\b\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 model}{\rtlch\ab\ai0\af2\afs22\ltrch\b\i0\fs22\loch\af2\dbch\af2\hich\f2\insrsid10976062\strike0\ulnone\cf1\par}\pard\plain\itap0\s0\ilvl0\fi0\sb0\sa0 \aspalpha\aspnum\adjustright\brdrt\brdrl\brdrb\brdrr\brdrbtw\brdrbar\widctlpar\ltrpar\li0\lin0\ri0\rin0\ql\faauto\sl276\slmult1\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2 \dbch\af2\hich\f2\strike0\ulnone\cf1 None}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 .}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\insrsid10976062\strike0\ulnone\cf1\par}\pard\plain\itap0\s4\ilvl0\fi0\sb240\sa40 \aspalpha\aspnum\adjustright\brdrt\brdrl\brdrb\brdrr\brdrbtw\brdrbar\widctlpar\ltrpar\li0\lin0\ri0\rin0\ql\faauto\sl276\slmult1\rtlch\ab0\ai0\af2\afs24\ltrch\b0\i0\fs24\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf3{\*\bkmkstart h.trghdb8n7esl}{\*\bkmkend h.trghdb8n7esl} {\rtlch\ab\ai0\af2\afs22\ltrch\b\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 REST}{\rtlch\ab\ai0\af2\afs22\ltrch\b\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab\ai0\af2\afs22\ltrch\b\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0 \ulnone\cf1 API}{\rtlch\ab\ai0\af2\afs22\ltrch\b\i0\fs22\loch\af2\dbch\af2\hich\f2\insrsid10976062\strike0\ulnone\cf1\par}\pard\plain\itap0\s0\ilvl0\fi0\sb0\sa0\aspalpha\aspnum\adjustright\brdrt\brdrl\brdrb\brdrr\brdrbtw\brdrbar\widctlpar\ltrpar\li0\lin0\ri0\rin0 \ql\faauto\sl276\slmult1\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 None}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2 \dbch\af2\hich\f2\strike0\ulnone\cf1 .}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\insrsid10976062\strike0\ulnone\cf1\par}\pard\plain\itap0\s3\ilvl0\fi0\sb280\sa80\aspalpha\aspnum\adjustright\brdrt\brdrl\brdrb\brdrr\brdrbtw\brdrbar \widctlpar\ltrpar\li0\lin0\ri0\rin0\ql\faauto\sl276\slmult1\rtlch\ab0\ai0\af2\afs28\ltrch\b0\i0\fs28\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf2{\*\bkmkstart h.sskpp9i98929}{\*\bkmkend h.sskpp9i98929}{\rtlch\ab\ai0\af2\afs26\ltrch\b\i0\fs26\loch\af2\dbch\af2 \hich\f2\strike0\ulnone\cf1 Orchestration}{\rtlch\ab\ai0\af2\afs26\ltrch\b\i0\fs26\loch\af2\dbch\af2\hich\f2\insrsid10976062\strike0\ulnone\cf1\par}\pard\plain\itap0\s0\ilvl0\fi0\sb0\sa0\aspalpha\aspnum\adjustright\brdrt\brdrl\brdrb\brdrr\brdrbtw\brdrbar \widctlpar\ltrpar\li0\lin0\ri0\rin0\ql\faauto\sl276\slmult1\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 None}{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 .}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\insrsid10976062\strike0\ulnone\cf1\par}\pard\plain\itap0\s4\ilvl0\fi0\sb240\sa40\aspalpha\aspnum\adjustright\brdrt\brdrl \brdrb\brdrr\brdrbtw\brdrbar\widctlpar\ltrpar\li0\lin0\ri0\rin0\ql\faauto\sl276\slmult1\rtlch\ab0\ai0\af2\afs24\ltrch\b0\i0\fs24\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf3{\*\bkmkstart h.am9j4hhnrkt4}{\*\bkmkend h.am9j4hhnrkt4}{\rtlch\ab\ai0\af2\afs22\ltrch\b\i0\fs22 \loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 RPC}{\rtlch\ab\ai0\af2\afs22\ltrch\b\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab\ai0\af2\afs22\ltrch\b\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 Protocol}{\rtlch\ab\ai0\af2\afs22 \ltrch\b\i0\fs22\loch\af2\dbch\af2\hich\f2\insrsid10976062\strike0\ulnone\cf1\par}\pard\plain\itap0\s0\ilvl0\fi0\sb0\sa0\aspalpha\aspnum\adjustright\brdrt\brdrl\brdrb\brdrr\brdrbtw\brdrbar\widctlpar\ltrpar\li0\lin0\ri0\rin0\ql\faauto\sl276\slmult1\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 None}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 .}{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\insrsid10976062\strike0\ulnone\cf1\par}\pard\plain\itap0\s3\ilvl0\fi0\sb280\sa80\aspalpha\aspnum\adjustright\brdrt\brdrl\brdrb\brdrr\brdrbtw\brdrbar\widctlpar\ltrpar\li0\lin0\ri0\rin0\ql\faauto\sl276\slmult1\rtlch\ab0\ai0\af2\afs28 \ltrch\b0\i0\fs28\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf2{\*\bkmkstart h.pfmz67qmym4y}{\*\bkmkend h.pfmz67qmym4y}{\rtlch\ab\ai0\af2\afs26\ltrch\b\i0\fs26\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 Fuel}{\rtlch\ab\ai0\af2\afs26\ltrch\b\i0\fs26\loch\af2 \dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab\ai0\af2\afs26\ltrch\b\i0\fs26\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 Client}{\rtlch\ab\ai0\af2\afs26\ltrch\b\i0\fs26\loch\af2\dbch\af2\hich\f2\insrsid10976062\strike0\ulnone\cf1\par}\pard\plain\itap0\s0\ilvl0\fi0\sb0\sa0 \aspalpha\aspnum\adjustright\brdrt\brdrl\brdrb\brdrr\brdrbtw\brdrbar\widctlpar\ltrpar\li0\lin0\ri0\rin0\ql\faauto\sl276\slmult1\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2 \dbch\af2\hich\f2\strike0\ulnone\cf1 Add}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 the}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22 \loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 following}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 commands}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 to}{ \rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 the}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0 \ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 Fuel}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2 \hich\f2\strike0\ulnone\cf1 CLI}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 ::\line \line }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 fuel}{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 -> }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 updates}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 --> }{ \rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 check}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 --> }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0 \ulnone\cf1 installed}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 \line | |\line | +----> }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0 \ulnone\cf1 available}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 \line |\line +-------> }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 install}{ \rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 \line \line }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 The}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0 \ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 Fuel}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2 \hich\f2\strike0\ulnone\cf1 CLI}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 command}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22 \loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 ``}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 updates}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 check}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 installed}{ \rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 `` }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 will}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0 \ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 check}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2 \hich\f2\strike0\ulnone\cf1 the}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 version}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22 \loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 of}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 the}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 \line }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 Maintenance} {\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 Update}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0 \ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 applied}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 (}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2 \hich\f2\strike0\ulnone\cf1 if}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 any}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22 \loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 ) }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 by}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 checking}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 the}{ \rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 file}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0 \ulnone\cf1 \line `/}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 etc}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 /}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2 \hich\f2\strike0\ulnone\cf1 fuel}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 /}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 mu}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22 \loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 -}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 version}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 .}{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 json}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 ` }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 which}{ \rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 is}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0 \ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 delivered}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2 \hich\f2\strike0\ulnone\cf1 as}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 a}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2 \dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 part}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22 \loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 of}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 the}{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 `}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 fuel}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 -}{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 misc}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 `\line }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 package} {\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 to}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0 \ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 every}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2 \hich\f2\strike0\ulnone\cf1 node}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 in}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22 \loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 the}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 particular}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 environment} {\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 . \line \line }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 The}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2 \hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 command}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 ``}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22 \loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 updates}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 check}{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 available}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 `` }{ \rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 will}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0 \ulnone\cf1 parse}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 the}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2 \hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 contents}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22 \loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 of}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 the}{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 \line }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 file}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 `}{ \rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 mu}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 -}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0 \ulnone\cf1 version}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 .}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 json}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2 \hich\f2\strike0\ulnone\cf1 ` }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 in}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22 \loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 the}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 appropriate}{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 sub}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 -}{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 folder}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 in}{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 `/}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 mcv}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 /}{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 mos}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 /` }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 on}{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 the}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 \line }{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 official}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 Fuel}{ \rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 mirror}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0 \ulnone\cf1 `}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 mirror}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 .}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2 \hich\f2\strike0\ulnone\cf1 fuel}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 -}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 infra}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22 \loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 .}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 org}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 ` [3]_, }{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 then}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 check}{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 its}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 contents}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 \line }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 against} {\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 the}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0 \ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 local}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2 \hich\f2\strike0\ulnone\cf1 file}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 `/}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 etc}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22 \loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 /}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 fuel}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 /}{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 mu}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 -}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 version}{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 .}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 json}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 ` }{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 and}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 show}{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 the}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 user}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 if}{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 there}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 \line }{ \rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 are}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0 \ulnone\cf1 new}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 updates}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2 \hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 available}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 . }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22 \loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 If}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 there}{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 is}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 no}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 local}{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 information}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{ \rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 to}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0 \ulnone\cf1 compare}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 with}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2 \hich\f2\strike0\ulnone\cf1 ,\line }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 the}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22 \loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 case}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 should}{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 be}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 treated}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 as}{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 no}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 Maintenance}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 Update} {\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 is}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0 \ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 currently}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2 \hich\f2\strike0\ulnone\cf1 installed}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 .\line \line }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 Having}{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 this}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 information}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 the}{ \rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 user}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0 \ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 may}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2 \hich\f2\strike0\ulnone\cf1 decide}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 whether}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22 \loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 to}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 apply}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 a}{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 new}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 update}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 \line }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 using}{ \rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 the}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0 \ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 command}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 ``}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2 \hich\f2\strike0\ulnone\cf1 updates}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 install}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22 \loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 `` }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 or}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 it}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 already}{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 has}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 the}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 needed}{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 Maintenance}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 \line } {\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 Update}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0 \ulnone\cf1 installed}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 . }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 In}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2 \hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 case}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22 \loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 of}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 successful}{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 installation}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{ \rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 of}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0 \ulnone\cf1 the}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 Maintenance}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2 \dbch\af2\hich\f2\strike0\ulnone\cf1 \line }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 Update}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 its}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 version}{ \rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 and}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0 \ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 timestamp}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2 \hich\f2\strike0\ulnone\cf1 will}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 be}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22 \loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 stored}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 on}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 each}{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 node}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 locally}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 as}{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 \line `/}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 etc}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 /}{ \rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 fuel}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 /}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0 \ulnone\cf1 mu}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 -}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 version}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2 \hich\f2\strike0\ulnone\cf1 .}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 json}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 ` }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22 \loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 to}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 make}{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 further}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 checks}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 against}{ \rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 the}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0 \ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 Fuel}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2 \hich\f2\strike0\ulnone\cf1 mirror}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 \line }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 possible}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22 \loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 .}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\insrsid10976062\strike0\ulnone\cf1\par}\pard\plain\itap0\s3\ilvl0\fi0\sb280\sa80\aspalpha\aspnum\adjustright\brdrt\brdrl\brdrb\brdrr\brdrbtw \brdrbar\widctlpar\ltrpar\li0\lin0\ri0\rin0\ql\faauto\sl276\slmult1\rtlch\ab0\ai0\af2\afs28\ltrch\b0\i0\fs28\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf2{\*\bkmkstart h.htletom3xrm3}{\*\bkmkend h.htletom3xrm3}{\rtlch\ab\ai0\af2\afs26\ltrch\b\i0\fs26\loch\af2 \dbch\af2\hich\f2\strike0\ulnone\cf1 Plugins}{\rtlch\ab\ai0\af2\afs26\ltrch\b\i0\fs26\loch\af2\dbch\af2\hich\f2\insrsid10976062\strike0\ulnone\cf1\par}\pard\plain\itap0\s0\ilvl0\fi0\sb0\sa0\aspalpha\aspnum\adjustright\brdrt\brdrl\brdrb\brdrr\brdrbtw\brdrbar \widctlpar\ltrpar\li0\lin0\ri0\rin0\ql\faauto\sl276\slmult1\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 None}{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\insrsid10976062\strike0\ulnone\cf1\par}\pard\plain\itap0\s3\ilvl0\fi0\sb280\sa80\aspalpha\aspnum\adjustright\brdrt\brdrl\brdrb\brdrr\brdrbtw\brdrbar\widctlpar\ltrpar\li0\lin0\ri0\rin0\ql\faauto\sl276\slmult1\rtlch\ab0\ai0\af2\afs28 \ltrch\b0\i0\fs28\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf2{\*\bkmkstart h.abvar771g6qp}{\*\bkmkend h.abvar771g6qp}{\rtlch\ab\ai0\af2\afs26\ltrch\b\i0\fs26\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 Fuel}{\rtlch\ab\ai0\af2\afs26\ltrch\b\i0\fs26\loch\af2 \dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab\ai0\af2\afs26\ltrch\b\i0\fs26\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 Library}{\rtlch\ab\ai0\af2\afs26\ltrch\b\i0\fs26\loch\af2\dbch\af2\hich\f2\insrsid10976062\strike0\ulnone\cf1\par}\pard\plain\itap0\s0\ilvl0\fi0\sb0\sa0 \aspalpha\aspnum\adjustright\brdrt\brdrl\brdrb\brdrr\brdrbtw\brdrbar\widctlpar\ltrpar\li0\lin0\ri0\rin0\ql\faauto\sl276\slmult1\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2 \dbch\af2\hich\f2\strike0\ulnone\cf1 Before}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 publishing}{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 each}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 Maintenance}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 Update} {\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 the}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0 \ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 file}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 ""}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2 \hich\f2\strike0\ulnone\cf1 mu}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 -}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 version}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22 \loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 .}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 json}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 "" }{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 should}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 be}{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 \line }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 updated}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{ \rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 in}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0 \ulnone\cf1 the}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 fuel}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2 \hich\f2\strike0\ulnone\cf1 -}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 library}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 `}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22 \loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 files}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 /}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 fuel}{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 -}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 misc}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 ` }{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 folder}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 . }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 This}{ \rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 file}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0 \ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 will}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2 \hich\f2\strike0\ulnone\cf1 be}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 \line }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 delivered}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22 \loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 to}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 all}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 nodes}{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 as}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 an}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 update}{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 of}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 the}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 `}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 fuel}{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 -}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 misc}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 ` }{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 package}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 .}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\insrsid10976062\strike0 \ulnone\cf1\par}\pard\plain\itap0\s2\ilvl0\fi0\sb360\sa80\aspalpha\aspnum\adjustright\brdrt\brdrl\brdrb\brdrr\brdrbtw\brdrbar\widctlpar\ltrpar\li0\lin0\ri0\rin0\ql\faauto\sl276\slmult1\rtlch\ab0\ai0\af2\afs32\ltrch\b0\i0\fs32\loch\af2\dbch\af2\hich\f2\strike0 \ulnone\cf1{\*\bkmkstart h.nf1v306i8e73}{\*\bkmkend h.nf1v306i8e73}{\rtlch\ab\ai0\af2\afs34\ltrch\b\i0\fs34\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 Alternatives}{\rtlch\ab\ai0\af2\afs34\ltrch\b\i0\fs34\loch\af2\dbch\af2\hich\f2\insrsid10976062\strike0 \ulnone\cf1\par}\pard\plain\itap0\s0\ilvl0\fi0\sb0\sa0\aspalpha\aspnum\adjustright\brdrt\brdrl\brdrb\brdrr\brdrbtw\brdrbar\widctlpar\ltrpar\li0\lin0\ri0\rin0\ql\faauto\sl276\slmult1\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0 \ulnone\cf1{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 Alternative}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2 \hich\f2\strike0\ulnone\cf1 way}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 of}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22 \loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 installing}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 maintenance}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 updates} {\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 on}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0 \ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 slave}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2 \hich\f2\strike0\ulnone\cf1 nodes}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 is}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22 \loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 to}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 use}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 current}{ \rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 method}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0 \ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 with}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2 \hich\f2\strike0\ulnone\cf1 mos}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 _}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 apply}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22 \loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 _}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 mu}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 .}{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 py}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 script}{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 and}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 restarting}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 services} {\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 manually}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0 \ulnone\cf1 . }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 This}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2 \hich\f2\strike0\ulnone\cf1 case}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 described}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22 \loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 here}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 at}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 [2].}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\insrsid10976062\strike0\ulnone\cf1 \par}\pard\plain\itap0\s0\ilvl0\fi0\sb0\sa0\aspalpha\aspnum\adjustright\brdrt\brdrl\brdrb\brdrr\brdrbtw\brdrbar\widctlpar\ltrpar\li0\lin0\ri0\rin0\ql\faauto\sl276\slmult1\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1{ \rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 Also}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0 \ulnone\cf1 we}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 can}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2 \hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 install}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22 \loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 maintenance}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 updates}{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 manually}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 using}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 package}{ \rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 management}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0 \ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 system}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2 \hich\f2\strike0\ulnone\cf1 on}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 every}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22 \loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 slave}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 node}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 , }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 but}{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 this}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 method}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 works}{ \rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 for}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0 \ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 small}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2 \hich\f2\strike0\ulnone\cf1 environments}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 as}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22 \loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 it}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 requires}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 lots}{ \rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 of}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0 \ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 manual}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2 \hich\f2\strike0\ulnone\cf1 actions}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 and}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22 \loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 is}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 error}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 prone}{ \rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 .}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\insrsid10976062\strike0\ulnone\cf1\par}\pard\plain\itap0\s2\ilvl0\fi0\sb360\sa80\aspalpha\aspnum \adjustright\brdrt\brdrl\brdrb\brdrr\brdrbtw\brdrbar\widctlpar\ltrpar\li0\lin0\ri0\rin0\ql\faauto\sl276\slmult1\rtlch\ab0\ai0\af2\afs32\ltrch\b0\i0\fs32\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1{\*\bkmkstart h.l9hx59ufpryr}{\*\bkmkend h.l9hx59ufpryr}{\rtlch\ab\ai0\af2\afs34 \ltrch\b\i0\fs34\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 Upgrade}{\rtlch\ab\ai0\af2\afs34\ltrch\b\i0\fs34\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab\ai0\af2\afs34\ltrch\b\i0\fs34\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 impact}{\rtlch\ab\ai0\af2\afs34 \ltrch\b\i0\fs34\loch\af2\dbch\af2\hich\f2\insrsid10976062\strike0\ulnone\cf1\par}\pard\plain\itap0\s0\ilvl0\fi0\sb0\sa0\aspalpha\aspnum\adjustright\brdrt\brdrl\brdrb\brdrr\brdrbtw\brdrbar\widctlpar\ltrpar\li0\lin0\ri0\rin0\ql\faauto\sl276\slmult1\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 None}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 .}{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\insrsid10976062\strike0\ulnone\cf1\par}\pard\plain\itap0\s2\ilvl0\fi0\sb360\sa80\aspalpha\aspnum\adjustright\brdrt\brdrl\brdrb\brdrr\brdrbtw\brdrbar\widctlpar\ltrpar\li0\lin0\ri0\rin0\ql\faauto\sl276\slmult1\rtlch\ab0\ai0\af2\afs32 \ltrch\b0\i0\fs32\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1{\*\bkmkstart h.avcetpu7mgim}{\*\bkmkend h.avcetpu7mgim}{\rtlch\ab\ai0\af2\afs34\ltrch\b\i0\fs34\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 Security}{\rtlch\ab\ai0\af2\afs34\ltrch\b\i0\fs34\loch\af2 \dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab\ai0\af2\afs34\ltrch\b\i0\fs34\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 impact}{\rtlch\ab\ai0\af2\afs34\ltrch\b\i0\fs34\loch\af2\dbch\af2\hich\f2\insrsid10976062\strike0\ulnone\cf1\par}\pard\plain\itap0\s0\ilvl0\fi0\sb0\sa0 \aspalpha\aspnum\adjustright\brdrt\brdrl\brdrb\brdrr\brdrbtw\brdrbar\widctlpar\ltrpar\li0\lin0\ri0\rin0\ql\faauto\sl276\slmult1\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2 \dbch\af2\hich\f2\strike0\ulnone\cf1 None}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 .}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\insrsid10976062\strike0\ulnone\cf1\par}\pard\plain\itap0\s2\ilvl0\fi0\sb360\sa80 \aspalpha\aspnum\adjustright\brdrt\brdrl\brdrb\brdrr\brdrbtw\brdrbar\widctlpar\ltrpar\li0\lin0\ri0\rin0\ql\faauto\sl276\slmult1\rtlch\ab0\ai0\af2\afs32\ltrch\b0\i0\fs32\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1{\*\bkmkstart h.awoh9k6zpxa}{\*\bkmkend h.awoh9k6zpxa} {\rtlch\ab\ai0\af2\afs34\ltrch\b\i0\fs34\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 Notifications}{\rtlch\ab\ai0\af2\afs34\ltrch\b\i0\fs34\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab\ai0\af2\afs34\ltrch\b\i0\fs34\loch\af2\dbch\af2\hich\f2\strike0 \ulnone\cf1 impact}{\rtlch\ab\ai0\af2\afs34\ltrch\b\i0\fs34\loch\af2\dbch\af2\hich\f2\insrsid10976062\strike0\ulnone\cf1\par}\pard\plain\itap0\s0\ilvl0\fi0\sb0\sa0\aspalpha\aspnum\adjustright\brdrt\brdrl\brdrb\brdrr\brdrbtw\brdrbar\widctlpar\ltrpar\li0\lin0\ri0\rin0 \ql\faauto\sl276\slmult1\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 None}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2 \dbch\af2\hich\f2\strike0\ulnone\cf1 .}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\insrsid10976062\strike0\ulnone\cf1\par}\pard\plain\itap0\s2\ilvl0\fi0\sb360\sa80\aspalpha\aspnum\adjustright\brdrt\brdrl\brdrb\brdrr\brdrbtw\brdrbar \widctlpar\ltrpar\li0\lin0\ri0\rin0\ql\faauto\sl276\slmult1\rtlch\ab0\ai0\af2\afs32\ltrch\b0\i0\fs32\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1{\*\bkmkstart h.vtjoiwrb7afv}{\*\bkmkend h.vtjoiwrb7afv}{\rtlch\ab\ai0\af2\afs34\ltrch\b\i0\fs34\loch\af2\dbch\af2 \hich\f2\strike0\ulnone\cf1 End}{\rtlch\ab\ai0\af2\afs34\ltrch\b\i0\fs34\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab\ai0\af2\afs34\ltrch\b\i0\fs34\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 user}{\rtlch\ab\ai0\af2\afs34\ltrch\b\i0\fs34\loch\af2 \dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab\ai0\af2\afs34\ltrch\b\i0\fs34\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 impact}{\rtlch\ab\ai0\af2\afs34\ltrch\b\i0\fs34\loch\af2\dbch\af2\hich\f2\insrsid10976062\strike0\ulnone\cf1\par}\pard\plain\itap0\s0\ilvl0\fi0\sb0\sa0 \aspalpha\aspnum\adjustright\brdrt\brdrl\brdrb\brdrr\brdrbtw\brdrbar\widctlpar\ltrpar\li0\lin0\ri0\rin0\ql\faauto\sl276\slmult1\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2 \dbch\af2\hich\f2\strike0\ulnone\cf1 User}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 experience}{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 for}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 installing}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 maintenance} {\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 updates}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0 \ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 on}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0 \ulnone\cf1 slave}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 nodes}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2 \hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 nodes}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22 \loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 changes}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 significantly}{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 . }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 Instead}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 of}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 executing}{ \rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 mos}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0 \ulnone\cf1 _}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 apply}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 _}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2 \hich\f2\strike0\ulnone\cf1 mu}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 .}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 py}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22 \loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 script}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 on}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 Fuel}{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 master}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 node}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 and}{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 manually}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 restarting}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 servises} {\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 on}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0 \ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 all}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2 \hich\f2\strike0\ulnone\cf1 Fuel}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 slave}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22 \loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 nodes}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 user}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 shall}{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 upload}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 custom}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 graph}{ \rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 and}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0 \ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 execute}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2 \hich\f2\strike0\ulnone\cf1 it}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 . }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 Also}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22 \loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 custom}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 graph}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 engine}{ \rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 allows}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0 \ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 us}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0 \ulnone\cf1 to}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 see}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2 \hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 the}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22 \loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 history}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 with}{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 the}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 statuses}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 of}{ \rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 every}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0 \ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 particular}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2 \hich\f2\strike0\ulnone\cf1 task}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 in}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22 \loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 the}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 each}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 execution}{ \rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 of}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0 \ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 the}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2 \hich\f2\strike0\ulnone\cf1 graph}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 .}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\insrsid10976062\strike0\ulnone\cf1\par}\pard\plain\itap0\s2\ilvl0\fi0\sb360\sa80 \aspalpha\aspnum\adjustright\brdrt\brdrl\brdrb\brdrr\brdrbtw\brdrbar\widctlpar\ltrpar\li0\lin0\ri0\rin0\ql\faauto\sl276\slmult1\rtlch\ab0\ai0\af2\afs32\ltrch\b0\i0\fs32\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1{\*\bkmkstart h.o9rv2jmbzuxq}{\*\bkmkend h.o9rv2jmbzuxq} {\rtlch\ab\ai0\af2\afs34\ltrch\b\i0\fs34\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 Performance}{\rtlch\ab\ai0\af2\afs34\ltrch\b\i0\fs34\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab\ai0\af2\afs34\ltrch\b\i0\fs34\loch\af2\dbch\af2\hich\f2\strike0 \ulnone\cf1 impact}{\rtlch\ab\ai0\af2\afs34\ltrch\b\i0\fs34\loch\af2\dbch\af2\hich\f2\insrsid10976062\strike0\ulnone\cf1\par}\pard\plain\itap0\s0\ilvl0\fi0\sb0\sa0\aspalpha\aspnum\adjustright\brdrt\brdrl\brdrb\brdrr\brdrbtw\brdrbar\widctlpar\ltrpar\li0\lin0\ri0\rin0 \ql\faauto\sl276\slmult1\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 None}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2 \dbch\af2\hich\f2\strike0\ulnone\cf1 .}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\insrsid10976062\strike0\ulnone\cf1\par}\pard\plain\itap0\s2\ilvl0\fi0\sb360\sa80\aspalpha\aspnum\adjustright\brdrt\brdrl\brdrb\brdrr\brdrbtw\brdrbar \widctlpar\ltrpar\li0\lin0\ri0\rin0\ql\faauto\sl276\slmult1\rtlch\ab0\ai0\af2\afs32\ltrch\b0\i0\fs32\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1{\*\bkmkstart h.ggxvejo3krp8}{\*\bkmkend h.ggxvejo3krp8}{\rtlch\ab\ai0\af2\afs34\ltrch\b\i0\fs34\loch\af2\dbch\af2 \hich\f2\strike0\ulnone\cf1 Deployment}{\rtlch\ab\ai0\af2\afs34\ltrch\b\i0\fs34\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab\ai0\af2\afs34\ltrch\b\i0\fs34\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 impact}{\rtlch\ab\ai0\af2\afs34\ltrch\b\i0\fs34 \loch\af2\dbch\af2\hich\f2\insrsid10976062\strike0\ulnone\cf1\par}\pard\plain\itap0\s0\ilvl0\fi0\sb0\sa0\aspalpha\aspnum\adjustright\brdrt\brdrl\brdrb\brdrr\brdrbtw\brdrbar\widctlpar\ltrpar\li0\lin0\ri0\rin0\ql\faauto\sl276\slmult1\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 This}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 spec}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 affects}{ \rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 only}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0 \ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 post}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 -}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2 \hich\f2\strike0\ulnone\cf1 deployment}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 process}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22 \loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 .}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\insrsid10976062\strike0\ulnone\cf1\par}\pard\plain\itap0\s2\ilvl0\fi0\sb360\sa80\aspalpha\aspnum\adjustright\brdrt\brdrl\brdrb\brdrr\brdrbtw \brdrbar\widctlpar\ltrpar\li0\lin0\ri0\rin0\ql\faauto\sl276\slmult1\rtlch\ab0\ai0\af2\afs32\ltrch\b0\i0\fs32\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1{\*\bkmkstart h.vhzba5xu3kbe}{\*\bkmkend h.vhzba5xu3kbe}{\rtlch\ab\ai0\af2\afs34\ltrch\b\i0\fs34\loch\af2 \dbch\af2\hich\f2\strike0\ulnone\cf1 Developer}{\rtlch\ab\ai0\af2\afs34\ltrch\b\i0\fs34\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab\ai0\af2\afs34\ltrch\b\i0\fs34\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 impact}{\rtlch\ab\ai0\af2\afs34\ltrch\b\i0\fs34 \loch\af2\dbch\af2\hich\f2\insrsid10976062\strike0\ulnone\cf1\par}\pard\plain\itap0\s0\ilvl0\fi0\sb0\sa0\aspalpha\aspnum\adjustright\brdrt\brdrl\brdrb\brdrr\brdrbtw\brdrbar\widctlpar\ltrpar\li0\lin0\ri0\rin0\ql\faauto\sl276\slmult1\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 None}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 .}{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\insrsid10976062\strike0\ulnone\cf1\par}\pard\plain\itap0\s2\ilvl0\fi0\sb360\sa80\aspalpha\aspnum\adjustright\brdrt\brdrl\brdrb\brdrr\brdrbtw\brdrbar\widctlpar\ltrpar\li0\lin0\ri0\rin0\ql\faauto\sl276\slmult1\rtlch\ab0\ai0\af2\afs32 \ltrch\b0\i0\fs32\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1{\*\bkmkstart h.p8o218bmxhwp}{\*\bkmkend h.p8o218bmxhwp}{\rtlch\ab\ai0\af2\afs34\ltrch\b\i0\fs34\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 Infrastructure}{\rtlch\ab\ai0\af2\afs34\ltrch\b\i0\fs34 \loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab\ai0\af2\afs34\ltrch\b\i0\fs34\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 impact}{\rtlch\ab\ai0\af2\afs34\ltrch\b\i0\fs34\loch\af2\dbch\af2\hich\f2\insrsid10976062\strike0\ulnone\cf1\par}\pard\plain\itap0\s0\ilvl0\fi0\sb0\sa0 \aspalpha\aspnum\adjustright\brdrt\brdrl\brdrb\brdrr\brdrbtw\brdrbar\widctlpar\ltrpar\li0\lin0\ri0\rin0\ql\faauto\sl276\slmult1\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2 \dbch\af2\hich\f2\strike0\ulnone\cf1 Custom}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 graph}{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 for}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 applying}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 MU}{ \rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 should}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0 \ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 be}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0 \ulnone\cf1 added}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 to}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2 \hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 fuel}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 -}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22 \loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 misc}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 package}{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 and}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 stored}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 on}{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 a}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 mirror}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 .}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\insrsid10976062\strike0\ulnone\cf1 \par}\pard\plain\itap0\s0\ilvl0\fi0\sb0\sa0\aspalpha\aspnum\adjustright\brdrt\brdrl\brdrb\brdrr\brdrbtw\brdrbar\widctlpar\ltrpar\li0\lin0\ri0\rin0\ql\faauto\sl276\slmult1\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1{ \rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\insrsid10976062\strike0\ulnone\cf1\par}\pard\plain\itap0\s0\ilvl0\fi0\sb0\sa0\aspalpha\aspnum\adjustright\brdrt\brdrl\brdrb\brdrr\brdrbtw\brdrbar\widctlpar\ltrpar\li0\lin0\ri0\rin0\ql\faauto\sl276 \slmult1\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 For}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0 \ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 each}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2 \hich\f2\strike0\ulnone\cf1 MOS}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 release}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22 \loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 should}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 be}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 created}{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 a}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 file}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 , }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 which}{ \rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 will}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0 \ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 contain}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2 \hich\f2\strike0\ulnone\cf1 information}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 \line }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 about}{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 the}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 latest}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 MU}{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 available}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 . }{ \rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 These}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0 \ulnone\cf1 files}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 should}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2 \hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 be}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2 \dbch\af2\hich\f2\strike0\ulnone\cf1 published}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 in}{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 the}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 \line `/}{ \rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 mcv}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 /}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0 \ulnone\cf1 mos}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 /$}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 mos}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2 \hich\f2\strike0\ulnone\cf1 _}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 version}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 /` }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22 \loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 folders}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 on}{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 the}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 `}{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 mirror}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 .}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 fuel}{ \rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 -}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 infra}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0 \ulnone\cf1 .}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 org}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 ` }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2 \hich\f2\strike0\ulnone\cf1 server}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 and}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22 \loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 \line }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 named}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 as}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 `}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 mu}{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 -}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 version}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 .}{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 json}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 `. }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 The}{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 publishing}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{ \rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 of}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0 \ulnone\cf1 a}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 file}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2 \hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 will}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22 \loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 serve}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 as}{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 a}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 signal}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 that}{ \rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 new}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0 \ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 MU}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0 \ulnone\cf1 is}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 available}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2 \hich\f2\strike0\ulnone\cf1 .\line }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 The}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22 \loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 contents}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 of}{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 files}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 is}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 a}{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 JSON}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 -}{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 formatted}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 data}{ \rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 .\line }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 For}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0 \ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 example}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 `/}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2 \hich\f2\strike0\ulnone\cf1 mcv}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 /}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 mos}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22 \loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 /8.0/}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 mu}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 -}{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 version}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 .}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 json}{ \rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 `::\line \line \{\line ""}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 id}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22 \loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 "": 3,\line ""}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 title}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 "": ""8.0-}{ \rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 MU}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 -3"",\line ""}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2 \hich\f2\strike0\ulnone\cf1 timestamp}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 "": 1467647277,\line ""}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 doc}{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 _}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 link}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 "": ""}{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 https}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 ://}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 docs}{ \rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 .}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 mirantis}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0 \ulnone\cf1 .}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 com}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 /}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2 \hich\f2\strike0\ulnone\cf1 openstack}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 /}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 fuel}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22 \loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 /}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 fuel}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 -8.0/}{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 maintenance}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 -}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 updates} {\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 .}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 html}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0 \ulnone\cf1 ""\line \}\line \line }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 The}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22 \loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 fields}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 ``}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 id}{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 ``, ``}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 title}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 `` }{ \rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 and}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 ``}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0 \ulnone\cf1 timestamp}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 `` }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 are}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2 \dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 mandatory}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 , }{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 others}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 are}{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 \line }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 optional}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 . }{ \rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 The}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 ``}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0 \ulnone\cf1 timestamp}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 `` }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 field}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2 \dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 has}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22 \loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 the}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 Epoch}{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 time}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 -}{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 format}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 . }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 The}{ \rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 ``}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 id}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0 \ulnone\cf1 `` }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 field}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 \line }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2 \dbch\af2\hich\f2\strike0\ulnone\cf1 represents}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 the}{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 number}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 of}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 the}{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 update}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 in}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 a}{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 sequence}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 .\line \line } {\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 Such}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0 \ulnone\cf1 a}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 file}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2 \hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 will}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22 \loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 be}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 generated}{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 for}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 every}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 Maintenance}{ \rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 Update}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0 \ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 when}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2 \hich\f2\strike0\ulnone\cf1 it}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 will}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22 \loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 be}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 \line }{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 published}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 allowing} {\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 end}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0 \ulnone\cf1 -}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 users}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2 \hich\f2\strike0\ulnone\cf1 to}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 keep}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22 \loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 themselves}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 informed}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 . }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 The}{ \rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 creation}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0 \ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 of}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 \line }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2 \hich\f2\strike0\ulnone\cf1 files}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 should}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22 \loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 be}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 implemented}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 as}{ \rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 part}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0 \ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 of}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0 \ulnone\cf1 the}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 MU}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2 \hich\f2\strike0\ulnone\cf1 -}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 publisher}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22 \loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 job}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 .\line }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\insrsid10976062\strike0\ulnone\cf1\par} \pard\plain\itap0\s2\ilvl0\fi0\sb360\sa80\aspalpha\aspnum\adjustright\brdrt\brdrl\brdrb\brdrr\brdrbtw\brdrbar\widctlpar\ltrpar\li0\lin0\ri0\rin0\ql\faauto\sl276\slmult1\rtlch\ab0\ai0\af2\afs32\ltrch\b0\i0\fs32\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1{ \*\bkmkstart h.vn5572yb0134}{\*\bkmkend h.vn5572yb0134}{\rtlch\ab\ai0\af2\afs34\ltrch\b\i0\fs34\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 Documentation}{\rtlch\ab\ai0\af2\afs34\ltrch\b\i0\fs34\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab\ai0\af2\afs34 \ltrch\b\i0\fs34\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 impact}{\rtlch\ab\ai0\af2\afs34\ltrch\b\i0\fs34\loch\af2\dbch\af2\hich\f2\insrsid10976062\strike0\ulnone\cf1\par}\pard\plain\itap0\s0\ilvl0\ls1\tx360\tx720\fi-360\sb0\sa0\aspalpha\aspnum \adjustright\brdrt\brdrl\brdrb\brdrr\brdrbtw\brdrbar\widctlpar\ltrpar\li720\lin720\ri0\rin0\ql\faauto\sl276\slmult1\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1{\listtext\pard\plain\tx360\fi-360\aspalpha\aspnum\adjustright \ltrpar\li720\lin720\ri0\rin0\ql\faauto\rtlch\ab0\ai0\af2\afs22\ltrch\fs22\loch\af2\dbch\af2\hich\f2\insrsid10976062\strike0\ulnone\cf1 \u9679 \tab }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 New}{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 maintenance}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{ \rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 updates}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0 \ulnone\cf1 workflow}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 shall}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2 \dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 be}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22 \loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 documented}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 in}{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 respective}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{ \rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 section}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0 \ulnone\cf1 of}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 MOS}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2 \hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 documentation}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 .}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22 \loch\af2\dbch\af2\hich\f2\insrsid10976062\strike0\ulnone\cf1\par}\pard\plain\itap0\s2\ilvl0\fi0\sb360\sa80\aspalpha\aspnum\adjustright\brdrt\brdrl\brdrb\brdrr\brdrbtw\brdrbar\widctlpar\ltrpar\li0\lin0\ri0\rin0\ql\faauto\sl276\slmult1\rtlch\ab0\ai0\af2\afs32 \ltrch\b0\i0\fs32\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1{\*\bkmkstart h.b714xh3299tn}{\*\bkmkend h.b714xh3299tn}{\rtlch\ab\ai0\af2\afs34\ltrch\b\i0\fs34\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 Implementation}{\rtlch\ab\ai0\af2\afs34\ltrch\b\i0\fs34 \loch\af2\dbch\af2\hich\f2\insrsid10976062\strike0\ulnone\cf1\par}\pard\plain\itap0\s3\ilvl0\fi0\sb280\sa80\aspalpha\aspnum\adjustright\brdrt\brdrl\brdrb\brdrr\brdrbtw\brdrbar\widctlpar\ltrpar\li0\lin0\ri0\rin0\ql\faauto\sl276\slmult1\rtlch\ab0\ai0\af2\afs28 \ltrch\b0\i0\fs28\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf2{\*\bkmkstart h.4blo52puh5hf}{\*\bkmkend h.4blo52puh5hf}{\rtlch\ab\ai0\af2\afs26\ltrch\b\i0\fs26\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 Assignee}{\rtlch\ab\ai0\af2\afs26\ltrch\b\i0\fs26\loch\af2 \dbch\af2\hich\f2\strike0\ulnone\cf1 (}{\rtlch\ab\ai0\af2\afs26\ltrch\b\i0\fs26\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 s}{\rtlch\ab\ai0\af2\afs26\ltrch\b\i0\fs26\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 )}{\rtlch\ab\ai0\af2\afs26\ltrch\b\i0\fs26 \loch\af2\dbch\af2\hich\f2\insrsid10976062\strike0\ulnone\cf1\par}\pard\plain\itap0\s0\ilvl0\fi0\sb0\sa0\aspalpha\aspnum\adjustright\brdrt\brdrl\brdrb\brdrr\brdrbtw\brdrbar\widctlpar\ltrpar\li0\lin0\ri0\rin0\ql\faauto\sl276\slmult1\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 Primary}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 assignee}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 :}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\insrsid10976062\strike0 \ulnone\cf1\par}\pard\plain\itap0\s0\ilvl0\fi0\sb0\sa0\aspalpha\aspnum\adjustright\brdrt\brdrl\brdrb\brdrr\brdrbtw\brdrbar\widctlpar\ltrpar\li0\lin0\ri0\rin0\ql\faauto\sl276\slmult1\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0 \ulnone\cf1{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 Sergii}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2 \hich\f2\strike0\ulnone\cf1 Rizvan}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 <}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 srizvan}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22 \loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 @}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 mirantis}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 .}{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 com}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 >}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\insrsid10976062\strike0\ulnone\cf1 \par}\pard\plain\itap0\s0\ilvl0\fi0\sb0\sa0\aspalpha\aspnum\adjustright\brdrt\brdrl\brdrb\brdrr\brdrbtw\brdrbar\widctlpar\ltrpar\li0\lin0\ri0\rin0\ql\faauto\sl276\slmult1\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1{ \rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\insrsid10976062\strike0\ulnone\cf1\par}\pard\plain\itap0\s0\ilvl0\fi0\sb0\sa0\aspalpha\aspnum\adjustright\brdrt\brdrl\brdrb\brdrr\brdrbtw\brdrbar\widctlpar\ltrpar\li0\lin0\ri0\rin0\ql\faauto\sl276 \slmult1\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 Mandatory}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0 \ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 design}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2 \hich\f2\strike0\ulnone\cf1 review}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 :}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\insrsid10976062\strike0\ulnone\cf1\par}\pard\plain\itap0\s0\ilvl0\fi0\sb0\sa0 \aspalpha\aspnum\adjustright\brdrt\brdrl\brdrb\brdrr\brdrbtw\brdrbar\widctlpar\ltrpar\li0\lin0\ri0\rin0\ql\faauto\sl276\slmult1\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2 \dbch\af2\hich\f2\strike0\ulnone\cf1 Vitaly}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 Sedelnik}{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 <}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 vsedelnik}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 @}{ \rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 mirantis}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 .}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0 \ulnone\cf1 com}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 >, }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 Denis}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2 \hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 Meltsaykin}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 <}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22 \loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 dmeltsaykin}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 @}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 mirantis}{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 .}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 com}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 >}{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\insrsid10976062\strike0\ulnone\cf1\par}\pard\plain\itap0\s3\ilvl0\fi0\sb280\sa80\aspalpha\aspnum\adjustright\brdrt\brdrl\brdrb\brdrr\brdrbtw\brdrbar\widctlpar\ltrpar\li0\lin0\ri0\rin0\ql\faauto\sl276\slmult1\rtlch\ab0\ai0\af2\afs28 \ltrch\b0\i0\fs28\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf2{\*\bkmkstart h.grw2m9bjwz0a}{\*\bkmkend h.grw2m9bjwz0a}{\rtlch\ab\ai0\af2\afs26\ltrch\b\i0\fs26\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 Work}{\rtlch\ab\ai0\af2\afs26\ltrch\b\i0\fs26\loch\af2 \dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab\ai0\af2\afs26\ltrch\b\i0\fs26\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 Items}{\rtlch\ab\ai0\af2\afs26\ltrch\b\i0\fs26\loch\af2\dbch\af2\hich\f2\insrsid10976062\strike0\ulnone\cf1\par}\pard\plain\itap0\s0\ilvl0\ls1\tx360\tx720\fi-360\sb0\sa0 \aspalpha\aspnum\adjustright\brdrt\brdrl\brdrb\brdrr\brdrbtw\brdrbar\widctlpar\ltrpar\li720\lin720\ri0\rin0\ql\faauto\sl276\slmult1\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1{\listtext\pard\plain\tx360\fi-360\aspalpha \aspnum\adjustright\ltrpar\li720\lin720\ri0\rin0\ql\faauto\rtlch\ab0\ai0\af2\afs22\ltrch\fs22\loch\af2\dbch\af2\hich\f2\insrsid10976062\strike0\ulnone\cf1 \u9679 \tab }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 Write} {\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 custom}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0 \ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 graph}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2 \hich\f2\strike0\ulnone\cf1 for}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 MU}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22 \loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 .}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\insrsid10976062\strike0\ulnone\cf1\par}\pard\plain\itap0\s0\ilvl0\ls1\tx360\tx720\fi-360\sb0\sa0\aspalpha\aspnum\adjustright\brdrt\brdrl \brdrb\brdrr\brdrbtw\brdrbar\widctlpar\ltrpar\li720\lin720\ri0\rin0\ql\faauto\sl276\slmult1\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1{\listtext\pard\plain\tx360\fi-360\aspalpha\aspnum\adjustright\ltrpar\li720\lin720\ri0\rin0 \ql\faauto\rtlch\ab0\ai0\af2\afs22\ltrch\fs22\loch\af2\dbch\af2\hich\f2\insrsid10976062\strike0\ulnone\cf1 \u9679 \tab }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 Add}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22 \loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 custom}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 graph}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 into}{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 python}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 -}{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 fuelclient}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 package} {\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 and}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0 \ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 place}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2 \hich\f2\strike0\ulnone\cf1 the}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 packet}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22 \loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 on}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 a}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 mirror}{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 .}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\insrsid10976062\strike0\ulnone\cf1\par}\pard\plain\itap0\s0\ilvl0\ls1\tx360\tx720\fi-360\sb0\sa0\aspalpha\aspnum\adjustright \brdrt\brdrl\brdrb\brdrr\brdrbtw\brdrbar\widctlpar\ltrpar\li720\lin720\ri0\rin0\ql\faauto\sl276\slmult1\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1{\listtext\pard\plain\tx360\fi-360\aspalpha\aspnum\adjustright\ltrpar\li720\lin720\ri0\rin0 \ql\faauto\rtlch\ab0\ai0\af2\afs22\ltrch\fs22\loch\af2\dbch\af2\hich\f2\insrsid10976062\strike0\ulnone\cf1 \u9679 \tab }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 Implement}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22 \loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 the}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 `}{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 updates}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 -}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 check}{ \rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 -}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 installed}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0 \ulnone\cf1 `, `}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 updates}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 -}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2 \hich\f2\strike0\ulnone\cf1 check}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 -}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 available}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22 \loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 ` }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 and}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 `}{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 updates}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 -}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 install}{ \rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 ` }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 commands}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0 \ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 in}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0 \ulnone\cf1 python}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 -}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 fuelclient}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2 \dbch\af2\hich\f2\strike0\ulnone\cf1 .}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\insrsid10976062\strike0\ulnone\cf1\par}\pard\plain\itap0\s0\ilvl0\ls1\tx360\tx720\fi-360\sb0\sa0\aspalpha\aspnum\adjustright\brdrt\brdrl\brdrb\brdrr \brdrbtw\brdrbar\widctlpar\ltrpar\li720\lin720\ri0\rin0\ql\faauto\sl276\slmult1\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1{\listtext\pard\plain\tx360\fi-360\aspalpha\aspnum\adjustright\ltrpar\li720\lin720\ri0\rin0\ql \faauto\rtlch\ab0\ai0\af2\afs22\ltrch\fs22\loch\af2\dbch\af2\hich\f2\insrsid10976062\strike0\ulnone\cf1 \u9679 \tab }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 Implement}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22 \loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 updates}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 installation}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 with}{ \rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 a}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0 \ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 custom}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2 \hich\f2\strike0\ulnone\cf1 graph}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 in}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22 \loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 the}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 fuel}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 -}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 qa}{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 framework}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 . }{ \rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\insrsid10976062\strike0\ulnone\cf1\par}\pard\plain\itap0\s3\ilvl0\fi0\sb280\sa80\aspalpha\aspnum\adjustright\brdrt\brdrl\brdrb\brdrr\brdrbtw\brdrbar\widctlpar\ltrpar\li0\lin0\ri0\rin0\ql \faauto\sl276\slmult1\rtlch\ab0\ai0\af2\afs28\ltrch\b0\i0\fs28\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf2{\*\bkmkstart h.ojqo1quxg57r}{\*\bkmkend h.ojqo1quxg57r}{\rtlch\ab\ai0\af2\afs26\ltrch\b\i0\fs26\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 Dependencies} {\rtlch\ab\ai0\af2\afs26\ltrch\b\i0\fs26\loch\af2\dbch\af2\hich\f2\insrsid10976062\strike0\ulnone\cf1\par}\pard\plain\itap0\s0\ilvl0\fi0\sb0\sa0\aspalpha\aspnum\adjustright\brdrt\brdrl\brdrb\brdrr\brdrbtw\brdrbar\widctlpar\ltrpar\li0\lin0\ri0\rin0\ql \faauto\sl276\slmult1\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 None}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2 \hich\f2\strike0\ulnone\cf1 .}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\insrsid10976062\strike0\ulnone\cf1\par}\pard\plain\itap0\s2\ilvl0\fi0\sb360\sa80\aspalpha\aspnum\adjustright\brdrt\brdrl\brdrb\brdrr\brdrbtw\brdrbar\widctlpar \ltrpar\li0\lin0\ri0\rin0\ql\faauto\sl276\slmult1\rtlch\ab0\ai0\af2\afs32\ltrch\b0\i0\fs32\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1{\*\bkmkstart h.4x21i02pc64x}{\*\bkmkend h.4x21i02pc64x}{\rtlch\ab\ai0\af2\afs34\ltrch\b\i0\fs34\loch\af2\dbch\af2\hich\f2\strike0 \ulnone\cf1 Testing}{\rtlch\ab\ai0\af2\afs34\ltrch\b\i0\fs34\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 , }{\rtlch\ab\ai0\af2\afs34\ltrch\b\i0\fs34\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 QA}{\rtlch\ab\ai0\af2\afs34\ltrch\b\i0\fs34\loch\af2\dbch\af2 \hich\f2\insrsid10976062\strike0\ulnone\cf1\par}\pard\plain\itap0\s0\ilvl0\fi0\sb0\sa0\aspalpha\aspnum\adjustright\brdrt\brdrl\brdrb\brdrr\brdrbtw\brdrbar\widctlpar\ltrpar\li0\lin0\ri0\rin0\ql\faauto\sl276\slmult1\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22 \loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 Applying}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 updates}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 in}{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 the}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 QA}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 frameworks}{ \rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 should}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0 \ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 be}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0 \ulnone\cf1 used}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 with}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2 \hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 executing}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22 \loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 this}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 custom}{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 graph}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 .}{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\insrsid10976062\strike0\ulnone\cf1\par}\pard\plain\itap0\s3\ilvl0\fi0\sb280\sa80\aspalpha\aspnum\adjustright\brdrt\brdrl\brdrb\brdrr\brdrbtw\brdrbar\widctlpar\ltrpar\li0\lin0\ri0\rin0\ql\faauto\sl276\slmult1\rtlch\ab0\ai0\af2\afs28 \ltrch\b0\i0\fs28\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf2{\*\bkmkstart h.ohke5hnhxjpj}{\*\bkmkend h.ohke5hnhxjpj}{\rtlch\ab\ai0\af2\afs26\ltrch\b\i0\fs26\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 Acceptance}{\rtlch\ab\ai0\af2\afs26\ltrch\b\i0\fs26 \loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab\ai0\af2\afs26\ltrch\b\i0\fs26\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 criteria}{\rtlch\ab\ai0\af2\afs26\ltrch\b\i0\fs26\loch\af2\dbch\af2\hich\f2\insrsid10976062\strike0\ulnone\cf1\par}\pard \plain\itap0\s0\ilvl0\fi0\sb0\sa0\aspalpha\aspnum\adjustright\brdrt\brdrl\brdrb\brdrr\brdrbtw\brdrbar\widctlpar\ltrpar\li0\lin0\ri0\rin0\ql\faauto\sl276\slmult1\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 Maintenance}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 updates} {\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 could}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0 \ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 be}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0 \ulnone\cf1 installed}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 using}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2 \dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 custom}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22 \loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 deployment}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 graph}{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 via}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 executing}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 Fuel}{ \rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 CLI}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0 \ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 commands}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 .}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2 \hich\f2\insrsid10976062\strike0\ulnone\cf1\par}\pard\plain\itap0\s2\ilvl0\fi0\sb360\sa80\aspalpha\aspnum\adjustright\brdrt\brdrl\brdrb\brdrr\brdrbtw\brdrbar\widctlpar\ltrpar\li0\lin0\ri0\rin0\ql\faauto\sl276\slmult1\rtlch\ab0\ai0\af2\afs32\ltrch\b0\i0\fs32 \loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1{\*\bkmkstart h.j90g9wixhfx}{\*\bkmkend h.j90g9wixhfx}{\rtlch\ab\ai0\af2\afs34\ltrch\b\i0\fs34\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 References}{\rtlch\ab\ai0\af2\afs34\ltrch\b\i0\fs34\loch\af2\dbch\af2 \hich\f2\insrsid10976062\strike0\ulnone\cf1\par}\pard\plain\itap0\s0\ilvl0\ls2\tx360\tx720\fi-360\sb0\sa0\aspalpha\aspnum\adjustright\brdrt\brdrl\brdrb\brdrr\brdrbtw\brdrbar\widctlpar\ltrpar\li720\lin720\ri0\rin0\ql\faauto\sl276\slmult1\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1{\listtext\pard\plain\tx360\fi-360\aspalpha\aspnum\adjustright\ltrpar\li720\lin720\ri0\rin0\ql\faauto\rtlch\ab0\ai0\af2\afs22\ltrch\fs22\loch\af2\dbch\af2\hich\f2\insrsid10976062\strike0\ulnone\cf1 \u9679 \tab } {\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 [1]}{\field{\*\fldinst{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\insrsid10976062\strike0\ulnone\cf1 HYPERLINK ""https://raw.githubusercontent.com/Mirantis/tools-sustaining/master/scripts/mos_apply_mu.py""}} {\fldrslt{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ul\cf4 https}}}{\field{\*\fldinst{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\insrsid10976062\strike0\ulnone\cf1 HYPERLINK ""https://raw.githubusercontent.com/Mirantis/tools-sustaining/master/scripts/mos_apply_mu.py""}} {\fldrslt{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ul\cf4 ://}}}{\field{\*\fldinst{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\insrsid10976062\strike0\ulnone\cf1 HYPERLINK ""https://raw.githubusercontent.com/Mirantis/tools-sustaining/master/scripts/mos_apply_mu.py""}} {\fldrslt{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ul\cf4 raw}}}{\field{\*\fldinst{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\insrsid10976062\strike0\ulnone\cf1 HYPERLINK ""https://raw.githubusercontent.com/Mirantis/tools-sustaining/master/scripts/mos_apply_mu.py""}} {\fldrslt{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ul\cf4 .}}}{\field{\*\fldinst{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\insrsid10976062\strike0\ulnone\cf1 HYPERLINK ""https://raw.githubusercontent.com/Mirantis/tools-sustaining/master/scripts/mos_apply_mu.py""}} {\fldrslt{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ul\cf4 githubusercontent}}}{\field{\*\fldinst{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\insrsid10976062\strike0\ulnone\cf1 HYPERLINK ""https://raw.githubusercontent.com/Mirantis/tools-sustaining/master/scripts/mos_apply_mu.py""}} {\fldrslt{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ul\cf4 .}}}{\field{\*\fldinst{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\insrsid10976062\strike0\ulnone\cf1 HYPERLINK ""https://raw.githubusercontent.com/Mirantis/tools-sustaining/master/scripts/mos_apply_mu.py""}} {\fldrslt{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ul\cf4 com}}}{\field{\*\fldinst{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\insrsid10976062\strike0\ulnone\cf1 HYPERLINK ""https://raw.githubusercontent.com/Mirantis/tools-sustaining/master/scripts/mos_apply_mu.py""}} {\fldrslt{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ul\cf4 /}}}{\field{\*\fldinst{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\insrsid10976062\strike0\ulnone\cf1 HYPERLINK ""https://raw.githubusercontent.com/Mirantis/tools-sustaining/master/scripts/mos_apply_mu.py""}} {\fldrslt{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ul\cf4 Mirantis}}}{\field{\*\fldinst{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\insrsid10976062\strike0\ulnone\cf1 HYPERLINK ""https://raw.githubusercontent.com/Mirantis/tools-sustaining/master/scripts/mos_apply_mu.py""}} {\fldrslt{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ul\cf4 /}}}{\field{\*\fldinst{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\insrsid10976062\strike0\ulnone\cf1 HYPERLINK ""https://raw.githubusercontent.com/Mirantis/tools-sustaining/master/scripts/mos_apply_mu.py""}} {\fldrslt{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ul\cf4 tools}}}{\field{\*\fldinst{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\insrsid10976062\strike0\ulnone\cf1 HYPERLINK ""https://raw.githubusercontent.com/Mirantis/tools-sustaining/master/scripts/mos_apply_mu.py""}} {\fldrslt{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ul\cf4 -}}}{\field{\*\fldinst{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\insrsid10976062\strike0\ulnone\cf1 HYPERLINK ""https://raw.githubusercontent.com/Mirantis/tools-sustaining/master/scripts/mos_apply_mu.py""}} {\fldrslt{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ul\cf4 sustaining}}}{\field{\*\fldinst{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\insrsid10976062\strike0\ulnone\cf1 HYPERLINK ""https://raw.githubusercontent.com/Mirantis/tools-sustaining/master/scripts/mos_apply_mu.py""}} {\fldrslt{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ul\cf4 /}}}{\field{\*\fldinst{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\insrsid10976062\strike0\ulnone\cf1 HYPERLINK ""https://raw.githubusercontent.com/Mirantis/tools-sustaining/master/scripts/mos_apply_mu.py""}} {\fldrslt{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ul\cf4 master}}}{\field{\*\fldinst{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\insrsid10976062\strike0\ulnone\cf1 HYPERLINK ""https://raw.githubusercontent.com/Mirantis/tools-sustaining/master/scripts/mos_apply_mu.py""}} {\fldrslt{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ul\cf4 /}}}{\field{\*\fldinst{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\insrsid10976062\strike0\ulnone\cf1 HYPERLINK ""https://raw.githubusercontent.com/Mirantis/tools-sustaining/master/scripts/mos_apply_mu.py""}} {\fldrslt{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ul\cf4 scripts}}}{\field{\*\fldinst{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\insrsid10976062\strike0\ulnone\cf1 HYPERLINK ""https://raw.githubusercontent.com/Mirantis/tools-sustaining/master/scripts/mos_apply_mu.py""}} {\fldrslt{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ul\cf4 /}}}{\field{\*\fldinst{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\insrsid10976062\strike0\ulnone\cf1 HYPERLINK ""https://raw.githubusercontent.com/Mirantis/tools-sustaining/master/scripts/mos_apply_mu.py""}} {\fldrslt{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ul\cf4 mos}}}{\field{\*\fldinst{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\insrsid10976062\strike0\ulnone\cf1 HYPERLINK ""https://raw.githubusercontent.com/Mirantis/tools-sustaining/master/scripts/mos_apply_mu.py""}} {\fldrslt{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ul\cf4 _}}}{\field{\*\fldinst{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\insrsid10976062\strike0\ulnone\cf1 HYPERLINK ""https://raw.githubusercontent.com/Mirantis/tools-sustaining/master/scripts/mos_apply_mu.py""}} {\fldrslt{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ul\cf4 apply}}}{\field{\*\fldinst{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\insrsid10976062\strike0\ulnone\cf1 HYPERLINK ""https://raw.githubusercontent.com/Mirantis/tools-sustaining/master/scripts/mos_apply_mu.py""}} {\fldrslt{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ul\cf4 _}}}{\field{\*\fldinst{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\insrsid10976062\strike0\ulnone\cf1 HYPERLINK ""https://raw.githubusercontent.com/Mirantis/tools-sustaining/master/scripts/mos_apply_mu.py""}} {\fldrslt{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ul\cf4 mu}}}{\field{\*\fldinst{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\insrsid10976062\strike0\ulnone\cf1 HYPERLINK ""https://raw.githubusercontent.com/Mirantis/tools-sustaining/master/scripts/mos_apply_mu.py""}} {\fldrslt{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ul\cf4 .}}}{\field{\*\fldinst{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\insrsid10976062\strike0\ulnone\cf1 HYPERLINK ""https://raw.githubusercontent.com/Mirantis/tools-sustaining/master/scripts/mos_apply_mu.py""}} {\fldrslt{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ul\cf4 py}}}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 - }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2 \hich\f2\strike0\ulnone\cf1 script}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 that}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22 \loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 currently}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 used}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 for}{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 installing}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{ \rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 maintenance}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0 \ulnone\cf1 updates}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 on}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2 \hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 the}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22 \loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 slave}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 nodes}{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\insrsid10976062\strike0\ulnone\cf1\par}\pard\plain\itap0\s0\ilvl0\ls2\tx360\tx720\fi-360\sb0\sa0\aspalpha\aspnum\adjustright\brdrt\brdrl\brdrb\brdrr\brdrbtw\brdrbar\widctlpar\ltrpar\li720\lin720\ri0\rin0\ql\faauto\sl276 \slmult1\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1{\listtext\pard\plain\tx360\fi-360\aspalpha\aspnum\adjustright\ltrpar\li720\lin720\ri0\rin0\ql\faauto\rtlch\ab0\ai0\af2\afs22\ltrch\fs22\loch\af2\dbch\af2\hich\f2\insrsid10976062\strike0 \ulnone\cf1 \u9679 \tab }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 [2]}{\field{\*\fldinst{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\insrsid10976062\strike0\ulnone\cf1 HYPERLINK ""https://docs.mirantis.com/openstack/fuel/fuel-8.0/maintenance-updates.html#mu8-0-how-to-update""}} {\fldrslt{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ul\cf4 https}}}{\field{\*\fldinst{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\insrsid10976062\strike0\ulnone\cf1 HYPERLINK ""https://docs.mirantis.com/openstack/fuel/fuel-8.0/maintenance-updates.html#mu8-0-how-to-update""}} {\fldrslt{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ul\cf4 ://}}}{\field{\*\fldinst{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\insrsid10976062\strike0\ulnone\cf1 HYPERLINK ""https://docs.mirantis.com/openstack/fuel/fuel-8.0/maintenance-updates.html#mu8-0-how-to-update""}} {\fldrslt{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ul\cf4 docs}}}{\field{\*\fldinst{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\insrsid10976062\strike0\ulnone\cf1 HYPERLINK ""https://docs.mirantis.com/openstack/fuel/fuel-8.0/maintenance-updates.html#mu8-0-how-to-update""}} {\fldrslt{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ul\cf4 .}}}{\field{\*\fldinst{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\insrsid10976062\strike0\ulnone\cf1 HYPERLINK ""https://docs.mirantis.com/openstack/fuel/fuel-8.0/maintenance-updates.html#mu8-0-how-to-update""}} {\fldrslt{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ul\cf4 mirantis}}}{\field{\*\fldinst{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\insrsid10976062\strike0\ulnone\cf1 HYPERLINK ""https://docs.mirantis.com/openstack/fuel/fuel-8.0/maintenance-updates.html#mu8-0-how-to-update""}} {\fldrslt{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ul\cf4 .}}}{\field{\*\fldinst{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\insrsid10976062\strike0\ulnone\cf1 HYPERLINK ""https://docs.mirantis.com/openstack/fuel/fuel-8.0/maintenance-updates.html#mu8-0-how-to-update""}} {\fldrslt{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ul\cf4 com}}}{\field{\*\fldinst{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\insrsid10976062\strike0\ulnone\cf1 HYPERLINK ""https://docs.mirantis.com/openstack/fuel/fuel-8.0/maintenance-updates.html#mu8-0-how-to-update""}} {\fldrslt{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ul\cf4 /}}}{\field{\*\fldinst{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\insrsid10976062\strike0\ulnone\cf1 HYPERLINK ""https://docs.mirantis.com/openstack/fuel/fuel-8.0/maintenance-updates.html#mu8-0-how-to-update""}} {\fldrslt{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ul\cf4 openstack}}}{\field{\*\fldinst{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\insrsid10976062\strike0\ulnone\cf1 HYPERLINK ""https://docs.mirantis.com/openstack/fuel/fuel-8.0/maintenance-updates.html#mu8-0-how-to-update""}} {\fldrslt{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ul\cf4 /}}}{\field{\*\fldinst{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\insrsid10976062\strike0\ulnone\cf1 HYPERLINK ""https://docs.mirantis.com/openstack/fuel/fuel-8.0/maintenance-updates.html#mu8-0-how-to-update""}} {\fldrslt{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ul\cf4 fuel}}}{\field{\*\fldinst{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\insrsid10976062\strike0\ulnone\cf1 HYPERLINK ""https://docs.mirantis.com/openstack/fuel/fuel-8.0/maintenance-updates.html#mu8-0-how-to-update""}} {\fldrslt{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ul\cf4 /}}}{\field{\*\fldinst{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\insrsid10976062\strike0\ulnone\cf1 HYPERLINK ""https://docs.mirantis.com/openstack/fuel/fuel-8.0/maintenance-updates.html#mu8-0-how-to-update""}} {\fldrslt{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ul\cf4 fuel}}}{\field{\*\fldinst{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\insrsid10976062\strike0\ulnone\cf1 HYPERLINK ""https://docs.mirantis.com/openstack/fuel/fuel-8.0/maintenance-updates.html#mu8-0-how-to-update""}} {\fldrslt{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ul\cf4 -8.0/}}}{\field{\*\fldinst{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\insrsid10976062\strike0\ulnone\cf1 HYPERLINK ""https://docs.mirantis.com/openstack/fuel/fuel-8.0/maintenance-updates.html#mu8-0-how-to-update""}} {\fldrslt{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ul\cf4 maintenance}}}{\field{\*\fldinst{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\insrsid10976062\strike0\ulnone\cf1 HYPERLINK ""https://docs.mirantis.com/openstack/fuel/fuel-8.0/maintenance-updates.html#mu8-0-how-to-update""}} {\fldrslt{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ul\cf4 -}}}{\field{\*\fldinst{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\insrsid10976062\strike0\ulnone\cf1 HYPERLINK ""https://docs.mirantis.com/openstack/fuel/fuel-8.0/maintenance-updates.html#mu8-0-how-to-update""}} {\fldrslt{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ul\cf4 updates}}}{\field{\*\fldinst{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\insrsid10976062\strike0\ulnone\cf1 HYPERLINK ""https://docs.mirantis.com/openstack/fuel/fuel-8.0/maintenance-updates.html#mu8-0-how-to-update""}} {\fldrslt{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ul\cf4 .}}}{\field{\*\fldinst{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\insrsid10976062\strike0\ulnone\cf1 HYPERLINK ""https://docs.mirantis.com/openstack/fuel/fuel-8.0/maintenance-updates.html#mu8-0-how-to-update""}} {\fldrslt{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ul\cf4 html}}}{\field{\*\fldinst{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\insrsid10976062\strike0\ulnone\cf1 HYPERLINK ""https://docs.mirantis.com/openstack/fuel/fuel-8.0/maintenance-updates.html#mu8-0-how-to-update""}} {\fldrslt{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ul\cf4 #}}}{\field{\*\fldinst{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\insrsid10976062\strike0\ulnone\cf1 HYPERLINK ""https://docs.mirantis.com/openstack/fuel/fuel-8.0/maintenance-updates.html#mu8-0-how-to-update""}} {\fldrslt{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ul\cf4 mu}}}{\field{\*\fldinst{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\insrsid10976062\strike0\ulnone\cf1 HYPERLINK ""https://docs.mirantis.com/openstack/fuel/fuel-8.0/maintenance-updates.html#mu8-0-how-to-update""}} {\fldrslt{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ul\cf4 8-0-}}}{\field{\*\fldinst{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\insrsid10976062\strike0\ulnone\cf1 HYPERLINK ""https://docs.mirantis.com/openstack/fuel/fuel-8.0/maintenance-updates.html#mu8-0-how-to-update""}} {\fldrslt{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ul\cf4 how}}}{\field{\*\fldinst{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\insrsid10976062\strike0\ulnone\cf1 HYPERLINK ""https://docs.mirantis.com/openstack/fuel/fuel-8.0/maintenance-updates.html#mu8-0-how-to-update""}} {\fldrslt{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ul\cf4 -}}}{\field{\*\fldinst{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\insrsid10976062\strike0\ulnone\cf1 HYPERLINK ""https://docs.mirantis.com/openstack/fuel/fuel-8.0/maintenance-updates.html#mu8-0-how-to-update""}} {\fldrslt{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ul\cf4 to}}}{\field{\*\fldinst{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\insrsid10976062\strike0\ulnone\cf1 HYPERLINK ""https://docs.mirantis.com/openstack/fuel/fuel-8.0/maintenance-updates.html#mu8-0-how-to-update""}} {\fldrslt{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ul\cf4 -}}}{\field{\*\fldinst{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\insrsid10976062\strike0\ulnone\cf1 HYPERLINK ""https://docs.mirantis.com/openstack/fuel/fuel-8.0/maintenance-updates.html#mu8-0-how-to-update""}} {\fldrslt{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ul\cf4 update}}}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2 \hich\f2\strike0\ulnone\cf1 - }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 documentation}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22 \loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 about}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 maintenance}{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 updates}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 application}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\insrsid10976062\strike0\ulnone\cf1\par}\pard\plain\itap0\s0\ilvl0\ls2\tx360\tx720\fi-360\sb0\sa0\aspalpha\aspnum \adjustright\brdrt\brdrl\brdrb\brdrr\brdrbtw\brdrbar\widctlpar\ltrpar\li720\lin720\ri0\rin0\ql\faauto\sl276\slmult1\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1{\listtext\pard\plain\tx360\fi-360\aspalpha\aspnum\adjustright \ltrpar\li720\lin720\ri0\rin0\ql\faauto\rtlch\ab0\ai0\af2\afs22\ltrch\fs22\loch\af2\dbch\af2\hich\f2\insrsid10976062\strike0\ulnone\cf1 \u9679 \tab }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 [3]}{\field{\*\fldinst{ \rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\insrsid10976062\strike0\ulnone\cf1 HYPERLINK ""https://docs.mirantis.com/openstack/fuel/fuel-master/reference-architecture.html#task-based-deployment""}}{\fldrslt{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22 \loch\af2\dbch\af2\hich\f2\strike0\ul\cf4 https}}}{\field{\*\fldinst{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\insrsid10976062\strike0\ulnone\cf1 HYPERLINK ""https://docs.mirantis.com/openstack/fuel/fuel-master/reference-architecture.html#task-based-deployment""}} {\fldrslt{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ul\cf4 ://}}}{\field{\*\fldinst{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\insrsid10976062\strike0\ulnone\cf1 HYPERLINK ""https://docs.mirantis.com/openstack/fuel/fuel-master/reference-architecture.html#task-based-deployment""}} {\fldrslt{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ul\cf4 docs}}}{\field{\*\fldinst{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\insrsid10976062\strike0\ulnone\cf1 HYPERLINK ""https://docs.mirantis.com/openstack/fuel/fuel-master/reference-architecture.html#task-based-deployment""}} {\fldrslt{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ul\cf4 .}}}{\field{\*\fldinst{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\insrsid10976062\strike0\ulnone\cf1 HYPERLINK ""https://docs.mirantis.com/openstack/fuel/fuel-master/reference-architecture.html#task-based-deployment""}} {\fldrslt{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ul\cf4 mirantis}}}{\field{\*\fldinst{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\insrsid10976062\strike0\ulnone\cf1 HYPERLINK ""https://docs.mirantis.com/openstack/fuel/fuel-master/reference-architecture.html#task-based-deployment""}} {\fldrslt{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ul\cf4 .}}}{\field{\*\fldinst{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\insrsid10976062\strike0\ulnone\cf1 HYPERLINK ""https://docs.mirantis.com/openstack/fuel/fuel-master/reference-architecture.html#task-based-deployment""}} {\fldrslt{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ul\cf4 com}}}{\field{\*\fldinst{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\insrsid10976062\strike0\ulnone\cf1 HYPERLINK ""https://docs.mirantis.com/openstack/fuel/fuel-master/reference-architecture.html#task-based-deployment""}} {\fldrslt{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ul\cf4 /}}}{\field{\*\fldinst{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\insrsid10976062\strike0\ulnone\cf1 HYPERLINK ""https://docs.mirantis.com/openstack/fuel/fuel-master/reference-architecture.html#task-based-deployment""}} {\fldrslt{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ul\cf4 openstack}}}{\field{\*\fldinst{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\insrsid10976062\strike0\ulnone\cf1 HYPERLINK ""https://docs.mirantis.com/openstack/fuel/fuel-master/reference-architecture.html#task-based-deployment""}} {\fldrslt{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ul\cf4 /}}}{\field{\*\fldinst{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\insrsid10976062\strike0\ulnone\cf1 HYPERLINK ""https://docs.mirantis.com/openstack/fuel/fuel-master/reference-architecture.html#task-based-deployment""}} {\fldrslt{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ul\cf4 fuel}}}{\field{\*\fldinst{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\insrsid10976062\strike0\ulnone\cf1 HYPERLINK ""https://docs.mirantis.com/openstack/fuel/fuel-master/reference-architecture.html#task-based-deployment""}} {\fldrslt{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ul\cf4 /}}}{\field{\*\fldinst{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\insrsid10976062\strike0\ulnone\cf1 HYPERLINK ""https://docs.mirantis.com/openstack/fuel/fuel-master/reference-architecture.html#task-based-deployment""}} {\fldrslt{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ul\cf4 fuel}}}{\field{\*\fldinst{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\insrsid10976062\strike0\ulnone\cf1 HYPERLINK ""https://docs.mirantis.com/openstack/fuel/fuel-master/reference-architecture.html#task-based-deployment""}} {\fldrslt{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ul\cf4 -}}}{\field{\*\fldinst{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\insrsid10976062\strike0\ulnone\cf1 HYPERLINK ""https://docs.mirantis.com/openstack/fuel/fuel-master/reference-architecture.html#task-based-deployment""}} {\fldrslt{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ul\cf4 master}}}{\field{\*\fldinst{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\insrsid10976062\strike0\ulnone\cf1 HYPERLINK ""https://docs.mirantis.com/openstack/fuel/fuel-master/reference-architecture.html#task-based-deployment""}} {\fldrslt{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ul\cf4 /}}}{\field{\*\fldinst{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\insrsid10976062\strike0\ulnone\cf1 HYPERLINK ""https://docs.mirantis.com/openstack/fuel/fuel-master/reference-architecture.html#task-based-deployment""}} {\fldrslt{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ul\cf4 reference}}}{\field{\*\fldinst{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\insrsid10976062\strike0\ulnone\cf1 HYPERLINK ""https://docs.mirantis.com/openstack/fuel/fuel-master/reference-architecture.html#task-based-deployment""}} {\fldrslt{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ul\cf4 -}}}{\field{\*\fldinst{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\insrsid10976062\strike0\ulnone\cf1 HYPERLINK ""https://docs.mirantis.com/openstack/fuel/fuel-master/reference-architecture.html#task-based-deployment""}} {\fldrslt{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ul\cf4 architecture}}}{\field{\*\fldinst{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\insrsid10976062\strike0\ulnone\cf1 HYPERLINK ""https://docs.mirantis.com/openstack/fuel/fuel-master/reference-architecture.html#task-based-deployment""}} {\fldrslt{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ul\cf4 .}}}{\field{\*\fldinst{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\insrsid10976062\strike0\ulnone\cf1 HYPERLINK ""https://docs.mirantis.com/openstack/fuel/fuel-master/reference-architecture.html#task-based-deployment""}} {\fldrslt{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ul\cf4 html}}}{\field{\*\fldinst{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\insrsid10976062\strike0\ulnone\cf1 HYPERLINK ""https://docs.mirantis.com/openstack/fuel/fuel-master/reference-architecture.html#task-based-deployment""}} {\fldrslt{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ul\cf4 #}}}{\field{\*\fldinst{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\insrsid10976062\strike0\ulnone\cf1 HYPERLINK ""https://docs.mirantis.com/openstack/fuel/fuel-master/reference-architecture.html#task-based-deployment""}} {\fldrslt{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ul\cf4 task}}}{\field{\*\fldinst{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\insrsid10976062\strike0\ulnone\cf1 HYPERLINK ""https://docs.mirantis.com/openstack/fuel/fuel-master/reference-architecture.html#task-based-deployment""}} {\fldrslt{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ul\cf4 -}}}{\field{\*\fldinst{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\insrsid10976062\strike0\ulnone\cf1 HYPERLINK ""https://docs.mirantis.com/openstack/fuel/fuel-master/reference-architecture.html#task-based-deployment""}} {\fldrslt{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ul\cf4 based}}}{\field{\*\fldinst{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\insrsid10976062\strike0\ulnone\cf1 HYPERLINK ""https://docs.mirantis.com/openstack/fuel/fuel-master/reference-architecture.html#task-based-deployment""}} {\fldrslt{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ul\cf4 -}}}{\field{\*\fldinst{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\insrsid10976062\strike0\ulnone\cf1 HYPERLINK ""https://docs.mirantis.com/openstack/fuel/fuel-master/reference-architecture.html#task-based-deployment""}} {\fldrslt{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ul\cf4 deployment}}}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 - }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2 \dbch\af2\hich\f2\strike0\ulnone\cf1 documentation}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 about}{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 task}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 -}{\rtlch\ab0\ai0\af2\afs22 \ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 based}{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 }{\rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\strike0\ulnone\cf1 deployment}{ \rtlch\ab0\ai0\af2\afs22\ltrch\b0\i0\fs22\loch\af2\dbch\af2\hich\f2\insrsid10976062\strike0\ulnone\cf1\par}{\*\latentstyles\lsdstimax267\lsdlockeddef0\lsdsemihiddendef0\lsdunhideuseddef0\lsdqformatdef0\lsdprioritydef0{\lsdlockedexcept\lsdqformat1 Normal;\lsdqformat1 heading 1;\lsdsemihidden1\lsdunhideused1\lsdqformat1 heading 2;\lsdsemihidden1\lsdunhideused1\lsdqformat1 heading 3 ;\lsdsemihidden1\lsdunhideused1\lsdqformat1 heading 4;\lsdsemihidden1\lsdunhideused1\lsdqformat1 heading 5;\lsdsemihidden1\lsdunhideused1\lsdqformat1 heading 6;\lsdsemihidden1\lsdunhideused1\lsdqformat1 heading 7;\lsdsemihidden1\lsdunhideused1\lsdqformat1 heading 8 ;\lsdsemihidden1\lsdunhideused1\lsdqformat1 heading 9;\lsdsemihidden1\lsdunhideused1\lsdqformat1 caption;\lsdqformat1 Title;\lsdqformat1 Subtitle;\lsdqformat1 Strong;\lsdqformat1 Emphasis;\lsdsemihidden1\lsdpriority99 Placeholder Text;\lsdqformat1\lsdpriority1 No Spacing ;\lsdpriority60 Light Shading;\lsdpriority61 Light List;\lsdpriority62 Light Grid;\lsdpriority63 Medium Shading 1;\lsdpriority64 Medium Shading 2;\lsdpriority65 Medium List 1;\lsdpriority66 Medium List 2;\lsdpriority67 Medium Grid 1;\lsdpriority68 Medium Grid 2 ;\lsdpriority69 Medium Grid 3;\lsdpriority70 Dark List;\lsdpriority71 Colorful Shading;\lsdpriority72 Colorful List;\lsdpriority73 Colorful Grid;\lsdpriority60 Light Shading Accent 1;\lsdpriority61 Light List Accent 1;\lsdpriority62 Light Grid Accent 1;\lsdpriority63 Medium Shading 1 Accent 1 ;\lsdpriority64 Medium Shading 2 Accent 1;\lsdpriority65 Medium List 1 Accent 1;\lsdsemihidden1\lsdpriority99 Revision;\lsdqformat1\lsdpriority34 List Paragraph;\lsdqformat1\lsdpriority29 Quote;\lsdqformat1\lsdpriority30 Intense Quote;\lsdpriority66 Medium List 2 Accent 1 ;\lsdpriority67 Medium Grid 1 Accent 1;\lsdpriority68 Medium Grid 2 Accent 1;\lsdpriority69 Medium Grid 3 Accent 1;\lsdpriority70 Dark List Accent 1;\lsdpriority71 Colorful Shading Accent 1;\lsdpriority72 Colorful List Accent 1;\lsdpriority73 Colorful Grid Accent 1 ;\lsdpriority60 Light Shading Accent 2;\lsdpriority61 Light List Accent 2;\lsdpriority62 Light Grid Accent 2;\lsdpriority63 Medium Shading 1 Accent 2;\lsdpriority64 Medium Shading 2 Accent 2;\lsdpriority65 Medium List 1 Accent 2;\lsdpriority66 Medium List 2 Accent 2 ;\lsdpriority67 Medium Grid 1 Accent 2;\lsdpriority68 Medium Grid 2 Accent 2;\lsdpriority69 Medium Grid 3 Accent 2;\lsdpriority70 Dark List Accent 2;\lsdpriority71 Colorful Shading Accent 2;\lsdpriority72 Colorful List Accent 2;\lsdpriority73 Colorful Grid Accent 2 ;\lsdpriority60 Light Shading Accent 3;\lsdpriority61 Light List Accent 3;\lsdpriority62 Light Grid Accent 3;\lsdpriority63 Medium Shading 1 Accent 3;\lsdpriority64 Medium Shading 2 Accent 3;\lsdpriority65 Medium List 1 Accent 3;\lsdpriority66 Medium List 2 Accent 3 ;\lsdpriority67 Medium Grid 1 Accent 3;\lsdpriority68 Medium Grid 2 Accent 3;\lsdpriority69 Medium Grid 3 Accent 3;\lsdpriority70 Dark List Accent 3;\lsdpriority71 Colorful Shading Accent 3;\lsdpriority72 Colorful List Accent 3;\lsdpriority73 Colorful Grid Accent 3 ;\lsdpriority60 Light Shading Accent 4;\lsdpriority61 Light List Accent 4;\lsdpriority62 Light Grid Accent 4;\lsdpriority63 Medium Shading 1 Accent 4;\lsdpriority64 Medium Shading 2 Accent 4;\lsdpriority65 Medium List 1 Accent 4;\lsdpriority66 Medium List 2 Accent 4 ;\lsdpriority67 Medium Grid 1 Accent 4;\lsdpriority68 Medium Grid 2 Accent 4;\lsdpriority69 Medium Grid 3 Accent 4;\lsdpriority70 Dark List Accent 4;\lsdpriority71 Colorful Shading Accent 4;\lsdpriority72 Colorful List Accent 4;\lsdpriority73 Colorful Grid Accent 4 ;\lsdpriority60 Light Shading Accent 5;\lsdpriority61 Light List Accent 5;\lsdpriority62 Light Grid Accent 5;\lsdpriority63 Medium Shading 1 Accent 5;\lsdpriority64 Medium Shading 2 Accent 5;\lsdpriority65 Medium List 1 Accent 5;\lsdpriority66 Medium List 2 Accent 5 ;\lsdpriority67 Medium Grid 1 Accent 5;\lsdpriority68 Medium Grid 2 Accent 5;\lsdpriority69 Medium Grid 3 Accent 5;\lsdpriority70 Dark List Accent 5;\lsdpriority71 Colorful Shading Accent 5;\lsdpriority72 Colorful List Accent 5;\lsdpriority73 Colorful Grid Accent 5 ;\lsdpriority60 Light Shading Accent 6;\lsdpriority61 Light List Accent 6;\lsdpriority62 Light Grid Accent 6;\lsdpriority63 Medium Shading 1 Accent 6;\lsdpriority64 Medium Shading 2 Accent 6;\lsdpriority65 Medium List 1 Accent 6;\lsdpriority66 Medium List 2 Accent 6 ;\lsdpriority67 Medium Grid 1 Accent 6;\lsdpriority68 Medium Grid 2 Accent 6;\lsdpriority69 Medium Grid 3 Accent 6;\lsdpriority70 Dark List Accent 6;\lsdpriority71 Colorful Shading Accent 6;\lsdpriority72 Colorful List Accent 6;\lsdpriority73 Colorful Grid Accent 6 ;\lsdqformat1\lsdpriority19 Subtle Emphasis;\lsdqformat1\lsdpriority21 Intense Emphasis;\lsdqformat1\lsdpriority31 Subtle Reference;\lsdqformat1\lsdpriority32 Intense Reference;\lsdqformat1\lsdpriority33 Book Title;\lsdsemihidden1\lsdunhideused1\lsdpriority37 Bibliography ;\lsdsemihidden1\lsdunhideused1\lsdqformat1\lsdpriority39 TOC Heading;}}}",,874,0
openstack%2Ftripleo-heat-templates~master~I3c8a946e439539d239ad7281a1395414df0893eb,openstack/tripleo-heat-templates,master,I3c8a946e439539d239ad7281a1395414df0893eb,Create composable mapping between enabled services and role ips,MERGED,2016-07-29 17:25:58.000000000,2016-08-29 12:10:39.000000000,2016-08-29 10:51:10.000000000,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 3153}, {'_account_id': 4328}, {'_account_id': 6796}, {'_account_id': 8042}, {'_account_id': 8449}]","[{'number': 1, 'created': '2016-07-29 17:25:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/a491cce4b65efd791b3bac5ea2f553664af027da', 'message': 'WIP Create composable mapping between enabled services and role ips\n\nCurrently we have a hard-coded list of ips for various services that\nrun on the controller, instead we can dynamically generate that list\nof per-service ips, initially only for the controller but this approach\ncan be extended so it works for any role.\n\nChange-Id: I3c8a946e439539d239ad7281a1395414df0893eb\nPartially-Implements: blueprint custom-roles\n'}, {'number': 2, 'created': '2016-08-09 13:00:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/27372cc1e999f0bd14c8ea48c734738c29e824b6', 'message': 'WIP Create composable mapping between enabled services and role ips\n\nCurrently we have a hard-coded list of ips for various services that\nrun on the controller, instead we can dynamically generate that list\nof per-service ips, initially only for the controller but this approach\ncan be extended so it works for any role.\n\nChange-Id: I3c8a946e439539d239ad7281a1395414df0893eb\nPartially-Implements: blueprint custom-roles\n'}, {'number': 3, 'created': '2016-08-12 20:28:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/93a000ad9179030035642dbc76034db6a9908f64', 'message': 'Create composable mapping between enabled services and role ips\n\nCurrently we have a hard-coded list of ips for various services that\nrun on the controller, instead we can dynamically generate that list\nof per-service ips, initially only for the controller but this approach\ncan be extended so it works for any role.\n\nChange-Id: I3c8a946e439539d239ad7281a1395414df0893eb\nPartially-Implements: blueprint custom-roles\n'}, {'number': 4, 'created': '2016-08-23 17:09:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/a3661b80c262d163dc19a033525bacc5cf2b037c', 'message': 'Create composable mapping between enabled services and role ips\n\nCurrently we have a hard-coded list of ips for various services that\nrun on the controller, instead we can dynamically generate that list\nof per-service ips, initially only for the controller but this approach\ncan be extended so it works for any role.\n\nChange-Id: I3c8a946e439539d239ad7281a1395414df0893eb\nPartially-Implements: blueprint custom-roles\n'}, {'number': 5, 'created': '2016-08-26 11:10:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/df7e2262104f3d9af52c512833260b6e1b2b1050', 'message': 'Create composable mapping between enabled services and role ips\n\nCurrently we have a hard-coded list of ips for various services that\nrun on the controller, instead we can dynamically generate that list\nof per-service ips, initially only for the controller but this approach\ncan be extended so it works for any role.\n\nChange-Id: I3c8a946e439539d239ad7281a1395414df0893eb\nPartially-Implements: blueprint custom-roles\n'}, {'number': 6, 'created': '2016-08-28 09:32:48.000000000', 'files': ['overcloud.yaml', 'network/ports/net_ip_list_map.yaml', 'puppet/all-nodes-config.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/2291cdda04d415501e75daaa62ea9c2fdada22f9', 'message': 'Create composable mapping between enabled services and role ips\n\nCurrently we have a hard-coded list of ips for various services that\nrun on the controller, instead we can dynamically generate that list\nof per-service ips, initially only for the controller but this approach\ncan be extended so it works for any role.\n\nChange-Id: I3c8a946e439539d239ad7281a1395414df0893eb\nPartially-Implements: blueprint custom-roles\n'}]",15,348974,2291cdda04d415501e75daaa62ea9c2fdada22f9,45,7,6,4328,,,0,"Create composable mapping between enabled services and role ips

Currently we have a hard-coded list of ips for various services that
run on the controller, instead we can dynamically generate that list
of per-service ips, initially only for the controller but this approach
can be extended so it works for any role.

Change-Id: I3c8a946e439539d239ad7281a1395414df0893eb
Partially-Implements: blueprint custom-roles
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/74/348974/2 && git format-patch -1 --stdout FETCH_HEAD,"['overcloud.yaml', 'network/ports/net_ip_list_map.yaml', 'puppet/all-nodes-config.yaml']",3,a491cce4b65efd791b3bac5ea2f553664af027da,bp/custom-roles," service_ips: type: json - {get_param: service_ips}# FIXME need to handle this # memcache_node_ips_v6: # str_replace: # template: ""['inet6:[SERVERS_LIST]']"" # params: # SERVERS_LIST: # list_join: # - ""]','inet6:["" # - {get_param: memcache_node_ips}# FIXME: move these to the service templates and access rabbit_node_ips# ceilometer::rabbit_hosts: *rabbit_nodes_array # aodh::rabbit_hosts: *rabbit_nodes_array # cinder::rabbit_hosts: *rabbit_nodes_array # glance::notify::rabbitmq::rabbit_hosts: *rabbit_nodes_array # heat::rabbit_hosts: *rabbit_nodes_array # neutron::rabbit_hosts: *rabbit_nodes_array # nova::rabbit_hosts: *rabbit_nodes_array # keystone::rabbit_hosts: *rabbit_nodes_array # sahara::rabbit_hosts: *rabbit_nodes_array # ironic::rabbit_hosts: *rabbit_nodes_array"," rabbit_node_ips: type: comma_delimited_list mongo_node_ips: type: comma_delimited_list redis_node_ips: type: comma_delimited_list memcache_node_ips: type: comma_delimited_list mysql_node_ips: type: comma_delimited_list horizon_node_ips: type: comma_delimited_list heat_api_node_ips: type: comma_delimited_list swift_proxy_node_ips: type: comma_delimited_list ceilometer_api_node_ips: type: comma_delimited_list aodh_api_node_ips: type: comma_delimited_list nova_api_node_ips: type: comma_delimited_list nova_metadata_node_ips: type: comma_delimited_list glance_api_node_ips: type: comma_delimited_list glance_registry_node_ips: type: comma_delimited_list gnocchi_api_node_ips: type: comma_delimited_list cinder_api_node_ips: type: comma_delimited_list neutron_api_node_ips: type: comma_delimited_list sahara_api_node_ips: type: comma_delimited_list ironic_api_node_ips: type: comma_delimited_list rabbit_node_ips: &rabbit_nodes_array str_replace: template: ""['SERVERS_LIST']"" params: SERVERS_LIST: list_join: - ""','"" - {get_param: rabbit_node_ips} mongo_node_ips: str_replace: template: ""['SERVERS_LIST']"" params: SERVERS_LIST: list_join: - ""','"" - {get_param: mongo_node_ips} redis_node_ips: str_replace: template: ""['SERVERS_LIST']"" params: SERVERS_LIST: list_join: - ""','"" - {get_param: redis_node_ips} memcache_node_ips: str_replace: template: ""['SERVERS_LIST']"" params: SERVERS_LIST: list_join: - ""','"" - {get_param: memcache_node_ips} memcache_node_ips_v6: str_replace: template: ""['inet6:[SERVERS_LIST]']"" params: SERVERS_LIST: list_join: - ""]','inet6:["" - {get_param: memcache_node_ips} mysql_node_ips: str_replace: template: ""['SERVERS_LIST']"" params: SERVERS_LIST: list_join: - ""','"" - {get_param: mysql_node_ips} horizon_node_ips: str_replace: template: ""['SERVERS_LIST']"" params: SERVERS_LIST: list_join: - ""','"" - {get_param: horizon_node_ips} heat_api_node_ips: str_replace: template: ""['SERVERS_LIST']"" params: SERVERS_LIST: list_join: - ""','"" - {get_param: heat_api_node_ips} swift_proxy_node_ips: str_replace: template: ""['SERVERS_LIST']"" params: SERVERS_LIST: list_join: - ""','"" - {get_param: swift_proxy_node_ips} ceilometer_api_node_ips: str_replace: template: ""['SERVERS_LIST']"" params: SERVERS_LIST: list_join: - ""','"" - {get_param: ceilometer_api_node_ips} aodh_api_node_ips: str_replace: template: ""['SERVERS_LIST']"" params: SERVERS_LIST: list_join: - ""','"" - {get_param: aodh_api_node_ips} gnocchi_api_node_ips: str_replace: template: ""['SERVERS_LIST']"" params: SERVERS_LIST: list_join: - ""','"" - {get_param: gnocchi_api_node_ips} nova_api_node_ips: str_replace: template: ""['SERVERS_LIST']"" params: SERVERS_LIST: list_join: - ""','"" - {get_param: nova_api_node_ips} nova_metadata_node_ips: str_replace: template: ""['SERVERS_LIST']"" params: SERVERS_LIST: list_join: - ""','"" - {get_param: nova_metadata_node_ips} glance_api_node_ips: str_replace: template: ""['SERVERS_LIST']"" params: SERVERS_LIST: list_join: - ""','"" - {get_param: glance_api_node_ips} glance_registry_node_ips: str_replace: template: ""['SERVERS_LIST']"" params: SERVERS_LIST: list_join: - ""','"" - {get_param: glance_registry_node_ips} cinder_api_node_ips: str_replace: template: ""['SERVERS_LIST']"" params: SERVERS_LIST: list_join: - ""','"" - {get_param: cinder_api_node_ips} neutron_api_node_ips: str_replace: template: ""['SERVERS_LIST']"" params: SERVERS_LIST: list_join: - ""','"" - {get_param: neutron_api_node_ips} # TODO: pass a `midonet_api_node_ips` var midonet_api_node_ips: str_replace: template: ""['SERVERS_LIST']"" params: SERVERS_LIST: list_join: - ""','"" - {get_param: neutron_api_node_ips} sahara_api_node_ips: str_replace: template: ""['SERVERS_LIST']"" params: SERVERS_LIST: list_join: - ""','"" - {get_param: sahara_api_node_ips} ironic_api_node_ips: str_replace: template: ""['SERVERS_LIST']"" params: SERVERS_LIST: list_join: - ""','"" - {get_param: ironic_api_node_ips} ceilometer::rabbit_hosts: *rabbit_nodes_array aodh::rabbit_hosts: *rabbit_nodes_array cinder::rabbit_hosts: *rabbit_nodes_array glance::notify::rabbitmq::rabbit_hosts: *rabbit_nodes_array heat::rabbit_hosts: *rabbit_nodes_array neutron::rabbit_hosts: *rabbit_nodes_array nova::rabbit_hosts: *rabbit_nodes_array keystone::rabbit_hosts: *rabbit_nodes_array sahara::rabbit_hosts: *rabbit_nodes_array ironic::rabbit_hosts: *rabbit_nodes_array",72,238
openstack%2Fyaql~master~Idb066b571019ea4a6bb7d132f9be347d1b141921,openstack/yaql,master,Idb066b571019ea4a6bb7d132f9be347d1b141921,[docs] Docstrings for branching YAQL functions,MERGED,2016-06-02 14:54:35.000000000,2016-08-29 12:04:29.000000000,2016-08-29 12:04:29.000000000,"[{'_account_id': 3}, {'_account_id': 7225}, {'_account_id': 7226}, {'_account_id': 7535}, {'_account_id': 8127}, {'_account_id': 14643}, {'_account_id': 14947}, {'_account_id': 15168}, {'_account_id': 20563}, {'_account_id': 20773}]","[{'number': 1, 'created': '2016-06-02 14:54:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/yaql/commit/0bd366233021211221300b630490c796ab0f7ef5', 'message': '[docs] Docstrings for branching YAQL functions\n\nChange-Id: Idb066b571019ea4a6bb7d132f9be347d1b141921\n'}, {'number': 2, 'created': '2016-06-02 15:49:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/yaql/commit/96eeaac9d32c70b1ebe8c7816ffe2f7a22c37de8', 'message': '[docs] Docstrings for branching YAQL functions\n\nChange-Id: Idb066b571019ea4a6bb7d132f9be347d1b141921\n'}, {'number': 3, 'created': '2016-06-06 16:27:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/yaql/commit/074541803842c9490537c78c56597f5108b7797a', 'message': '[docs] Docstrings for branching YAQL functions\n\nChange-Id: Idb066b571019ea4a6bb7d132f9be347d1b141921\n'}, {'number': 4, 'created': '2016-07-17 11:57:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/yaql/commit/a2cd908e5077058ab6bc0f74c267b3dc684d65b2', 'message': '[docs] Docstrings for branching YAQL functions\n\nChange-Id: Idb066b571019ea4a6bb7d132f9be347d1b141921\n'}, {'number': 5, 'created': '2016-07-20 12:42:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/yaql/commit/fa17b2743707921d15a8b8eb331c218dea324031', 'message': '[docs] Docstrings for branching YAQL functions\n\nChange-Id: Idb066b571019ea4a6bb7d132f9be347d1b141921\n'}, {'number': 6, 'created': '2016-07-20 13:18:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/yaql/commit/9f78be90406f0ad7761a6a87fc28bf1d1c993367', 'message': '[docs] Docstrings for branching YAQL functions\n\nChange-Id: Idb066b571019ea4a6bb7d132f9be347d1b141921\n'}, {'number': 7, 'created': '2016-07-20 13:20:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/yaql/commit/865d128608a1724b54043c15d4e852d19eec455a', 'message': '[docs] Docstrings for branching YAQL functions\n\nChange-Id: Idb066b571019ea4a6bb7d132f9be347d1b141921\n'}, {'number': 8, 'created': '2016-07-22 11:43:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/yaql/commit/9c965f92b106a8575d14e2308dead3e499a31ea6', 'message': '[docs] Docstrings for branching YAQL functions\n\nChange-Id: Idb066b571019ea4a6bb7d132f9be347d1b141921\n'}, {'number': 9, 'created': '2016-07-22 17:56:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/yaql/commit/d1a6275ef745a7cdb2ea829556a77e436923fe72', 'message': '[docs] Docstrings for branching YAQL functions\n\nChange-Id: Idb066b571019ea4a6bb7d132f9be347d1b141921\n'}, {'number': 10, 'created': '2016-07-29 18:10:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/yaql/commit/5e543ea36e78119d7d4cecb750042c3743126f58', 'message': '[docs] Docstrings for branching YAQL functions\n\nChange-Id: Idb066b571019ea4a6bb7d132f9be347d1b141921\n'}, {'number': 11, 'created': '2016-08-09 13:49:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/yaql/commit/8d646d41a0a528b2ff0113954870bff0285a7d61', 'message': '[docs] Docstrings for branching YAQL functions\n\nChange-Id: Idb066b571019ea4a6bb7d132f9be347d1b141921\n'}, {'number': 12, 'created': '2016-08-11 17:15:37.000000000', 'files': ['yaql/standard_library/branching.py'], 'web_link': 'https://opendev.org/openstack/yaql/commit/e4c6413076f39c8bb0631f5f79acc07d16534bf0', 'message': '[docs] Docstrings for branching YAQL functions\n\nChange-Id: Idb066b571019ea4a6bb7d132f9be347d1b141921\n'}]",100,324584,e4c6413076f39c8bb0631f5f79acc07d16534bf0,49,10,12,20563,,,0,"[docs] Docstrings for branching YAQL functions

Change-Id: Idb066b571019ea4a6bb7d132f9be347d1b141921
",git fetch https://review.opendev.org/openstack/yaql refs/changes/84/324584/12 && git format-patch -1 --stdout FETCH_HEAD,['yaql/standard_library/branching.py'],1,0bd366233021211221300b630490c796ab0f7ef5,yaqldocs," """""" Returns first value of args for which key is true, if there is no such returns null. :name: switch """""" """""" Returns index of first true args. If there is no such returns size of args. :name: selectCase """""" """""" Returns list of indexes of all true args. :name: selectAllCases """""" """""" Returns list of args converted to boolean. :name: examine """""" """""" Returns args[index] case. If there is no such case returns the last one. :name: switchCase """""" """""" Returns first not null args value. If there is no such returns nul. :name: coalesce """"""",,34,0
openstack%2Fyaql~master~I99b947cf86a8131b205351c8f60d1437b6907559,openstack/yaql,master,I99b947cf86a8131b205351c8f60d1437b6907559,[docs] Docstrings for strings YAQL functions,MERGED,2016-06-02 14:54:35.000000000,2016-08-29 12:02:29.000000000,2016-08-29 12:02:29.000000000,"[{'_account_id': 3}, {'_account_id': 7225}, {'_account_id': 7226}, {'_account_id': 7535}, {'_account_id': 8127}, {'_account_id': 14947}, {'_account_id': 15168}, {'_account_id': 20563}, {'_account_id': 20773}]","[{'number': 1, 'created': '2016-06-02 14:54:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/yaql/commit/76845452f98b8206bcbfc252691fa861889799a3', 'message': '[docs] Docstrings for strings YAQL functions\n\nChange-Id: I99b947cf86a8131b205351c8f60d1437b6907559\n'}, {'number': 2, 'created': '2016-06-02 15:49:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/yaql/commit/7e1fc266cfbaee249afb18cdd455a154e17b4447', 'message': '[docs] Docstrings for strings YAQL functions\n\nChange-Id: I99b947cf86a8131b205351c8f60d1437b6907559\n'}, {'number': 3, 'created': '2016-06-03 11:55:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/yaql/commit/cd7fc7ab246a8ccce2600023f33b48ea1f3980d1', 'message': '[docs] Docstrings for strings YAQL functions\n\nChange-Id: I99b947cf86a8131b205351c8f60d1437b6907559\n'}, {'number': 4, 'created': '2016-06-03 12:38:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/yaql/commit/79ca9b0d54de236b7de0eddc0bb9a28614649dc0', 'message': '[docs] Docstrings for strings YAQL functions\n\nChange-Id: I99b947cf86a8131b205351c8f60d1437b6907559\n'}, {'number': 5, 'created': '2016-06-06 16:37:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/yaql/commit/7753eaa4777d1f0e204dc01a673e7c4fb5a9e440', 'message': '[docs] Docstrings for strings YAQL functions\n\nChange-Id: I99b947cf86a8131b205351c8f60d1437b6907559\n'}, {'number': 6, 'created': '2016-07-11 09:02:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/yaql/commit/89830901111e55cc8897975ff5854258e5beb905', 'message': '[docs] Docstrings for strings YAQL functions\n\nChange-Id: I99b947cf86a8131b205351c8f60d1437b6907559\n'}, {'number': 7, 'created': '2016-07-13 15:30:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/yaql/commit/f627d64f24379482f2d76efb577aaad9e6243ef0', 'message': '[docs] Docstrings for strings YAQL functions\n\nChange-Id: I99b947cf86a8131b205351c8f60d1437b6907559\n'}, {'number': 8, 'created': '2016-07-15 10:16:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/yaql/commit/8cffab30e6156460188f8b75fbecf60a7a605a49', 'message': '[docs] Docstrings for strings YAQL functions\n\nChange-Id: I99b947cf86a8131b205351c8f60d1437b6907559\n'}, {'number': 9, 'created': '2016-07-15 15:40:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/yaql/commit/a5d5abdcee21a072fe7a2f0940e15da83daaedc7', 'message': '[docs] Docstrings for strings YAQL functions\n\nChange-Id: I99b947cf86a8131b205351c8f60d1437b6907559\n'}, {'number': 10, 'created': '2016-07-16 16:43:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/yaql/commit/2ab9f2032be5b947168bd744cc0014e6d6a9a38a', 'message': '[docs] Docstrings for strings YAQL functions\n\nChange-Id: I99b947cf86a8131b205351c8f60d1437b6907559\n'}, {'number': 11, 'created': '2016-07-18 07:16:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/yaql/commit/ab64edc1e8aff64e07673f8329366f8164052f1b', 'message': '[docs] Docstrings for strings YAQL functions\n\nChange-Id: I99b947cf86a8131b205351c8f60d1437b6907559\n'}, {'number': 12, 'created': '2016-07-18 10:18:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/yaql/commit/8fafe76580e72dcb4a2a2d7b3f0a09f54d846e0c', 'message': '[docs] Docstrings for strings YAQL functions\n\nChange-Id: I99b947cf86a8131b205351c8f60d1437b6907559\n'}, {'number': 13, 'created': '2016-07-18 10:32:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/yaql/commit/ff07a89c6cf80e9e780a9932929f8b8b16197883', 'message': '[docs] Docstrings for strings YAQL functions\n\nChange-Id: I99b947cf86a8131b205351c8f60d1437b6907559\n'}, {'number': 14, 'created': '2016-07-19 14:38:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/yaql/commit/b18866e58eab6b4096cb138eabfa6cd38215a074', 'message': '[docs] Docstrings for strings YAQL functions\n\nChange-Id: I99b947cf86a8131b205351c8f60d1437b6907559\n'}, {'number': 15, 'created': '2016-07-20 12:42:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/yaql/commit/df0594bb4b391c502abbaf514d1c1ea85dc569c7', 'message': '[docs] Docstrings for strings YAQL functions\n\nChange-Id: I99b947cf86a8131b205351c8f60d1437b6907559\n'}, {'number': 16, 'created': '2016-07-20 12:47:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/yaql/commit/ef255464349a6139267397ad22d67d2f06fe06d1', 'message': '[docs] Docstrings for strings YAQL functions\n\nChange-Id: I99b947cf86a8131b205351c8f60d1437b6907559\n'}, {'number': 17, 'created': '2016-07-29 13:43:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/yaql/commit/e0bfc1bf946084a745bcbc2ecb59c6a88e43d8c4', 'message': '[docs] Docstrings for strings YAQL functions\n\nChange-Id: I99b947cf86a8131b205351c8f60d1437b6907559\n'}, {'number': 18, 'created': '2016-08-09 12:15:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/yaql/commit/689f114a105228f3fe12f7653b0ce41f92cd959f', 'message': '[docs] Docstrings for strings YAQL functions\n\nChange-Id: I99b947cf86a8131b205351c8f60d1437b6907559\n'}, {'number': 19, 'created': '2016-08-11 17:25:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/yaql/commit/c007ad906472b661120b0082503e6eabd3dc81a9', 'message': '[docs] Docstrings for strings YAQL functions\n\nChange-Id: I99b947cf86a8131b205351c8f60d1437b6907559\n'}, {'number': 20, 'created': '2016-08-12 13:06:35.000000000', 'files': ['yaql/standard_library/strings.py'], 'web_link': 'https://opendev.org/openstack/yaql/commit/529c231794f78fe38ce1e07d16b93165c1abf4ce', 'message': '[docs] Docstrings for strings YAQL functions\n\nChange-Id: I99b947cf86a8131b205351c8f60d1437b6907559\n'}]",96,324592,529c231794f78fe38ce1e07d16b93165c1abf4ce,63,9,20,20563,,,0,"[docs] Docstrings for strings YAQL functions

Change-Id: I99b947cf86a8131b205351c8f60d1437b6907559
",git fetch https://review.opendev.org/openstack/yaql refs/changes/92/324592/15 && git format-patch -1 --stdout FETCH_HEAD,['yaql/standard_library/strings.py'],1,76845452f98b8206bcbfc252691fa861889799a3,script," """""" Returns true if left is stricly greater than right ordering lexicographically, otherwise false. """""" """""" Returns true if left is stricly less than right ordering lexicographically, otherwise false. """""" """""" Returns true if left is greater or equal to right ordering lexicographically, otherwise false. """""" return left >= right """""" Returns true if left is less or equal to right ordering lexicographically, otherwise false. """""" return left <= right """""" Returns concatenated args. :name: concat """""" """""" Returns a string with all case-based characters uppercased. :name: toUpper """""" """""" Returns size of the string. :name: len """""" """""" Returns a string with all case-based characters lowercased. :name: toLower """""" """""" Returns a list of the strings, using separator as the delimiter for string. If separator isn't given or None, If max_splits is specified, at most max_splits are done. If maxsplit is not specified or -1 all possible splits are done. :name: split """""" """""" Returns a list of the strings, using separator as the delimiter for string. If max_splits is specified, at most max_splits are done - the rightmost ones. If maxsplit is not specified or -1 all possible splits are done. :name: rightSplit """""" """""" Returns concatenated sequence elements with separator between every pair. :name: join """""" """""" Returns concatenated sequence elements with separator between every pair. :name: join """""" """""" Returns a string representation of the value. :name: str """""" """""" Returns a string with the leading and trailing chars removed. :name: trim """""" """""" Returns a string with the leading chars removed. :name: trimLeft """""" """""" Returns a string with the trailing chars removed. :name: trimRight """""" """""" Returns a string with the leading and trailing chars removed. If resulted string is empty returns null. :name: norm """""" """""" Returns true if a string with removed leading and trailing chars is empty. By default firstly deletes leading and trailing whitespaces. :name: isEmpty """""" """""" Returns a string with all occurrences of old replaced with new. If count is specified only the first count occurrences are replaced. :name: replace """""" """""" Returns a string with all occurrences of replacements's keys replaced with corresponding replacements's values. If count is specified only the first count occurrences of every key are replaced. :name: replace """""" """""" Returns string formatted with arbitrary set of positional and keyword arguments. Works as format method in python. :name: format """"""@specs.parameter('string', yaqltypes.String()) @specs.parameter('count', int)def string_by_int(string, count, engine): """""" Returns string repeated count times. """""" utils.limit_memory_usage(engine, (-count + 1, u''), (count, string)) return string * count @specs.parameter('count', int) @specs.parameter('string', yaqltypes.String()) @specs.name('#operator_*') def int_by_string(count, string, engine): """""" Returns string repeated count times. """""" return string_by_int(string, count, engine) """""" Returns true if there is at least one occurrence of left string in right. """""" """""" Returns a substring beginning from start index to the end. Returns a substring beginning from start index with length if given. :name: substring """""" """""" Returns an index of first occurence sub in string beginning from start. :name: indexOf """""" """""" Returns an index of first occurence sub in string beginning from start to start+length. :name: indexOf """""" """""" Returns an index of last occurence sub in string beginning from start. :name: lastIndexOf """""" """""" Returns an index of last occurence sub in string beginning from start to start+length. :name: lastIndexOf """""" """""" Returns a list of chars of string. :name: toCharArray """""" """""" Returns a tuple of all distinct items of specified types. :name: characters """""" """""" Returns true if arg is a string. :name: isString """""" """""" Returns true if string starts with any of given prefixes. :name: startsWith """""" """""" Returns true if string ends with any of given prefixes. :name: endsWith """""" """""" Returns string with hexadecimal representation of num. :name: hex """""""," return left > right return left < right@specs.parameter('left', yaqltypes.String()) @specs.parameter('right', int)def string_by_int(left, right, engine): utils.limit_memory_usage(engine, (-right + 1, u''), (right, left)) return left * right@specs.parameter('left', int) @specs.parameter('right', yaqltypes.String()) @specs.name('#operator_*') def int_by_string(left, right, engine): return string_by_int(right, left, engine) ",196,14
openstack%2Fyaql~master~Ib4c2ca5fd0d1f6c62e1a2d24f422c1cd78013e4b,openstack/yaql,master,Ib4c2ca5fd0d1f6c62e1a2d24f422c1cd78013e4b,[docs] Docstrings for math YAQL functions,MERGED,2016-06-02 14:54:35.000000000,2016-08-29 12:02:17.000000000,2016-08-29 12:02:17.000000000,"[{'_account_id': 3}, {'_account_id': 7225}, {'_account_id': 7226}, {'_account_id': 7535}, {'_account_id': 8127}, {'_account_id': 14947}, {'_account_id': 15168}, {'_account_id': 20563}, {'_account_id': 20773}]","[{'number': 1, 'created': '2016-06-02 14:54:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/yaql/commit/bd498d622ee50865ca2a67989a05e264447345bf', 'message': '[docs] Docstrings for math YAQL functions\n\nChange-Id: Ib4c2ca5fd0d1f6c62e1a2d24f422c1cd78013e4b\n'}, {'number': 2, 'created': '2016-06-02 15:49:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/yaql/commit/01d5e0005982bb642755c8818e7360c68008d5b4', 'message': '[docs] Docstrings for math YAQL functions\n\nChange-Id: Ib4c2ca5fd0d1f6c62e1a2d24f422c1cd78013e4b\n'}, {'number': 3, 'created': '2016-06-06 16:55:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/yaql/commit/2800fd5daf69cdcd7f91526ed0bafe38c0cabadb', 'message': '[docs] Docstrings for math YAQL functions\n\nChange-Id: Ib4c2ca5fd0d1f6c62e1a2d24f422c1cd78013e4b\n'}, {'number': 4, 'created': '2016-07-11 10:57:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/yaql/commit/929ac06a2cfd65de349f22950f69d38133bc3231', 'message': '[docs] Docstrings for math YAQL functions\n\nChange-Id: Ib4c2ca5fd0d1f6c62e1a2d24f422c1cd78013e4b\n'}, {'number': 5, 'created': '2016-07-17 18:06:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/yaql/commit/c7d7a38626efd06a210a28396d550d349269c7cc', 'message': '[docs] Docstrings for math YAQL functions\n\nChange-Id: Ib4c2ca5fd0d1f6c62e1a2d24f422c1cd78013e4b\n'}, {'number': 6, 'created': '2016-07-20 12:42:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/yaql/commit/f6e3345bc36aab09265fc75b5a14158e0f2d35ba', 'message': '[docs] Docstrings for math YAQL functions\n\nChange-Id: Ib4c2ca5fd0d1f6c62e1a2d24f422c1cd78013e4b\n'}, {'number': 7, 'created': '2016-07-20 13:23:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/yaql/commit/f0ec5925cf014d27f4ce7af8e68624efb925f56b', 'message': '[docs] Docstrings for math YAQL functions\n\nChange-Id: Ib4c2ca5fd0d1f6c62e1a2d24f422c1cd78013e4b\n'}, {'number': 8, 'created': '2016-07-20 13:24:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/yaql/commit/02df1569f6f918fd0b275baf04ef7d7b8bd01aff', 'message': '[docs] Docstrings for math YAQL functions\n\nChange-Id: Ib4c2ca5fd0d1f6c62e1a2d24f422c1cd78013e4b\n'}, {'number': 9, 'created': '2016-07-20 15:31:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/yaql/commit/85fa0984deb4e24bbc1ed59727834a8e1777204f', 'message': '[docs] Docstrings for math YAQL functions\n\nChange-Id: Ib4c2ca5fd0d1f6c62e1a2d24f422c1cd78013e4b\n'}, {'number': 10, 'created': '2016-07-21 17:43:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/yaql/commit/37c77e0a24b3076390cf163ceb852e528357c199', 'message': '[docs] Docstrings for math YAQL functions\n\nChange-Id: Ib4c2ca5fd0d1f6c62e1a2d24f422c1cd78013e4b\n'}, {'number': 11, 'created': '2016-07-24 21:19:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/yaql/commit/77fcdcf6e837fcd3b44cafc0768bcf1846697951', 'message': '[docs] Docstrings for math YAQL functions\n\nChange-Id: Ib4c2ca5fd0d1f6c62e1a2d24f422c1cd78013e4b\n'}, {'number': 12, 'created': '2016-07-25 11:36:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/yaql/commit/88868a6d32125d1d981ec8c5e5faf37f074b33d2', 'message': '[docs] Docstrings for math YAQL functions\n\nChange-Id: Ib4c2ca5fd0d1f6c62e1a2d24f422c1cd78013e4b\n'}, {'number': 13, 'created': '2016-07-29 13:12:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/yaql/commit/39047396dc6c6ca128c10ac03e7e90d8740cd9bc', 'message': '[docs] Docstrings for math YAQL functions\n\nChange-Id: Ib4c2ca5fd0d1f6c62e1a2d24f422c1cd78013e4b\n'}, {'number': 14, 'created': '2016-07-29 13:15:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/yaql/commit/c46146b6f1ab057fd5eab4e443f3d595ece2d7f3', 'message': '[docs] Docstrings for math YAQL functions\n\nChange-Id: Ib4c2ca5fd0d1f6c62e1a2d24f422c1cd78013e4b\n'}, {'number': 15, 'created': '2016-08-09 13:54:57.000000000', 'files': ['yaql/standard_library/math.py'], 'web_link': 'https://opendev.org/openstack/yaql/commit/074a733f22b4104c550e50084e3ac6d876aafa2f', 'message': '[docs] Docstrings for math YAQL functions\n\nChange-Id: Ib4c2ca5fd0d1f6c62e1a2d24f422c1cd78013e4b\n'}]",35,324589,074a733f22b4104c550e50084e3ac6d876aafa2f,53,9,15,20563,,,0,"[docs] Docstrings for math YAQL functions

Change-Id: Ib4c2ca5fd0d1f6c62e1a2d24f422c1cd78013e4b
",git fetch https://review.opendev.org/openstack/yaql refs/changes/89/324589/6 && git format-patch -1 --stdout FETCH_HEAD,['yaql/standard_library/math.py'],1,bd498d622ee50865ca2a67989a05e264447345bf,(detached," """""" Returns sum of left and right. """""" """""" Returns difference between left and right. """""" """""" Returns left multiplyed by right. """""" """""" Returns left divided by right. """""" """""" Returns left modulo right. """""" """""" Returns +op. """""" """""" Returns -op. """""" """""" Returns true if left strictly greater than right, false otherwise. """""" """""" Returns true if left greater or equal to right, false otherwise. """""" """""" Returns true if left strictly less than right, false otherwise. """""" """""" Returns true if left less or equal to right, false otherwise. """""" """""" Returns the absolute value of a number. """""" """""" Returns an integer built from a number or string value. """""" """""" Returns a floating number built from a number or string value. """""" """""" Returns the next random floating number from [0.0, 1.0). """""" """""" Returns a random integer from [a, b]. """""" """""" Returns applied ""bitwise and"" to left and right numbers. Each bit of the output is 1 if the corresponding bit of left AND right is 1, otherwise it's 0. :name: bitwiseAnd """""" """""" Returns applied ""bitwise or"" to left and right numbers. Each bit of the output is 1 if the corresponding bit of left OR right is 1, otherwise it's 0. :name: bitwiseOr """""" """""" Returns applied ""bitwise exclusive or"" to left and right numbers. Each bit of the output is equal to the sum of corresponding left and right bits mod 2. :name: bitwiseXor """""" """""" Returns a number where each bit is a reversed corresponding bit of arg. :name: bitwiseXor """"""@specs.parameter('arg', int) @specs.parameter('shift', int) def shift_bits_right(arg, shift): """""" Returns arg with the bits shifted to the right by shift places. :name: shiftBitsRight """""" return arg >> shift @specs.parameter('arg', int) @specs.parameter('shift', int) def shift_bits_left(arg, shift): """""" Returns arg with the bits shifted to the left by shift places. :name: shiftBitsLeft """""" return arg << shift """""" Returns max from a and b. :name: max """""" """""" Returns min from a and b. :name: min """""" """""" Returns a to the power b. If c is present, return a to the power b, modulo c. :name: pow """""" """""" Returns 1 if num > 0; 0 if num == 0; -1 if num < 0. :name: pow """""" """""" Returns a floating number rounded to ndigits after the decimal point. If ndigits isn't specified, it defaults to zero. :name: round """""" """""" Returns true if value is an integer number, otherwise false. :name: isInteger """""" """""" Returns true if value is an integer or floating number, otherwise false. :name: isNumber """"""","@specs.parameter('left', int) @specs.parameter('right', int) def shift_bits_right(left, right): return left >> right @specs.parameter('left', int) @specs.parameter('right', int) def shift_bits_left(left, right): return left << right",129,8
openstack%2Fmonasca-log-api~master~I835a00262d10f813e33808a854f9fc174443a6ae,openstack/monasca-log-api,master,I835a00262d10f813e33808a854f9fc174443a6ae,Fix E126 test,MERGED,2016-08-29 10:32:26.000000000,2016-08-29 11:59:37.000000000,2016-08-29 11:59:37.000000000,"[{'_account_id': 3}, {'_account_id': 16168}]","[{'number': 1, 'created': '2016-08-29 10:32:26.000000000', 'files': ['monasca_log_api/tests/test_healthchecks.py', 'tox.ini', 'monasca_log_api/tests/test_logs_v3.py'], 'web_link': 'https://opendev.org/openstack/monasca-log-api/commit/d0bb9f0e8e43c1f2c58ba790cdbd462960cf5eba', 'message': 'Fix E126 test\n\nFix indentation in code for E126 tests.\n\nChange-Id: I835a00262d10f813e33808a854f9fc174443a6ae\n'}]",0,361997,d0bb9f0e8e43c1f2c58ba790cdbd462960cf5eba,6,2,1,20033,,,0,"Fix E126 test

Fix indentation in code for E126 tests.

Change-Id: I835a00262d10f813e33808a854f9fc174443a6ae
",git fetch https://review.opendev.org/openstack/monasca-log-api refs/changes/97/361997/1 && git format-patch -1 --stdout FETCH_HEAD,"['monasca_log_api/tests/test_healthchecks.py', 'tox.ini', 'monasca_log_api/tests/test_logs_v3.py']",3,d0bb9f0e8e43c1f2c58ba790cdbd462960cf5eba,test," 'message': _generate_unique_message(100), 'dimensions': { 'hostname': 'host_%d' % it, 'component': 'component_%d' % it, 'service': 'service_%d' % it } } for it in xrange(log_count)]"," 'message': _generate_unique_message(100), 'dimensions': { 'hostname': 'host_%d' % it, 'component': 'component_%d' % it, 'service': 'service_%d' % it } } for it in xrange(log_count)]",9,10
openstack%2Fironic~master~I1ce8253e9afba2608bb2f6a3246cd9617ec81e9c,openstack/ironic,master,I1ce8253e9afba2608bb2f6a3246cd9617ec81e9c,Add multi-tenancy section to security doc,MERGED,2016-07-21 17:07:18.000000000,2016-08-29 11:58:49.000000000,2016-08-29 11:58:49.000000000,"[{'_account_id': 3}, {'_account_id': 2889}, {'_account_id': 6773}, {'_account_id': 10343}, {'_account_id': 12356}, {'_account_id': 14525}]","[{'number': 1, 'created': '2016-07-21 17:07:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/5c8c3d77784c2d1bc95827c3ff83504c708620bb', 'message': 'Add multi-tenancy section to security doc\n\nAdd a small section describing the major concerns to be considered when\nevaluating a multi-tenant deployment to the documentation.\n\nChange-Id: I1ce8253e9afba2608bb2f6a3246cd9617ec81e9c\n'}, {'number': 2, 'created': '2016-08-21 22:49:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/167fe714f1974bdd886d0f9df284289a864f7b30', 'message': 'Add multi-tenancy section to security doc\n\nAdd a small section describing the major concerns to be considered when\nevaluating a multi-tenant deployment to the documentation.\n\nChange-Id: I1ce8253e9afba2608bb2f6a3246cd9617ec81e9c\n'}, {'number': 3, 'created': '2016-08-26 19:22:27.000000000', 'files': ['doc/source/deploy/security.rst'], 'web_link': 'https://opendev.org/openstack/ironic/commit/91a9627b456ae42b4b64c6572b23daff1eec194a', 'message': 'Add multi-tenancy section to security doc\n\nAdd a small section describing the major concerns to be considered when\nevaluating a multi-tenant deployment to the documentation.\n\nChange-Id: I1ce8253e9afba2608bb2f6a3246cd9617ec81e9c\n'}]",5,345557,91a9627b456ae42b4b64c6572b23daff1eec194a,16,6,3,2889,,,0,"Add multi-tenancy section to security doc

Add a small section describing the major concerns to be considered when
evaluating a multi-tenant deployment to the documentation.

Change-Id: I1ce8253e9afba2608bb2f6a3246cd9617ec81e9c
",git fetch https://review.opendev.org/openstack/ironic refs/changes/57/345557/2 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/deploy/security.rst'],1,5c8c3d77784c2d1bc95827c3ff83504c708620bb,doc,"Multi-tenancy ============= There are two aspects of multitenancy to consider when evaluating a deployment of the Bare Metal Service: * Interactions between tenants' workloads running simultaneously on separate servers, for example, IP spoofing, packet sniffing, man-in-the-middle attacks, and so on. - By default, the Bare Metal service provisions all nodes on a ""flat"" network, and does not take any precautions to avoid or prevent interaction between tenants. - This can be addressed by integration with the OpenStack Identity, Compute, and Networking services, so as to provide tenant-network isolation. * Interactions between tenants placed sequentially on the same server, for example, changes in BIOS settings, modifications to firmware, or files left on disk or peripheral storage devices. - By default, the Bare Metal service will erase (clean) the local disk drives during the ""cleaning"" phase, after deleting an instance. It *does not* reset BIOS or reflash firmware or peripheral devices. - This can be addressed through customizing the utility ramdisk used during the ""cleaning"" phase. See details in the :ref:`Firmware security` section. ",,24,0
openstack%2Fironic~master~I392cabbf04badabd8ae7bb00a914b0a06db3d421,openstack/ironic,master,I392cabbf04badabd8ae7bb00a914b0a06db3d421,Update documentation for keystone policy support,MERGED,2016-07-21 17:05:57.000000000,2016-08-29 11:58:41.000000000,2016-08-29 11:58:41.000000000,"[{'_account_id': 3}, {'_account_id': 2889}, {'_account_id': 6618}, {'_account_id': 6773}, {'_account_id': 7080}, {'_account_id': 10118}, {'_account_id': 10239}, {'_account_id': 10342}, {'_account_id': 12356}, {'_account_id': 14525}, {'_account_id': 14629}, {'_account_id': 19339}, {'_account_id': 19901}, {'_account_id': 20311}]","[{'number': 1, 'created': '2016-07-21 17:05:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/7c5c87985f86338629769d84a65faac08f1a198d', 'message': 'Update documentation for keystone policy support\n\nThis change adds information about keystone policy support in the\nfollowing places:\n\n* api-ref: add notes to the Nodes reference, indicating that\n  password and configdrive contents may be hidden in responses\n* deploy security guide: add a section about limiting API access\n  by using the new policies and roles\n* deploy install guide: add instructions for creating the necessary\n  Roles with the Identity service\n\nCloses-bug: #1526752\nChange-Id: I392cabbf04badabd8ae7bb00a914b0a06db3d421\n'}, {'number': 2, 'created': '2016-07-21 19:04:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/de03912b9c9396e1ec1d9134e474f4c63562bfa5', 'message': 'Update documentation for keystone policy support\n\nThis change adds information about keystone policy support in the\nfollowing places:\n\n* api-ref: add notes to the Nodes reference, indicating that\n  password and configdrive contents may be hidden in responses\n* deploy security guide: add a section about limiting API access\n  by using the new policies and roles\n* deploy install guide: add instructions for creating the necessary\n  Roles with the Identity service\n\nCloses-bug: #1526752\nChange-Id: I392cabbf04badabd8ae7bb00a914b0a06db3d421\n'}, {'number': 3, 'created': '2016-07-21 21:23:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/3764da76faa078f28f52fa62549c957bdde08a80', 'message': 'Update documentation for keystone policy support\n\nThis change adds information about keystone policy support in the\nfollowing places:\n\n* api-ref: add notes to the Nodes reference, indicating that\n  password and configdrive contents may be hidden in responses\n* deploy security guide: add a section about limiting API access\n  by using the new policies and roles\n* deploy install guide: add instructions for creating the necessary\n  Roles with the Identity service\n\nCloses-bug: #1526752\nChange-Id: I392cabbf04badabd8ae7bb00a914b0a06db3d421\n'}, {'number': 4, 'created': '2016-07-22 18:09:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/3c730b682ce5160a11d5f21b830157532250cb91', 'message': 'Update documentation for keystone policy support\n\nThis change adds information about keystone policy support in the\nfollowing places:\n\n* api-ref: add notes to the Nodes reference, indicating that\n  password and configdrive contents may be hidden in responses\n* deploy security guide: add a section about limiting API access\n  by using the new policies and roles\n* deploy install guide: add instructions for creating the necessary\n  Roles with the Identity service\n\nCloses-bug: #1526752\nChange-Id: I392cabbf04badabd8ae7bb00a914b0a06db3d421\n'}, {'number': 5, 'created': '2016-07-26 01:23:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/3b133b4d84252ab68b3afebbb409b47d212008e7', 'message': 'Update documentation for keystone policy support\n\nThis change adds information about keystone policy support in the\nfollowing places:\n\n* api-ref: add notes to the Nodes reference, indicating that\n  password and configdrive contents may be hidden in responses\n* deploy security guide: add a section about limiting API access\n  by using the new policies and roles\n* deploy install guide: add instructions for creating the necessary\n  Roles with the Identity service\n\nCloses-bug: #1526752\nChange-Id: I392cabbf04badabd8ae7bb00a914b0a06db3d421\n'}, {'number': 6, 'created': '2016-07-29 16:12:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/04a5836888cca530aa2e116c6d81150dc0cc0c8a', 'message': 'Update documentation for keystone policy support\n\nThis change adds information about keystone policy support in the\nfollowing places:\n\n* api-ref: add notes to the Nodes reference, indicating that\n  password and configdrive contents may be hidden in responses\n* deploy security guide: add a section about limiting API access\n  by using the new policies and roles\n* deploy install guide: add instructions for creating the necessary\n  Roles with the Identity service\n\nCloses-bug: #1526752\nChange-Id: I392cabbf04badabd8ae7bb00a914b0a06db3d421\n'}, {'number': 7, 'created': '2016-07-29 20:34:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/735c92b454f48225c96b398adac46e35617513c8', 'message': 'Update documentation for keystone policy support\n\nThis change adds information about keystone policy support in the\nfollowing places:\n\n* api-ref: add notes to the Nodes reference, indicating that\n  password and configdrive contents may be hidden in responses\n* deploy security guide: add a section about limiting API access\n  by using the new policies and roles\n* deploy install guide: add instructions for creating the necessary\n  Roles with the Identity service\n\nCloses-bug: #1526752\nChange-Id: I392cabbf04badabd8ae7bb00a914b0a06db3d421\n'}, {'number': 8, 'created': '2016-08-03 02:44:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/5bda7bb68152efc6c4697474483ccd2a657c18d1', 'message': 'Update documentation for keystone policy support\n\nThis change adds information about keystone policy support in the\nfollowing places:\n\n* api-ref: add notes to the Nodes reference, indicating that\n  password and configdrive contents may be hidden in responses\n* deploy security guide: add a section about limiting API access\n  by using the new policies and roles\n* deploy install guide: add instructions for creating the necessary\n  Roles with the Identity service\n\nCloses-bug: #1526752\nChange-Id: I392cabbf04badabd8ae7bb00a914b0a06db3d421\n'}, {'number': 9, 'created': '2016-08-10 23:36:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/174a1f9f99ca26fc5335f2f397d12b7826a3c701', 'message': 'Update documentation for keystone policy support\n\nThis change adds information about keystone policy support in the\nfollowing places:\n\n* api-ref: add notes to the Nodes reference, indicating that\n  password and configdrive contents may be hidden in responses\n* deploy security guide: add a section about limiting API access\n  by using the new policies and roles\n* deploy install guide: add instructions for creating the necessary\n  Roles with the Identity service\n\nCloses-bug: #1526752\nChange-Id: I392cabbf04badabd8ae7bb00a914b0a06db3d421\n'}, {'number': 10, 'created': '2016-08-11 22:40:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/43144930215a7cc150b2ed27459511e9d5cc6c4c', 'message': 'Update documentation for keystone policy support\n\nThis change adds information about keystone policy support in the\nfollowing places:\n\n* api-ref: add notes to the Nodes reference, indicating that\n  password and configdrive contents may be hidden in responses\n* deploy security guide: add a section about limiting API access\n  by using the new policies and roles\n* deploy install guide: add instructions for creating the necessary\n  Roles with the Identity service\n\nCloses-bug: #1526752\nChange-Id: I392cabbf04badabd8ae7bb00a914b0a06db3d421\n'}, {'number': 11, 'created': '2016-08-16 21:31:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/de3249daffe795dffa5cdca4291abeb682af99d5', 'message': 'Update documentation for keystone policy support\n\nThis change adds information about keystone policy support in the\nfollowing places:\n\n* api-ref: add notes to the Nodes reference, indicating that\n  password and configdrive contents may be hidden in responses\n* deploy security guide: add a section about limiting API access\n  by using the new policies and roles\n* deploy install guide: add instructions for creating the necessary\n  Roles with the Identity service\n\nPartial-bug: #1526752\nChange-Id: I392cabbf04badabd8ae7bb00a914b0a06db3d421\n'}, {'number': 12, 'created': '2016-08-16 21:53:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/0bc8fbbf1fd864dc7ab0ad8a64257678f3e16feb', 'message': 'Update documentation for keystone policy support\n\nThis change adds information about keystone policy support in the\nfollowing places:\n\n* api-ref: add notes to the Nodes reference, indicating that\n  password and configdrive contents may be hidden in responses\n* deploy security guide: add a section about limiting API access\n  by using the new policies and roles\n* deploy install guide: add instructions for creating the necessary\n  Roles with the Identity service\n* dev quickstart guide: use devstack ""demo"" user throughout the guide,\n  and add a note about why. Incidentally, switch to using ""openstack""\n  client instead of ""ironic"" and ""nova"" clients.\n\nPartial-bug: #1526752\nChange-Id: I392cabbf04badabd8ae7bb00a914b0a06db3d421\n'}, {'number': 13, 'created': '2016-08-26 15:11:16.000000000', 'files': ['doc/source/dev/dev-quickstart.rst', 'api-ref/source/baremetal-api-v1-nodes.inc', 'doc/source/deploy/install-guide.rst', 'doc/source/deploy/security.rst'], 'web_link': 'https://opendev.org/openstack/ironic/commit/a5c26972b28018083e0a76c0dbc41d738ca84fff', 'message': 'Update documentation for keystone policy support\n\nThis change adds information about keystone policy support in the\nfollowing places:\n\n* api-ref: add notes to the Nodes reference, indicating that\n  password and configdrive contents may be hidden in responses\n* deploy security guide: add a section about limiting API access\n  by using the new policies and roles\n* deploy install guide: add instructions for creating the necessary\n  Roles with the Identity service\n* dev quickstart guide: use devstack ""demo"" user throughout the guide,\n  and add a note about why. Incidentally, switch to using ""openstack""\n  client instead of ""ironic"" and ""nova"" clients.\n\nPartial-bug: #1526752\nChange-Id: I392cabbf04badabd8ae7bb00a914b0a06db3d421\n'}]",33,345556,a5c26972b28018083e0a76c0dbc41d738ca84fff,66,14,13,2889,,,0,"Update documentation for keystone policy support

This change adds information about keystone policy support in the
following places:

* api-ref: add notes to the Nodes reference, indicating that
  password and configdrive contents may be hidden in responses
* deploy security guide: add a section about limiting API access
  by using the new policies and roles
* deploy install guide: add instructions for creating the necessary
  Roles with the Identity service
* dev quickstart guide: use devstack ""demo"" user throughout the guide,
  and add a note about why. Incidentally, switch to using ""openstack""
  client instead of ""ironic"" and ""nova"" clients.

Partial-bug: #1526752
Change-Id: I392cabbf04badabd8ae7bb00a914b0a06db3d421
",git fetch https://review.opendev.org/openstack/ironic refs/changes/56/345556/1 && git format-patch -1 --stdout FETCH_HEAD,"['api-ref/source/baremetal-api-v1-nodes.inc', 'doc/source/deploy/install-guide.rst', 'doc/source/deploy/security.rst']",3,7c5c87985f86338629769d84a65faac08f1a198d,bug/1526752," Security Overview =================actions to secure their environment(s). This document is intended to provide an overview of what risks an operator of the Bare Metal service should be aware of. It is not intended as a How-To guide for securing a data center or an OpenStack deployment. REST API: user roles and policy settings ======================================== Beginning with the Newton (6.1.0) release, the Bare Metal service allows operators significant control over API access: * Access may be restricted to each method (GET, PUT, etc) for each REST resource. Defaults are provided with the release and defined in code. * Access may be divided between an ""administrative"" role and ""observer"" role. * The ``driver_info`` and ``driver_internal_info`` properties are hidden from the ""observer"" role. * Both passwords and configdrive contents may be hidden from responses, depending on the ``show_password`` and ``show_configdrive`` policy settings respectively. The default is to always mask both. Prior to the Newton (6.1.0) release, the Bare Metal service only supported two policy options: * API access may be secured by a simple policy rule: users with administrative privileges may access all API resources, whereas uses without administrative privileges may only access public API resources. * Passwords may be hidden from responses, depending on the ``show_password`` policy setting; the default is to always mask passwords. ","======== Security ======== Overview ========actions to secure their environment appropriately. This document is intended to provide an overview of what risks an operator of the Bare Metal service should be aware of. It is not intended as a How-To guide for securing a data center or an OpenStack deployment... TODO: add ""Securing Ironic's REST API"" section ",71,19
openstack%2Fironic~master~Ie9821fa7a6b841e32445b6ddd37220d1c3c7ccfd,openstack/ironic,master,Ie9821fa7a6b841e32445b6ddd37220d1c3c7ccfd,Fix formatting strings in LOG.error,MERGED,2016-08-26 12:03:26.000000000,2016-08-29 11:58:33.000000000,2016-08-29 11:58:33.000000000,"[{'_account_id': 3}, {'_account_id': 6773}, {'_account_id': 10239}, {'_account_id': 12356}, {'_account_id': 20311}, {'_account_id': 21239}, {'_account_id': 22255}]","[{'number': 1, 'created': '2016-08-26 12:03:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/856156fa73fe87146e432bcf2313a6234356358c', 'message': 'Fix formatting strings in LOG.error\n\nFollowing OpenStack Style Guidelines:\nhttp://docs.openstack.org/developer/hacking/#dictionaries-lists\n\nUsing multiple variables for formmatting strings is not clear as using explicit dictionaries and can hire errors during refactoring.\n\nChange-Id: Ie9821fa7a6b841e32445b6ddd37220d1c3c7ccfd\n'}, {'number': 2, 'created': '2016-08-26 16:09:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/673948fcb7c0e47a32b1e29dafb32dd3ebb34b46', 'message': 'Fix formatting strings in LOG.error\n\nFollowing OpenStack Style Guidelines:\nhttp://docs.openstack.org/developer/hacking/#dictionaries-lists\n\nUsing multiple variables for formmatting strings is not clear as using \nexplicit dictionaries and can hire errors during refactoring.\n\nChange-Id: Ie9821fa7a6b841e32445b6ddd37220d1c3c7ccfd\n'}, {'number': 3, 'created': '2016-08-26 17:27:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/03c81662307423d153e79a20919d052badcc4987', 'message': 'Fix formatting strings in LOG.error\n\nFollowing OpenStack Style Guidelines:\nhttp://docs.openstack.org/developer/hacking/#dictionaries-lists\n\nUsing multiple variables for formmatting strings is not clear as using \nexplicit dictionaries and can hire errors during refactoring.\n\nChange-Id: Ie9821fa7a6b841e32445b6ddd37220d1c3c7ccfd\n'}, {'number': 4, 'created': '2016-08-26 17:28:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/538ba7192146932a1f5ddc7e95923902d6e56a82', 'message': 'Fix formatting strings in LOG.error\n\nFollowing OpenStack Style Guidelines:\nhttp://docs.openstack.org/developer/hacking/#dictionaries-lists\n\nUsing multiple variables for formmatting strings is not clear as using \nexplicit dictionaries and can hire errors during refactoring.\n\nChange-Id: Ie9821fa7a6b841e32445b6ddd37220d1c3c7ccfd\n'}, {'number': 5, 'created': '2016-08-26 17:35:00.000000000', 'files': ['ironic/common/exception.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/03ed31faa4c4aaf52fad9241da1821fcee4598b9', 'message': 'Fix formatting strings in LOG.error\n\nFollowing OpenStack Style Guidelines:[H703]\nhttp://docs.openstack.org/developer/hacking/#internationalization-i18n-strings\n\nUsing multiple variables for formmatting strings is not clear as using\nexplicit dictionaries and can hide errors during refactoring.\n\nChange-Id: Ie9821fa7a6b841e32445b6ddd37220d1c3c7ccfd\n'}]",1,361127,03ed31faa4c4aaf52fad9241da1821fcee4598b9,20,7,5,22255,,,0,"Fix formatting strings in LOG.error

Following OpenStack Style Guidelines:[H703]
http://docs.openstack.org/developer/hacking/#internationalization-i18n-strings

Using multiple variables for formmatting strings is not clear as using
explicit dictionaries and can hide errors during refactoring.

Change-Id: Ie9821fa7a6b841e32445b6ddd37220d1c3c7ccfd
",git fetch https://review.opendev.org/openstack/ironic refs/changes/27/361127/4 && git format-patch -1 --stdout FETCH_HEAD,['ironic/common/exception.py'],1,856156fa73fe87146e432bcf2313a6234356358c,fixLog," LOG.error(_LE(""%(name)s: %(value)s""), {""name"": name, ""value"": value})"," LOG.error(""%s: %s"" % (name, value))",2,1
openstack%2Fpython-neutronclient~master~I1bee877a2e83801527bcccffe404053b6aafe012,openstack/python-neutronclient,master,I1bee877a2e83801527bcccffe404053b6aafe012,"Fix the problem of ""qos-bandwidth-limit-rule-show""",MERGED,2016-06-08 08:25:53.000000000,2016-08-29 11:51:54.000000000,2016-08-29 11:51:54.000000000,"[{'_account_id': 3}, {'_account_id': 841}, {'_account_id': 1131}, {'_account_id': 7448}, {'_account_id': 8788}, {'_account_id': 9656}, {'_account_id': 11975}, {'_account_id': 14605}, {'_account_id': 16707}, {'_account_id': 17776}, {'_account_id': 20082}, {'_account_id': 20256}, {'_account_id': 20566}, {'_account_id': 20787}, {'_account_id': 23265}]","[{'number': 1, 'created': '2016-06-08 08:25:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/7a6defe67da1be07bfc44c9f7b5d016bed3349bb', 'message': 'Fix the problem of ""qos-bandwidth-limit-rule-show""\n\nAdd a arg ""**_params"" in show_bandwidth_limit_rule() to use the\n""-F"" option.\n\nChange-Id: I1bee877a2e83801527bcccffe404053b6aafe012\nPartial-Bug: #1587291\n'}, {'number': 2, 'created': '2016-06-16 01:27:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/c358a263ae73436628aa8893f5f39fcc325b6fae', 'message': 'Fix the problem of ""qos-bandwidth-limit-rule-show""\n\nAdd a arg ""**_params"" in show_bandwidth_limit_rule() to use the\n""-F"" option.\n\nChange-Id: I1bee877a2e83801527bcccffe404053b6aafe012\nPartial-Bug: #1587291\n'}, {'number': 3, 'created': '2016-06-22 02:18:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/a2374f93e038788d5cf0aa7c300708acbbeebd11', 'message': 'Fix the problem of ""qos-bandwidth-limit-rule-show""\n\nAdd a arg ""**_params"" in show_bandwidth_limit_rule() to use the\n""-F"" option.\n\nChange-Id: I1bee877a2e83801527bcccffe404053b6aafe012\nPartial-Bug: #1587291\n'}, {'number': 4, 'created': '2016-06-23 06:40:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/33a7a31d2f2ee74a2d99bad4cc68edbaddf41bf0', 'message': 'Fix the problem of ""qos-bandwidth-limit-rule-show""\n\nAdd a arg ""**_params"" in show_bandwidth_limit_rule() to use the\n""-F"" option.\n\nChange-Id: I1bee877a2e83801527bcccffe404053b6aafe012\nPartial-Bug: #1587291\n'}, {'number': 5, 'created': '2016-06-28 10:25:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/2b79c87f912539a782f8b4dc9bc13f9b6f656e3e', 'message': 'Fix the problem of ""qos-bandwidth-limit-rule-show""\n\nAdd a arg ""**_params"" in show_bandwidth_limit_rule() to use the\n""-F"" option.\n\nChange-Id: I1bee877a2e83801527bcccffe404053b6aafe012\nPartial-Bug: #1587291\n'}, {'number': 6, 'created': '2016-07-14 01:52:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/92ebf48142e39983f4eb4e06cc5e61e42b5fb1ae', 'message': 'Fix the problem of ""qos-bandwidth-limit-rule-show""\n\nAdd a arg ""**_params"" in show_bandwidth_limit_rule() to use the\n""-F"" option.\n\nChange-Id: I1bee877a2e83801527bcccffe404053b6aafe012\nPartial-Bug: #1587291\n'}, {'number': 7, 'created': '2016-08-18 06:42:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/73fffb24e9fc8f8780f140438626b402fb2412c5', 'message': 'Fix the problem of ""qos-bandwidth-limit-rule-show""\n\nAdd a arg ""**_params"" in show_bandwidth_limit_rule() to use the\n""-F"" option.\n\nChange-Id: I1bee877a2e83801527bcccffe404053b6aafe012\nPartial-Bug: #1587291\n'}, {'number': 8, 'created': '2016-08-23 01:37:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/e5c7d828c2340364f23a3759c0f2f448c121c529', 'message': 'Fix the problem of ""qos-bandwidth-limit-rule-show""\n\nAdd a arg ""**_params"" in show_bandwidth_limit_rule() to use the\n""-F"" option.\n\nChange-Id: I1bee877a2e83801527bcccffe404053b6aafe012\nPartial-Bug: #1587291\n'}, {'number': 9, 'created': '2016-08-29 09:21:18.000000000', 'files': ['neutronclient/v2_0/client.py', 'neutronclient/tests/unit/qos/test_cli20_bandwidth_limit_rule.py'], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/d875cb34b94c9efe9767cc5ccd89e462bc0e7614', 'message': 'Fix the problem of ""qos-bandwidth-limit-rule-show""\n\nAdd a arg ""**_params"" in show_bandwidth_limit_rule() to use the\n""-F"" option.\n\nChange-Id: I1bee877a2e83801527bcccffe404053b6aafe012\nPartial-Bug: #1587291\n'}]",2,326902,d875cb34b94c9efe9767cc5ccd89e462bc0e7614,36,15,9,20000,,,0,"Fix the problem of ""qos-bandwidth-limit-rule-show""

Add a arg ""**_params"" in show_bandwidth_limit_rule() to use the
""-F"" option.

Change-Id: I1bee877a2e83801527bcccffe404053b6aafe012
Partial-Bug: #1587291
",git fetch https://review.opendev.org/openstack/python-neutronclient refs/changes/02/326902/9 && git format-patch -1 --stdout FETCH_HEAD,"['neutronclient/v2_0/client.py', 'neutronclient/tests/unit/qos/test_cli20_bandwidth_limit_rule.py']",2,7a6defe67da1be07bfc44c9f7b5d016bed3349bb,bug/1587291," args = ['--fields', 'id', self.test_id, policy_id] ['id'], cmd_resource=self.cmd_res,"," args = [self.test_id, policy_id] [], cmd_resource=self.cmd_res,",4,4
openstack%2Ftripleo-common~master~I7175af3d6154b383513d54f5a4848f84a8acb168,openstack/tripleo-common,master,I7175af3d6154b383513d54f5a4848f84a8acb168,Don't expect input to be in every workflow in doc generation,MERGED,2016-08-29 10:03:17.000000000,2016-08-29 11:44:48.000000000,2016-08-29 11:44:48.000000000,"[{'_account_id': 3}, {'_account_id': 4330}, {'_account_id': 4978}, {'_account_id': 10873}]","[{'number': 1, 'created': '2016-08-29 10:03:17.000000000', 'files': ['doc/source/_exts/workbooks.py'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/81514076c8aa595373ccce001a7b9cb8578cf817', 'message': ""Don't expect input to be in every workflow in doc generation\n\nChange-Id: I7175af3d6154b383513d54f5a4848f84a8acb168\n""}]",0,361984,81514076c8aa595373ccce001a7b9cb8578cf817,8,4,1,9712,,,0,"Don't expect input to be in every workflow in doc generation

Change-Id: I7175af3d6154b383513d54f5a4848f84a8acb168
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/84/361984/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/_exts/workbooks.py'],1,81514076c8aa595373ccce001a7b9cb8578cf817,, if 'input' in workflow: yield ' Workflow inputs:' yield '' for input_param in workflow['input']: try: yield ' :input {}: Default: {}'.format( *input_param.items()[0]) except: yield ' :input {}: Required.'.format(input_param) yield '', yield ' Workflow inputs:' yield '' for input_param in workflow['input']: try: yield ' :input {}: Default: {}'.format( *input_param.items()[0]) except: yield ' :input {}: Required.'.format(input_param) yield '',10,9
openstack%2Fpuppet-nova~master~I5ed53cfffe80dbbbb9dcee7c2ea6037afbed2382,openstack/puppet-nova,master,I5ed53cfffe80dbbbb9dcee7c2ea6037afbed2382,Allow to set pci_passthrough to an empty value,MERGED,2016-08-26 16:33:32.000000000,2016-08-29 11:44:40.000000000,2016-08-29 11:44:40.000000000,"[{'_account_id': 3}, {'_account_id': 7745}, {'_account_id': 14985}]","[{'number': 1, 'created': '2016-08-26 16:33:32.000000000', 'files': ['manifests/compute.pp', 'spec/classes/nova_compute_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/4f93e49cee4339df7e291792b999dcb4df320bff', 'message': ""Allow to set pci_passthrough to an empty value\n\nIf pci_passthrough is set to an empty value, puppet won't configure the\nparameter and use os_service_default, so the parameter won't be set.\nThis patch is required because of the usage of a custom function to\ncompute the final parameter.\n\nChange-Id: I5ed53cfffe80dbbbb9dcee7c2ea6037afbed2382\n""}]",0,361355,4f93e49cee4339df7e291792b999dcb4df320bff,9,3,1,3153,,,0,"Allow to set pci_passthrough to an empty value

If pci_passthrough is set to an empty value, puppet won't configure the
parameter and use os_service_default, so the parameter won't be set.
This patch is required because of the usage of a custom function to
compute the final parameter.

Change-Id: I5ed53cfffe80dbbbb9dcee7c2ea6037afbed2382
",git fetch https://review.opendev.org/openstack/puppet-nova refs/changes/55/361355/1 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/compute.pp', 'spec/classes/nova_compute_spec.rb']",2,4f93e49cee4339df7e291792b999dcb4df320bff,pci," context 'when vcpu_pin_set and pci_passthrough are empty' do { :vcpu_pin_set => """", :pci_passthrough => """" } it 'clears pci_passthrough configuration' do is_expected.to contain_nova_config('DEFAULT/pci_passthrough_whitelist').with(:value => '<SERVICE DEFAULT>') end"," context 'when vcpu_pin_set is empty' do { :vcpu_pin_set => """" }",23,18
openstack%2Fheat~master~I7a9a10b871f50a5a2885adc72d60d626f960557c,openstack/heat,master,I7a9a10b871f50a5a2885adc72d60d626f960557c,Provide 'and' function,MERGED,2016-07-27 09:50:25.000000000,2016-08-29 11:40:29.000000000,2016-08-29 11:40:29.000000000,"[{'_account_id': 3}, {'_account_id': 4571}, {'_account_id': 6577}, {'_account_id': 7385}, {'_account_id': 8289}, {'_account_id': 8833}, {'_account_id': 10487}, {'_account_id': 12363}, {'_account_id': 13009}, {'_account_id': 20559}]","[{'number': 1, 'created': '2016-07-27 09:50:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/54b47bd624434dd939bb6415850d5be95c13df8b', 'message': ""Provide 'and' function\n\nProvides condition function 'and' for templates:\nAWSTemplateFormatVersion.2010-09-09\nheat_template_version.2016-10-14\n\nBlueprint: support-conditions-function\nChange-Id: I7a9a10b871f50a5a2885adc72d60d626f960557c\n""}, {'number': 2, 'created': '2016-07-27 10:37:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/e9aa7a583ab0d54b4a0c257b7af4a1401e759c60', 'message': ""Provide 'and' function\n\nProvides condition function 'and' for templates:\nAWSTemplateFormatVersion.2010-09-09\nheat_template_version.2016-10-14\n\nBlueprint: support-conditions-function\nChange-Id: I7a9a10b871f50a5a2885adc72d60d626f960557c\n""}, {'number': 3, 'created': '2016-07-28 02:27:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/422d918dee8cf858ad02b7fd65736372a250784e', 'message': ""Provide 'and' function\n\nProvides condition function 'and' for templates:\nAWSTemplateFormatVersion.2010-09-09\nheat_template_version.2016-10-14\n\nBlueprint: support-conditions-function\nChange-Id: I7a9a10b871f50a5a2885adc72d60d626f960557c\n""}, {'number': 4, 'created': '2016-07-28 05:22:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/a28eea1605d2c702e4a11c9cac9ecd781ee7878d', 'message': ""Provide 'and' function\n\nProvides condition function 'and' for templates:\nAWSTemplateFormatVersion.2010-09-09\nheat_template_version.2016-10-14\n\nBlueprint: support-conditions-function\nChange-Id: I7a9a10b871f50a5a2885adc72d60d626f960557c\n""}, {'number': 5, 'created': '2016-07-28 06:34:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/062d1e62fa74fb16e506b2e0a99d96fbcacd1b42', 'message': ""Provide 'and' function\n\nProvides condition function 'and' for templates:\nAWSTemplateFormatVersion.2010-09-09\nheat_template_version.2016-10-14\n\nBlueprint: support-conditions-function\nChange-Id: I7a9a10b871f50a5a2885adc72d60d626f960557c\n""}, {'number': 6, 'created': '2016-08-03 07:18:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/67c502dd093e58f6ab0b9440d1119947de328aeb', 'message': ""Provide 'and' function\n\nProvides condition function 'and' for templates:\nAWSTemplateFormatVersion.2010-09-09\nheat_template_version.2016-10-14\n\nBlueprint: support-conditions-function\nChange-Id: I7a9a10b871f50a5a2885adc72d60d626f960557c\n""}, {'number': 7, 'created': '2016-08-04 03:49:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/f0a6d45db3f77993ee2111c60cf08c8f95c3d3fb', 'message': ""Provide 'and' function\n\nProvides condition function 'and' for templates:\nAWSTemplateFormatVersion.2010-09-09\nheat_template_version.2016-10-14\n\nBlueprint: support-conditions-function\nChange-Id: I7a9a10b871f50a5a2885adc72d60d626f960557c\n""}, {'number': 8, 'created': '2016-08-11 09:16:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/6139bdb266f130296b1410e8b5ccc14d3f3588aa', 'message': ""Provide 'and' function\n\nProvides condition function 'and' for templates:\nAWSTemplateFormatVersion.2010-09-09\nheat_template_version.2016-10-14\n\nBlueprint: support-conditions-function\nChange-Id: I7a9a10b871f50a5a2885adc72d60d626f960557c\n""}, {'number': 9, 'created': '2016-08-22 07:24:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/2effb268cfad1278e7241192882f9015060377f4', 'message': ""Provide 'and' function\n\nProvides condition function 'and' for templates:\nAWSTemplateFormatVersion.2010-09-09\nheat_template_version.2016-10-14\n\nBlueprint: support-conditions-function\nChange-Id: I7a9a10b871f50a5a2885adc72d60d626f960557c\n""}, {'number': 10, 'created': '2016-08-22 07:59:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/b446770b097e352bef993d49b7b7a753af3c95a3', 'message': ""Provide 'and' function\n\nProvides condition function 'and' for templates:\nAWSTemplateFormatVersion.2010-09-09\nheat_template_version.2016-10-14\n\nBlueprint: support-conditions-function\nChange-Id: I7a9a10b871f50a5a2885adc72d60d626f960557c\n""}, {'number': 11, 'created': '2016-08-22 08:15:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/64b597e0102df6a9c3a2c3a944bba052b15d4036', 'message': ""Provide 'and' function\n\nProvides condition function 'and' for templates:\nAWSTemplateFormatVersion.2010-09-09\nheat_template_version.2016-10-14\n\nBlueprint: support-conditions-function\nChange-Id: I7a9a10b871f50a5a2885adc72d60d626f960557c\n""}, {'number': 12, 'created': '2016-08-23 04:02:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/fcce3b779e6e48bc0a35be4ef8d6bb50c4ad2a40', 'message': ""Provide 'and' function\n\nProvides condition function 'and' for templates:\nAWSTemplateFormatVersion.2010-09-09\nheat_template_version.2016-10-14\n\nBlueprint: support-conditions-function\nChange-Id: I7a9a10b871f50a5a2885adc72d60d626f960557c\n""}, {'number': 13, 'created': '2016-08-24 03:06:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/9dbdf40108d7b9c80bf7fddc5aa109f68a4df04f', 'message': ""Provide 'and' function\n\nProvides condition function 'and' for templates:\nAWSTemplateFormatVersion.2010-09-09\nheat_template_version.2016-10-14\n\nBlueprint: support-conditions-function\nChange-Id: I7a9a10b871f50a5a2885adc72d60d626f960557c\n""}, {'number': 14, 'created': '2016-08-25 01:14:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/31fd3f636a0db0c30c7affec927a9f531c04ee48', 'message': ""Provide 'and' function\n\nProvides condition function 'and' for templates:\nAWSTemplateFormatVersion.2010-09-09\nheat_template_version.2016-10-14\n\nBlueprint: support-conditions-function\nChange-Id: I7a9a10b871f50a5a2885adc72d60d626f960557c\n""}, {'number': 15, 'created': '2016-08-26 01:44:32.000000000', 'files': ['heat/engine/hot/functions.py', 'doc/source/template_guide/hot_spec.rst', 'heat/engine/cfn/template.py', 'heat/tests/test_template.py', 'heat/engine/hot/template.py', 'doc/source/template_guide/functions.rst', 'heat_integrationtests/functional/test_conditions.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/6fa325e34e5ba46de2631acf019ad893b7c8115f', 'message': ""Provide 'and' function\n\nProvides condition function 'and' for templates:\nAWSTemplateFormatVersion.2010-09-09\nheat_template_version.2016-10-14\n\nBlueprint: support-conditions-function\nChange-Id: I7a9a10b871f50a5a2885adc72d60d626f960557c\n""}]",14,347731,6fa325e34e5ba46de2631acf019ad893b7c8115f,49,10,15,8289,,,0,"Provide 'and' function

Provides condition function 'and' for templates:
AWSTemplateFormatVersion.2010-09-09
heat_template_version.2016-10-14

Blueprint: support-conditions-function
Change-Id: I7a9a10b871f50a5a2885adc72d60d626f960557c
",git fetch https://review.opendev.org/openstack/heat refs/changes/31/347731/8 && git format-patch -1 --stdout FETCH_HEAD,"['heat/engine/hot/functions.py', 'doc/source/template_guide/hot_spec.rst', 'heat/engine/cfn/template.py', 'heat/tests/test_template.py', 'heat/engine/hot/template.py', 'doc/source/template_guide/functions.rst', 'heat_integrationtests/functional/test_conditions.py']",7,54b47bd624434dd939bb6415850d5be95c13df8b,bp/support-conditions-function," zone: Type: String Default: beijing Conditions: Prod: {""Fn::Equals"": [{Ref: env_type}, ""prod""]} Beijing_Prod: {'Fn::And': [{""Fn::Equals"" : [{Ref: env_type}, ""prod""]}}, {""Fn::Equals"" : [{Ref: zone}, ""beijing""]}]} vol_attach_1: Type: OS::Cinder::VolumeAttachment Condition: Beijing_Prod Properties: instance_uuid: {Ref: test_server} volume_id: {Ref: my_volume} mountpoint: /dev/vdc my_volume_1: Type: OS::Cinder::Volume Condition: Beijing_Prod Properties: size: 2 Value: {'Fn::If': [Prod, {'Fn::GetAtt': [my_volume, status]}, 'error']} vol_1_status: Value: {'Fn::If': [Beijing_Prod, {'Fn::GetAtt': [my_volume_1, status]}, 'error']} zone: type: string default: beijing conditions: prod: {equals: [{get_param: env_type}, ""prod""]} test: {not: [{equals: [{get_param: env_type}, ""prod""]}]} beijing_prod: {and: [{equals: [{get_param: zone}, ""beijing""]}, {equals: [{get_param: env_type}, ""prod""]}]} vol_attach_1: type: OS::Cinder::VolumeAttachment condition: beijing_prod properties: instance_uuid: {get_resource: test_server} volume_id: {get_resource: my_volume} mountpoint: /dev/vdc my_volume_1: type: OS::Cinder::Volume condition: beijing_prod properties: size: 2 vol_1_status: value: {if: [beijing_prod, {get_attr: [my_volume_1, status]}, 'error']} def res_assert_for_prod(self, resources, bj_prod=True): if bj_prod: self.assertEqual(7, len(resources)) self.assertIn('vol_attach_1', res_names) self.assertIn('my_volume_1', res_names) else: self.assertEqual(5, len(resources)) def output_assert_for_prod(self, stack_id, bj_prod=True): vol_1_status = self.client.stacks.output_show( stack_id, 'vol_1_status')['output'] if bj_prod: self.assertEqual('in-use', vol_1_status['output_value']) else: self.assertEqual('error', vol_1_status['output_value']) vol_1_status = self.client.stacks.output_show( stack_id, 'vol_1_status')['output'] self.assertEqual('error', vol_1_status['output_value']) parms = {'flavor': self.conf.minimal_instance_type, 'image': self.conf.minimal_image_ref, 'env_type': 'prod', 'zone': 'shanghai'} self.update_stack(stack_identifier, template=cfn_template, parameters=parms) resources = self.client.resources.list(stack_identifier) self.res_assert_for_prod(resources, False) self.output_assert_for_prod(stack_identifier, False) parms = {'flavor': self.conf.minimal_instance_type, 'image': self.conf.minimal_image_ref, 'env_type': 'prod', 'zone': 'shanghai'} self.update_stack(stack_identifier, template=cfn_template, parameters=parms) resources = self.client.resources.list(stack_identifier) self.res_assert_for_prod(resources, False) self.output_assert_for_prod(stack_identifier, False) ","Conditions: Prod: {""Fn::Equals"" : [{Ref: env_type}, ""prod""]} Value: {""Fn::If"": [Prod, {""Fn::GetAtt"": [my_volume, status]}, 'error']}conditions: prod: {equals : [{get_param: env_type}, ""prod""]} test: {not: [{equals : [{get_param: env_type}, ""prod""]}]} def res_assert_for_prod(self, resources): self.assertEqual(5, len(resources)) def output_assert_for_prod(self, stack_id):",252,11
openstack%2Ftripleo-validations~master~I866211d516384713403bde4b5356782f3f1919a7,openstack/tripleo-validations,master,I866211d516384713403bde4b5356782f3f1919a7,Updated from global requirements,MERGED,2016-08-29 06:18:36.000000000,2016-08-29 11:39:00.000000000,2016-08-29 11:39:00.000000000,"[{'_account_id': 3}, {'_account_id': 13039}]","[{'number': 1, 'created': '2016-08-29 06:18:36.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/tripleo-validations/commit/28aca0ad29fec2d1a022e137039ae8f8c252b8c6', 'message': 'Updated from global requirements\n\nChange-Id: I866211d516384713403bde4b5356782f3f1919a7\n'}]",0,361877,28aca0ad29fec2d1a022e137039ae8f8c252b8c6,6,2,1,11131,,,0,"Updated from global requirements

Change-Id: I866211d516384713403bde4b5356782f3f1919a7
",git fetch https://review.opendev.org/openstack/tripleo-validations refs/changes/77/361877/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,28aca0ad29fec2d1a022e137039ae8f8c252b8c6,openstack/requirements,python-heatclient>=1.4.0 # Apache-2.0,python-heatclient>=1.1.0 # Apache-2.0,1,1
openstack%2Ftripleo-ci~master~I3e128573e72cd516e7b581a6fde3c412e76e43d8,openstack/tripleo-ci,master,I3e128573e72cd516e7b581a6fde3c412e76e43d8,Add temporary script to collect the status of periodic jobs,ABANDONED,2016-04-21 09:29:51.000000000,2016-08-29 11:36:36.000000000,,"[{'_account_id': 3}, {'_account_id': 1926}, {'_account_id': 4328}, {'_account_id': 6928}, {'_account_id': 7144}, {'_account_id': 10873}, {'_account_id': 11105}]","[{'number': 1, 'created': '2016-04-21 09:29:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/dd8645b8fb40b914b82153ff3cf85bf8a40e77ec', 'message': 'Add temporary script to collect the status of periodic jobs\n\nChange-Id: I3e128573e72cd516e7b581a6fde3c412e76e43d8\n'}, {'number': 2, 'created': '2016-05-24 09:19:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/ea1ac86755c27c63316519538d9ff3a9a1f36ea8', 'message': 'Add temporary script to collect the status of periodic jobs\n\nChange-Id: I3e128573e72cd516e7b581a6fde3c412e76e43d8\n'}, {'number': 3, 'created': '2016-05-31 12:00:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/f91e454f2e9bf1c435ccb0b9db4f9cad16c4e72e', 'message': 'Add temporary script to collect the status of periodic jobs\n\nChange-Id: I3e128573e72cd516e7b581a6fde3c412e76e43d8\n'}, {'number': 4, 'created': '2016-07-22 12:11:22.000000000', 'files': ['scripts/website/check-periodic-jobs.sh', 'scripts/website/generate_site.sh'], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/9539c9df683bdff9bfc96c89aba93b0e614630a9', 'message': 'Add temporary script to collect the status of periodic jobs\n\nChange-Id: I3e128573e72cd516e7b581a6fde3c412e76e43d8\n'}]",2,308865,9539c9df683bdff9bfc96c89aba93b0e614630a9,23,7,4,1926,,,0,"Add temporary script to collect the status of periodic jobs

Change-Id: I3e128573e72cd516e7b581a6fde3c412e76e43d8
",git fetch https://review.opendev.org/openstack/tripleo-ci refs/changes/65/308865/3 && git format-patch -1 --stdout FETCH_HEAD,"['scripts/website/check-periodic-jobs.sh', 'scripts/website/generate_site.sh']",2,dd8645b8fb40b914b82153ff3cf85bf8a40e77ec,308865, # Temporary replacemnt for periodic jobs ./tripleo-ci/scripts/website/check-periodic-jobs.sh > $SCRIPT_DIR/tripleo-docs/doc/build/html/periodic-status.txt,,39,0
openstack%2Ftripleo-common~master~I950b7d79581eba9d7f4cc85c93dda1af592ae625,openstack/tripleo-common,master,I950b7d79581eba9d7f4cc85c93dda1af592ae625,Clean yum metadata before installing the undercloud,ABANDONED,2015-11-03 17:41:03.000000000,2016-08-29 11:34:57.000000000,,"[{'_account_id': 3}, {'_account_id': 1926}, {'_account_id': 4328}, {'_account_id': 6796}, {'_account_id': 6928}, {'_account_id': 7144}, {'_account_id': 9712}, {'_account_id': 10873}]","[{'number': 1, 'created': '2015-11-03 17:41:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/73cc3b59a9be1d9f563dfb67bbe374c938f8a3ac', 'message': ""[WIP] Add undercloud update support\n\nThis currently works in that a stable/liberty undercloud can be\nupdated to master and we can still deploy an overcloud.\n\nNot much is actually updated though as tripleo is currently pinned\non a oldish centos/current-tripleo repo. I'm going to work on updatng\nthe pin so that we can properly test this.\n\nChange-Id: I950b7d79581eba9d7f4cc85c93dda1af592ae625\n""}, {'number': 2, 'created': '2015-11-11 14:51:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/dfafb2d5cbd6249baf411f331583b85e664df7e6', 'message': 'Add undercloud update support\n\nDepends-On: I1750e09de73aec3a5a0fe181808231ab68e25f69\nChange-Id: I950b7d79581eba9d7f4cc85c93dda1af592ae625\n'}, {'number': 3, 'created': '2015-11-11 16:47:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/07e25f75bc512c6591e70b6822e0bd230839134e', 'message': 'Clean yum metadata before installing the undercloud\n\nWe need to ensure old metadata is removed to enable\n--updercloud to do an upgrade(assuming --repo-setup has\nbeen used to reconfigure the repositories befor hand)\n\nDepends-On: I1750e09de73aec3a5a0fe181808231ab68e25f69\nChange-Id: I950b7d79581eba9d7f4cc85c93dda1af592ae625\n'}, {'number': 4, 'created': '2015-12-17 01:40:14.000000000', 'files': ['scripts/tripleo.sh'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/36870fce4756ce998d9b322b7c4ed98ca0ec9425', 'message': 'Clean yum metadata before installing the undercloud\n\nWe need to ensure old metadata is removed to enable\n--updercloud to do an upgrade(assuming --repo-setup has\nbeen used to reconfigure the repositories befor hand)\n\nDepends-On: I1750e09de73aec3a5a0fe181808231ab68e25f69\nChange-Id: I950b7d79581eba9d7f4cc85c93dda1af592ae625\n'}]",7,241312,36870fce4756ce998d9b322b7c4ed98ca0ec9425,29,8,4,1926,,,0,"Clean yum metadata before installing the undercloud

We need to ensure old metadata is removed to enable
--updercloud to do an upgrade(assuming --repo-setup has
been used to reconfigure the repositories befor hand)

Depends-On: I1750e09de73aec3a5a0fe181808231ab68e25f69
Change-Id: I950b7d79581eba9d7f4cc85c93dda1af592ae625
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/12/241312/3 && git format-patch -1 --stdout FETCH_HEAD,['scripts/tripleo.sh'],1,73cc3b59a9be1d9f563dfb67bbe374c938f8a3ac,stable_liberty," echo "" --undercloud-update -- Update a installed undercloud to master."" -l,help,repo-setup,delorean-setup,delorean-build,undercloud,undercloud-update,overcloud-images,register-nodes,introspect-nodes,flavors,overcloud-deploy,all \UNDERCLOUD_UPDATE=${UNDERCLOUD_UPDATE:-""""} --undercloud-update) UNDERCLOUD_UPDATE=""1""; shift 1;;function undercloud_update { log ""Undercloud update"" # We're not asserting specific values for $STABLE_RELEASE, ""repo_setup"" # will simply set up the most recent repositories that match it. So this # function can be used to update # from stable/X-1 to stable/X # from stable/X to a more recent stable/X # from stable/X to a master repo_setup sudo yum update -y log ""Undercloud install - DONE."" } if [ ""$UNDERCLOUD_UPDATE"" = 1 ]; then undercloud_update fi "," -l,help,repo-setup,delorean-setup,delorean-build,undercloud,overcloud-images,register-nodes,introspect-nodes,flavors,overcloud-deploy,all \",26,1
openstack%2Fpuppet-ec2api~master~I8a9c664b8de3f831efe5cf6890e51e8c9616941c,openstack/puppet-ec2api,master,I8a9c664b8de3f831efe5cf6890e51e8c9616941c,Fix authtoken,MERGED,2016-08-27 03:54:54.000000000,2016-08-29 11:33:24.000000000,2016-08-29 11:33:24.000000000,"[{'_account_id': 3}, {'_account_id': 7732}, {'_account_id': 7745}]","[{'number': 1, 'created': '2016-08-27 03:54:54.000000000', 'files': ['metadata.json', 'manifests/keystone/authtoken.pp'], 'web_link': 'https://opendev.org/openstack/puppet-ec2api/commit/7344155a5b3d8f84d16540cfa7a1c526af12e1c5', 'message': 'Fix authtoken\n\n- Fix doc in authtoken class\n- Fix metadata dependencies\n\nChange-Id: I8a9c664b8de3f831efe5cf6890e51e8c9616941c\n'}]",0,361550,7344155a5b3d8f84d16540cfa7a1c526af12e1c5,7,3,1,15519,,,0,"Fix authtoken

- Fix doc in authtoken class
- Fix metadata dependencies

Change-Id: I8a9c664b8de3f831efe5cf6890e51e8c9616941c
",git fetch https://review.opendev.org/openstack/puppet-ec2api refs/changes/50/361550/1 && git format-patch -1 --stdout FETCH_HEAD,"['metadata.json', 'manifests/keystone/authtoken.pp']",2,7344155a5b3d8f84d16540cfa7a1c526af12e1c5,fix_authtoken,"# (Optional) If true, explicitly allow TLS without checking server cert # against any certificate authorities. WARNING: not recommended. Use with # caution. # Defaults to $:os_service_default# (Optional) Config Section from which to load plugin specific options # Defaults to $::os_service_default.# (Optional) Authentication type to load # Defaults to 'password'# (Optional) Complete public Identity API endpoint. # Defaults to 'http://localhost:5000'# (Optional) API version of the admin Identity API endpoint. # Defaults to $::os_service_default.# (Optional) Env key for the swift cache. # Defaults to $::os_service_default.# (Optional) A PEM encoded Certificate Authority to use when verifying HTTPs # connections. # Defaults to $::os_service_default.# (Optional) Required if identity server requires client certificate # Defaults to $::os_service_default.# (Optional) If true, the revocation list will be checked for cached tokens. # This requires that PKI tokens are configured on the identity server. # boolean value. # Defaults to $::os_service_default.# (Optional) Do not handle authorization requests within the middleware, but # delegate the authorization decision to downstream WSGI components. Boolean # value # Defaults to $::os_service_default.# (Optional) Used to control the use and type of token binding. Can be set # to: ""disabled"" to not check token binding. ""permissive"" (default) to # validate binding information if the bind type is of a form known to the # server and ignore it if not. ""strict"" like ""permissive"" but if the bind # type is unknown the token will be rejected. ""required"" any form of token # binding is needed to be allowed. Finally the name of a binding method that # must be present in tokens. String value. # Defaults to $::os_service_default.# (Optional) Hash algorithms to use for hashing PKI tokens. This may be a # single algorithm or multiple. The algorithms are those supported by Python # standard hashlib.new(). The hashes will be tried in the order given, so put # the preferred one first for performance. The result of the first hash will # be stored in the cache. This will typically be set to multiple values only # while migrating from a less secure algorithm to a more secure one. Once all # the old tokens are expired this option should be set to a single value for # better performance. List value. # Defaults to $::os_service_default.# (Optional) Request timeout value for communicating with Identity API # server. # Defaults to $::os_service_default.# (Optional) How many times are we trying to reconnect when communicating # with Identity API Server. Integer value # Defaults to $::os_service_default.# (Optional) Indicate whether to set the X-Service-Catalog header. If False, # middleware will not ask for service catalog on token validation and will # not set the X-Service-Catalog header. Boolean value. # Defaults to $::os_service_default.# (Optional) Required if identity server requires client certificate # Defaults to $::os_service_default.# (Optional) Number of seconds that an operation will wait to get a memcached # client connection from the pool. Integer value # Defaults to $::os_service_default.# (Optional) Number of seconds memcached server is considered dead before it # is tried again. Integer value # Defaults to $::os_service_default.# (Optional) Maximum total number of open connections to every memcached # server. Integer value # Defaults to $::os_service_default.# (Optional) Number of seconds a connection to memcached is held unused in # the pool before it is closed. Integer value # Defaults to $::os_service_default.# (Optional) Number of seconds a connection to memcached is held unused in # the pool before it is closed. Integer value # Defaults to $::os_service_default.# (Optional, mandatory if memcache_security_strategy is defined) This string # is used for key derivation. # Defaults to $::os_service_default.# (Optional) If defined, indicate whether token data should be authenticated # or authenticated and encrypted. If MAC, token data is authenticated (with # HMAC) in the cache. If ENCRYPT, token data is encrypted and authenticated in the # cache. If the value is not one of these options or empty, auth_token will # raise an exception on initialization. # Defaults to $::os_service_default.# (Optional) Use the advanced (eventlet safe) memcached client pool. The # advanced pool will only work under python 2.x Boolean value # Defaults to $::os_service_default.# (Optional) Optionally specify a list of memcached server(s) to use for # caching. If left undefined, tokens will instead be cached in-process. # Defaults to $::os_service_default.# (Optional) The region in which the identity server can be found. # Defaults to $::os_service_default.# (Optional) Determines the frequency at which the list of revoked tokens is # retrieved from the Identity service (in seconds). A high number of # revocation events combined with a low cache duration may significantly # reduce performance. Only valid for PKI tokens. Integer value # Defaults to $::os_service_default.# (Optional) Directory used to cache files related to PKI tokens. # Defaults to $::os_service_default.# (Optional) In order to prevent excessive effort spent validating tokens, # the middleware caches previously-seen tokens for a configurable duration # (in seconds). Set to -1 to disable caching completely. Integer value # Defaults to $::os_service_default.","# (Optional) If true, explicitly allow TLS without checking server cert # against any certificate authorities. WARNING: not recommended. Use with # caution. # Defaults to $:os_service_default# (Optional) Config Section from which to load plugin specific options # Defaults to $::os_service_default.# (Optional) Authentication type to load # Defaults to 'password'# (Optional) Complete public Identity API endpoint. # Defaults to 'http://localhost:5000'# (Optional) API version of the admin Identity API endpoint. # Defaults to $::os_service_default.# (Optional) Env key for the swift cache. # Defaults to $::os_service_default.# (Optional) A PEM encoded Certificate Authority to use when verifying HTTPs # connections. # Defaults to $::os_service_default.# (Optional) Required if identity server requires client certificate # Defaults to $::os_service_default.# (Optional) If true, the revocation list will be checked for cached tokens. # This requires that PKI tokens are configured on the identity server. # boolean value. # Defaults to $::os_service_default.# (Optional) Do not handle authorization requests within the middleware, but # delegate the authorization decision to downstream WSGI components. Boolean # value # Defaults to $::os_service_default.# (Optional) Used to control the use and type of token binding. Can be set # to: ""disabled"" to not check token binding. ""permissive"" (default) to # validate binding information if the bind type is of a form known to the # server and ignore it if not. ""strict"" like ""permissive"" but if the bind # type is unknown the token will be rejected. ""required"" any form of token # binding is needed to be allowed. Finally the name of a binding method that # must be present in tokens. String value. # Defaults to $::os_service_default.# (Optional) Hash algorithms to use for hashing PKI tokens. This may be a # single algorithm or multiple. The algorithms are those supported by Python # standard hashlib.new(). The hashes will be tried in the order given, so put # the preferred one first for performance. The result of the first hash will # be stored in the cache. This will typically be set to multiple values only # while migrating from a less secure algorithm to a more secure one. Once all # the old tokens are expired this option should be set to a single value for # better performance. List value. # Defaults to $::os_service_default.# (Optional) Request timeout value for communicating with Identity API # server. # Defaults to $::os_service_default.# (Optional) How many times are we trying to reconnect when communicating # with Identity API Server. Integer value # Defaults to $::os_service_default.# (Optional) Indicate whether to set the X-Service-Catalog header. If False, # middleware will not ask for service catalog on token validation and will # not # set the X-Service-Catalog header. Boolean value. # Defaults to $::os_service_default.# (Optional) Required if identity server requires client certificate # Defaults to $::os_service_default.# (Optional) Number of seconds that an operation will wait to get a memcached # client connection from the pool. Integer value # Defaults to $::os_service_default.# (Optional) Number of seconds memcached server is considered dead before it # is tried again. Integer value # Defaults to $::os_service_default.# (Optional) Maximum total number of open connections to every memcached # server. Integer value # Defaults to $::os_service_default.# (Optional) Number of seconds a connection to memcached is held unused in # the # pool before it is closed. Integer value # Defaults to $::os_service_default.# (Optional) Number of seconds a connection to memcached is held unused in # the # pool before it is closed. Integer value # Defaults to $::os_service_default.# (Optional, mandatory if memcache_security_strategy is defined) This string # is used for key derivation. # Defaults to $::os_service_default.# (Optional) If defined, indicate whether token data should be authenticated # or # authenticated and encrypted. If MAC, token data is authenticated (with # HMAC) # in the cache. If ENCRYPT, token data is encrypted and authenticated in the # cache. If the value is not one of these options or empty, auth_token will # raise an exception on initialization. # Defaults to $::os_service_default.# (Optional) Use the advanced (eventlet safe) memcached client pool. The # advanced pool will only work under python 2.x Boolean value # Defaults to $::os_service_default.# (Optional) Optionally specify a list of memcached server(s) to use for # caching. If left undefined, tokens will instead be cached in-process. # Defaults to $::os_service_default.# (Optional) The region in which the identity server can be found. # Defaults to $::os_service_default.# (Optional) Determines the frequency at which the list of revoked tokens is # retrieved from the Identity service (in seconds). A high number of # revocation events combined with a low cache duration may significantly # reduce performance. Only valid for PKI tokens. Integer value # Defaults to $::os_service_default.# (Optional) Directory used to cache files related to PKI tokens. # Defaults to $::os_service_default.# (Optional) In order to prevent excessive effort spent validating tokens, # the middleware caches previously-seen tokens for a configurable duration # (in seconds). Set to -1 to disable caching completely. Integer value # Defaults to $::os_service_default.",101,106
openstack%2Ftripleo-ci~master~I40fb95248bf6ae31e5f55d7de28b59e280c970a7,openstack/tripleo-ci,master,I40fb95248bf6ae31e5f55d7de28b59e280c970a7,Stop destroying VM's that don't exist,ABANDONED,2016-05-05 08:49:13.000000000,2016-08-29 11:33:03.000000000,,"[{'_account_id': 3}, {'_account_id': 1926}, {'_account_id': 6928}, {'_account_id': 10873}, {'_account_id': 10969}, {'_account_id': 11105}]","[{'number': 1, 'created': '2016-05-05 08:49:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/e8c76b94502e9158a8adca96e440d0d894ea0513', 'message': ""Stop destroying VM's that don't exist\n\nOur testenvs each hold 10 VM's not 15 (as used to be the case long ago).\n\nChange-Id: I40fb95248bf6ae31e5f55d7de28b59e280c970a7\n""}, {'number': 2, 'created': '2016-06-20 11:10:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/ae48622f1bb0bc7a6bf0ac26f3e6ea6e66004609', 'message': ""Stop destroying VM's that don't exist\n\nOur testenvs each hold 10 VM's not 15 (as used to be the case long ago).\n\nChange-Id: I40fb95248bf6ae31e5f55d7de28b59e280c970a7\n""}, {'number': 3, 'created': '2016-06-20 22:55:03.000000000', 'files': ['toci_instack.sh'], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/da57902f21510fc015d6f03a3c3345a6649cec15', 'message': ""Stop destroying VM's that don't exist\n\nOur testenvs each hold 5 VM's not 15 (as used to be the case long ago).\n\nChange-Id: I40fb95248bf6ae31e5f55d7de28b59e280c970a7\n""}]",1,312863,da57902f21510fc015d6f03a3c3345a6649cec15,25,6,3,1926,,,0,"Stop destroying VM's that don't exist

Our testenvs each hold 5 VM's not 15 (as used to be the case long ago).

Change-Id: I40fb95248bf6ae31e5f55d7de28b59e280c970a7
",git fetch https://review.opendev.org/openstack/tripleo-ci refs/changes/63/312863/1 && git format-patch -1 --stdout FETCH_HEAD,['toci_instack.sh'],1,e8c76b94502e9158a8adca96e440d0d894ea0513,less-vm-killing, for i in $(seq 0 9) ; do, for i in $(seq 0 14) ; do,1,1
openstack%2Ftripleo-ci~master~I27ff140295d4b63630f861d87cdbe7b07fa5da78,openstack/tripleo-ci,master,I27ff140295d4b63630f861d87cdbe7b07fa5da78,Use mirrored puppet modules on rh2,ABANDONED,2016-07-07 07:05:59.000000000,2016-08-29 11:32:33.000000000,,"[{'_account_id': 3}, {'_account_id': 6928}, {'_account_id': 11105}]","[{'number': 1, 'created': '2016-07-07 07:05:59.000000000', 'files': ['toci_instack_ovb.sh', 'toci_instack.sh', 'scripts/common_functions.sh'], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/1dc31838e5404815d0540d8df8178ce36679e103', 'message': 'Use mirrored puppet modules on rh2\n\nThe non openstack puppet modules are mirrored on rh2\nas they were on rh1, lets use them.\n\nChange-Id: I27ff140295d4b63630f861d87cdbe7b07fa5da78\n'}]",0,338720,1dc31838e5404815d0540d8df8178ce36679e103,9,3,1,1926,,,0,"Use mirrored puppet modules on rh2

The non openstack puppet modules are mirrored on rh2
as they were on rh1, lets use them.

Change-Id: I27ff140295d4b63630f861d87cdbe7b07fa5da78
",git fetch https://review.opendev.org/openstack/tripleo-ci refs/changes/20/338720/1 && git format-patch -1 --stdout FETCH_HEAD,"['toci_instack_ovb.sh', 'toci_instack.sh', 'scripts/common_functions.sh']",3,1dc31838e5404815d0540d8df8178ce36679e103,,"function create_dib_vars_for_mirrored_puppet { # If running on either of the tripleo maintained cloud use the mirrored git repositories IFS=$'\n' # For the others we use local mirror server for REPO in $(cat $TRIPLEO_ROOT/tripleo-ci/scripts/mirror-server/mirrored.list | grep -v ""^#""); do RDIR=${REPO%% *} REPOLOCATION=http://$MIRRORSERVER/repos/$RDIR if curl -sf ${REPOLOCATION}/HEAD ; then echo ""export DIB_REPOLOCATION_$RDIR=$REPOLOCATION"" >> $TRIPLEO_ROOT/tripleo-ci/deploy.env fi done IFS=$' \t\n' } ",,16,10
openstack%2Fpython-aodhclient~master~Ib9a00d74c18412ad6dafa491d68224ebfc9a0b99,openstack/python-aodhclient,master,Ib9a00d74c18412ad6dafa491d68224ebfc9a0b99,Replace osc-lib with openstackclient,ABANDONED,2016-08-26 13:46:42.000000000,2016-08-29 11:27:03.000000000,,"[{'_account_id': 3}, {'_account_id': 6537}, {'_account_id': 22752}]","[{'number': 1, 'created': '2016-08-26 13:46:42.000000000', 'files': ['releasenotes/notes/osc-support-9f9dae2d2203f307.yaml', 'aodhclient/osc.py'], 'web_link': 'https://opendev.org/openstack/python-aodhclient/commit/ec36a15fcd9e0dfe3a809c46f67e27566a0ba4be', 'message': 'Replace osc-lib with openstackclient\n\nosc-lib is a package of common support modules for writing\nOSC plugins. All common functions, classes such as exceptions,\nutils, logs and so on have been moved from openstackclient to\nosc-lib. So use osc-lib instead of openstackclient.\n\nSince osc-lib 1.0.2 has released, it is stable to use.\n\nChange-Id: Ib9a00d74c18412ad6dafa491d68224ebfc9a0b99\n'}]",0,361190,ec36a15fcd9e0dfe3a809c46f67e27566a0ba4be,8,3,1,22752,,,0,"Replace osc-lib with openstackclient

osc-lib is a package of common support modules for writing
OSC plugins. All common functions, classes such as exceptions,
utils, logs and so on have been moved from openstackclient to
osc-lib. So use osc-lib instead of openstackclient.

Since osc-lib 1.0.2 has released, it is stable to use.

Change-Id: Ib9a00d74c18412ad6dafa491d68224ebfc9a0b99
",git fetch https://review.opendev.org/openstack/python-aodhclient refs/changes/90/361190/1 && git format-patch -1 --stdout FETCH_HEAD,"['aodhclient/osc.py', 'releasenotes/notes/osc-support-9f9dae2d2203f307.yaml']",2,ec36a15fcd9e0dfe3a809c46f67e27566a0ba4be,lhx/osc-lib, - Add support for using Aodh command with osc-lib instead of python-openstackclient., - Add support for using Aodh command with python-openstackclient.,2,2
openstack%2Fsenlin~master~I7fb2f92bf5bf5db2b5e2219704c11aa8a0f68fc7,openstack/senlin,master,I7fb2f92bf5bf5db2b5e2219704c11aa8a0f68fc7,Fix exception handling in node_recover,MERGED,2016-08-29 09:36:43.000000000,2016-08-29 11:25:46.000000000,2016-08-29 11:25:46.000000000,"[{'_account_id': 3}, {'_account_id': 8246}]","[{'number': 1, 'created': '2016-08-29 09:36:43.000000000', 'files': ['senlin/tests/unit/engine/test_node.py', 'senlin/common/exception.py', 'senlin/engine/node.py', 'senlin/profiles/base.py', 'senlin/tests/unit/profiles/test_profile_base.py'], 'web_link': 'https://opendev.org/openstack/senlin/commit/6affcb9b6760ca251163c750015c7f2bd73938d8', 'message': 'Fix exception handling in node_recover\n\nThe current node_recover logic (thus the profile do_recover) logic is\nnot raising/handling exceptions in a proper way. The type of exceptions\nraised should be concise and the handling should be concise too.\n\nThis patch removes the EResourceStatusError which was never raised\nanywhere in the code. It adds an EResourceOperation exception type to be\nraised (in a following patch) from the driver layer. The patch also\nremoves the useless _handle_exception() routine from the node module.\n\nChange-Id: I7fb2f92bf5bf5db2b5e2219704c11aa8a0f68fc7\n'}]",0,361967,6affcb9b6760ca251163c750015c7f2bd73938d8,6,2,1,8246,,,0,"Fix exception handling in node_recover

The current node_recover logic (thus the profile do_recover) logic is
not raising/handling exceptions in a proper way. The type of exceptions
raised should be concise and the handling should be concise too.

This patch removes the EResourceStatusError which was never raised
anywhere in the code. It adds an EResourceOperation exception type to be
raised (in a following patch) from the driver layer. The patch also
removes the useless _handle_exception() routine from the node module.

Change-Id: I7fb2f92bf5bf5db2b5e2219704c11aa8a0f68fc7
",git fetch https://review.opendev.org/openstack/senlin refs/changes/67/361967/1 && git format-patch -1 --stdout FETCH_HEAD,"['senlin/tests/unit/engine/test_node.py', 'senlin/common/exception.py', 'senlin/engine/node.py', 'senlin/profiles/base.py', 'senlin/tests/unit/profiles/test_profile_base.py']",5,6affcb9b6760ca251163c750015c7f2bd73938d8,health-policy-skip-actions," err = exception.EResourceDeletion(type='STACK', id='ID', message='BANG') self.patchobject(profile, 'do_delete', side_effect=err) ex = self.assertRaises(exception.EResourceOperation, profile.do_recover, mock.Mock(id='NODE_ID'), operation='RECREATE') self.assertEqual(""Failed in recovering node NODE_ID: "" ""Failed in deleting STACK ID: BANG."", six.text_type(ex)) err = exception.EResourceCreation(type='STACK', message='BANNG') self.patchobject(profile, 'do_create', side_effect=err) ex = self.assertRaises(exception.EResourceOperation, profile.do_recover, mock.Mock(id='NODE_ID'), operation='RECREATE') msg = (""Failed in recovering node NODE_ID: Failed in creating "" ""STACK: BANNG."") self.assertEqual(msg, six.text_type(ex))"," # Fail because do_delete not implemented self.assertRaises(NotImplementedError, profile.do_recover, mock.Mock(), operation='RECREATE') # Failed in do_delete self.patchobject(profile, 'do_delete', return_value=False) res = profile.do_recover(mock.Mock(), operation='RECREATE') self.assertFalse(res) # Failed because do_create is not implemented (weird case) res = profile.do_recover(mock.Mock(), operation='RECREATE') self.assertEqual(False, res) # Failed in do_create self.patchobject(profile, 'do_delete', return_value=True) self.patchobject(profile, 'do_create', return_value=False) res = profile.do_recover(mock.Mock(), operation='RECREATE') self.assertFalse(res) # Failed in do_create with exception self.patchobject(profile, 'do_create', side_effect=Exception) res = profile.do_recover(mock.Mock(), operation='RECREATE') self.assertFalse(res)",38,82
openstack%2Fsahara~master~Ib035a800d6ae151fbd42dba38fad57a46cf9f52d,openstack/sahara,master,Ib035a800d6ae151fbd42dba38fad57a46cf9f52d,delete unused LOG in some files,MERGED,2016-08-26 01:21:24.000000000,2016-08-29 11:25:40.000000000,2016-08-29 11:25:40.000000000,"[{'_account_id': 3}, {'_account_id': 7213}, {'_account_id': 10459}, {'_account_id': 12038}, {'_account_id': 19372}, {'_account_id': 21287}]","[{'number': 1, 'created': '2016-08-26 01:21:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/758dbdeabfe24b5fbb2efc0ed564e68070cc106c', 'message': 'delete unused LOG in some files\n\nremove unused log in config_helper.py,base.py\nnetwork.py,procutils.py and wsgi.py\n\nChange-Id: Ib035a800d6ae151fbd42dba38fad57a46cf9f52d\n'}, {'number': 2, 'created': '2016-08-26 08:31:09.000000000', 'files': ['sahara/utils/wsgi.py', 'sahara/plugins/storm/config_helper.py', 'sahara/utils/procutils.py', 'sahara/utils/network.py'], 'web_link': 'https://opendev.org/openstack/sahara/commit/75053af9508597f9f6129f0eceb677e3c2f19aa3', 'message': 'delete unused LOG in some files\n\nremove unused log in config_helper.py,base.py\nnetwork.py,procutils.py and wsgi.py\n\nChange-Id: Ib035a800d6ae151fbd42dba38fad57a46cf9f52d\n'}]",1,360840,75053af9508597f9f6129f0eceb677e3c2f19aa3,14,6,2,21387,,,0,"delete unused LOG in some files

remove unused log in config_helper.py,base.py
network.py,procutils.py and wsgi.py

Change-Id: Ib035a800d6ae151fbd42dba38fad57a46cf9f52d
",git fetch https://review.opendev.org/openstack/sahara refs/changes/40/360840/1 && git format-patch -1 --stdout FETCH_HEAD,"['sahara/utils/wsgi.py', 'sahara/tests/tempest/scenario/data_processing/client_tests/base.py', 'sahara/plugins/storm/config_helper.py', 'sahara/utils/procutils.py', 'sahara/utils/network.py']",5,758dbdeabfe24b5fbb2efc0ed564e68070cc106c,bugFix,,from oslo_log import log as logging LOG = logging.getLogger(__name__),0,13
openstack%2Fsahara~master~I897c06cdefafa5fb6570b0130078931b772e6338,openstack/sahara,master,I897c06cdefafa5fb6570b0130078931b772e6338,Fix wrong epel version for CentOS 7,MERGED,2016-08-22 18:13:03.000000000,2016-08-29 11:25:34.000000000,2016-08-29 11:25:34.000000000,"[{'_account_id': 3}, {'_account_id': 12038}, {'_account_id': 13953}, {'_account_id': 19372}, {'_account_id': 22689}]","[{'number': 1, 'created': '2016-08-22 18:13:03.000000000', 'files': ['sahara/plugins/mapr/resources/add_mapr_repo.sh'], 'web_link': 'https://opendev.org/openstack/sahara/commit/da70bca7b4fb9784e04e9f03d1d3a8bbff4a1111', 'message': 'Fix wrong epel version for CentOS 7\n\nWhen installing MapR into a cluster on CentOS 7, the plugin tries to\ndownload epel release version 7-5 from the url\nhttp://download.fedoraproject.org/pub/epel/7/x86_64/e/epel-release-7-5.noarch.rpm.\nThis release version is not available anymore and should be replaced\nwith epel-release-7-8 on the url rpm -i\nhttp://download.fedoraproject.org/pub/epel/7/x86_64/e/epel-release-7-8.noarch.rpm\n\nChange-Id: I897c06cdefafa5fb6570b0130078931b772e6338\nCloses-bug: #1615761\n'}]",0,358800,da70bca7b4fb9784e04e9f03d1d3a8bbff4a1111,10,5,1,8932,,,0,"Fix wrong epel version for CentOS 7

When installing MapR into a cluster on CentOS 7, the plugin tries to
download epel release version 7-5 from the url
http://download.fedoraproject.org/pub/epel/7/x86_64/e/epel-release-7-5.noarch.rpm.
This release version is not available anymore and should be replaced
with epel-release-7-8 on the url rpm -i
http://download.fedoraproject.org/pub/epel/7/x86_64/e/epel-release-7-8.noarch.rpm

Change-Id: I897c06cdefafa5fb6570b0130078931b772e6338
Closes-bug: #1615761
",git fetch https://review.opendev.org/openstack/sahara refs/changes/00/358800/1 && git format-patch -1 --stdout FETCH_HEAD,['sahara/plugins/mapr/resources/add_mapr_repo.sh'],1,da70bca7b4fb9784e04e9f03d1d3a8bbff4a1111,bug/1615761, rpm -q epel-release-7-8 || \ rpm -i http://download.fedoraproject.org/pub/epel/7/x86_64/e/epel-release-7-8.noarch.rpm, rpm -q epel-release-7-5 || \ rpm -i http://download.fedoraproject.org/pub/epel/7/x86_64/e/epel-release-7-5.noarch.rpm,2,2
openstack%2Fsahara~master~I637ae7800c25e610e9293ad764046df58d3d434a,openstack/sahara,master,I637ae7800c25e610e9293ad764046df58d3d434a,[doc] Fix some problems in docs,MERGED,2016-08-26 04:11:57.000000000,2016-08-29 11:25:22.000000000,2016-08-29 11:25:22.000000000,"[{'_account_id': 3}, {'_account_id': 12038}, {'_account_id': 19372}, {'_account_id': 22689}]","[{'number': 1, 'created': '2016-08-26 04:11:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/1ac5385cab78900812be4977efd86d5a121ee18f', 'message': '[doc] Fix some problems in docs\n\nAdd a specification to remind devstack user of changing the owner\nof sahara service in rootwrap script.\nThere are also some changes of devref docs.\n\nChange-Id: I637ae7800c25e610e9293ad764046df58d3d434a\n'}, {'number': 2, 'created': '2016-08-26 08:44:34.000000000', 'files': ['doc/source/devref/quickstart.rst', 'doc/source/userdoc/advanced.configuration.guide.rst'], 'web_link': 'https://opendev.org/openstack/sahara/commit/6427bc6715e8366f323eabfe2f984e81b81b5d86', 'message': '[doc] Fix some problems in docs\n\nAdd a specification to remind devstack user of changing the owner\nof sahara service in rootwrap script.\n\nChange-Id: I637ae7800c25e610e9293ad764046df58d3d434a\n'}]",4,360880,6427bc6715e8366f323eabfe2f984e81b81b5d86,12,4,2,22689,,,0,"[doc] Fix some problems in docs

Add a specification to remind devstack user of changing the owner
of sahara service in rootwrap script.

Change-Id: I637ae7800c25e610e9293ad764046df58d3d434a
",git fetch https://review.opendev.org/openstack/sahara refs/changes/80/360880/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/devref/development.environment.rst', 'doc/source/devref/quickstart.rst', 'doc/source/userdoc/advanced.configuration.guide.rst']",3,1ac5385cab78900812be4977efd86d5a121ee18f,doc-modify, access to the rootwrap script. Using devstack should pay attention to change the user ``sahara`` to ``stack``. It contains the following:, access to the rootwrap script. It contains the following:,4,3
openstack%2Fmanila~master~I36d59740b4e52005e6025e5df5989bf55d6bade4,openstack/manila,master,I36d59740b4e52005e6025e5df5989bf55d6bade4,Fix fallback share migration with empty files,MERGED,2016-08-16 13:53:15.000000000,2016-08-29 11:21:55.000000000,2016-08-19 22:14:55.000000000,"[{'_account_id': 3}, {'_account_id': 2417}, {'_account_id': 9003}, {'_account_id': 10621}, {'_account_id': 11047}, {'_account_id': 12017}, {'_account_id': 13144}, {'_account_id': 14384}, {'_account_id': 14567}, {'_account_id': 15942}, {'_account_id': 16203}, {'_account_id': 16643}, {'_account_id': 17565}, {'_account_id': 17623}, {'_account_id': 18128}, {'_account_id': 18752}, {'_account_id': 20695}, {'_account_id': 21884}, {'_account_id': 22236}, {'_account_id': 22248}]","[{'number': 1, 'created': '2016-08-16 13:53:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/d9d66cccb095b5b0a183c9d296bc811f3af33e9b', 'message': 'Fix fallback share migration with empty files\n\nFallback share migration fails with empty files. This patch fixes it\nby performing additional checks to address this specific scenario.\n\nChange-Id: I36d59740b4e52005e6025e5df5989bf55d6bade4\nCloses-bug: #1613713\n'}, {'number': 2, 'created': '2016-08-19 15:11:42.000000000', 'files': ['manila/tests/data/test_utils.py', 'releasenotes/notes/migration-empty-files-01d1a3caa2e9705e.yaml', 'manila/data/utils.py'], 'web_link': 'https://opendev.org/openstack/manila/commit/e4ddb090aede72b5a40cfaaa15bb2ff72d2a1e89', 'message': 'Fix fallback share migration with empty files\n\nFallback share migration fails with empty files. This patch fixes it\nby performing additional checks to address this specific scenario.\n\nChange-Id: I36d59740b4e52005e6025e5df5989bf55d6bade4\nCloses-bug: #1613713\n'}]",7,355946,e4ddb090aede72b5a40cfaaa15bb2ff72d2a1e89,59,20,2,14567,,,0,"Fix fallback share migration with empty files

Fallback share migration fails with empty files. This patch fixes it
by performing additional checks to address this specific scenario.

Change-Id: I36d59740b4e52005e6025e5df5989bf55d6bade4
Closes-bug: #1613713
",git fetch https://review.opendev.org/openstack/manila refs/changes/46/355946/2 && git format-patch -1 --stdout FETCH_HEAD,"['manila/tests/data/test_utils.py', 'releasenotes/notes/migration-empty-files-01d1a3caa2e9705e.yaml', 'manila/data/utils.py']",3,d9d66cccb095b5b0a183c9d296bc811f3af33e9b,migration," self.initialized = False self.completed = False # Empty share or empty contents if self.completed and self.total_size == 0: return {'total_progress': 100} if not self.initialized or self.current_copy is None: return {'total_progress': 0} # If share is not empty, there will be files total_progress = 0 if self.total_size > 0: if current_file_progress == 100: size = 0 total_progress = int((self.current_size + size) * 100 / self.total_size) self.initialized = True self.completed = True", total_progress = 0 if self.total_size > 0: total_progress = self.current_size * 100 / self.total_size else: return {'total_progress': 100},50,7
openstack%2Fkeystone~master~Ib31b3abf1705a0d64468aca536258e1ac971d2d9,openstack/keystone,master,Ib31b3abf1705a0d64468aca536258e1ac971d2d9,Remove import unused,ABANDONED,2016-08-29 07:01:05.000000000,2016-08-29 11:19:34.000000000,,"[{'_account_id': 3}, {'_account_id': 7725}]","[{'number': 1, 'created': '2016-08-29 07:01:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/7a77184caadb7d5c0d6552020bd14d569e98d57d', 'message': 'Remove import unused\n\nRemove import unused: absolute_import and print_function\n\nChange-Id: Ib31b3abf1705a0d64468aca536258e1ac971d2d9\n'}, {'number': 2, 'created': '2016-08-29 07:51:47.000000000', 'files': ['keystone/token/persistence/backends/kvs.py', 'keystone/token/providers/uuid.py', 'keystone/identity/backends/ldap/core.py', 'keystone/cmd/cli.py', 'keystone/oauth1/core.py', 'keystone/tests/unit/core.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/c3a6c5f2dba73a6e0b992b4a49a574530e3dfd44', 'message': 'Remove import unused\n\nRemove import unused: absolute_import and print_function\n\nChange-Id: Ib31b3abf1705a0d64468aca536258e1ac971d2d9\n'}]",0,361890,c3a6c5f2dba73a6e0b992b4a49a574530e3dfd44,5,2,2,22255,,,0,"Remove import unused

Remove import unused: absolute_import and print_function

Change-Id: Ib31b3abf1705a0d64468aca536258e1ac971d2d9
",git fetch https://review.opendev.org/openstack/keystone refs/changes/90/361890/1 && git format-patch -1 --stdout FETCH_HEAD,"['keystone/token/persistence/backends/kvs.py', 'keystone/token/providers/uuid.py', 'keystone/cmd/cli.py', 'keystone/identity/backends/ldap/core.py', 'keystone/oauth1/core.py', 'keystone/tests/unit/core.py']",6,7a77184caadb7d5c0d6552020bd14d569e98d57d,removeimport,,from __future__ import absolute_import,0,10
openstack%2Ffuel-library~master~I74e2ca95f31983d36ac8f17f3f5ee6c9f92c1ef0,openstack/fuel-library,master,I74e2ca95f31983d36ac8f17f3f5ee6c9f92c1ef0,Fix fuel-library package build,ABANDONED,2016-08-24 11:36:37.000000000,2016-08-29 11:05:27.000000000,,"[{'_account_id': 7227}, {'_account_id': 8971}, {'_account_id': 20656}]","[{'number': 1, 'created': '2016-08-24 11:36:37.000000000', 'files': ['files/fuel-utils/updates/update-master-node.sh'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/286c9a217362709e280bd52a19247a7c8cf783c9', 'message': 'Fix fuel-library package build\n\nCloses-Bug: #1605602\n\nChange-Id: I74e2ca95f31983d36ac8f17f3f5ee6c9f92c1ef0\n'}]",1,359813,286c9a217362709e280bd52a19247a7c8cf783c9,18,3,1,7732,,,0,"Fix fuel-library package build

Closes-Bug: #1605602

Change-Id: I74e2ca95f31983d36ac8f17f3f5ee6c9f92c1ef0
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/13/359813/1 && git format-patch -1 --stdout FETCH_HEAD,['files/fuel-utils/updates/update-master-node.sh'],1,286c9a217362709e280bd52a19247a7c8cf783c9,fix,"#!/bin/bash set -x [ -d '/var/log/puppet' ] || mkdir -p /var/log/puppet LOGFILE=${LOGFILE:-/var/log/puppet/update_master_node.log} exec > >(tee -i ""${LOGFILE}"") exec 2>&1 echo 'Master node update is in progress' yum clean all yum update -y bash -x /etc/puppet/modules/fuel/examples/deploy.sh SERVICES="" astute cobblerd mcollective nailgun nginx openstack-keystone ostf rabbitmq-server oswl_flavor_collectord oswl_image_collectord oswl_keystone_user_collectord oswl_tenant_collectord oswl_vm_collectord oswl_volume_collectord receiverd statsenderd assassind"" service postgresql restart sleep 32 for service in $SERVICES; do echo ""Restarting $service"" systemctl restart $service done ",,43,0
openstack%2Ftripleo-heat-templates~master~Idb0d55f99dbdd9d89881ce981d489756eb508fc0,openstack/tripleo-heat-templates,master,Idb0d55f99dbdd9d89881ce981d489756eb508fc0,Set the default gnocchi driver to swift,MERGED,2016-08-11 20:44:43.000000000,2016-08-29 11:04:32.000000000,2016-08-29 11:04:32.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 4328}, {'_account_id': 6796}, {'_account_id': 6924}, {'_account_id': 7144}]","[{'number': 1, 'created': '2016-08-11 20:44:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/dd244c28e3b9285f99575b200f7e344c83a1e913', 'message': 'Set the default gnocchi driver to swift\n\nUntil mitaka we have been using file driver. Swift is much more\nscalable so lets use that instead as the default.\n\nChange-Id: Idb0d55f99dbdd9d89881ce981d489756eb508fc0\n'}, {'number': 2, 'created': '2016-08-17 15:07:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/40eac244093284f67c53e15cdf3e838377e5ccd7', 'message': 'Set the default gnocchi driver to swift\n\nUntil mitaka we have been using file driver. Swift is much more\nscalable so lets use that instead as the default.\n\nChange-Id: Idb0d55f99dbdd9d89881ce981d489756eb508fc0\n'}, {'number': 3, 'created': '2016-08-18 18:55:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/78b56f1a112285227834cdb4f9e8df5605d260a4', 'message': 'Set the default gnocchi driver to rbd\n\nUntil mitaka we have been using file driver. Ceph is much more\nscalable so lets use that instead as the default.\n\nChange-Id: Idb0d55f99dbdd9d89881ce981d489756eb508fc0\n'}, {'number': 4, 'created': '2016-08-23 13:59:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/72efc71af5edfc46e02dcdff6b9ec3acc5180de9', 'message': 'Set the default gnocchi driver to swift\n\nUntil mitaka we have been using file driver. Swift is much more\nscalable so lets use that instead as the default.\n\nChange-Id: Idb0d55f99dbdd9d89881ce981d489756eb508fc0\n'}, {'number': 5, 'created': '2016-08-24 18:13:15.000000000', 'files': ['puppet/services/gnocchi-api.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/780750e881187024b0b2d120274333309aa50cb7', 'message': 'Set the default gnocchi driver to swift\n\nUntil mitaka we have been using file driver. Swift is much more\nscalable so lets use that instead as the default.\n\nChange-Id: Idb0d55f99dbdd9d89881ce981d489756eb508fc0\n'}]",1,354385,780750e881187024b0b2d120274333309aa50cb7,52,6,5,6924,,,0,"Set the default gnocchi driver to swift

Until mitaka we have been using file driver. Swift is much more
scalable so lets use that instead as the default.

Change-Id: Idb0d55f99dbdd9d89881ce981d489756eb508fc0
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/85/354385/5 && git format-patch -1 --stdout FETCH_HEAD,['puppet/services/gnocchi-base.yaml'],1,dd244c28e3b9285f99575b200f7e344c83a1e913,gnocchi-default-driver, default: swift, default: file,1,1
openstack%2Fneutron~master~Id434902e469700505fc55e09ba51207d9ce9ea71,openstack/neutron,master,Id434902e469700505fc55e09ba51207d9ce9ea71,Remove unused config.CONF,MERGED,2016-08-29 03:10:14.000000000,2016-08-29 11:02:47.000000000,2016-08-29 11:02:47.000000000,"[{'_account_id': 3}, {'_account_id': 5170}, {'_account_id': 6524}, {'_account_id': 8655}, {'_account_id': 9732}, {'_account_id': 11159}, {'_account_id': 14605}, {'_account_id': 14611}]","[{'number': 1, 'created': '2016-08-29 03:10:14.000000000', 'files': ['neutron/tests/tempest/api/test_allowed_address_pair.py', 'neutron/tests/tempest/api/test_extensions.py', 'neutron/tests/tempest/api/test_security_groups_negative.py', 'neutron/tests/tempest/api/test_networks.py', 'neutron/tests/tempest/api/test_network_ip_availability.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/e2196132f32e3a6438acbc9a89da91de7703638c', 'message': 'Remove unused config.CONF\n\nThis is to remove unused config.CONF to keep code clean.\n\nChange-Id: Id434902e469700505fc55e09ba51207d9ce9ea71\n'}]",0,361812,e2196132f32e3a6438acbc9a89da91de7703638c,17,8,1,20190,,,0,"Remove unused config.CONF

This is to remove unused config.CONF to keep code clean.

Change-Id: Id434902e469700505fc55e09ba51207d9ce9ea71
",git fetch https://review.opendev.org/openstack/neutron refs/changes/12/361812/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/tempest/api/test_allowed_address_pair.py', 'neutron/tests/tempest/api/test_extensions.py', 'neutron/tests/tempest/api/test_security_groups_negative.py', 'neutron/tests/tempest/api/test_networks.py', 'neutron/tests/tempest/api/test_network_ip_availability.py']",5,e2196132f32e3a6438acbc9a89da91de7703638c,remove_unuse_conf,,CONF = config.CONF ,0,13
openstack%2Fopenstack-doc-tools~master~I2f9605f8632f746cb16b0a8ee241f68a311e2855,openstack/openstack-doc-tools,master,I2f9605f8632f746cb16b0a8ee241f68a311e2855,Fix install-guide draft translated publishing,MERGED,2016-08-29 10:43:09.000000000,2016-08-29 11:00:59.000000000,2016-08-29 11:00:59.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 10497}]","[{'number': 1, 'created': '2016-08-29 10:43:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-doc-tools/commit/0c041ed6f4c240064ecac888d989eed776261bf6', 'message': 'Fix install-guide draft publishing\n\nUse a central TAGS variable for install-guide and use it everywhere. We\nmissed debian and debconf in one place and thus publish that translated\ncontent in the wrong place.\n\nDo the same change for first-app.\n\nChange-Id: I2f9605f8632f746cb16b0a8ee241f68a311e2855\n'}, {'number': 2, 'created': '2016-08-29 10:43:38.000000000', 'files': ['bin/doc-tools-check-languages'], 'web_link': 'https://opendev.org/openstack/openstack-doc-tools/commit/a9b18182238cf8b1f860de414a44d46ff8e69b2c', 'message': 'Fix install-guide draft translated publishing\n\nUse a central TAGS variable for install-guide and use it everywhere. We\nmissed debian and debconf in one place and thus publish that translated\ncontent in the wrong place.\n\nDo the same change for first-app.\n\nChange-Id: I2f9605f8632f746cb16b0a8ee241f68a311e2855\n'}]",0,362003,a9b18182238cf8b1f860de414a44d46ff8e69b2c,8,3,2,6547,,,0,"Fix install-guide draft translated publishing

Use a central TAGS variable for install-guide and use it everywhere. We
missed debian and debconf in one place and thus publish that translated
content in the wrong place.

Do the same change for first-app.

Change-Id: I2f9605f8632f746cb16b0a8ee241f68a311e2855
",git fetch https://review.opendev.org/openstack/openstack-doc-tools refs/changes/03/362003/2 && git format-patch -1 --stdout FETCH_HEAD,['bin/doc-tools-check-languages'],1,0c041ed6f4c240064ecac888d989eed776261bf6,fix-debian,"INSTALL_TAGS=""obs rdo ubuntu debian debconf"" FIRSTAPP_TAGS=""libcloud dotnet fog openstacksdk pkgcloud shade"" for tag in $FIRSTAPP_TAGS ; do for tag in $INSTALL_TAGS; do for tag in $FIRSTAPP_TAGS; do for tag in $INSTALL_TAGS ; do"," for tag in libcloud dotnet fog openstacksdk pkgcloud shade; do TAGS=""obs rdo ubuntu debian debconf"" for tag in $TAGS; do for tag in libcloud dotnet fog openstacksdk pkgcloud shade; do for tag in obs rdo ubuntu ; do",6,5
openstack%2Ffuel-library~stable%2Fmitaka~Iaa4855d769fe1e0203fcfb9981413273e0e4dda2,openstack/fuel-library,stable/mitaka,Iaa4855d769fe1e0203fcfb9981413273e0e4dda2,Detect a split-brain for Galera OCF RA,MERGED,2016-08-29 08:44:09.000000000,2016-08-29 10:48:32.000000000,2016-08-29 10:23:42.000000000,"[{'_account_id': 3}, {'_account_id': 6926}, {'_account_id': 7195}, {'_account_id': 8786}, {'_account_id': 8789}, {'_account_id': 8971}, {'_account_id': 9387}, {'_account_id': 14200}, {'_account_id': 14985}, {'_account_id': 16771}, {'_account_id': 18290}, {'_account_id': 20656}]","[{'number': 1, 'created': '2016-08-29 08:44:09.000000000', 'files': ['files/fuel-ha-utils/ocf/mysql-wss'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/3478e0d1c8b35191e35a59a0f8cfc3f59030959f', 'message': 'Detect a split-brain for Galera OCF RA\n\n* One and only seed node (the one with the wsrep-new-cluster) shall\n  be running, eventually.\n* For action monitor, check if the node is the seed one\n  and is running the most recent GTID, or fail\n\nCloses-bug: #1583173\n\nChange-Id: Iaa4855d769fe1e0203fcfb9981413273e0e4dda2\nSigned-off-by: Bogdan Dobrelya <bdobrelia@mirantis.com>\n(cherry picked from commit 8093431349441f6b486e45e8aab62e0a8927a8e2)\n'}]",0,361943,3478e0d1c8b35191e35a59a0f8cfc3f59030959f,35,12,1,11090,,,0,"Detect a split-brain for Galera OCF RA

* One and only seed node (the one with the wsrep-new-cluster) shall
  be running, eventually.
* For action monitor, check if the node is the seed one
  and is running the most recent GTID, or fail

Closes-bug: #1583173

Change-Id: Iaa4855d769fe1e0203fcfb9981413273e0e4dda2
Signed-off-by: Bogdan Dobrelya <bdobrelia@mirantis.com>
(cherry picked from commit 8093431349441f6b486e45e8aab62e0a8927a8e2)
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/43/361943/1 && git format-patch -1 --stdout FETCH_HEAD,['files/fuel-ha-utils/ocf/mysql-wss'],1,3478e0d1c8b35191e35a59a0f8cfc3f59030959f,bug/1583173,"#Get galera GTID from local mysql instance. #If changed, update it in CIB, then return 0 and new GTID #If unchanged or bad vlue, return 1 and the current GTID from CIB echo ""${GTID_current}"" return 1# Return 0 and the pid, if running a new cluster as a seed node check_if_new_cluster() { local pid # Match a mysqld pid by the datadir and a new cluster sign, exclude position recovery pid=$(ps -C mysqld -o pid= -o command= -o args= | \ grep -e ""${OCF_RESKEY_datadir}.*wsrep-new-cluster"" -e ""wsrep-new-cluster.*${OCF_RESKEY_datadir}"" | \ awk '!/wsrep.recover|defunct/ {print $1}') if [ ""${pid}"" ]; then echo ""${pid}"" exit 0 fi exit 1 } #Find the best master and return its GTID. #If the best master is this node, propose it as a prim, then return 1. #If another node is, check if *this* node is also running a new cluster and exit #with error for safety concerns local GTID local pid GTID=$(get_node_gtid $MASTER) ocf_log info ""${LH} I\'m Primary Component. Join me! My GTID: ${GTID}"" echo ""${GTID}"" ocf_log info ""${LH} My neighbour is Primary Component with GTID: ${GTID}"" pid=$(check_if_new_cluster) if [ ""${pid}"" ]; then ocf_log err ""${LH} But I'm running a new cluster, PID:${pid}, this is a split-brain!"" exit $OCF_ERR_GENERIC fi echo ""${GTID}"" local MGTID local GTID GTID=$(update_node_gtid) # Check if this node is the master and is running the most recent GTID MGTID=$(check_if_galera_pc) rc=$? if [ $rc -eq 1 -a ""${MGTID}"" != ""${GTID}"" ]; then ocf_log err ""${LH} I'm a master, and my GTID: ${GTID}, which was not expected"" return $OCF_ERR_GENERIC fi","#Get galera GTID from local mysql instance ocf_log info ""${LH} I\'m Primary Component. Join me!"" ocf_log info ""${LH} My neighbour is Primary Component"" update_node_gtid",45,4
openstack%2Fsenlin~master~I610d87195eec1cccf827292bdbd4e6582243d57c,openstack/senlin,master,I610d87195eec1cccf827292bdbd4e6582243d57c,Enable health policy to skip more actions,MERGED,2016-08-29 08:44:53.000000000,2016-08-29 10:46:35.000000000,2016-08-29 10:46:35.000000000,"[{'_account_id': 3}, {'_account_id': 8246}]","[{'number': 1, 'created': '2016-08-29 08:44:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/6d396e402f3ef0a98e30ed4dbd4da3815d5f6de4', 'message': 'Enable health policy to skip more actions\n\nThis patch enables the health policy to skip checkings when the action\nis CLUSTER_DEL_NODES or NODE_DELETE. These actions are supposed to be\nexecuted with interference from the health policy. In other words,\nthe health policy are tasked to handle only UNEXPECTED node failures.\n\nChange-Id: I610d87195eec1cccf827292bdbd4e6582243d57c\n'}, {'number': 2, 'created': '2016-08-29 09:36:43.000000000', 'files': ['senlin/policies/health_policy.py', 'senlin/tests/unit/policies/test_health_policy.py'], 'web_link': 'https://opendev.org/openstack/senlin/commit/e875c50851005d637b01c551f5c4f720b00afdaf', 'message': 'Enable health policy to skip more actions\n\nThis patch enables the health policy to skip checkings when the action\nis CLUSTER_DEL_NODES or NODE_DELETE. These actions are supposed to be\nexecuted with interference from the health policy. In other words,\nthe health policy are tasked to handle only UNEXPECTED node failures.\n\nChange-Id: I610d87195eec1cccf827292bdbd4e6582243d57c\n'}]",0,361944,e875c50851005d637b01c551f5c4f720b00afdaf,8,2,2,8246,,,0,"Enable health policy to skip more actions

This patch enables the health policy to skip checkings when the action
is CLUSTER_DEL_NODES or NODE_DELETE. These actions are supposed to be
executed with interference from the health policy. In other words,
the health policy are tasked to handle only UNEXPECTED node failures.

Change-Id: I610d87195eec1cccf827292bdbd4e6582243d57c
",git fetch https://review.opendev.org/openstack/senlin refs/changes/44/361944/2 && git format-patch -1 --stdout FETCH_HEAD,"['senlin/policies/health_policy.py', 'senlin/tests/unit/policies/test_health_policy.py']",2,6d396e402f3ef0a98e30ed4dbd4da3815d5f6de4,health-policy-skip-actions," def test_pre_op_cluster_del_nodes(self, mock_disable): action = mock.Mock(context='action_context', data={}, action=consts.CLUSTER_DEL_NODES) res = self.hp.pre_op(self.cluster.id, action) self.assertTrue(res) mock_disable.assert_called_once_with(self.cluster.id) @mock.patch.object(health_manager, 'disable') def test_pre_op_node_delete(self, mock_disable): action = mock.Mock(context='action_context', data={}, action=consts.NODE_DELETE) res = self.hp.pre_op(self.cluster.id, action) self.assertTrue(res) mock_disable.assert_called_once_with(self.cluster.id) @mock.patch.object(health_manager, 'disable') @mock.patch.object(health_manager, 'enable') def test_post_op_cluster_del_nodes(self, mock_enable): action = mock.Mock(action=consts.CLUSTER_DEL_NODES) res = self.hp.post_op(self.cluster.id, action) self.assertTrue(res) mock_enable.assert_called_once_with(self.cluster.id) @mock.patch.object(health_manager, 'enable') def test_post_op_node_delete(self, mock_enable): action = mock.Mock(action=consts.NODE_DELETE) res = self.hp.post_op(self.cluster.id, action) self.assertTrue(res) mock_enable.assert_called_once_with(self.cluster.id)",,48,2
openstack%2Ffuel-ui~master~I717716cc4eb03b1a0524ec4cc1bb82f6e90fb59c,openstack/fuel-ui,master,I717716cc4eb03b1a0524ec4cc1bb82f6e90fb59c,Animation for time marker,ABANDONED,2016-08-02 14:56:05.000000000,2016-08-29 10:45:07.000000000,,"[{'_account_id': 3}, {'_account_id': 8735}, {'_account_id': 8766}, {'_account_id': 8970}, {'_account_id': 8971}, {'_account_id': 9730}, {'_account_id': 15315}, {'_account_id': 20656}]","[{'number': 1, 'created': '2016-08-02 14:56:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-ui/commit/db62a5aac505f01d4b62b763062f3adfccfa9d87', 'message': 'Animation for time market\n\nChange-Id: I717716cc4eb03b1a0524ec4cc1bb82f6e90fb59c\n'}, {'number': 2, 'created': '2016-08-02 15:00:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-ui/commit/d88ecdbd9484bde85c2306d9f28b091d89aa7a38', 'message': 'Animation for time marker\n\nChange-Id: I717716cc4eb03b1a0524ec4cc1bb82f6e90fb59c\n'}, {'number': 3, 'created': '2016-08-16 14:37:44.000000000', 'files': ['static/styles/main.less'], 'web_link': 'https://opendev.org/openstack/fuel-ui/commit/5973314fb49deefe32ab243fc30082aa2c54845d', 'message': 'Animation for time marker\n\nImplements blueprint ui-deployment-history\n\nChange-Id: I717716cc4eb03b1a0524ec4cc1bb82f6e90fb59c\n'}]",0,350076,5973314fb49deefe32ab243fc30082aa2c54845d,23,8,3,8970,,,0,"Animation for time marker

Implements blueprint ui-deployment-history

Change-Id: I717716cc4eb03b1a0524ec4cc1bb82f6e90fb59c
",git fetch https://review.opendev.org/openstack/fuel-ui refs/changes/76/350076/3 && git format-patch -1 --stdout FETCH_HEAD,['static/styles/main.less'],1,db62a5aac505f01d4b62b763062f3adfccfa9d87,bp/ui-deployment-history, transition: all .2s ease-in-out; transition: all .2s ease-in-out;,,2,0
openstack%2Ffuel-qa~stable%2F7.0~Ie419ba35fc6d4647ca8ddc3b72c4009b7ba1840a,openstack/fuel-qa,stable/7.0,Ie419ba35fc6d4647ca8ddc3b72c4009b7ba1840a,Sync requirements.txt with OS global requirements,MERGED,2016-08-08 10:44:40.000000000,2016-08-29 10:43:20.000000000,2016-08-29 10:43:20.000000000,"[{'_account_id': 3}, {'_account_id': 7126}, {'_account_id': 8971}, {'_account_id': 11081}, {'_account_id': 15984}, {'_account_id': 16106}, {'_account_id': 19119}]","[{'number': 1, 'created': '2016-08-08 10:44:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/34110f7a21336458c8d436e6e77be683d742a082', 'message': 'Sync requirements.txt with OS global requirements\n\nChange-Id: Ie419ba35fc6d4647ca8ddc3b72c4009b7ba1840a\n'}, {'number': 2, 'created': '2016-08-08 11:02:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/47433a6903076a96c7db13cc72d3a5ce138e97dd', 'message': 'Sync requirements.txt with OS global requirements\n\nChange-Id: Ie419ba35fc6d4647ca8ddc3b72c4009b7ba1840a\n'}, {'number': 3, 'created': '2016-08-22 11:31:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/4dd12b128c4373d98f51b682601f710251df2aef', 'message': 'Sync requirements.txt with OS global requirements\n\nChange-Id: Ie419ba35fc6d4647ca8ddc3b72c4009b7ba1840a\n'}, {'number': 4, 'created': '2016-08-22 12:43:17.000000000', 'files': ['fuelweb_test/requirements.txt'], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/f43bbf6c7be7e0ab94bf4f1e5fbfad7f5629a8af', 'message': 'Sync requirements.txt with OS global requirements\n\nChange-Id: Ie419ba35fc6d4647ca8ddc3b72c4009b7ba1840a\n'}]",1,352327,f43bbf6c7be7e0ab94bf4f1e5fbfad7f5629a8af,31,7,4,15984,,,0,"Sync requirements.txt with OS global requirements

Change-Id: Ie419ba35fc6d4647ca8ddc3b72c4009b7ba1840a
",git fetch https://review.opendev.org/openstack/fuel-qa refs/changes/27/352327/4 && git format-patch -1 --stdout FETCH_HEAD,['fuelweb_test/requirements.txt'],1,34110f7a21336458c8d436e6e77be683d742a082,,"python-glanceclient>=0.15.0,<0.18.0 python-keystoneclient>=1.2.0,<1.4.0 python-novaclient>=2.22.0,<2.24.0 python-cinderclient>=1.1.0,<1.2.0 python-neutronclient>=2.22.0,<2.24.0 python-heatclient>=0.3.0,<0.5.0 oslo.i18n>=1.5.0,<1.6.0",python-glanceclient==0.19.0 python-keystoneclient>=1.6.0 python-novaclient>=2.26.0 python-cinderclient>=1.2.2 python-neutronclient>=2.6.0 python-heatclient>=0.6.0,7,6
openstack%2Fpython-neutronclient~master~I7634d205430ce01de28ac1ecf571696d84d865d3,openstack/python-neutronclient,master,I7634d205430ce01de28ac1ecf571696d84d865d3,"Fix the problem of ""qos-dscp-marking-rule-show""",MERGED,2016-06-15 09:59:37.000000000,2016-08-29 10:42:56.000000000,2016-08-29 10:42:56.000000000,"[{'_account_id': 3}, {'_account_id': 841}, {'_account_id': 6854}, {'_account_id': 7244}, {'_account_id': 7448}, {'_account_id': 9656}, {'_account_id': 13995}, {'_account_id': 14605}, {'_account_id': 16688}, {'_account_id': 17711}, {'_account_id': 17776}, {'_account_id': 20082}, {'_account_id': 20251}]","[{'number': 1, 'created': '2016-06-15 09:59:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/440b330dcd18f908e8d61ff8f3f6fc74463d1d0c', 'message': 'Fix the problem of ""qos-dscp-marking-rule-show""\n\nAdd a arg ""**_params"" in show_dscp_marking_rule() to use the\n""-F"" option.\n\nChange-Id: I7634d205430ce01de28ac1ecf571696d84d865d3\nPartial-Bug: #1587291\n'}, {'number': 2, 'created': '2016-06-21 01:48:46.000000000', 'files': ['neutronclient/tests/unit/qos/test_cli20_dscp_marking_rule.py', 'neutronclient/v2_0/client.py'], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/c5c705120a3e9d45e9d868f728531316029284a7', 'message': 'Fix the problem of ""qos-dscp-marking-rule-show""\n\nAdd an arg ""**_params"" in show_dscp_marking_rule() to use the\n""-F"" option.\n\nChange-Id: I7634d205430ce01de28ac1ecf571696d84d865d3\nPartial-Bug: #1587291\n'}]",1,329852,c5c705120a3e9d45e9d868f728531316029284a7,18,13,2,20254,,,0,"Fix the problem of ""qos-dscp-marking-rule-show""

Add an arg ""**_params"" in show_dscp_marking_rule() to use the
""-F"" option.

Change-Id: I7634d205430ce01de28ac1ecf571696d84d865d3
Partial-Bug: #1587291
",git fetch https://review.opendev.org/openstack/python-neutronclient refs/changes/52/329852/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutronclient/tests/unit/qos/test_cli20_dscp_marking_rule.py', 'neutronclient/v2_0/client.py']",2,440b330dcd18f908e8d61ff8f3f6fc74463d1d0c,bug/1587291," def show_dscp_marking_rule(self, rule, policy, **_params): (policy, rule), params=_params)"," def show_dscp_marking_rule(self, rule, policy, body=None): (policy, rule), body=body)",4,4
openstack%2Fironic~master~I13298cf6f1939f1bf67342a826c26f50f18123f4,openstack/ironic,master,I13298cf6f1939f1bf67342a826c26f50f18123f4,Updated from global requirements,MERGED,2016-08-26 05:08:22.000000000,2016-08-29 10:41:22.000000000,2016-08-29 10:41:22.000000000,"[{'_account_id': 3}, {'_account_id': 10118}, {'_account_id': 10239}, {'_account_id': 12356}, {'_account_id': 14525}, {'_account_id': 14629}, {'_account_id': 14760}, {'_account_id': 17998}, {'_account_id': 19339}, {'_account_id': 20311}]","[{'number': 1, 'created': '2016-08-26 05:08:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/f1d6cdb8d6eb0726b6f818e74bc1f373580fe6e5', 'message': 'Updated from global requirements\n\nChange-Id: I13298cf6f1939f1bf67342a826c26f50f18123f4\n'}, {'number': 2, 'created': '2016-08-26 09:11:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/897a6ef167f8d9f4f048dd01e713118c6cfe02fd', 'message': 'Updated from global requirements\n\nChange-Id: I13298cf6f1939f1bf67342a826c26f50f18123f4\n'}, {'number': 3, 'created': '2016-08-26 22:06:58.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/ironic/commit/a5cec645b3db4df729a3fef77d0ed39c5b54c1ce', 'message': 'Updated from global requirements\n\nChange-Id: I13298cf6f1939f1bf67342a826c26f50f18123f4\n'}]",0,360889,a5cec645b3db4df729a3fef77d0ed39c5b54c1ce,22,10,3,11131,,,0,"Updated from global requirements

Change-Id: I13298cf6f1939f1bf67342a826c26f50f18123f4
",git fetch https://review.opendev.org/openstack/ironic refs/changes/89/360889/2 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,f1d6cdb8d6eb0726b6f818e74bc1f373580fe6e5,openstack/requirements,"hacking<0.12,>=0.11.0 # Apache-2.0","hacking>=0.11.0,<0.12 # Apache-2.0",1,1
openstack%2Fpuppet-magnum~master~I4a69bd72e6114e287520548587a14ac0e44b1e84,openstack/puppet-magnum,master,I4a69bd72e6114e287520548587a14ac0e44b1e84,Move magnum to authtoken,MERGED,2016-08-06 04:17:27.000000000,2016-08-29 10:40:48.000000000,2016-08-29 10:40:48.000000000,"[{'_account_id': 3}, {'_account_id': 1607}, {'_account_id': 3153}, {'_account_id': 7732}, {'_account_id': 7745}, {'_account_id': 14985}, {'_account_id': 15519}, {'_account_id': 21515}, {'_account_id': 22493}]","[{'number': 1, 'created': '2016-08-06 04:17:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-magnum/commit/7441aa89ea57f4e0adb5ac8cbbc9ee4ddb6473ce', 'message': ""Add itesm fo keystone_authtoken\n\nNow intalling magnum with packstack, magnum can't work normally,\nthere is some exception about authentication.\nI add some items for keystone_authtoken in the file 'magnum.conf'.\nThe items is added according to magnum's installing in devstack.\nWith this modification, after installing magnum with packstack,\nmagnum work succussfully.\n\nChange-Id: I4a69bd72e6114e287520548587a14ac0e44b1e84\n""}, {'number': 2, 'created': '2016-08-06 05:25:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-magnum/commit/eef98a6ec6bb742b6b659d3cfa0aab524ae7ddd2', 'message': ""Add itesm fo keystone_authtoken\n\nNow intalling magnum with packstack, magnum can't work normally,\nthere is some exception about authentication.\nI add some items for keystone_authtoken in the file 'magnum.conf'.\nThe items is added according to magnum's installing in devstack.\nWith this modification, after installing magnum with packstack,\nmagnum work succussfully.\n\nChange-Id: I4a69bd72e6114e287520548587a14ac0e44b1e84\n""}, {'number': 3, 'created': '2016-08-09 05:31:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-magnum/commit/0e04bd7a415eb7b92aff064e80aa2978ada25c35', 'message': ""Add itesm for keystone_authtoken using keystone::resource::authtoken\n\nNow intalling magnum with packstack, magnum can't work normally,\nthere is some exception about authentication.\nI add some items for keystone_authtoken in the file 'magnum.conf'.\nThe items is added according to magnum's installing in devstack.\nWith this modification, after installing magnum with packstack,\nmagnum work succussfully.\nI put all keystone_authtoken items into file keystone/authtoken.pp.\n\nChange-Id: I4a69bd72e6114e287520548587a14ac0e44b1e84\n""}, {'number': 4, 'created': '2016-08-09 06:30:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-magnum/commit/7baf04490b32855afade3895d6f6ef138ee0f499', 'message': ""Add itesm for keystone_authtoken using keystone::resource::authtoken\n\nNow intalling magnum with packstack, magnum can't work normally,\nthere is some exception about authentication.\nI add some items for keystone_authtoken in the file 'magnum.conf'.\nThe items is added according to magnum's installing in devstack.\nWith this modification, after installing magnum with packstack,\nmagnum work succussfully.\nI put all keystone_authtoken items into file keystone/authtoken.pp.\n\nChange-Id: I4a69bd72e6114e287520548587a14ac0e44b1e84\n""}, {'number': 5, 'created': '2016-08-12 07:03:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-magnum/commit/7a3dee64279ad98850dac4ac432a53890e030120', 'message': ""Add itesm for keystone_authtoken using class keystone::resource::authtoken\n\nNow intalling magnum with packstack, magnum can't work normally,\nthere is some exception about authentication.\nI add some items for keystone_authtoken in the file 'magnum.conf'.\nThe items is added according to magnum's installing in devstack.\nWith this modification, after installing magnum with packstack,\nmagnum work succussfully.\nI put all keystone_authtoken items into file keystone/authtoken.pp.\n\nChange-Id: I4a69bd72e6114e287520548587a14ac0e44b1e84\n""}, {'number': 6, 'created': '2016-08-12 09:50:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-magnum/commit/02fa7a8cfc11a38d0d66d6b1a89d2e1e21a017db', 'message': ""Add itesm for keystone_authtoken using class keystone::resource::authtoken\n\nNow intalling magnum with packstack, magnum can't work normally,\nthere is some exception about authentication.\nI add some items for keystone_authtoken in the file 'magnum.conf'.\nThe items is added according to magnum's installing in devstack.\nWith this modification, after installing magnum with packstack,\nmagnum work succussfully.\nI put all keystone_authtoken items into file keystone/authtoken.pp.\n\nChange-Id: I4a69bd72e6114e287520548587a14ac0e44b1e84\n""}, {'number': 7, 'created': '2016-08-12 11:27:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-magnum/commit/cb16279d8288284e635a88a13128a33dc43ce07f', 'message': ""Add itesm for keystone_authtoken using class keystone::resource::authtoken\n\nNow intalling magnum with packstack, magnum can't work normally,\nthere is some exception about authentication.\nI add some items for keystone_authtoken in the file 'magnum.conf'.\nThe items is added according to magnum's installing in devstack.\nWith this modification, after installing magnum with packstack,\nmagnum work succussfully.\nI put all keystone_authtoken items into file keystone/authtoken.pp.\n\nChange-Id: I4a69bd72e6114e287520548587a14ac0e44b1e84\n""}, {'number': 8, 'created': '2016-08-17 02:47:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-magnum/commit/bb96660d1be20532b00ff82302aad8ac3abdbbbd', 'message': ""Add itesm for keystone_authtoken using class keystone::resource::authtoken\n\nNow intalling magnum with packstack, magnum can't work normally,\nthere is some exception about authentication.\nI add some items for keystone_authtoken in the file 'magnum.conf'.\nThe items is added according to magnum's installing in devstack.\nWith this modification, after installing magnum with packstack,\nmagnum work succussfully.\nI put all keystone_authtoken items into file keystone/authtoken.pp.\n\nChange-Id: I4a69bd72e6114e287520548587a14ac0e44b1e84\n""}, {'number': 9, 'created': '2016-08-25 04:20:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-magnum/commit/1a9d06ed038cbcc78dd4b9780f9123dae093f25a', 'message': ""Add itesm for keystone_authtoken using class keystone::resource::authtoken\n\nNow intalling magnum with packstack, magnum can't work normally,\nthere is some exception about authentication.\nI add some items for keystone_authtoken in the file 'magnum.conf'.\nThe items is added according to magnum's installing in devstack.\nWith this modification, after installing magnum with packstack,\nmagnum work succussfully.\nI put all keystone_authtoken items into file keystone/authtoken.pp.\n\nChange-Id: I4a69bd72e6114e287520548587a14ac0e44b1e84\n""}, {'number': 10, 'created': '2016-08-25 14:50:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-magnum/commit/19e7187cc2336fc04a306135430b72fb118a676b', 'message': ""Add itesm for keystone_authtoken using class keystone::resource::authtoken\n\nNow intalling magnum with packstack, magnum can't work normally,\nthere is some exception about authentication.\nI add some items for keystone_authtoken in the file 'magnum.conf'.\nThe items is added according to magnum's installing in devstack.\nWith this modification, after installing magnum with packstack,\nmagnum work succussfully.\nI put all keystone_authtoken items into file keystone/authtoken.pp.\n\nChange-Id: I4a69bd72e6114e287520548587a14ac0e44b1e84\nCloses-Bug: #1604463\n""}, {'number': 11, 'created': '2016-08-25 14:53:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-magnum/commit/c70588ac4a37bb35d8adffc8bbe4943d0fd75c05', 'message': ""Move magnum to authtoken\n\nNow intalling magnum with packstack, magnum can't work normally,\nthere is some exception about authentication.\nI add some items for keystone_authtoken in the file 'magnum.conf'.\nThe items is added according to magnum's installing in devstack.\nWith this modification, after installing magnum with packstack,\nmagnum work succussfully.\nI put all keystone_authtoken items into file keystone/authtoken.pp.\n\nChange-Id: I4a69bd72e6114e287520548587a14ac0e44b1e84\nCloses-Bug: #1604463\n""}, {'number': 12, 'created': '2016-08-26 19:20:38.000000000', 'files': ['spec/acceptance/basic_magnum_spec.rb', 'spec/classes/magnum_keystone_authtoken_spec.rb', 'manifests/api.pp', 'examples/magnum.pp', 'spec/classes/magnum_api_spec.rb', 'manifests/keystone/authtoken.pp'], 'web_link': 'https://opendev.org/openstack/puppet-magnum/commit/987e53f94d5de2868a3e1b02108a6a8dd72c81b8', 'message': 'Move magnum to authtoken\n\nAllow magnum to configure the keystone_authtoken section in\nmagnum.conf with all new parameters from Keystone Middleware\nusing the  keystone::resource::authtoken from puppet-keystone\nThis will also add support to authentication using Keystone v3.\n\nChange-Id: I4a69bd72e6114e287520548587a14ac0e44b1e84\nCloses-Bug: #1604463\n'}]",16,351980,987e53f94d5de2868a3e1b02108a6a8dd72c81b8,47,9,12,22493,,,0,"Move magnum to authtoken

Allow magnum to configure the keystone_authtoken section in
magnum.conf with all new parameters from Keystone Middleware
using the  keystone::resource::authtoken from puppet-keystone
This will also add support to authentication using Keystone v3.

Change-Id: I4a69bd72e6114e287520548587a14ac0e44b1e84
Closes-Bug: #1604463
",git fetch https://review.opendev.org/openstack/puppet-magnum refs/changes/80/351980/1 && git format-patch -1 --stdout FETCH_HEAD,['manifests/api.pp'],1,7441aa89ea57f4e0adb5ac8cbbc9ee4ddb6473ce,add_keystone_authtoken,"# [*memcached_servers*] # (Optional)Optionally specify a list of memcached server(s) to use for caching. If left # undefined, tokens will instead be cached in-process. # # [*project_domain_id*] # (Optional)Domain ID containing project # # [*project_name*] # (Optional)Project name to scope to # # [*user_domain_id*] # (Optional)User's domain id # # [*password*] # (Optional)User's password # # [*username*] # (Optional)User's name # # [*auth_url*] # (Optional)Authentication URL # # [*auth_type*] # (Optional)Authentication type to load $memcached_servers = '0.0.0.0:11211', $project_domain_id = 'default', $project_name = 'admin', $user_domain_id = 'default', $password = 'magnum', $username = 'magnum', $auth_url = 'http://127.0.0.1:35357', $auth_type = 'password', 'keystone_authtoken/memcached_servers' : value => $memcached_servers; 'keystone_authtoken/project_domain_id' : value => $project_domain_id; 'keystone_authtoken/project_name' : value => $project_name; 'keystone_authtoken/user_domain_id' : value => $user_domain_id; 'keystone_authtoken/password' : value => $password; 'keystone_authtoken/username' : value => $username; 'keystone_authtoken/auth_url' : value => $auth_url; 'keystone_authtoken/auth_type' : value => $auth_type;"," 'keystone_authtoken/identity_uri' : value => $identity_uri; 'keystone_authtoken/admin_tenant_name' : value => $admin_tenant_name; 'keystone_authtoken/admin_user' : value => $admin_user; 'keystone_authtoken/admin_password' : value => $admin_password, secret => true;",40,4
openstack%2Fdeb-auto-backports~debian%2Fnewton~I9c2b189ed9934545cfe456fa6c902ecd811304b5,openstack/deb-auto-backports,debian/newton,I9c2b189ed9934545cfe456fa6c902ecd811304b5,Do not build git-buildpackage again,MERGED,2016-08-29 10:00:01.000000000,2016-08-29 10:40:23.000000000,2016-08-29 10:40:23.000000000,"[{'_account_id': 3}, {'_account_id': 12841}]","[{'number': 1, 'created': '2016-08-29 10:00:01.000000000', 'files': ['packages-list'], 'web_link': 'https://opendev.org/openstack/deb-auto-backports/commit/95c9b3d19d58f7476385d49439a1e98546375649', 'message': 'Do not build git-buildpackage again\n\nChange-Id: I9c2b189ed9934545cfe456fa6c902ecd811304b5\n'}]",0,361980,95c9b3d19d58f7476385d49439a1e98546375649,6,2,1,6476,,,0,"Do not build git-buildpackage again

Change-Id: I9c2b189ed9934545cfe456fa6c902ecd811304b5
",git fetch https://review.opendev.org/openstack/deb-auto-backports refs/changes/80/361980/1 && git format-patch -1 --stdout FETCH_HEAD,['packages-list'],1,95c9b3d19d58f7476385d49439a1e98546375649,,"#git-buildpackage <- Already in the archive, creates errors in reprepro",git-buildpackage,1,1
openstack%2Freleases~master~I8bca376d910c218b65a29d2e400fd519348f73b9,openstack/releases,master,I8bca376d910c218b65a29d2e400fd519348f73b9,replace summit weeks with trailing weeks,MERGED,2016-08-18 13:24:57.000000000,2016-08-29 10:39:00.000000000,2016-08-29 10:39:00.000000000,"[{'_account_id': 3}, {'_account_id': 308}, {'_account_id': 3153}, {'_account_id': 5638}, {'_account_id': 11105}, {'_account_id': 12898}, {'_account_id': 22970}]","[{'number': 1, 'created': '2016-08-18 13:24:57.000000000', 'files': ['tools/list_weeks.py'], 'web_link': 'https://opendev.org/openstack/releases/commit/8a3e97707dfa9ad137d557c5341102b71697b8fb', 'message': ""replace summit weeks with trailing weeks\n\nThe release schedule is no longer bounded by the summit, so don't\ninclude it.\n\nAdd 2 weeks for the cycle-trailing deadline.\n\nChange-Id: I8bca376d910c218b65a29d2e400fd519348f73b9\nSigned-off-by: Doug Hellmann <doug@doughellmann.com>\n""}]",0,357213,8a3e97707dfa9ad137d557c5341102b71697b8fb,12,7,1,2472,,,0,"replace summit weeks with trailing weeks

The release schedule is no longer bounded by the summit, so don't
include it.

Add 2 weeks for the cycle-trailing deadline.

Change-Id: I8bca376d910c218b65a29d2e400fd519348f73b9
Signed-off-by: Doug Hellmann <doug@doughellmann.com>
",git fetch https://review.opendev.org/openstack/releases refs/changes/13/357213/1 && git format-patch -1 --stdout FETCH_HEAD,['tools/list_weeks.py'],1,8a3e97707dfa9ad137d557c5341102b71697b8fb,ocata-schedule,# Add weeks for the cycle-trailing deadline. for i in range(2): weeks.append(current),"parser.add_argument( 'summit', help='monday of the week of upcoming summit after the release, YYYY-MM-DD', )summit_date = datetime.datetime.strptime( args.summit, '%Y-%m-%d')# Add the list of Mondays following the release leading up to the # summit. Increment current before entering the loop because we've # already used that week. current += week while current <= summit_date: weeks.append(current)",3,12
openstack%2Ffuel-library~stable%2F8.0~I941dce03e8655447af3b6e9d552578934a4c914e,openstack/fuel-library,stable/8.0,I941dce03e8655447af3b6e9d552578934a4c914e,move puppet-firewall module to 1.2.0-mos-rc2 tag,MERGED,2016-08-26 14:03:16.000000000,2016-08-29 10:38:32.000000000,2016-08-29 10:35:14.000000000,"[{'_account_id': 3}, {'_account_id': 8971}, {'_account_id': 11827}, {'_account_id': 14610}, {'_account_id': 14985}, {'_account_id': 20656}]","[{'number': 1, 'created': '2016-08-26 14:03:16.000000000', 'files': ['deployment/Puppetfile'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/c7b053a6656effb4ea2f74329871929adc59f136', 'message': 'move puppet-firewall module to 1.2.0-mos-rc2 tag\n\nRelated-bug:1612185\nChange-Id: I941dce03e8655447af3b6e9d552578934a4c914e\n'}]",0,361227,c7b053a6656effb4ea2f74329871929adc59f136,31,6,1,23092,,,0,"move puppet-firewall module to 1.2.0-mos-rc2 tag

Related-bug:1612185
Change-Id: I941dce03e8655447af3b6e9d552578934a4c914e
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/27/361227/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/Puppetfile'],1,c7b053a6656effb4ea2f74329871929adc59f136,bug/1612185, :ref => '1.2.0-mos-rc2', :ref => '1.2.0',1,1
openstack%2Fcinder~master~I8293ff33e5b20a9316730fbcbd91250a73e17a87,openstack/cinder,master,I8293ff33e5b20a9316730fbcbd91250a73e17a87,Bugfix for CoprHD Volume driver,ABANDONED,2016-08-22 11:57:40.000000000,2016-08-29 10:38:30.000000000,,"[{'_account_id': 3}, {'_account_id': 6491}, {'_account_id': 9008}, {'_account_id': 9732}, {'_account_id': 12016}, {'_account_id': 12176}, {'_account_id': 12369}, {'_account_id': 12822}, {'_account_id': 13394}, {'_account_id': 14259}, {'_account_id': 14624}, {'_account_id': 14797}, {'_account_id': 15296}, {'_account_id': 15941}, {'_account_id': 16160}, {'_account_id': 16595}, {'_account_id': 16897}, {'_account_id': 16898}, {'_account_id': 17852}, {'_account_id': 18120}, {'_account_id': 18752}, {'_account_id': 19146}, {'_account_id': 21193}, {'_account_id': 22126}]","[{'number': 1, 'created': '2016-08-22 11:57:40.000000000', 'files': ['cinder/volume/drivers/coprhd/common.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/1ba2049a6f42bacb0e5d33dbeaadbc5a18de614a', 'message': 'Bugfix for CoprHD Volume driver\n\nThis fix generates the appropriate error message when the user tries\ncreating a volume from snapshot which is a part of a Consistency Group\n\nAs this operation is not supported in CoprHD as of now, the error\nmessage is generated\n\nChange-Id: I8293ff33e5b20a9316730fbcbd91250a73e17a87\nCloses-Bug: #1615547\n'}]",4,358581,1ba2049a6f42bacb0e5d33dbeaadbc5a18de614a,33,24,1,22797,,,0,"Bugfix for CoprHD Volume driver

This fix generates the appropriate error message when the user tries
creating a volume from snapshot which is a part of a Consistency Group

As this operation is not supported in CoprHD as of now, the error
message is generated

Change-Id: I8293ff33e5b20a9316730fbcbd91250a73e17a87
Closes-Bug: #1615547
",git fetch https://review.opendev.org/openstack/cinder refs/changes/81/358581/1 && git format-patch -1 --stdout FETCH_HEAD,['cinder/volume/drivers/coprhd/common.py'],1,1ba2049a6f42bacb0e5d33dbeaadbc5a18de614a,bug/1615547," try: if snapshot['cgsnapshot_id']: raise coprhd_utils.CoprHdError( coprhd_utils.CoprHdError.SOS_FAILURE_ERR, _(""Volume cannot be created individually from a snapshot"" "" that is part of a Consistency Group"")) except KeyError as e: return ",,9,0
openstack%2Frelease-tools~master~I8ce14b19dc13bad6260a3e32f14e06f5f5fc5df4,openstack/release-tools,master,I8ce14b19dc13bad6260a3e32f14e06f5f5fc5df4,fix announce.sh for projects with setup_requires,MERGED,2016-08-23 17:19:46.000000000,2016-08-29 10:37:53.000000000,2016-08-29 10:37:53.000000000,"[{'_account_id': 3}, {'_account_id': 308}, {'_account_id': 5638}, {'_account_id': 12898}]","[{'number': 1, 'created': '2016-08-23 17:19:46.000000000', 'files': ['announce.sh'], 'web_link': 'https://opendev.org/openstack/release-tools/commit/55c0dcb126ae5c870e506b4370402a8a27b21452', 'message': ""fix announce.sh for projects with setup_requires\n\nThe XStatic projects can't use pbr because they need four digit\nversions. They use setuptools-scm to collect their file list instead,\nbut that is not pre-installed on the nodes where the announce script\nruns. Rather than deal with that explicitly, run a setuptools command to\ncause all of the needed things to be installed in a way that will log\nthe output but not include it in the outgoing email body.\n\nChange-Id: I8ce14b19dc13bad6260a3e32f14e06f5f5fc5df4\nSigned-off-by: Doug Hellmann <doug@doughellmann.com>\n""}]",0,359351,55c0dcb126ae5c870e506b4370402a8a27b21452,8,4,1,2472,,,0,"fix announce.sh for projects with setup_requires

The XStatic projects can't use pbr because they need four digit
versions. They use setuptools-scm to collect their file list instead,
but that is not pre-installed on the nodes where the announce script
runs. Rather than deal with that explicitly, run a setuptools command to
cause all of the needed things to be installed in a way that will log
the output but not include it in the outgoing email body.

Change-Id: I8ce14b19dc13bad6260a3e32f14e06f5f5fc5df4
Signed-off-by: Doug Hellmann <doug@doughellmann.com>
",git fetch https://review.opendev.org/openstack/release-tools refs/changes/51/359351/1 && git format-patch -1 --stdout FETCH_HEAD,['announce.sh'],1,55c0dcb126ae5c870e506b4370402a8a27b21452,announce-setup-requires,"# Some projects have setup_requires dependencies on packages that are # not pre-installed, so run a setuptools command in a way to get them # installed without capturing the output in the email we're going to # be sending. echo ""Priming setup_requires packages"" python setup.py --name echo echo ""Generating email body in $relnotes_file""",echo $relnotes_file echo,9,3
openstack%2Ftempest~master~I1749e05a8b57f004969cd0bd1930781f906a201f,openstack/tempest,master,I1749e05a8b57f004969cd0bd1930781f906a201f,Test VRRP scenario,ABANDONED,2016-02-18 06:44:22.000000000,2016-08-29 10:37:04.000000000,,"[{'_account_id': 3}, {'_account_id': 9732}, {'_account_id': 10385}, {'_account_id': 13342}, {'_account_id': 16425}]","[{'number': 1, 'created': '2016-02-18 06:44:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/3999916e9e734255e8f8cacc1a89c095515fe02e', 'message': 'Test VRRP scenario\n\nCheck for max_l3_agents_per_router\nVerify the HA link Interfaces\nverify the HA link Interface ip address\n\nChange-Id: I1749e05a8b57f004969cd0bd1930781f906a201f\n'}, {'number': 2, 'created': '2016-02-18 09:10:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/22a25395d86801db5e2f43110fc5daa712a35143', 'message': 'Test VRRP scenario\n\nCheck for max_l3_agents_per_router\nVerify the HA link Interfaces\nverify the HA link Interface ip address\n\nChange-Id: I1749e05a8b57f004969cd0bd1930781f906a201f\n'}, {'number': 3, 'created': '2016-02-18 09:26:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/80f64e58824e3f5215b7f4484e5d2655c8e0e6c8', 'message': 'Test VRRP scenario\n\nCheck for max_l3_agents_per_router\nVerify the HA link Interfaces\nverify the HA link Interface ip address\n\nChange-Id: I1749e05a8b57f004969cd0bd1930781f906a201f\n'}, {'number': 4, 'created': '2016-02-18 10:04:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/6b453b618e82645865796c1b7a2a4cf7a824a33b', 'message': 'Test VRRP scenario\n\nCheck for max_l3_agents_per_router\nVerify the HA link Interfaces\nverify the HA link Interface ip address\n\nChange-Id: I1749e05a8b57f004969cd0bd1930781f906a201f\n'}, {'number': 5, 'created': '2016-02-18 12:06:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/16ce49559ca26bb9a9980ff91eda79079a744570', 'message': 'Test VRRP scenario\n\nCheck for max_l3_agents_per_router\nVerify the HA link Interfaces\nverify the HA link Interface ip address\n\nChange-Id: I1749e05a8b57f004969cd0bd1930781f906a201f\n'}, {'number': 6, 'created': '2016-02-19 09:10:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/13c483df7bf6e9f634e82e29b4e673bbd8e2108f', 'message': 'Test VRRP scenario\n\nCheck for max_l3_agents_per_router\nVerify the HA link Interfaces\nverify the HA link Interface ip address\n\nChange-Id: I1749e05a8b57f004969cd0bd1930781f906a201f\n'}, {'number': 7, 'created': '2016-02-19 10:10:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/29d895f6b2b88b4957089c579efe78d22ff2f680', 'message': 'Test VRRP scenario\n\nCheck for max_l3_agents_per_router\nVerify the HA link Interfaces\nverify the HA link Interface ip address\n\nChange-Id: I1749e05a8b57f004969cd0bd1930781f906a201f\n'}, {'number': 8, 'created': '2016-02-19 11:29:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/4029573c3bcc0a075f91b3488080e7e8b39d935d', 'message': 'Test VRRP scenario\n\nCheck for max_l3_agents_per_router\nVerify the HA link Interfaces\nverify the HA link Interface ip address\n\nChange-Id: I1749e05a8b57f004969cd0bd1930781f906a201f\n'}, {'number': 9, 'created': '2016-02-22 06:43:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/c42e4854ef10ad27e62356bc3a5c3c8775648969', 'message': 'Test VRRP scenario\n\nCheck for max_l3_agents_per_router\nVerify the HA link Interfaces\nverify the HA link Interface ip address\n\nChange-Id: I1749e05a8b57f004969cd0bd1930781f906a201f\n'}, {'number': 10, 'created': '2016-02-24 11:13:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/5f03fe499e759cfca01ec66decc4a1786604f3a7', 'message': 'Test VRRP scenario\n\nCheck for max_l3_agents_per_router\nVerify the HA link Interfaces\nverify the HA link Interface ip address\n\nChange-Id: I1749e05a8b57f004969cd0bd1930781f906a201f\n'}, {'number': 11, 'created': '2016-02-25 07:30:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/5578a26bc5b229ecca93d51dc374301886a9620e', 'message': 'Test VRRP scenario\n\nCheck for max_l3_agents_per_router\nVerify the HA link Interfaces\nverify the HA link Interface ip address\n\nChange-Id: I1749e05a8b57f004969cd0bd1930781f906a201f\n'}, {'number': 12, 'created': '2016-02-25 09:54:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/e205e70b9e55c74b61030f20fd63451f93ca4ea8', 'message': 'Test VRRP scenario\n\nCheck for max_l3_agents_per_router\nVerify the HA link Interfaces\nverify the HA link Interface ip address\n\nChange-Id: I1749e05a8b57f004969cd0bd1930781f906a201f\n'}, {'number': 13, 'created': '2016-02-25 10:05:04.000000000', 'files': ['tempest/scenario/test_vrrp_scenario.py', 'tempest/config.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/eb2d460dacb782f85d17f86477e4bf3f1708b55e', 'message': 'Test VRRP scenario\n\nCheck for max_l3_agents_per_router\nVerify the HA link Interfaces\nverify the HA link Interface ip address\n\nChange-Id: I1749e05a8b57f004969cd0bd1930781f906a201f\n'}]",2,281662,eb2d460dacb782f85d17f86477e4bf3f1708b55e,43,5,13,13342,,,0,"Test VRRP scenario

Check for max_l3_agents_per_router
Verify the HA link Interfaces
verify the HA link Interface ip address

Change-Id: I1749e05a8b57f004969cd0bd1930781f906a201f
",git fetch https://review.opendev.org/openstack/tempest refs/changes/62/281662/3 && git format-patch -1 --stdout FETCH_HEAD,['tempest/scenario/test_vrrp_scenario.py'],1,3999916e9e734255e8f8cacc1a89c095515fe02e,test_vrrp,"# Copyright (c) 2016 Hewlett-Packard Development Company, L.P. # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import subprocess from networking_vsphere.tests.scenario import manager from oslo_config import cfg from tempest_lib.common.utils import data_utils CONF = cfg.CONF class L3HAVRRP(manager.ESXNetworksTestJSON): def _to_find_number_of_l3_agenst_per_routers(self, HOST): cmd = ('ps -ef | grep neutron.conf') ssh = subprocess.Popen([""ssh"", ""%s"" % HOST, cmd], shell=False, stdout=subprocess.PIPE, stderr=subprocess.PIPE) output = ssh.stdout.readlines() path = output[2].split()[10].split('=')[1] ssh = subprocess.Popen(['ssh', ""%s"" % HOST, 'sudo cat', path], stdout=subprocess.PIPE) output = ssh.stdout.readlines() find = filter(lambda x: 'max_l3_agents_per_router' in x, output) no_of_routers = find[0].split('=')[1] return int(no_of_routers) def _connect_to_host(self, HOST, total, router_id): cmd = ('sudo ip netns exec qrouter-' + router_id + ' ifconfig') ssh = subprocess.Popen([""ssh"", ""%s"" % HOST, cmd], shell=False, stdout=subprocess.PIPE, stderr=subprocess.PIPE) output = ssh.stdout.readlines() if output: get_ha_link = output[0].split()[0].split(""-"")[1] find = filter(lambda x: get_ha_link in x, total) return find else: return None def _verify_ip_address(self, HOST, octet11, octet22, router_id): cmd = ('sudo ip netns exec qrouter-' + router_id + ' ifconfig') ssh = subprocess.Popen([""ssh"", ""%s"" % HOST, cmd], shell=False, stdout=subprocess.PIPE, stderr=subprocess.PIPE) output = ssh.stdout.readlines() if output: ip_address = output[1].split()[1].split(':')[1].split('.') octet1 = ip_address[0] octet2 = ip_address[1] octet3 = ip_address[2] octet4 = ip_address[3] if octet11 == octet1 and octet22 == octet2: if int(octet3) < 255 and int(octet4) < 255: pass else: raise Exception(""IP address is not in the given CIDR"") else: raise Exception(""IP address is not in the given CIDR"") def _get_ip_addtess_from_neutron_conf(self, HOST): cmd = ('ps -ef | grep neutron.conf') ssh = subprocess.Popen([""ssh"", ""%s"" % HOST, cmd], shell=False, stdout=subprocess.PIPE, stderr=subprocess.PIPE) output = ssh.stdout.readlines() path = output[4].split()[10].split('=')[1] ssh = subprocess.Popen(['ssh', ""%s"" % HOST, 'sudo cat', path], stdout=subprocess.PIPE) output = ssh.stdout.readlines() find = filter(lambda x: 'l3_ha_net_cidr' in x, output) x = find[0].split()[2].split()[0].split('.') octet11 = x[0] octet22 = x[1] return octet11, octet22 def test_HA_link_present_on_controllers(self): self.external_network_id = CONF.network.public_network_id name = data_utils.rand_name('router-') router = self.admin_client.create_router( name, external_gateway_info={ ""network_id"": CONF.network.public_network_id}, admin_state_up=True) router_id = router['router']['id'] self.addCleanup(self.admin_client.delete_router, router['router']['id']) device_owner = ""network:router_ha_interface"" username = cfg.CONF.VCENTER.host_username ctrl_ip_address1 = cfg.CONF.VCENTER.deployer_ip_1 ctrl_ip_address2 = cfg.CONF.VCENTER.deployer_ip_2 ctrl_ip_address3 = cfg.CONF.VCENTER.deployer_ip_3 HOST1 = username + ""@"" + ctrl_ip_address1 HOST2 = username + ""@"" + ctrl_ip_address2 HOST3 = username + ""@"" + ctrl_ip_address3 self.router_list = self._to_find_number_of_l3_agenst_per_routers(HOST1) if self.router_list == 3: port_body = self.admin_client.list_ports(device_id=router_id, device_owner=device_owner) first_id = port_body['ports'][0]['id'] second_id = port_body['ports'][1]['id'] third_id = port_body['ports'][2]['id'] total = [first_id, second_id, third_id] self.value1 = self._connect_to_host(HOST1, total, router_id) self.value2 = self._connect_to_host(HOST2, total, router_id) self.value3 = self._connect_to_host(HOST3, total, router_id) content = [self.value1, self.value2, self.value3] count = 0 for ww in content: if ww == []: count = count + 1 if count > 0: msg = ""All controllers not having a HA link"" raise Exception(msg) if self.router_list == 2: port_body = self.admin_client.list_ports(device_id=router_id, device_owner=device_owner) first_id = port_body['ports'][0]['id'] second_id = port_body['ports'][1]['id'] total = [first_id, second_id] self.value1 = self._connect_to_host(HOST1, total, router_id) self.value2 = self._connect_to_host(HOST2, total, router_id) self.value3 = self._connect_to_host(HOST3, total, router_id) content = [self.value1, self.value2, self.value3] count = 0 for ww in content: if ww == []: count = count + 1 if count > 1: msg = ""More than one controller not having HA link"" raise Exception(msg) self.octet11, self.octet22 = self._get_ip_addtess_from_neutron_conf( HOST1) self._verify_ip_address(HOST1, self.octet11, self.octet22, router_id) self._verify_ip_address(HOST2, self.octet11, self.octet22, router_id) self._verify_ip_address(HOST3, self.octet11, self.octet22, router_id) ",,161,0
openstack%2Frally~master~I2d3adef7893fbef1b90e69f56818fbe4d3ce4366,openstack/rally,master,I2d3adef7893fbef1b90e69f56818fbe4d3ce4366,Add watcher audit template context and 2 scenarios,MERGED,2016-07-13 15:08:37.000000000,2016-08-29 10:32:58.000000000,2016-08-29 10:32:58.000000000,"[{'_account_id': 3}, {'_account_id': 9545}, {'_account_id': 10475}, {'_account_id': 12395}, {'_account_id': 14817}, {'_account_id': 19055}]","[{'number': 1, 'created': '2016-07-13 15:08:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/aef1b9c57fa3c115ae65ec3f8271600a33a60cf3', 'message': 'Add watcher audit template context and 2 scenarios\n\nThis patch set adds audit template context with two scenarios:\nlist_audit_templates\ncreate_audit_and_delete\n\nChange-Id: I2d3adef7893fbef1b90e69f56818fbe4d3ce4366\n'}, {'number': 2, 'created': '2016-07-14 10:02:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/156708be3e85e6558d6ac1a6b9f119f1cb9faf43', 'message': 'Add watcher audit template context and 2 scenarios\n\nThis patch set adds audit template context with two scenarios:\nlist_audit_templates\ncreate_audit_and_delete\n\nChange-Id: I2d3adef7893fbef1b90e69f56818fbe4d3ce4366\n'}, {'number': 3, 'created': '2016-07-15 18:15:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/02402be7b597439b43d04d24c8e37895997b2c8d', 'message': 'Add watcher audit template context and 2 scenarios\n\nThis patch set adds audit template context with two scenarios:\nlist_audit_templates\ncreate_audit_and_delete\n\nChange-Id: I2d3adef7893fbef1b90e69f56818fbe4d3ce4366\n'}, {'number': 4, 'created': '2016-07-18 11:57:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/03c31adf72b48bd2e5f885ac7234e2699ff161ae', 'message': 'Add watcher audit template context and 2 scenarios\n\nThis patch set adds audit template context with two scenarios:\nlist_audit_templates\ncreate_audit_and_delete\n\nChange-Id: I2d3adef7893fbef1b90e69f56818fbe4d3ce4366\n'}, {'number': 5, 'created': '2016-07-18 13:30:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/07355e786927fdaa3f6fe5ec0f3667279c6548f9', 'message': 'Add watcher audit template context and 2 scenarios\n\nThis patch set adds audit template context with two scenarios:\nlist_audit_templates\ncreate_audit_and_delete\n\nChange-Id: I2d3adef7893fbef1b90e69f56818fbe4d3ce4366\n'}, {'number': 6, 'created': '2016-07-20 12:43:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/14dbf5212854898c0ea4dde14959daa4f091aaee', 'message': 'Add watcher audit template context and 2 scenarios\n\nThis patch set adds audit template context with two scenarios:\nlist_audit_templates\ncreate_audit_and_delete\n\nChange-Id: I2d3adef7893fbef1b90e69f56818fbe4d3ce4366\n'}, {'number': 7, 'created': '2016-08-03 12:02:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/1873eb000ab8b0a095f9d22b2c2def9f03a51cae', 'message': 'Add watcher audit template context and 2 scenarios\n\nThis patch set adds audit template context with two scenarios:\nlist_audit_templates\ncreate_audit_and_delete\n\nChange-Id: I2d3adef7893fbef1b90e69f56818fbe4d3ce4366\n'}, {'number': 8, 'created': '2016-08-09 09:02:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/256692217e41d3226efdc59a515b5f45dd6b2d45', 'message': 'Add watcher audit template context and 2 scenarios\n\nThis patch set adds audit template context with two scenarios:\nlist_audit_templates\ncreate_audit_and_delete\n\nChange-Id: I2d3adef7893fbef1b90e69f56818fbe4d3ce4366\n'}, {'number': 9, 'created': '2016-08-12 12:23:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/ff7292094e0afeb18a570d3aa8667501a5d730d0', 'message': 'Add watcher audit template context and 2 scenarios\n\nThis patch set adds audit template context with two scenarios:\nlist_audit_templates\ncreate_audit_and_delete\n\nChange-Id: I2d3adef7893fbef1b90e69f56818fbe4d3ce4366\n'}, {'number': 10, 'created': '2016-08-15 14:12:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/b8d5499999310db8fdc98dff6ed494b431df73e4', 'message': 'Add watcher audit template context and 2 scenarios\n\nThis patch set adds audit template context with two scenarios:\nlist_audit_templates\ncreate_audit_and_delete\n\nChange-Id: I2d3adef7893fbef1b90e69f56818fbe4d3ce4366\n'}, {'number': 11, 'created': '2016-08-18 08:22:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/8558084a90151e28491d230c8fb51e2a4e47494b', 'message': 'Add watcher audit template context and 2 scenarios\n\nThis patch set adds audit template context with two scenarios:\nlist_audit_templates\ncreate_audit_and_delete\n\nChange-Id: I2d3adef7893fbef1b90e69f56818fbe4d3ce4366\n'}, {'number': 12, 'created': '2016-08-18 11:01:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/208df12d789428cc8464687f090b71772b68796a', 'message': 'Add watcher audit template context and 2 scenarios\n\nThis patch set adds audit template context with two scenarios:\nlist_audit_templates\ncreate_audit_and_delete\n\nChange-Id: I2d3adef7893fbef1b90e69f56818fbe4d3ce4366\n'}, {'number': 13, 'created': '2016-08-18 14:16:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/31c8c9953fa10688da2969680dd0fc2f0ff8931b', 'message': 'Add watcher audit template context and 2 scenarios\n\nThis patch set adds audit template context with two scenarios:\nlist_audit_templates\ncreate_audit_and_delete\n\nChange-Id: I2d3adef7893fbef1b90e69f56818fbe4d3ce4366\n'}, {'number': 14, 'created': '2016-08-19 07:28:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/10e4d01c2e7dd5fe35aa1e84f94dfdd49b34135c', 'message': 'Add watcher audit template context and 2 scenarios\n\nThis patch set adds audit template context with two scenarios:\nlist_audit_templates\ncreate_audit_and_delete\n\nChange-Id: I2d3adef7893fbef1b90e69f56818fbe4d3ce4366\n'}, {'number': 15, 'created': '2016-08-22 07:53:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/5676f8823337446eac4f02854a5f4eb7693affaa', 'message': 'Add watcher audit template context and 2 scenarios\n\nThis patch set adds audit template context with two scenarios:\nlist_audit_templates\ncreate_audit_and_delete\n\nChange-Id: I2d3adef7893fbef1b90e69f56818fbe4d3ce4366\n'}, {'number': 16, 'created': '2016-08-24 07:48:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/72a821ff66c174666fad29a8fa5e3415985502b3', 'message': 'Add watcher audit template context and 2 scenarios\n\nThis patch set adds audit template context with two scenarios:\nlist_audit_templates\ncreate_audit_and_delete\n\nChange-Id: I2d3adef7893fbef1b90e69f56818fbe4d3ce4366\n'}, {'number': 17, 'created': '2016-08-24 09:20:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/691defe5ee1f03d402bbc3d2af34e1a49bb44571', 'message': 'Add watcher audit template context and 2 scenarios\n\nThis patch set adds audit template context with two scenarios:\nlist_audit_templates\ncreate_audit_and_delete\n\nChange-Id: I2d3adef7893fbef1b90e69f56818fbe4d3ce4366\n'}, {'number': 18, 'created': '2016-08-24 21:23:40.000000000', 'files': ['tests/ci/osresources.py', 'rally/plugins/openstack/scenarios/watcher/basic.py', 'tests/unit/plugins/openstack/context/watcher/__init__.py', 'rally-jobs/rally-watcher.yaml', 'rally/plugins/openstack/context/watcher/__init__.py', 'samples/tasks/scenarios/watcher/create-audit-and-delete.json', 'tests/unit/plugins/openstack/scenarios/watcher/test_utils.py', 'samples/tasks/scenarios/watcher/list-audit-templates.json', 'rally/plugins/openstack/cleanup/resources.py', 'samples/tasks/scenarios/watcher/list-audit-templates.yaml', 'rally/plugins/openstack/scenarios/watcher/utils.py', 'etc/rally/rally.conf.sample', 'rally/common/opts.py', 'samples/tasks/scenarios/watcher/create-audit-and-delete.yaml', 'tests/unit/plugins/openstack/context/watcher/test_audit_templates.py', 'tests/unit/plugins/openstack/cleanup/test_resources.py', 'tests/unit/plugins/openstack/scenarios/watcher/test_basic.py', 'rally/plugins/openstack/context/watcher/audit_templates.py'], 'web_link': 'https://opendev.org/openstack/rally/commit/27604462c4e6d53ba39c65efe823a26a4ad7eba7', 'message': 'Add watcher audit template context and 2 scenarios\n\nThis patch set adds audit template context with two scenarios:\nlist_audit_templates\ncreate_audit_and_delete\n\nChange-Id: I2d3adef7893fbef1b90e69f56818fbe4d3ce4366\n'}]",49,341604,27604462c4e6d53ba39c65efe823a26a4ad7eba7,133,6,18,19055,,,0,"Add watcher audit template context and 2 scenarios

This patch set adds audit template context with two scenarios:
list_audit_templates
create_audit_and_delete

Change-Id: I2d3adef7893fbef1b90e69f56818fbe4d3ce4366
",git fetch https://review.opendev.org/openstack/rally refs/changes/04/341604/18 && git format-patch -1 --stdout FETCH_HEAD,"['rally/plugins/openstack/scenarios/watcher/basic.py', 'tests/unit/plugins/openstack/context/watcher/__init__.py', 'rally/plugins/openstack/context/watcher/__init__.py', 'samples/tasks/scenarios/watcher/create-audit-and-delete.json', 'tests/unit/plugins/openstack/scenarios/watcher/test_utils.py', 'samples/tasks/scenarios/watcher/list-audit-templates.json', 'samples/tasks/scenarios/watcher/list-audit-templates.yaml', 'rally/plugins/openstack/scenarios/watcher/utils.py', 'etc/rally/rally.conf.sample', 'rally/common/opts.py', 'samples/tasks/scenarios/watcher/create-audit-and-delete.yaml', 'tests/unit/plugins/openstack/context/watcher/test_audit_templates.py', 'tests/unit/plugins/openstack/scenarios/watcher/test_basic.py', 'rally/plugins/openstack/context/watcher/audit_templates.py']",14,aef1b9c57fa3c115ae65ec3f8271600a33a60cf3,watcher-context,"# All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. from rally.common.i18n import _ from rally.common import logging from rally.common import utils as rutils from rally import consts from rally import osclients from rally.plugins.openstack.cleanup import manager as resource_manager from rally.plugins.openstack.scenarios.watcher import utils as watcher_utils from rally.plugins.openstack import types from rally.task import context LOG = logging.getLogger(__name__) @context.configure(name=""audit_templates"", order=550) class AuditTemplateGenerator(context.Context): """"""Context class for adding temporary audit template for benchmarks."""""" CONFIG_SCHEMA = { ""type"": ""array"", ""$schema"": consts.JSON_SCHEMA, ""minItems"": 1, ""uniqueItems"": True, ""items"": { ""type"": ""object"", ""properties"": { ""goal"": { ""type"": ""object"", ""properties"": { ""name"": { ""type"": ""string"" } } }, ""strategy"": { ""type"": ""object"", ""properties"": { ""name"": { ""type"": ""string"" } } }, }, }, ""additionalProperties"": False, ""required"": [""goal"", ""strategy""] } @logging.log_task_wrapper(LOG.info, _(""Enter context: `Audit Templates`"")) def setup(self): watcher_scenario = watcher_utils.WatcherScenario( {""user"": self.context[""users""][0], ""task"": self.context[""task""]}) clients = osclients.Clients(self.context[""admin""][""credential""]) for user, tenant_id in rutils.iterate_per_tenants( self.context[""users""]): self.context[""audit_templates""] = [] for template in self.config: goal = template[""goal""] strategy = template[""strategy""] goal_id = types.WatcherGoal.transform(clients=clients, resource_config=goal) strategy_id = types.WatcherStrategy.transform( clients=clients, resource_config=strategy) audit_template = watcher_scenario._create_audit_template( goal_id, strategy_id) self.context[""audit_templates""].append(audit_template.uuid) @logging.log_task_wrapper(LOG.info, _(""Exit context: `Audit Templates`"")) def cleanup(self): resource_manager.cleanup(names=[""watcher.audit_template""], users=self.context.get(""users"", [])) ",,460,9
openstack%2Freleases~master~I9b36da31f9e06ba3be11ade7c0a17969e5e9c671,openstack/releases,master,I9b36da31f9e06ba3be11ade7c0a17969e5e9c671,add pike and queens as future releases,MERGED,2016-08-19 15:41:42.000000000,2016-08-29 10:32:06.000000000,2016-08-29 10:32:06.000000000,"[{'_account_id': 3}, {'_account_id': 308}, {'_account_id': 5638}, {'_account_id': 11105}, {'_account_id': 12898}]","[{'number': 1, 'created': '2016-08-19 15:41:42.000000000', 'files': ['doc/source/pike/schedule.rst', 'doc/source/index.rst', 'doc/source/queens/schedule.rst', 'doc/source/pike/index.rst', 'doc/source/queens/index.rst'], 'web_link': 'https://opendev.org/openstack/releases/commit/4c606bace264dc4cce8b4b6ff383dcc17cec693b', 'message': 'add pike and queens as future releases\n\nNow that we have names for the P and Q releases [1], add them to the\nfuture schedule.\n\n[1] http://lists.openstack.org/pipermail/openstack-dev/2016-August/101891.html\n\nChange-Id: I9b36da31f9e06ba3be11ade7c0a17969e5e9c671\nSigned-off-by: Doug Hellmann <doug@doughellmann.com>\n'}]",0,357975,4c606bace264dc4cce8b4b6ff383dcc17cec693b,9,5,1,2472,,,0,"add pike and queens as future releases

Now that we have names for the P and Q releases [1], add them to the
future schedule.

[1] http://lists.openstack.org/pipermail/openstack-dev/2016-August/101891.html

Change-Id: I9b36da31f9e06ba3be11ade7c0a17969e5e9c671
Signed-off-by: Doug Hellmann <doug@doughellmann.com>
",git fetch https://review.opendev.org/openstack/releases refs/changes/75/357975/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/pike/schedule.rst', 'doc/source/index.rst', 'doc/source/queens/schedule.rst', 'doc/source/pike/index.rst', 'doc/source/queens/index.rst']",5,4c606bace264dc4cce8b4b6ff383dcc17cec693b,p-q-series-names,======== Queens ======== Projected Release Date: TBD .. toctree:: :maxdepth: 1 schedule .. deliverable:: :series: queens ,,476,0
openstack%2Ffuel-library~stable%2F8.0~I17d04fbad6def1217429fc3c92bed997fd510eb8,openstack/fuel-library,stable/8.0,I17d04fbad6def1217429fc3c92bed997fd510eb8,Add -n to iptables calls,MERGED,2016-08-15 15:09:41.000000000,2016-08-29 10:31:41.000000000,2016-08-29 10:30:40.000000000,"[{'_account_id': 3}, {'_account_id': 8971}, {'_account_id': 10068}, {'_account_id': 11827}, {'_account_id': 14610}, {'_account_id': 14985}, {'_account_id': 20656}]","[{'number': 1, 'created': '2016-08-15 15:09:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/2f7749b605b26e737714189544a0ea8e1fb3594d', 'message': 'Add -n to iptables calls\n\nThis change updates the calls that we use in the ocf scripts to\ndetermine if the rules are present to include the -n flag to prevent\nunnecessary dns lookups which can lead to deployment failures if dns is\nunavailable.\n\nChange-Id: I17d04fbad6def1217429fc3c92bed997fd510eb8\nCloses-Bug: #1605540\n(cherry picked from 28e3108dcf778f76899dc6b7f3a031ed8d6c6393)\n'}, {'number': 2, 'created': '2016-08-16 14:07:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/45e5aa3d4ca984f3b4320262dcc7b46f1ed5e838', 'message': 'Add -n to iptables calls\n\nThis change updates the calls that we use in the ocf scripts to\ndetermine if the rules are present to include the -n flag to prevent\nunnecessary dns lookups which can lead to deployment failures if dns is\nunavailable.\n\nChange-Id: I17d04fbad6def1217429fc3c92bed997fd510eb8\nCloses-Bug: #1605540\n'}, {'number': 3, 'created': '2016-08-16 14:11:51.000000000', 'files': ['files/fuel-ha-utils/ocf/ns_haproxy', 'files/fuel-ha-utils/ocf/ns_vrouter'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/02d7b33ab8a7a31dd3ac7995d23a21f6f7ccf9fd', 'message': 'Add -n to iptables calls\n\nThis change updates the calls that we use in the ocf scripts to\ndetermine if the rules are present to include the -n flag to prevent\nunnecessary dns lookups which can lead to deployment failures if dns is\nunavailable.\n\nChange-Id: I17d04fbad6def1217429fc3c92bed997fd510eb8\nCloses-Bug: #1605540\n(cherry picked from 28e3108dcf778f76899dc6b7f3a031ed8d6c6393)\n'}]",0,355518,02d7b33ab8a7a31dd3ac7995d23a21f6f7ccf9fd,65,7,3,23092,,,0,"Add -n to iptables calls

This change updates the calls that we use in the ocf scripts to
determine if the rules are present to include the -n flag to prevent
unnecessary dns lookups which can lead to deployment failures if dns is
unavailable.

Change-Id: I17d04fbad6def1217429fc3c92bed997fd510eb8
Closes-Bug: #1605540
(cherry picked from 28e3108dcf778f76899dc6b7f3a031ed8d6c6393)
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/18/355518/1 && git format-patch -1 --stdout FETCH_HEAD,"['files/fuel-ha-utils/ocf/ns_haproxy', 'files/fuel-ha-utils/ocf/ns_vrouter']",2,2f7749b605b26e737714189544a0ea8e1fb3594d,bug/1605540, iptables -n -t nat -L | grep -q masquerade-for-vrouter-namespace, iptables -t nat -L | grep -q masquerade-for-vrouter-namespace,2,2
openstack%2Ffuel-devops~master~I0ed6b6d56d35460248e3e306ca73affb005f75fa,openstack/fuel-devops,master,I0ed6b6d56d35460248e3e306ca73affb005f75fa,Implement sftp.stat for file attributes read,MERGED,2016-08-29 10:03:00.000000000,2016-08-29 10:29:57.000000000,2016-08-29 10:29:57.000000000,"[{'_account_id': 3}, {'_account_id': 11969}, {'_account_id': 19119}]","[{'number': 1, 'created': '2016-08-29 10:03:00.000000000', 'files': ['devops/helpers/ssh_client.py', 'devops/tests/helpers/test_ssh_client.py'], 'web_link': 'https://opendev.org/openstack/fuel-devops/commit/56f97c5bf8c63ab586a2149d610ebc341c200734', 'message': 'Implement sftp.stat for file attributes read\n\nImplement sftp.stat for file attributes read\n\nChange-Id: I0ed6b6d56d35460248e3e306ca73affb005f75fa\n'}]",0,361983,56f97c5bf8c63ab586a2149d610ebc341c200734,7,3,1,19119,,,0,"Implement sftp.stat for file attributes read

Implement sftp.stat for file attributes read

Change-Id: I0ed6b6d56d35460248e3e306ca73affb005f75fa
",git fetch https://review.opendev.org/openstack/fuel-devops refs/changes/83/361983/1 && git format-patch -1 --stdout FETCH_HEAD,"['devops/helpers/ssh_client.py', 'devops/tests/helpers/test_ssh_client.py']",2,56f97c5bf8c63ab586a2149d610ebc341c200734,," def test_stat(self, client, policy, logger): class Attrs(object): def __init__(self, mode): self.st_mode = mode self.st_size = 0 ssh, _sftp = self.prepare_sftp_file_tests(client) stat = mock.Mock() _sftp.attach_mock(stat, 'stat') stat.return_value = paramiko.sftp_attr.SFTPAttributes() stat.return_value.st_size = 0 stat.return_value.st_uid = 0 stat.return_value.st_gid = 0 path = '/etc/passwd' # noinspection PyTypeChecker result = ssh.stat(path) self.assertEqual(result.st_size, 0) self.assertEqual(result.st_uid, 0) self.assertEqual(result.st_gid, 0) ",,30,0
openstack%2Fpython-cloudkittyclient~master~I09fe3bc3c71a399bdcfaaa178543a2516494399b,openstack/python-cloudkittyclient,master,I09fe3bc3c71a399bdcfaaa178543a2516494399b,Replaces client_kwargs by empty dict in ckclient/shell.py,MERGED,2016-08-25 12:40:55.000000000,2016-08-29 10:20:59.000000000,2016-08-29 10:20:59.000000000,"[{'_account_id': 3}, {'_account_id': 2376}, {'_account_id': 7923}, {'_account_id': 9642}, {'_account_id': 23173}]","[{'number': 1, 'created': '2016-08-25 12:40:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-cloudkittyclient/commit/ddc07d06f8b2eecbbc46bcff3167a3a275129eac', 'message': ""Replaced client_kwargs = vars(args) by client_kwargs = {} in cloudkittyclient/shell.py\n\n         ckclient.get_client() doesn't need the command-line args.\n\n         The client_kwargs.update() altered the args, and caused the project_id field to be overwritten leading to an invalid http request in some cases.\n\nChange-Id: I09fe3bc3c71a399bdcfaaa178543a2516494399b\n""}, {'number': 2, 'created': '2016-08-25 12:53:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-cloudkittyclient/commit/27a959f280e22a43403928abbee20159f47f0f5f', 'message': ""Replaces client_kwargs = vars(args) by empty dict in ckclient/shell.py\n\nckclient.get_client() doesn't need the command-line args.\n\nThe client_kwargs.update() altered the args, and caused the project_id\nfield to be overwritten, leading to an invalid http request in\nsome cases.\n\nChange-Id: I09fe3bc3c71a399bdcfaaa178543a2516494399b\n""}, {'number': 3, 'created': '2016-08-25 12:54:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-cloudkittyclient/commit/23d09258e625d2b0bf9a7a3b725f639251433c9d', 'message': ""Replaces client_kwargs by empty dict in ckclient/shell.py\n\nckclient.get_client() doesn't need the command-line args.\n\nThe client_kwargs.update() altered the args, and caused the project_id\nfield to be overwritten, leading to an invalid http request in\nsome cases.\n\nChange-Id: I09fe3bc3c71a399bdcfaaa178543a2516494399b\n""}, {'number': 4, 'created': '2016-08-25 13:55:50.000000000', 'files': ['cloudkittyclient/shell.py'], 'web_link': 'https://opendev.org/openstack/python-cloudkittyclient/commit/83188918355b333675ed0c767b3ce60608455029', 'message': ""Replaces client_kwargs by empty dict in ckclient/shell.py\n\nckclient.get_client() doesn't need the command-line args.\n\nThe client_kwargs.update() altered the args, and caused the project_id\nfield to be overwritten, leading to an invalid http request in\nsome cases.\n\nCloses-Bug: #1616805\nChange-Id: I09fe3bc3c71a399bdcfaaa178543a2516494399b\n""}]",0,360503,83188918355b333675ed0c767b3ce60608455029,14,5,4,23060,,,0,"Replaces client_kwargs by empty dict in ckclient/shell.py

ckclient.get_client() doesn't need the command-line args.

The client_kwargs.update() altered the args, and caused the project_id
field to be overwritten, leading to an invalid http request in
some cases.

Closes-Bug: #1616805
Change-Id: I09fe3bc3c71a399bdcfaaa178543a2516494399b
",git fetch https://review.opendev.org/openstack/python-cloudkittyclient refs/changes/03/360503/2 && git format-patch -1 --stdout FETCH_HEAD,['cloudkittyclient/shell.py'],1,ddc07d06f8b2eecbbc46bcff3167a3a275129eac,bug/1616805, client_kwargs = {}, client_kwargs = vars(args),1,1
openstack%2Fnova~master~Ided59ecc3726c357ae76ce48251c066a5af20d0e,openstack/nova,master,Ided59ecc3726c357ae76ce48251c066a5af20d0e,WIP experiment with the remainder of the placement API,ABANDONED,2016-03-15 19:40:56.000000000,2016-08-29 10:20:47.000000000,,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 782}, {'_account_id': 4694}, {'_account_id': 5170}, {'_account_id': 5754}, {'_account_id': 7166}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9569}, {'_account_id': 9578}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 11564}, {'_account_id': 13692}, {'_account_id': 14384}, {'_account_id': 15286}, {'_account_id': 15648}, {'_account_id': 15751}, {'_account_id': 16376}, {'_account_id': 16897}, {'_account_id': 16898}, {'_account_id': 19726}]","[{'number': 1, 'created': '2016-03-15 19:40:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6571da453ac88d7a915fcb38accc61f8108d8ac3', 'message': 'WIP resource-pools/placement api\n\nThis is a very (_very_) rough and incomplete proof of concept of\nthe resource-pools portion of a new placement api server. It is\nbeing done first to help flesh out what interface is needed on the\nResourcePools object, second to explore ideas on how how to manage\nthe placement api in a way that will be eventually extractable.\n\nThe api is made up of two apps: One which has no auth and loads up\n/ with what will become a basic JSON-Home document. The other\nleads to the /resource_pools endpoint. The handler there is a\nSelector <https://pypi.python.org/pypi/selector> app dispatching\nto simple WSGI handler functions. This structure was chosen for\nvisibility.\n\njsonschema is used to validate the resource pool.\n\nOpen questions:\n\n* auth and exception handling needs to be resolved\n* at the moment this feels too nova for easy extraction\n\nNext steps:\n\n* continue fulfilling the API and see what that shows\n\nChange-Id: Ided59ecc3726c357ae76ce48251c066a5af20d0e\n'}, {'number': 2, 'created': '2016-03-17 17:33:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/fe125686ced0e69e68aa7ce90217c081e403348c', 'message': ""WIP resource-pools/placement api\n\nThis is a very (_very_) rough and incomplete proof of concept of\nthe resource-pools portion of a new placement api server. It is\nbeing done first to help flesh out what interface is needed on the\nResourcePools object, second to explore ideas on how how to manage\nthe placement api in a way that will be eventually extractable.\n\nThe api is made up of two apps: One which has no auth and loads up\n/ with what will become a basic JSON-Home document. The other\nleads to the /resource_pools endpoint. The handler there is a\nSelector <https://pypi.python.org/pypi/selector> app dispatching\nto simple WSGI handler functions. This structure was chosen for\nvisibility.\n\njsonschema is used to validate the resource pool.\n\nOpen questions:\n\n* auth and exception handling needs to be resolved\n* at the moment this feels too nova for easy extraction\n\nNext steps:\n\n* continue fulfilling the API and see what that shows\n\nNote: the use of gabbi here is to enable an api-first form of test\ndriven development. I'll scrap it, later, if people don't like its\ninclusion. However, for the sake of velocity in making the proof of\nconcept it is very useful.\n\nChange-Id: Ided59ecc3726c357ae76ce48251c066a5af20d0e\n""}, {'number': 3, 'created': '2016-03-17 20:08:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/fd752edf945593253c5dca324ab483b5b0aa179b', 'message': ""WIP resource-pools/placement api\n\nThis is a very (_very_) rough and incomplete proof of concept of\nthe resource-pools portion of a new placement api server. It is\nbeing done first to help flesh out what interface is needed on the\nResourcePools object, second to explore ideas on how how to manage\nthe placement api in a way that will be eventually extractable.\n\nThe api is made up of two apps: One which has no auth and loads up\n/ with what will become a basic JSON-Home document. The other\nleads to the /resource_pools endpoint. The handler there is a\nSelector <https://pypi.python.org/pypi/selector> app dispatching\nto simple WSGI handler functions. This structure was chosen for\nvisibility.\n\njsonschema is used to validate the resource pool.\n\nOpen questions:\n\n* auth and exception handling needs to be resolved\n* at the moment this feels too nova for easy extraction\n\nNext steps:\n\n* continue fulfilling the API and see what that shows\n\nNote: the use of gabbi here is to enable an api-first form of test\ndriven development. I'll scrap it, later, if people don't like its\ninclusion. However, for the sake of velocity in making the proof of\nconcept it is very useful.\n\nChange-Id: Ided59ecc3726c357ae76ce48251c066a5af20d0e\n""}, {'number': 4, 'created': '2016-03-17 22:11:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/408a2f60584fe64731a4b62ee9ee6dcbe45a1c14', 'message': ""WIP resource-pools/placement api\n\nThis is a very (_very_) rough and incomplete proof of concept of\nthe resource-pools portion of a new placement api server. It is\nbeing done first to help flesh out what interface is needed on the\nResourcePools object, second to explore ideas on how how to manage\nthe placement api in a way that will be eventually extractable.\n\nThe api is made up of two apps: One which has no auth and loads up\n/ with what will become a basic JSON-Home document. The other\nleads to the /resource_pools endpoint. The handler there is a\nSelector <https://pypi.python.org/pypi/selector> app dispatching\nto simple WSGI handler functions. This structure was chosen for\nvisibility.\n\njsonschema is used to validate the resource pool.\n\nOpen questions:\n\n* authZ needs to be resolved\n* at the moment this feels too nova for easy extraction\n\nNext steps:\n\n* continue fulfilling the API and see what that shows\n\nNote: the use of gabbi here is to enable an api-first form of test\ndriven development. I'll scrap it, later, if people don't like its\ninclusion. However, for the sake of velocity in making the proof of\nconcept it is very useful.\n\nChange-Id: Ided59ecc3726c357ae76ce48251c066a5af20d0e\n""}, {'number': 5, 'created': '2016-03-18 11:47:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/bdce2ffccee298f9d7db7e9e5a3f13c94dcafbae', 'message': ""WIP resource-pools/placement api\n\nThis is a very (_very_) rough and incomplete proof of concept of\nthe resource-pools portion of a new placement api server. It is\nbeing done first to help flesh out what interface is needed on the\nResourcePools object, second to explore ideas on how how to manage\nthe placement api in a way that will be eventually extractable.\n\nThe api is made up of two apps: One which has no auth and loads up\n/ with what will become a basic JSON-Home document. The other\nleads to the /resource_pools endpoint. The handler there is a\nSelector <https://pypi.python.org/pypi/selector> app dispatching\nto simple WSGI handler functions. This structure was chosen for\nvisibility.\n\njsonschema is used to validate the resource pool.\n\nOpen questions:\n\n* authZ needs to be resolved\n* at the moment this feels too nova for easy extraction\n\nNext steps:\n\n* continue fulfilling the API and see what that shows\n\nNote: the use of gabbi here is to enable an api-first form of test\ndriven development. I'll scrap it, later, if people don't like its\ninclusion. However, for the sake of velocity in making the proof of\nconcept it is very useful.\n\nChange-Id: Ided59ecc3726c357ae76ce48251c066a5af20d0e\n""}, {'number': 6, 'created': '2016-03-18 11:55:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1f180e356a9f301cd081002f2dfbcbff607e2296', 'message': ""WIP resource-pools/placement api\n\nThis is a very (_very_) rough and incomplete proof of concept of\nthe resource-pools portion of a new placement api server. It is\nbeing done first to help flesh out what interface is needed on the\nResourcePools object, second to explore ideas on how how to manage\nthe placement api in a way that will be eventually extractable.\n\nThe api is made up of two apps: One which has no auth and loads up\n/ with what will become a basic JSON-Home document. The other\nleads to the /resource_pools endpoint. The handler there is a\nSelector <https://pypi.python.org/pypi/selector> app dispatching\nto simple WSGI handler functions. This structure was chosen for\nvisibility.\n\njsonschema is used to validate the resource pool.\n\nOpen questions:\n\n* authZ needs to be resolved\n* at the moment this feels too nova for easy extraction\n\nNext steps:\n\n* continue fulfilling the API and see what that shows\n\nNote: the use of gabbi here is to enable an api-first form of test\ndriven development. I'll scrap it, later, if people don't like its\ninclusion. However, for the sake of velocity in making the proof of\nconcept it is very useful.\n\nChange-Id: Ided59ecc3726c357ae76ce48251c066a5af20d0e\n""}, {'number': 7, 'created': '2016-03-21 11:40:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/060056f4e6515786277502357e25e05a55852059', 'message': ""WIP resource-pools/placement api\n\nThis is a very (_very_) rough and incomplete proof of concept of\nthe resource-pools portion of a new placement api server. It is\nbeing done first to help flesh out what interface is needed on the\nResourcePools object, second to explore ideas on how how to manage\nthe placement api in a way that will be eventually extractable.\n\nThe api is made up of two apps: One which has no auth and loads up\n/ with what will become a basic JSON-Home document. The other\nleads to the /resource_pools endpoint. The handler there is a\nSelector <https://pypi.python.org/pypi/selector> app dispatching\nto simple WSGI handler functions. This structure was chosen for\nvisibility.\n\njsonschema is used to validate the resource pool.\n\nOpen questions:\n\n* authZ needs to be resolved\n* at the moment this feels too nova for easy extraction\n\nNext steps:\n\n* continue fulfilling the API and see what that shows\n\nNote: the use of gabbi here is to enable an api-first form of test\ndriven development. I'll scrap it, later, if people don't like its\ninclusion. However, for the sake of velocity in making the proof of\nconcept it is very useful.\n\nChange-Id: Ided59ecc3726c357ae76ce48251c066a5af20d0e\n""}, {'number': 8, 'created': '2016-03-21 21:54:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2edf28bbee2438f0f9aa2c730bbab75defc7257b', 'message': ""WIP resource-pools/placement api\n\nThis is a very (_very_) rough and incomplete proof of concept of\nthe resource-pools portion of a new placement api server. It is\nbeing done first to help flesh out what interface is needed on the\nResourcePools object, second to explore ideas on how how to manage\nthe placement api in a way that will be eventually extractable.\n\nThe api is made up of two apps: One which has no auth and loads up\n/ with what will become a basic JSON-Home document. The other\nleads to the /resource_pools endpoint. The handler there is a\nSelector <https://pypi.python.org/pypi/selector> app dispatching\nto simple WSGI handler functions. This structure was chosen for\nvisibility.\n\njsonschema is used to validate the resource pool.\n\nOpen questions:\n\n* authZ needs to be resolved\n* at the moment this feels too nova for easy extraction\n\nNext steps:\n\n* continue fulfilling the API and see what that shows\n\nNote: the use of gabbi here is to enable an api-first form of test\ndriven development. I'll scrap it, later, if people don't like its\ninclusion. However, for the sake of velocity in making the proof of\nconcept it is very useful.\n\nChange-Id: Ided59ecc3726c357ae76ce48251c066a5af20d0e\n""}, {'number': 9, 'created': '2016-03-22 13:29:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/79d32cebbdc88954559b758f400f139f2f648cda', 'message': ""WIP resource-pools/placement api\n\nThis is a very (_very_) rough and incomplete proof of concept of\nthe resource-pools portion of a new placement api server. It is\nbeing done first to help flesh out what interface is needed on the\nResourcePools object, second to explore ideas on how how to manage\nthe placement api in a way that will be eventually extractable.\n\nThe api is made up of two apps: One which has no auth and loads up\n/ with what will become a basic JSON-Home document. The other\nleads to the /resource_pools endpoint. The handler there is a\nSelector <https://pypi.python.org/pypi/selector> app dispatching\nto simple WSGI handler functions. This structure was chosen for\nvisibility.\n\njsonschema is used to validate the resource pool.\n\nOpen questions:\n\n* authZ needs to be resolved\n* at the moment this feels too nova for easy extraction\n\nNext steps:\n\n* continue fulfilling the API and see what that shows\n\nNote: the use of gabbi here is to enable an api-first form of test\ndriven development. I'll scrap it, later, if people don't like its\ninclusion. However, for the sake of velocity in making the proof of\nconcept it is very useful.\n\nChange-Id: Ided59ecc3726c357ae76ce48251c066a5af20d0e\n""}, {'number': 10, 'created': '2016-03-23 11:14:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/324cdf8c6a3097b71d414388893fdb22cb621d5e', 'message': ""WIP resource-pools/placement api\n\nThis is a very (_very_) rough and incomplete proof of concept of\nthe resource-pools portion of a new placement api server. It is\nbeing done first to help flesh out what interface is needed on the\nResourcePools object, second to explore ideas on how how to manage\nthe placement api in a way that will be eventually extractable.\n\nThe api is made up of two apps: One which has no auth and loads up\n/ with what will become a basic JSON-Home document. The other\nleads to the /resource_pools endpoint. The handler there is a\nSelector <https://pypi.python.org/pypi/selector> app dispatching\nto simple WSGI handler functions. This structure was chosen for\nvisibility.\n\njsonschema is used to validate the resource pool.\n\nOpen questions:\n\n* authZ needs to be resolved\n* at the moment this feels too nova for easy extraction\n\nNext steps:\n\n* continue fulfilling the API and see what that shows\n\nNote: the use of gabbi here is to enable an api-first form of test\ndriven development. I'll scrap it, later, if people don't like its\ninclusion. However, for the sake of velocity in making the proof of\nconcept it is very useful.\n\nChange-Id: Ided59ecc3726c357ae76ce48251c066a5af20d0e\n""}, {'number': 11, 'created': '2016-03-23 17:44:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/55244b490992d8bff4412926f44be91eb764e78f', 'message': ""WIP resource-pools/placement api\n\nThis is a very (_very_) rough and incomplete proof of concept of\nthe resource-pools portion of a new placement api server. It is\nbeing done first to help flesh out what interface is needed on the\nResourcePools object, second to explore ideas on how how to manage\nthe placement api in a way that will be eventually extractable.\n\nThe api is made up of two apps: One which has no auth and loads up\n/ with what will become a basic JSON-Home document. The other\nleads to the /resource_pools endpoint. The handler there is a\nSelector <https://pypi.python.org/pypi/selector> app dispatching\nto simple WSGI handler functions. This structure was chosen for\nvisibility.\n\njsonschema is used to validate the resource pool.\n\nOpen questions:\n\n* authZ needs to be resolved\n* at the moment this feels too nova for easy extraction\n\nNext steps:\n\n* continue fulfilling the API and see what that shows\n\nNote: the use of gabbi here is to enable an api-first form of test\ndriven development. I'll scrap it, later, if people don't like its\ninclusion. However, for the sake of velocity in making the proof of\nconcept it is very useful.\n\nChange-Id: Ided59ecc3726c357ae76ce48251c066a5af20d0e\n""}, {'number': 12, 'created': '2016-03-23 18:57:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/36c03d159e4281d42d551c566feac9c876cc20c4', 'message': ""WIP resource-pools/placement api\n\nThis is a very (_very_) rough and incomplete proof of concept of\nthe resource-pools portion of a new placement api server. It is\nbeing done first to help flesh out what interface is needed on the\nResourcePools object, second to explore ideas on how how to manage\nthe placement api in a way that will be eventually extractable.\n\nThe api is made up of two apps: One which has no auth and loads up\n/ with what will become a basic JSON-Home document. The other\nleads to the /resource_pools endpoint. The handler there is a\nSelector <https://pypi.python.org/pypi/selector> app dispatching\nto simple WSGI handler functions. This structure was chosen for\nvisibility.\n\njsonschema is used to validate the resource pool.\n\nOpen questions:\n\n* authZ needs to be resolved\n* at the moment this feels too nova for easy extraction\n\nNext steps:\n\n* continue fulfilling the API and see what that shows\n\nNote: the use of gabbi here is to enable an api-first form of test\ndriven development. I'll scrap it, later, if people don't like its\ninclusion. However, for the sake of velocity in making the proof of\nconcept it is very useful.\n\nChange-Id: Ided59ecc3726c357ae76ce48251c066a5af20d0e\n""}, {'number': 13, 'created': '2016-03-24 11:54:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c97ef97a15c05576cb5a54840ef7d19385acb41a', 'message': ""WIP resource-pools/placement api\n\nThis is a very (_very_) rough and incomplete proof of concept of\nthe resource-pools portion of a new placement api server. It is\nbeing done first to help flesh out what interface is needed on the\nResourcePools object, second to explore ideas on how how to manage\nthe placement api in a way that will be eventually extractable.\n\nThe api is made up of two apps: One which has no auth and loads up\n/ with what will become a basic JSON-Home document. The other\nleads to the /resource_pools endpoint. The handler there is a\nSelector <https://pypi.python.org/pypi/selector> app dispatching\nto simple WSGI handler functions. This structure was chosen for\nvisibility.\n\njsonschema is used to validate the resource pool.\n\nOpen questions:\n\n* authZ needs to be resolved\n* at the moment this feels too nova for easy extraction\n\nNext steps:\n\n* continue fulfilling the API and see what that shows\n\nNote: the use of gabbi here is to enable an api-first form of test\ndriven development. I'll scrap it, later, if people don't like its\ninclusion. However, for the sake of velocity in making the proof of\nconcept it is very useful.\n\nPartially-Implements: blueprint generic-resource-pools\nChange-Id: Ided59ecc3726c357ae76ce48251c066a5af20d0e\n""}, {'number': 14, 'created': '2016-03-24 12:00:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5350f5ae539dfbce0240e4d60e59c73909420c7b', 'message': ""WIP resource-pools/placement api\n\nThis is a very (_very_) rough and incomplete proof of concept of\nthe resource-pools portion of a new placement api server. It is\nbeing done first to help flesh out what interface is needed on the\nResourcePools object, second to explore ideas on how how to manage\nthe placement api in a way that will be eventually extractable.\n\nThe api is made up of two apps: One which has no auth and loads up\n/ with what will become a basic JSON-Home document. The other\nleads to the /resource_pools endpoint. The handler there is a\nSelector <https://pypi.python.org/pypi/selector> app dispatching\nto simple WSGI handler functions. This structure was chosen for\nvisibility.\n\njsonschema is used to validate the resource pool.\n\nOpen questions:\n\n* authZ needs to be resolved\n* at the moment this feels too nova for easy extraction\n\nNext steps:\n\n* continue fulfilling the API and see what that shows\n\nNote: the use of gabbi here is to enable an api-first form of test\ndriven development. I'll scrap it, later, if people don't like its\ninclusion. However, for the sake of velocity in making the proof of\nconcept it is very useful.\n\nPartially-Implements: blueprint generic-resource-pools\nChange-Id: Ided59ecc3726c357ae76ce48251c066a5af20d0e\n""}, {'number': 15, 'created': '2016-04-01 11:56:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/00c3b024bbdf58d667bd878e5b70e6f772bdf3c8', 'message': ""WIP resource-pools/placement api\n\nThis is a very (_very_) rough and incomplete proof of concept of\nthe resource-pools portion of a new placement api server. It is\nbeing done first to help flesh out what interface is needed on the\nResourcePools object, second to explore ideas on how how to manage\nthe placement api in a way that will be eventually extractable.\n\nThe api is made up of two apps: One which has no auth and loads up\n/ with what will become a basic JSON-Home document. The other\nleads to the /resource_pools endpoint. The handler there is a\nSelector <https://pypi.python.org/pypi/selector> app dispatching\nto simple WSGI handler functions. This structure was chosen for\nvisibility.\n\njsonschema is used to validate the resource pool.\n\nOpen questions:\n\n* authZ needs to be resolved\n* at the moment this feels too nova for easy extraction\n\nNext steps:\n\n* continue fulfilling the API and see what that shows\n* implement destroy in parent\n* properly handle and transform exceptions\n\nNote: the use of gabbi here is to enable an api-first form of test\ndriven development. I'll scrap it, later, if people don't like its\ninclusion. However, for the sake of velocity in making the proof of\nconcept it is very useful.\n\nPartially-Implements: blueprint generic-resource-pools\nChange-Id: Ided59ecc3726c357ae76ce48251c066a5af20d0e\n""}, {'number': 16, 'created': '2016-04-01 13:41:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c1635c0daabffd4d583466811f160dfb7833d084', 'message': ""WIP resource-pools/placement api\n\nThis is a very (_very_) rough and incomplete proof of concept of\nthe resource-pools portion of a new placement api server. It is\nbeing done first to help flesh out what interface is needed on the\nResourcePools object, second to explore ideas on how how to manage\nthe placement api in a way that will be eventually extractable.\n\nThe api is made up of two apps: One which has no auth and loads up\n/ with what will become a basic JSON-Home document. The other\nleads to the /resource_pools endpoint. The handler there is a\nSelector <https://pypi.python.org/pypi/selector> app dispatching\nto simple WSGI handler functions. This structure was chosen for\nvisibility.\n\njsonschema is used to validate the resource pool.\n\nOpen questions:\n\n* authZ needs to be resolved\n* at the moment this feels too nova for easy extraction\n\nNext steps:\n\n* continue fulfilling the API and see what that shows\n* implement destroy in parent\n* properly handle and transform exceptions\n\nNote: the use of gabbi here is to enable an api-first form of test\ndriven development. I'll scrap it, later, if people don't like its\ninclusion. However, for the sake of velocity in making the proof of\nconcept it is very useful.\n\nPartially-Implements: blueprint generic-resource-pools\nChange-Id: Ided59ecc3726c357ae76ce48251c066a5af20d0e\n""}, {'number': 17, 'created': '2016-04-01 15:21:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c204ee011639c761fbdb0fbc0182a239f2dc47a4', 'message': ""WIP resource-pools/placement api\n\nThis is a very (_very_) rough and incomplete proof of concept of\nthe resource-pools portion of a new placement api server. It is\nbeing done first to help flesh out what interface is needed on the\nResourcePools object, second to explore ideas on how how to manage\nthe placement api in a way that will be eventually extractable.\n\nThe api is made up of two apps: One which has no auth and loads up\n/ with what will become a basic JSON-Home document. The other\nleads to the /resource_pools endpoint. The handler there is a\nSelector <https://pypi.python.org/pypi/selector> app dispatching\nto simple WSGI handler functions. This structure was chosen for\nvisibility.\n\njsonschema is used to validate the resource pool.\n\nOpen questions:\n\n* authZ needs to be resolved\n* at the moment this feels too nova for easy extraction\n\nNext steps:\n\n* continue fulfilling the API and see what that shows\n* implement destroy in parent\n* properly handle and transform exceptions\n\nNote: the use of gabbi here is to enable an api-first form of test\ndriven development. I'll scrap it, later, if people don't like its\ninclusion. However, for the sake of velocity in making the proof of\nconcept it is very useful.\n\nPartially-Implements: blueprint generic-resource-pools\nChange-Id: Ided59ecc3726c357ae76ce48251c066a5af20d0e\n""}, {'number': 18, 'created': '2016-04-04 12:15:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/35d17fd2913582f449776abcb1b9747e049574d9', 'message': ""WIP resource-pools/placement api\n\nThis is a very (_very_) rough and incomplete proof of concept of\nthe resource-pools portion of a new placement api server. It is\nbeing done first to help flesh out what interface is needed on the\nResourcePools object, second to explore ideas on how how to manage\nthe placement api in a way that will be eventually extractable.\n\nThe api is made up of two apps: One which has no auth and loads up\n/ with what will become a basic JSON-Home document. The other\nleads to the /resource_pools endpoint. The handler there is a\nSelector <https://pypi.python.org/pypi/selector> app dispatching\nto simple WSGI handler functions. This structure was chosen for\nvisibility.\n\njsonschema is used to validate the resource pool.\n\nOpen questions:\n\n* authZ needs to be resolved\n* at the moment this feels too nova for easy extraction\n\nNext steps:\n\n* continue fulfilling the API and see what that shows\n* implement destroy in parent\n* properly handle and transform exceptions\n\nNote: the use of gabbi here is to enable an api-first form of test\ndriven development. I'll scrap it, later, if people don't like its\ninclusion. However, for the sake of velocity in making the proof of\nconcept it is very useful.\n\nPartially-Implements: blueprint generic-resource-pools\nChange-Id: Ided59ecc3726c357ae76ce48251c066a5af20d0e\n""}, {'number': 19, 'created': '2016-04-04 17:09:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7f90336019380f0e5ad7f3a236746a2d40fcd8a7', 'message': ""WIP resource-pools/placement api\n\nThis is a very (_very_) rough and incomplete proof of concept of\nthe resource-pools portion of a new placement api server. It is\nbeing done first to help flesh out what interface is needed on the\nResourcePools object, second to explore ideas on how how to manage\nthe placement api in a way that will be eventually extractable.\n\nThe api is made up of two apps: One which has no auth and loads up\n/ with what will become a basic JSON-Home document. The other\nleads to the /resource_pools endpoint. The handler there is a\nSelector <https://pypi.python.org/pypi/selector> app dispatching\nto simple WSGI handler functions. This structure was chosen for\nvisibility. Part of the goal here is to not use classes and to\nnot allow subclassing as we are trying to create an API which\nis effectively (once correct) static.\n\njsonschema is used to validate the resource pool.\n\nOpen questions:\n\n* authZ needs to be resolved\n* at the moment this feels too nova for easy extraction\n\nNext steps:\n\n* continue fulfilling the API and see what that shows\n* properly handle and transform exceptions\n* fix issues with ResourcePoolList.get_all gets wrong aggs.\n\nNote: the use of gabbi here is to enable an api-first form of test\ndriven development. I'll scrap it, later, if people don't like its\ninclusion. However, for the sake of velocity in making the proof of\nconcept it is very useful.\n\nPartially-Implements: blueprint generic-resource-pools\nChange-Id: Ided59ecc3726c357ae76ce48251c066a5af20d0e\n""}, {'number': 20, 'created': '2016-04-04 20:20:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/151c0305bff8e6bc43538a047a1c03b1e2849497', 'message': ""WIP resource-pools/placement api\n\nThis is a very (_very_) rough and incomplete proof of concept of\nthe resource-pools portion of a new placement api server. It is\nbeing done first to help flesh out what interface is needed on the\nResourcePools object, second to explore ideas on how how to manage\nthe placement api in a way that will be eventually extractable.\n\nThe api is made up of two apps: One which has no auth and loads up\n/ with what will become a basic JSON-Home document. The other\nleads to the /resource_pools endpoint. The handler there is a\nSelector <https://pypi.python.org/pypi/selector> app dispatching\nto simple WSGI handler functions. This structure was chosen for\nvisibility. Part of the goal here is to not use classes and to\nnot allow subclassing as we are trying to create an API which\nis effectively (once correct) static.\n\njsonschema is used to validate the resource pool.\n\nOpen questions:\n\n* authZ needs to be resolved\n* at the moment this feels too nova for easy extraction\n\nNext steps:\n\n* continue fulfilling the API and see what that shows\n* properly handle and transform exceptions\n* fix issues with ResourcePoolList.get_all gets wrong aggs.\n\nNote: the use of gabbi here is to enable an api-first form of test\ndriven development. I'll scrap it, later, if people don't like its\ninclusion. However, for the sake of velocity in making the proof of\nconcept it is very useful.\n\nPartially-Implements: blueprint generic-resource-pools\nChange-Id: Ided59ecc3726c357ae76ce48251c066a5af20d0e\n""}, {'number': 21, 'created': '2016-04-04 20:49:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4f4fc2c658d5ca0874f443ce1545a0b33800989e', 'message': ""WIP resource-pools/placement api\n\nThis is a very (_very_) rough and incomplete proof of concept of\nthe resource-pools portion of a new placement api server. It is\nbeing done first to help flesh out what interface is needed on the\nResourcePools object, second to explore ideas on how how to manage\nthe placement api in a way that will be eventually extractable.\n\nThe api is made up of two apps: One which has no auth and loads up\n/ with what will become a basic JSON-Home document. The other\nleads to the /resource_pools endpoint. The handler there is a\nSelector <https://pypi.python.org/pypi/selector> app dispatching\nto simple WSGI handler functions. This structure was chosen for\nvisibility. Part of the goal here is to not use classes and to\nnot allow subclassing as we are trying to create an API which\nis effectively (once correct) static.\n\njsonschema is used to validate the resource pool.\n\nOpen questions:\n\n* authZ needs to be resolved\n* at the moment this feels too nova for easy extraction\n\nNext steps:\n\n* continue fulfilling the API and see what that shows\n* add aggregate related endpoints\n* properly handle and transform exceptions\n\nNote: the use of gabbi here is to enable an api-first form of test\ndriven development. I'll scrap it, later, if people don't like its\ninclusion. However, for the sake of velocity in making the proof of\nconcept it is very useful.\n\nPartially-Implements: blueprint generic-resource-pools\nChange-Id: Ided59ecc3726c357ae76ce48251c066a5af20d0e\n""}, {'number': 22, 'created': '2016-04-06 12:21:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/83572b91e7d196e2dd7a5618b770fdd91b636fad', 'message': ""WIP resource-pools/placement api\n\nThis is a very (_very_) rough and incomplete proof of concept of\nthe resource-pools portion of a new placement api server. It is\nbeing done first to help flesh out what interface is needed on the\nResourcePools object, second to explore ideas on how how to manage\nthe placement api in a way that will be eventually extractable.\n\nThe api is made up of two apps: One which has no auth and loads up\n/ with what will become a basic JSON-Home document. The other\nleads to the /resource_pools endpoint. The handler there is a\nSelector <https://pypi.python.org/pypi/selector> app dispatching\nto simple WSGI handler functions. This structure was chosen for\nvisibility. Part of the goal here is to not use classes and to\nnot allow subclassing as we are trying to create an API which\nis effectively (once correct) static.\n\njsonschema is used to validate the resource pool.\n\nOpen questions:\n\n* authZ needs to be resolved\n* at the moment this feels too nova for easy extraction\n\nNext steps:\n\n* continue fulfilling the API and see what that shows\n* add aggregate related endpoints\n* properly handle and transform exceptions\n\nNote: the use of gabbi here is to enable an api-first form of test\ndriven development. I'll scrap it, later, if people don't like its\ninclusion. However, for the sake of velocity in making the proof of\nconcept it is very useful.\n\nPartially-Implements: blueprint generic-resource-pools\nChange-Id: Ided59ecc3726c357ae76ce48251c066a5af20d0e\n""}, {'number': 23, 'created': '2016-04-06 20:30:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0badfdfb34905f08105d20bfd231ef6a821a694c', 'message': ""WIP resource-pools/placement api\n\nThis is a very (_very_) rough and incomplete proof of concept of\nthe resource-pools portion of a new placement api server. It is\nbeing done first to help flesh out what interface is needed on the\nResourcePools object, second to explore ideas on how how to manage\nthe placement api in a way that will be eventually extractable.\n\nThe api is made up of two apps: One which has no auth and loads up\n/ with what will become a basic JSON-Home document. The other\nleads to the /resource_pools endpoint. The handler there is a\nSelector <https://pypi.python.org/pypi/selector> app dispatching\nto simple WSGI handler functions. This structure was chosen for\nvisibility. Part of the goal here is to not use classes and to\nnot allow subclassing as we are trying to create an API which\nis effectively (once correct) static.\n\njsonschema is used to validate the resource pool.\n\nOpen questions:\n\n* authZ needs to be resolved\n* at the moment this feels too nova for easy extraction\n\nNext steps:\n\n* continue fulfilling the API and see what that shows\n* fix associate and disassociate aggregate on upstream object\n* add aggregate related endpoints\n* properly handle and transform exceptions\n\nNote: the use of gabbi here is to enable an api-first form of test\ndriven development. I'll scrap it, later, if people don't like its\ninclusion. However, for the sake of velocity in making the proof of\nconcept it is very useful.\n\nPartially-Implements: blueprint generic-resource-pools\nChange-Id: Ided59ecc3726c357ae76ce48251c066a5af20d0e\n""}, {'number': 24, 'created': '2016-04-13 14:13:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9a3ebc74f89cfcc7fa0176b74b58d2a3362a2f2f', 'message': ""WIP resource-pools/placement api\n\nThis is a very (_very_) rough and incomplete proof of concept of\nthe resource-pools portion of a new placement api server. It is\nbeing done first to help flesh out what interface is needed on the\nResourcePools object, second to explore ideas on how how to manage\nthe placement api in a way that will be eventually extractable.\n\nThe api is made up of two apps: One which has no auth and loads up\n/ with what will become a basic JSON-Home document. The other\nleads to the /resource_pools endpoint. The handler there is a\nSelector <https://pypi.python.org/pypi/selector> app dispatching\nto simple WSGI handler functions. This structure was chosen for\nvisibility. Part of the goal here is to not use classes and to\nnot allow subclassing as we are trying to create an API which\nis effectively (once correct) static.\n\njsonschema is used to validate the resource pool.\n\nOpen questions:\n\n* authZ needs to be resolved\n* at the moment this feels too nova for easy extraction\n\nNext steps:\n\n* continue fulfilling the API and see what that shows\n* fix associate and disassociate aggregate on upstream object\n* add aggregate related endpoints\n* properly handle and transform exceptions\n\nNote: the use of gabbi here is to enable an api-first form of test\ndriven development. I'll scrap it, later, if people don't like its\ninclusion. However, for the sake of velocity in making the proof of\nconcept it is very useful.\n\nPartially-Implements: blueprint generic-resource-pools\nChange-Id: Ided59ecc3726c357ae76ce48251c066a5af20d0e\n""}, {'number': 25, 'created': '2016-04-13 17:58:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/82ed2095336b10d13c125ee49ccc1c8db56368ae', 'message': ""WIP resource-pools/placement api\n\nThis is a very (_very_) rough and incomplete proof of concept of\nthe resource-pools portion of a new placement api server. It is\nbeing done first to help flesh out what interface is needed on the\nResourcePools object, second to explore ideas on how how to manage\nthe placement api in a way that will be eventually extractable.\n\nThe api is made up of two apps: One which has no auth and loads up\n/ with what will become a basic JSON-Home document. The other\nleads to the /resource_pools endpoint. The handler there is a\nSelector <https://pypi.python.org/pypi/selector> app dispatching\nto simple WSGI handler functions. This structure was chosen for\nvisibility. Part of the goal here is to not use classes and to\nnot allow subclassing as we are trying to create an API which\nis effectively (once correct) static.\n\njsonschema is used to validate the resource pool.\n\nOpen questions:\n\n* authZ needs to be resolved\n* at the moment this feels too nova for easy extraction\n\nNext steps:\n\n* continue fulfilling the API and see what that shows\n* fix associate and disassociate aggregate on upstream object\n* properly handle and transform exceptions\n\nNote: the use of gabbi here is to enable an api-first form of test\ndriven development. I'll scrap it, later, if people don't like its\ninclusion. However, for the sake of velocity in making the proof of\nconcept it is very useful.\n\nPartially-Implements: blueprint generic-resource-pools\nChange-Id: Ided59ecc3726c357ae76ce48251c066a5af20d0e\n""}, {'number': 26, 'created': '2016-04-14 11:48:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6bd348ad629e6fab8ecb32a5c619d0eb4b8cebc7', 'message': ""WIP resource-pools/placement api\n\nThis is a very (_very_) rough and incomplete proof of concept of\nthe resource-pools portion of a new placement api server. It is\nbeing done first to help flesh out what interface is needed on the\nResourcePools object, second to explore ideas on how how to manage\nthe placement api in a way that will be eventually extractable.\n\nThe api is made up of two apps: One which has no auth and loads up\n/ with what will become a basic JSON-Home document. The other\nleads to the /resource_pools endpoint. The handler there is a\nSelector <https://pypi.python.org/pypi/selector> app dispatching\nto simple WSGI handler functions. This structure was chosen for\nvisibility. Part of the goal here is to not use classes and to\nnot allow subclassing as we are trying to create an API which\nis effectively (once correct) static.\n\njsonschema is used to validate the resource pool.\n\nOpen questions:\n\n* authZ needs to be resolved\n* at the moment this feels too nova for easy extraction\n\nNext steps:\n\n* continue fulfilling the API and see what that shows\n* fix associate and disassociate aggregate on upstream object\n* properly handle and transform exceptions\n\nNote: the use of gabbi here is to enable an api-first form of test\ndriven development. I'll scrap it, later, if people don't like its\ninclusion. However, for the sake of velocity in making the proof of\nconcept it is very useful.\n\nPartially-Implements: blueprint generic-resource-pools\nChange-Id: Ided59ecc3726c357ae76ce48251c066a5af20d0e\n""}, {'number': 27, 'created': '2016-04-14 14:10:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/685eca8fffaa3fc24fb4ee269780823eba9142d1', 'message': ""WIP resource-pools/placement api\n\nThis is a very (_very_) rough and incomplete proof of concept of\nthe resource-pools portion of a new placement api server. It is\nbeing done first to help flesh out what interface is needed on the\nResourcePools object, second to explore ideas on how how to manage\nthe placement api in a way that will be eventually extractable.\n\nThe api is made up of two apps: One which has no auth and loads up\n/ with what will become a basic JSON-Home document. The other\nleads to the /resource_pools endpoint. The handler there is a\nSelector <https://pypi.python.org/pypi/selector> app dispatching\nto simple WSGI handler functions. This structure was chosen for\nvisibility. Part of the goal here is to not use classes and to\nnot allow subclassing as we are trying to create an API which\nis effectively (once correct) static.\n\njsonschema is used to validate the resource pool.\n\nOpen questions:\n\n* authZ needs to be resolved\n* at the moment this feels too nova for easy extraction\n\nNext steps:\n\n* continue fulfilling the API and see what that shows\n* fix associate and disassociate aggregate on upstream object\n* properly handle and transform exceptions\n\nNote: the use of gabbi here is to enable an api-first form of test\ndriven development. I'll scrap it, later, if people don't like its\ninclusion. However, for the sake of velocity in making the proof of\nconcept it is very useful.\n\nPartially-Implements: blueprint generic-resource-pools\nChange-Id: Ided59ecc3726c357ae76ce48251c066a5af20d0e\n""}, {'number': 28, 'created': '2016-04-14 16:28:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/769f26b5411c219f61ebc6265139895d59b65e0c', 'message': ""WIP resource-pools/placement api\n\nThis is a very (_very_) rough and incomplete proof of concept of\nthe resource-pools portion of a new placement api server. It is\nbeing done first to help flesh out what interface is needed on the\nResourcePools object, second to explore ideas on how how to manage\nthe placement api in a way that will be eventually extractable.\n\nThe api is made up of two apps: One which has no auth and loads up\n/ with what will become a basic JSON-Home document. The other\nleads to the /resource_pools endpoint. The handler there is a\nSelector <https://pypi.python.org/pypi/selector> app dispatching\nto simple WSGI handler functions. This structure was chosen for\nvisibility. Part of the goal here is to not use classes and to\nnot allow subclassing as we are trying to create an API which\nis effectively (once correct) static.\n\njsonschema is used to validate the resource pool.\n\nOpen questions:\n\n* authZ needs to be resolved\n* at the moment this feels too nova for easy extraction\n\nNext steps:\n\n* continue fulfilling the API and see what that shows\n* properly handle and transform exceptions\n\nNote: the use of gabbi here is to enable an api-first form of test\ndriven development. I'll scrap it, later, if people don't like its\ninclusion. However, for the sake of velocity in making the proof of\nconcept it is very useful.\n\nPartially-Implements: blueprint generic-resource-pools\nChange-Id: Ided59ecc3726c357ae76ce48251c066a5af20d0e\n""}, {'number': 29, 'created': '2016-04-18 13:27:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d480e6bb605d7827c6d14e24f71f85450ab8fd13', 'message': ""WIP resource-pools/placement api\n\nThis is a very (_very_) rough and incomplete proof of concept of\nthe resource-pools portion of a new placement api server. It is\nbeing done first to help flesh out what interface is needed on the\nResourcePools object, second to explore ideas on how how to manage\nthe placement api in a way that will be eventually extractable.\n\nThe api is made up of two apps: One which has no auth and loads up\n/ with what will become a basic JSON-Home document. The other\nleads to the /resource_pools endpoint. The handler there is a\nSelector <https://pypi.python.org/pypi/selector> app dispatching\nto simple WSGI handler functions. This structure was chosen for\nvisibility. Part of the goal here is to not use classes and to\nnot allow subclassing as we are trying to create an API which\nis effectively (once correct) static.\n\njsonschema is used to validate the resource pool.\n\nAll requests, except for /, require an a context that is_admin.\n\nOpen questions:\n\n* at the moment this feels too nova for easy extraction\n\nNext steps:\n\n* continue fulfilling the API and see what that shows\n* properly handle and transform exceptions\n\nNote: the use of gabbi here is to enable an api-first form of test\ndriven development. I'll scrap it, later, if people don't like its\ninclusion. However, for the sake of velocity in making the proof of\nconcept it is very useful.\n\nPartially-Implements: blueprint generic-resource-pools\nChange-Id: Ided59ecc3726c357ae76ce48251c066a5af20d0e\n""}, {'number': 30, 'created': '2016-04-18 17:36:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/cd9faf1b783942169389b68b1b005f2cdf8707fd', 'message': ""WIP resource-pools/placement api\n\nThis is a rough and mostly incomplete proof of concept of\nthe resource-pools portion of a new placement api server. It is\nbeing done first to help flesh out what interface is needed on the\nResourcePools object, second to explore ideas on how how to manage\nthe placement api in a way that will be eventually extractable.\n\nThe api is made up of two apps: One which has no auth and loads up\n/ with what will become a basic JSON-Home document. The other\nleads to the /resource_pools endpoint. The handler there is a\nSelector <https://pypi.python.org/pypi/selector> app dispatching\nto simple WSGI handler functions. This structure was chosen for\nvisibility. Part of the goal here is to not use classes and to\nnot allow subclassing as we are trying to create an API which\nis effectively (once correct) static.\n\njsonschema is used to validate the resource pool when POST or PUT.\n\nAll requests, except for /, require a nova.context that is_admin.\n\nOpen questions:\n\n* at the moment this feels too nova for easy extraction\n* The code layout needs significant tuning but doing so in absence\n  of feedback on the basic approach is challenging\n* the basic API is in place but there are likely many corner cases\n  and situations with unexpected data that are not yet addressed\n\nNote: the use of gabbi here is to enable an api-first form of test\ndriven development. I'll scrap it, later, if people don't like its\ninclusion. However, for the sake of velocity in making the proof of\nconcept it is very useful.\n\nPartially-Implements: blueprint generic-resource-pools\nChange-Id: Ided59ecc3726c357ae76ce48251c066a5af20d0e\n""}, {'number': 31, 'created': '2016-04-20 09:16:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1090c6eeeaabf5e57d8df657f1969efde79fa085', 'message': ""WIP resource-pools/placement api\n\nThis is a rough and mostly incomplete proof of concept of\nthe resource-pools portion of a new placement api server. It is\nbeing done first to help flesh out what interface is needed on the\nResourcePools object, second to explore ideas on how how to manage\nthe placement api in a way that will be eventually extractable.\n\nThe api is made up of two apps: One which has no auth and loads up\n/ with what will become a basic JSON-Home document. The other\nleads to the /resource_pools endpoint. The handler there is a\nSelector <https://pypi.python.org/pypi/selector> app dispatching\nto simple WSGI handler functions. This structure was chosen for\nvisibility. Part of the goal here is to not use classes and to\nnot allow subclassing as we are trying to create an API which\nis effectively (once correct) static.\n\njsonschema is used to validate the resource pool when POST or PUT.\n\nAll requests, except for /, require a nova.context that is_admin.\n\nOpen questions:\n\n* at the moment this feels too nova for easy extraction\n* The code layout needs significant tuning but doing so in absence\n  of feedback on the basic approach is challenging\n* the basic API is in place but there are likely many corner cases\n  and situations with unexpected data that are not yet addressed\n\nNote: the use of gabbi here is to enable an api-first form of test\ndriven development. I'll scrap it, later, if people don't like its\ninclusion. However, for the sake of velocity in making the proof of\nconcept it is very useful.\n\nPartially-Implements: blueprint generic-resource-pools\nChange-Id: Ided59ecc3726c357ae76ce48251c066a5af20d0e\n""}, {'number': 32, 'created': '2016-04-22 20:22:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/17947603b762994de8a2dc38cc293bb473c55161', 'message': ""WIP resource-pools/placement api\n\nThis is a rough and mostly incomplete proof of concept of\nthe resource-pools portion of a new placement api server. It is\nbeing done first to help flesh out what interface is needed on the\nResourcePools object, second to explore ideas on how how to manage\nthe placement api in a way that will be eventually extractable.\n\nThe api is made up of two apps: One which has no auth and loads up\n/ with what will become a basic JSON-Home document. The other\nleads to the /resource_pools endpoint. The handler there is a\nSelector <https://pypi.python.org/pypi/selector> app dispatching\nto simple WSGI handler functions. This structure was chosen for\nvisibility. Part of the goal here is to not use classes and to\nnot allow subclassing as we are trying to create an API which\nis effectively (once correct) static.\n\njsonschema is used to validate the resource pool when POST or PUT.\n\nAll requests, except for /, require a nova.context that is_admin.\n\nOpen questions:\n\n* at the moment this feels too nova for easy extraction\n* The code layout needs significant tuning but doing so in absence\n  of feedback on the basic approach is challenging\n* the basic API is in place but there are likely many corner cases\n  and situations with unexpected data that are not yet addressed\n\nNote: the use of gabbi here is to enable an api-first form of test\ndriven development. I'll scrap it, later, if people don't like its\ninclusion. However, for the sake of velocity in making the proof of\nconcept it is very useful.\n\nPartially-Implements: blueprint generic-resource-pools\nChange-Id: Ided59ecc3726c357ae76ce48251c066a5af20d0e\n""}, {'number': 33, 'created': '2016-04-22 20:50:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/81b23e2f9daf468751bcaca2aa54a85ecb697e1d', 'message': ""WIP resource-pools/placement api\n\nThis is a rough and mostly incomplete proof of concept of\nthe resource-pools portion of a new placement api server. It is\nbeing done first to help flesh out what interface is needed on the\nResourceProviders object, second to explore ideas on how how to manage\nthe placement api in a way that will be eventually extractable.\n\nBecause of the collapse of the ResourcePool object into the\nResourceProvider object, there's some name weirdness going on here.\n\nThe api is made up of two apps: One which has no auth and loads up\n/ with what will become a basic JSON-Home document. The other\nleads to the /resource_pools endpoint. The handler there is a\nSelector <https://pypi.python.org/pypi/selector> app dispatching\nto simple WSGI handler functions. This structure was chosen for\nvisibility. Part of the goal here is to not use classes and to\nnot allow subclassing as we are trying to create an API which\nis effectively (once correct) static.\n\njsonschema is used to validate the resource pool when POST or PUT.\n\nAll requests, except for /, require a nova.context that is_admin.\n\nOpen questions:\n\n* at the moment this feels too nova for easy extraction\n* The code layout needs significant tuning but doing so in absence\n  of feedback on the basic approach is challenging\n* the basic API is in place but there are likely many corner cases\n  and situations with unexpected data that are not yet addressed\n\nNote: the use of gabbi here is to enable an api-first form of test\ndriven development. I'll scrap it, later, if people don't like its\ninclusion. However, for the sake of velocity in making the proof of\nconcept it is very useful.\n\nPartially-Implements: blueprint generic-resource-pools\nChange-Id: Ided59ecc3726c357ae76ce48251c066a5af20d0e\n""}, {'number': 34, 'created': '2016-04-22 20:56:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1e286f44a81ed6ca4b2e6da64799796fae25ff89', 'message': ""WIP resource-pools/placement api\n\nThis is a rough and mostly incomplete proof of concept of\nthe resource-pools portion of a new placement api server. It is\nbeing done first to help flesh out what interface is needed on the\nResourceProviders object, second to explore ideas on how how to manage\nthe placement api in a way that will be eventually extractable.\n\nBecause of the collapse of the ResourcePool object into the\nResourceProvider object, there's some name weirdness going on here.\n\nThe api is made up of two apps: One which has no auth and loads up\n/ with what will become a basic JSON-Home document. The other\nleads to the /resource_pools endpoint. The handler there is a\nSelector <https://pypi.python.org/pypi/selector> app dispatching\nto simple WSGI handler functions. This structure was chosen for\nvisibility. Part of the goal here is to not use classes and to\nnot allow subclassing as we are trying to create an API which\nis effectively (once correct) static.\n\njsonschema is used to validate the resource pool when POST or PUT.\n\nAll requests, except for /, require a nova.context that is_admin.\n\nOpen questions:\n\n* at the moment this feels too nova for easy extraction\n* The code layout needs significant tuning but doing so in absence\n  of feedback on the basic approach is challenging\n* the basic API is in place but there are likely many corner cases\n  and situations with unexpected data that are not yet addressed\n\nNote: the use of gabbi here is to enable an api-first form of test\ndriven development. I'll scrap it, later, if people don't like its\ninclusion. However, for the sake of velocity in making the proof of\nconcept it is very useful.\n\nPartially-Implements: blueprint generic-resource-pools\nChange-Id: Ided59ecc3726c357ae76ce48251c066a5af20d0e\n""}, {'number': 35, 'created': '2016-05-03 11:44:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3db08d58c067ef10ad3e9469793a10ec4d9136b3', 'message': ""WIP resource-pools/placement api\n\nThis is a rough and mostly incomplete proof of concept of\nthe resource-pools portion of a new placement api server. It is\nbeing done first to help flesh out what interface is needed on the\nResourceProviders object, second to explore ideas on how how to manage\nthe placement api in a way that will be eventually extractable.\n\nBecause of the collapse of the ResourcePool object into the\nResourceProvider object, there's some name weirdness going on here.\n\nThe api is made up of two apps: One which has no auth and loads up\n/ with what will become a basic JSON-Home document. The other\nleads to the /resource_pools endpoint. The handler there is a\nSelector <https://pypi.python.org/pypi/selector> app dispatching\nto simple WSGI handler functions. This structure was chosen for\nvisibility. Part of the goal here is to not use classes and to\nnot allow subclassing as we are trying to create an API which\nis effectively (once correct) static.\n\njsonschema is used to validate the resource pool when POST or PUT.\n\nAll requests, except for /, require a nova.context that is_admin.\n\nOpen questions:\n\n* at the moment this feels too nova for easy extraction\n* The code layout needs significant tuning but doing so in absence\n  of feedback on the basic approach is challenging\n* the basic API is in place but there are likely many corner cases\n  and situations with unexpected data that are not yet addressed\n\nNote: the use of gabbi here is to enable an api-first form of test\ndriven development. I'll scrap it, later, if people don't like its\ninclusion. However, for the sake of velocity in making the proof of\nconcept it is very useful.\n\nPartially-Implements: blueprint generic-resource-pools\nChange-Id: Ided59ecc3726c357ae76ce48251c066a5af20d0e\n""}, {'number': 36, 'created': '2016-05-03 18:17:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9db9ab3cb5d880c0fbc9ccfd3ebff6470a39a607', 'message': ""WIP resource-pools/placement api\n\nThis is a rough and mostly incomplete proof of concept of\nthe resource-pools portion of a new placement api server. It is\nbeing done first to help flesh out what interface is needed on the\nResourceProviders object, second to explore ideas on how how to manage\nthe placement api in a way that will be eventually extractable.\n\nBecause of the collapse of the ResourcePool object into the\nResourceProvider object, there's some name weirdness going on here.\n\nThe api is made up of two apps: One which has no auth and loads up\n/ with what will become a basic JSON-Home document. The other\nleads to the /resource_pools endpoint. The handler there is a\nSelector <https://pypi.python.org/pypi/selector> app dispatching\nto simple WSGI handler functions. This structure was chosen for\nvisibility. Part of the goal here is to not use classes and to\nnot allow subclassing as we are trying to create an API which\nis effectively (once correct) static.\n\njsonschema is used to validate the resource pool when POST or PUT.\n\nAll requests, except for /, require a nova.context that is_admin.\n\nOpen questions:\n\n* at the moment this feels too nova for easy extraction\n* The code layout needs significant tuning but doing so in absence\n  of feedback on the basic approach is challenging\n* the basic API is in place but there are likely many corner cases\n  and situations with unexpected data that are not yet addressed\n\nNote: the use of gabbi here is to enable an api-first form of test\ndriven development. I'll scrap it, later, if people don't like its\ninclusion. However, for the sake of velocity in making the proof of\nconcept it is very useful.\n\nPartially-Implements: blueprint generic-resource-pools\nChange-Id: Ided59ecc3726c357ae76ce48251c066a5af20d0e\n""}, {'number': 37, 'created': '2016-05-09 12:00:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b7627e54734258e98d63f9c123d1b8bf3dbe8e0a', 'message': ""WIP resource-pools/placement api\n\nThis is a rough and mostly incomplete proof of concept of\nthe resource-pools portion of a new placement api server. It is\nbeing done first to help flesh out what interface is needed on the\nResourceProviders object, second to explore ideas on how how to manage\nthe placement api in a way that will be eventually extractable.\n\nBecause of the collapse of the ResourcePool object into the\nResourceProvider object, there's some name weirdness going on here.\n\nThe api is made up of two apps: One which has no auth and loads up\n/ with what will become a basic JSON-Home document. The other\nleads to the /resource_pools endpoint. The handler there is a\nSelector <https://pypi.python.org/pypi/selector> app dispatching\nto simple WSGI handler functions. This structure was chosen for\nvisibility. Part of the goal here is to not use classes and to\nnot allow subclassing as we are trying to create an API which\nis effectively (once correct) static.\n\njsonschema is used to validate the resource pool when POST or PUT.\n\nAll requests, except for /, require a nova.context that is_admin.\n\nOpen questions:\n\n* at the moment this feels too nova for easy extraction\n* The code layout needs significant tuning but doing so in absence\n  of feedback on the basic approach is challenging\n* the basic API is in place but there are likely many corner cases\n  and situations with unexpected data that are not yet addressed\n\nNote: the use of gabbi here is to enable an api-first form of test\ndriven development. I'll scrap it, later, if people don't like its\ninclusion. However, for the sake of velocity in making the proof of\nconcept it is very useful.\n\nPartially-Implements: blueprint generic-resource-pools\nChange-Id: Ided59ecc3726c357ae76ce48251c066a5af20d0e\n""}, {'number': 38, 'created': '2016-05-09 14:59:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c5fe046e73128569e1fbc8228e2135beecf29c26', 'message': ""WIP resource-pools/placement api\n\nThis is a rough and mostly incomplete proof of concept of\nthe resource-pools portion of a new placement api server. It is\nbeing done first to help flesh out what interface is needed on the\nResourceProviders object, second to explore ideas on how how to manage\nthe placement api in a way that will be eventually extractable.\n\nBecause of the collapse of the ResourcePool object into the\nResourceProvider object, there's some name weirdness going on here.\n\nThe api is made up of two apps: One which has no auth and loads up\n/ with what will become a basic JSON-Home document. The other\nleads to the /resource_pools endpoint. The handler there is a\nSelector <https://pypi.python.org/pypi/selector> app dispatching\nto simple WSGI handler functions. This structure was chosen for\nvisibility. Part of the goal here is to not use classes and to\nnot allow subclassing as we are trying to create an API which\nis effectively (once correct) static.\n\njsonschema is used to validate the resource pool when POST or PUT.\n\nrudimentary support for parsing microversion headers is present,\nbut as we are only at version 1.0 now, there's no microversioned\nbehavior\n\nAll requests, except for /, require a nova.context that is_admin.\n\nOpen questions:\n\n* at the moment this feels too nova for easy extraction\n* The code layout needs significant tuning but doing so in absence\n  of feedback on the basic approach is challenging\n* the basic API is in place but there are likely many corner cases\n  and situations with unexpected data that are not yet addressed\n\nNote: the use of gabbi here is to enable an api-first form of test\ndriven development. I'll scrap it, later, if people don't like its\ninclusion. However, for the sake of velocity in making the proof of\nconcept it is very useful.\n\nPartially-Implements: blueprint generic-resource-pools\nChange-Id: Ided59ecc3726c357ae76ce48251c066a5af20d0e\n""}, {'number': 39, 'created': '2016-05-12 01:52:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b15ec435293b7fee463e1bfe6f5b3ae46272277d', 'message': ""WIP resource-pools/placement api\n\nThis is a rough and mostly incomplete proof of concept of\nthe resource-pools portion of a new placement api server. It is\nbeing done first to help flesh out what interface is needed on the\nResourceProviders object, second to explore ideas on how how to manage\nthe placement api in a way that will be eventually extractable.\n\nBecause of the collapse of the ResourcePool object into the\nResourceProvider object, there's some name weirdness going on here.\n\nThe api is made up of two apps: One which has no auth and loads up\n/ with what will become a basic JSON-Home document. The other\nleads to the /resource_pools endpoint. The handler there is a\nSelector <https://pypi.python.org/pypi/selector> app dispatching\nto simple WSGI handler functions. This structure was chosen for\nvisibility. Part of the goal here is to not use classes and to\nnot allow subclassing as we are trying to create an API which\nis effectively (once correct) static.\n\njsonschema is used to validate the resource pool when POST or PUT.\n\nrudimentary support for parsing microversion headers is present,\nbut as we are only at version 1.0 now, there's no microversioned\nbehavior\n\nAll requests, except for /, require a nova.context that is_admin.\n\nOpen questions:\n\n* at the moment this feels too nova for easy extraction\n* The code layout needs significant tuning but doing so in absence\n  of feedback on the basic approach is challenging\n* the basic API is in place but there are likely many corner cases\n  and situations with unexpected data that are not yet addressed\n\nNote: the use of gabbi here is to enable an api-first form of test\ndriven development. I'll scrap it, later, if people don't like its\ninclusion. However, for the sake of velocity in making the proof of\nconcept it is very useful.\n\nPartially-Implements: blueprint generic-resource-pools\nChange-Id: Ided59ecc3726c357ae76ce48251c066a5af20d0e\n""}, {'number': 40, 'created': '2016-05-12 10:42:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/597bc673b9f2be9413c6078d7bfeeac4948e416c', 'message': ""WIP resource-pools/placement api\n\nThis is a rough and mostly incomplete proof of concept of\nthe resource-pools portion of a new placement api server. It is\nbeing done first to help flesh out what interface is needed on the\nResourceProviders object, second to explore ideas on how how to manage\nthe placement api in a way that will be eventually extractable.\n\nBecause of the collapse of the ResourcePool object into the\nResourceProvider object, there's some name weirdness going on here.\n\nThe api is made up of two apps: One which has no auth and loads up\n/ with what will become a basic JSON-Home document. The other\nleads to the /resource_pools endpoint. The handler there is a\nSelector <https://pypi.python.org/pypi/selector> app dispatching\nto simple WSGI handler functions. This structure was chosen for\nvisibility. Part of the goal here is to not use classes and to\nnot allow subclassing as we are trying to create an API which\nis effectively (once correct) static.\n\njsonschema is used to validate the resource pool when POST or PUT.\n\nrudimentary support for parsing microversion headers is present,\nbut as we are only at version 1.0 now, there's no microversioned\nbehavior\n\nAll requests, except for /, require a nova.context that is_admin.\n\nOpen questions:\n\n* at the moment this feels too nova for easy extraction\n* The code layout needs significant tuning but doing so in absence\n  of feedback on the basic approach is challenging\n* the basic API is in place but there are likely many corner cases\n  and situations with unexpected data that are not yet addressed\n\nNote: the use of gabbi here is to enable an api-first form of test\ndriven development. I'll scrap it, later, if people don't like its\ninclusion. However, for the sake of velocity in making the proof of\nconcept it is very useful.\n\nPartially-Implements: blueprint generic-resource-pools\nChange-Id: Ided59ecc3726c357ae76ce48251c066a5af20d0e\n""}, {'number': 41, 'created': '2016-05-12 22:00:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9ed32b972dcb9764ca1203f50671604f1b32b2e9', 'message': ""WIP resource-pools/placement api\n\nThis is a rough and mostly incomplete proof of concept of\nthe resource-pools portion of a new placement api server. It is\nbeing done first to help flesh out what interface is needed on the\nResourceProviders object, second to explore ideas on how how to manage\nthe placement api in a way that will be eventually extractable.\n\nBecause of the collapse of the ResourcePool object into the\nResourceProvider object, there's some name weirdness going on here.\n\nThe api is made up of two apps: One which has no auth and loads up\n/ with what will become a basic JSON-Home document. The other\nleads to the /resource_pools endpoint. The handler there is a\nSelector <https://pypi.python.org/pypi/selector> app dispatching\nto simple WSGI handler functions. This structure was chosen for\nvisibility. Part of the goal here is to not use classes and to\nnot allow subclassing as we are trying to create an API which\nis effectively (once correct) static.\n\njsonschema is used to validate the resource pool when POST or PUT.\n\nrudimentary support for parsing microversion headers is present,\nbut as we are only at version 1.0 now, there's no microversioned\nbehavior\n\nAll requests, except for /, require a nova.context that is_admin.\n\nOpen questions:\n\n* at the moment this feels too nova for easy extraction\n* The code layout needs significant tuning but doing so in absence\n  of feedback on the basic approach is challenging\n* the basic API is in place but there are likely many corner cases\n  and situations with unexpected data that are not yet addressed\n\nNote: the use of gabbi here is to enable an api-first form of test\ndriven development. I'll scrap it, later, if people don't like its\ninclusion. However, for the sake of velocity in making the proof of\nconcept it is very useful.\n\nPartially-Implements: blueprint generic-resource-pools\nChange-Id: Ided59ecc3726c357ae76ce48251c066a5af20d0e\n""}, {'number': 42, 'created': '2016-05-16 16:34:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/172290273af1380dae14d0a2e0fb2be4ca0bc23b', 'message': ""WIP resource-pools/placement api\n\nThis is a rough and mostly incomplete proof of concept of\nthe resource-pools portion of a new placement api server. It is\nbeing done first to help flesh out what interface is needed on the\nResourceProviders object, second to explore ideas on how how to manage\nthe placement api in a way that will be eventually extractable.\n\nBecause of the collapse of the ResourcePool object into the\nResourceProvider object, there's some name weirdness going on here.\n\nThe api is made up of two apps: One which has no auth and loads up\n/ with what will become a basic JSON-Home document. The other\nleads to the /resource_pools endpoint. The handler there is a\nSelector <https://pypi.python.org/pypi/selector> app dispatching\nto simple WSGI handler functions. This structure was chosen for\nvisibility. Part of the goal here is to not use classes and to\nnot allow subclassing as we are trying to create an API which\nis effectively (once correct) static.\n\njsonschema is used to validate the resource pool when POST or PUT.\n\nrudimentary support for parsing microversion headers is present,\nbut as we are only at version 1.0 now, there's no microversioned\nbehavior\n\nAll requests, except for /, require a nova.context that is_admin.\n\nOpen questions:\n\n* at the moment this feels too nova for easy extraction\n* The code layout needs significant tuning but doing so in absence\n  of feedback on the basic approach is challenging\n* the basic API is in place but there are likely many corner cases\n  and situations with unexpected data that are not yet addressed\n\nNote: the use of gabbi here is to enable an api-first form of test\ndriven development. I'll scrap it, later, if people don't like its\ninclusion. However, for the sake of velocity in making the proof of\nconcept it is very useful.\n\nPartially-Implements: blueprint generic-resource-pools\nChange-Id: Ided59ecc3726c357ae76ce48251c066a5af20d0e\n""}, {'number': 43, 'created': '2016-05-16 22:10:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7f805637f6f5937a9f39e3d788379bead4755902', 'message': ""WIP resource-pools/placement api\n\nThis is a rough and mostly incomplete proof of concept of\nthe resource-pools portion of a new placement api server. It is\nbeing done first to help flesh out what interface is needed on the\nResourceProviders object, second to explore ideas on how how to manage\nthe placement api in a way that will be eventually extractable.\n\nBecause of the collapse of the ResourcePool object into the\nResourceProvider object, there's some name weirdness going on here.\n\nThe api is made up of two apps: One which has no auth and loads up\n/ with what will become a basic JSON-Home document. The other\nleads to the /resource_pools endpoint. The handler there is a\nSelector <https://pypi.python.org/pypi/selector> app dispatching\nto simple WSGI handler functions. This structure was chosen for\nvisibility. Part of the goal here is to not use classes and to\nnot allow subclassing as we are trying to create an API which\nis effectively (once correct) static.\n\njsonschema is used to validate the resource pool and inventories\nwhen POST or PUT.\n\nrudimentary support for parsing microversion headers is present,\nbut as we are only at version 1.0 now, there's no microversioned\nbehavior\n\nAll requests, except for /, require a nova.context that is_admin.\n\nOpen questions:\n\n* at the moment this feels too nova for easy extraction\n* The code layout needs significant tuning but doing so in absence\n  of feedback on the basic approach is challenging\n* the basic API is in place but there are likely many corner cases\n  and situations with unexpected data that are not yet addressed\n\nNote: the use of gabbi here is to enable an api-first form of test\ndriven development. I'll scrap it, later, if people don't like its\ninclusion. However, for the sake of velocity in making the proof of\nconcept it is very useful.\n\nPartially-Implements: blueprint generic-resource-pools\nChange-Id: Ided59ecc3726c357ae76ce48251c066a5af20d0e\n""}, {'number': 44, 'created': '2016-05-17 17:48:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/700f91ac03d869b8c2fb18eadfb43c70b7f55d27', 'message': ""WIP resource-pools/placement api\n\nThis is a rough proof of concept of the resource-pools portion\nof a new placement api server. It is being done first to help\nflesh out what interface is needed on the ResourceProviders object,\nsecond to explore ideas on how how to manage the placement api\nin a way that will be eventually extractable.\n\nBecause of the collapse of the ResourcePool object into the\nResourceProvider object, there's some name weirdness going on here.\n\nThe api is made up of two apps: One which has no auth and loads up\n/ with what will become a basic JSON-Home document. The other\nleads to the /resource_pools endpoint. The handler there is a\nSelector <https://pypi.python.org/pypi/selector> app dispatching\nto simple WSGI handler functions. This structure was chosen for\nvisibility. Part of the goal here is to not use classes and to\nnot allow subclassing as we are trying to create an API which\nis effectively (once correct) static.\n\njsonschema is used to validate the resource pool and inventories\nwhen POST or PUT.\n\nrudimentary support for parsing microversion headers is present,\nbut as we are only at version 1.0 now, there's no microversioned\nbehavior\n\nAll requests, except for /, require a nova.context that is_admin.\n\nOpen questions:\n\n* at the moment this feels too nova for easy extraction\n* The code layout needs tuning but doing so in absence\n  of feedback on the basic approach is meh\n* the basic API is in place but there are likely many corner cases\n  and situations with unexpected data that are not yet addressed\n* quite likely some more specific exceptions need to be raised in\n  the nova.objects used by the API\n\nNote: the use of gabbi here is to enable an api-first form of test\ndriven development which is vastly improving velocity.\n\nPartially-Implements: blueprint generic-resource-pools\nChange-Id: Ided59ecc3726c357ae76ce48251c066a5af20d0e\n""}, {'number': 45, 'created': '2016-05-19 19:09:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6bad8dc8bd413ba214765b4fb7f25875e9fe8c35', 'message': ""WIP resource-pools/placement api\n\nThis is a rough proof of concept of the resource-pools portion\nof a new placement api server. It is being done first to help\nflesh out what interface is needed on the ResourceProviders object,\nsecond to explore ideas on how how to manage the placement api\nin a way that will be eventually extractable.\n\nBecause of the collapse of the ResourcePool object into the\nResourceProvider object, there's some name weirdness going on here.\n\nThe api is made up of two apps: One which has no auth and loads up\n/ with what will become a basic JSON-Home document. The other\nleads to the /resource_pools endpoint. The handler there is a\nSelector <https://pypi.python.org/pypi/selector> app dispatching\nto simple WSGI handler functions. This structure was chosen for\nvisibility. Part of the goal here is to not use classes and to\nnot allow subclassing as we are trying to create an API which\nis effectively (once correct) static.\n\njsonschema is used to validate the resource pool and inventories\nwhen POST or PUT.\n\nrudimentary support for parsing microversion headers is present,\nbut as we are only at version 1.0 now, there's no microversioned\nbehavior\n\nAll requests, except for /, require a nova.context that is_admin.\n\nOpen questions:\n\n* at the moment this feels too nova for easy extraction\n* The code layout needs tuning but doing so in absence\n  of feedback on the basic approach is meh\n* the basic API is in place but there are likely many corner cases\n  and situations with unexpected data that are not yet addressed\n* quite likely some more specific exceptions need to be raised in\n  the nova.objects used by the API\n\nNote: the use of gabbi here is to enable an api-first form of test\ndriven development which is vastly improving velocity.\n\nPartially-Implements: blueprint generic-resource-pools\nChange-Id: Ided59ecc3726c357ae76ce48251c066a5af20d0e\n""}, {'number': 46, 'created': '2016-05-20 16:51:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/30f598534544d8735fed8f340298c62827710eeb', 'message': ""WIP resource-pools/placement api\n\nThis is a rough proof of concept of the resource-pools portion\nof a new placement api server. It is being done first to help\nflesh out what interface is needed on the ResourceProviders object,\nsecond to explore ideas on how how to manage the placement api\nin a way that will be eventually extractable.\n\nBecause of the collapse of the ResourcePool object into the\nResourceProvider object, there's some name weirdness going on here.\n\nThe api is made up of two apps: One which has no auth and loads up\n/ with what will become a basic JSON-Home document. The other\nleads to the /resource_pools endpoint. The handler there is a\nSelector <https://pypi.python.org/pypi/selector> app dispatching\nto simple WSGI handler functions. This structure was chosen for\nvisibility. Part of the goal here is to not use classes and to\nnot allow subclassing as we are trying to create an API which\nis effectively (once correct) static.\n\njsonschema is used to validate the resource pool and inventories\nwhen POST or PUT.\n\nrudimentary support for parsing microversion headers is present,\nbut as we are only at version 1.0 now, there's no microversioned\nbehavior\n\nAll requests, except for /, require a nova.context that is_admin.\n\nOpen questions:\n\n* at the moment this feels too nova for easy extraction\n* The code layout needs tuning but doing so in absence\n  of feedback on the basic approach is meh\n* the basic API is in place but there are likely many corner cases\n  and situations with unexpected data that are not yet addressed\n* quite likely some more specific exceptions need to be raised in\n  the nova.objects used by the API\n\nNote: the use of gabbi here is to enable an api-first form of test\ndriven development which is vastly improving velocity.\n\nPartially-Implements: blueprint generic-resource-pools\nChange-Id: Ided59ecc3726c357ae76ce48251c066a5af20d0e\n""}, {'number': 47, 'created': '2016-05-20 21:51:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b178bb6fac740802f3c9f8a1cac1bd0a6616ef68', 'message': ""WIP resource-pools/placement api\n\nThis is a rough proof of concept of the resource-pools portion\nof a new placement api server. It is being done first to help\nflesh out what interface is needed on the ResourceProviders object,\nsecond to explore ideas on how how to manage the placement api\nin a way that will be eventually extractable.\n\nBecause of the collapse of the ResourcePool object into the\nResourceProvider object, there's some name weirdness going on here.\n\nThe api is made up of two apps: One which has no auth and loads up\n/ with what will become a basic JSON-Home document. The other\nleads to the /resource_pools endpoint. The handler there is a\nSelector <https://pypi.python.org/pypi/selector> app dispatching\nto simple WSGI handler functions. This structure was chosen for\nvisibility. Part of the goal here is to not use classes and to\nnot allow subclassing as we are trying to create an API which\nis effectively (once correct) static.\n\njsonschema is used to validate the resource pool and inventories\nwhen POST or PUT.\n\nrudimentary support for parsing microversion headers is present,\nbut as we are only at version 1.0 now, there's no microversioned\nbehavior\n\nAll requests, except for /, require a nova.context that is_admin.\n\nOpen questions:\n\n* at the moment this feels too nova for easy extraction\n* The code layout needs tuning but doing so in absence\n  of feedback on the basic approach is meh\n* the basic API is in place but there are likely many corner cases\n  and situations with unexpected data that are not yet addressed\n* quite likely some more specific exceptions need to be raised in\n  the nova.objects used by the API\n\nNote: the use of gabbi here is to enable an api-first form of test\ndriven development which is vastly improving velocity.\n\nPartially-Implements: blueprint generic-resource-pools\nChange-Id: Ided59ecc3726c357ae76ce48251c066a5af20d0e\n""}, {'number': 48, 'created': '2016-05-29 20:27:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f756ad6cdf3b1d7a6922559760ed91ae79ae214b', 'message': ""WIP resource-pools/placement api\n\nThis is a rough proof of concept of the resource-pools portion\nof a new placement api server. It is being done first to help\nflesh out what interface is needed on the ResourceProviders object,\nsecond to explore ideas on how how to manage the placement api\nin a way that will be eventually extractable.\n\nBecause of the collapse of the ResourcePool object into the\nResourceProvider object, there's some name weirdness going on here.\n\nThe api is made up of two apps: One which has no auth and loads up\n/ with what will become a basic JSON-Home document. The other\nleads to the /resource_pools endpoint. The handler there is a\nSelector <https://pypi.python.org/pypi/selector> app dispatching\nto simple WSGI handler functions. This structure was chosen for\nvisibility. Part of the goal here is to not use classes and to\nnot allow subclassing as we are trying to create an API which\nis effectively (once correct) static.\n\njsonschema is used to validate the resource pool and inventories\nwhen POST or PUT.\n\nrudimentary support for parsing microversion headers is present,\nbut as we are only at version 1.0 now, there's no microversioned\nbehavior\n\nAll requests, except for /, require a nova.context that is_admin.\n\nOpen questions:\n\n* at the moment this feels too nova for easy extraction\n* The code layout needs tuning but doing so in absence\n  of feedback on the basic approach is meh\n* the basic API is in place but there are likely many corner cases\n  and situations with unexpected data that are not yet addressed\n* quite likely some more specific exceptions need to be raised in\n  the nova.objects used by the API\n\nNote: the use of gabbi here is to enable an api-first form of test\ndriven development which is vastly improving velocity.\n\nPartially-Implements: blueprint generic-resource-pools\nChange-Id: Ided59ecc3726c357ae76ce48251c066a5af20d0e\n""}, {'number': 49, 'created': '2016-06-03 11:39:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8f2d47d52e6410873941263a475ef360bb6a0eb2', 'message': ""WIP resource-pools/placement api\n\nThis is a rough proof of concept of the resource-pools portion\nof a new placement api server. It is being done first to help\nflesh out what interface is needed on the ResourceProviders object,\nsecond to explore ideas on how how to manage the placement api\nin a way that will be eventually extractable.\n\nBecause of the collapse of the ResourcePool object into the\nResourceProvider object, there's some name weirdness going on here.\n\nThe api is made up of two apps: One which has no auth and loads up\n/ with what will become a basic JSON-Home document. The other\nleads to the /resource_pools endpoint. The handler there is a\nSelector <https://pypi.python.org/pypi/selector> app dispatching\nto simple WSGI handler functions. This structure was chosen for\nvisibility. Part of the goal here is to not use classes and to\nnot allow subclassing as we are trying to create an API which\nis effectively (once correct) static.\n\njsonschema is used to validate the resource pool and inventories\nwhen POST or PUT.\n\nrudimentary support for parsing microversion headers is present,\nbut as we are only at version 1.0 now, there's no microversioned\nbehavior\n\nAll requests, except for /, require a nova.context that is_admin.\n\nOpen questions:\n\n* at the moment this feels too nova for easy extraction\n* The code layout needs tuning but doing so in absence\n  of feedback on the basic approach is meh\n* the basic API is in place but there are likely many corner cases\n  and situations with unexpected data that are not yet addressed\n* quite likely some more specific exceptions need to be raised in\n  the nova.objects used by the API\n\nNote: the use of gabbi here is to enable an api-first form of test\ndriven development which is vastly improving velocity.\n\nPartially-Implements: blueprint generic-resource-pools\nChange-Id: Ided59ecc3726c357ae76ce48251c066a5af20d0e\n""}, {'number': 50, 'created': '2016-06-03 13:28:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f5c9226c44abaf1dc366602f47a8f0e763db30ac', 'message': ""WIP resource-pools/placement api\n\nThis is a rough proof of concept of the resource-pools portion\nof a new placement api server. It is being done first to help\nflesh out what interface is needed on the ResourceProviders object,\nsecond to explore ideas on how how to manage the placement api\nin a way that will be eventually extractable.\n\nRecent discussions have revealed some potential problems with\nseveral aspects across the resource provider concepts, resolution\nof those problems will inevitably leads to changes here as we\nfigure out what needs to be done. The need for those changes,\nhowever, should not discourage reviewers from comments on the\nWSGI and other HTTP related handling going on here.\n\nThe api is made up of two apps: One which has no auth and loads up\n/ with what will become a basic JSON-Home document. The other\nleads to the /resource_pools endpoint. The handler there is a\nSelector <https://pypi.python.org/pypi/selector> app dispatching\nto simple WSGI handler functions. This structure was chosen for\nvisibility. Part of the goal here is to not use classes and to\nnot allow subclassing as we are trying to create an API which\nis effectively (once correct) static.\n\njsonschema is used to validate the resource pool and inventories\nwhen POST or PUT.\n\nrudimentary support for parsing microversion headers is present,\nbut as we are only at version 1.0 now, there's no microversioned\nbehavior\n\nAll requests, except for /, require a nova.context that is_admin.\n\nOpen questions:\n\n* at the moment this feels too nova for easy extraction\n* The code layout needs tuning but doing so in absence\n  of feedback on the basic approach is meh\n* the basic API is in place but there are likely many corner cases\n  and situations with unexpected data that are not yet addressed\n* quite likely some more specific exceptions need to be raised in\n  the nova.objects used by the API\n\nNote: the use of gabbi here is to enable an api-first form of test\ndriven development which is vastly improving velocity.\n\nPartially-Implements: blueprint generic-resource-pools\nChange-Id: Ided59ecc3726c357ae76ce48251c066a5af20d0e\n""}, {'number': 51, 'created': '2016-06-06 15:45:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8b526d47ecc968beeff7f7e9eb08b376ece16bd3', 'message': ""WIP resource-pools/placement api\n\nThis is a rough proof of concept of the resource-pools portion\nof a new placement api server. It is being done first to help\nflesh out what interface is needed on the ResourceProviders object,\nsecond to explore ideas on how how to manage the placement api\nin a way that will be eventually extractable.\n\nRecent discussions have revealed some potential problems with\nseveral aspects across the resource provider concepts, resolution\nof those problems will inevitably leads to changes here as we\nfigure out what needs to be done. The need for those changes,\nhowever, should not discourage reviewers from comments on the\nWSGI and other HTTP related handling going on here.\n\nThe api is made up of two apps: One which has no auth and loads up\n/ with what will become a basic JSON-Home document. The other\nleads to the /resource_pools endpoint. The handler there is a\nSelector <https://pypi.python.org/pypi/selector> app dispatching\nto simple WSGI handler functions. This structure was chosen for\nvisibility. Part of the goal here is to not use classes and to\nnot allow subclassing as we are trying to create an API which\nis effectively (once correct) static.\n\njsonschema is used to validate the resource pool and inventories\nwhen POST or PUT.\n\nrudimentary support for parsing microversion headers is present,\nbut as we are only at version 1.0 now, there's no microversioned\nbehavior\n\nAll requests, except for /, require a nova.context that is_admin.\n\nOpen questions:\n\n* at the moment this feels too nova for easy extraction\n* The code layout needs tuning but doing so in absence\n  of feedback on the basic approach is meh\n* the basic API is in place but there are likely many corner cases\n  and situations with unexpected data that are not yet addressed\n* quite likely some more specific exceptions need to be raised in\n  the nova.objects used by the API\n\nNote: the use of gabbi here is to enable an api-first form of test\ndriven development which is vastly improving velocity.\n\nPartially-Implements: blueprint generic-resource-pools\nChange-Id: Ided59ecc3726c357ae76ce48251c066a5af20d0e\n""}, {'number': 52, 'created': '2016-06-07 11:54:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/450dad7e869e0bfd5a9dea375bfc43040f8b82d7', 'message': ""WIP resource-providers/placement api\n\nThis is a rough proof of concept of the resource-providers portion\nof a new placement api server. It is being done first to help\nflesh out what interface is needed on the ResourceProviders object,\nsecond to explore ideas on how how to manage the placement api\nin a way that will be eventually extractable.\n\nThe api is made up of two apps: One which has no auth and loads up\n/ with what will become a basic JSON-Home document. The other\nleads to the /resource_providers endpoint. The handler there is a\nSelector <https://pypi.python.org/pypi/selector> app dispatching\nto simple WSGI handler functions. This structure was chosen for\nvisibility. Part of the goal here is to not use classes and to\nnot allow subclassing as we are trying to create an API which\nis effectively (once correct) static on the URL dimension.\n\njsonschema is used to validate the resource pproviders and inventories\nwhen POST or PUT.\n\nRudimentary support for parsing microversion headers is present,\nbut as we are only at version 1.0 now, there's no microversioned\nbehavior\n\nAll requests, except for /, require a nova.context that is_admin.\n\nOpen questions:\n\n* at the moment this feels too nova for easy extraction\n* The code layout needs tuning but doing so in absence\n  of feedback on the basic approach is meh\n* the basic API is in place but there are likely many corner cases\n  and situations with unexpected data that are not yet addressed\n* quite likely some more specific exceptions need to be raised in\n  the nova.objects used by the API\n\nPartially-Implements: blueprint generic-resource-pools\nChange-Id: Ided59ecc3726c357ae76ce48251c066a5af20d0e\n""}, {'number': 53, 'created': '2016-06-10 14:49:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c0fe6cdadf89cda07aa2eec3f94516affaf04f55', 'message': ""WIP resource-providers/placement api\n\nThis is a rough proof of concept of the resource-providers portion\nof a new placement api server. It is being done first to help\nflesh out what interface is needed on the ResourceProviders object,\nsecond to explore ideas on how how to manage the placement api\nin a way that will be eventually extractable.\n\nThe api is made up of two apps: One which has no auth and loads up\n/ with what will become a basic JSON-Home document. The other\nleads to the /resource_providers endpoint. The handler there is a\nSelector <https://pypi.python.org/pypi/selector> app dispatching\nto simple WSGI handler functions. This structure was chosen for\nvisibility. Part of the goal here is to not use classes and to\nnot allow subclassing as we are trying to create an API which\nis effectively (once correct) static on the URL dimension.\n\njsonschema is used to validate the resource pproviders and inventories\nwhen POST or PUT.\n\nRudimentary support for parsing microversion headers is present,\nbut as we are only at version 1.0 now, there's no microversioned\nbehavior\n\nAll requests, except for /, require a nova.context that is_admin.\n\nCurrent issues:\n\n* allocations, aggregates and usages (and checks for usages) are\n  currently broken, need commits below in the stack to get them\n  working again\n* at the moment this feels too nova for easy extraction\n* The code layout needs tuning but doing so in absence\n  of feedback on the basic approach is meh\n* the basic API is in place but there are likely many corner cases\n  and situations with unexpected data that are not yet addressed\n* quite likely some more specific exceptions need to be raised in\n  the nova.objects used by the API\n\nPartially-Implements: blueprint generic-resource-pools\nChange-Id: Ided59ecc3726c357ae76ce48251c066a5af20d0e\n""}, {'number': 54, 'created': '2016-06-11 15:20:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3a2f0e07302c2a451500515b669b19408694cdbd', 'message': ""WIP resource-providers/placement api\n\nThis is a rough proof of concept of the resource-providers portion\nof a new placement api server. It is being done first to help\nflesh out what interface is needed on the ResourceProviders object,\nsecond to explore ideas on how how to manage the placement api\nin a way that will be eventually extractable.\n\nThe api is made up of two apps: One which has no auth and loads up\n/ with what will become a basic JSON-Home document. The other\nleads to the /resource_providers endpoint. The handler there is a\nSelector <https://pypi.python.org/pypi/selector> app dispatching\nto simple WSGI handler functions. This structure was chosen for\nvisibility. Part of the goal here is to not use classes and to\nnot allow subclassing as we are trying to create an API which\nis effectively (once correct) static on the URL dimension.\n\njsonschema is used to validate the resource pproviders and inventories\nwhen POST or PUT.\n\nRudimentary support for parsing microversion headers is present,\nbut as we are only at version 1.0 now, there's no microversioned\nbehavior\n\nAll requests, except for /, require a nova.context that is_admin.\n\nCurrent issues:\n\n* allocations, aggregates and usages (and checks for usages) are\n  currently broken, need commits below in the stack to get them\n  working again\n* at the moment this feels too nova for easy extraction\n* The code layout needs tuning but doing so in absence\n  of feedback on the basic approach is meh\n* the basic API is in place but there are likely many corner cases\n  and situations with unexpected data that are not yet addressed\n* quite likely some more specific exceptions need to be raised in\n  the nova.objects used by the API\n\nPartially-Implements: blueprint generic-resource-pools\nChange-Id: Ided59ecc3726c357ae76ce48251c066a5af20d0e\n""}, {'number': 55, 'created': '2016-06-11 16:02:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0b15765242dcec758fb6915c7a7ca1dafa15d5b8', 'message': ""WIP resource-providers/placement api\n\nThis is a rough proof of concept of the resource-providers portion\nof a new placement api server. It is being done first to help\nflesh out what interface is needed on the ResourceProviders object,\nsecond to explore ideas on how how to manage the placement api\nin a way that will be eventually extractable.\n\nThe api is made up of two apps: One which has no auth and loads up\n/ with what will become a basic JSON-Home document. The other\nleads to the /resource_providers endpoint. The handler there is a\nSelector <https://pypi.python.org/pypi/selector> app dispatching\nto simple WSGI handler functions. This structure was chosen for\nvisibility. Part of the goal here is to not use classes and to\nnot allow subclassing as we are trying to create an API which\nis effectively (once correct) static on the URL dimension.\n\njsonschema is used to validate the resource pproviders and inventories\nwhen POST or PUT.\n\nRudimentary support for parsing microversion headers is present,\nbut as we are only at version 1.0 now, there's no microversioned\nbehavior\n\nAll requests, except for /, require a nova.context that is_admin.\n\nCurrent issues:\n\n* allocations, aggregates and usages (and checks for usages) are\n  currently broken, need commits below in the stack to get them\n  working again\n* at the moment this feels too nova for easy extraction\n* The code layout needs tuning but doing so in absence\n  of feedback on the basic approach is meh\n* the basic API is in place but there are likely many corner cases\n  and situations with unexpected data that are not yet addressed\n* quite likely some more specific exceptions need to be raised in\n  the nova.objects used by the API\n\nPartially-Implements: blueprint generic-resource-pools\nChange-Id: Ided59ecc3726c357ae76ce48251c066a5af20d0e\n""}, {'number': 56, 'created': '2016-06-13 12:00:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/577066167bda41ea0ec0d5e7cca21ab3e0533e3f', 'message': ""WIP resource-providers/placement api\n\nThis is a rough proof of concept of the resource-providers portion\nof a new placement api server. It is being done first to help\nflesh out what interface is needed on the ResourceProviders object,\nsecond to explore ideas on how how to manage the placement api\nin a way that will be eventually extractable.\n\nThe api is made up of two apps: One which has no auth and loads up\n/ with what will become a basic JSON-Home document. The other\nleads to the /resource_providers endpoint. The handler there is a\nSelector <https://pypi.python.org/pypi/selector> app dispatching\nto simple WSGI handler functions. This structure was chosen for\nvisibility. Part of the goal here is to not use classes and to\nnot allow subclassing as we are trying to create an API which\nis effectively (once correct) static on the URL dimension.\n\njsonschema is used to validate the resource pproviders and inventories\nwhen POST or PUT.\n\nRudimentary support for parsing microversion headers is present,\nbut as we are only at version 1.0 now, there's no microversioned\nbehavior\n\nAll requests, except for /, require a nova.context that is_admin.\n\nCurrent issues:\n\n* allocations, aggregates and usages (and checks for usages) are\n  currently broken, need commits below in the stack to get them\n  working again\n* the basic API is in place but there are likely many corner cases\n  and situations with unexpected data that are not yet addressed\n* quite likely some more specific exceptions need to be raised in\n  the nova.objects used by the API\n* not really all that happy with webob nor its exceptions\n\nPartially-Implements: blueprint generic-resource-pools\nChange-Id: Ided59ecc3726c357ae76ce48251c066a5af20d0e\n""}, {'number': 57, 'created': '2016-06-13 13:58:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c2866bb330756ce7df6dfb7b44f12b4a12218402', 'message': ""WIP resource-providers/placement api\n\nThis is a rough proof of concept of the resource-providers portion\nof a new placement api server. It is being done first to help\nflesh out what interface is needed on the ResourceProviders object,\nsecond to explore ideas on how how to manage the placement api\nin a way that will be eventually extractable.\n\nThe api is made up of two apps: One which has no auth and loads up\n/ with what will become a basic JSON-Home document. The other\nleads to the /resource_providers endpoint. The handler there is a\nSelector <https://pypi.python.org/pypi/selector> app dispatching\nto simple WSGI handler functions. This structure was chosen for\nvisibility. Part of the goal here is to not use classes and to\nnot allow subclassing as we are trying to create an API which\nis effectively (once correct) static on the URL dimension.\n\njsonschema is used to validate the resource pproviders and inventories\nwhen POST or PUT.\n\nRudimentary support for parsing microversion headers is present,\nbut as we are only at version 1.0 now, there's no microversioned\nbehavior\n\nAll requests, except for /, require a nova.context that is_admin.\n\nCurrent issues:\n\n* allocations, aggregates and usages (and checks for usages) are\n  currently broken, need commits below in the stack to get them\n  working again\n* the basic API is in place but there are likely many corner cases\n  and situations with unexpected data that are not yet addressed\n* quite likely some more specific exceptions need to be raised in\n  the nova.objects used by the API\n* not really all that happy with webob nor its exceptions\n* will probably need to trap nova.exception.NotFound and re-raise as\n  a webob.exc (which is sort of hilariously circular)\n\nPartially-Implements: blueprint generic-resource-pools\nChange-Id: Ided59ecc3726c357ae76ce48251c066a5af20d0e\n""}, {'number': 58, 'created': '2016-06-13 18:59:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/23cd0894830b8b9427b285339d094d85505f0741', 'message': 'WIP experiment with the remainder of the placement API\n\nThis is a workspace for figuring out those parts of the placement\nAPI that have not been determined enough to have their own patches.\n\nCurrent issues:\n\n* allocations, aggregates and usages (and checks for usages) are\n  currently broken, need commits below in the stack to get them\n  working again\n* quite likely some more specific exceptions need to be raised in\n  the nova.objects used by the API\n* not really all that happy with webob nor its exceptions\n* will probably need to trap nova.exception.NotFound and re-raise as\n  a webob.exc (which is sort of hilariously circular)\n\nPartially-Implements: blueprint generic-resource-pools\nChange-Id: Ided59ecc3726c357ae76ce48251c066a5af20d0e\n'}, {'number': 59, 'created': '2016-06-13 19:55:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/dee2dfe4a67573fa2a7393b0df19d53eb22f6743', 'message': 'WIP experiment with the remainder of the placement API\n\nThis is a workspace for figuring out those parts of the placement\nAPI that have not been determined enough to have their own patches.\n\nCurrent issues:\n\n* allocations, aggregates and usages (and checks for usages) are\n  currently broken, need commits below in the stack to get them\n  working again\n* quite likely some more specific exceptions need to be raised in\n  the nova.objects used by the API\n* not really all that happy with webob nor its exceptions\n* will probably need to trap nova.exception.NotFound and re-raise as\n  a webob.exc (which is sort of hilariously circular)\n\nPartially-Implements: blueprint generic-resource-pools\nChange-Id: Ided59ecc3726c357ae76ce48251c066a5af20d0e\n'}, {'number': 60, 'created': '2016-06-14 12:07:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0ab8b6720b1410548acabdf136b6ee3c0da7b2b3', 'message': 'WIP experiment with the remainder of the placement API\n\nThis is a workspace for figuring out those parts of the placement\nAPI that have not been determined enough to have their own patches.\n\nCurrent issues:\n\n* allocations, aggregates and usages (and checks for usages) are\n  currently broken, need commits below in the stack to get them\n  working again\n* quite likely some more specific exceptions need to be raised in\n  the nova.objects used by the API\n* not really all that happy with webob nor its exceptions\n* will probably need to trap nova.exception.NotFound and re-raise as\n  a webob.exc (which is sort of hilariously circular)\n\nPartially-Implements: blueprint generic-resource-pools\nChange-Id: Ided59ecc3726c357ae76ce48251c066a5af20d0e\n'}, {'number': 61, 'created': '2016-06-14 13:53:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/fdc5b0b27860d8d28c88faa761ab5a022dbdf77d', 'message': 'WIP experiment with the remainder of the placement API\n\nThis is a workspace for figuring out those parts of the placement\nAPI that have not been determined enough to have their own patches.\n\nCurrent issues:\n\n* allocations, aggregates and usages (and checks for usages) are\n  currently broken, need commits below in the stack to get them\n  working again\n* quite likely some more specific exceptions need to be raised in\n  the nova.objects used by the API\n* not really all that happy with webob nor its exceptions\n* will probably need to trap nova.exception.NotFound and re-raise as\n  a webob.exc (which is sort of hilariously circular)\n\nPartially-Implements: blueprint generic-resource-pools\nChange-Id: Ided59ecc3726c357ae76ce48251c066a5af20d0e\n'}, {'number': 62, 'created': '2016-06-14 17:13:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0d5c4e270410dbba0a8c16d1c1733f2f899bf34b', 'message': 'WIP experiment with the remainder of the placement API\n\nThis is a workspace for figuring out those parts of the placement\nAPI that have not been determined enough to have their own patches.\n\nCurrent issues:\n\n* allocations, aggregates and usages (and checks for usages) are\n  currently broken, need commits below in the stack to get them\n  working again\n* quite likely some more specific exceptions need to be raised in\n  the nova.objects used by the API\n* not really all that happy with webob nor its exceptions\n* will probably need to trap nova.exception.NotFound and re-raise as\n  a webob.exc (which is sort of hilariously circular)\n\nPartially-Implements: blueprint generic-resource-pools\nChange-Id: Ided59ecc3726c357ae76ce48251c066a5af20d0e\n'}, {'number': 63, 'created': '2016-06-14 17:51:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/fb4f596e0fda10c444d6e66f3968a87cee5e10f1', 'message': 'WIP experiment with the remainder of the placement API\n\nThis is a workspace for figuring out those parts of the placement\nAPI that have not been determined enough to have their own patches.\n\nCurrent issues:\n\n* allocations, aggregates and usages (and checks for usages) are\n  currently broken, need commits below in the stack to get them\n  working again\n* quite likely some more specific exceptions need to be raised in\n  the nova.objects used by the API\n* not really all that happy with webob nor its exceptions\n* will probably need to trap nova.exception.NotFound and re-raise as\n  a webob.exc (which is sort of hilariously circular)\n\nPartially-Implements: blueprint generic-resource-pools\nChange-Id: Ided59ecc3726c357ae76ce48251c066a5af20d0e\n'}, {'number': 64, 'created': '2016-06-14 19:22:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/214b49431652b4901a91f574ce74c88c6ea49110', 'message': ""WIP experiment with the remainder of the placement API\n\nThis is a workspace for figuring out those parts of the placement\nAPI that have not been determined enough to have their own patches.\n\nMany gabbi tests have been marked xfail as a reference that there's\nstill work to be done in that area.\n\nCurrent issues:\n\n* allocations, aggregates and checks for usages are\n  currently broken, need commits below in the stack to get them\n  working again\n  * The usages URI now works, but there are no checks.\n* quite likely some more specific exceptions need to be raised in\n  the nova.objects used by the API\n* not really all that happy with webob nor its exceptions\n* will probably need to trap nova.exception.NotFound and re-raise as\n  a webob.exc (which is sort of hilariously circular)\n\nPartially-Implements: blueprint generic-resource-pools\nChange-Id: Ided59ecc3726c357ae76ce48251c066a5af20d0e\n""}, {'number': 65, 'created': '2016-06-15 11:47:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9ac3bd8c708524f63ec1a33b840ef677cfba7344', 'message': ""WIP experiment with the remainder of the placement API\n\nThis is a workspace for figuring out those parts of the placement\nAPI that have not been determined enough to have their own patches.\n\nMany gabbi tests have been marked xfail as a reference that there's\nstill work to be done in that area.\n\nCurrent issues:\n\n* allocations, aggregates and checks for usages are\n  currently broken, need commits below in the stack to get them\n  working again\n  * The usages URI now works, but there are no checks.\n* quite likely some more specific exceptions need to be raised in\n  the nova.objects used by the API\n* not really all that happy with webob nor its exceptions\n* will probably need to trap nova.exception.NotFound and re-raise as\n  a webob.exc (which is sort of hilariously circular)\n\nPartially-Implements: blueprint generic-resource-pools\nChange-Id: Ided59ecc3726c357ae76ce48251c066a5af20d0e\n""}, {'number': 66, 'created': '2016-06-16 09:34:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b231b8b1793b305557b6abc1e44fb25564c3d98b', 'message': ""WIP experiment with the remainder of the placement API\n\nThis is a workspace for figuring out those parts of the placement\nAPI that have not been determined enough to have their own patches.\n\nMany gabbi tests have been marked xfail as a reference that there's\nstill work to be done in that area.\n\nCurrent issues:\n\n* allocations, aggregates and checks for usages are\n  currently broken, need commits below in the stack to get them\n  working again\n  * The usages URI now works, but there are no checks.\n* quite likely some more specific exceptions need to be raised in\n  the nova.objects used by the API\n* not really all that happy with webob nor its exceptions\n* will probably need to trap nova.exception.NotFound and re-raise as\n  a webob.exc (which is sort of hilariously circular)\n\nPartially-Implements: blueprint generic-resource-pools\nChange-Id: Ided59ecc3726c357ae76ce48251c066a5af20d0e\n""}, {'number': 67, 'created': '2016-06-16 12:13:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7c1d11e0a18f20fefe120b03d31b5a4b73beba52', 'message': ""WIP experiment with the remainder of the placement API\n\nThis is a workspace for figuring out those parts of the placement\nAPI that have not been determined enough to have their own patches.\n\nMany gabbi tests have been marked xfail as a reference that there's\nstill work to be done in that area.\n\nCurrent issues:\n\n* allocations, aggregates and checks for usages are\n  currently broken, need commits below in the stack to get them\n  working again\n  * The usages URI now works, but there are no checks.\n* quite likely some more specific exceptions need to be raised in\n  the nova.objects used by the API\n* not really all that happy with webob nor its exceptions\n* will probably need to trap nova.exception.NotFound and re-raise as\n  a webob.exc (which is sort of hilariously circular)\n\nPartially-Implements: blueprint generic-resource-pools\nChange-Id: Ided59ecc3726c357ae76ce48251c066a5af20d0e\n""}, {'number': 68, 'created': '2016-06-16 13:15:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5c91fde8df0f7b7a4afa5f38d3df9059b639ab20', 'message': ""WIP experiment with the remainder of the placement API\n\nThis is a workspace for figuring out those parts of the placement\nAPI that have not been determined enough to have their own patches.\n\nMany gabbi tests have been marked xfail as a reference that there's\nstill work to be done in that area.\n\nCurrent issues:\n\n* allocations, aggregates and checks for usages are\n  currently broken, need commits below in the stack to get them\n  working again\n  * The usages URI now works, but there are no checks.\n* quite likely some more specific exceptions need to be raised in\n  the nova.objects used by the API\n* not really all that happy with webob nor its exceptions\n* will probably need to trap nova.exception.NotFound and re-raise as\n  a webob.exc (which is sort of hilariously circular)\n\nPartially-Implements: blueprint generic-resource-pools\nChange-Id: Ided59ecc3726c357ae76ce48251c066a5af20d0e\n""}, {'number': 69, 'created': '2016-06-19 15:01:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9aff76fa8ff9f4f151241a68eefffaecc6908ee8', 'message': ""WIP experiment with the remainder of the placement API\n\nThis is a workspace for figuring out those parts of the placement\nAPI that have not been determined enough to have their own patches.\n\nMany gabbi tests have been marked xfail as a reference that there's\nstill work to be done in that area.\n\nCurrent issues:\n\n* allocations, aggregates and checks for usages are\n  currently broken, need commits below in the stack to get them\n  working again\n  * The usages URI now works, but there are no checks.\n* quite likely some more specific exceptions need to be raised in\n  the nova.objects used by the API\n* not really all that happy with webob nor its exceptions\n* will probably need to trap nova.exception.NotFound and re-raise as\n  a webob.exc (which is sort of hilariously circular)\n\nPartially-Implements: blueprint generic-resource-pools\nChange-Id: Ided59ecc3726c357ae76ce48251c066a5af20d0e\n""}, {'number': 70, 'created': '2016-06-27 22:01:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/52c45670b51e2d0497ef7abffae1e963c6ac6359', 'message': ""WIP experiment with the remainder of the placement API\n\nThis is a workspace for figuring out those parts of the placement\nAPI that have not been determined enough to have their own patches.\n\nMany gabbi tests have been marked xfail as a reference that there's\nstill work to be done in that area.\n\nCurrent issues:\n\n* allocations, aggregates and checks for usages are\n  currently broken, need commits below in the stack to get them\n  working again\n  * The usages URI now works, but there are no checks.\n* quite likely some more specific exceptions need to be raised in\n  the nova.objects used by the API\n* not really all that happy with webob nor its exceptions\n* will probably need to trap nova.exception.NotFound and re-raise as\n  a webob.exc (which is sort of hilariously circular)\n\nPartially-Implements: blueprint generic-resource-pools\nChange-Id: Ided59ecc3726c357ae76ce48251c066a5af20d0e\n""}, {'number': 71, 'created': '2016-06-27 22:04:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5dea254f5eb049a6fc95e4db859172300adc7ed7', 'message': ""WIP experiment with the remainder of the placement API\n\nThis is a workspace for figuring out those parts of the placement\nAPI that have not been determined enough to have their own patches.\n\nMany gabbi tests have been marked xfail as a reference that there's\nstill work to be done in that area.\n\nCurrent issues:\n\n* allocations, aggregates and checks for usages are\n  currently broken, need commits below in the stack to get them\n  working again\n  * The usages URI now works, but there are no checks.\n* quite likely some more specific exceptions need to be raised in\n  the nova.objects used by the API\n* not really all that happy with webob nor its exceptions\n* will probably need to trap nova.exception.NotFound and re-raise as\n  a webob.exc (which is sort of hilariously circular)\n\nPartially-Implements: blueprint generic-resource-pools\nChange-Id: Ided59ecc3726c357ae76ce48251c066a5af20d0e\n""}, {'number': 72, 'created': '2016-07-02 03:41:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7e9790589cde9b0b4c261efd798a22e03fd09de4', 'message': ""WIP experiment with the remainder of the placement API\n\nThis is a workspace for figuring out those parts of the placement\nAPI that have not been determined enough to have their own patches.\n\nMany gabbi tests have been marked xfail as a reference that there's\nstill work to be done in that area.\n\nCurrent issues:\n\n* allocations, aggregates and checks for usages are\n  currently broken, need commits below in the stack to get them\n  working again\n  * The usages URI now works, but there are no checks.\n* quite likely some more specific exceptions need to be raised in\n  the nova.objects used by the API\n* not really all that happy with webob nor its exceptions\n* will probably need to trap nova.exception.NotFound and re-raise as\n  a webob.exc (which is sort of hilariously circular)\n\nPartially-Implements: blueprint generic-resource-pools\nChange-Id: Ided59ecc3726c357ae76ce48251c066a5af20d0e\n""}, {'number': 73, 'created': '2016-07-02 22:55:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ae85ef59bca1deffb210866ec476326af1ef94f3', 'message': ""WIP experiment with the remainder of the placement API\n\nThis is a workspace for figuring out those parts of the placement\nAPI that have not been determined enough to have their own patches.\n\nMany gabbi tests have been marked xfail as a reference that there's\nstill work to be done in that area.\n\nCurrent issues:\n\n* allocations, aggregates and checks for usages are\n  currently broken, need commits below in the stack to get them\n  working again\n  * The usages URI now works, but there are no checks.\n* quite likely some more specific exceptions need to be raised in\n  the nova.objects used by the API\n* not really all that happy with webob nor its exceptions\n* will probably need to trap nova.exception.NotFound and re-raise as\n  a webob.exc (which is sort of hilariously circular)\n\nPartially-Implements: blueprint generic-resource-pools\nChange-Id: Ided59ecc3726c357ae76ce48251c066a5af20d0e\n""}, {'number': 74, 'created': '2016-07-04 16:34:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/56f9b0210b66c6b98c2b087869b2481989eb1163', 'message': ""WIP experiment with the remainder of the placement API\n\nThis is a workspace for figuring out those parts of the placement\nAPI that have not been determined enough to have their own patches.\n\nMany gabbi tests have been marked xfail as a reference that there's\nstill work to be done in that area.\n\nCurrent issues:\n\n* allocations, aggregates and checks for usages are\n  currently broken, need commits below in the stack to get them\n  working again\n  * The usages URI now works, but there are no checks.\n* quite likely some more specific exceptions need to be raised in\n  the nova.objects used by the API\n* not really all that happy with webob nor its exceptions\n* will probably need to trap nova.exception.NotFound and re-raise as\n  a webob.exc (which is sort of hilariously circular)\n\nPartially-Implements: blueprint generic-resource-pools\nChange-Id: Ided59ecc3726c357ae76ce48251c066a5af20d0e\n""}, {'number': 75, 'created': '2016-07-04 20:21:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/37b79b669c2475d5673b079ee562ffd594a7ce17', 'message': ""WIP experiment with the remainder of the placement API\n\nThis is a workspace for figuring out those parts of the placement\nAPI that have not been determined enough to have their own patches.\n\nMany gabbi tests have been marked xfail as a reference that there's\nstill work to be done in that area.\n\nCurrent issues:\n\n* allocations, aggregates and checks for usages are\n  currently broken, need commits below in the stack to get them\n  working again\n  * The usages URI now works, but there are no checks.\n* quite likely some more specific exceptions need to be raised in\n  the nova.objects used by the API\n* not really all that happy with webob nor its exceptions\n* will probably need to trap nova.exception.NotFound and re-raise as\n  a webob.exc (which is sort of hilariously circular)\n\nPartially-Implements: blueprint generic-resource-pools\nChange-Id: Ided59ecc3726c357ae76ce48251c066a5af20d0e\n""}, {'number': 76, 'created': '2016-07-05 20:27:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2ababe661bc24ae485475a8473e49c78a63cb6ee', 'message': ""WIP experiment with the remainder of the placement API\n\nThis is a workspace for figuring out those parts of the placement\nAPI that have not been determined enough to have their own patches.\n\nMany gabbi tests have been marked xfail as a reference that there's\nstill work to be done in that area.\n\nCurrent issues:\n\n* allocations, aggregates and checks for usages are\n  currently broken, need commits below in the stack to get them\n  working again\n  * The usages URI now works, but there are no checks.\n* quite likely some more specific exceptions need to be raised in\n  the nova.objects used by the API\n* not really all that happy with webob nor its exceptions\n* will probably need to trap nova.exception.NotFound and re-raise as\n  a webob.exc (which is sort of hilariously circular)\n\nPartially-Implements: blueprint generic-resource-pools\nChange-Id: Ided59ecc3726c357ae76ce48251c066a5af20d0e\n""}, {'number': 77, 'created': '2016-07-05 22:39:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8924474ac961cc161eddd16fa1ea7749308d7343', 'message': ""WIP experiment with the remainder of the placement API\n\nThis is a workspace for figuring out those parts of the placement\nAPI that have not been determined enough to have their own patches.\n\nMany gabbi tests have been marked xfail as a reference that there's\nstill work to be done in that area.\n\nCurrent issues:\n\n* allocations, aggregates and checks for usages are\n  currently broken, need commits below in the stack to get them\n  working again\n  * The usages URI now works, but there are no checks.\n* quite likely some more specific exceptions need to be raised in\n  the nova.objects used by the API\n* not really all that happy with webob nor its exceptions\n* will probably need to trap nova.exception.NotFound and re-raise as\n  a webob.exc (which is sort of hilariously circular)\n\nPartially-Implements: blueprint generic-resource-pools\nChange-Id: Ided59ecc3726c357ae76ce48251c066a5af20d0e\n""}, {'number': 78, 'created': '2016-07-06 00:11:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/01c7c32465d0f0620c21d78b0e90842b97970e41', 'message': ""WIP experiment with the remainder of the placement API\n\nThis is a workspace for figuring out those parts of the placement\nAPI that have not been determined enough to have their own patches.\n\nMany gabbi tests have been marked xfail as a reference that there's\nstill work to be done in that area.\n\nCurrent issues:\n\n* allocations, aggregates and checks for usages are\n  currently broken, need commits below in the stack to get them\n  working again\n  * The usages URI now works, but there are no checks.\n* quite likely some more specific exceptions need to be raised in\n  the nova.objects used by the API\n* not really all that happy with webob nor its exceptions\n* will probably need to trap nova.exception.NotFound and re-raise as\n  a webob.exc (which is sort of hilariously circular)\n\nPartially-Implements: blueprint generic-resource-pools\nChange-Id: Ided59ecc3726c357ae76ce48251c066a5af20d0e\n""}, {'number': 79, 'created': '2016-07-06 00:22:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/25a64a926bc6219e3555f9e7c109f66d6253eace', 'message': ""WIP experiment with the remainder of the placement API\n\nThis is a workspace for figuring out those parts of the placement\nAPI that have not been determined enough to have their own patches.\n\nMany gabbi tests have been marked xfail as a reference that there's\nstill work to be done in that area.\n\nCurrent issues:\n\n* allocations, aggregates and checks for usages are\n  currently broken, need commits below in the stack to get them\n  working again\n  * The usages URI now works, but there are no checks.\n* quite likely some more specific exceptions need to be raised in\n  the nova.objects used by the API\n* not really all that happy with webob nor its exceptions\n* will probably need to trap nova.exception.NotFound and re-raise as\n  a webob.exc (which is sort of hilariously circular)\n\nPartially-Implements: blueprint generic-resource-pools\nChange-Id: Ided59ecc3726c357ae76ce48251c066a5af20d0e\n""}, {'number': 80, 'created': '2016-07-06 17:21:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8de08888f1f160663ee89d4fc1c4725f12a3b9be', 'message': ""WIP experiment with the remainder of the placement API\n\nThis is a workspace for figuring out those parts of the placement\nAPI that have not been determined enough to have their own patches.\n\nMany gabbi tests have been marked xfail as a reference that there's\nstill work to be done in that area.\n\nCurrent issues:\n\n* allocations, aggregates and checks for usages are\n  currently broken, need commits below in the stack to get them\n  working again\n  * The usages URI now works, but there are no checks.\n* quite likely some more specific exceptions need to be raised in\n  the nova.objects used by the API\n* not really all that happy with webob nor its exceptions\n* will probably need to trap nova.exception.NotFound and re-raise as\n  a webob.exc (which is sort of hilariously circular)\n\nPartially-Implements: blueprint generic-resource-pools\nChange-Id: Ided59ecc3726c357ae76ce48251c066a5af20d0e\n""}, {'number': 81, 'created': '2016-07-07 23:44:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f721db62d8c3aae4dbdf4d8ec84094fa482fd060', 'message': ""WIP experiment with the remainder of the placement API\n\nThis is a workspace for figuring out those parts of the placement\nAPI that have not been determined enough to have their own patches.\n\nMany gabbi tests have been marked xfail as a reference that there's\nstill work to be done in that area.\n\nCurrent issues:\n\n* allocations, aggregates and checks for usages are\n  currently broken, need commits below in the stack to get them\n  working again\n  * The usages URI now works, but there are no checks.\n* quite likely some more specific exceptions need to be raised in\n  the nova.objects used by the API\n* not really all that happy with webob nor its exceptions\n* will probably need to trap nova.exception.NotFound and re-raise as\n  a webob.exc (which is sort of hilariously circular)\n\nPartially-Implements: blueprint generic-resource-pools\nChange-Id: Ided59ecc3726c357ae76ce48251c066a5af20d0e\n""}, {'number': 82, 'created': '2016-07-08 00:04:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f765e71be91b3b330febf721565e5f35ffe3754e', 'message': ""WIP experiment with the remainder of the placement API\n\nThis is a workspace for figuring out those parts of the placement\nAPI that have not been determined enough to have their own patches.\n\nMany gabbi tests have been marked xfail as a reference that there's\nstill work to be done in that area.\n\nCurrent issues:\n\n* allocations, aggregates and checks for usages are\n  currently broken, need commits below in the stack to get them\n  working again\n  * The usages URI now works, but there are no checks.\n* quite likely some more specific exceptions need to be raised in\n  the nova.objects used by the API\n* not really all that happy with webob nor its exceptions\n* will probably need to trap nova.exception.NotFound and re-raise as\n  a webob.exc (which is sort of hilariously circular)\n\nPartially-Implements: blueprint generic-resource-pools\nChange-Id: Ided59ecc3726c357ae76ce48251c066a5af20d0e\n""}, {'number': 83, 'created': '2016-07-08 00:09:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/899b809ce505886b5b2c38c096173fe7d1388c2e', 'message': ""WIP experiment with the remainder of the placement API\n\nThis is a workspace for figuring out those parts of the placement\nAPI that have not been determined enough to have their own patches.\n\nMany gabbi tests have been marked xfail as a reference that there's\nstill work to be done in that area.\n\nCurrent issues:\n\n* allocations, aggregates and checks for usages are\n  currently broken, need commits below in the stack to get them\n  working again\n  * The usages URI now works, but there are no checks.\n* quite likely some more specific exceptions need to be raised in\n  the nova.objects used by the API\n* not really all that happy with webob nor its exceptions\n* will probably need to trap nova.exception.NotFound and re-raise as\n  a webob.exc (which is sort of hilariously circular)\n\nPartially-Implements: blueprint generic-resource-pools\nChange-Id: Ided59ecc3726c357ae76ce48251c066a5af20d0e\n""}, {'number': 84, 'created': '2016-07-09 02:20:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b12adb3dc1935fca297427ad52277dffe4c7adcf', 'message': ""WIP experiment with the remainder of the placement API\n\nThis is a workspace for figuring out those parts of the placement\nAPI that have not been determined enough to have their own patches.\n\nMany gabbi tests have been marked xfail as a reference that there's\nstill work to be done in that area.\n\nCurrent issues:\n\n* aggregates and checks for usages are\n  currently broken, need commits below in the stack to get them\n  working again\n  * The usages URI now works, but there are no checks.\n* quite likely some more specific exceptions need to be raised in\n  the nova.objects used by the API\n* not really all that happy with webob nor its exceptions\n* will probably need to trap nova.exception.NotFound and re-raise as\n  a webob.exc (which is sort of hilariously circular)\n\nPartially-Implements: blueprint generic-resource-pools\nChange-Id: Ided59ecc3726c357ae76ce48251c066a5af20d0e\n""}, {'number': 85, 'created': '2016-07-11 22:31:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/36d6a096c2a8453e96ec65aef9a14f20bef80292', 'message': ""WIP experiment with the remainder of the placement API\n\nThis is a workspace for figuring out those parts of the placement\nAPI that have not been determined enough to have their own patches.\n\nMany gabbi tests have been marked xfail as a reference that there's\nstill work to be done in that area.\n\nCurrent issues:\n\n* aggregates are currently broken, need commits below in the stack\n  to get them working again\n* not really all that happy with webob nor its exceptions\n* will probably need to trap nova.exception.NotFound and re-raise as\n  a webob.exc (which is sort of hilariously circular)\n\nPartially-Implements: blueprint generic-resource-pools\nChange-Id: Ided59ecc3726c357ae76ce48251c066a5af20d0e\n""}, {'number': 86, 'created': '2016-07-11 23:05:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/91e85796009b71c7fa16f2655f86a68993ce5f84', 'message': ""WIP experiment with the remainder of the placement API\n\nThis is a workspace for figuring out those parts of the placement\nAPI that have not been determined enough to have their own patches.\n\nMany gabbi tests have been marked xfail as a reference that there's\nstill work to be done in that area.\n\nCurrent issues:\n\n* aggregates are currently broken, need commits below in the stack\n  to get them working again\n* not really all that happy with webob nor its exceptions\n* will probably need to trap nova.exception.NotFound and re-raise as\n  a webob.exc (which is sort of hilariously circular)\n\nPartially-Implements: blueprint generic-resource-pools\nChange-Id: Ided59ecc3726c357ae76ce48251c066a5af20d0e\n""}, {'number': 87, 'created': '2016-07-12 01:14:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/09f8e0a6703d51395c5877a9193d615be7cc28fd', 'message': ""WIP experiment with the remainder of the placement API\n\nThis is a workspace for figuring out those parts of the placement\nAPI that have not been determined enough to have their own patches.\n\nMany gabbi tests have been marked xfail as a reference that there's\nstill work to be done in that area.\n\nCurrent issues:\n\n* aggregates are currently broken, need commits below in the stack\n  to get them working again\n* not really all that happy with webob nor its exceptions\n* will probably need to trap nova.exception.NotFound and re-raise as\n  a webob.exc (which is sort of hilariously circular)\n\nPartially-Implements: blueprint generic-resource-pools\nChange-Id: Ided59ecc3726c357ae76ce48251c066a5af20d0e\n""}, {'number': 88, 'created': '2016-07-12 04:21:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/58a47928b00c9984aaeb1785cb608bd58e533f15', 'message': ""WIP experiment with the remainder of the placement API\n\nThis is a workspace for figuring out those parts of the placement\nAPI that have not been determined enough to have their own patches.\n\nMany gabbi tests have been marked xfail as a reference that there's\nstill work to be done in that area.\n\nCurrent issues:\n\n* aggregates are currently broken, need commits below in the stack\n  to get them working again\n* not really all that happy with webob nor its exceptions\n* will probably need to trap nova.exception.NotFound and re-raise as\n  a webob.exc (which is sort of hilariously circular)\n\nPartially-Implements: blueprint generic-resource-pools\nChange-Id: Ided59ecc3726c357ae76ce48251c066a5af20d0e\n""}, {'number': 89, 'created': '2016-07-12 16:06:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/292f15491099d554a8775632b7e93649123a4297', 'message': ""WIP experiment with the remainder of the placement API\n\nThis is a workspace for figuring out those parts of the placement\nAPI that have not been determined enough to have their own patches.\n\nMany gabbi tests have been marked xfail as a reference that there's\nstill work to be done in that area.\n\nCurrent issues:\n\n* aggregates are currently broken, need commits below in the stack\n  to get them working again\n* not really all that happy with webob nor its exceptions\n* will probably need to trap nova.exception.NotFound and re-raise as\n  a webob.exc (which is sort of hilariously circular)\n\nPartially-Implements: blueprint generic-resource-pools\nChange-Id: Ided59ecc3726c357ae76ce48251c066a5af20d0e\n""}, {'number': 90, 'created': '2016-07-12 19:45:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/af8946ed96df6d29d685b140f4c66c1e5f645751', 'message': ""WIP experiment with the remainder of the placement API\n\nThis is a workspace for figuring out those parts of the placement\nAPI that have not been determined enough to have their own patches.\n\nThis also adds a wsgi app for running under apache2 and other wsgi\ncontainers and the necessary service config settings.\n\nMany gabbi tests have been marked xfail as a reference that there's\nstill work to be done in that area.\n\nCurrent issues:\n\n* aggregates are currently broken, need commits below in the stack\n  to get them working again\n* not really all that happy with webob nor its exceptions\n* will probably need to trap nova.exception.NotFound and re-raise as\n  a webob.exc (which is sort of hilariously circular)\n* the conf settings are in nova services\n\nPartially-Implements: blueprint generic-resource-pools\nChange-Id: Ided59ecc3726c357ae76ce48251c066a5af20d0e\n""}, {'number': 91, 'created': '2016-07-13 02:19:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/18a7ed4410a74907533272a698769a0a28e151be', 'message': ""WIP experiment with the remainder of the placement API\n\nThis is a workspace for figuring out those parts of the placement\nAPI that have not been determined enough to have their own patches.\n\nThis also adds a wsgi app for running under apache2 and other wsgi\ncontainers and the necessary service config settings.\n\nMany gabbi tests have been marked xfail as a reference that there's\nstill work to be done in that area.\n\nCurrent issues:\n\n* aggregates are currently broken, need commits below in the stack\n  to get them working again\n* not really all that happy with webob nor its exceptions\n* will probably need to trap nova.exception.NotFound and re-raise as\n  a webob.exc (which is sort of hilariously circular)\n* the conf settings are in nova services\n\nPartially-Implements: blueprint generic-resource-pools\nChange-Id: Ided59ecc3726c357ae76ce48251c066a5af20d0e\n""}, {'number': 92, 'created': '2016-07-13 03:48:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/202cc0b1b12d91e9f135f342e9d0e98eab9b8026', 'message': ""WIP experiment with the remainder of the placement API\n\nThis is a workspace for figuring out those parts of the placement\nAPI that have not been determined enough to have their own patches.\n\nThis also adds a wsgi app for running under apache2 and other wsgi\ncontainers and the necessary service config settings.\n\nMany gabbi tests have been marked xfail as a reference that there's\nstill work to be done in that area.\n\nCurrent issues:\n\n* aggregates are currently broken, need commits below in the stack\n  to get them working again\n* not really all that happy with webob nor its exceptions\n* will probably need to trap nova.exception.NotFound and re-raise as\n  a webob.exc (which is sort of hilariously circular)\n* the conf settings are in nova services\n\nPartially-Implements: blueprint generic-resource-pools\nChange-Id: Ided59ecc3726c357ae76ce48251c066a5af20d0e\n""}, {'number': 93, 'created': '2016-07-13 18:57:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a7cfbf862b592b3e68502af6b31aade52c51a473', 'message': ""WIP experiment with the remainder of the placement API\n\nThis is a workspace for figuring out those parts of the placement\nAPI that have not been determined enough to have their own patches.\n\nThis also adds a wsgi app for running under apache2 and other wsgi\ncontainers and the necessary service config settings.\n\nMany gabbi tests have been marked xfail as a reference that there's\nstill work to be done in that area.\n\nCurrent issues:\n\n* aggregates are currently broken, need commits below in the stack\n  to get them working again\n* not really all that happy with webob nor its exceptions\n* will probably need to trap nova.exception.NotFound and re-raise as\n  a webob.exc (which is sort of hilariously circular)\n* the conf settings are in nova services\n\nPartially-Implements: blueprint generic-resource-pools\nChange-Id: Ided59ecc3726c357ae76ce48251c066a5af20d0e\n""}, {'number': 94, 'created': '2016-07-13 19:29:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/968d91f6ccb2968d8c4f7bf99967288dbad90db6', 'message': ""WIP experiment with the remainder of the placement API\n\nThis is a workspace for figuring out those parts of the placement\nAPI that have not been determined enough to have their own patches.\n\nThis also adds a wsgi app for running under apache2 and other wsgi\ncontainers and the necessary service config settings.\n\nMany gabbi tests have been marked xfail as a reference that there's\nstill work to be done in that area.\n\nCurrent issues:\n\n* aggregates are currently broken, need commits below in the stack\n  to get them working again\n* not really all that happy with webob nor its exceptions\n* will probably need to trap nova.exception.NotFound and re-raise as\n  a webob.exc (which is sort of hilariously circular)\n* the conf settings are in nova services\n\nPartially-Implements: blueprint generic-resource-pools\nChange-Id: Ided59ecc3726c357ae76ce48251c066a5af20d0e\n""}, {'number': 95, 'created': '2016-07-15 23:42:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2c2b5c8059f9241a1c44f3d8b3f51a9e1e17649d', 'message': ""WIP experiment with the remainder of the placement API\n\nThis is a workspace for figuring out those parts of the placement\nAPI that have not been determined enough to have their own patches.\n\nThis also adds a wsgi app for running under apache2 and other wsgi\ncontainers and the necessary service config settings.\n\nMany gabbi tests have been marked xfail as a reference that there's\nstill work to be done in that area.\n\nCurrent issues:\n\n* aggregates are currently broken, need commits below in the stack\n  to get them working again\n* not really all that happy with webob nor its exceptions\n* will probably need to trap nova.exception.NotFound and re-raise as\n  a webob.exc (which is sort of hilariously circular)\n* the conf settings are in nova services\n\nPartially-Implements: blueprint generic-resource-pools\nChange-Id: Ided59ecc3726c357ae76ce48251c066a5af20d0e\n""}, {'number': 96, 'created': '2016-07-21 19:59:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0e1a770adaf5f498f813b83862931e270ddf0c67', 'message': ""WIP experiment with the remainder of the placement API\n\nThis is a workspace for figuring out those parts of the placement\nAPI that have not been determined enough to have their own patches.\n\nThis also adds a wsgi app for running under apache2 and other wsgi\ncontainers and the necessary service config settings.\n\nMany gabbi tests have been marked xfail as a reference that there's\nstill work to be done in that area.\n\nCurrent issues:\n\n* aggregates are currently broken, need commits below in the stack\n  to get them working again\n* missing non-gabbi tests\n\nPartially-Implements: blueprint generic-resource-pools\nChange-Id: Ided59ecc3726c357ae76ce48251c066a5af20d0e\n""}, {'number': 97, 'created': '2016-07-22 02:39:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/478761bd80e20730a96d05ab15b95756064d37fb', 'message': ""WIP experiment with the remainder of the placement API\n\nThis is a workspace for figuring out those parts of the placement\nAPI that have not been determined enough to have their own patches.\n\nThis also adds a wsgi app for running under apache2 and other wsgi\ncontainers and the necessary service config settings.\n\nMany gabbi tests have been marked xfail as a reference that there's\nstill work to be done in that area.\n\nCurrent issues:\n\n* aggregates are currently broken, need commits below in the stack\n  to get them working again\n* missing non-gabbi tests\n\nPartially-Implements: blueprint generic-resource-pools\nChange-Id: Ided59ecc3726c357ae76ce48251c066a5af20d0e\n""}, {'number': 98, 'created': '2016-07-25 14:45:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/54ec9aa6fcf928a8c3503c5d30baa1010281a03f', 'message': ""WIP experiment with the remainder of the placement API\n\nThis is a workspace for figuring out those parts of the placement\nAPI that have not been determined enough to have their own patches.\n\nThis also adds a wsgi app for running under apache2 and other wsgi\ncontainers and the necessary service config settings.\n\nMany gabbi tests have been marked xfail as a reference that there's\nstill work to be done in that area.\n\nCurrent issues:\n\n* aggregates are currently broken, need commits below in the stack\n  to get them working again\n* missing non-gabbi tests\n\nPartially-Implements: blueprint generic-resource-pools\nChange-Id: Ided59ecc3726c357ae76ce48251c066a5af20d0e\n""}, {'number': 99, 'created': '2016-07-28 11:25:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d9a1ceb1b6767bd742c94ddd66e9d2146d8bb990', 'message': ""WIP experiment with the remainder of the placement API\n\nThis is a workspace for figuring out those parts of the placement\nAPI that have not been determined enough to have their own patches.\n\nThis also adds a wsgi app for running under apache2 and other wsgi\ncontainers and the necessary service config settings.\n\nMany gabbi tests have been marked xfail as a reference that there's\nstill work to be done in that area.\n\nCurrent issues:\n\n* aggregates are currently broken, need commits below in the stack\n  to get them working again\n* missing non-gabbi tests\n\nPartially-Implements: blueprint generic-resource-pools\nChange-Id: Ided59ecc3726c357ae76ce48251c066a5af20d0e\n""}, {'number': 100, 'created': '2016-07-28 18:35:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/41e0fb7ebca7a432574a0604522b5b969cd94f2f', 'message': ""WIP experiment with the remainder of the placement API\n\nThis is a workspace for figuring out those parts of the placement\nAPI that have not been determined enough to have their own patches.\n\nThis also adds a wsgi app for running under apache2 and other wsgi\ncontainers and the necessary service config settings.\n\nMany gabbi tests have been marked xfail as a reference that there's\nstill work to be done in that area.\n\nCurrent issues:\n\n* aggregates are currently broken, need commits below in the stack\n  to get them working again\n* missing non-gabbi tests\n\nPartially-Implements: blueprint generic-resource-pools\nChange-Id: Ided59ecc3726c357ae76ce48251c066a5af20d0e\n""}, {'number': 101, 'created': '2016-07-28 20:21:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1ce65dc32f74dca66d953e8f5aa9bf674cf6bdb2', 'message': ""WIP experiment with the remainder of the placement API\n\nThis is a workspace for figuring out those parts of the placement\nAPI that have not been determined enough to have their own patches.\n\nThis also adds a wsgi app for running under apache2 and other wsgi\ncontainers and the necessary service config settings.\n\nMany gabbi tests have been marked xfail as a reference that there's\nstill work to be done in that area.\n\nCurrent issues:\n\n* aggregates are currently broken, need commits below in the stack\n  to get them working again\n* missing non-gabbi tests\n\nPartially-Implements: blueprint generic-resource-pools\nChange-Id: Ided59ecc3726c357ae76ce48251c066a5af20d0e\n""}, {'number': 102, 'created': '2016-08-01 11:08:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a55a913bdb278ca88dc2e1f722ca9718702e95a2', 'message': ""WIP experiment with the remainder of the placement API\n\nThis is a workspace for figuring out those parts of the placement\nAPI that have not been determined enough to have their own patches.\n\nThis also adds a wsgi app for running under apache2 and other wsgi\ncontainers and the necessary service config settings.\n\nMany gabbi tests have been marked xfail as a reference that there's\nstill work to be done in that area.\n\nCurrent issues:\n\n* aggregates are currently broken, need commits below in the stack\n  to get them working again\n* missing non-gabbi tests\n\nPartially-Implements: blueprint generic-resource-pools\nChange-Id: Ided59ecc3726c357ae76ce48251c066a5af20d0e\n""}, {'number': 103, 'created': '2016-08-05 13:24:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ba231141a7900fd30013e8decf052287e5d2f453', 'message': ""WIP experiment with the remainder of the placement API\n\nThis is a workspace for figuring out those parts of the placement\nAPI that have not been determined enough to have their own patches.\n\nThis also adds a wsgi app for running under apache2 and other wsgi\ncontainers and the necessary service config settings.\n\nMany gabbi tests have been marked xfail as a reference that there's\nstill work to be done in that area.\n\nCurrent issues:\n\n* aggregates are currently broken, need commits below in the stack\n  to get them working again\n* missing non-gabbi tests\n\nPartially-Implements: blueprint generic-resource-pools\nChange-Id: Ided59ecc3726c357ae76ce48251c066a5af20d0e\n""}, {'number': 104, 'created': '2016-08-05 15:31:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ecb87696999e5293976e768db8a48bb5dce11049', 'message': ""WIP experiment with the remainder of the placement API\n\nThis is a workspace for figuring out those parts of the placement\nAPI that have not been determined enough to have their own patches.\n\nThis also adds a wsgi app for running under apache2 and other wsgi\ncontainers and the necessary service config settings.\n\nMany gabbi tests have been marked xfail as a reference that there's\nstill work to be done in that area.\n\nCurrent issues:\n\n* aggregates are currently broken, need commits below in the stack\n  to get them working again\n* missing non-gabbi tests\n\nPartially-Implements: blueprint generic-resource-pools\nChange-Id: Ided59ecc3726c357ae76ce48251c066a5af20d0e\n""}, {'number': 105, 'created': '2016-08-05 18:09:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/16891b274e63beec97b4418b6b5b63f7b32802c7', 'message': ""WIP experiment with the remainder of the placement API\n\nThis is a workspace for figuring out those parts of the placement\nAPI that have not been determined enough to have their own patches.\n\nThis also adds a wsgi app for running under apache2 and other wsgi\ncontainers and the necessary service config settings.\n\nMany gabbi tests have been marked xfail as a reference that there's\nstill work to be done in that area.\n\nCurrent issues:\n\n* aggregates are currently broken, need commits below in the stack\n  to get them working again\n* missing non-gabbi tests\n\nPartially-Implements: blueprint generic-resource-pools\nChange-Id: Ided59ecc3726c357ae76ce48251c066a5af20d0e\n""}, {'number': 106, 'created': '2016-08-06 11:37:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8afa54977ea96118efd905d816cf5adb7ba9bcab', 'message': ""WIP experiment with the remainder of the placement API\n\nThis is a workspace for figuring out those parts of the placement\nAPI that have not been determined enough to have their own patches.\n\nThis also adds a wsgi app for running under apache2 and other wsgi\ncontainers and the necessary service config settings.\n\nMany gabbi tests have been marked xfail as a reference that there's\nstill work to be done in that area.\n\nCurrent issues:\n\n* aggregates are currently broken, need commits below in the stack\n  to get them working again\n* missing non-gabbi tests\n\nPartially-Implements: blueprint generic-resource-pools\nChange-Id: Ided59ecc3726c357ae76ce48251c066a5af20d0e\n""}, {'number': 107, 'created': '2016-08-08 09:49:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/96b9c1a9cc75590cafc00d650045a7bc67938438', 'message': ""WIP experiment with the remainder of the placement API\n\nThis is a workspace for figuring out those parts of the placement\nAPI that have not been determined enough to have their own patches.\n\nThis also adds a wsgi app for running under apache2 and other wsgi\ncontainers and the necessary service config settings.\n\nMany gabbi tests have been marked xfail as a reference that there's\nstill work to be done in that area.\n\nCurrent issues:\n\n* aggregates are currently broken, need commits below in the stack\n  to get them working again\n* missing non-gabbi tests\n\nPartially-Implements: blueprint generic-resource-pools\nChange-Id: Ided59ecc3726c357ae76ce48251c066a5af20d0e\n""}, {'number': 108, 'created': '2016-08-08 12:53:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0e67f96d7aa5e13ee331ce039f1e84f856c258b8', 'message': ""WIP experiment with the remainder of the placement API\n\nThis is a workspace for figuring out those parts of the placement\nAPI that have not been determined enough to have their own patches.\n\nThis also adds a wsgi app for running under apache2 and other wsgi\ncontainers and the necessary service config settings.\n\nMany gabbi tests have been marked xfail as a reference that there's\nstill work to be done in that area.\n\nCurrent issues:\n\n* aggregates are currently broken, need commits below in the stack\n  to get them working again\n* missing non-gabbi tests\n\nPartially-Implements: blueprint generic-resource-pools\nChange-Id: Ided59ecc3726c357ae76ce48251c066a5af20d0e\n""}, {'number': 109, 'created': '2016-08-08 19:31:55.000000000', 'files': ['nova/wsgi/placement-api.py', 'nova/api/openstack/placement/handlers/aggregate.py', 'nova/tests/functional/api/openstack/placement/gabbits/with-allocations.yaml', 'nova/tests/functional/api/openstack/placement/gabbits/aggregate.yaml', 'nova/api/openstack/placement/handler.py', 'nova/conf/service.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/470777a4cc1c88a4814108e5ed0d0d6fec77e0ab', 'message': ""WIP experiment with the remainder of the placement API\n\nThis is a workspace for figuring out those parts of the placement\nAPI that have not been determined enough to have their own patches.\n\nThis also adds a wsgi app for running under apache2 and other wsgi\ncontainers and the necessary service config settings.\n\nMany gabbi tests have been marked xfail as a reference that there's\nstill work to be done in that area.\n\nCurrent issues:\n\n* aggregates are currently broken, need commits below in the stack\n  to get them working again\n* missing non-gabbi tests\n\nPartially-Implements: blueprint generic-resource-pools\nChange-Id: Ided59ecc3726c357ae76ce48251c066a5af20d0e\n""}]",20,293104,470777a4cc1c88a4814108e5ed0d0d6fec77e0ab,936,24,109,11564,,,0,"WIP experiment with the remainder of the placement API

This is a workspace for figuring out those parts of the placement
API that have not been determined enough to have their own patches.

This also adds a wsgi app for running under apache2 and other wsgi
containers and the necessary service config settings.

Many gabbi tests have been marked xfail as a reference that there's
still work to be done in that area.

Current issues:

* aggregates are currently broken, need commits below in the stack
  to get them working again
* missing non-gabbi tests

Partially-Implements: blueprint generic-resource-pools
Change-Id: Ided59ecc3726c357ae76ce48251c066a5af20d0e
",git fetch https://review.opendev.org/openstack/nova refs/changes/04/293104/57 && git format-patch -1 --stdout FETCH_HEAD,"['placement.yaml', 'nova/api/openstack/placement/__init__.py', 'etc/nova/api-paste.ini', 'nova/api/openstack/placement/handler.py', 'setup.cfg', 'nova/cmd/placement_api.py']",6,6571da453ac88d7a915fcb38accc61f8108d8ac3,bp/generic-resource-pools,"# Licensed under the Apache License, Version 2.0 (the ""License""); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. """"""Starter script for Placement API."""""" import sys from oslo_config import cfg from oslo_log import log as logging from oslo_reports import guru_meditation_report as gmr from nova import config from nova import objects from nova import service from nova import utils from nova import version CONF = cfg.CONF CONF.import_opt('enabled_ssl_apis', 'nova.service') def main(): config.parse_args(sys.argv) logging.setup(CONF, ""nova"") utils.monkey_patch() objects.register_all() api_name = 'placement' gmr.TextGuruMeditation.setup_autorun(version) launcher = service.process_launcher() should_use_ssl = api_name in CONF.enabled_ssl_apis server = service.WSGIService(api_name, use_ssl=should_use_ssl) launcher.launch_service(server, workers=server.workers or 1) launcher.wait() ",,230,0
openstack%2Fneutron-fwaas~master~I894cf28910c0969a8f7920f5b34c34ca0d5658b2,openstack/neutron-fwaas,master,I894cf28910c0969a8f7920f5b34c34ca0d5658b2,Use temporary directory for neutron install,MERGED,2016-08-28 15:56:41.000000000,2016-08-29 10:15:31.000000000,2016-08-29 10:15:31.000000000,"[{'_account_id': 3}, {'_account_id': 9656}, {'_account_id': 13995}]","[{'number': 1, 'created': '2016-08-28 15:56:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-fwaas/commit/c05dc9dc810646547d110dd4aa3a9a6e485c8092', 'message': 'Use temporary directory for neutron install\n\nDo not install in /tmp/openstack/neutron and leave the git repository\nthere after the script is run - if zuul-cloner is used.\n\nWe run jobs on long lived workers and also on developers machines, let\'s\ncleanup afterwards.\n\nInstall into a temporary directory that can be removed with ""git clean""\nafterwards. Add this directory to ignore list of pep8.\n\nSimplify with using pushd/popd which are bash features, so change\nshe-bang.\n\nAlso, remove setup of ZUUL_BRANCH, this is not needed with current zuul\nanymore.\n\nMove over some changes from neutron-lbaas so that these two are in sync.\n\nChange-Id: I894cf28910c0969a8f7920f5b34c34ca0d5658b2\n'}, {'number': 2, 'created': '2016-08-28 17:11:21.000000000', 'files': ['tools/tox_install.sh', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/neutron-fwaas/commit/82473d3d9317d9f5267d2550996f2ea20b030c75', 'message': 'Use temporary directory for neutron install\n\nDo not install in /tmp/openstack/neutron and leave the git repository\nthere after the script is run - if zuul-cloner is used.\n\nWe run jobs on long lived workers and also on developers machines, let\'s\ncleanup afterwards.\n\nInstall into a temporary directory that can be removed with ""git clean""\nafterwards. Add this directory to ignore list of pep8.\n\nSimplify with using pushd/popd which are bash features, so change\nshe-bang.\n\nAlso, remove setup of ZUUL_BRANCH, this is not needed with current zuul\nanymore.\n\nMove over some changes from neutron-lbaas so that these two are in sync.\n\nChange-Id: I894cf28910c0969a8f7920f5b34c34ca0d5658b2\n'}]",1,361755,82473d3d9317d9f5267d2550996f2ea20b030c75,9,3,2,6547,,,0,"Use temporary directory for neutron install

Do not install in /tmp/openstack/neutron and leave the git repository
there after the script is run - if zuul-cloner is used.

We run jobs on long lived workers and also on developers machines, let's
cleanup afterwards.

Install into a temporary directory that can be removed with ""git clean""
afterwards. Add this directory to ignore list of pep8.

Simplify with using pushd/popd which are bash features, so change
she-bang.

Also, remove setup of ZUUL_BRANCH, this is not needed with current zuul
anymore.

Move over some changes from neutron-lbaas so that these two are in sync.

Change-Id: I894cf28910c0969a8f7920f5b34c34ca0d5658b2
",git fetch https://review.opendev.org/openstack/neutron-fwaas refs/changes/55/361755/2 && git format-patch -1 --stdout FETCH_HEAD,"['tools/tox_install.sh', 'tox.ini']",2,c05dc9dc810646547d110dd4aa3a9a6e485c8092,tox_install,"exclude = .venv,.git,.tox,dist,doc,*lib/python*,.tmp,*egg,build,tools,.ropeproject,rally-scenarios","exclude = .venv,.git,.tox,dist,doc,*lib/python*,*egg,build,tools,.ropeproject,rally-scenarios",19,7
openstack%2Fkolla~master~Ie6480a1954f853f79faffa093452715ebd9f7d90,openstack/kolla,master,Ie6480a1954f853f79faffa093452715ebd9f7d90,Change source with dot at extend_start files,MERGED,2016-08-24 14:33:57.000000000,2016-08-29 10:15:24.000000000,2016-08-29 10:15:24.000000000,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 1390}, {'_account_id': 2834}, {'_account_id': 11105}, {'_account_id': 11869}, {'_account_id': 13671}]","[{'number': 1, 'created': '2016-08-24 14:33:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/b5e2d6f6e06f7d2def5bfb963c938be04fcd399f', 'message': 'Change source with dot at extend_start files\n\nIs a best practice in Unix/Linux scripts to use dots\ninstead of source command.\nUsing dots will avoid issues with non BASH shells\n\nTrivialFix\nChange-Id: Ie6480a1954f853f79faffa093452715ebd9f7d90\nSigned-off-by: Eduardo Gonzalez <dabarren@gmail.com>\n'}, {'number': 2, 'created': '2016-08-29 05:31:28.000000000', 'files': ['docker/heat/heat-base/extend_start.sh', 'docker/base/start.sh', 'docker/designate/designate-base/extend_start.sh', 'docker/horizon/extend_start.sh', 'docker/manila/manila-base/extend_start.sh', 'docker/neutron/neutron-base/extend_start.sh', 'docker/keystone/keystone/extend_start.sh', 'docker/nova/nova-base/extend_start.sh', 'docker/glance/glance-base/extend_start.sh', 'docker/cinder/cinder-base/extend_start.sh', 'docker/watcher/watcher-base/extend_start.sh', 'docker/magnum/magnum-base/extend_start.sh', 'docker/sahara/sahara-base/extend_start.sh', 'docker/mistral/mistral-base/extend_start.sh', 'docker/senlin/senlin-base/extend_start.sh', 'docker/openvswitch/openvswitch-base/extend_start.sh', 'docker/murano/murano-base/extend_start.sh', 'docker/ceilometer/ceilometer-base/extend_start.sh'], 'web_link': 'https://opendev.org/openstack/kolla/commit/8e98e5f15e253263fe18833d623968a9de677d69', 'message': 'Change source with dot at extend_start files\n\nIs a best practice in Unix/Linux scripts to use dots\ninstead of source command.\nUsing dots will avoid issues with non BASH shells\n\nTrivialFix\nChange-Id: Ie6480a1954f853f79faffa093452715ebd9f7d90\nSigned-off-by: Eduardo Gonzalez <dabarren@gmail.com>\n'}]",1,359926,8e98e5f15e253263fe18833d623968a9de677d69,19,7,2,19316,,,0,"Change source with dot at extend_start files

Is a best practice in Unix/Linux scripts to use dots
instead of source command.
Using dots will avoid issues with non BASH shells

TrivialFix
Change-Id: Ie6480a1954f853f79faffa093452715ebd9f7d90
Signed-off-by: Eduardo Gonzalez <dabarren@gmail.com>
",git fetch https://review.opendev.org/openstack/kolla refs/changes/26/359926/1 && git format-patch -1 --stdout FETCH_HEAD,"['docker/heat/heat-base/extend_start.sh', 'docker/base/start.sh', 'docker/designate/designate-base/extend_start.sh', 'docker/horizon/extend_start.sh', 'docker/manila/manila-base/extend_start.sh', 'docker/neutron/neutron-base/extend_start.sh', 'docker/nova/nova-base/extend_start.sh', 'docker/glance/glance-base/extend_start.sh', 'docker/cinder/cinder-base/extend_start.sh', 'docker/keystone/extend_start.sh', 'docker/watcher/watcher-base/extend_start.sh', 'docker/magnum/magnum-base/extend_start.sh', 'docker/sahara/sahara-base/extend_start.sh', 'docker/mistral/mistral-base/extend_start.sh', 'docker/senlin/senlin-base/extend_start.sh', 'docker/openvswitch/openvswitch-base/extend_start.sh', 'docker/murano/murano-base/extend_start.sh', 'docker/ceilometer/ceilometer-base/extend_start.sh']",18,b5e2d6f6e06f7d2def5bfb963c938be04fcd399f,remove_source_command,. /usr/local/bin/kolla_ceilometer_extend_start,source /usr/local/bin/kolla_ceilometer_extend_start,18,18
openstack%2Fnetworking-bagpipe~master~I409b55c640668d552d4e2bed38110b710bbf6156,openstack/networking-bagpipe,master,I409b55c640668d552d4e2bed38110b710bbf6156,Update deprecated i18n an neutron const imports,MERGED,2016-08-29 10:02:00.000000000,2016-08-29 10:14:34.000000000,2016-08-29 10:14:34.000000000,"[{'_account_id': 3}, {'_account_id': 12021}]","[{'number': 1, 'created': '2016-08-29 10:02:00.000000000', 'files': ['networking_bagpipe/tests/unit/driver/test_mech_bagpipe.py', 'networking_bagpipe/agent/bagpipe_bgp_agent.py', 'networking_bagpipe/agent/bagpipe_linuxbridge_neutron_agent.py', 'networking_bagpipe/driver/mech_bagpipe.py', 'networking_bagpipe/tests/unit/agent/test_linuxbridge_agent_extension.py', 'networking_bagpipe/driver/type_route_target.py', 'networking_bagpipe/tests/unit/agent/test_bagpipe_bgp_agent.py'], 'web_link': 'https://opendev.org/openstack/networking-bagpipe/commit/c7b28ca9fe5a6a65c6f5047cbbcd2c431803f681', 'message': 'Update deprecated i18n an neutron const imports\n\nThis change clears the few DeprecationWarning occurences that we had, by:\n- importing exceptions and agent-related constants from neutron_lib\n- importing _ explictly from our _i18n module\n\nWe also now use n_ instead of q_ in neutron-related imports.\n\nChange-Id: I409b55c640668d552d4e2bed38110b710bbf6156\n'}]",0,361981,c7b28ca9fe5a6a65c6f5047cbbcd2c431803f681,6,2,1,12021,,,0,"Update deprecated i18n an neutron const imports

This change clears the few DeprecationWarning occurences that we had, by:
- importing exceptions and agent-related constants from neutron_lib
- importing _ explictly from our _i18n module

We also now use n_ instead of q_ in neutron-related imports.

Change-Id: I409b55c640668d552d4e2bed38110b710bbf6156
",git fetch https://review.opendev.org/openstack/networking-bagpipe refs/changes/81/361981/1 && git format-patch -1 --stdout FETCH_HEAD,"['networking_bagpipe/tests/unit/driver/test_mech_bagpipe.py', 'networking_bagpipe/agent/bagpipe_bgp_agent.py', 'networking_bagpipe/agent/bagpipe_linuxbridge_neutron_agent.py', 'networking_bagpipe/driver/mech_bagpipe.py', 'networking_bagpipe/tests/unit/agent/test_linuxbridge_agent_extension.py', 'networking_bagpipe/driver/type_route_target.py', 'networking_bagpipe/tests/unit/agent/test_bagpipe_bgp_agent.py']",7,c7b28ca9fe5a6a65c6f5047cbbcd2c431803f681,undeprecate,"from neutron_lib import constants as n_const self.agent = BaGPipeBGPAgent(n_const.AGENT_TYPE_LINUXBRIDGE, self.agent = BaGPipeBGPAgent(n_const.AGENT_TYPE_OVS,","from neutron.common import constants as q_const self.agent = BaGPipeBGPAgent(q_const.AGENT_TYPE_LINUXBRIDGE, self.agent = BaGPipeBGPAgent(q_const.AGENT_TYPE_OVS,",36,26
openstack%2Fpython-heatclient~master~I9b20a7cedd416b6d8b788a30f66e472b85babf4a,openstack/python-heatclient,master,I9b20a7cedd416b6d8b788a30f66e472b85babf4a,Add parameter_merge_startegies section,MERGED,2016-08-25 05:40:05.000000000,2016-08-29 10:12:53.000000000,2016-08-29 10:12:53.000000000,"[{'_account_id': 3}, {'_account_id': 4328}, {'_account_id': 6577}]","[{'number': 1, 'created': '2016-08-25 05:40:05.000000000', 'files': ['heatclient/common/environment_format.py', 'heatclient/tests/unit/test_environment_format.py'], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/da0da4c1afc00dd2732b678b09fc2d826137a44d', 'message': 'Add parameter_merge_startegies section\n\nThis adds parameter_merge_strategies section to environment.\nThis also adds the missing section parameter_encrypted_names.\nWe use a server side module and a client side module that have\ndeviated over a period of time. This patch syncs them. We probably\nshould move these to a library and use use them for both server and\nclient in the future.\n\nChange-Id: I9b20a7cedd416b6d8b788a30f66e472b85babf4a\nBlueprint: environment-merging\n'}]",0,360251,da0da4c1afc00dd2732b678b09fc2d826137a44d,8,3,1,8833,,,0,"Add parameter_merge_startegies section

This adds parameter_merge_strategies section to environment.
This also adds the missing section parameter_encrypted_names.
We use a server side module and a client side module that have
deviated over a period of time. This patch syncs them. We probably
should move these to a library and use use them for both server and
client in the future.

Change-Id: I9b20a7cedd416b6d8b788a30f66e472b85babf4a
Blueprint: environment-merging
",git fetch https://review.opendev.org/openstack/python-heatclient refs/changes/51/360251/1 && git format-patch -1 --stdout FETCH_HEAD,"['heatclient/common/environment_format.py', 'heatclient/tests/unit/test_environment_format.py']",2,da0da4c1afc00dd2732b678b09fc2d826137a44d,bp/environment-merging,"encrypted_param_names: []event_sinks: [] def test_param_valid_strategy_section(self): yaml1 = '' yaml2 = ''' parameters: {} encrypted_param_names: [] parameter_defaults: {} parameter_merge_strategies: {} event_sinks: [] resource_registry: {} ''' tpl1 = environment_format.parse(yaml1) environment_format.default_for_missing(tpl1) tpl2 = environment_format.parse(yaml2) self.assertNotEqual(tpl1, tpl2) ",event_sinks: {},28,6
openstack%2Frally~master~I63db699b053c16dce14df919f72579af2f66fa3e,openstack/rally,master,I63db699b053c16dce14df919f72579af2f66fa3e,[Plugins] Add executable availability check to instance_test.sh,MERGED,2016-08-18 12:27:59.000000000,2016-08-29 10:10:54.000000000,2016-08-29 10:10:54.000000000,"[{'_account_id': 3}, {'_account_id': 8491}, {'_account_id': 9545}]","[{'number': 1, 'created': '2016-08-18 12:27:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/2619327c44e1e59fcf818a54606893ee5a97cded', 'message': '[Plugins] Add executable availability check to instance_test.sh\n\nThis is related VMTasks.*runcommand* workloads which can use\nstandard shell script ""instance_test.sh"".\nIn some rare cases (like [1]) it is possible that wide-used\nexecutable is not available on the VM instance. The result is\nconfusing error message from shell interpreter which obstructs\nunderstanding what is actually wrong with the scenario (nothing\nis wrong actually with the scenario, but the instance).\n\nThis patch adds a small piece of code to script instance_test.sh\nwhich checks availability of all used executable commands and\noutputs clear error message if some command is missed.\n\n[1] https://bugs.launchpad.net/rally/+bug/1613144\n\nChange-Id: I63db699b053c16dce14df919f72579af2f66fa3e\n'}, {'number': 2, 'created': '2016-08-18 12:43:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/956715ba4096a12f80dc118e6134f451d54384fe', 'message': '[Plugins] Add executable availability check to instance_test.sh\n\nThis is related VMTasks.*runcommand* workloads which can use\nstandard shell script ""instance_test.sh"".\nIn some rare cases (like [1]) it is possible that wide-used\nexecutable is not available on the VM instance. The result is\nconfusing error message from shell interpreter which obstructs\nunderstanding what is actually wrong with the scenario (nothing\nis wrong actually with the scenario, but the instance).\n\nThis patch adds a small piece of code to script instance_test.sh\nwhich checks availability of all used executable commands and\noutputs clear error message if some command is missed.\n\n[1] https://bugs.launchpad.net/rally/+bug/1613144\n\nChange-Id: I63db699b053c16dce14df919f72579af2f66fa3e\n'}, {'number': 3, 'created': '2016-08-18 12:45:01.000000000', 'files': ['samples/tasks/support/instance_test.sh'], 'web_link': 'https://opendev.org/openstack/rally/commit/cb0db51ff041a253db5562cc895076bfbb6ae92a', 'message': '[Plugins] Add executable availability check to instance_test.sh\n\nThis is related VMTasks.*runcommand* workloads which can use\nstandard shell script ""instance_test.sh"".\nIn some rare cases (like [1]) it is possible that wide-used\nexecutable is not available on the VM instance. The result is\nconfusing error message from shell interpreter which obstructs\nunderstanding what is actually wrong with the scenario (nothing\nis wrong actually with the scenario, but the instance).\n\nThis patch adds a small piece of code to script instance_test.sh\nwhich checks availability of all used executable commands and\noutputs clear error message if some command is missed.\n\n[1] https://bugs.launchpad.net/rally/+bug/1613144\n\nChange-Id: I63db699b053c16dce14df919f72579af2f66fa3e\n'}]",0,357165,cb0db51ff041a253db5562cc895076bfbb6ae92a,19,3,3,10475,,,0,"[Plugins] Add executable availability check to instance_test.sh

This is related VMTasks.*runcommand* workloads which can use
standard shell script ""instance_test.sh"".
In some rare cases (like [1]) it is possible that wide-used
executable is not available on the VM instance. The result is
confusing error message from shell interpreter which obstructs
understanding what is actually wrong with the scenario (nothing
is wrong actually with the scenario, but the instance).

This patch adds a small piece of code to script instance_test.sh
which checks availability of all used executable commands and
outputs clear error message if some command is missed.

[1] https://bugs.launchpad.net/rally/+bug/1613144

Change-Id: I63db699b053c16dce14df919f72579af2f66fa3e
",git fetch https://review.opendev.org/openstack/rally refs/changes/65/357165/2 && git format-patch -1 --stdout FETCH_HEAD,['samples/tasks/support/instance_test.sh'],1,2619327c44e1e59fcf818a54606893ee5a97cded,add-command-availability-check-to-instance-test-script,"for ex in awk top grep free tr df dc do if ! type ${ex} >/dev/null then echo ""Executable is required by script but not available on a server: ${ex}"" >&2 return 1 fi done ",,9,0
openstack%2Fkolla~master~Ibf09b0327adc4454864ed0876d58cc52078592e8,openstack/kolla,master,Ibf09b0327adc4454864ed0876d58cc52078592e8,Updated from global requirements,MERGED,2016-08-29 06:11:46.000000000,2016-08-29 10:00:22.000000000,2016-08-29 10:00:22.000000000,"[{'_account_id': 3}, {'_account_id': 979}, {'_account_id': 11105}]","[{'number': 1, 'created': '2016-08-29 06:11:46.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/kolla/commit/2aac59a91bfbb36817091b8142722e88f86812fe', 'message': 'Updated from global requirements\n\nChange-Id: Ibf09b0327adc4454864ed0876d58cc52078592e8\n'}]",0,361865,2aac59a91bfbb36817091b8142722e88f86812fe,7,3,1,11131,,,0,"Updated from global requirements

Change-Id: Ibf09b0327adc4454864ed0876d58cc52078592e8
",git fetch https://review.opendev.org/openstack/kolla refs/changes/65/361865/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,2aac59a91bfbb36817091b8142722e88f86812fe,openstack/requirements,python-heatclient>=1.4.0 # Apache-2.0,python-heatclient>=1.1.0 # Apache-2.0,1,1
openstack%2Fmonasca-log-api~master~I9547e654de0c618386d56dd98c053118ec0100cf,openstack/monasca-log-api,master,I9547e654de0c618386d56dd98c053118ec0100cf,Manual sync with requirements,MERGED,2016-08-25 20:08:33.000000000,2016-08-29 09:52:25.000000000,2016-08-29 09:52:25.000000000,"[{'_account_id': 3}, {'_account_id': 16168}]","[{'number': 1, 'created': '2016-08-25 20:08:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-log-api/commit/9096663f67fe09441eb1262f039735286ebe16b1', 'message': ""Manual sync with requirements\n\nSync manually with requirements. The automatic sync will not work yet\nsince gunicorn is not in global-requirements file and then the sync\nstops.\n\nSo, let's sync what can be synced...\n\nChange-Id: I9547e654de0c618386d56dd98c053118ec0100cf\n""}, {'number': 2, 'created': '2016-08-26 04:30:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-log-api/commit/8486a9e8384baab6b78c253e787be2c1a0e362a9', 'message': ""Manual sync with requirements\n\nSync manually with requirements. The automatic sync will not work yet\nsince gunicorn is not in global-requirements file and then the sync\nstops.\n\nSo, let's sync what can be synced...\n\nDisable E126 flake8 test since it now fails due to newer flake8\nversion.\n\nChange-Id: I9547e654de0c618386d56dd98c053118ec0100cf\n""}, {'number': 3, 'created': '2016-08-26 04:32:45.000000000', 'files': ['requirements.txt', 'test-requirements.txt', 'setup.py', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/monasca-log-api/commit/5f987c3bf43ae1f6cca1fa23a4fa26a62de2588d', 'message': ""Manual sync with requirements\n\nSync manually with requirements. The automatic sync will not work yet\nsince gunicorn is not in global-requirements file and then the sync\nstops.\n\nSo, let's sync what can be synced...\n\nRemove flake8, let hacking install it as dependency in the corresponding\nversion.\n\nDisable E126 flake8 test since it now fails due to newer flake8\nversion.\n\nChange-Id: I9547e654de0c618386d56dd98c053118ec0100cf\n""}]",0,360765,5f987c3bf43ae1f6cca1fa23a4fa26a62de2588d,10,2,3,6547,,,0,"Manual sync with requirements

Sync manually with requirements. The automatic sync will not work yet
since gunicorn is not in global-requirements file and then the sync
stops.

So, let's sync what can be synced...

Remove flake8, let hacking install it as dependency in the corresponding
version.

Disable E126 flake8 test since it now fails due to newer flake8
version.

Change-Id: I9547e654de0c618386d56dd98c053118ec0100cf
",git fetch https://review.opendev.org/openstack/monasca-log-api refs/changes/65/360765/2 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'test-requirements.txt', 'setup.py']",3,9096663f67fe09441eb1262f039735286ebe16b1,requirements,"# Copyright (c) 2013 Hewlett-Packard Development Company, L.P. # # Licensed under the Apache License, Version 2.0 (the ""License""); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or # implied. # See the License for the specific language governing permissions and # limitations under the License. # THIS FILE IS MANAGED BY THE GLOBAL REQUIREMENTS REPO - DO NOT EDIT import setuptools # In python < 2.7.4, a lazy loading of package `pbr` will break # setuptools if some other modules registered functions in `atexit`. # solution from: http://bugs.python.org/issue15881#msg170215 try: import multiprocessing # noqa except ImportError: pass setuptools.setup( setup_requires=['pbr>=1.8'], pbr=True)","from setuptools import setup __author__ = 'kornicameister@gmail.com' setup( setup_requires=['pbr'], pbr=True, )",55,26
openstack%2Fpython-openstackclient~master~I939eae82dba3287fd4e4086128ebf4609a0e0770,openstack/python-openstackclient,master,I939eae82dba3287fd4e4086128ebf4609a0e0770,Cleanup after install,MERGED,2016-08-28 06:50:22.000000000,2016-08-29 09:51:32.000000000,2016-08-29 09:51:32.000000000,"[{'_account_id': 3}, {'_account_id': 6482}, {'_account_id': 14937}]","[{'number': 1, 'created': '2016-08-28 06:50:22.000000000', 'files': ['tools/tox_install.sh'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/9962403d3c52c96ef02e110a056c4a0c21bc5ab7', 'message': 'Cleanup after install\n\nTox tests are run on developer machines and on long lived slaves. We\nshould not leave lots of directories like\n/tmp/python-openstackclient-tox_install-sdnltRu lying around.\n\nInstead delete the temporary directory after our run.\n\nRemove also an obsolete comment.\n\nChange-Id: I939eae82dba3287fd4e4086128ebf4609a0e0770\n'}]",0,361698,9962403d3c52c96ef02e110a056c4a0c21bc5ab7,7,3,1,6547,,,0,"Cleanup after install

Tox tests are run on developer machines and on long lived slaves. We
should not leave lots of directories like
/tmp/python-openstackclient-tox_install-sdnltRu lying around.

Instead delete the temporary directory after our run.

Remove also an obsolete comment.

Change-Id: I939eae82dba3287fd4e4086128ebf4609a0e0770
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/98/361698/1 && git format-patch -1 --stdout FETCH_HEAD,['tools/tox_install.sh'],1,9962403d3c52c96ef02e110a056c4a0c21bc5ab7,cleanup-zuul,"trap ""rm -rf $mydir"" EXIT"," # If this is called in a periodic job, these will not be set",1,1
openstack%2Ffuel-library~stable%2Fmitaka~I4f5d8b0bfabfb7a8b8a47cecb3c00a69698c7bf3,openstack/fuel-library,stable/mitaka,I4f5d8b0bfabfb7a8b8a47cecb3c00a69698c7bf3,Fix heat reauthentication_auth_method with Radosgw,MERGED,2016-08-19 12:59:23.000000000,2016-08-29 09:50:21.000000000,2016-08-29 09:45:27.000000000,"[{'_account_id': 3}, {'_account_id': 6926}, {'_account_id': 7745}, {'_account_id': 8789}, {'_account_id': 8971}, {'_account_id': 11827}, {'_account_id': 14985}, {'_account_id': 18290}, {'_account_id': 20656}]","[{'number': 1, 'created': '2016-08-19 12:59:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/4bf5f2db97d3c0f69c01b0cc29e3463ab71c2173', 'message': 'Fix heat reauthentication_auth_method with Radosgw\n\n* Set reauthentication_auth_method = trusts only when Radosgw is not used\n* Update YAQL expression for heat\n\nChange-Id: I4f5d8b0bfabfb7a8b8a47cecb3c00a69698c7bf3\nCloses-Bug: 1611031\n(cherry picked from commit 549155f8a9fe620e1011a44b4e5dc0c55cb78b5e)\n'}, {'number': 2, 'created': '2016-08-19 15:41:49.000000000', 'files': ['deployment/puppet/openstack_tasks/examples/heat/tasks.yaml', 'deployment/puppet/openstack_tasks/manifests/heat/heat.pp', 'tests/noop/spec/hosts/heat/heat_spec.rb'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/fbf091b29c41bc4ba008d723b833ff2f851b8903', 'message': 'Fix heat reauthentication_auth_method with Radosgw\n\n* Set reauthentication_auth_method = trusts only when Radosgw is not used\n* Update YAQL expression for heat\n\nChange-Id: I4f5d8b0bfabfb7a8b8a47cecb3c00a69698c7bf3\nCloses-Bug: 1611031\n(cherry picked from commit 549155f8a9fe620e1011a44b4e5dc0c55cb78b5e)\n'}]",0,357847,fbf091b29c41bc4ba008d723b833ff2f851b8903,52,9,2,13344,,,0,"Fix heat reauthentication_auth_method with Radosgw

* Set reauthentication_auth_method = trusts only when Radosgw is not used
* Update YAQL expression for heat

Change-Id: I4f5d8b0bfabfb7a8b8a47cecb3c00a69698c7bf3
Closes-Bug: 1611031
(cherry picked from commit 549155f8a9fe620e1011a44b4e5dc0c55cb78b5e)
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/47/357847/1 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/puppet/openstack_tasks/examples/heat/tasks.yaml', 'deployment/puppet/openstack_tasks/manifests/heat/heat.pp', 'tests/noop/spec/hosts/heat/heat_spec.rb']",3,4bf5f2db97d3c0f69c01b0cc29e3463ab71c2173,bug/1611031, storage_hash = Noop.hiera_hash 'storage' if sahara and !storage_hash['objects_ceph'], if sahara,6,3
openstack%2Ffuel-library~stable%2F8.0~I7224c82c1addee027bb87ece958bcb7042b11dda,openstack/fuel-library,stable/8.0,I7224c82c1addee027bb87ece958bcb7042b11dda,Disable IPv6 on the master node,ABANDONED,2016-08-29 07:52:26.000000000,2016-08-29 09:49:11.000000000,,"[{'_account_id': 3}, {'_account_id': 7732}, {'_account_id': 7745}, {'_account_id': 8971}, {'_account_id': 11827}, {'_account_id': 14200}, {'_account_id': 18290}, {'_account_id': 20656}]","[{'number': 1, 'created': '2016-08-29 07:52:26.000000000', 'files': ['deployment/puppet/nailgun/manifests/host.pp'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/0538a00cde483d3afa31a4d4eecd89c4dc022f4c', 'message': 'Disable IPv6 on the master node\n\nChange-Id: I7224c82c1addee027bb87ece958bcb7042b11dda\nCloses-Bug: #1614146\n(cherry picked from commit 14daf4287ce4749961be4df9696971f7ce74177a)\n(cherry picked from commit 53db5b4175e079b7f78d820387e6ab425d45c17c)\n'}]",1,361916,0538a00cde483d3afa31a4d4eecd89c4dc022f4c,20,8,1,19234,,,0,"Disable IPv6 on the master node

Change-Id: I7224c82c1addee027bb87ece958bcb7042b11dda
Closes-Bug: #1614146
(cherry picked from commit 14daf4287ce4749961be4df9696971f7ce74177a)
(cherry picked from commit 53db5b4175e079b7f78d820387e6ab425d45c17c)
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/16/361916/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/puppet/nailgun/manifests/host.pp'],1,0538a00cde483d3afa31a4d4eecd89c4dc022f4c,bug/1614146, #Disable IPv6 sysctl::value{'net.ipv6.conf.all.disable_ipv6': value => '1'} sysctl::value{'net.ipv6.conf.default.disable_ipv6': value => '1'} ,,4,0
openstack%2Ffuel-library~stable%2F7.0~I7224c82c1addee027bb87ece958bcb7042b11dda,openstack/fuel-library,stable/7.0,I7224c82c1addee027bb87ece958bcb7042b11dda,Disable IPv6 on the master node,ABANDONED,2016-08-29 07:59:37.000000000,2016-08-29 09:48:59.000000000,,"[{'_account_id': 3}, {'_account_id': 7732}, {'_account_id': 7745}, {'_account_id': 8971}, {'_account_id': 11827}, {'_account_id': 14200}, {'_account_id': 18290}, {'_account_id': 20656}]","[{'number': 1, 'created': '2016-08-29 07:59:37.000000000', 'files': ['deployment/puppet/nailgun/manifests/host.pp'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/10ed62fafaaaf5126420a9e46f28d0ea4a2fd1da', 'message': 'Disable IPv6 on the master node\n\nChange-Id: I7224c82c1addee027bb87ece958bcb7042b11dda\nCloses-Bug: #1614146\n(cherry picked from commit 14daf4287ce4749961be4df9696971f7ce74177a)\n(cherry picked from commit 53db5b4175e079b7f78d820387e6ab425d45c17c)\n'}]",1,361923,10ed62fafaaaf5126420a9e46f28d0ea4a2fd1da,15,8,1,19234,,,0,"Disable IPv6 on the master node

Change-Id: I7224c82c1addee027bb87ece958bcb7042b11dda
Closes-Bug: #1614146
(cherry picked from commit 14daf4287ce4749961be4df9696971f7ce74177a)
(cherry picked from commit 53db5b4175e079b7f78d820387e6ab425d45c17c)
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/23/361923/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/puppet/nailgun/manifests/host.pp'],1,10ed62fafaaaf5126420a9e46f28d0ea4a2fd1da,bug/1614146, #Disable IPv6 sysctl::value{'net.ipv6.conf.all.disable_ipv6': value => '1'} sysctl::value{'net.ipv6.conf.default.disable_ipv6': value => '1'} ,,4,0
openstack%2Ftripleo-heat-templates~master~Ia9adcfd5a898f0c712b4a37ae33db88a44630f0d,openstack/tripleo-heat-templates,master,Ia9adcfd5a898f0c712b4a37ae33db88a44630f0d,M/N upgrade set scheduler_host_manager right.,MERGED,2016-08-19 16:32:58.000000000,2016-08-29 09:36:18.000000000,2016-08-29 09:36:18.000000000,"[{'_account_id': 3}, {'_account_id': 1926}, {'_account_id': 3153}, {'_account_id': 8042}, {'_account_id': 8297}, {'_account_id': 10239}, {'_account_id': 10873}, {'_account_id': 11166}, {'_account_id': 16515}]","[{'number': 1, 'created': '2016-08-19 16:32:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/a26e7d1ee5ce3fc624e8a20a2c865d70be792be3', 'message': ""M/N upgrade set scheduler_host_manager right.\n\nscheduler_host_manager doesn't take\nnova.scheduler.host_manager.HostManager as a value anymore.  This fix it\nbefore restarting the service.\n\nChange-Id: Ia9adcfd5a898f0c712b4a37ae33db88a44630f0d\nCloses-Bug: 1615035\n""}, {'number': 2, 'created': '2016-08-26 17:28:13.000000000', 'files': ['extraconfig/tasks/major_upgrade_controller_pacemaker_1.sh'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/1e8d7f9b0072b8e713f23496f02d1f82f2cc7d1f', 'message': ""M/N upgrade set scheduler_host_manager right.\n\nscheduler_host_manager doesn't take\nnova.scheduler.host_manager.HostManager as a value anymore.  This fix it\nbefore restarting the service.\n\nChange-Id: Ia9adcfd5a898f0c712b4a37ae33db88a44630f0d\nCloses-Bug: 1615035\n""}]",3,358005,1e8d7f9b0072b8e713f23496f02d1f82f2cc7d1f,26,9,2,8297,,,0,"M/N upgrade set scheduler_host_manager right.

scheduler_host_manager doesn't take
nova.scheduler.host_manager.HostManager as a value anymore.  This fix it
before restarting the service.

Change-Id: Ia9adcfd5a898f0c712b4a37ae33db88a44630f0d
Closes-Bug: 1615035
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/05/358005/1 && git format-patch -1 --stdout FETCH_HEAD,['extraconfig/tasks/major_upgrade_controller_pacemaker_1.sh'],1,a26e7d1ee5ce3fc624e8a20a2c865d70be792be3,bug/1615035,crudini --set /etc/nova/nova.conf DEFAULT scheduler_host_manager host_manager,,1,0
openstack%2Ftempest~master~Ibb479c303ebeafdc8584403b0b334a0f47b6924f,openstack/tempest,master,Ibb479c303ebeafdc8584403b0b334a0f47b6924f,Remove unused config.CONF,MERGED,2016-08-29 02:18:48.000000000,2016-08-29 09:34:17.000000000,2016-08-29 09:34:17.000000000,"[{'_account_id': 3}, {'_account_id': 5689}, {'_account_id': 7350}]","[{'number': 1, 'created': '2016-08-29 02:18:48.000000000', 'files': ['tempest/scenario/test_object_storage_basic_ops.py', 'tempest/api/orchestration/stacks/test_soft_conf.py', 'tempest/api/volume/test_volumes_extend.py', 'tempest/api/compute/admin/test_security_groups.py', 'tempest/api/compute/servers/test_list_server_filters.py', 'tempest/api/identity/admin/v3/test_inherits.py', 'tempest/api/volume/admin/test_volume_quotas_negative.py', 'tempest/api/orchestration/stacks/test_environment.py', 'tempest/scenario/test_baremetal_basic_ops.py', 'tempest/api/volume/test_volume_transfers.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/1e8a3a416f6d0a0d744c40c47bf3e1875f63efec', 'message': 'Remove unused config.CONF\n\nThis is to remove unused config.CONF to keep code clean.\n\nChange-Id: Ibb479c303ebeafdc8584403b0b334a0f47b6924f\n'}]",0,361794,1e8a3a416f6d0a0d744c40c47bf3e1875f63efec,8,3,1,20190,,,0,"Remove unused config.CONF

This is to remove unused config.CONF to keep code clean.

Change-Id: Ibb479c303ebeafdc8584403b0b334a0f47b6924f
",git fetch https://review.opendev.org/openstack/tempest refs/changes/94/361794/1 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/api/orchestration/stacks/test_soft_conf.py', 'tempest/scenario/test_object_storage_basic_ops.py', 'tempest/api/volume/test_volumes_extend.py', 'tempest/api/compute/admin/test_security_groups.py', 'tempest/api/compute/servers/test_list_server_filters.py', 'tempest/api/identity/admin/v3/test_inherits.py', 'tempest/api/volume/admin/test_volume_quotas_negative.py', 'tempest/api/orchestration/stacks/test_environment.py', 'tempest/scenario/test_baremetal_basic_ops.py', 'tempest/api/volume/test_volume_transfers.py']",10,1e8a3a416f6d0a0d744c40c47bf3e1875f63efec,remove_unuse_conf,,from tempest import configCONF = config.CONF ,0,31
openstack%2Fdeb-auto-backports~debian%2Fnewton~I3c4428c9bf1eba165059810faf277902c5d38b5d,openstack/deb-auto-backports,debian/newton,I3c4428c9bf1eba165059810faf277902c5d38b5d,Add possibility to use (.gz|.bz2|.xz) archives,MERGED,2016-08-26 18:41:42.000000000,2016-08-29 09:32:15.000000000,2016-08-29 09:32:15.000000000,"[{'_account_id': 3}, {'_account_id': 6476}, {'_account_id': 7613}, {'_account_id': 12841}]","[{'number': 1, 'created': '2016-08-26 18:41:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/deb-auto-backports/commit/7715b667da99d0f9cef4f8514ed5af6fab257781', 'message': 'Add possibility to use (.gz|.bz2|.xz) archives\n\nCurrently script downloads only .gz archives which\nthen are sourced by madison-lite.\nThe issue is that experimental repository contains\nonly .xz archive [1] (26.08.2016) and it leads to errors [2].\n\n[1] http://httpredir.debian.org/debian/dists/experimental/main/source/\n[2] http://logs.openstack.org/14/360814/1/check/pkgdeb-build-auto-backports/\n    f28ead2/console.html\n\nChange-Id: I3c4428c9bf1eba165059810faf277902c5d38b5d\n'}, {'number': 2, 'created': '2016-08-26 18:43:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/deb-auto-backports/commit/71895d4ada9aee7b28e358a9f6d936e25be23719', 'message': 'Add possibility to use (.gz|.bz2|.xz) archives\n\nCurrently script downloads archives based on distribution\nwhich then are sourced by madison-lite.\n\nChange-Id: I3c4428c9bf1eba165059810faf277902c5d38b5d\n'}, {'number': 3, 'created': '2016-08-26 18:44:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/deb-auto-backports/commit/fbba657c9a039a915e3f544256da1f917bc7aa19', 'message': 'Add possibility to use (.gz|.bz2|.xz) archives\n\nCurrently script downloads archives based on distribution\nwhich then are sourced by madison-lite.\n\nChange-Id: I3c4428c9bf1eba165059810faf277902c5d38b5d\n'}, {'number': 4, 'created': '2016-08-26 18:57:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/deb-auto-backports/commit/854eecfbc87f664287db999c9e67291787cd9bf7', 'message': 'Add possibility to use (.gz|.bz2|.xz) archives\n\nCurrently script downloads archives based on distribution\nwhich then are sourced by madison-lite.\n\nChange-Id: I3c4428c9bf1eba165059810faf277902c5d38b5d\n'}, {'number': 5, 'created': '2016-08-27 00:41:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/deb-auto-backports/commit/7a24376d2a14175b1286d8b7ba5dba458178ae96', 'message': 'Add possibility to use (.gz|.bz2|.xz) archives\n\nCurrently script downloads archives based on distribution\nwhich then are sourced by madison-lite.\n\nChange-Id: I3c4428c9bf1eba165059810faf277902c5d38b5d\n'}, {'number': 6, 'created': '2016-08-27 00:46:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/deb-auto-backports/commit/7c7c186e8fde9cbe3ca7def509aa99246b89e65d', 'message': 'Add possibility to use (.gz|.bz2|.xz) archives\n\nCurrently script downloads archives based on distribution\nwhich then are sourced by madison-lite.\n\nChange-Id: I3c4428c9bf1eba165059810faf277902c5d38b5d\n'}, {'number': 7, 'created': '2016-08-27 07:43:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/deb-auto-backports/commit/3c52aa772fdda59ace5d45ddf016f14a38136b98', 'message': 'Add possibility to use (.gz|.bz2|.xz) archives\n\nCurrently script downloads archives based on distribution\nwhich then are sourced by madison-lite.\n\nGet python-mock package from experimental repository.\n\nChange-Id: I3c4428c9bf1eba165059810faf277902c5d38b5d\n'}, {'number': 8, 'created': '2016-08-27 08:05:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/deb-auto-backports/commit/a13633e9ca1447aa170feca86c7076b8d0b421cf', 'message': 'Add possibility to use (.gz|.bz2|.xz) archives\n\nCurrently script downloads archives based on distribution\nwhich then are sourced by madison-lite.\n\nGet python-mock package from experimental repository.\n\nChange-Id: I3c4428c9bf1eba165059810faf277902c5d38b5d\n'}, {'number': 9, 'created': '2016-08-27 19:02:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/deb-auto-backports/commit/cda392ef7a54f96ba4f5470b6573117dec64e839', 'message': 'Add possibility to use (.gz|.bz2|.xz) archives\n\nCurrently script downloads archives based on distribution\nwhich then are sourced by madison-lite.\n\nGet python-mock package from experimental repository.\n\nChange-Id: I3c4428c9bf1eba165059810faf277902c5d38b5d\n'}, {'number': 10, 'created': '2016-08-27 23:22:01.000000000', 'files': ['packages-list', 'check-and-build-bpo'], 'web_link': 'https://opendev.org/openstack/deb-auto-backports/commit/584074146100bf83e66bb086b169292a81bac728', 'message': 'Add possibility to use (.gz|.bz2|.xz) archives\n\nCurrently script downloads archives based on distribution\nwhich then are sourced by madison-lite.\n\nGet python-mock package from experimental repository.\n\nChange-Id: I3c4428c9bf1eba165059810faf277902c5d38b5d\n'}]",0,361417,584074146100bf83e66bb086b169292a81bac728,28,4,10,12841,,,0,"Add possibility to use (.gz|.bz2|.xz) archives

Currently script downloads archives based on distribution
which then are sourced by madison-lite.

Get python-mock package from experimental repository.

Change-Id: I3c4428c9bf1eba165059810faf277902c5d38b5d
",git fetch https://review.opendev.org/openstack/deb-auto-backports refs/changes/17/361417/9 && git format-patch -1 --stdout FETCH_HEAD,['check-and-build-bpo'],1,7715b667da99d0f9cef4f8514ed5af6fab257781,," for BINARY_ARCH in binary-all binary-amd64 source ; do if ! [ -d ${DEST_DIST_DIR}/${BINARY_ARCH} ] ; then mkdir -p ${DEST_DIST_DIR}/${BINARY_ARCH} if [ ""${BINARY_ARCH}"" = ""source"" ] ; then LISTFILE=Sources LISTFILE=Packages fi ARCHIVE='' for FILE_EXTENSION in gz bz2 xz ; do LINK_TO_LISTFILE=${FETCH_REPO_URL}/dists/${NAME_OF_MIRROR}/main/${BINARY_ARCH}}/${LISTFILE}.${FILE_EXTENSION} HTTP_CODE=$(curl -sL -w ""%{http_code}"" ""${LINK_TO_LISTFILE}"" -o /dev/null) if [ ""$HTTP_CODE"" = ""200"" ] ; then if [ ""${FILE_EXTENSION}"" = 'xz' ] ; then echo 'madison-lite (v0.21) does not support XZ (LZMA/LZMA2 compression algorithms).' # TODO(tlbr): Provide workaround and remove it once newer version of madison-lite is out. fi ARCHIVE=${LISTFILE}.${FILE_EXTENSION} if ! [ -z $ARCHIVE ] ; then rm -f ${DEST_DIST_DIR}/${BINARY_ARCH}/${ARCHIVE} wget ${FETCH_REPO_URL}/dists/${NAME_OF_MIRROR}/main/${BINARY_ARCH}/${ARCHIVE} -O ${DEST_DIST_DIR}/${BINARY_ARCH}/${ARCHIVE} else echo ""There is no ${LISTFILE} archive to work with."" fi"," for i in binary-all binary-amd64 source ; do if ! [ -d ${DEST_DIST_DIR}/$i ] ; then mkdir -p ${DEST_DIST_DIR}/$i if [ ""$i"" = ""source"" ] ; then if [ ""${NAME_OF_MIRROR}"" = ""experimental"" ] ; then GZFILE=Sources.xz else GZFILE=Sources.gz fi if [ ""${NAME_OF_MIRROR}"" = ""experimental"" ] ; then GZFILE=Packages.xz else GZFILE=Packages.gz rm -f ${DEST_DIST_DIR}/$i/$GZFILE wget ${FETCH_REPO_URL}/dists/${NAME_OF_MIRROR}/main/$i/$GZFILE -O ${DEST_DIST_DIR}/$i/$GZFILE || true",23,15
openstack%2Ffuel-library~master~I97c1e8d9c6efe23028137eef5623e8b4b27593f2,openstack/fuel-library,master,I97c1e8d9c6efe23028137eef5623e8b4b27593f2,Repeat processing each APT repository on timeout,MERGED,2016-08-25 22:29:01.000000000,2016-08-29 09:29:04.000000000,2016-08-29 09:24:50.000000000,"[{'_account_id': 3}, {'_account_id': 7468}, {'_account_id': 7732}, {'_account_id': 7745}, {'_account_id': 8971}, {'_account_id': 9037}, {'_account_id': 11090}, {'_account_id': 11827}, {'_account_id': 14200}, {'_account_id': 14985}, {'_account_id': 16771}, {'_account_id': 18290}, {'_account_id': 20656}]","[{'number': 1, 'created': '2016-08-25 22:29:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/f54843cc4dcd0d364b0ae2af90952b8cb2e07e7c', 'message': 'Repeat processing each APT repository on timeout\n\nThis change wrapups the Net::HTTP call to correctly handle exception\nTimeout::Error and try to repeat processing each APT repository while\ninternet connection slow.\n\nChange-Id: I97c1e8d9c6efe23028137eef5623e8b4b27593f2\nCloses-Bug: #1595110\nSigned-off-by: Maksim Malchuk <mmalchuk@mirantis.com>\n'}, {'number': 2, 'created': '2016-08-25 23:17:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/a8bf98abcbedb2bc1c427b5115947a94b479b53d', 'message': 'Repeat processing each APT repository on timeout\n\nThis change wrapups the Net::HTTP call to correctly handle exception\nTimeout::Error and try to repeat processing each APT repository while\ninternet connection slow.\n\nChange-Id: I97c1e8d9c6efe23028137eef5623e8b4b27593f2\nCloses-Bug: #1595110\nSigned-off-by: Maksim Malchuk <mmalchuk@mirantis.com>\n'}, {'number': 3, 'created': '2016-08-26 09:02:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/1a22e48b3b57eaa0c9ea1891d7345758cff6b777', 'message': 'Repeat processing each APT repository on timeout\n\nThis change wrapups the Net::HTTP call to correctly handle exception\nTimeout::Error and try to repeat processing each APT repository while\ninternet connection slow.\n\nChange-Id: I97c1e8d9c6efe23028137eef5623e8b4b27593f2\nCloses-Bug: #1595110\nSigned-off-by: Maksim Malchuk <mmalchuk@mirantis.com>\n'}, {'number': 4, 'created': '2016-08-26 12:25:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/ed0c9ce0d12bd98a4c86301bc0282013fa91d73b', 'message': 'Repeat processing each APT repository on timeout\n\nThis change wrapups the Net::HTTP call to correctly handle exception\nTimeout::Error and try to repeat processing each APT repository while\ninternet connection slow.\n\nChange-Id: I97c1e8d9c6efe23028137eef5623e8b4b27593f2\nCloses-Bug: #1595110\nSigned-off-by: Maksim Malchuk <mmalchuk@mirantis.com>\n'}, {'number': 5, 'created': '2016-08-26 13:35:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/4c35c71cd3b2c346651437b0ee15bd0b8ee36dca', 'message': 'Repeat processing each APT repository on timeout\n\nThis change wrapups the Net::HTTP call to correctly handle exception\nTimeout::Error and try to repeat processing each APT repository while\ninternet connection slow.\n\nChange-Id: I97c1e8d9c6efe23028137eef5623e8b4b27593f2\nCloses-Bug: #1595110\nSigned-off-by: Maksim Malchuk <mmalchuk@mirantis.com>\n'}, {'number': 6, 'created': '2016-08-26 15:27:35.000000000', 'files': ['deployment/puppet/osnailyfacter/lib/puppet/parser/functions/generate_apt_pins.rb'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/9225eee645a9f1a070ac85f6d61fed292509cc3b', 'message': 'Repeat processing each APT repository on timeout\n\nThis change wrapups the Net::HTTP call to correctly handle exception\nTimeout::Error and try to repeat processing each APT repository while\ninternet connection slow.\n\nChange-Id: I97c1e8d9c6efe23028137eef5623e8b4b27593f2\nCloses-Bug: #1595110\nSigned-off-by: Maksim Malchuk <mmalchuk@mirantis.com>\n'}]",0,360808,9225eee645a9f1a070ac85f6d61fed292509cc3b,146,13,6,14200,,,0,"Repeat processing each APT repository on timeout

This change wrapups the Net::HTTP call to correctly handle exception
Timeout::Error and try to repeat processing each APT repository while
internet connection slow.

Change-Id: I97c1e8d9c6efe23028137eef5623e8b4b27593f2
Closes-Bug: #1595110
Signed-off-by: Maksim Malchuk <mmalchuk@mirantis.com>
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/08/360808/5 && git format-patch -1 --stdout FETCH_HEAD,['deployment/puppet/osnailyfacter/lib/puppet/parser/functions/generate_apt_pins.rb'],1,f54843cc4dcd0d364b0ae2af90952b8cb2e07e7c,bug/1595110," response = nil retry_count = 3 (1..retry_count).each do |try| begin response = Net::HTTP.get_response uri break rescue Timeout::Error => exception info ""Attempt '#{try}' of '#{retry_count}' has failed: #{exception.message}"" raise exception if try >= retry_count sleep 5 end end", response = Net::HTTP.get_response uri,13,1
openstack%2Fceilometer~master~I4e4f6fe692773133de03a80147d0cee59bab875b,openstack/ceilometer,master,I4e4f6fe692773133de03a80147d0cee59bab875b,Add log hints for partition coordinator,MERGED,2016-05-05 12:15:38.000000000,2016-08-29 09:27:08.000000000,2016-08-29 09:27:08.000000000,"[{'_account_id': 3}, {'_account_id': 4491}, {'_account_id': 6537}, {'_account_id': 6676}, {'_account_id': 8290}, {'_account_id': 8358}, {'_account_id': 15843}, {'_account_id': 22739}]","[{'number': 1, 'created': '2016-05-05 12:15:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/e51ca8bc5600ee0098a2658924add1a9425bbed1', 'message': 'Add log hints for partition coordinator\n\nTrivially, but these log hints are useful to track the processing of\npartition coordinator.\n\nChange-Id: I4e4f6fe692773133de03a80147d0cee59bab875b\n'}, {'number': 2, 'created': '2016-05-09 08:09:33.000000000', 'files': ['ceilometer/coordination.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/dfc34522051c4ec49a0516ea54fcd598b814a498', 'message': 'Add log hints for partition coordinator\n\nTrivially, but these log hints are useful to track the processing of\npartition coordinator.\n\nChange-Id: I4e4f6fe692773133de03a80147d0cee59bab875b\n'}]",6,312918,dfc34522051c4ec49a0516ea54fcd598b814a498,26,8,2,8290,,,0,"Add log hints for partition coordinator

Trivially, but these log hints are useful to track the processing of
partition coordinator.

Change-Id: I4e4f6fe692773133de03a80147d0cee59bab875b
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/18/312918/2 && git format-patch -1 --stdout FETCH_HEAD,['ceilometer/coordination.py'],1,e51ca8bc5600ee0098a2658924add1a9425bbed1,partition-coordinator-log," LOG.debug('Members of group %s are: %s, Me: %s', group_id, members, self._my_id) LOG.debug('Members of group %s are: %s, Me: %s', group_id, members, self._my_id) iterable = list(iterable) LOG.debug('Universal set: %s', [str(f) for f in iterable])"," LOG.debug('Members of group: %s, Me: %s', members, self._my_id)",6,1
openstack%2Fcinder~master~Ib7545438998b02fb7670df44a6486764c401c5f6,openstack/cinder,master,Ib7545438998b02fb7670df44a6486764c401c5f6,NetApp: Report multiattach as enabled,MERGED,2016-08-17 17:40:02.000000000,2016-08-29 09:25:50.000000000,2016-08-25 21:17:09.000000000,"[{'_account_id': 3}, {'_account_id': 2243}, {'_account_id': 9008}, {'_account_id': 10621}, {'_account_id': 10622}, {'_account_id': 11904}, {'_account_id': 12017}, {'_account_id': 12032}, {'_account_id': 12033}, {'_account_id': 12822}, {'_account_id': 13394}, {'_account_id': 14384}, {'_account_id': 14797}, {'_account_id': 15249}, {'_account_id': 15296}, {'_account_id': 15374}, {'_account_id': 15831}, {'_account_id': 16269}, {'_account_id': 16422}, {'_account_id': 16595}, {'_account_id': 16660}, {'_account_id': 16862}, {'_account_id': 16897}, {'_account_id': 16898}, {'_account_id': 16941}, {'_account_id': 18120}, {'_account_id': 18752}, {'_account_id': 19146}, {'_account_id': 19933}, {'_account_id': 21193}, {'_account_id': 21863}, {'_account_id': 21976}, {'_account_id': 22126}, {'_account_id': 22248}]","[{'number': 1, 'created': '2016-08-17 17:40:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/8eae416a6992a419bf3f6d949b560ce353a37827', 'message': 'NetApp: Report multiattach as enabled\n\nPools reported by NFS and block drivers for CDOT and 7mode\nnow report multiattach as a capability. NetApp cDOT and 7mode\nLUNs have always supported multi-attach, but their capability\nwas not previously reported as such.\n\nCloses-Bug: #1612763\nChange-Id: Ib7545438998b02fb7670df44a6486764c401c5f6\n'}, {'number': 2, 'created': '2016-08-22 15:34:49.000000000', 'files': ['cinder/volume/drivers/netapp/dataontap/nfs_7mode.py', 'cinder/volume/drivers/netapp/dataontap/nfs_cmode.py', 'cinder/tests/unit/volume/drivers/netapp/dataontap/fakes.py', 'cinder/tests/unit/volume/drivers/netapp/dataontap/test_nfs_7mode.py', 'cinder/tests/unit/volume/drivers/netapp/dataontap/test_nfs_cmode.py', 'cinder/tests/unit/volume/drivers/netapp/dataontap/test_block_cmode.py', 'cinder/volume/drivers/netapp/dataontap/block_cmode.py', 'releasenotes/notes/bug-1612763-report-multiattach-enabled-NetApp-backends-0fbf2cb621e4747d.yaml', 'cinder/tests/unit/volume/drivers/netapp/dataontap/test_block_7mode.py', 'cinder/volume/drivers/netapp/dataontap/block_7mode.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/5568b40d0682f6c34bce3f4dd7b5b824c93f6082', 'message': 'NetApp: Report multiattach as enabled\n\nPools reported by NFS and block drivers for CDOT and 7mode\nnow report multiattach as a capability. NetApp cDOT and 7mode\nLUNs have always supported multi-attach, but their capability\nwas not previously reported as such.\n\nCloses-Bug: #1612763\nChange-Id: Ib7545438998b02fb7670df44a6486764c401c5f6\n'}]",0,356635,5568b40d0682f6c34bce3f4dd7b5b824c93f6082,75,34,2,16064,,,0,"NetApp: Report multiattach as enabled

Pools reported by NFS and block drivers for CDOT and 7mode
now report multiattach as a capability. NetApp cDOT and 7mode
LUNs have always supported multi-attach, but their capability
was not previously reported as such.

Closes-Bug: #1612763
Change-Id: Ib7545438998b02fb7670df44a6486764c401c5f6
",git fetch https://review.opendev.org/openstack/cinder refs/changes/35/356635/2 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/tests/unit/volume/drivers/netapp/dataontap/fakes.py', 'cinder/volume/drivers/netapp/dataontap/nfs_7mode.py', 'cinder/volume/drivers/netapp/dataontap/nfs_cmode.py', 'cinder/tests/unit/volume/drivers/netapp/dataontap/test_nfs_7mode.py', 'cinder/tests/unit/volume/drivers/netapp/dataontap/test_nfs_cmode.py', 'cinder/tests/unit/volume/drivers/netapp/dataontap/test_block_cmode.py', 'cinder/volume/drivers/netapp/dataontap/block_cmode.py', 'releasenotes/notes/bug-1612763-report-multiattach-enabled-NetApp-backends-0fbf2cb621e4747d.yaml', 'cinder/tests/unit/volume/drivers/netapp/dataontap/test_block_7mode.py', 'cinder/volume/drivers/netapp/dataontap/block_7mode.py']",10,8eae416a6992a419bf3f6d949b560ce353a37827,bug/1612763, pool['multiattach'] = True,,14,0
openstack%2Ffuel-docs~master~I2a5ebf0031dc7257d3f26587c8be7200f0dc5ed9,openstack/fuel-docs,master,I2a5ebf0031dc7257d3f26587c8be7200f0dc5ed9,[DevGuide] Minor edit,MERGED,2016-08-18 12:02:19.000000000,2016-08-29 09:24:38.000000000,2016-08-29 09:18:08.000000000,"[{'_account_id': 3}, {'_account_id': 8971}, {'_account_id': 14962}, {'_account_id': 17626}]","[{'number': 1, 'created': '2016-08-18 12:02:19.000000000', 'files': ['devdocs/develop/ostf_contributors_guide.rst'], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/23302340a2fc50da02a2deaf45d08560c0063f1b', 'message': '[DevGuide] Minor edit\n\nRemoves the duplicated content.\n\nChange-Id: I2a5ebf0031dc7257d3f26587c8be7200f0dc5ed9\n'}]",0,357148,23302340a2fc50da02a2deaf45d08560c0063f1b,15,4,1,14947,,,0,"[DevGuide] Minor edit

Removes the duplicated content.

Change-Id: I2a5ebf0031dc7257d3f26587c8be7200f0dc5ed9
",git fetch https://review.opendev.org/openstack/fuel-docs refs/changes/48/357148/1 && git format-patch -1 --stdout FETCH_HEAD,['devdocs/develop/ostf_contributors_guide.rst'],1,23302340a2fc50da02a2deaf45d08560c0063f1b,minor_edits,"Health Check (OSTF) Contributor's Guide ======================================= Health Check or OSTF? ^^^^^^^^^^^^^^^^^^^^^ Fuel UI has a tab which is called Health Check. In development team though, there is an established acronym OSTF, which stands for OpenStack Testing Framework. This is all about the same. For simplicity, this document will use the widely accepted term OSTF. Main goal of OSTF ^^^^^^^^^^^^^^^^^ After OpenStack installation via Fuel, it`s very important to understand whether it was successful and if it`s ready for work. OSTF provides a set of health checks - sanity, smoke, HA and additional components tests that check the proper operation of all system components in typical conditions. There are tests for OpenStack scenarios validation and other specific tests useful in validating an OpenStack deployment. Main rules of code contributions ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ There are a few rules you need to follow to successfully pass the code review and contribute high-quality code. How to setup my environment? ---------------------------- OSTF repository is located at git.openstack.org or GitHub mirror: https://github.com/openstack/fuel-ostf. You also have to install and hook-up gerrit, because otherwise you will not be able to contribute code. To do that you need to follow registration and installation instructions in the document https://wiki.openstack.org/wiki/CLA#Contributors_License_Agreement After you've completed the instructions, you're all set to begin editing/creating code. How should my modules look like? -------------------------------- The rules are quite simple: - follow Python coding rules - follow OpenStack contributor's rules - watch out for mistakes in docstrings - follow correct test structure - always execute your tests after you wrote them before sending them to review Speaking of following Python coding standards, you can find the style guide here: http://www.python.org/dev/peps/pep-0008/. You should read it carefully once and after implementing scripts you need to run some checks that will ensure that your code corresponds the standards. Without correcting issues with coding stadards your scripts will not be merged to master. You should always follow the following implementation rules: - name the test module, test class and test method beginning with the word ""test"" - if you have some tests that should be ran in a specific order, add a number to test method name, for example: test_001_create_keypair - use verify(), verify_response_body_content() and other methods from mixins (see OSTF package architecture fuel_health/common/test_mixins.py section) with giving them failed step parameter - always list all steps you are checking using test_mixins methods in the docstring in Scenario section in correct order - always use verify() method when you want to check an operation that can go to an infinite loop The test docstrings are another important piece and you should always stick to the following docstring structure: - test title - test description that will be always shown on UI (the remaining part of docstring will only be shown in cases when test failed) - target component (optional) - component name that is tested (e.g. Nova, Keystone) - blank line - test scenario, example:: Scenario: 1. Create a new small-size volume. 2. Wait for volume status to become ""available"". 3. Check volume has correct name. 4. Create new instance. 5. Wait for ""Active"" status. 6. Attach volume to an instance. 7. Check volume status is ""in use"". 8. Get information on the created volume by its id. 9. Detach volume from the instance. 10. Check volume has ""available"" status. 11. Delete volume. - test duration - an estimate of how much a test will take deployment tags (optional) - gives information about what kind of environment the test will be run, possible values are CENTOS, Ubuntu, RHEL nova_network, Heat, Sahara) Here's a test example which confirms the above explanations: .. image:: _images/test_docstring_structure.png Test run ordering and profiles ------------------------------ Each test set (sanity, smoke, HA and platform_tests) contains a special variable in __init__.py module which is called __profile__. The profile variable makes it possible to set different rules, such as test run order, set up deployment tags, information gathering on cleanup and expected time estimate for running a test set. If you are to develop a new set of tests, you need to create __init__.py module and place __profile__ dict in it. It is important that your profile matches the following structure:: __profile__ = { ""test_runs_ordering_priority"": 4, ""id"": ""platform_tests"", ""driver"": ""nose"", ""test_path"": ""fuel_health/tests/platform_tests"", ""description"": (""Platform services functional tests."" "" Duration 3 min - 60 min""), ""cleanup_path"": ""fuel_health.cleanup"", ""deployment_tags"": ['additional_components'], ""exclusive_testsets"": [], ""available_since_release"": ""2015.2-6.1"", } Take note of each field in the profile, along with acceptable values. - test_runs_ordering_priority is a field responsible for setting the priority in which the test set will be displayed. For example, if you set ""6"" for sanity tests and ""3"" for smoke tests, smoke test set will be displayed first on the HealthCheck tab; - id is just the unique id of a test set; - driver field is used for setting the test runner; - test_path is the field representing path where test set is located starting from fuel_health directory; - description is the field which contains the value to be shown on the UI as the tests duration; - cleanup_path is the field that specifies path to module responsible for cleanup mechanism (if you do not specify this value, cleanup will not be started after your test set); - deployment_tags field is used for defining when these tests should be available depending on cluster settings; - exclusive_testsets field gives you an opportunity to specify test sets that will be run successively. For example, you can specify ""smoke_sanity"" for smoke and sanity test set profiles, then these tests will be run not simultaneously, but successively. - available_since_release field is responsible for the release version starting from which a particular test set can be run. This means that the test will run only on the specified or newer version of Fuel. It is necessary to specify a value for each of the attributes. The optional attribute is ""deployment_tags"", meaning optionally you may not specify it in your profile at all. You can leave the ""exclusive_testsets"" empty ([]) to run your testset simultaneously with other ones. How to execute my tests? ------------------------ Simplest way is to install Fuel, and OSTF will be installed as part of it. - install virtualbox - build Fuel ISO: :ref:`building-fuel-iso` - use `virtualbox scripts to run an ISO <https://github.com/openstack/fuel-virtualbox/tree/master/>`_ - once the installation is finished, go to Fuel UI (usually it's 10.20.0.2:8000) and create a new cluster with necessary configuration - execute:: rsync -avz <path to fuel_health>/ root@10.20.0.2:/opt/fuel_plugins/ostf/lib/python2.6/site-packages/fuel_health/ - execute:: ssh root@10.20.0.2 ps uax | grep supervisor kill <supervisord process number> service supervisord start - go to Fuel UI and run your new tests Now I'm done, what's next? -------------------------- - don't forget to run pep8 on modified part of code - commit your changes - execute git review - ask to review in IRC From this part you'll only need to fix and commit review comments (if there are any) by doing the same steps. If there are no review comments left, the reviewers will accept your code and it will be automatically merged to master. General OSTF architecture ^^^^^^^^^^^^^^^^^^^^^^^^^ Tests are included to Fuel, so they will be accessible as soon as you install Fuel on your lab. OSTF architecture is quite simple, it consists of two main packages: - fuel_health which contains the test set itself and related modules - fuel_plugin which contains OSTF-adapter that forms necessary test list in context of cluster deployment options and transfers them to UI using REST_API On the other hand, there is some information necessary for test execution itself. There are several modules that gather information and parse them into objects which will be used in the tests themselves. All information is gathered from Nailgun component. OSTF REST api interface ----------------------- Fuel OSTF module provides not only testing, but also RESTful interface, a means for interaction with the components. In terms of REST, all types of OSTF entities are managed by three HTTP verbs: GET, POST and PUT. The following basic URL is used to make requests to OSTF:: {ostf_host}:{ostf_port}/v1/{requested_entity}/{cluster_id} Currently, you can get information about testsets, tests and testruns via GET request on corresponding URLs for ostf_plugin. To get information about testsets, make the following GET request on:: {ostf_host}:{ostf_port}/v1/testsets/{cluster_id} To get information about tests, make GET request on:: {ostf_host}:{ostf_port}/v1/tests/{cluster_id} To get information about executed tests, make the following GET requests: - for the whole set of testruns:: {ostf_host}:{ostf_port}/v1/testruns/ - for the particular testrun:: {ostf_host}:{ostf_port}/v1/testruns/{testrun_id} - for the list of testruns executed on the particular cluster:: {ostf_host}:{ostf_port}/v1/testruns/last/{cluster_id} To start test execution, make the following POST request on this URL:: {ostf_host}:{ostf_port}/v1/testruns/ The body must consist of JSON data structure with testsets and the list of tests belonging to it that must be executed. It should also have metadata with the information about the cluster (the key with the ""cluster_id"" name is used to store the parameter's value):: [ { ""testset"": ""test_set_name"", ""tests"": [""module.path.to.test.1"", ..., ""module.path.to.test.n""], ""metadata"": {""cluster_id"": id} }, ..., {...}, # info for another testrun {...}, ..., {...} ] If succeeded, OSTF adapter returns attributes of created testrun entities in JSON format. If you want to launch only one test, put its id into the list. To launch all tests, leave the list empty (by default). Example of the response:: [ { ""status"": ""running"", ""testset"": ""sanity"", ""meta"": null, ""ended_at"": ""2014-12-12 15:31:54.528773"", ""started_at"": ""2014-12-12 15:31:41.481071"", ""cluster_id"": 1, ""id"": 1, ""tests"": [.....info on tests.....] }, .... ] You can also stop and restart testruns. To do that, make a PUT request on testruns. The request body must contain the list of the testruns and tests to be stopped or restarted. Example:: [ { ""id"": test_run_id, ""status"": (""stopped"" | ""restarted""), ""tests"": [""module.path.to.test.1"", ..., ""module.path.to.test.n""] }, ..., {...}, # info for another testrun {...}, ..., {...} ] If succeeded, OSTF adapter returns attributes of the processed testruns in JSON format. Its structure is the same as for POST request, described above. OSTF package architecture ^^^^^^^^^^^^^^^^^^^^^^^^^ The main modules used in fuel_health package are: **config** module is responsible of getting data which is necessary for tests. All data is gathered from Nailgun component or a text config. Nailgun provides us with the following data: - OpenStack admin user name - OpenStack admin user password - OpenStack admin user tenant - ip of controllers node - ip of compute node - easily get data from nailgun by parsing role key in response json - deployment mode (HA /non-HA) - deployment os (RHEL/CENTOS) - keystone / horizon urls - tiny proxy address All other information we need is stored in config.py itself and remains default in this case. In case you are using data from Nailgun (OpenStack installation using Fuel) you should to the following: initialize NailgunConfig() class. Nailgun is running on Fuel master node, so you can easily get data for each cluster by invoking curl http:/localhost:8000/api/<uri_here>. Cluster id can be get from OS environment (provided by Fuel) If you want run OSTF for non Fuel installation, change the initialization of NailgunConfig() to FileConfig() and set parameters marked with green color in config - see Appendix 1 (default config file path fuel_health/etc/test.conf) **cleanup.py** - invoked by OSTF adapter in case if user stops test execution in Web UI. This module is responsible for deleting all test resources created during test suite run. It simply finds all resources whose name starts with ost1_test- and destroys each of them using _delete_it method. *Important: if you decide to add additional cleanup for this resource, you have to keep in mind: All resources depend on each other, that's why deleting a resource that is still in use will give you an exception; Don't forget that deleting several resources requires an ID for each resource, but not its name. You'll need to specify delete_type optional argument in _delete_it method to id* **nmanager.py** contains base classes for tests. Each base class contains setup, teardown and methods that act as an interlayer between tests and OpenStack python clients (see nmanager architecture diagram). .. image:: _images/nmanager.png **fuel_health/common/test_mixins.py** - provides mixins to pack response verification into a human-readable message. For assertion failure cases, the method requires a step on which we failed and a descriptive message to be provided. The verify() method also requires a timeout value to be set. This method should be used when checking OpenStack operations (such as instance creation). Sometimes a cluster operation taking too long may be a sign of a problem, so this will secure the tests from such a situation or even from going into infinite loop. **fuel_health/common/ssh.py** - provides an easy way to ssh to nodes or instances. This module uses the paramiko library and contains some useful wrappers that make some routine tasks for you (such as ssh key authentication, starting transport threads, etc). Also, it contains a rather useful method exec_command_on_vm(), which makes an ssh to an instance through a controller and then executes the necessary command on it. OSTF Adapter architecture ^^^^^^^^^^^^^^^^^^^^^^^^^ .. image:: _images/plugin_structure.png The important thing to remember about OSTF Adapter is that just like when writing tests, all code should follow pep8 standard. Appendix 1 ---------- :: IdentityGroup = [ cfg.StrOpt('catalog_type', default='identity', may be changes on keystone help=""Catalog type of the Identity service.""), cfg.BoolOpt('disable_ssl_certificate_validation', default=False, help=""Set to True if using self-signed SSL certificates.""), cfg.StrOpt('uri', default='http://localhost/' (If you are using FileConfig set here appropriate address) help=""Full URI of the OpenStack Identity API (Keystone), v2""), cfg.StrOpt('url', default='http://localhost:5000/v2.0/', (If you are using FileConfig set here appropriate address to horizon) help=""Dashboard Openstack url, v2""), cfg.StrOpt('uri_v3', help='Full URI of the OpenStack Identity API (Keystone), v3'), cfg.StrOpt('strategy', default='keystone', help=""Which auth method does the environment use? "" ""(basic|keystone)""), cfg.StrOpt('region', default='RegionOne', help=""The identity region name to use.""), cfg.StrOpt('admin_username', default='nova' , (If you are using FileConfig set appropriate value here) help=""Administrative Username to use for"" ""Keystone API requests.""), cfg.StrOpt('admin_tenant_name', (If you are using FileConfig set appropriate value here) default='service', help=""Administrative Tenant name to use for Keystone API "" ""requests.""), cfg.StrOpt('admin_password', (If you are using FileConfig set appropriate value here) default='nova', help=""API key to use when authenticating as admin."", secret=True), ] ComputeGroup = [ cfg.BoolOpt('allow_tenant_isolation', default=False, help=""Allows test cases to create/destroy tenants and "" ""users. This option enables isolated test cases and "" ""better parallel execution, but also requires that "" ""OpenStack Identity API admin credentials are known.""), cfg.BoolOpt('allow_tenant_reuse', default=True, help=""If allow_tenant_isolation is True and a tenant that "" ""would be created for a given test already exists (such "" ""as from a previously-failed run), re-use that tenant "" ""instead of failing because of the conflict. Note that "" ""this would result in the tenant being deleted at the "" ""end of a subsequent successful run.""), cfg.StrOpt('image_ssh_user', default=""root"", (If you are using FileConfig set appropriate value here) help=""User name used to authenticate to an instance.""), cfg.StrOpt('image_alt_ssh_user', default=""root"", (If you are using FileConfig set appropriate value here) help=""User name used to authenticate to an instance using "" ""the alternate image.""), cfg.BoolOpt('create_image_enabled', default=True, help=""Does the test environment support snapshots?""), cfg.IntOpt('build_interval', default=10, help=""Time in seconds between build status checks.""), cfg.IntOpt('build_timeout', default=160, help=""Timeout in seconds to wait for an instance to build.""), cfg.BoolOpt('run_ssh', default=False, help=""Does the test environment support snapshots?""), cfg.StrOpt('ssh_user', default='root', (If you are using FileConfig set appropriate value here) help=""User name used to authenticate to an instance.""), cfg.IntOpt('ssh_timeout', default=50, help=""Timeout in seconds to wait for authentication to "" ""succeed.""), cfg.IntOpt('ssh_channel_timeout', default=20, help=""Timeout in seconds to wait for output from ssh "" ""channel.""), cfg.IntOpt('ip_version_for_ssh', default=4, help=""IP version used for SSH connections.""), cfg.StrOpt('catalog_type', default='compute', help=""Catalog type of the Compute service.""), cfg.StrOpt('path_to_private_key', default='/root/.ssh/id_rsa', (If you are using FileConfig set appropriate value here) help=""Path to a private key file for SSH access to remote "" ""hosts""), cfg.ListOpt('controller_nodes', default=[], (If you are using FileConfig set appropriate value here) help=""IP addresses of controller nodes""), cfg.ListOpt('compute_nodes', default=[], (If you are using FileConfig set appropriate value here) help=""IP addresses of compute nodes""), cfg.StrOpt('controller_node_ssh_user', default='root', (If you are using FileConfig set appropriate value here) help=""ssh user of one of the controller nodes""), cfg.StrOpt('controller_node_ssh_password', default='r00tme', (If you are using FileConfig set appropriate value here) help=""ssh user pass of one of the controller nodes""), cfg.StrOpt('image_name', default=""TestVM"", (If you are using FileConfig set appropriate value here) help=""Valid secondary image reference to be used in tests.""), cfg.StrOpt('deployment_mode', default=""ha"", (If you are using FileConfig set appropriate value here) help=""Deployments mode""), cfg.StrOpt('deployment_os', default=""RHEL"", (If you are using FileConfig set appropriate value here) help=""Deployments os""), cfg.IntOpt('flavor_ref', default=42, help=""Valid primary flavor to use in tests.""), ] ImageGroup = [ cfg.StrOpt('api_version', default='1', help=""Version of the API""), cfg.StrOpt('catalog_type', default='image', help='Catalog type of the Image service.'), cfg.StrOpt('http_image', default='http://download.cirros-cloud.net/0.3.1/' 'cirros-0.3.1-x86_64-uec.tar.gz', help='http accessable image') ] NetworkGroup = [ cfg.StrOpt('catalog_type', default='network', help='Catalog type of the Network service.'), cfg.StrOpt('tenant_network_cidr', default=""10.100.0.0/16"", help=""The cidr block to allocate tenant networks from""), cfg.IntOpt('tenant_network_mask_bits', default=29, help=""The mask bits for tenant networks""), cfg.BoolOpt('tenant_networks_reachable', default=True, help=""Whether tenant network connectivity should be "" ""evaluated directly""), cfg.BoolOpt('neutron_available', default=False, help=""Whether or not neutron is expected to be available""), ] VolumeGroup = [ cfg.IntOpt('build_interval', default=10, help='Time in seconds between volume availability checks.'), cfg.IntOpt('build_timeout', default=180, help='Timeout in seconds to wait for a volume to become' 'available.'), cfg.StrOpt('catalog_type', default='volume', help=""Catalog type of the Volume Service""), cfg.BoolOpt('cinder_node_exist', default=True, help=""Allow to run tests if cinder exist""), cfg.BoolOpt('multi_backend_enabled', default=False, help=""Runs Cinder multi-backend test (requires 2 backends)""), cfg.StrOpt('backend1_name', default='BACKEND_1', help=""Name of the backend1 (must be declared in cinder.conf)""), cfg.StrOpt('backend2_name', default='BACKEND_2', help=""Name of the backend2 (must be declared in cinder.conf)""), ] ObjectStoreConfig = [ cfg.StrOpt('catalog_type', default='object-store', help=""Catalog type of the Object-Storage service.""), cfg.StrOpt('container_sync_timeout', default=120, help=""Number of seconds to time on waiting for a container"" ""to container synchronization complete.""), cfg.StrOpt('container_sync_interval', default=5, help=""Number of seconds to wait while looping to check the"" ""status of a container to container synchronization""), ] ","Health Check (OSTF) Contributor's Guide ======================================= Health Check or OSTF? Main goal of OSTF Main rules of code contributions How to setup my environment? How should my modules look like? How to execute my tests? Now I'm done, what's next? General OSTF architecture OSTF packages architecture OSTF Adapter architecture Appendix 1 Health Check or OSTF? ^^^^^^^^^^^^^^^^^^^^^ Fuel UI has tab which is called Health Check. In development team though, there is an established acronym OSTF, which stands for OpenStack Testing Framework. This is all about the same. For simplicity, this document will use widely accepted term OSTF. Main goal of OSTF ^^^^^^^^^^^^^^^^^ After OpenStack installation via Fuel, it`s very important to understand whether it was successful and if it`s ready for work. OSTF provides a set of health checks - sanity, smoke, HA and additional components tests that check the proper operation of all system components in typical conditions. There are tests for OpenStack scenarios validation and other specific tests useful in validating an OpenStack deployment. Main rules of code contributions ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ There are a few rules you need to follow to successfully pass the code review and contribute high-quality code. How to setup my environment? ---------------------------- OSTF repository is located at git.openstack.org or GitHub mirror: https://github.com/openstack/fuel-ostf. You also have to install and hook-up gerrit, because otherwise you will not be able to contribute code. To do that you need to follow registration and installation instructions in the document https://wiki.openstack.org/wiki/CLA#Contributors_License_Agreement After you've completed the instructions, you're all set to begin editing/creating code. How should my modules look like? -------------------------------- The rules are quite simple: - follow Python coding rules - follow OpenStack contributor's rules - watch out for mistakes in docstrings - follow correct test structure - always execute your tests after you wrote them before sending them to review Speaking of following Python coding standards, you can find the style guide here: http://www.python.org/dev/peps/pep-0008/. You should read it carefully once and after implementing scripts you need to run some checks that will ensure that your code corresponds the standards. Without correcting issues with coding stadards your scripts will not be merged to master. You should always follow the following implementation rules: - name the test module, test class and test method beginning with the word ""test"" - if you have some tests that should be ran in a specific order, add a number to test method name, for example: test_001_create_keypair - use verify(), verify_response_body_content() and other methods from mixins (see OSTF package architecture fuel_health/common/test_mixins.py section) with giving them failed step parameter - always list all steps you are checking using test_mixins methods in the docstring in Scenario section in correct order - always use verify() method when you want to check an operation that can go to an infinite loop The test docstrings are another important piece and you should always stick to the following docstring structure: - test title - test description that will be always shown on UI (the remaining part of docstring will only be shown in cases when test failed) - target component (optional) - component name that is tested (e.g. Nova, Keystone) - blank line - test scenario, example:: Scenario: 1. Create a new small-size volume. 2. Wait for volume status to become ""available"". 3. Check volume has correct name. 4. Create new instance. 5. Wait for ""Active"" status. 6. Attach volume to an instance. 7. Check volume status is ""in use"". 8. Get information on the created volume by its id. 9. Detach volume from the instance. 10. Check volume has ""available"" status. 11. Delete volume. - test duration - an estimate of how much a test will take deployment tags (optional) - gives information about what kind of environment the test will be run, possible values are CENTOS, Ubuntu, RHEL nova_network, Heat, Sahara) Here's a test example which confirms the above explanations: .. image:: _images/test_docstring_structure.png Test run ordering and profiles ------------------------------ Each test set (sanity, smoke, HA and platform_tests) contains a special variable in __init__.py module which is called __profile__. The profile variable makes it possible to set different rules, such as test run order, set up deployment tags, information gathering on cleanup and expected time estimate for running a test set. If you are to develop a new set of tests, you need to create __init__.py module and place __profile__ dict in it. It is important that your profile matches the following structure:: __profile__ = { ""test_runs_ordering_priority"": 4, ""id"": ""platform_tests"", ""driver"": ""nose"", ""test_path"": ""fuel_health/tests/platform_tests"", ""description"": (""Platform services functional tests."" "" Duration 3 min - 60 min""), ""cleanup_path"": ""fuel_health.cleanup"", ""deployment_tags"": ['additional_components'], ""exclusive_testsets"": [], ""available_since_release"": ""2015.2-6.1"", } Take note of each field in the profile, along with acceptable values. - test_runs_ordering_priority is a field responsible for setting the priority in which the test set will be displayed. For example, if you set ""6"" for sanity tests and ""3"" for smoke tests, smoke test set will be displayed first on the HealthCheck tab; - id is just the unique id of a test set; - driver field is used for setting the test runner; - test_path is the field representing path where test set is located starting from fuel_health directory; - description is the field which contains the value to be shown on the UI as the tests duration; - cleanup_path is the field that specifies path to module responsible for cleanup mechanism (if you do not specify this value, cleanup will not be started after your test set); - deployment_tags field is used for defining when these tests should be available depending on cluster settings; - exclusive_testsets field gives you an opportunity to specify test sets that will be run successively. For example, you can specify ""smoke_sanity"" for smoke and sanity test set profiles, then these tests will be run not simultaneously, but successively. - available_since_release field is responsible for the release version starting from which a particular test set can be run. This means that the test will run only on the specified or newer version of Fuel. It is necessary to specify a value for each of the attributes. The optional attribute is ""deployment_tags"", meaning optionally you may not specify it in your profile at all. You can leave the ""exclusive_testsets"" empty ([]) to run your testset simultaneously with other ones. How to execute my tests? ------------------------ Simplest way is to install Fuel, and OSTF will be installed as part of it. - install virtualbox - build Fuel ISO: :ref:`building-fuel-iso` - use `virtualbox scripts to run an ISO <https://github.com/openstack/fuel-virtualbox/tree/master/>`_ - once the installation is finished, go to Fuel UI (usually it's 10.20.0.2:8000) and create a new cluster with necessary configuration - execute:: rsync -avz <path to fuel_health>/ root@10.20.0.2:/opt/fuel_plugins/ostf/lib/python2.6/site-packages/fuel_health/ - execute:: ssh root@10.20.0.2 ps uax | grep supervisor kill <supervisord process number> service supervisord start - go to Fuel UI and run your new tests Now I'm done, what's next? -------------------------- - don't forget to run pep8 on modified part of code - commit your changes - execute git review - ask to review in IRC From this part you'll only need to fix and commit review comments (if there are any) by doing the same steps. If there are no review comments left, the reviewers will accept your code and it will be automatically merged to master. General OSTF architecture ^^^^^^^^^^^^^^^^^^^^^^^^^ Tests are included to Fuel, so they will be accessible as soon as you install Fuel on your lab. OSTF architecture is quite simple, it consists of two main packages: - fuel_health which contains the test set itself and related modules - fuel_plugin which contains OSTF-adapter that forms necessary test list in context of cluster deployment options and transfers them to UI using REST_API On the other hand, there is some information necessary for test execution itself. There are several modules that gather information and parse them into objects which will be used in the tests themselves. All information is gathered from Nailgun component. OSTF REST api interface ----------------------- Fuel OSTF module provides not only testing, but also RESTful interface, a means for interaction with the components. In terms of REST, all types of OSTF entities are managed by three HTTP verbs: GET, POST and PUT. The following basic URL is used to make requests to OSTF:: {ostf_host}:{ostf_port}/v1/{requested_entity}/{cluster_id} Currently, you can get information about testsets, tests and testruns via GET request on corresponding URLs for ostf_plugin. To get information about testsets, make the following GET request on:: {ostf_host}:{ostf_port}/v1/testsets/{cluster_id} To get information about tests, make GET request on:: {ostf_host}:{ostf_port}/v1/tests/{cluster_id} To get information about executed tests, make the following GET requests: - for the whole set of testruns:: {ostf_host}:{ostf_port}/v1/testruns/ - for the particular testrun:: {ostf_host}:{ostf_port}/v1/testruns/{testrun_id} - for the list of testruns executed on the particular cluster:: {ostf_host}:{ostf_port}/v1/testruns/last/{cluster_id} To start test execution, make the following POST request on this URL:: {ostf_host}:{ostf_port}/v1/testruns/ The body must consist of JSON data structure with testsets and the list of tests belonging to it that must be executed. It should also have metadata with the information about the cluster (the key with the ""cluster_id"" name is used to store the parameter's value):: [ { ""testset"": ""test_set_name"", ""tests"": [""module.path.to.test.1"", ..., ""module.path.to.test.n""], ""metadata"": {""cluster_id"": id} }, ..., {...}, # info for another testrun {...}, ..., {...} ] If succeeded, OSTF adapter returns attributes of created testrun entities in JSON format. If you want to launch only one test, put its id into the list. To launch all tests, leave the list empty (by default). Example of the response:: [ { ""status"": ""running"", ""testset"": ""sanity"", ""meta"": null, ""ended_at"": ""2014-12-12 15:31:54.528773"", ""started_at"": ""2014-12-12 15:31:41.481071"", ""cluster_id"": 1, ""id"": 1, ""tests"": [.....info on tests.....] }, .... ] You can also stop and restart testruns. To do that, make a PUT request on testruns. The request body must contain the list of the testruns and tests to be stopped or restarted. Example:: [ { ""id"": test_run_id, ""status"": (""stopped"" | ""restarted""), ""tests"": [""module.path.to.test.1"", ..., ""module.path.to.test.n""] }, ..., {...}, # info for another testrun {...}, ..., {...} ] If succeeded, OSTF adapter returns attributes of the processed testruns in JSON format. Its structure is the same as for POST request, described above. OSTF package architecture ^^^^^^^^^^^^^^^^^^^^^^^^^ The main modules used in fuel_health package are: **config** module is responsible of getting data which is necessary for tests. All data is gathered from Nailgun component or a text config. Nailgun provides us with the following data: - OpenStack admin user name - OpenStack admin user password - OpenStack admin user tenant - ip of controllers node - ip of compute node - easily get data from nailgun by parsing role key in response json - deployment mode (HA /non-HA) - deployment os (RHEL/CENTOS) - keystone / horizon urls - tiny proxy address All other information we need is stored in config.py itself and remains default in this case. In case you are using data from Nailgun (OpenStack installation using Fuel) you should to the following: initialize NailgunConfig() class. Nailgun is running on Fuel master node, so you can easily get data for each cluster by invoking curl http:/localhost:8000/api/<uri_here>. Cluster id can be get from OS environment (provided by Fuel) If you want run OSTF for non Fuel installation, change the initialization of NailgunConfig() to FileConfig() and set parameters marked with green color in config - see Appendix 1 (default config file path fuel_health/etc/test.conf) **cleanup.py** - invoked by OSTF adapter in case if user stops test execution in Web UI. This module is responsible for deleting all test resources created during test suite run. It simply finds all resources whose name starts with ost1_test- and destroys each of them using _delete_it method. *Important: if you decide to add additional cleanup for this resource, you have to keep in mind: All resources depend on each other, that's why deleting a resource that is still in use will give you an exception; Don't forget that deleting several resources requires an ID for each resource, but not its name. You'll need to specify delete_type optional argument in _delete_it method to id* **nmanager.py** contains base classes for tests. Each base class contains setup, teardown and methods that act as an interlayer between tests and OpenStack python clients (see nmanager architecture diagram). .. image:: _images/nmanager.png **fuel_health/common/test_mixins.py** - provides mixins to pack response verification into a human-readable message. For assertion failure cases, the method requires a step on which we failed and a descriptive message to be provided. The verify() method also requires a timeout value to be set. This method should be used when checking OpenStack operations (such as instance creation). Sometimes a cluster operation taking too long may be a sign of a problem, so this will secure the tests from such a situation or even from going into infinite loop. **fuel_health/common/ssh.py** - provides an easy way to ssh to nodes or instances. This module uses the paramiko library and contains some useful wrappers that make some routine tasks for you (such as ssh key authentication, starting transport threads, etc). Also, it contains a rather useful method exec_command_on_vm(), which makes an ssh to an instance through a controller and then executes the necessary command on it. OSTF Adapter architecture ^^^^^^^^^^^^^^^^^^^^^^^^^ .. image:: _images/plugin_structure.png The important thing to remember about OSTF Adapter is that just like when writing tests, all code should follow pep8 standard. Appendix 1 ---------- :: IdentityGroup = [ cfg.StrOpt('catalog_type', default='identity', may be changes on keystone help=""Catalog type of the Identity service.""), cfg.BoolOpt('disable_ssl_certificate_validation', default=False, help=""Set to True if using self-signed SSL certificates.""), cfg.StrOpt('uri', default='http://localhost/' (If you are using FileConfig set here appropriate address) help=""Full URI of the OpenStack Identity API (Keystone), v2""), cfg.StrOpt('url', default='http://localhost:5000/v2.0/', (If you are using FileConfig set here appropriate address to horizon) help=""Dashboard Openstack url, v2""), cfg.StrOpt('uri_v3', help='Full URI of the OpenStack Identity API (Keystone), v3'), cfg.StrOpt('strategy', default='keystone', help=""Which auth method does the environment use? "" ""(basic|keystone)""), cfg.StrOpt('region', default='RegionOne', help=""The identity region name to use.""), cfg.StrOpt('admin_username', default='nova' , (If you are using FileConfig set appropriate value here) help=""Administrative Username to use for"" ""Keystone API requests.""), cfg.StrOpt('admin_tenant_name', (If you are using FileConfig set appropriate value here) default='service', help=""Administrative Tenant name to use for Keystone API "" ""requests.""), cfg.StrOpt('admin_password', (If you are using FileConfig set appropriate value here) default='nova', help=""API key to use when authenticating as admin."", secret=True), ] ComputeGroup = [ cfg.BoolOpt('allow_tenant_isolation', default=False, help=""Allows test cases to create/destroy tenants and "" ""users. This option enables isolated test cases and "" ""better parallel execution, but also requires that "" ""OpenStack Identity API admin credentials are known.""), cfg.BoolOpt('allow_tenant_reuse', default=True, help=""If allow_tenant_isolation is True and a tenant that "" ""would be created for a given test already exists (such "" ""as from a previously-failed run), re-use that tenant "" ""instead of failing because of the conflict. Note that "" ""this would result in the tenant being deleted at the "" ""end of a subsequent successful run.""), cfg.StrOpt('image_ssh_user', default=""root"", (If you are using FileConfig set appropriate value here) help=""User name used to authenticate to an instance.""), cfg.StrOpt('image_alt_ssh_user', default=""root"", (If you are using FileConfig set appropriate value here) help=""User name used to authenticate to an instance using "" ""the alternate image.""), cfg.BoolOpt('create_image_enabled', default=True, help=""Does the test environment support snapshots?""), cfg.IntOpt('build_interval', default=10, help=""Time in seconds between build status checks.""), cfg.IntOpt('build_timeout', default=160, help=""Timeout in seconds to wait for an instance to build.""), cfg.BoolOpt('run_ssh', default=False, help=""Does the test environment support snapshots?""), cfg.StrOpt('ssh_user', default='root', (If you are using FileConfig set appropriate value here) help=""User name used to authenticate to an instance.""), cfg.IntOpt('ssh_timeout', default=50, help=""Timeout in seconds to wait for authentication to "" ""succeed.""), cfg.IntOpt('ssh_channel_timeout', default=20, help=""Timeout in seconds to wait for output from ssh "" ""channel.""), cfg.IntOpt('ip_version_for_ssh', default=4, help=""IP version used for SSH connections.""), cfg.StrOpt('catalog_type', default='compute', help=""Catalog type of the Compute service.""), cfg.StrOpt('path_to_private_key', default='/root/.ssh/id_rsa', (If you are using FileConfig set appropriate value here) help=""Path to a private key file for SSH access to remote "" ""hosts""), cfg.ListOpt('controller_nodes', default=[], (If you are using FileConfig set appropriate value here) help=""IP addresses of controller nodes""), cfg.ListOpt('compute_nodes', default=[], (If you are using FileConfig set appropriate value here) help=""IP addresses of compute nodes""), cfg.StrOpt('controller_node_ssh_user', default='root', (If you are using FileConfig set appropriate value here) help=""ssh user of one of the controller nodes""), cfg.StrOpt('controller_node_ssh_password', default='r00tme', (If you are using FileConfig set appropriate value here) help=""ssh user pass of one of the controller nodes""), cfg.StrOpt('image_name', default=""TestVM"", (If you are using FileConfig set appropriate value here) help=""Valid secondary image reference to be used in tests.""), cfg.StrOpt('deployment_mode', default=""ha"", (If you are using FileConfig set appropriate value here) help=""Deployments mode""), cfg.StrOpt('deployment_os', default=""RHEL"", (If you are using FileConfig set appropriate value here) help=""Deployments os""), cfg.IntOpt('flavor_ref', default=42, help=""Valid primary flavor to use in tests.""), ] ImageGroup = [ cfg.StrOpt('api_version', default='1', help=""Version of the API""), cfg.StrOpt('catalog_type', default='image', help='Catalog type of the Image service.'), cfg.StrOpt('http_image', default='http://download.cirros-cloud.net/0.3.1/' 'cirros-0.3.1-x86_64-uec.tar.gz', help='http accessable image') ] NetworkGroup = [ cfg.StrOpt('catalog_type', default='network', help='Catalog type of the Network service.'), cfg.StrOpt('tenant_network_cidr', default=""10.100.0.0/16"", help=""The cidr block to allocate tenant networks from""), cfg.IntOpt('tenant_network_mask_bits', default=29, help=""The mask bits for tenant networks""), cfg.BoolOpt('tenant_networks_reachable', default=True, help=""Whether tenant network connectivity should be "" ""evaluated directly""), cfg.BoolOpt('neutron_available', default=False, help=""Whether or not neutron is expected to be available""), ] VolumeGroup = [ cfg.IntOpt('build_interval', default=10, help='Time in seconds between volume availability checks.'), cfg.IntOpt('build_timeout', default=180, help='Timeout in seconds to wait for a volume to become' 'available.'), cfg.StrOpt('catalog_type', default='volume', help=""Catalog type of the Volume Service""), cfg.BoolOpt('cinder_node_exist', default=True, help=""Allow to run tests if cinder exist""), cfg.BoolOpt('multi_backend_enabled', default=False, help=""Runs Cinder multi-backend test (requires 2 backends)""), cfg.StrOpt('backend1_name', default='BACKEND_1', help=""Name of the backend1 (must be declared in cinder.conf)""), cfg.StrOpt('backend2_name', default='BACKEND_2', help=""Name of the backend2 (must be declared in cinder.conf)""), ] ObjectStoreConfig = [ cfg.StrOpt('catalog_type', default='object-store', help=""Catalog type of the Object-Storage service.""), cfg.StrOpt('container_sync_timeout', default=120, help=""Number of seconds to time on waiting for a container"" ""to container synchronization complete.""), cfg.StrOpt('container_sync_interval', default=5, help=""Number of seconds to wait while looping to check the"" ""status of a container to container synchronization""), ] ",521,533
openstack%2Fgovernance~master~I5eeb59029bd8391c244f4ee48c8c69a90a603d98,openstack/governance,master,I5eeb59029bd8391c244f4ee48c8c69a90a603d98,Add new tags to DNS Project,MERGED,2016-08-15 13:21:05.000000000,2016-08-29 09:22:39.000000000,2016-08-29 09:22:39.000000000,"[{'_account_id': 3}, {'_account_id': 308}, {'_account_id': 970}, {'_account_id': 6159}]","[{'number': 1, 'created': '2016-08-15 13:21:05.000000000', 'files': ['reference/projects.yaml'], 'web_link': 'https://opendev.org/openstack/governance/commit/a98ddeca5fe0b71e95ce7ac4e4750a22153ae958', 'message': 'Add new tags to DNS Project\n\nAdds:\n\n- assert:follows-standard-deprecation\n- assert:supports-upgrade\n\nas we now have a gating grenade gate.\n\nChange-Id: I5eeb59029bd8391c244f4ee48c8c69a90a603d98\n'}]",0,355462,a98ddeca5fe0b71e95ce7ac4e4750a22153ae958,9,4,1,8099,,,0,"Add new tags to DNS Project

Adds:

- assert:follows-standard-deprecation
- assert:supports-upgrade

as we now have a gating grenade gate.

Change-Id: I5eeb59029bd8391c244f4ee48c8c69a90a603d98
",git fetch https://review.opendev.org/openstack/governance refs/changes/62/355462/1 && git format-patch -1 --stdout FETCH_HEAD,['reference/projects.yaml'],1,a98ddeca5fe0b71e95ce7ac4e4750a22153ae958,designate-updates, - assert:follows-standard-deprecation - assert:supports-upgrade,,2,0
openstack%2Ftraining-guides~master~I8839f08d2e85ccb751d354be5f48bdfd95b886e2,openstack/training-guides,master,I8839f08d2e85ccb751d354be5f48bdfd95b886e2,Do not publish doctrees,MERGED,2016-08-29 07:22:09.000000000,2016-08-29 09:22:33.000000000,2016-08-29 09:22:33.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 10497}, {'_account_id': 11889}]","[{'number': 1, 'created': '2016-08-29 07:22:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/training-guides/commit/581277854b4b50a72612217b5595519a15ca92ee', 'message': ""Do not publish doctrees\n\nDoctrees are build artefacts thta do not need to be published, place\nthem in separete directories so that they won't get published.\n\nChange-Id: I8839f08d2e85ccb751d354be5f48bdfd95b886e2\n""}, {'number': 2, 'created': '2016-08-29 08:28:34.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/training-guides/commit/546083d1b7c82413973b48ae315dc4dbe1aa0407', 'message': ""Do not publish doctrees\n\nDoctrees are build artefacts thta do not need to be published, place\nthem in separete directories so that they won't get published.\n\nChange-Id: I8839f08d2e85ccb751d354be5f48bdfd95b886e2\n""}]",1,361904,546083d1b7c82413973b48ae315dc4dbe1aa0407,12,4,2,6547,,,0,"Do not publish doctrees

Doctrees are build artefacts thta do not need to be published, place
them in separete directories so that they won't get published.

Change-Id: I8839f08d2e85ccb751d354be5f48bdfd95b886e2
",git fetch https://review.opendev.org/openstack/training-guides refs/changes/04/361904/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,581277854b4b50a72612217b5595519a15ca92ee,doctrees, sphinx-build -b slides -d doc/upstream-training/build.doctrees/slides doc/upstream-training/source/ doc/upstream-training/build/slides sphinx-build -b html -d doc/upstream-training/build.doctrees/slides doc/upstream-training doc/upstream-training/build/slides sphinx-build -b slides -d doc/training-guides/build.doctroees/slides/associate-guide doc/training-guides/associate-guide/ doc/training-guides/build/slides/associate-guide sphinx-build -b html -d doc/training-guides/build.doctrees/slides doc/training-guides doc/training-guides/build/slides doc/training-guides/index.rst sphinx-build -b slides -d doc/upstream-training/build.doctrees/slides doc/upstream-training/source/ doc/upstream-training/build/slides sphinx-build -b html -d doc/upstream-training/build.doctrees/slides doc/upstream-training doc/upstream-training/build/slides sphinx-build -b slides -d doc/training-guides/build.doctrees/slides/associate-guide doc/training-guides/associate-guide/ doc/training-guides/build/slides/associate-guide sphinx-build -b html -d doc/training-guides/build.doctrees/slides doc/training-guides doc/training-guides/build/slides doc/training-guides/index.rst, sphinx-build -b slides doc/upstream-training/source/ doc/upstream-training/build/slides sphinx-build -b html doc/upstream-training doc/upstream-training/build/slides sphinx-build -b slides doc/training-guides/associate-guide/ doc/training-guides/build/slides/associate-guide sphinx-build -b html doc/training-guides doc/training-guides/build/slides doc/training-guides/index.rst sphinx-build -b slides doc/upstream-training/source/ doc/upstream-training/build/slides sphinx-build -b html doc/upstream-training doc/upstream-training/build/slides sphinx-build -b slides doc/training-guides/associate-guide/ doc/training-guides/build/slides/associate-guide sphinx-build -b html doc/training-guides doc/training-guides/build/slides doc/training-guides/index.rst,8,8
openstack%2Fmagnum-ui~master~I553a559746911b5bd5b79f8f270e280882ba78b8,openstack/magnum-ui,master,I553a559746911b5bd5b79f8f270e280882ba78b8,Imported Translations from Zanata,MERGED,2016-08-29 09:05:41.000000000,2016-08-29 09:19:41.000000000,2016-08-29 09:19:41.000000000,"[{'_account_id': 3}, {'_account_id': 16352}]","[{'number': 1, 'created': '2016-08-29 09:05:41.000000000', 'files': ['magnum_ui/locale/ko_KR/LC_MESSAGES/djangojs.po', 'magnum_ui/locale/en_GB/LC_MESSAGES/django.po', 'magnum_ui/locale/fr/LC_MESSAGES/django.po', 'magnum_ui/locale/cs/LC_MESSAGES/djangojs.po', 'magnum_ui/locale/ko_KR/LC_MESSAGES/django.po', 'magnum_ui/locale/zh_CN/LC_MESSAGES/djangojs.po', 'magnum_ui/locale/ru/LC_MESSAGES/djangojs.po', 'magnum_ui/locale/zh_TW/LC_MESSAGES/django.po', 'magnum_ui/locale/cs/LC_MESSAGES/django.po', 'magnum_ui/locale/ru/LC_MESSAGES/django.po', 'magnum_ui/locale/en_GB/LC_MESSAGES/djangojs.po', 'magnum_ui/locale/zh_CN/LC_MESSAGES/django.po', 'magnum_ui/locale/ja/LC_MESSAGES/djangojs.po', 'magnum_ui/locale/pt_BR/LC_MESSAGES/django.po', 'magnum_ui/locale/de/LC_MESSAGES/django.po', 'magnum_ui/locale/ja/LC_MESSAGES/django.po', 'magnum_ui/locale/pt_BR/LC_MESSAGES/djangojs.po'], 'web_link': 'https://opendev.org/openstack/magnum-ui/commit/7a3f43f279e37c17e43f5a59726a05010ede70d1', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I553a559746911b5bd5b79f8f270e280882ba78b8\n'}]",0,361955,7a3f43f279e37c17e43f5a59726a05010ede70d1,6,2,1,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
https://wiki.openstack.org/wiki/Translations/Infrastructure

Change-Id: I553a559746911b5bd5b79f8f270e280882ba78b8
",git fetch https://review.opendev.org/openstack/magnum-ui refs/changes/55/361955/1 && git format-patch -1 --stdout FETCH_HEAD,"['magnum_ui/locale/ko_KR/LC_MESSAGES/djangojs.po', 'magnum_ui/locale/en_GB/LC_MESSAGES/django.po', 'magnum_ui/locale/fr/LC_MESSAGES/django.po', 'magnum_ui/locale/cs/LC_MESSAGES/djangojs.po', 'magnum_ui/locale/ko_KR/LC_MESSAGES/django.po', 'magnum_ui/locale/zh_CN/LC_MESSAGES/djangojs.po', 'magnum_ui/locale/ru/LC_MESSAGES/djangojs.po', 'magnum_ui/locale/zh_TW/LC_MESSAGES/django.po', 'magnum_ui/locale/cs/LC_MESSAGES/django.po', 'magnum_ui/locale/ru/LC_MESSAGES/django.po', 'magnum_ui/locale/en_GB/LC_MESSAGES/djangojs.po', 'magnum_ui/locale/zh_CN/LC_MESSAGES/django.po', 'magnum_ui/locale/ja/LC_MESSAGES/djangojs.po', 'magnum_ui/locale/pt_BR/LC_MESSAGES/django.po', 'magnum_ui/locale/de/LC_MESSAGES/django.po', 'magnum_ui/locale/ja/LC_MESSAGES/django.po', 'magnum_ui/locale/pt_BR/LC_MESSAGES/djangojs.po']",17,7a3f43f279e37c17e43f5a59726a05010ede70d1,zanata/translations,"""Project-Id-Version: magnum-ui 1.0.1.dev41\n""""POT-Creation-Date: 2016-08-29 05:32+0000\n""","""Project-Id-Version: magnum-ui 1.0.1.dev35\n""""POT-Creation-Date: 2016-08-23 00:46+0000\n""msgid """" ""Arbitrary labels in the form of key=value pairs to associate with a "" ""baymodel. May be used multiple times."" msgstr """" ""Rtulos arbitrrios no formato de pares key=value para associar ao modelo de "" ""compartimento. Pode ser utilizado mltiplas vezes."" msgid ""Bay"" msgstr ""Compartimento"" #, python-format msgid ""Bay %s was successfully created."" msgstr ""Compartimento %s criado com sucesso."" msgid ""Bay Create Timeout"" msgstr ""Tempo limite de Criao do Compartimento"" msgid ""Bay Name"" msgstr ""Nome do Compartimento"" msgid ""Baymodel"" msgstr ""Modelo de Compartimento"" #, python-format msgid ""Baymodel %s was successfully created."" msgstr ""O Modelo de Compartimento %s foi criado com sucesso."" msgid ""Baymodel Detail"" msgstr ""Detalhe do Modelo de Compartimento"" msgid ""Baymodel Name"" msgstr ""Nome do Modelo de Compartimento"" msgid ""Baymodels"" msgstr ""Modelos de Compartimentos"" msgid ""Bays"" msgstr ""Compartimentos"" msgid ""Choose a Baymodel"" msgstr ""Escolha um Modelo de Compartimento"" msgid ""Confirm Delete Bay"" msgid_plural ""Confirm Delete Bays"" msgstr[0] ""Confirmar Excluso de Compartimento"" msgstr[1] ""Confirmar Excluso de Compartimentos"" msgid ""Confirm Delete Baymodel"" msgid_plural ""Confirm Delete Baymodels"" msgstr[0] ""Confirma excluso do Modelo de Compartimento"" msgstr[1] ""Confirma excluso dos Modelos de Compartimentos"" msgid ""Create Bay"" msgstr ""Criar Compartimento"" msgid ""Create Baymodel"" msgstr ""Criar Modelo de Compartimento"" msgid ""Delete Bay"" msgid_plural ""Delete Bays"" msgstr[0] ""Excluir Compartimento"" msgstr[1] ""Excluir Compartimentos"" msgid ""Delete Baymodel"" msgid_plural ""Delete Baymodels"" msgstr[0] ""Excluir Modelo de Compartimento"" msgstr[1] ""Excluir Modelos de Compartimentos"" msgid ""Delete Baymodels"" msgstr ""Excluir Modelos de Compartimento"" msgid ""Delete Bays"" msgstr ""Excluir Compartimentos"" #, python-format msgid ""Deleted Bay: %s."" msgid_plural ""Deleted Bays: %s."" msgstr[0] ""Compartimento Excludo: %s."" msgstr[1] ""Compartimentos Excludos: %s."" #, python-format msgid ""Deleted Baymodel: %s."" msgid_plural ""Deleted Baymodels: %s."" msgstr[0] ""Modelo de Compartimento Excludo: %s."" msgstr[1] ""Modelos de Compartimentos Excludos: %s."" msgid ""Disable TLS in the Bay. Default: False"" msgstr ""Desativa TLS no Compartimento. Padro: Falso"" msgid ""Enable docker registry in the Bay. Default: False"" msgstr ""Ativar registro do docker no Compartimento. Padro: Falso"" msgid ""Make baymodel public. Default: False"" msgstr ""Tornar o modelo de compartimento pblico. Padro: Falso"" msgid ""Name of the bay to create."" msgstr ""Nome do compartimento a ser criado."" msgid ""Name of the baymodel to create."" msgstr ""Nome do modelo de compartimento a ser criado."" msgid ""Specify bay name and choose baymodel"" msgstr """" ""Especifique o nome do compartimento e escolha o modelo de compartimento"" msgid ""Specify conditions for bay creation."" msgstr ""Especifique as condies para criao do compartimento."" msgid ""Specify the nameserver to use for the Bay. Default: 8.8.8.8"" msgstr """" ""Especifique o endereo do servidor de nomes para utilizar com o "" ""Compartimento. Padro: 8.8.8.8"" msgid ""Specify the number of master nodes and bay nodes for the bay."" msgstr """" ""Especifique o nmero de ns principais e ns de compartimento para o "" ""compartimento."" msgid ""The DNS nameserver to use for this Bay"" msgstr """" ""O endereo do servidor de nomes do DNS para uso com este Compartimento."" msgid ""The bay node count."" msgstr ""A contagem de ns do compartimento."" msgid ""The external Neutron network ID to connect to this bay model"" msgstr """" ""O ID da rede externa do Neutron para conectar a este modelo de compartimento"" msgid ""The http_proxy address to use for nodes in bay"" msgstr ""O endereo http_proxy a ser usado para ns no compartimento. "" msgid ""The https_proxy address to use for nodes in bay"" msgstr ""O endereo https_proxy a ser usado para ns no compartimento. "" msgid ""The name or UUID of the SSH keypair to load into the Bay nodes."" msgstr """" ""Nome ou UUID do par de chaves SSH para carregar nos ns do Compartimento."" msgid ""The name or UUID of the base image to customize for the bay."" msgstr """" ""O nome ou UUID da imagem a ser usado como a imagem de base para customizar o "" ""compartimento."" msgid ""The no_proxy address to use for nodes in bay"" msgstr ""O endereo no_proxy a ser usado para ns no compartimento. "" msgid ""The nova flavor id to use when launching the bay. Default: m1.small"" msgstr """" ""O id do sabor nova para utilizar ao iniciar o compartimento. Padro: m1.small"" msgid """" ""The nova flavor id to use when launching the master node of the bay. "" ""Default: m1.small"" msgstr """" ""O id do sabor nova para utilizar ao iniciar o n principal do compartimento. "" ""Padro: m1.small"" msgid ""The number of master nodes for the bay."" msgstr ""O nmero de ns principais para o compartimento."" msgid ""The private Neutron network name to connect to this bay model"" msgstr """" ""O nome da rede privada do Neutron para conectar a este modelo de "" ""compartimento"" msgid """" ""The timeout for bay creation in minutes. Set to 0 for no timeout. The "" ""default is no timeout."" msgstr """" ""O Tempo limite para criar o compartimento em minutos. Configure para 0 para "" ""nenhum tempo limite. O padro  nenhum tempo limite."" msgid ""Unable to create Bay."" msgstr ""No  possvel criar Compartimento."" msgid ""Unable to create Baymodel"" msgstr ""No foi possvel criar o Modelo de Compartimento"" #, python-format msgid ""Unable to delete Bay: %s."" msgid_plural ""Unable to delete Bays: %s."" msgstr[0] ""No  possvel excluir Compartimento: %s."" msgstr[1] ""No  possvel excluir Compartimentos: %s."" #, python-format msgid ""Unable to delete Baymodel: %s."" msgid_plural ""Unable to delete Baymodels: %s."" msgstr[0] ""No  possvel excluir o Modelo de Compartimento: %s."" msgstr[1] ""No  possvel excluir os Modelos de Compartimentos: %s."" #, python-format msgid ""Unable to delete the Bay with id: %(id)s"" msgstr ""No foi possvel remover o Compartimento com id:%(id)s"" #, python-format msgid ""Unable to delete the Baymodel with id: %(id)s"" msgstr ""No foi possvel remover o Modelo de Compartimento com id: %(id)s"" msgid ""Unable to delete the Baymodels."" msgstr ""No foi possvel remover os Modelos de Compartimentos."" msgid ""Unable to delete the Bays."" msgstr ""No  possvel remover os Compartimentos."" msgid ""Unable to retrieve the Bay."" msgstr ""No  possvel recuperar o Compartimento."" msgid ""Unable to retrieve the Baymodel."" msgstr ""No foi possvel obter o Modelo de Compartimento."" msgid ""Unable to retrieve the Baymodels."" msgstr ""No foi possvel obter os Modelos de Compartimentos."" msgid ""Unable to retrieve the Bays."" msgstr ""No  possvel recuperar os Compartimentos."" #, python-format msgid """" ""You have selected \""%s\"". Please confirm your selection. Deleted bay is not "" ""recoverable."" msgid_plural """" ""You have selected \""%s\"". Please confirm your selection. Deleted bays are "" ""not recoverable."" msgstr[0] ""Voc selecionou \""%s\"". Compartimento excludo no  recupervel."" msgstr[1] """" ""Voc selecionou \""%s\"". Compartimentos excludos no so recuperveis."" #, python-format msgid """" ""You have selected \""%s\"". Please confirm your selection. Deleted baymodel is "" ""not recoverable."" msgid_plural """" ""You have selected \""%s\"". Please confirm your selection. Deleted baymodels "" ""are not recoverable."" msgstr[0] """" ""Voc selecionou \""%s\"". Modelo de Compartimento excludo no  recupervel."" msgstr[1] """" ""Voc selecionou \""%s\"". Modelos de Compartimento excludos no so "" ""recuperveis."" msgid ""{$ ctrl.bay.bay_create_timeout $} minute"" msgid_plural ""{$ ctrl.bay.bay_create_timeout $} minutes"" msgstr[0] ""{$ ctrl.bay.bay_create_timeout $} minuto"" msgstr[1] ""{$ ctrl.bay.bay_create_timeout $} minutos""",204,1713
openstack%2Fdeb-auto-backports~debian%2Fnewton~Ibd2fe0436579887cb493704e8eb2516d1775ab6a,openstack/deb-auto-backports,debian/newton,Ibd2fe0436579887cb493704e8eb2516d1775ab6a,Build python-pip,MERGED,2016-08-25 14:34:07.000000000,2016-08-29 09:17:32.000000000,2016-08-29 09:17:32.000000000,"[{'_account_id': 3}, {'_account_id': 6476}]","[{'number': 1, 'created': '2016-08-25 14:34:07.000000000', 'files': ['packages-list'], 'web_link': 'https://opendev.org/openstack/deb-auto-backports/commit/b165c245b831c58b3a55a3402fde75591f67d800', 'message': 'Build python-pip\n\nChange-Id: Ibd2fe0436579887cb493704e8eb2516d1775ab6a\n'}]",0,360594,b165c245b831c58b3a55a3402fde75591f67d800,8,2,1,6476,,,0,"Build python-pip

Change-Id: Ibd2fe0436579887cb493704e8eb2516d1775ab6a
",git fetch https://review.opendev.org/openstack/deb-auto-backports refs/changes/94/360594/1 && git format-patch -1 --stdout FETCH_HEAD,['packages-list'],1,b165c245b831c58b3a55a3402fde75591f67d800,python-pip,python-pip,#python-pip,1,1
openstack%2Fsenlin~master~I6ff088a4629578491e5982786083509071065ddd,openstack/senlin,master,I6ff088a4629578491e5982786083509071065ddd,Always change desired_capacity for node_delete,MERGED,2016-08-27 12:50:24.000000000,2016-08-29 09:15:10.000000000,2016-08-29 09:15:10.000000000,"[{'_account_id': 3}, {'_account_id': 7404}, {'_account_id': 8246}]","[{'number': 1, 'created': '2016-08-27 12:50:24.000000000', 'files': ['senlin/engine/actions/node_action.py', 'senlin/tests/unit/engine/actions/test_node_action.py'], 'web_link': 'https://opendev.org/openstack/senlin/commit/8a6a2e0325b04414278d0c25ca835c84dde57c2c', 'message': 'Always change desired_capacity for node_delete\n\nThis patch changes the logic for node_delete action so that\ndesired_capacity is adjusted when the node belongs to a cluster.\n\nChange-Id: I6ff088a4629578491e5982786083509071065ddd\n'}]",0,361598,8a6a2e0325b04414278d0c25ca835c84dde57c2c,6,3,1,8246,,,0,"Always change desired_capacity for node_delete

This patch changes the logic for node_delete action so that
desired_capacity is adjusted when the node belongs to a cluster.

Change-Id: I6ff088a4629578491e5982786083509071065ddd
",git fetch https://review.opendev.org/openstack/senlin refs/changes/98/361598/1 && git format-patch -1 --stdout FETCH_HEAD,"['senlin/engine/actions/node_action.py', 'senlin/tests/unit/engine/actions/test_node_action.py']",2,8a6a2e0325b04414278d0c25ca835c84dde57c2c,node-delete-capacity," cluster = mock.Mock(id='CID', desired_capacity=1) node = mock.Mock(id='NID', cluster_id='CID') node.do_delete.return_value = True cluster = mock.Mock(id='CID', desired_capacity=1) node = mock.Mock(id='NID', cluster_id='CID') node.do_delete.return_value = True node.do_delete.return_value = True node.do_delete.return_value = True node.do_delete.return_value = True @mock.patch.object(eventlet, 'sleep') @mock.patch.object(scaleutils, 'check_size_params') @mock.patch.object(cluster_mod.Cluster, 'load') def test_do_delete_failed_deletion(self, mock_c_load, mock_check, mock_sleep, mock_load): node = mock.Mock(id='NID', cluster_id='CLUSTER_ID') node.do_delete.return_value = False mock_load.return_value = node action = node_action.NodeAction(node.id, 'ACTION', self.ctx, cause=base_action.CAUSE_DERIVED) res_code, res_msg = action.do_delete() self.assertEqual(action.RES_ERROR, res_code) self.assertEqual(0, mock_check.call_count) self.assertEqual(0, mock_c_load.call_count) mock_load.assert_called_once_with(action.context, node_id='NID') self.assertEqual(0, mock_sleep.call_count) ", cluster = mock.Mock() cluster.id = 'CID' cluster.desired_capacity = 1 node = mock.Mock() node.id = 'NID' node.do_delete = mock.Mock(return_value=None) node.cluster_id = cluster.id node.do_delete = mock.Mock(return_value=mock.Mock()) cluster = mock.Mock() cluster.id = 'CID' cluster.desired_capacity = 1 node = mock.Mock() node.id = 'NID' node.do_delete = mock.Mock(return_value=None) node.cluster_id = cluster.id node.do_delete = mock.Mock(return_value=mock.Mock()) node.do_delete = mock.Mock(return_value=None) node.do_delete = mock.Mock(return_value=mock.Mock()) node.do_delete = mock.Mock(return_value=None) node.do_delete = mock.Mock(return_value=mock.Mock()) node.do_delete = mock.Mock(return_value=None) node.do_delete = mock.Mock(return_value=mock.Mock()),34,33
openstack%2Fsenlin~master~Ice6720a085d8f17000998a3b66aaa76f272dca48,openstack/senlin,master,Ice6720a085d8f17000998a3b66aaa76f272dca48,Tweak cluster recover workflow,MERGED,2016-08-27 03:53:21.000000000,2016-08-29 09:15:02.000000000,2016-08-29 09:15:02.000000000,"[{'_account_id': 3}, {'_account_id': 8246}]","[{'number': 1, 'created': '2016-08-27 03:53:21.000000000', 'files': ['senlin/policies/health_policy.py', 'senlin/tests/unit/engine/test_node.py', 'senlin/engine/actions/cluster_action.py', 'senlin/engine/node.py', 'senlin/tests/unit/engine/actions/test_cluster_action.py', 'senlin/tests/unit/policies/test_health_policy.py'], 'web_link': 'https://opendev.org/openstack/senlin/commit/7020abac905f7743d2a2707f4936d2469cb57a25', 'message': ""Tweak cluster recover workflow\n\nThis patch fixes several problems in the cluster recover execution path:\n\n- The cluster_recover action doesn't need to store anything into the\n  action.data because no object will read them.\n- The 'recover action' is modeled as a list, so it should remain as a\n  list till the very end of the call chain.\n- The 'force' delete option should be determined dynamically, we should\n  not enforce that too early.\n- When updating the node physical_id to a new one, we should use the\n  'set_status' call instead of involving a new DB interaction.\n\nChange-Id: Ice6720a085d8f17000998a3b66aaa76f272dca48\n""}]",0,361549,7020abac905f7743d2a2707f4936d2469cb57a25,6,2,1,8246,,,0,"Tweak cluster recover workflow

This patch fixes several problems in the cluster recover execution path:

- The cluster_recover action doesn't need to store anything into the
  action.data because no object will read them.
- The 'recover action' is modeled as a list, so it should remain as a
  list till the very end of the call chain.
- The 'force' delete option should be determined dynamically, we should
  not enforce that too early.
- When updating the node physical_id to a new one, we should use the
  'set_status' call instead of involving a new DB interaction.

Change-Id: Ice6720a085d8f17000998a3b66aaa76f272dca48
",git fetch https://review.opendev.org/openstack/senlin refs/changes/49/361549/1 && git format-patch -1 --stdout FETCH_HEAD,"['senlin/policies/health_policy.py', 'senlin/engine/actions/cluster_action.py', 'senlin/tests/unit/engine/test_node.py', 'senlin/engine/node.py', 'senlin/tests/unit/engine/actions/test_cluster_action.py', 'senlin/tests/unit/policies/test_health_policy.py']",6,7020abac905f7743d2a2707f4936d2469cb57a25,health-policy-params," 'health': { 'recover_action': ['REBUILD'], 'fencing': ['COMPUTE'], }"," 'health': { 'recover_action': 'REBUILD', 'fencing': ['COMPUTE'], }",39,49
openstack%2Ffuel-library~stable%2Fmitaka~I672a5331a5affb242fbc1a90d1f9508f3dd3f114,openstack/fuel-library,stable/mitaka,I672a5331a5affb242fbc1a90d1f9508f3dd3f114,Improve the new l23network loader,MERGED,2016-08-25 21:52:04.000000000,2016-08-29 09:11:47.000000000,2016-08-29 09:07:35.000000000,"[{'_account_id': 3}, {'_account_id': 7468}, {'_account_id': 8971}, {'_account_id': 11827}, {'_account_id': 14200}, {'_account_id': 14985}, {'_account_id': 20656}]","[{'number': 1, 'created': '2016-08-25 21:52:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/5db94bb704a951dba7eb2055413791a8c3454ebb', 'message': 'Improve the new l23network loader\n\n* Move the loader out of the puppetx\n* Add loader to the osnailyfacter module\n\ncherry picked from 44dde0cb55b97f0df019b7bec19840676571a83c\n\nChange-Id: I672a5331a5affb242fbc1a90d1f9508f3dd3f114\n'}, {'number': 2, 'created': '2016-08-25 21:52:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/991e4affb067c8e5e870b40f0745f93f4e7ce6c9', 'message': 'Improve the new l23network loader\n\n* Move the loader out of the puppetx\n* Add loader to the osnailyfacter module\n\nChange-Id: I672a5331a5affb242fbc1a90d1f9508f3dd3f114\n'}, {'number': 3, 'created': '2016-08-26 14:55:30.000000000', 'files': ['deployment/puppet/osnailyfacter/lib/puppet/parser/functions/generate_vips.rb', 'deployment/puppet/l23network/lib/puppet/parser/functions/get_default_gateways.rb', 'deployment/puppet/l23network/lib/puppet/parser/functions/get_nic_passthrough_whitelist.rb', 'deployment/puppet/l23network/lib/puppet/parser/functions/get_route_resource_name.rb', 'deployment/puppet/l23network/lib/puppet/parser/functions/get_pair_of_jack_names.rb', 'deployment/puppet/osnailyfacter/lib/loader/loader.rb', 'deployment/puppet/osnailyfacter/lib/loader/l23network.rb', 'deployment/puppet/l23network/lib/puppetx/loader/l23network.rb', 'deployment/puppet/l23network/lib/puppet/parser/functions/get_network_role_property.rb', 'deployment/puppet/l23network/lib/puppet/parser/functions/override_transformations.rb', 'deployment/puppet/l23network/lib/puppet/provider/interface_toolset.rb', 'deployment/puppet/l23network/lib/puppet/parser/functions/generate_network_config.rb', 'deployment/puppet/l23network/lib/puppet/provider/l23_stored_config_base.rb', 'deployment/puppet/l23network/lib/puppet/parser/functions/prepare_network_config.rb', 'deployment/puppet/l23network/lib/puppet/parser/functions/sanitize_bool_in_hash.rb', 'deployment/puppet/l23network/lib/puppetx/loader/filemapper.rb', 'deployment/puppet/l23network/lib/puppet/parser/functions/get_patch_name.rb', 'deployment/puppet/l23network/lib/puppet/loader/l23network.rb', 'deployment/puppet/osnailyfacter/lib/puppet/parser/functions/configure_default_route.rb', 'deployment/puppet/l23network/lib/puppet/parser/functions/remove_empty_members.rb', 'deployment/puppet/l23network/lib/puppet/loader/loader.rb', 'deployment/puppet/l23network/lib/puppet/loader/filemapper.rb', 'deployment/puppet/l23network/lib/puppet/parser/functions/get_dpdk_interfaces.rb', 'deployment/puppet/l23network/lib/puppet/type/l2_port.rb', 'deployment/puppet/l23network/lib/puppet/parser/functions/get_transformation_property.rb'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/85b615208418d7b8ada95ed34798626ce193bdec', 'message': 'Improve the new l23network loader\n\n* Move the loader out of the puppetx\n* Add loader to the osnailyfacter module\n\nChange-Id: I672a5331a5affb242fbc1a90d1f9508f3dd3f114\n'}]",1,360803,85b615208418d7b8ada95ed34798626ce193bdec,67,7,3,9037,,,0,"Improve the new l23network loader

* Move the loader out of the puppetx
* Add loader to the osnailyfacter module

Change-Id: I672a5331a5affb242fbc1a90d1f9508f3dd3f114
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/03/360803/1 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/puppet/osnailyfacter/lib/puppet/parser/functions/generate_vips.rb', 'deployment/puppet/l23network/lib/puppet/parser/functions/get_default_gateways.rb', 'deployment/puppet/l23network/lib/puppet/parser/functions/get_nic_passthrough_whitelist.rb', 'deployment/puppet/l23network/lib/puppet/parser/functions/get_route_resource_name.rb', 'deployment/puppet/l23network/lib/puppet/parser/functions/get_pair_of_jack_names.rb', 'deployment/puppet/osnailyfacter/lib/loader/loader.rb', 'deployment/puppet/osnailyfacter/lib/loader/l23network.rb', 'deployment/puppet/l23network/lib/puppetx/loader/l23network.rb', 'deployment/puppet/l23network/lib/puppet/parser/functions/get_network_role_property.rb', 'deployment/puppet/l23network/lib/puppet/parser/functions/override_transformations.rb', 'deployment/puppet/l23network/lib/puppet/provider/interface_toolset.rb', 'deployment/puppet/l23network/lib/puppet/parser/functions/generate_network_config.rb', 'deployment/puppet/l23network/lib/puppet/provider/l23_stored_config_base.rb', 'deployment/puppet/l23network/lib/puppet/parser/functions/prepare_network_config.rb', 'deployment/puppet/l23network/lib/puppet/parser/functions/sanitize_bool_in_hash.rb', 'deployment/puppet/l23network/lib/puppetx/loader/filemapper.rb', 'deployment/puppet/l23network/lib/puppet/parser/functions/get_patch_name.rb', 'deployment/puppet/l23network/lib/puppet/loader/l23network.rb', 'deployment/puppet/osnailyfacter/lib/puppet/parser/functions/configure_default_route.rb', 'deployment/puppet/l23network/lib/puppet/parser/functions/remove_empty_members.rb', 'deployment/puppet/l23network/lib/puppet/loader/loader.rb', 'deployment/puppet/l23network/lib/puppet/loader/filemapper.rb', 'deployment/puppet/l23network/lib/puppet/parser/functions/get_dpdk_interfaces.rb', 'deployment/puppet/l23network/lib/puppet/type/l2_port.rb', 'deployment/puppet/l23network/lib/puppet/parser/functions/get_transformation_property.rb']",25,5db94bb704a951dba7eb2055413791a8c3454ebb,mitaka,require_relative '../../loader/l23network',require_relative '../../../puppetx/loader/l23network',62,41
openstack%2Fneutron~master~I1288056fc1d5d8b7ccb122fdfb05c2c6f2718553,openstack/neutron,master,I1288056fc1d5d8b7ccb122fdfb05c2c6f2718553,Remove unused logging import,MERGED,2016-08-28 09:52:18.000000000,2016-08-29 09:05:15.000000000,2016-08-29 09:05:15.000000000,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 5170}, {'_account_id': 6524}, {'_account_id': 9732}, {'_account_id': 16237}, {'_account_id': 17776}]","[{'number': 1, 'created': '2016-08-28 09:52:18.000000000', 'files': ['neutron/api/rpc/handlers/resources_rpc.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/4c3e876f819fe810fb35796a86b19be5d020686e', 'message': 'Remove unused logging import\n\nChange-Id: I1288056fc1d5d8b7ccb122fdfb05c2c6f2718553\n'}]",0,361705,4c3e876f819fe810fb35796a86b19be5d020686e,21,7,1,22574,,,0,"Remove unused logging import

Change-Id: I1288056fc1d5d8b7ccb122fdfb05c2c6f2718553
",git fetch https://review.opendev.org/openstack/neutron refs/changes/05/361705/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/api/rpc/handlers/resources_rpc.py'],1,4c3e876f819fe810fb35796a86b19be5d020686e,log,,from oslo_log import log as loggingLOG = logging.getLogger(__name__) ,0,4
openstack%2Fmurano-apps~stable%2Fmitaka~Id2d68346034c0697f3fb41a090201e8736f8deec,openstack/murano-apps,stable/mitaka,Id2d68346034c0697f3fb41a090201e8736f8deec,[K8s] Fixing service naming,MERGED,2016-08-26 12:12:52.000000000,2016-08-29 09:01:31.000000000,2016-08-29 09:01:31.000000000,"[{'_account_id': 3}, {'_account_id': 6577}, {'_account_id': 13149}, {'_account_id': 15168}]","[{'number': 1, 'created': '2016-08-26 12:12:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-apps/commit/fa75cb30ef542be9aa1ecf0178680735b558baea', 'message': '[K8s] Fixing service naming\n\n * Due to the service name length limitation\n   it needs to be cut to 24 characters.\n\nCloses-Bug: #1613651\n\nChange-Id: Id2d68346034c0697f3fb41a090201e8736f8deec\n(cherry picked from commit 2fe1ddc8e3c8a9f2d07c1f6bde25156f39776b62)\n'}, {'number': 2, 'created': '2016-08-29 08:14:07.000000000', 'files': ['Docker/Kubernetes/KubernetesCluster/package/Classes/KubernetesCluster.yaml'], 'web_link': 'https://opendev.org/openstack/murano-apps/commit/6277ddf2047aa272e693ccb0dd49de2ed550e63a', 'message': '[K8s] Fixing service naming\n\n * Due to the service name length limitation\n   it needs to be cut to 24 characters.\n\nCloses-Bug: #1613651\n\nChange-Id: Id2d68346034c0697f3fb41a090201e8736f8deec\n(cherry picked from commit 2fe1ddc8e3c8a9f2d07c1f6bde25156f39776b62)\n'}]",0,361135,6277ddf2047aa272e693ccb0dd49de2ed550e63a,16,4,2,7700,,,0,"[K8s] Fixing service naming

 * Due to the service name length limitation
   it needs to be cut to 24 characters.

Closes-Bug: #1613651

Change-Id: Id2d68346034c0697f3fb41a090201e8736f8deec
(cherry picked from commit 2fe1ddc8e3c8a9f2d07c1f6bde25156f39776b62)
",git fetch https://review.opendev.org/openstack/murano-apps refs/changes/35/361135/2 && git format-patch -1 --stdout FETCH_HEAD,['Docker/Kubernetes/KubernetesCluster/package/Classes/KubernetesCluster.yaml'],1,fa75cb30ef542be9aa1ecf0178680735b558baea,bug/1613651," - $serviceName: format('{0}-{1}', randomName(), $applicationName).substring(0, 24).toLower()"," - $serviceName: format('svc-{0}', randomName())",1,2
openstack%2Fkolla-kubernetes~master~I676a6b7199a6c4db0b3420c38ff536acbd02b436,openstack/kolla-kubernetes,master,I676a6b7199a6c4db0b3420c38ff536acbd02b436,Cleanup tox.ini constraints,MERGED,2016-08-26 08:46:55.000000000,2016-08-29 08:58:08.000000000,2016-08-29 08:58:08.000000000,"[{'_account_id': 3}, {'_account_id': 10419}, {'_account_id': 19384}, {'_account_id': 22582}]","[{'number': 1, 'created': '2016-08-26 08:46:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-kubernetes/commit/b0fa3c65df2b6d168aca36cd3b8d6f2dfada8eca', 'message': 'Properly use constraints\n\nRemove old constraint setup, use constraints everywhere in the current\nway.\n\nThis removes all the -constraint environments and uses normal\nenvironments that are constraint enabled.\n\nSee also\nhttp://lists.openstack.org/pipermail/openstack-dev/2016-August/101474.html\n\nChange-Id: I676a6b7199a6c4db0b3420c38ff536acbd02b436\n'}, {'number': 2, 'created': '2016-08-26 08:52:05.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/kolla-kubernetes/commit/c8a0f9b6b4d99f01a9e4886da778d157e968a8ca', 'message': 'Cleanup tox.ini constraints\n\nRemove old constraint setup, these environments are completely unused.\nway.\n\nNote that the repo did not use constraints before - and does not use\nthem now since the repo is not part of global requirements process.\n\nChange-Id: I676a6b7199a6c4db0b3420c38ff536acbd02b436\n'}]",0,360984,c8a0f9b6b4d99f01a9e4886da778d157e968a8ca,13,4,2,6547,,,0,"Cleanup tox.ini constraints

Remove old constraint setup, these environments are completely unused.
way.

Note that the repo did not use constraints before - and does not use
them now since the repo is not part of global requirements process.

Change-Id: I676a6b7199a6c4db0b3420c38ff536acbd02b436
",git fetch https://review.opendev.org/openstack/kolla-kubernetes refs/changes/84/360984/2 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,b0fa3c65df2b6d168aca36cd3b8d6f2dfada8eca,constraints,"envlist = py34,py27,pypy,pep8install_command = pip install -c{env:UPPER_CONSTRAINTS_FILE:https://git.openstack.org/cgit/openstack/requirements/plain/upper-constraints.txt} {opts} {packages}","envlist = py34-constraints,py27-constraints,pypy-constraints,pep8-constraintsinstall_command = constraints: {[testenv:common-constraints]install_command} pip install -U {opts} {packages}[testenv:common-constraints] install_command = pip install -c{env:UPPER_CONSTRAINTS_FILE:https://git.openstack.org/cgit/openstack/requirements/plain/upper-constraints.txt} {opts} {packages} [testenv:pep8-constraints] install_command = {[testenv:common-constraints]install_command} commands = flake8 {posargs} [testenv:venv-constraints] install_command = {[testenv:common-constraints]install_command} commands = {posargs} [testenv:cover-constraints] install_command = {[testenv:common-constraints]install_command} commands = python setup.py test --coverage --testr-args='{posargs}' [testenv:docs-constraints] install_command = {[testenv:common-constraints]install_command} commands = python setup.py build_sphinx [testenv:debug-constraints] install_command = {[testenv:common-constraints]install_command} commands = oslo_debug_helper {posargs} ",2,27
openstack%2Ftripleo-heat-templates~master~Ic179550027f37946097afe0e5b9f504ea19fa7bc,openstack/tripleo-heat-templates,master,Ic179550027f37946097afe0e5b9f504ea19fa7bc,Rename opendaylight service to opendaylight_api,MERGED,2016-08-27 08:55:50.000000000,2016-08-29 08:48:41.000000000,2016-08-29 08:48:41.000000000,"[{'_account_id': 3}, {'_account_id': 4328}, {'_account_id': 4330}, {'_account_id': 10873}, {'_account_id': 17280}]","[{'number': 1, 'created': '2016-08-27 08:55:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/28e489d939fa5cfe1d112df811cca800f09e17e6', 'message': 'Rename opendaylight service to opendaylight_api\n\nFor compatibility with the custom-roles patches which convert\nhard-coded hiera mappings (such as opendaylight_api_node_ips) to\ndata generated based on the service_name, we need to either change\nthis name to match the hiera (node_ips and vip) keys, or change the\nhiera keys to match the service.  I took the former approach because\nit involves less juggling patch dependencies between t-h-t and p-t.\n\nChange-Id: Ic179550027f37946097afe0e5b9f504ea19fa7bc\nPartially-Implements: blueprint custom-roles\n'}, {'number': 2, 'created': '2016-08-28 09:32:48.000000000', 'files': ['environments/neutron-opendaylight-l3.yaml', 'environments/neutron-opendaylight.yaml', 'puppet/services/opendaylight-api.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/49b7064601a58f9d2861674d97934eea05b04592', 'message': 'Rename opendaylight service to opendaylight_api\n\nFor compatibility with the custom-roles patches which convert\nhard-coded hiera mappings (such as opendaylight_api_node_ips) to\ndata generated based on the service_name, we need to either change\nthis name to match the hiera (node_ips and vip) keys, or change the\nhiera keys to match the service.  I took the former approach because\nit involves less juggling patch dependencies between t-h-t and p-t.\n\nChange-Id: Ic179550027f37946097afe0e5b9f504ea19fa7bc\nPartially-Implements: blueprint custom-roles\n'}]",0,361578,49b7064601a58f9d2861674d97934eea05b04592,18,5,2,4328,,,0,"Rename opendaylight service to opendaylight_api

For compatibility with the custom-roles patches which convert
hard-coded hiera mappings (such as opendaylight_api_node_ips) to
data generated based on the service_name, we need to either change
this name to match the hiera (node_ips and vip) keys, or change the
hiera keys to match the service.  I took the former approach because
it involves less juggling patch dependencies between t-h-t and p-t.

Change-Id: Ic179550027f37946097afe0e5b9f504ea19fa7bc
Partially-Implements: blueprint custom-roles
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/78/361578/1 && git format-patch -1 --stdout FETCH_HEAD,"['environments/neutron-opendaylight-l3.yaml', 'environments/neutron-opendaylight.yaml', 'puppet/services/opendaylight-api.yaml']",3,28e489d939fa5cfe1d112df811cca800f09e17e6,bp/custom-roles, service_name: opendaylight_api, service_name: opendaylight,3,3
openstack%2Fmistral-lib~master~Ieeabdaa74f76e5dc6b9530a35bc6343e4250194a,openstack/mistral-lib,master,Ieeabdaa74f76e5dc6b9530a35bc6343e4250194a,"Cleanup tox.ini, enable constraints",MERGED,2016-08-26 14:48:08.000000000,2016-08-29 08:47:06.000000000,2016-08-29 08:47:06.000000000,"[{'_account_id': 3}, {'_account_id': 8731}, {'_account_id': 18238}, {'_account_id': 19206}, {'_account_id': 23294}]","[{'number': 1, 'created': '2016-08-26 14:48:08.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/mistral-lib/commit/e14e4ab8e319658c2d2792c025667fade811c573', 'message': 'Cleanup tox.ini, enable constraints\n\nRemove old and unused constraints environments from tox.ini. Those\nhave never been used. Use standard environments as default list.\n\nEnable use of constraints for all tox based jobs.\n\nFor more information about constraints see:\nhttp://lists.openstack.org/pipermail/openstack-dev/2016-August/101474.html\n\nChange-Id: Ieeabdaa74f76e5dc6b9530a35bc6343e4250194a\n'}]",0,361265,e14e4ab8e319658c2d2792c025667fade811c573,8,5,1,6547,,,0,"Cleanup tox.ini, enable constraints

Remove old and unused constraints environments from tox.ini. Those
have never been used. Use standard environments as default list.

Enable use of constraints for all tox based jobs.

For more information about constraints see:
http://lists.openstack.org/pipermail/openstack-dev/2016-August/101474.html

Change-Id: Ieeabdaa74f76e5dc6b9530a35bc6343e4250194a
",git fetch https://review.opendev.org/openstack/mistral-lib refs/changes/65/361265/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,e14e4ab8e319658c2d2792c025667fade811c573,constraints,"envlist = py34,py27,pep8install_command = pip install -c{env:UPPER_CONSTRAINTS_FILE:https://git.openstack.org/cgit/openstack/requirements/plain/upper-constraints.txt} {opts} {packages}","envlist = py34-constraints,py27-constraints,pep8-constraintsinstall_command = constraints: {[testenv:common-constraints]install_command} pip install -U {opts} {packages}[testenv:common-constraints] install_command = pip install -c{env:UPPER_CONSTRAINTS_FILE:https://git.openstack.org/cgit/openstack/requirements/plain/upper-constraints.txt} {opts} {packages} [testenv:pep8-constraints] install_command = {[testenv:common-constraints]install_command} commands = flake8 {posargs} [testenv:venv-constraints] install_command = {[testenv:common-constraints]install_command} commands = {posargs} [testenv:cover-constraints] install_command = {[testenv:common-constraints]install_command} commands = python setup.py test --coverage --testr-args='{posargs}' [testenv:docs-constraints] install_command = {[testenv:common-constraints]install_command} commands = python setup.py build_sphinx [testenv:debug-constraints] install_command = {[testenv:common-constraints]install_command} commands = oslo_debug_helper {posargs} ",2,27
openstack%2Ffuel-library~master~Iaa4855d769fe1e0203fcfb9981413273e0e4dda2,openstack/fuel-library,master,Iaa4855d769fe1e0203fcfb9981413273e0e4dda2,Detect a split-brain for Galera OCF RA,MERGED,2016-05-18 15:07:10.000000000,2016-08-29 08:44:09.000000000,2016-05-20 08:15:07.000000000,"[{'_account_id': 3}, {'_account_id': 6926}, {'_account_id': 8786}, {'_account_id': 8971}, {'_account_id': 11090}, {'_account_id': 14200}, {'_account_id': 18290}, {'_account_id': 20656}]","[{'number': 1, 'created': '2016-05-18 15:07:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/36834810bec0b37bafb4a356f614e09c50cb4d25', 'message': 'Detect a split-brain for Galera OCF RA\n\n* One and only seed node (the one with the wsrep-new-cluster) shall\n  be running, eventually.\n* For action monitor, check if the node is the seed one\n  and is running the most recent GTID, or fail\n\nCloses-bug: #1583173\n\nChange-Id: Iaa4855d769fe1e0203fcfb9981413273e0e4dda2\nSigned-off-by: Bogdan Dobrelya <bdobrelia@mirantis.com>\n'}, {'number': 2, 'created': '2016-05-18 15:11:05.000000000', 'files': ['files/fuel-ha-utils/ocf/mysql-wss'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/8093431349441f6b486e45e8aab62e0a8927a8e2', 'message': 'Detect a split-brain for Galera OCF RA\n\n* One and only seed node (the one with the wsrep-new-cluster) shall\n  be running, eventually.\n* For action monitor, check if the node is the seed one\n  and is running the most recent GTID, or fail\n\nCloses-bug: #1583173\n\nChange-Id: Iaa4855d769fe1e0203fcfb9981413273e0e4dda2\nSigned-off-by: Bogdan Dobrelya <bdobrelia@mirantis.com>\n'}]",0,318162,8093431349441f6b486e45e8aab62e0a8927a8e2,42,8,2,6926,,,0,"Detect a split-brain for Galera OCF RA

* One and only seed node (the one with the wsrep-new-cluster) shall
  be running, eventually.
* For action monitor, check if the node is the seed one
  and is running the most recent GTID, or fail

Closes-bug: #1583173

Change-Id: Iaa4855d769fe1e0203fcfb9981413273e0e4dda2
Signed-off-by: Bogdan Dobrelya <bdobrelia@mirantis.com>
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/62/318162/2 && git format-patch -1 --stdout FETCH_HEAD,['files/fuel-ha-utils/ocf/mysql-wss'],1,36834810bec0b37bafb4a356f614e09c50cb4d25,bug/1583173,"#Get galera GTID from local mysql instance. #If changed, update it in CIB, then return 0 and new GTID #If unchanged or bad vlue, return 1 and the current GTID from CIB echo ""${GTID_current}"" return 1 local rc# Return 0 and the pid, if running a new cluster as a seed node check_if_new_cluster() { local pid # Match a mysqld pid by the datadir and a new cluster sign, exclude position recovery pid=$(ps -C mysqld -o pid= -o command= -o args= | \ grep -e ""${OCF_RESKEY_datadir}.*wsrep-new-cluster"" -e ""wsrep-new-cluster.*${OCF_RESKEY_datadir}"" | \ awk '!/wsrep.recover|defunct/ {print $1}') if [ ""${pid}"" ]; then echo ""${pid}"" exit 0 fi exit 1 } #Find the best master and return its GTID. #If the best master is this node, propose it as a prim, then return 1. #If another node is, check if *this* node is also running a new cluster and exit #with error for safety concerns local GTID local pid GTID=$(get_node_gtid $MASTER) ocf_log info ""${LH} I\'m Primary Component. Join me! My GTID: ${GTID}"" echo ""${GTID}"" ocf_log info ""${LH} My neighbour is Primary Component with GTID: ${GTID}"" pid=$(check_if_new_cluster) if [ ""${pid}"" ]; then ocf_log err ""${LH} But I'm running a new cluster, PID:${pid}, this is a split-brain!"" exit $OCF_ERR_GENERIC fi echo ""${GTID}"" local MGTID local GTID GTID=$(update_node_gtid) # Check if this node is the master and is running the most recent GTID MGTID=$(check_if_galera_pc) rc=$? if [ $rc -eq 1 -a ""${MGTID}"" != ""${GTID}"" ]; then ocf_log err ""${LH} I'm a master, and my GTID: ${GTID}, which was not expected"" return $OCF_ERR_GENERIC fi","#Get galera GTID from local mysql instance ocf_log info ""${LH} I\'m Primary Component. Join me!"" ocf_log info ""${LH} My neighbour is Primary Component"" update_node_gtid",46,4
openstack%2Fheat~master~I957708562f20c3cc0974a48b448f743b39f3ec87,openstack/heat,master,I957708562f20c3cc0974a48b448f743b39f3ec87,Updated from global requirements,MERGED,2016-08-29 06:10:48.000000000,2016-08-29 08:42:22.000000000,2016-08-29 08:42:22.000000000,"[{'_account_id': 3}, {'_account_id': 8833}]","[{'number': 1, 'created': '2016-08-29 06:10:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/6dffe25cd906aed64140966496b424cc471247d6', 'message': 'Updated from global requirements\n\nChange-Id: I957708562f20c3cc0974a48b448f743b39f3ec87\n'}, {'number': 2, 'created': '2016-08-29 06:21:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/0e29a381e3c2b5d2bfb9adfe06af0bde550dceee', 'message': 'Updated from global requirements\n\nChange-Id: I957708562f20c3cc0974a48b448f743b39f3ec87\n'}, {'number': 3, 'created': '2016-08-29 06:42:37.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/heat/commit/93bbf9261c4b0cf1548d8c91744b8d6d5c8960cb', 'message': 'Updated from global requirements\n\nChange-Id: I957708562f20c3cc0974a48b448f743b39f3ec87\n'}]",0,361860,93bbf9261c4b0cf1548d8c91744b8d6d5c8960cb,8,2,3,11131,,,0,"Updated from global requirements

Change-Id: I957708562f20c3cc0974a48b448f743b39f3ec87
",git fetch https://review.opendev.org/openstack/heat refs/changes/60/361860/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,6dffe25cd906aed64140966496b424cc471247d6,openstack/requirements,python-heatclient>=1.4.0 # Apache-2.0,python-heatclient>=1.1.0 # Apache-2.0,1,1
openstack%2Fmistral~master~Ie742d1565f505404fdb58d4d9d0f013ae4475ff4,openstack/mistral,master,Ie742d1565f505404fdb58d4d9d0f013ae4475ff4,TrivialFix: Remove logging import unused,MERGED,2016-08-26 10:21:39.000000000,2016-08-29 08:41:59.000000000,2016-08-29 08:41:59.000000000,"[{'_account_id': 3}, {'_account_id': 7700}, {'_account_id': 9712}, {'_account_id': 18238}]","[{'number': 1, 'created': '2016-08-26 10:21:39.000000000', 'files': ['mistral/engine/actions.py', 'mistral/utils/rest_utils.py', 'mistral/cmd/launch.py'], 'web_link': 'https://opendev.org/openstack/mistral/commit/72a34e859325864e02f5513bd5b2223269f354f5', 'message': 'TrivialFix: Remove logging import unused\n\nThis patch removes logging import unused in\nmistral/cmd/launch.py\nmistral/engine/actions.py\nmistral/utils/rest_utils.py\n\nChange-Id: Ie742d1565f505404fdb58d4d9d0f013ae4475ff4\n'}]",0,361060,72a34e859325864e02f5513bd5b2223269f354f5,8,4,1,15905,,,0,"TrivialFix: Remove logging import unused

This patch removes logging import unused in
mistral/cmd/launch.py
mistral/engine/actions.py
mistral/utils/rest_utils.py

Change-Id: Ie742d1565f505404fdb58d4d9d0f013ae4475ff4
",git fetch https://review.opendev.org/openstack/mistral refs/changes/60/361060/1 && git format-patch -1 --stdout FETCH_HEAD,"['mistral/engine/actions.py', 'mistral/utils/rest_utils.py', 'mistral/cmd/launch.py']",3,72a34e859325864e02f5513bd5b2223269f354f5,bug/remove-logging-unused,,LOG = logging.getLogger(__name__) ,0,8
openstack%2Ftripleo-puppet-elements~master~I743f349decfc560c757fe70373073d9e59ff0b64,openstack/tripleo-puppet-elements,master,I743f349decfc560c757fe70373073d9e59ff0b64,Install OpenStack Manila UI,MERGED,2016-08-15 09:44:38.000000000,2016-08-29 08:41:49.000000000,2016-08-29 08:41:49.000000000,"[{'_account_id': 3}, {'_account_id': 2417}, {'_account_id': 4328}, {'_account_id': 8297}, {'_account_id': 8449}, {'_account_id': 9003}, {'_account_id': 20775}]","[{'number': 1, 'created': '2016-08-15 09:44:38.000000000', 'files': ['elements/overcloud-controller/pkg-map', 'elements/overcloud-controller/install.d/package-installs-overcloud-controller'], 'web_link': 'https://opendev.org/openstack/tripleo-puppet-elements/commit/f5a195ca1032e784f2d74be997f174217315c350', 'message': 'Install OpenStack Manila UI\n\nChange-Id: I743f349decfc560c757fe70373073d9e59ff0b64\n'}]",0,355394,f5a195ca1032e784f2d74be997f174217315c350,37,7,1,5202,,,0,"Install OpenStack Manila UI

Change-Id: I743f349decfc560c757fe70373073d9e59ff0b64
",git fetch https://review.opendev.org/openstack/tripleo-puppet-elements refs/changes/94/355394/1 && git format-patch -1 --stdout FETCH_HEAD,"['elements/overcloud-controller/pkg-map', 'elements/overcloud-controller/install.d/package-installs-overcloud-controller']",2,f5a195ca1032e784f2d74be997f174217315c350,manila-ui,manila_ui_package,,2,0
openstack%2Ftripleo-heat-templates~master~I62273f403838893602816204d9bc50d516c0057f,openstack/tripleo-heat-templates,master,I62273f403838893602816204d9bc50d516c0057f,Create hiera service_enabled keys for enabled services,MERGED,2016-08-26 09:25:07.000000000,2016-08-29 08:40:24.000000000,2016-08-29 08:40:24.000000000,"[{'_account_id': 3}, {'_account_id': 4330}, {'_account_id': 6796}, {'_account_id': 6924}, {'_account_id': 8042}, {'_account_id': 10873}]","[{'number': 1, 'created': '2016-08-26 09:25:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/21af4484d29420cef3ebcf9ae5f58d77eb1a2f16', 'message': 'Create hiera service_enabled keys for enabled services\n\nThis adds a list of all enabled service_names in the\nenabled_services key, and also generates some boolean\nvalues e.g service_name_enabled, which is more convenient\nfor some usage (such as haproxy where we need an easy way to\nset a flag saying if a given service is enabled)\n\nPartially-Implements: blueprint custom-roles\nChange-Id: I62273f403838893602816204d9bc50d516c0057f\n'}, {'number': 2, 'created': '2016-08-26 09:26:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/5536708db6c3b2bcd6a3b3b7ffde7ef15aa74ae0', 'message': 'Create hiera service_enabled keys for enabled services\n\nThis adds a list of all enabled service_names in the\nenabled_services key, and also generates some boolean\nvalues e.g service_name_enabled, which is more convenient\nfor some usage (such as haproxy where we need an easy way to\nset a flag saying if a given service is enabled)\n\nPartially-Implements: blueprint custom-roles\nChange-Id: I62273f403838893602816204d9bc50d516c0057f\n'}, {'number': 3, 'created': '2016-08-27 08:34:34.000000000', 'files': ['overcloud.yaml', 'puppet/all-nodes-config.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/753131d6b5520552f73c9489274f2bd3c25b9e50', 'message': 'Create hiera service_enabled keys for enabled services\n\nThis adds a list of all enabled service_names in the\nenabled_services key, and also generates some boolean\nvalues e.g service_name_enabled, which is more convenient\nfor some usage (such as haproxy where we need an easy way to\nset a flag saying if a given service is enabled)\n\nPartially-Implements: blueprint custom-roles\nChange-Id: I62273f403838893602816204d9bc50d516c0057f\n'}]",0,361029,753131d6b5520552f73c9489274f2bd3c25b9e50,24,6,3,4328,,,0,"Create hiera service_enabled keys for enabled services

This adds a list of all enabled service_names in the
enabled_services key, and also generates some boolean
values e.g service_name_enabled, which is more convenient
for some usage (such as haproxy where we need an easy way to
set a flag saying if a given service is enabled)

Partially-Implements: blueprint custom-roles
Change-Id: I62273f403838893602816204d9bc50d516c0057f
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/29/361029/2 && git format-patch -1 --stdout FETCH_HEAD,"['overcloud.yaml', 'puppet/all-nodes-config.yaml']",2,21af4484d29420cef3ebcf9ae5f58d77eb1a2f16,bp/custom-roles,"heat_template_version: 2016-10-14 # FIXME(shardy) this can be comma_delimited_list when # https://bugs.launchpad.net/heat/+bug/1617019 is fixed enabled_services: type: string map_merge: - enabled_services: {get_param: enabled_services} # This writes out a mapping of service_name_enabled: 'true' # For any services not enabled, hiera foo_enabled will # return nil, as it's undefined - map_merge: repeat: template: # Note this must be string 'true' due to # https://bugs.launchpad.net/heat/+bug/1617203 SERVICE_enabled: 'true' for_each: SERVICE: str_split: [',', {get_param: enabled_services}] - controller_node_ips: list_join: - ',' - {get_param: controller_ips} controller_node_names: list_join: - ',' - {get_param: controller_names} galera_node_names: list_join: - ',' - {get_param: controller_names} rabbitmq_node_ips: &rabbit_nodes_array str_replace: template: ""['SERVERS_LIST']"" params: SERVERS_LIST: list_join: - ""','"" - {get_param: rabbit_node_ips} mongodb_node_ips: str_replace: template: ""['SERVERS_LIST']"" params: SERVERS_LIST: list_join: - ""','"" - {get_param: mongo_node_ips} redis_node_ips: str_replace: template: ""['SERVERS_LIST']"" params: SERVERS_LIST: list_join: - ""','"" - {get_param: redis_node_ips} memcached_node_ips: str_replace: template: ""['SERVERS_LIST']"" params: SERVERS_LIST: list_join: - ""','"" - {get_param: memcache_node_ips} memcached_node_ips_v6: str_replace: template: ""['inet6:[SERVERS_LIST]']"" params: SERVERS_LIST: list_join: - ""]','inet6:["" - {get_param: memcache_node_ips} mysql_node_ips: str_replace: template: ""['SERVERS_LIST']"" params: SERVERS_LIST: list_join: - ""','"" - {get_param: mysql_node_ips} horizon_node_ips: str_replace: template: ""['SERVERS_LIST']"" params: SERVERS_LIST: list_join: - ""','"" - {get_param: horizon_node_ips} heat_api_node_ips: str_replace: template: ""['SERVERS_LIST']"" params: SERVERS_LIST: list_join: - ""','"" - {get_param: heat_api_node_ips} swift_proxy_node_ips: str_replace: template: ""['SERVERS_LIST']"" params: SERVERS_LIST: list_join: - ""','"" - {get_param: swift_proxy_node_ips} ceilometer_api_node_ips: str_replace: template: ""['SERVERS_LIST']"" params: SERVERS_LIST: list_join: - ""','"" - {get_param: ceilometer_api_node_ips} aodh_api_node_ips: str_replace: template: ""['SERVERS_LIST']"" params: SERVERS_LIST: list_join: - ""','"" - {get_param: aodh_api_node_ips} gnocchi_api_node_ips: str_replace: template: ""['SERVERS_LIST']"" params: SERVERS_LIST: list_join: - ""','"" - {get_param: gnocchi_api_node_ips} nova_api_node_ips: str_replace: template: ""['SERVERS_LIST']"" params: SERVERS_LIST: list_join: - ""','"" - {get_param: nova_api_node_ips} nova_metadata_node_ips: str_replace: template: ""['SERVERS_LIST']"" params: SERVERS_LIST: list_join: - ""','"" - {get_param: nova_metadata_node_ips} glance_api_node_ips: str_replace: template: ""['SERVERS_LIST']"" params: SERVERS_LIST: list_join: - ""','"" - {get_param: glance_api_node_ips} glance_registry_node_ips: str_replace: template: ""['SERVERS_LIST']"" params: SERVERS_LIST: list_join: - ""','"" - {get_param: glance_registry_node_ips} cinder_api_node_ips: str_replace: template: ""['SERVERS_LIST']"" params: SERVERS_LIST: list_join: - ""','"" - {get_param: cinder_api_node_ips} manila_api_node_ips: str_replace: template: ""['SERVERS_LIST']"" params: SERVERS_LIST: list_join: - ""','"" - {get_param: manila_api_node_ips} neutron_api_node_ips: str_replace: template: ""['SERVERS_LIST']"" params: SERVERS_LIST: list_join: - ""','"" - {get_param: neutron_api_node_ips} # TODO: pass a `midonet_api_node_ips` var midonet_api_node_ips: str_replace: template: ""['SERVERS_LIST']"" params: SERVERS_LIST: list_join: - ""','"" - {get_param: neutron_api_node_ips} keystone_public_api_node_ips: str_replace: template: ""['SERVERS_LIST']"" params: SERVERS_LIST: list_join: - ""','"" - {get_param: keystone_public_api_node_ips} keystone_admin_api_node_ips: str_replace: template: ""['SERVERS_LIST']"" params: SERVERS_LIST: list_join: - ""','"" - {get_param: keystone_admin_api_node_ips} sahara_api_node_ips: str_replace: template: ""['SERVERS_LIST']"" params: SERVERS_LIST: list_join: - ""','"" - {get_param: sahara_api_node_ips} ironic_api_node_ips: str_replace: template: ""['SERVERS_LIST']"" params: SERVERS_LIST: list_join: - ""','"" - {get_param: ironic_api_node_ips} tripleo::profile::base::ceph::ceph_mon_initial_members: list_join: - ',' - {get_param: ceph_mon_node_names} tripleo::profile::base::ceph::ceph_mon_host: list_join: - ',' - {get_param: ceph_mon_node_ips} tripleo::profile::base::ceph::ceph_mon_host_v6: str_replace: template: ""'[IPS_LIST]'"" params: IPS_LIST: list_join: - '],[' - {get_param: ceph_mon_node_ips} # NOTE(gfidente): interpolation with %{} in the # hieradata file can't be used as it returns string ceilometer::rabbit_hosts: *rabbit_nodes_array aodh::rabbit_hosts: *rabbit_nodes_array cinder::rabbit_hosts: *rabbit_nodes_array glance::notify::rabbitmq::rabbit_hosts: *rabbit_nodes_array manila::rabbit_hosts: *rabbit_nodes_array heat::rabbit_hosts: *rabbit_nodes_array neutron::rabbit_hosts: *rabbit_nodes_array nova::rabbit_hosts: *rabbit_nodes_array keystone::rabbit_hosts: *rabbit_nodes_array sahara::rabbit_hosts: *rabbit_nodes_array ironic::rabbit_hosts: *rabbit_nodes_array deploy_identifier: {get_param: DeployIdentifier} update_identifier: {get_param: UpdateIdentifier} stack_action: {get_param: StackAction}","heat_template_version: 2015-04-30 controller_node_ips: list_join: - ',' - {get_param: controller_ips} controller_node_names: list_join: - ',' - {get_param: controller_names} galera_node_names: list_join: - ',' - {get_param: controller_names} rabbitmq_node_ips: &rabbit_nodes_array str_replace: template: ""['SERVERS_LIST']"" params: SERVERS_LIST: list_join: - ""','"" - {get_param: rabbit_node_ips} mongodb_node_ips: str_replace: template: ""['SERVERS_LIST']"" params: SERVERS_LIST: list_join: - ""','"" - {get_param: mongo_node_ips} redis_node_ips: str_replace: template: ""['SERVERS_LIST']"" params: SERVERS_LIST: list_join: - ""','"" - {get_param: redis_node_ips} memcached_node_ips: str_replace: template: ""['SERVERS_LIST']"" params: SERVERS_LIST: list_join: - ""','"" - {get_param: memcache_node_ips} memcached_node_ips_v6: str_replace: template: ""['inet6:[SERVERS_LIST]']"" params: SERVERS_LIST: list_join: - ""]','inet6:["" - {get_param: memcache_node_ips} mysql_node_ips: str_replace: template: ""['SERVERS_LIST']"" params: SERVERS_LIST: list_join: - ""','"" - {get_param: mysql_node_ips} horizon_node_ips: str_replace: template: ""['SERVERS_LIST']"" params: SERVERS_LIST: list_join: - ""','"" - {get_param: horizon_node_ips} heat_api_node_ips: str_replace: template: ""['SERVERS_LIST']"" params: SERVERS_LIST: list_join: - ""','"" - {get_param: heat_api_node_ips} swift_proxy_node_ips: str_replace: template: ""['SERVERS_LIST']"" params: SERVERS_LIST: list_join: - ""','"" - {get_param: swift_proxy_node_ips} ceilometer_api_node_ips: str_replace: template: ""['SERVERS_LIST']"" params: SERVERS_LIST: list_join: - ""','"" - {get_param: ceilometer_api_node_ips} aodh_api_node_ips: str_replace: template: ""['SERVERS_LIST']"" params: SERVERS_LIST: list_join: - ""','"" - {get_param: aodh_api_node_ips} gnocchi_api_node_ips: str_replace: template: ""['SERVERS_LIST']"" params: SERVERS_LIST: list_join: - ""','"" - {get_param: gnocchi_api_node_ips} nova_api_node_ips: str_replace: template: ""['SERVERS_LIST']"" params: SERVERS_LIST: list_join: - ""','"" - {get_param: nova_api_node_ips} nova_metadata_node_ips: str_replace: template: ""['SERVERS_LIST']"" params: SERVERS_LIST: list_join: - ""','"" - {get_param: nova_metadata_node_ips} glance_api_node_ips: str_replace: template: ""['SERVERS_LIST']"" params: SERVERS_LIST: list_join: - ""','"" - {get_param: glance_api_node_ips} glance_registry_node_ips: str_replace: template: ""['SERVERS_LIST']"" params: SERVERS_LIST: list_join: - ""','"" - {get_param: glance_registry_node_ips} cinder_api_node_ips: str_replace: template: ""['SERVERS_LIST']"" params: SERVERS_LIST: list_join: - ""','"" - {get_param: cinder_api_node_ips} manila_api_node_ips: str_replace: template: ""['SERVERS_LIST']"" params: SERVERS_LIST: list_join: - ""','"" - {get_param: manila_api_node_ips} neutron_api_node_ips: str_replace: template: ""['SERVERS_LIST']"" params: SERVERS_LIST: list_join: - ""','"" - {get_param: neutron_api_node_ips} # TODO: pass a `midonet_api_node_ips` var midonet_api_node_ips: str_replace: template: ""['SERVERS_LIST']"" params: SERVERS_LIST: list_join: - ""','"" - {get_param: neutron_api_node_ips} keystone_public_api_node_ips: str_replace: template: ""['SERVERS_LIST']"" params: SERVERS_LIST: list_join: - ""','"" - {get_param: keystone_public_api_node_ips} keystone_admin_api_node_ips: str_replace: template: ""['SERVERS_LIST']"" params: SERVERS_LIST: list_join: - ""','"" - {get_param: keystone_admin_api_node_ips} sahara_api_node_ips: str_replace: template: ""['SERVERS_LIST']"" params: SERVERS_LIST: list_join: - ""','"" - {get_param: sahara_api_node_ips} ironic_api_node_ips: str_replace: template: ""['SERVERS_LIST']"" params: SERVERS_LIST: list_join: - ""','"" - {get_param: ironic_api_node_ips} tripleo::profile::base::ceph::ceph_mon_initial_members: list_join: - ',' - {get_param: ceph_mon_node_names} tripleo::profile::base::ceph::ceph_mon_host: list_join: - ',' - {get_param: ceph_mon_node_ips} tripleo::profile::base::ceph::ceph_mon_host_v6: str_replace: template: ""'[IPS_LIST]'"" params: IPS_LIST: list_join: - '],[' - {get_param: ceph_mon_node_ips} # NOTE(gfidente): interpolation with %{} in the # hieradata file can't be used as it returns string ceilometer::rabbit_hosts: *rabbit_nodes_array aodh::rabbit_hosts: *rabbit_nodes_array cinder::rabbit_hosts: *rabbit_nodes_array glance::notify::rabbitmq::rabbit_hosts: *rabbit_nodes_array manila::rabbit_hosts: *rabbit_nodes_array heat::rabbit_hosts: *rabbit_nodes_array neutron::rabbit_hosts: *rabbit_nodes_array nova::rabbit_hosts: *rabbit_nodes_array keystone::rabbit_hosts: *rabbit_nodes_array sahara::rabbit_hosts: *rabbit_nodes_array ironic::rabbit_hosts: *rabbit_nodes_array deploy_identifier: {get_param: DeployIdentifier} update_identifier: {get_param: UpdateIdentifier} stack_action: {get_param: StackAction}",274,238
openstack%2Fkolla~master~I11af66cd14772c7cd34e35609491f4eb9f6b93ee,openstack/kolla,master,I11af66cd14772c7cd34e35609491f4eb9f6b93ee,Fix the wrong install_packages usage in kibana Dockerfile,ABANDONED,2016-08-29 07:38:11.000000000,2016-08-29 08:36:16.000000000,,"[{'_account_id': 3}, {'_account_id': 11105}]","[{'number': 1, 'created': '2016-08-29 07:38:11.000000000', 'files': ['docker/kibana/Dockerfile.j2'], 'web_link': 'https://opendev.org/openstack/kolla/commit/b5d23ad4168b958cfeeb696901f3dbeb7c4916cf', 'message': 'Fix the wrong install_packages usage in kibana Dockerfile\n\nTrivialFix\n\nChange-Id: I11af66cd14772c7cd34e35609491f4eb9f6b93ee\nSigned-off-by: Jeffrey Zhang <zhang.lei.fly@gmail.com>\n'}]",0,361909,b5d23ad4168b958cfeeb696901f3dbeb7c4916cf,4,2,1,7488,,,0,"Fix the wrong install_packages usage in kibana Dockerfile

TrivialFix

Change-Id: I11af66cd14772c7cd34e35609491f4eb9f6b93ee
Signed-off-by: Jeffrey Zhang <zhang.lei.fly@gmail.com>
",git fetch https://review.opendev.org/openstack/kolla refs/changes/09/361909/1 && git format-patch -1 --stdout FETCH_HEAD,['docker/kibana/Dockerfile.j2'],1,b5d23ad4168b958cfeeb696901f3dbeb7c4916cf,,"{{ macros.install_packages(kibana_packages | customizable(""packages"")) }}","RUN {{ macros.install_packages(kibana_packages | customizable(""packages"")) }}",1,1
openstack%2Fcongress~master~Idfddd2927303a5927f5486429fabd527a153c6c6,openstack/congress,master,Idfddd2927303a5927f5486429fabd527a153c6c6,Updated from global requirements,MERGED,2016-08-29 06:10:05.000000000,2016-08-29 08:35:20.000000000,2016-08-29 08:35:20.000000000,"[{'_account_id': 3}, {'_account_id': 11278}]","[{'number': 1, 'created': '2016-08-29 06:10:05.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/congress/commit/9cfa2975c9544e9aa1bde0ac6b2bab245ba74888', 'message': 'Updated from global requirements\n\nChange-Id: Idfddd2927303a5927f5486429fabd527a153c6c6\n'}]",0,361859,9cfa2975c9544e9aa1bde0ac6b2bab245ba74888,6,2,1,11131,,,0,"Updated from global requirements

Change-Id: Idfddd2927303a5927f5486429fabd527a153c6c6
",git fetch https://review.opendev.org/openstack/congress refs/changes/59/361859/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,9cfa2975c9544e9aa1bde0ac6b2bab245ba74888,openstack/requirements,python-heatclient>=1.4.0 # Apache-2.0,python-heatclient>=1.1.0 # Apache-2.0,1,1
openstack%2Fopenstack-manuals~stable%2Fmitaka~If58fe213cf3822019393583cc9473af857b20cb6,openstack/openstack-manuals,stable/mitaka,If58fe213cf3822019393583cc9473af857b20cb6,Imported Translations from Zanata,MERGED,2016-08-29 07:58:21.000000000,2016-08-29 08:34:49.000000000,2016-08-29 08:34:49.000000000,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2016-08-29 07:58:21.000000000', 'files': ['doc/common/source/locale/ru/LC_MESSAGES/common.po', 'doc/networking-guide/source/locale/ja/LC_MESSAGES/networking-guide.po'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/483e7ab3bc649fda99a1b4370fd0dcac5a5a51ed', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: If58fe213cf3822019393583cc9473af857b20cb6\n'}]",0,361922,483e7ab3bc649fda99a1b4370fd0dcac5a5a51ed,6,2,1,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
https://wiki.openstack.org/wiki/Translations/Infrastructure

Change-Id: If58fe213cf3822019393583cc9473af857b20cb6
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/22/361922/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/common/source/locale/ru/LC_MESSAGES/common.po', 'doc/networking-guide/source/locale/ja/LC_MESSAGES/networking-guide.po']",2,483e7ab3bc649fda99a1b4370fd0dcac5a5a51ed,zanata/translations,"""POT-Creation-Date: 2016-08-28 09:49+0000\n""""PO-Revision-Date: 2016-08-29 06:58+0000\n""msgid """" ""Create a subnet on the provider network using an IP address range from the "" ""provider subnet pool."" msgstr """" "" IP "" """" msgid ""Create and configure the routers"" msgstr """" msgid ""Create the routers."" msgstr """" msgid ""One BGP agent."" msgstr ""1  BGP "" msgid """" ""One address scope containing IP address range 203.0.113.0/24 for provider "" ""networks, and IP address ranges 10.0.1.0/24 and 10.0.2.0/24 for self-service "" ""networks."" msgstr """" ""1  "" ""IP  203.0.113.0/24  IP "" "" 10.0.1.0/24  10.0.2.0/24 "" msgid ""One provider network using IP address range 203.0.113.0/24."" msgstr """" ""1  IP  203.0.113.0/24 "" """" ""Replace ``ROUTER_ID`` with a suitable unique 32-bit number, typically an "" ""IPv4 address on the host running the agent. For example, 192.0.2.2."" msgstr """" ""``ROUTER_ID``  32 "" "" IPv4 : 192.0.2.2"" msgid """"msgid ""Router 1 contains IP addresses 203.0.113.11 and 10.0.1.1."" msgstr "" 1  IP  203.0.113.11  10.0.1.1 "" msgid ""Router 2 contains IP addresses 203.0.113.12 and 10.0.2.1."" msgstr "" 2  IP  203.0.113.12  10.0.2.1 "" msgid ""Router 3 contains IP addresses 203.0.113.13 and 10.0.3.1."" msgstr "" 3  IP  203.0.113.13  10.0.3.1 "" msgid """" ""Self-service network 3 uses a unique IP address range 10.0.3.0/24 to "" ""demonstrate that the BGP speaker does not advertise prefixes outside of "" ""address scopes."" msgstr """" "" 3  IP  10.0.3.0/24 "" "" BGP "" """" msgid """" ""Self-service networks 1 and 2 use IP address ranges inside of the address "" ""scope."" msgstr """" "" 1  2  IP "" """" msgid ""The example configuration involves the following components:"" msgstr """" ""Three routers. Each router connects one self-service network to the provider "" ""network."" msgstr """" ""3  1 "" """" msgid ""Three self-service networks."" msgstr ""3 "" msgid """"","""POT-Creation-Date: 2016-08-26 09:46+0000\n""""PO-Revision-Date: 2016-08-26 04:41+0000\n""",252,5
openstack%2Fopenstack-manuals~master~I6cfde09348ae0d6a83c0fdca4eb838a472f36b2b,openstack/openstack-manuals,master,I6cfde09348ae0d6a83c0fdca4eb838a472f36b2b,Imported Translations from Zanata,MERGED,2016-08-29 07:55:32.000000000,2016-08-29 08:34:32.000000000,2016-08-29 08:34:32.000000000,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2016-08-29 07:55:32.000000000', 'files': ['doc/image-guide/source/locale/ja/LC_MESSAGES/image-guide.po', 'doc/user-guide/source/locale/ja/LC_MESSAGES/user-guide.po', 'doc/ha-guide/source/locale/ja/LC_MESSAGES/ha-guide.po'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/2ecda3be817c5c989c7dc70ec879a224f391d6ff', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I6cfde09348ae0d6a83c0fdca4eb838a472f36b2b\n'}]",0,361919,2ecda3be817c5c989c7dc70ec879a224f391d6ff,6,2,1,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
https://wiki.openstack.org/wiki/Translations/Infrastructure

Change-Id: I6cfde09348ae0d6a83c0fdca4eb838a472f36b2b
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/19/361919/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/image-guide/source/locale/ja/LC_MESSAGES/image-guide.po', 'doc/user-guide/source/locale/ja/LC_MESSAGES/user-guide.po', 'doc/ha-guide/source/locale/ja/LC_MESSAGES/ha-guide.po']",3,2ecda3be817c5c989c7dc70ec879a224f391d6ff,zanata/translations,"""POT-Creation-Date: 2016-08-29 04:39+0000\n""","""POT-Creation-Date: 2016-08-18 00:43+0000\n""""The current design of the neutron LBaaS agent using the HAProxy driver does "" ""not allow high availability for the tenant load balancers. The neutron-lbaas-"" ""agent service will be enabled and running on all controllers, allowing for "" ""load balancers to be distributed across all nodes. However, a controller "" ""node failure will stop all load balancers running on that node until the "" ""service is recovered or the load balancer is manually removed and created "" ""again."" msgstr """" "" HAProxy  neutron LBaaS "" ""neutron-lbaas-agent "" """" """" """" """" """" msgid """"",18,35
openstack%2Fmistral~master~I4a2386cfd98e452716f689445b83d7099f7d892d,openstack/mistral,master,I4a2386cfd98e452716f689445b83d7099f7d892d,Use upper constraints for all jobs in tox.ini Openstack infra now supports upper constraints for all jobs. Updated tox.ini to use upper constraints for all jobs.,ABANDONED,2016-08-22 06:33:30.000000000,2016-08-29 08:34:26.000000000,,"[{'_account_id': 3}, {'_account_id': 5558}, {'_account_id': 6732}, {'_account_id': 7700}, {'_account_id': 8592}, {'_account_id': 8731}, {'_account_id': 18238}, {'_account_id': 19206}]","[{'number': 1, 'created': '2016-08-22 06:33:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/7df7d89f51f25d760abb25dae1ad227dd1cf27f9', 'message': 'Use upper constraints for all jobs in tox.ini\nOpenstack infra now supports upper constraints for\nall jobs. Updated tox.ini to use upper constraints\nfor all jobs.\n\nChange-Id: I4a2386cfd98e452716f689445b83d7099f7d892d\nCloses-Bug: #1614117\n'}, {'number': 2, 'created': '2016-08-23 12:39:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/143e3f91f2587f1fc7a6fb0ba7a9339eebf7ea75', 'message': 'Use upper constraints for all jobs in tox.ini\nOpenstack infra now supports upper constraints for\nall jobs. Updated tox.ini to use upper constraints\nfor all jobs.\n\nChange-Id: I4a2386cfd98e452716f689445b83d7099f7d892d\nCloses-Bug: #1614117\n'}]",0,358420,143e3f91f2587f1fc7a6fb0ba7a9339eebf7ea75,8,8,2,22575,,,0,"Use upper constraints for all jobs in tox.ini
Openstack infra now supports upper constraints for
all jobs. Updated tox.ini to use upper constraints
for all jobs.

Change-Id: I4a2386cfd98e452716f689445b83d7099f7d892d
Closes-Bug: #1614117
",git fetch https://review.opendev.org/openstack/mistral refs/changes/20/358420/2 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,7df7d89f51f25d760abb25dae1ad227dd1cf27f9,bug/1614117,,install_command = pip install -U {opts} {packages}# TODO(kong): Avoid 'Couldn't open file...upper-constraints.txt' error. Remove # this line once infra supports constraints for this target. install_command = pip install -U {opts} {packages},0,4
openstack%2Ftripleo-ui~master~If177f04b3db8b0b7a56c1d687717c0eba9d6e52d,openstack/tripleo-ui,master,If177f04b3db8b0b7a56c1d687717c0eba9d6e52d,Fix multiple default exports in single module,MERGED,2016-08-25 15:34:43.000000000,2016-08-29 08:31:07.000000000,2016-08-29 08:31:07.000000000,"[{'_account_id': 3}, {'_account_id': 7509}, {'_account_id': 9317}, {'_account_id': 10112}, {'_account_id': 17888}]","[{'number': 1, 'created': '2016-08-25 15:34:43.000000000', 'files': ['src/js/components/UserAuthenticator.js', 'src/js/components/notifications/NotificationsToaster.js', 'src/js/components/AuthenticatedContent.js', 'src/js/components/deployment_plan/NodesAssignment.js'], 'web_link': 'https://opendev.org/openstack/tripleo-ui/commit/bbcf00273ae0e0e0eb2f95bceb55fcd7e6f7c606', 'message': 'Fix multiple default exports in single module\n\nChange-Id: If177f04b3db8b0b7a56c1d687717c0eba9d6e52d\n'}]",0,360641,bbcf00273ae0e0e0eb2f95bceb55fcd7e6f7c606,9,5,1,7509,,,0,"Fix multiple default exports in single module

Change-Id: If177f04b3db8b0b7a56c1d687717c0eba9d6e52d
",git fetch https://review.opendev.org/openstack/tripleo-ui refs/changes/41/360641/1 && git format-patch -1 --stdout FETCH_HEAD,"['src/js/components/UserAuthenticator.js', 'src/js/components/notifications/NotificationsToaster.js', 'src/js/components/AuthenticatedContent.js', 'src/js/components/deployment_plan/NodesAssignment.js']",4,bbcf00273ae0e0e0eb2f95bceb55fcd7e6f7c606,default_export_fix,class NodesAssignment extends React.Component {,export default class NodesAssignment extends React.Component {,4,4
openstack%2Ffuel-qa~master~I91f68fc92ab6580927027196f9b7de158e5f5a30,openstack/fuel-qa,master,I91f68fc92ab6580927027196f9b7de158e5f5a30,Drop old yaml-modification methods,MERGED,2016-08-29 08:08:37.000000000,2016-08-29 08:29:45.000000000,2016-08-29 08:29:45.000000000,"[{'_account_id': 3}, {'_account_id': 8971}, {'_account_id': 11081}, {'_account_id': 16414}, {'_account_id': 19119}]","[{'number': 1, 'created': '2016-08-29 08:08:37.000000000', 'files': ['fuelweb_test/helpers/fuel_actions.py', 'fuelweb_test/tests/plugins/plugin_vip_reservation/test_plugin_vip_reservation.py', 'fuelweb_test/helpers/utils.py', 'fuelweb_test/tests/plugins/plugin_reboot/test_plugin_reboot_task.py', 'gates_tests/helpers/utils.py'], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/f5a4e7499b16eab8818032459e0e126f9a3a0790', 'message': ""Drop old yaml-modification methods\n\nYamlEditor is now tested and it's possible to replace old\ndocker-related methods with it.\n\nChange-Id: I91f68fc92ab6580927027196f9b7de158e5f5a30\n""}]",0,361925,f5a4e7499b16eab8818032459e0e126f9a3a0790,11,5,1,15984,,,0,"Drop old yaml-modification methods

YamlEditor is now tested and it's possible to replace old
docker-related methods with it.

Change-Id: I91f68fc92ab6580927027196f9b7de158e5f5a30
",git fetch https://review.opendev.org/openstack/fuel-qa refs/changes/25/361925/1 && git format-patch -1 --stdout FETCH_HEAD,"['fuelweb_test/helpers/fuel_actions.py', 'fuelweb_test/tests/plugins/plugin_vip_reservation/test_plugin_vip_reservation.py', 'fuelweb_test/helpers/utils.py', 'fuelweb_test/tests/plugins/plugin_reboot/test_plugin_reboot_task.py', 'gates_tests/helpers/utils.py']",5,f5a4e7499b16eab8818032459e0e126f9a3a0790,,"from fuelweb_test.helpers.utils import YamlEditor with YamlEditor(path, ip=actions.admin_ip) as editor: editor['repos'].append(new_repo)"," element = ['repos'] repos = actions.get_value_from_remote_yaml(path, element) repos.append(new_repo) actions.change_remote_yaml(path, element, repos)",28,128
openstack%2Fhorizon~master~I7059ee6fc2bab6524c807abbfd57cd100765e2d0,openstack/horizon,master,I7059ee6fc2bab6524c807abbfd57cd100765e2d0,fix ascii error in servers test data,ABANDONED,2016-08-26 08:32:12.000000000,2016-08-29 08:29:19.000000000,,"[{'_account_id': 3}, {'_account_id': 12071}, {'_account_id': 14151}, {'_account_id': 22587}]","[{'number': 1, 'created': '2016-08-26 08:32:12.000000000', 'files': ['openstack_dashboard/test/test_data/nova_data.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/b1c3dc988a232e2a30dc2fe3ad3be5eae81b3f1b', 'message': 'fix ascii error in servers test data\n\nIncorrect name of server 3 in servers test data.\n\nChange-Id: I7059ee6fc2bab6524c807abbfd57cd100765e2d0\nCloses-Bug: #1617210\n'}]",0,360977,b1c3dc988a232e2a30dc2fe3ad3be5eae81b3f1b,6,4,1,22587,,,0,"fix ascii error in servers test data

Incorrect name of server 3 in servers test data.

Change-Id: I7059ee6fc2bab6524c807abbfd57cd100765e2d0
Closes-Bug: #1617210
",git fetch https://review.opendev.org/openstack/horizon refs/changes/77/360977/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack_dashboard/test/test_data/nova_data.py'],1,b1c3dc988a232e2a30dc2fe3ad3be5eae81b3f1b,bug/1617210," vals.update({""name"": u'server_3',"," vals.update({""name"": u'\u4e91\u89c4\u5219',",1,1
openstack%2Fmistral~master~I56f91354a959b0d958080b61d27bc6d3d88dc7ac,openstack/mistral,master,I56f91354a959b0d958080b61d27bc6d3d88dc7ac,Clean imports in code,MERGED,2016-08-26 10:26:56.000000000,2016-08-29 08:27:05.000000000,2016-08-29 08:27:05.000000000,"[{'_account_id': 3}, {'_account_id': 7700}, {'_account_id': 16237}, {'_account_id': 18238}]","[{'number': 1, 'created': '2016-08-26 10:26:56.000000000', 'files': ['mistral/workbook/parser.py'], 'web_link': 'https://opendev.org/openstack/mistral/commit/3661bc0b35798160ccf3535dd61219b911e64986', 'message': 'Clean imports in code\n\nThis patch set modifies lines which are importing objects\ninstead of modules. As per openstack import guide lines, user should\nimport modules in a file not objects.\n\nhttp://docs.openstack.org/developer/hacking/#imports\n\nChange-Id: I56f91354a959b0d958080b61d27bc6d3d88dc7ac\n'}]",0,361063,3661bc0b35798160ccf3535dd61219b911e64986,8,4,1,15905,,,0,"Clean imports in code

This patch set modifies lines which are importing objects
instead of modules. As per openstack import guide lines, user should
import modules in a file not objects.

http://docs.openstack.org/developer/hacking/#imports

Change-Id: I56f91354a959b0d958080b61d27bc6d3d88dc7ac
",git fetch https://review.opendev.org/openstack/mistral refs/changes/63/361063/1 && git format-patch -1 --stdout FETCH_HEAD,['mistral/workbook/parser.py'],1,3661bc0b35798160ccf3535dd61219b911e64986,cleancode,import threading_WF_EX_CACHE_LOCK = threading.RLock()_WF_DEF_CACHE_LOCK = threading.RLock(),from threading import RLock_WF_EX_CACHE_LOCK = RLock()_WF_DEF_CACHE_LOCK = RLock(),3,3
openstack%2Fmistral~master~I76adfc5e5aa275699830b607662bd4c26bdd60e2,openstack/mistral,master,I76adfc5e5aa275699830b607662bd4c26bdd60e2,Updated from global requirements,MERGED,2016-08-29 05:41:03.000000000,2016-08-29 08:26:59.000000000,2016-08-29 08:26:59.000000000,"[{'_account_id': 3}, {'_account_id': 7700}]","[{'number': 1, 'created': '2016-08-29 05:41:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/b724fc7cc353bd189d9325cd4d352d700c3d7829', 'message': 'Updated from global requirements\n\nChange-Id: I76adfc5e5aa275699830b607662bd4c26bdd60e2\n'}, {'number': 2, 'created': '2016-08-29 06:12:05.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/mistral/commit/2706b257bd7f730f67880323bcdfb847975ab587', 'message': 'Updated from global requirements\n\nChange-Id: I76adfc5e5aa275699830b607662bd4c26bdd60e2\n'}]",0,361845,2706b257bd7f730f67880323bcdfb847975ab587,7,2,2,11131,,,0,"Updated from global requirements

Change-Id: I76adfc5e5aa275699830b607662bd4c26bdd60e2
",git fetch https://review.opendev.org/openstack/mistral refs/changes/45/361845/2 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,b724fc7cc353bd189d9325cd4d352d700c3d7829,openstack/requirements,python-tackerclient>=0.6.0 # Apache-2.0,python-tackerclient>=0.5.0 # Apache-2.0,1,1
openstack%2Ffuel-qa~stable%2Fmitaka~I59c589e8626bfa23fbf4f06845db27775f9714a2,openstack/fuel-qa,stable/mitaka,I59c589e8626bfa23fbf4f06845db27775f9714a2,Make coverage report human-readable on gates,MERGED,2016-08-29 05:30:38.000000000,2016-08-29 08:26:53.000000000,2016-08-29 08:26:53.000000000,"[{'_account_id': 3}, {'_account_id': 8971}, {'_account_id': 11969}, {'_account_id': 15984}]","[{'number': 1, 'created': '2016-08-29 05:30:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/a716cf9f3ffbe6c261a5377057a1382047b2ab5d', 'message': 'Make coverage report human-readable on gates\n\nMake coverage report human-readable on gates\nRequire minimal coverage of moved helpers: 75%\n\nChange-Id: I59c589e8626bfa23fbf4f06845db27775f9714a2\n'}, {'number': 2, 'created': '2016-08-29 06:08:10.000000000', 'files': ['core/_tests/helpers/test_setup_teardown.py', 'core/_tests/models/test_collector_client.py', 'core/_tests/helpers/test_http.py', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/955dd69ab0baa399ad30455c2475104f886d5837', 'message': 'Make coverage report human-readable on gates\n\nMake coverage report human-readable on gates\nRequire minimal coverage of moved helpers: 75%\n\nChange-Id: I59c589e8626bfa23fbf4f06845db27775f9714a2\n(cherry picked from commit e96978d)\n'}]",0,361840,955dd69ab0baa399ad30455c2475104f886d5837,14,4,2,19119,,,0,"Make coverage report human-readable on gates

Make coverage report human-readable on gates
Require minimal coverage of moved helpers: 75%

Change-Id: I59c589e8626bfa23fbf4f06845db27775f9714a2
(cherry picked from commit e96978d)
",git fetch https://review.opendev.org/openstack/fuel-qa refs/changes/40/361840/1 && git format-patch -1 --stdout FETCH_HEAD,"['core/_tests/helpers/test_setup_teardown.py', 'tox.ini']",2,a716cf9f3ffbe6c261a5377057a1382047b2ab5d,, coverage html -d {envlogdir} coverage report --fail-under 75, coverage report,7,1
openstack%2Ffuel-qa~master~I59c589e8626bfa23fbf4f06845db27775f9714a2,openstack/fuel-qa,master,I59c589e8626bfa23fbf4f06845db27775f9714a2,Make coverage report human-readable on gates,MERGED,2016-08-29 05:25:19.000000000,2016-08-29 08:26:47.000000000,2016-08-29 08:26:47.000000000,"[{'_account_id': 3}, {'_account_id': 8971}, {'_account_id': 11969}, {'_account_id': 12867}, {'_account_id': 14057}, {'_account_id': 14708}, {'_account_id': 15984}]","[{'number': 1, 'created': '2016-08-29 05:25:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/6e0e7bafa9b91229fb4c42475008c9b71f4e3c93', 'message': 'Make coverage report human-readable on gates\n\nMake coverage report human-readable on gates\nRequire minimal coverage of moved helpers: 75%\n\nChange-Id: I59c589e8626bfa23fbf4f06845db27775f9714a2\n'}, {'number': 2, 'created': '2016-08-29 05:29:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/b5a74dda998f90b109faa7b9d48564177871608a', 'message': 'Make coverage report human-readable on gates\n\nMake coverage report human-readable on gates\nRequire minimal coverage of moved helpers: 75%\n\nChange-Id: I59c589e8626bfa23fbf4f06845db27775f9714a2\n'}, {'number': 3, 'created': '2016-08-29 06:04:10.000000000', 'files': ['core/_tests/helpers/test_setup_teardown.py', 'core/_tests/models/test_collector_client.py', 'core/_tests/helpers/test_http.py', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/e96978ddea08f004f582e3aad3d1256b61c60a6b', 'message': 'Make coverage report human-readable on gates\n\nMake coverage report human-readable on gates\nRequire minimal coverage of moved helpers: 75%\n\nChange-Id: I59c589e8626bfa23fbf4f06845db27775f9714a2\n'}]",0,361839,e96978ddea08f004f582e3aad3d1256b61c60a6b,20,7,3,19119,,,0,"Make coverage report human-readable on gates

Make coverage report human-readable on gates
Require minimal coverage of moved helpers: 75%

Change-Id: I59c589e8626bfa23fbf4f06845db27775f9714a2
",git fetch https://review.opendev.org/openstack/fuel-qa refs/changes/39/361839/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,6e0e7bafa9b91229fb4c42475008c9b71f4e3c93,, coverage html -d {envlogdir} coverage report --fail-under 75, coverage report,2,1
openstack%2Frally~master~I420970b1f147c9cae97fc8c160175dd2b9dc98a4,openstack/rally,master,I420970b1f147c9cae97fc8c160175dd2b9dc98a4,Fix neutron gate jobs,MERGED,2016-08-27 06:46:35.000000000,2016-08-29 08:25:58.000000000,2016-08-29 08:25:58.000000000,"[{'_account_id': 3}, {'_account_id': 6172}, {'_account_id': 9545}, {'_account_id': 10475}, {'_account_id': 12395}, {'_account_id': 13252}]","[{'number': 1, 'created': '2016-08-27 06:46:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/9ba560a89d1739372deaedb6b94dc9dab2951fe8', 'message': 'Fix neutron gate jobs\n\nNuetron LBaaS drop v1 see https://review.openstack.org/#/c/286381/\n\nChange-Id: I420970b1f147c9cae97fc8c160175dd2b9dc98a4\n'}, {'number': 2, 'created': '2016-08-29 04:41:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/6a271fadd20ea102c42285f52c5a649ecdae6f4d', 'message': 'Fix neutron gate jobs\n\nNuetron LBaaS drop v1 see https://review.openstack.org/#/c/286381/\n\nChange-Id: I420970b1f147c9cae97fc8c160175dd2b9dc98a4\n'}, {'number': 3, 'created': '2016-08-29 04:42:28.000000000', 'files': ['rally-jobs/rally-neutron-existing-users.yaml', 'rally-jobs/rally-neutron.yaml', 'tests/ci/rally-gate.sh'], 'web_link': 'https://opendev.org/openstack/rally/commit/d8af9827de58999b62dde27317115a7084530eb6', 'message': 'Fix neutron gate jobs\n\nNuetron LBaaS drop v1 see https://review.openstack.org/#/c/286381/\n\nChange-Id: I420970b1f147c9cae97fc8c160175dd2b9dc98a4\n'}]",0,361565,d8af9827de58999b62dde27317115a7084530eb6,16,6,3,12395,,,0,"Fix neutron gate jobs

Nuetron LBaaS drop v1 see https://review.openstack.org/#/c/286381/

Change-Id: I420970b1f147c9cae97fc8c160175dd2b9dc98a4
",git fetch https://review.opendev.org/openstack/rally refs/changes/65/361565/3 && git format-patch -1 --stdout FETCH_HEAD,"['rally-jobs/rally-neutron-existing-users.yaml', 'rally-jobs/rally-neutron.yaml']",2,9ba560a89d1739372deaedb6b94dc9dab2951fe8,fix_gate,," NeutronLoadbalancerV1.create_and_list_pools: - args: pool_create_args: {} runner: type: ""constant"" times: {{smoke or 20}} concurrency: {{smoke or 10}} context: users: tenants: {{smoke or 3}} users_per_tenant: {{smoke or 2}} network: {} lbaas: pool: {} lbaas_version: 1 quotas: neutron: network: -1 subnet: -1 pool: -1 sla: failure_rate: max: 0 NeutronLoadbalancerV1.create_and_delete_pools: - args: pool_create_args: {} runner: type: ""constant"" times: {{smoke or 20}} concurrency: {{smoke or 10}} context: users: tenants: {{smoke or 3}} users_per_tenant: {{smoke or 2}} network: {} quotas: neutron: network: -1 subnet: -1 pool: -1 sla: failure_rate: max: 0 NeutronLoadbalancerV1.create_and_update_pools: - args: pool_create_args: {} pool_update_args: {} runner: type: ""constant"" times: {{smoke or 20}} concurrency: {{smoke or 10}} context: users: tenants: {{smoke or 3}} users_per_tenant: {{smoke or 2}} network: {} quotas: neutron: network: -1 subnet: -1 pool: -1 sla: failure_rate: max: 0 NeutronLoadbalancerV1.create_and_list_vips: - args: vip_create_args: {} runner: type: ""constant"" times: {{smoke or 20}} concurrency: {{smoke or 10}} context: users: tenants: {{smoke or 5}} users_per_tenant: {{smoke or 4}} network: {} quotas: neutron: network: -1 subnet: -1 pool: -1 vip: -1 sla: failure_rate: max: 0 NeutronLoadbalancerV1.create_and_update_vips: - args: vip_create_args: {} vip_update_args: {} pool_create_args: {} runner: type: ""constant"" times: {{smoke or 20}} concurrency: {{smoke or 10}} context: users: tenants: {{smoke or 5}} users_per_tenant: {{smoke or 2}} network: {} quotas: neutron: network: -1 subnet: -1 pool: -1 vip: -1 sla: failure_rate: max: 0 NeutronLoadbalancerV1.create_and_list_healthmonitors: - args: healthmonitor_create_args: {} runner: type: ""constant"" times: {{smoke or 20}} concurrency: {{smoke or 10}} context: users: tenants: {{smoke or 5}} users_per_tenant: {{smoke or 2}} quotas: neutron: health_monitor: -1 sla: failure_rate: max: 0 NeutronLoadbalancerV1.create_and_delete_healthmonitors: - args: healthmonitor_create_args: {} runner: type: ""constant"" times: {{smoke or 20}} concurrency: {{smoke or 10}} context: users: tenants: {{smoke or 5}} users_per_tenant: {{smoke or 2}} quotas: neutron: health_monitor: -1 sla: failure_rate: max: 0 NeutronLoadbalancerV1.create_and_update_healthmonitors: - args: healthmonitor_create_args: {} healthmonitor_update_args: admin_state_up: False runner: type: ""constant"" times: {{smoke or 20}} concurrency: {{smoke or 10}} context: users: tenants: {{smoke or 5}} users_per_tenant: {{smoke or 2}} quotas: neutron: health_monitor: -1 sla: failure_rate: max: 0 ",0,306
openstack%2Fcinder~master~Ie6f7d07bffe3f532e7ac3bf0b7eff19bb9055563,openstack/cinder,master,Ie6f7d07bffe3f532e7ac3bf0b7eff19bb9055563,Sending ScaleIO volume id in attach and detach volume,MERGED,2016-08-14 08:59:58.000000000,2016-08-29 08:24:51.000000000,2016-08-24 23:33:10.000000000,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 6491}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9732}, {'_account_id': 10621}, {'_account_id': 10622}, {'_account_id': 11904}, {'_account_id': 12016}, {'_account_id': 12017}, {'_account_id': 12032}, {'_account_id': 12033}, {'_account_id': 12176}, {'_account_id': 12369}, {'_account_id': 12778}, {'_account_id': 12822}, {'_account_id': 12924}, {'_account_id': 13394}, {'_account_id': 14259}, {'_account_id': 14384}, {'_account_id': 14624}, {'_account_id': 14797}, {'_account_id': 15249}, {'_account_id': 15296}, {'_account_id': 15374}, {'_account_id': 15386}, {'_account_id': 15831}, {'_account_id': 15941}, {'_account_id': 16269}, {'_account_id': 16422}, {'_account_id': 16595}, {'_account_id': 16834}, {'_account_id': 16862}, {'_account_id': 16880}, {'_account_id': 16897}, {'_account_id': 16898}, {'_account_id': 16941}, {'_account_id': 17852}, {'_account_id': 18120}, {'_account_id': 18444}, {'_account_id': 18752}, {'_account_id': 18997}, {'_account_id': 19004}, {'_account_id': 19146}, {'_account_id': 19933}, {'_account_id': 21193}, {'_account_id': 21863}, {'_account_id': 21976}, {'_account_id': 22126}, {'_account_id': 22248}]","[{'number': 1, 'created': '2016-08-14 08:59:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/6c56736b9d131e29a04f99e37f023e685da31bd9', 'message': 'Sending ScaleIO volume id in attach and detach volume\n\nDriver was changed to send volume.id in initialize\nconnection, but forgot to change in attach and detach\nvolume, so now we add it.\n\nChange-Id: Ie6f7d07bffe3f532e7ac3bf0b7eff19bb9055563\n'}, {'number': 2, 'created': '2016-08-15 07:16:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/1e32892de18e0ca436562d29029fc26b7cd28413', 'message': 'Sending ScaleIO volume id in attach and detach volume\n\nDriver was changed to send volume.id in initialize\nconnection, but forgot to change in attach and detach\nvolume, so now we add it.\n\nChange-Id: Ie6f7d07bffe3f532e7ac3bf0b7eff19bb9055563\n'}, {'number': 3, 'created': '2016-08-16 12:59:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/76e467268ae7b2279f3aab3ade1466ef3d9c5b9a', 'message': 'Sending ScaleIO volume id in attach and detach volume\n\nDriver was changed to send volume.id in initialize\nconnection, but forgot to change in attach and detach\nvolume, so now we add it.\n\nChange-Id: Ie6f7d07bffe3f532e7ac3bf0b7eff19bb9055563\n'}, {'number': 4, 'created': '2016-08-16 19:23:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/ed7d181bde16489bd209e44f567b450a3dd372d6', 'message': 'Sending ScaleIO volume id in attach and detach volume\n\nDriver was changed to send volume.id in initialize\nconnection, but forgot to change in attach and detach\nvolume, so now we add it.\n\nChange-Id: Ie6f7d07bffe3f532e7ac3bf0b7eff19bb9055563\n'}, {'number': 5, 'created': '2016-08-23 08:16:45.000000000', 'files': ['cinder/tests/unit/volume/drivers/emc/scaleio/test_attach_detach_volume.py', 'cinder/volume/drivers/emc/scaleio.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/c8f7e80034caff65222d94d1b467f87541563577', 'message': 'Sending ScaleIO volume id in attach and detach volume\n\nDriver was changed to send volume.id in initialize\nconnection, but forgot to change in attach and detach\nvolume, so now we add it.\n\nCloses-Bug: #1615953\nChange-Id: Ie6f7d07bffe3f532e7ac3bf0b7eff19bb9055563\n'}]",1,355231,c8f7e80034caff65222d94d1b467f87541563577,168,51,5,18997,,,0,"Sending ScaleIO volume id in attach and detach volume

Driver was changed to send volume.id in initialize
connection, but forgot to change in attach and detach
volume, so now we add it.

Closes-Bug: #1615953
Change-Id: Ie6f7d07bffe3f532e7ac3bf0b7eff19bb9055563
",git fetch https://review.opendev.org/openstack/cinder refs/changes/31/355231/4 && git format-patch -1 --stdout FETCH_HEAD,['cinder/volume/drivers/emc/scaleio.py'],1,6c56736b9d131e29a04f99e37f023e685da31bd9,connection_props, connection_properties['scaleIO_volume_id'] = volume.provider_id connection_properties['scaleIO_volume_id'] = volume.provider_id,,2,1
openstack%2Fsahara~master~I353f89ee6d44b323d17110a52cb19c150f88453a,openstack/sahara,master,I353f89ee6d44b323d17110a52cb19c150f88453a,Updated from global requirements,MERGED,2016-08-29 06:17:47.000000000,2016-08-29 08:24:20.000000000,2016-08-29 08:20:44.000000000,"[{'_account_id': 3}, {'_account_id': 7213}, {'_account_id': 12038}]","[{'number': 1, 'created': '2016-08-29 06:17:47.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/sahara/commit/05b0dd08ceb9cccc5295c4b1d70547887095611e', 'message': 'Updated from global requirements\n\nChange-Id: I353f89ee6d44b323d17110a52cb19c150f88453a\n'}]",0,361876,05b0dd08ceb9cccc5295c4b1d70547887095611e,7,3,1,11131,,,0,"Updated from global requirements

Change-Id: I353f89ee6d44b323d17110a52cb19c150f88453a
",git fetch https://review.opendev.org/openstack/sahara refs/changes/76/361876/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,05b0dd08ceb9cccc5295c4b1d70547887095611e,openstack/requirements,python-heatclient>=1.4.0 # Apache-2.0,python-heatclient>=1.1.0 # Apache-2.0,1,1
openstack%2Fopenstack-manuals~master~Id9e6b1a17835a4bc5f0c4b5fdb6dfe61d2ff9472,openstack/openstack-manuals,master,Id9e6b1a17835a4bc5f0c4b5fdb6dfe61d2ff9472,IBM volume driver now supports manage/unmanage volumes,MERGED,2016-08-29 04:05:13.000000000,2016-08-29 08:21:30.000000000,2016-08-29 08:21:30.000000000,"[{'_account_id': 3}, {'_account_id': 10497}, {'_account_id': 12514}, {'_account_id': 14962}, {'_account_id': 21486}]","[{'number': 1, 'created': '2016-08-29 04:05:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/2b6c0bf18be5ff0ceef9507a97eaec43a313887b', 'message': 'IBM volume driver now supports manage/unmanage volumes\n\nChange-Id: Id9e6b1a17835a4bc5f0c4b5fdb6dfe61d2ff9472\nCloses-Bug: #1617822\n'}, {'number': 2, 'created': '2016-08-29 04:17:11.000000000', 'files': ['doc/config-reference/source/block-storage/drivers/ibm-flashsystem-volume-driver.rst'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/9b277670ba461013fcd31ec834d7f69a49ac484b', 'message': 'IBM volume driver now supports manage/unmanage volumes\n\nChange-Id: Id9e6b1a17835a4bc5f0c4b5fdb6dfe61d2ff9472\nCloses-Bug: #1617822\n'}]",0,361824,9b277670ba461013fcd31ec834d7f69a49ac484b,11,5,2,16237,,,0,"IBM volume driver now supports manage/unmanage volumes

Change-Id: Id9e6b1a17835a4bc5f0c4b5fdb6dfe61d2ff9472
Closes-Bug: #1617822
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/24/361824/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/config-reference/source/block-storage/drivers/ibm-flashsystem-volume-driver.rst'],1,2b6c0bf18be5ff0ceef9507a97eaec43a313887b,bug/1617822, - Manage and unmanage a volume. ,,3,0
openstack%2Fkuryr~master~I28d19323312b1704479261b364498676c3eedbb0,openstack/kuryr,master,I28d19323312b1704479261b364498676c3eedbb0,Fix binding dir installation path,ABANDONED,2016-08-27 05:59:35.000000000,2016-08-29 08:18:20.000000000,,"[{'_account_id': 3}, {'_account_id': 1923}, {'_account_id': 6598}, {'_account_id': 9820}, {'_account_id': 11343}, {'_account_id': 14352}]","[{'number': 1, 'created': '2016-08-27 05:59:35.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/kuryr/commit/2b315fd861b476571686508aafc71d44a8a9f2d6', 'message': 'Fix binding dir installation path\n\nInstallation path is being changes to as per default config.\n\nChange-Id: I28d19323312b1704479261b364498676c3eedbb0\nCloses-bug: #1617513\n'}]",0,361560,2b315fd861b476571686508aafc71d44a8a9f2d6,5,6,1,15967,,,0,"Fix binding dir installation path

Installation path is being changes to as per default config.

Change-Id: I28d19323312b1704479261b364498676c3eedbb0
Closes-bug: #1617513
",git fetch https://review.opendev.org/openstack/kuryr refs/changes/60/361560/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,2b315fd861b476571686508aafc71d44a8a9f2d6,bug/1617513, /usr/libexec/kuryr = usr/libexec/kuryr/*, libexec/kuryr = usr/libexec/kuryr/*,1,1
openstack%2Ffuel-qa~stable%2Fmitaka~I91f68fc92ab6580927027196f9b7de158e5f5a30,openstack/fuel-qa,stable/mitaka,I91f68fc92ab6580927027196f9b7de158e5f5a30,Drop old yaml-modification methods,MERGED,2016-08-26 13:28:31.000000000,2016-08-29 08:18:04.000000000,2016-08-29 08:18:04.000000000,"[{'_account_id': 3}, {'_account_id': 8971}, {'_account_id': 15984}, {'_account_id': 16106}, {'_account_id': 19119}]","[{'number': 1, 'created': '2016-08-26 13:28:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/60b8f94e8228a05519727ab1c598a74373963fb0', 'message': ""Drop old yaml-modification methods\n\nYamlEditor is now tested and it's possible to replace old\ndocker-related methods with it.\n\nChange-Id: I91f68fc92ab6580927027196f9b7de158e5f5a30\n""}, {'number': 2, 'created': '2016-08-29 08:00:25.000000000', 'files': ['fuelweb_test/helpers/fuel_actions.py', 'fuelweb_test/tests/plugins/plugin_vip_reservation/test_plugin_vip_reservation.py', 'fuelweb_test/helpers/utils.py', 'fuelweb_test/tests/plugins/plugin_reboot/test_plugin_reboot_task.py', 'gates_tests/helpers/utils.py'], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/1f9e7c0e762728657ce713327a960b75dc20b794', 'message': ""Drop old yaml-modification methods\n\nYamlEditor is now tested and it's possible to replace old\ndocker-related methods with it.\n\nChange-Id: I91f68fc92ab6580927027196f9b7de158e5f5a30\n""}]",0,361177,1f9e7c0e762728657ce713327a960b75dc20b794,16,5,2,15984,,,0,"Drop old yaml-modification methods

YamlEditor is now tested and it's possible to replace old
docker-related methods with it.

Change-Id: I91f68fc92ab6580927027196f9b7de158e5f5a30
",git fetch https://review.opendev.org/openstack/fuel-qa refs/changes/77/361177/2 && git format-patch -1 --stdout FETCH_HEAD,"['fuelweb_test/helpers/fuel_actions.py', 'fuelweb_test/tests/plugins/plugin_vip_reservation/test_plugin_vip_reservation.py', 'fuelweb_test/helpers/utils.py', 'fuelweb_test/tests/plugins/plugin_reboot/test_plugin_reboot_task.py', 'gates_tests/helpers/utils.py']",5,60b8f94e8228a05519727ab1c598a74373963fb0,,"from fuelweb_test.helpers.utils import YamlEditor with YamlEditor(path, ip=actions.admin_ip) as editor: editor['repos'].append(new_repo)"," element = ['repos'] repos = actions.get_value_from_remote_yaml(path, element) repos.append(new_repo) actions.change_remote_yaml(path, element, repos)",28,128
openstack%2Fproject-config~master~I44ba29a60223af5c62cf40a2263fac49fe3d2404,openstack/project-config,master,I44ba29a60223af5c62cf40a2263fac49fe3d2404,Adds an api-ref publishing job for cinder - Block Storage API,MERGED,2016-08-26 21:27:13.000000000,2016-08-29 08:16:33.000000000,2016-08-29 08:16:33.000000000,"[{'_account_id': 2}, {'_account_id': 3}, {'_account_id': 964}, {'_account_id': 1106}, {'_account_id': 6547}, {'_account_id': 7069}, {'_account_id': 11904}, {'_account_id': 16308}]","[{'number': 1, 'created': '2016-08-26 21:27:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/1881972aabd533fe91da7b7df6bd324c99d2edc5', 'message': 'Adds an api-ref publishing job for cinder - Block Storage API\n\nChange-Id: I44ba29a60223af5c62cf40a2263fac49fe3d2404\n'}, {'number': 2, 'created': '2016-08-26 21:31:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/8b6a4235e5be51e87e43483c7c12c5bd8748c0cb', 'message': 'Adds an api-ref publishing job for cinder - Block Storage API\n\nChange-Id: I44ba29a60223af5c62cf40a2263fac49fe3d2404\n'}, {'number': 3, 'created': '2016-08-27 05:58:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/7a32d182439e40895f029058b92eecbf277c2949', 'message': 'Adds an api-ref publishing job for cinder - Block Storage API\n\nChange-Id: I44ba29a60223af5c62cf40a2263fac49fe3d2404\n'}, {'number': 4, 'created': '2016-08-27 15:05:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/39d2ea890fc4dfa48b4e359f9982cf1f9775cd94', 'message': 'Adds an api-ref publishing job for cinder - Block Storage API (1/2)\n\nFor now only gate the documents, we publish later.\n\nChange-Id: I44ba29a60223af5c62cf40a2263fac49fe3d2404\n'}, {'number': 5, 'created': '2016-08-27 15:09:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/888727237d27c501754530fdc07b9639c0e70add', 'message': 'Adds an api-ref publishing job for cinder - Block Storage API (1/2)\n\nFor now only gate the documents, we publish later.\n\nAdd api-ref folder to the skip list.\n\nChange-Id: I44ba29a60223af5c62cf40a2263fac49fe3d2404\n'}, {'number': 6, 'created': '2016-08-28 17:00:47.000000000', 'files': ['jenkins/jobs/projects.yaml', 'zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/f707daf451e098eac7abc13148b6eefa0a4e6784', 'message': 'Adds an api-ref publishing job for cinder - Block Storage API\n\nAlso, add api-ref folder to the skip list.\n\nDepends-On: I82c8b9ca317298b3dc1f7133ce8c0e9b3503730d\nChange-Id: I44ba29a60223af5c62cf40a2263fac49fe3d2404\n'}]",1,361475,f707daf451e098eac7abc13148b6eefa0a4e6784,31,8,6,964,,,0,"Adds an api-ref publishing job for cinder - Block Storage API

Also, add api-ref folder to the skip list.

Depends-On: I82c8b9ca317298b3dc1f7133ce8c0e9b3503730d
Change-Id: I44ba29a60223af5c62cf40a2263fac49fe3d2404
",git fetch https://review.opendev.org/openstack/project-config refs/changes/75/361475/6 && git format-patch -1 --stdout FETCH_HEAD,['jenkins/jobs/projects.yaml'],1,1881972aabd533fe91da7b7df6bd324c99d2edc5,block-storage-api-ref, - api-ref-jobs: service: block-storage ,,3,0
openstack%2Fcinder-specs~master~Id1afb6cc9637951a08c136fdfb141e0e5ae170e8,openstack/cinder-specs,master,Id1afb6cc9637951a08c136fdfb141e0e5ae170e8,Reset Cgsnapshot state,ABANDONED,2016-08-10 03:29:42.000000000,2016-08-29 08:10:32.000000000,,"[{'_account_id': 3}, {'_account_id': 4523}, {'_account_id': 20146}]","[{'number': 1, 'created': '2016-08-10 03:29:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/86b185de5769e3b5e6d3085300eed166abab6c72', 'message': ""Reset Cgsnapshot state\n\nCurrently a user can create Cgsnapshot from a Consistency Group.\nBut there's no single API that allows a user to reset the state\nof cgsnapshot.In this spec, we propose to provide a cgsnapshot\nAPI that can be supported to reset cgsnapshot state.\n\nChange-Id: Id1afb6cc9637951a08c136fdfb141e0e5ae170e8\nblueprint: cgsnapshot-reset-state\n""}, {'number': 2, 'created': '2016-08-13 03:00:14.000000000', 'files': ['specs/ocata/cgsnapshot-reset-state.rst'], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/f337a5c45295ba229eebf581cca6653a76936720', 'message': ""Reset Cgsnapshot state\n\nCurrently a user can create Cgsnapshot from a Consistency Group.\nBut there's no single API that allows a user to reset the state\nof cgsnapshot.In this spec, we propose to provide a cgsnapshot\nAPI that can be supported to reset cgsnapshot state.\n\nChange-Id: Id1afb6cc9637951a08c136fdfb141e0e5ae170e8\nblueprint: cgsnapshot-reset-state\n""}]",1,353233,f337a5c45295ba229eebf581cca6653a76936720,7,3,2,20160,,,0,"Reset Cgsnapshot state

Currently a user can create Cgsnapshot from a Consistency Group.
But there's no single API that allows a user to reset the state
of cgsnapshot.In this spec, we propose to provide a cgsnapshot
API that can be supported to reset cgsnapshot state.

Change-Id: Id1afb6cc9637951a08c136fdfb141e0e5ae170e8
blueprint: cgsnapshot-reset-state
",git fetch https://review.opendev.org/openstack/cinder-specs refs/changes/33/353233/2 && git format-patch -1 --stdout FETCH_HEAD,['specs/ocata/cgsnapshot-reset-state.rst'],1,86b185de5769e3b5e6d3085300eed166abab6c72,bp/cgsnapshot-reset-state,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode =============== Support reset the state of cgsnapshot =============== https://blueprints.launchpad.net/cinder/+spec/cgsnapshot-reset-state Consistency Groups (CG) and CG snapshot support was introduced in Juno. Currently, if the cgsnapshot status become error because some reasons, we can not reset the cgsnapshot state as user hope. This proposal is to allow user reset the cgsnapshot state. Problem description =================== * Reset Cgsnapshot state Currently a user can create Cgsnapshot from a Consistency Group.But there's no single API that allows a user to reset the state of cgsnapshot. In this spec, we propose to provide a cgsnapshot API that can be supported to reset cgsnapshot state. Use Cases ========= User can use a command line to reset cgsnapshot state. Such as `cinder cgsnapshot-reset-state --state <state>` Proposed change =============== * Reset cgsnapshot state * Add an API that allows a tenant to reset cgsnapshot state. Alternatives ------------ We can continue to use the existing CG and CG snapshot APIs. Data model impact ----------------- None REST API impact --------------- New Group Snapshot APIs * Reset cgsnapshot state * V3/<tenant id>/cgsnapshot/<cgsnapshot uuid> * Method: POST * JSON schema definition for V3:: { ""cgsnapshot"": { ""status"": state } } * This methed can reset cgsnapshot state. The list after ""cgsnapshot-reset-state"" will contain UUIDS of cgsnapshots to be reset state and the state after ""--state"" will be reset to the cgsnapshots. Security impact --------------- None. Notifications impact -------------------- None Other end user impact --------------------- python-cinderclient needs to be changed to support the new APIs. * Reset cgsnapshot state cinder snapshot-reset-state <cgsnapshot> --state <state> Performance Impact ------------------ None Other deployer impact --------------------- None Developer impact ---------------- None Implementation ============== Assignee(s) ----------- Primary assignee: haobing <hao.bing1@zte.com.cn> Other contributors: Work Items ---------- 1. New cgsnapshot APIs * Reset cgsnapshot state Dependencies ============ Testing ======= New unit tests will be added to test the changed code. Tempest tests should be added as well. Functional tests could be added if needed. Documentation Impact ==================== Documentation changes are needed. References ========== * [1]: https://review.openstack.org/#/c/96665/ * [2]: https://review.openstack.org/#/c/131024/ ",,142,0
openstack%2Fmurano-apps~master~Ie7e5c4aea3b0cee519ae5ed81cff0dcc3ab67562,openstack/murano-apps,master,Ie7e5c4aea3b0cee519ae5ed81cff0dcc3ab67562,[K8s] Fixing patchService.sh,MERGED,2016-08-26 13:33:40.000000000,2016-08-29 08:09:52.000000000,2016-08-26 14:24:22.000000000,"[{'_account_id': 3}, {'_account_id': 6577}, {'_account_id': 13149}, {'_account_id': 13323}]","[{'number': 1, 'created': '2016-08-26 13:33:40.000000000', 'files': ['Docker/Kubernetes/KubernetesCluster/package/Resources/scripts/patchService.sh'], 'web_link': 'https://opendev.org/openstack/murano-apps/commit/94734974c62102cb4272cc75ce72b8ed039e83ef', 'message': ""[K8s] Fixing patchService.sh\n\n * Since update command is replaced by replace here\n   https://review.openstack.org/#/c/358661/\n   for patching the resource it needs to use\n   'kubectl patch <type> <name> --patch <patch>'\n\nChange-Id: Ie7e5c4aea3b0cee519ae5ed81cff0dcc3ab67562\n""}]",0,361182,94734974c62102cb4272cc75ce72b8ed039e83ef,10,4,1,7700,,,0,"[K8s] Fixing patchService.sh

 * Since update command is replaced by replace here
   https://review.openstack.org/#/c/358661/
   for patching the resource it needs to use
   'kubectl patch <type> <name> --patch <patch>'

Change-Id: Ie7e5c4aea3b0cee519ae5ed81cff0dcc3ab67562
",git fetch https://review.opendev.org/openstack/murano-apps refs/changes/82/361182/1 && git format-patch -1 --stdout FETCH_HEAD,['Docker/Kubernetes/KubernetesCluster/package/Resources/scripts/patchService.sh'],1,94734974c62102cb4272cc75ce72b8ed039e83ef,k8s_fix_patch,"/opt/bin/kubectl patch service ""$1"" --patch=""$2""","/opt/bin/kubectl replace service ""$1"" --patch=""$2""",1,1
openstack%2Fheat~stable%2Fmitaka~Icb4f58630016874eb40dd77590469fc5de6287e4,openstack/heat,stable/mitaka,Icb4f58630016874eb40dd77590469fc5de6287e4,Validate that python3 is ready for loguserdata,MERGED,2016-08-26 13:57:31.000000000,2016-08-29 08:07:31.000000000,2016-08-29 08:07:31.000000000,"[{'_account_id': 3}, {'_account_id': 4328}, {'_account_id': 6577}, {'_account_id': 19372}]","[{'number': 1, 'created': '2016-08-26 13:57:31.000000000', 'files': ['heat/cloudinit/loguserdata.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/ed46562157d2f9983f5665394ec47d2e27aad0df', 'message': ""Validate that python3 is ready for loguserdata\n\nBy default, ubuntu trusty images has python3 executable in\npath, but we can't use that for executing loguserdata script,\nbecause pkg_resources can't be imported. Now it's proposed to\ntry importing pkg_resources for validating readiness of\npython3 for executing this script. If pkg_resources can't be\nimported there is no other choice except using python2.\n\nChange-Id: Icb4f58630016874eb40dd77590469fc5de6287e4\nCloses-bug: 1617069\n""}]",0,361223,ed46562157d2f9983f5665394ec47d2e27aad0df,8,4,1,12038,,,0,"Validate that python3 is ready for loguserdata

By default, ubuntu trusty images has python3 executable in
path, but we can't use that for executing loguserdata script,
because pkg_resources can't be imported. Now it's proposed to
try importing pkg_resources for validating readiness of
python3 for executing this script. If pkg_resources can't be
imported there is no other choice except using python2.

Change-Id: Icb4f58630016874eb40dd77590469fc5de6287e4
Closes-bug: 1617069
",git fetch https://review.opendev.org/openstack/heat refs/changes/23/361223/1 && git format-patch -1 --stdout FETCH_HEAD,['heat/cloudinit/loguserdata.py'],1,ed46562157d2f9983f5665394ec47d2e27aad0df,bug/1617069,"# NOTE(vgridnev): ubuntu trusty by default has python3, # but pkg_resources can't be imported. echo ""import pkg_resources"" | python3 2>/dev/null has_py3=$? if [ $has_py3 = 0 ]; then",if hash python3 2>/dev/null; then,5,1
openstack%2Fopenstack-manuals~master~Idbb5f02e042978d47cb86327705bfc419238e888,openstack/openstack-manuals,master,Idbb5f02e042978d47cb86327705bfc419238e888,EMC-vmax driver supports iSCSI multipath,MERGED,2016-08-29 04:26:23.000000000,2016-08-29 08:02:52.000000000,2016-08-29 08:02:52.000000000,"[{'_account_id': 3}, {'_account_id': 10497}, {'_account_id': 14962}]","[{'number': 1, 'created': '2016-08-29 04:26:23.000000000', 'files': ['doc/config-reference/source/block-storage/drivers/emc-vmax-driver.rst'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/ad4321e1faed8f2f174e7349e92c7df5119191aa', 'message': 'EMC-vmax driver supports iSCSI multipath\n\nChange-Id: Idbb5f02e042978d47cb86327705bfc419238e888\nCloses-Bug: #1614668\n'}]",0,361829,ad4321e1faed8f2f174e7349e92c7df5119191aa,7,3,1,16237,,,0,"EMC-vmax driver supports iSCSI multipath

Change-Id: Idbb5f02e042978d47cb86327705bfc419238e888
Closes-Bug: #1614668
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/29/361829/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/config-reference/source/block-storage/drivers/emc-vmax-driver.rst'],1,ad4321e1faed8f2f174e7349e92c7df5119191aa,bug/1614668,- iSCSI multipath support.- iSCSI multipath support.,,2,0
openstack%2Fmanila~master~I99c1a8b2621efccab71f716f661c539e7d9eef57,openstack/manila,master,I99c1a8b2621efccab71f716f661c539e7d9eef57,[Do Not Merge] Test networking issues in tests,ABANDONED,2016-08-26 08:25:01.000000000,2016-08-29 07:59:31.000000000,,"[{'_account_id': 3}, {'_account_id': 12017}, {'_account_id': 15942}, {'_account_id': 16657}, {'_account_id': 17565}, {'_account_id': 18128}, {'_account_id': 18752}, {'_account_id': 21884}]","[{'number': 1, 'created': '2016-08-26 08:25:01.000000000', 'files': ['manila/share/drivers/service_instance.py'], 'web_link': 'https://opendev.org/openstack/manila/commit/8e1ee2df1c640192f55036857d96d71187447b86', 'message': '[Do Not Merge] Test networking issues in tests\n\nChange-Id: I99c1a8b2621efccab71f716f661c539e7d9eef57\n'}]",0,360973,8e1ee2df1c640192f55036857d96d71187447b86,10,8,1,6938,,,0,"[Do Not Merge] Test networking issues in tests

Change-Id: I99c1a8b2621efccab71f716f661c539e7d9eef57
",git fetch https://review.opendev.org/openstack/manila refs/changes/73/360973/1 && git format-patch -1 --stdout FETCH_HEAD,['manila/share/drivers/service_instance.py'],1,8e1ee2df1c640192f55036857d96d71187447b86,generic-rntelink," @utils.retry(exception.ProcessExecutionError, 5, 15) def _pullup_with_caution(self, device, interface_name): # Always stay alert when pulling things up! device.route.pullup_route(interface_name) try: self._pullup_with_caution(device, interface_name) except exception.ProcessExecutionError: LOG.warning(_LW(""Failed to pullup interface %(i)s on device "" ""%(d)s""), {'i': str(interface_name), 'd': str(device)}) raise", device.route.pullup_route(interface_name),12,1
openstack%2Fmanila~master~I5fcbb16c706981910fec1c5c1eb68cf9099f0ab7,openstack/manila,master,I5fcbb16c706981910fec1c5c1eb68cf9099f0ab7,[Do Not Merge] More tests for generic networking behaviour,ABANDONED,2016-08-26 09:50:45.000000000,2016-08-29 07:59:24.000000000,,"[{'_account_id': 3}, {'_account_id': 6938}, {'_account_id': 12017}, {'_account_id': 14567}, {'_account_id': 15942}, {'_account_id': 16657}, {'_account_id': 17565}, {'_account_id': 18128}, {'_account_id': 18752}, {'_account_id': 21884}]","[{'number': 1, 'created': '2016-08-26 09:50:45.000000000', 'files': ['manila/share/drivers/service_instance.py'], 'web_link': 'https://opendev.org/openstack/manila/commit/ad145c86d0dbb5e1f2b70cd5d3785304637ff363', 'message': '[Do Not Merge] More tests for generic networking behaviour\n\nChange-Id: I5fcbb16c706981910fec1c5c1eb68cf9099f0ab7\n'}]",1,361045,ad145c86d0dbb5e1f2b70cd5d3785304637ff363,16,10,1,6938,,,0,"[Do Not Merge] More tests for generic networking behaviour

Change-Id: I5fcbb16c706981910fec1c5c1eb68cf9099f0ab7
",git fetch https://review.opendev.org/openstack/manila refs/changes/45/361045/1 && git format-patch -1 --stdout FETCH_HEAD,['manila/share/drivers/service_instance.py'],1,ad145c86d0dbb5e1f2b70cd5d3785304637ff363,netwcheck-scnario-fix," @utils.retry(exception.ProcessExecutionError, 5, 15) def _pullup_with_caution(self, device, interface_name): # Never whistle while you're pulling up. device.route.pullup_route(interface_name) try: self._pullup_with_caution(device, interface_name) except exception.ProcessExecutionError: LOG.warning(_LW(""Failed to pullup interface %(i)s on device "" ""%(d)s""), {'i': str(interface_name), 'd': str(device)}) raise", device.route.pullup_route(interface_name),12,1
openstack%2Ftempest~master~I822242c98974dbb5cc90ce63c8afadb08fdc16e9,openstack/tempest,master,I822242c98974dbb5cc90ce63c8afadb08fdc16e9,Add InvalidConfiguration's error message,ABANDONED,2016-08-11 07:46:13.000000000,2016-08-29 07:58:42.000000000,,"[{'_account_id': 3}, {'_account_id': 5689}, {'_account_id': 6167}, {'_account_id': 7350}, {'_account_id': 8871}, {'_account_id': 9152}, {'_account_id': 10385}, {'_account_id': 12017}, {'_account_id': 16803}, {'_account_id': 20190}]","[{'number': 1, 'created': '2016-08-11 07:46:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/61caad46edb2c44b4d592a37abb02149c0e1f4ed', 'message': 'Add InvalidConfiguration\'s error message\n\nIn get_server_ip, when value of CONF.validation.connect_method\nis neigher \'floating\' nor \'fixed\', it will raise en exception\nwith error message ""Invalid Configuration"", and this is too\nsimple for person to know what happens. This is to add detailed\ninfo.\n\nChange-Id: I822242c98974dbb5cc90ce63c8afadb08fdc16e9\n'}, {'number': 2, 'created': '2016-08-11 09:29:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/deb4d63773187f8419c2fe2609dd2ce1dce3d80a', 'message': 'Add InvalidConfiguration\'s error message\n\nIn get_server_ip, when value of CONF.validation.connect_method\nis neigher \'floating\' nor \'fixed\', it will raise en exception\nwith error message ""Invalid Configuration"", and this is too\nsimple for person to know what happens. This is to add detailed\ninfo.\n\nChange-Id: I822242c98974dbb5cc90ce63c8afadb08fdc16e9\n'}, {'number': 3, 'created': '2016-08-16 09:45:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/b7ab2ccce2e6ca1bf4d45d50ba99fe3053db6f6a', 'message': 'Add InvalidConfiguration\'s error message\n\nIn get_server_ip, when value of CONF.validation.connect_method\nis neigher \'floating\' nor \'fixed\', it will raise en exception\nwith error message ""Invalid Configuration"", and this is too\nsimple for person to know what happens. This is to add detailed\ninfo.\n\nChange-Id: I822242c98974dbb5cc90ce63c8afadb08fdc16e9\n'}, {'number': 4, 'created': '2016-08-29 00:47:35.000000000', 'files': ['tempest/api/compute/base.py', 'tempest/scenario/manager.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/5388a8d236d96e4d216af2c111e16bf057f7e842', 'message': 'Add InvalidConfiguration\'s error message\n\nIn get_server_ip, when value of CONF.validation.connect_method\nis neigher \'floating\' nor \'fixed\', it will raise en exception\nwith error message ""Invalid Configuration"", and this is too\nsimple for person to know what happens. This is to add detailed\ninfo.\n\nChange-Id: I822242c98974dbb5cc90ce63c8afadb08fdc16e9\n'}]",0,353885,5388a8d236d96e4d216af2c111e16bf057f7e842,39,10,4,20190,,,0,"Add InvalidConfiguration's error message

In get_server_ip, when value of CONF.validation.connect_method
is neigher 'floating' nor 'fixed', it will raise en exception
with error message ""Invalid Configuration"", and this is too
simple for person to know what happens. This is to add detailed
info.

Change-Id: I822242c98974dbb5cc90ce63c8afadb08fdc16e9
",git fetch https://review.opendev.org/openstack/tempest refs/changes/85/353885/4 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/api/compute/base.py', 'tempest/scenario/manager.py']",2,61caad46edb2c44b4d592a37abb02149c0e1f4ed,InvalidConfiguration," raise exceptions.InvalidConfiguration(""value of CONF.validation."" ""connect_method should be 'floating' or 'fixed'"")", raise exceptions.InvalidConfiguration(),4,2
openstack%2Fpython-karborclient~master~I62290f48e2cc5d4b7f837abaaf44d6b21251f57e,openstack/python-karborclient,master,I62290f48e2cc5d4b7f837abaaf44d6b21251f57e,Fix package to be 'karborclient',MERGED,2016-08-28 12:10:47.000000000,2016-08-29 07:54:52.000000000,2016-08-29 07:54:52.000000000,"[{'_account_id': 3}, {'_account_id': 17151}, {'_account_id': 17192}, {'_account_id': 20883}]","[{'number': 1, 'created': '2016-08-28 12:10:47.000000000', 'files': ['setup.cfg', 'karborclient/__init__.py'], 'web_link': 'https://opendev.org/openstack/python-karborclient/commit/271998a5e8c96a0b497688dac56cf3d8ca65e908', 'message': ""Fix package to be 'karborclient'\n\nPackage name will be 'python-smaugclient' for pypi, and\n'karborclient' for python\n\nChange-Id: I62290f48e2cc5d4b7f837abaaf44d6b21251f57e\n""}]",0,361724,271998a5e8c96a0b497688dac56cf3d8ca65e908,8,4,1,20883,,,0,"Fix package to be 'karborclient'

Package name will be 'python-smaugclient' for pypi, and
'karborclient' for python

Change-Id: I62290f48e2cc5d4b7f837abaaf44d6b21251f57e
",git fetch https://review.opendev.org/openstack/python-karborclient refs/changes/24/361724/1 && git format-patch -1 --stdout FETCH_HEAD,"['setup.cfg', 'karborclient/__init__.py']",2,271998a5e8c96a0b497688dac56cf3d8ca65e908,karborclient, 'python-smaugclient').version_string(), 'python-karborclient').version_string(),2,2
openstack%2Fheat~master~Idd08d9729deac463175c1bbfd70230b9700afad8,openstack/heat,master,Idd08d9729deac463175c1bbfd70230b9700afad8,Use param_schema and merge strategy for merging,MERGED,2016-07-25 14:21:50.000000000,2016-08-29 07:54:28.000000000,2016-08-29 07:54:27.000000000,"[{'_account_id': 3}, {'_account_id': 4328}, {'_account_id': 4571}, {'_account_id': 6681}, {'_account_id': 7404}, {'_account_id': 8833}, {'_account_id': 22785}]","[{'number': 1, 'created': '2016-07-25 14:21:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/68fcfa66feccfdbc0f35f180fc3d03d69fee4bb3', 'message': 'WIP Add parameter merge strategy to environments\n\nThis adds a new section to environment files that\nspecifies the merge strategy for parameters. This\nis subsequently dropped from the env.\n\nChange-Id: Idd08d9729deac463175c1bbfd70230b9700afad8\nBlueprint: environment-merging\n'}, {'number': 2, 'created': '2016-08-03 11:15:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/61e0ef2a1f3b4ca0826a5dee7a7eed3b5617ea7a', 'message': 'WIP Add parameter merge strategy to environments\n\nThis adds a new section to environment files that\nspecifies the merge strategy for parameters. This\nis subsequently dropped from the env.\n\nChange-Id: Idd08d9729deac463175c1bbfd70230b9700afad8\nBlueprint: environment-merging\n'}, {'number': 3, 'created': '2016-08-04 09:48:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/d786144c3d83e4789f32e93cfdb3a7534720beee', 'message': 'Use param_schema and merge strategy for merging\n\nNow we can use the param schema to decide the type for\nparameters/parameter defaults and the param specific\nmerge startegy when doing environment merging.\n\nChange-Id: Idd08d9729deac463175c1bbfd70230b9700afad8\nBlueprint: environment-merging\n'}, {'number': 4, 'created': '2016-08-04 12:21:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/bd8af92a97e4b4a75256dcd1d8d56ec7beb6475f', 'message': 'Use param_schema and merge strategy for merging\n\nNow we can use the param schema to decide the type for\nparameters/parameter defaults and the param specific\nmerge startegy when doing environment merging.\n\nChange-Id: Idd08d9729deac463175c1bbfd70230b9700afad8\nBlueprint: environment-merging\n'}, {'number': 5, 'created': '2016-08-05 04:37:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/cd2cd1cda0c7446d1ead8966943a74828df698c4', 'message': 'Use param_schema and merge strategy for merging\n\nNow we can use the param schema to decide the type for\nparameters/parameter defaults and the param specific\nmerge startegy when doing environment merging.\n\nChange-Id: Idd08d9729deac463175c1bbfd70230b9700afad8\nBlueprint: environment-merging\n'}, {'number': 6, 'created': '2016-08-19 03:53:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/ebd8d697fadac8e1a08a3082fc0b4c4261888c5c', 'message': 'Use param_schema and merge strategy for merging\n\nNow we can use the param schema to decide the type for\nparameters/parameter defaults and the param specific\nmerge startegy when doing environment merging.\n\nChange-Id: Idd08d9729deac463175c1bbfd70230b9700afad8\nBlueprint: environment-merging\n'}, {'number': 7, 'created': '2016-08-22 08:16:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/d041d6ad0e817dfdc00f6fe01a328ab0eac0cfa0', 'message': 'Use param_schema and merge strategy for merging\n\nNow we can use the param schema to decide the type for\nparameters/parameter defaults and the param specific\nmerge startegy when doing environment merging.\n\nChange-Id: Idd08d9729deac463175c1bbfd70230b9700afad8\nBlueprint: environment-merging\n'}, {'number': 8, 'created': '2016-08-22 12:14:40.000000000', 'files': ['heat/tests/test_common_env_util.py', 'heat/common/exception.py', 'heat/common/environment_util.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/4c8294d9ac3e02df95f47200396fdd29fb41af60', 'message': 'Use param_schema and merge strategy for merging\n\nNow we can use the param schema to decide the type for\nparameters/parameter defaults and the param specific\nmerge startegy when doing environment merging.\n\nChange-Id: Idd08d9729deac463175c1bbfd70230b9700afad8\nBlueprint: environment-merging\n'}]",1,346850,4c8294d9ac3e02df95f47200396fdd29fb41af60,25,7,8,8833,,,0,"Use param_schema and merge strategy for merging

Now we can use the param schema to decide the type for
parameters/parameter defaults and the param specific
merge startegy when doing environment merging.

Change-Id: Idd08d9729deac463175c1bbfd70230b9700afad8
Blueprint: environment-merging
",git fetch https://review.opendev.org/openstack/heat refs/changes/50/346850/8 && git format-patch -1 --stdout FETCH_HEAD,"['heat/tests/engine/service/test_service_engine.py', 'heat/engine/environment.py', 'heat/common/environment_format.py', 'heat/engine/service.py']",4,68fcfa66feccfdbc0f35f180fc3d03d69fee4bb3,bp/environment-merging," parsed_env = env_fmt.parse(raw_env) merge_strategies = parsed_env.pop( env_fmt.PARAMETER_MERGE_STRATEGIES, {}) parameters = params.pop(env_fmt.PARAMETERS, {}) parsed_params = parsed_env.pop(env_fmt.PARAMETERS, {}) env_fmt.merge_parameters(parameters, parsed_params, merge_strategies) params[env_fmt.PARAMETERS] = parameters",from heatclient.common import environment_format parsed_env = environment_format.parse(raw_env),217,6
openstack%2Fheat~master~I86a28d0496e05f978fa1b734818404639541761b,openstack/heat,master,I86a28d0496e05f978fa1b734818404639541761b,Refactor to use param_schemata with env merge,MERGED,2016-08-04 09:48:57.000000000,2016-08-29 07:54:20.000000000,2016-08-29 07:54:20.000000000,"[{'_account_id': 3}, {'_account_id': 4328}, {'_account_id': 4571}, {'_account_id': 7404}]","[{'number': 1, 'created': '2016-08-04 09:48:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/300af8a6ae08caa6241b751a30548448a61d93e8', 'message': 'Refactor to use param_schemata with env merge\n\nThis refactors the service module to use template_schemata\nfor environment merging.\n\nChange-Id: I86a28d0496e05f978fa1b734818404639541761b\nBlueprint: environment-merging\n'}, {'number': 2, 'created': '2016-08-04 12:21:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/c3f9d4ffbe0c4fbec31cae4fd85220b1a8237d83', 'message': 'Refactor to use param_schemata with env merge\n\nThis refactors the service module to use template_schemata\nfor environment merging.\n\nChange-Id: I86a28d0496e05f978fa1b734818404639541761b\nBlueprint: environment-merging\n'}, {'number': 3, 'created': '2016-08-05 04:37:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/44cdfefead9d7b4eb7815c1a93e0b24a0f953ee4', 'message': 'Refactor to use param_schemata with env merge\n\nThis refactors the service module to use template_schemata\nfor environment merging.\n\nChange-Id: I86a28d0496e05f978fa1b734818404639541761b\nBlueprint: environment-merging\n'}, {'number': 4, 'created': '2016-08-19 03:53:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/01ddfddeb772a8d33359a92ee612f3f281113388', 'message': 'Refactor to use param_schemata with env merge\n\nThis refactors the service module to use template_schemata\nfor environment merging.\n\nChange-Id: I86a28d0496e05f978fa1b734818404639541761b\nBlueprint: environment-merging\n'}, {'number': 5, 'created': '2016-08-22 08:16:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/8bfb395d7f55358b4616fa80e16e36b2e2f98d78', 'message': 'Refactor to use param_schemata with env merge\n\nThis refactors the service module to use template_schemata\nfor environment merging.\n\nChange-Id: I86a28d0496e05f978fa1b734818404639541761b\nBlueprint: environment-merging\n'}, {'number': 6, 'created': '2016-08-22 12:14:40.000000000', 'files': ['heat/tests/test_engine_service.py', 'heat/tests/engine/service/test_stack_update.py', 'heat/common/environment_util.py', 'heat/engine/service.py', 'heat/tests/engine/service/test_stack_create.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/35a2dd9196230449b256ca120c26814805042494', 'message': 'Refactor to use param_schemata with env merge\n\nThis refactors the service module to use template_schemata\nfor environment merging.\n\nChange-Id: I86a28d0496e05f978fa1b734818404639541761b\nBlueprint: environment-merging\n'}]",0,351096,35a2dd9196230449b256ca120c26814805042494,17,4,6,8833,,,0,"Refactor to use param_schemata with env merge

This refactors the service module to use template_schemata
for environment merging.

Change-Id: I86a28d0496e05f978fa1b734818404639541761b
Blueprint: environment-merging
",git fetch https://review.opendev.org/openstack/heat refs/changes/96/351096/3 && git format-patch -1 --stdout FETCH_HEAD,"['heat/tests/test_engine_service.py', 'heat/tests/engine/service/test_stack_update.py', 'heat/common/environment_util.py', 'heat/engine/service.py', 'heat/tests/engine/service/test_stack_create.py']",5,300af8a6ae08caa6241b751a30548448a61d93e8,bp/environment-merging," mock_tmpl.assert_called_once_with(template, files=None) mock_merge.assert_called_once_with(environment_files, None, params, mock.ANY) mock_tmpl.assert_called_once_with(template, files=None) mock_tmpl.assert_called_once_with(template, files=None) mock_tmpl.assert_called_once_with(template, files=None) mock_tmpl.assert_called_once_with(template, files=None)"," mock_tmpl.assert_called_once_with(template, files=None, env=stk.env) mock_merge.assert_called_once_with(environment_files, None, params) mock_tmpl.assert_called_once_with(template, files=None, env=stk.env) mock_tmpl.assert_called_once_with(template, files=None, env=stk.env) mock_tmpl.assert_called_once_with(template, files=None, env=stk.env) mock_tmpl.assert_called_once_with(template, files=None, env=stk.env)",58,54
openstack%2Fkolla~master~I029e7589716b7d4fd29d4fc75bafc434ea275a9f,openstack/kolla,master,I029e7589716b7d4fd29d4fc75bafc434ea275a9f,Fix Kibana image build error,MERGED,2016-08-29 04:44:10.000000000,2016-08-29 07:52:14.000000000,2016-08-29 07:52:14.000000000,"[{'_account_id': 3}, {'_account_id': 11105}, {'_account_id': 19316}]","[{'number': 1, 'created': '2016-08-29 04:44:10.000000000', 'files': ['docker/kibana/Dockerfile.j2'], 'web_link': 'https://opendev.org/openstack/kolla/commit/92b2fd94c12f6b52d3af8a0aa911a30bbb25493d', 'message': 'Fix Kibana image build error\n\nTrivialFix\nCloses-Bug: #1617877\n\nChange-Id: I029e7589716b7d4fd29d4fc75bafc434ea275a9f\n'}]",0,361833,92b2fd94c12f6b52d3af8a0aa911a30bbb25493d,7,3,1,22582,,,0,"Fix Kibana image build error

TrivialFix
Closes-Bug: #1617877

Change-Id: I029e7589716b7d4fd29d4fc75bafc434ea275a9f
",git fetch https://review.opendev.org/openstack/kolla refs/changes/33/361833/1 && git format-patch -1 --stdout FETCH_HEAD,['docker/kibana/Dockerfile.j2'],1,92b2fd94c12f6b52d3af8a0aa911a30bbb25493d,bug/1617877,"{{ macros.install_packages(kibana_packages | customizable(""packages"")) }}","RUN {{ macros.install_packages(kibana_packages | customizable(""packages"")) }}",1,1
openstack%2Fwatcher~master~I0b967e4931223b3b7e9459fb1483ed8185a1a7a0,openstack/watcher,master,I0b967e4931223b3b7e9459fb1483ed8185a1a7a0,TrivialFix: Remove logging import unused,MERGED,2016-08-29 05:48:37.000000000,2016-08-29 07:48:35.000000000,2016-08-29 07:48:35.000000000,"[{'_account_id': 3}, {'_account_id': 12394}]","[{'number': 1, 'created': '2016-08-29 05:48:37.000000000', 'files': ['watcher/decision_engine/goal/base.py', 'watcher/decision_engine/model/notification/filtering.py', 'watcher/decision_engine/model/notification/base.py', 'watcher/applier/rpcapi.py', 'watcher/applier/manager.py'], 'web_link': 'https://opendev.org/openstack/watcher/commit/720884cd5551466d649fb7797cd180ae6c3379e4', 'message': 'TrivialFix: Remove logging import unused\n\nThis patch removes logging import unused in\nwatcher/applier/manager.py\nwatcher/applier/rpcapi.py\nwatcher/decision_engine/goal/base.py\nwatcher/decision_engine/model/notification/base.py\nwatcher/decision_engine/model/notification/filtering.py\n\nChange-Id: I0b967e4931223b3b7e9459fb1483ed8185a1a7a0\n'}]",0,361849,720884cd5551466d649fb7797cd180ae6c3379e4,6,2,1,15905,,,0,"TrivialFix: Remove logging import unused

This patch removes logging import unused in
watcher/applier/manager.py
watcher/applier/rpcapi.py
watcher/decision_engine/goal/base.py
watcher/decision_engine/model/notification/base.py
watcher/decision_engine/model/notification/filtering.py

Change-Id: I0b967e4931223b3b7e9459fb1483ed8185a1a7a0
",git fetch https://review.opendev.org/openstack/watcher refs/changes/49/361849/1 && git format-patch -1 --stdout FETCH_HEAD,"['watcher/decision_engine/goal/base.py', 'watcher/decision_engine/model/notification/filtering.py', 'watcher/decision_engine/model/notification/base.py', 'watcher/applier/rpcapi.py', 'watcher/applier/manager.py']",5,720884cd5551466d649fb7797cd180ae6c3379e4,bug/remove-logging-unused,,from oslo_log import logLOG = log.getLogger(__name__),0,15
openstack%2Fnetworking-bagpipe~master~I2e020d94aef48983f98656ba1a16216a61354dcd,openstack/networking-bagpipe,master,I2e020d94aef48983f98656ba1a16216a61354dcd,Updated from global requirements,MERGED,2016-08-26 22:07:58.000000000,2016-08-29 07:42:59.000000000,2016-08-29 07:42:59.000000000,"[{'_account_id': 3}, {'_account_id': 12021}]","[{'number': 1, 'created': '2016-08-26 22:07:58.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/networking-bagpipe/commit/68962b853eea06de4761f6c7d543cb07af34f50c', 'message': 'Updated from global requirements\n\nChange-Id: I2e020d94aef48983f98656ba1a16216a61354dcd\n'}]",0,361487,68962b853eea06de4761f6c7d543cb07af34f50c,6,2,1,11131,,,0,"Updated from global requirements

Change-Id: I2e020d94aef48983f98656ba1a16216a61354dcd
",git fetch https://review.opendev.org/openstack/networking-bagpipe refs/changes/87/361487/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,68962b853eea06de4761f6c7d543cb07af34f50c,openstack/requirements,neutron-lib>=0.4.0 # Apache-2.0,neutron-lib>=0.3.0 # Apache-2.0,1,1
openstack%2Ffuel-devops~master~Icd3bb59844abe171c075b38accbbc1e8f222d435,openstack/fuel-devops,master,Icd3bb59844abe171c075b38accbbc1e8f222d435,Make coverage report human-readable,MERGED,2016-08-29 05:17:08.000000000,2016-08-29 07:39:36.000000000,2016-08-29 07:39:36.000000000,"[{'_account_id': 3}, {'_account_id': 11969}, {'_account_id': 19119}]","[{'number': 1, 'created': '2016-08-29 05:17:08.000000000', 'files': ['.pylintrc', '.pylintrc_gerrit', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/fuel-devops/commit/07a2791259d05d758c4cc995100ed9eeb643018e', 'message': 'Make coverage report human-readable\n\nrequest HTML lig in tox logdir, which is accessible on gates\ncompletely ignore migrations in pylint\n\nChange-Id: Icd3bb59844abe171c075b38accbbc1e8f222d435\n'}]",0,361837,07a2791259d05d758c4cc995100ed9eeb643018e,7,3,1,19119,,,0,"Make coverage report human-readable

request HTML lig in tox logdir, which is accessible on gates
completely ignore migrations in pylint

Change-Id: Icd3bb59844abe171c075b38accbbc1e8f222d435
",git fetch https://review.opendev.org/openstack/fuel-devops refs/changes/37/361837/1 && git format-patch -1 --stdout FETCH_HEAD,"['.pylintrc', '.pylintrc_gerrit', 'tox.ini']",3,07a2791259d05d758c4cc995100ed9eeb643018e,, coverage html -d {envlogdir},,3,2
openstack%2Fneutron~master~I5ef0e7cc79609ba9df31d6573fe935a6e8d837f4,openstack/neutron,master,I5ef0e7cc79609ba9df31d6573fe935a6e8d837f4,Fix NoSuchOptError on identity config option lookup,MERGED,2016-08-19 02:26:37.000000000,2016-08-29 07:31:40.000000000,2016-08-19 07:32:19.000000000,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 5170}, {'_account_id': 6854}, {'_account_id': 6951}, {'_account_id': 8246}, {'_account_id': 8344}, {'_account_id': 8873}, {'_account_id': 9656}, {'_account_id': 9845}, {'_account_id': 10980}, {'_account_id': 11278}, {'_account_id': 14208}, {'_account_id': 15752}, {'_account_id': 16710}, {'_account_id': 17120}]","[{'number': 1, 'created': '2016-08-19 02:26:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e5dd901abaa6aba5b591eeea752f69c9312280a5', 'message': 'Fix NoSuchOptError on identity config option lookup\n\nChange 1afca56b059 moved a few options around and that\nbroke the Tempest API client module.\n\nChange-Id: I5ef0e7cc79609ba9df31d6573fe935a6e8d837f4\nCloses-bug: #1614799\n'}, {'number': 2, 'created': '2016-08-19 02:50:22.000000000', 'files': ['neutron/tests/tempest/api/clients.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/af9ad0c35e40e91357a7ec41b12416b4ca34cd83', 'message': 'Fix NoSuchOptError on identity config option lookup\n\nChange 1afca56b059 moved a few options around and that\nbroke the Tempest API clients module. This patch adds\nthe logic to handle the change.\n\nCloses-bug: #1614799\n\nChange-Id: I5ef0e7cc79609ba9df31d6573fe935a6e8d837f4\n'}]",0,357575,af9ad0c35e40e91357a7ec41b12416b4ca34cd83,22,16,2,748,,,0,"Fix NoSuchOptError on identity config option lookup

Change 1afca56b059 moved a few options around and that
broke the Tempest API clients module. This patch adds
the logic to handle the change.

Closes-bug: #1614799

Change-Id: I5ef0e7cc79609ba9df31d6573fe935a6e8d837f4
",git fetch https://review.opendev.org/openstack/neutron refs/changes/75/357575/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/tests/tempest/api/clients.py'],1,e5dd901abaa6aba5b591eeea752f69c9312280a5,bug/1614799," CONF.service_clients.disable_ssl_certificate_validation, 'ca_certs': CONF.service_clients.ca_certificates_file,"," CONF.identity.disable_ssl_certificate_validation, 'ca_certs': CONF.identity.ca_certificates_file,",2,2
openstack%2Ffuel-main~master~Iaf7520b96e26c0830238a79f84b4e17d388e1c43,openstack/fuel-main,master,Iaf7520b96e26c0830238a79f84b4e17d388e1c43,Remove unused prepare_file_source function,ABANDONED,2016-02-10 20:20:37.000000000,2016-08-29 07:31:34.000000000,,"[{'_account_id': 3}, {'_account_id': 3009}, {'_account_id': 10474}, {'_account_id': 12817}, {'_account_id': 13194}, {'_account_id': 14200}]","[{'number': 1, 'created': '2016-02-10 20:20:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/a90d8319529a34bbdec18b437b4f5fbb3ebb8853', 'message': ""Remove unused prepare_file_source function\n\nSince fuel-bootstrap-image and fuel-docker-images were removed\nfrom build system we don't need prepare_file_source function any\nmore\n\nChange-Id: Iaf7520b96e26c0830238a79f84b4e17d388e1c43\nRelated-bp: #get-rid-docker-containers\nRelated-bp: #remove-centos-bootstrap-from-fuel\n""}, {'number': 2, 'created': '2016-02-11 09:07:54.000000000', 'files': ['packages/module.mk'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/f5b1db704cee3aa08a27304f493d510e35988d87', 'message': ""Remove unused prepare_file_source function\n\nSince fuel-bootstrap-image and fuel-docker-images were removed\nfrom build system we don't need prepare_file_source function any\nmore\n\nChange-Id: Iaf7520b96e26c0830238a79f84b4e17d388e1c43\nRelated-bp: #get-rid-docker-containers\nRelated-bp: #remove-centos-bootstrap-from-fuel\n""}]",0,278601,f5b1db704cee3aa08a27304f493d510e35988d87,9,6,2,12817,,,0,"Remove unused prepare_file_source function

Since fuel-bootstrap-image and fuel-docker-images were removed
from build system we don't need prepare_file_source function any
more

Change-Id: Iaf7520b96e26c0830238a79f84b4e17d388e1c43
Related-bp: #get-rid-docker-containers
Related-bp: #remove-centos-bootstrap-from-fuel
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/01/278601/1 && git format-patch -1 --stdout FETCH_HEAD,['packages/module.mk'],1,a90d8319529a34bbdec18b437b4f5fbb3ebb8853,,,"# Usage: # (eval (call prepare_file_source,package_name,file_name,source_path,optional_prerequisite)) # Note: dependencies for deb targets are also specified here to make # sure the source is ready before the build is started. define prepare_file_source ifeq ($4,) $(BUILD_DIR)/packages/sources/$1/$2: $(BUILD_DIR)/repos/repos.done else $(BUILD_DIR)/packages/sources/$1/$2: $4 endif $(BUILD_DIR)/packages/source_$1.done: $(BUILD_DIR)/packages/sources/$1/$2 $(BUILD_DIR)/packages/sources/$1/$2: $(call find-files,$3) mkdir -p $(BUILD_DIR)/packages/sources/$1 cp $3 $(BUILD_DIR)/packages/sources/$1/$2 endef ",0,16
openstack%2Frequirements~master~Icf6e1fd6b1090bdf2a7851e70d2bca0ddb2aef78,openstack/requirements,master,Icf6e1fd6b1090bdf2a7851e70d2bca0ddb2aef78,update constraint for oslo.db to new release 4.13.0,MERGED,2016-08-25 11:57:49.000000000,2016-08-29 07:29:17.000000000,2016-08-29 07:29:17.000000000,"[{'_account_id': 3}, {'_account_id': 12898}, {'_account_id': 14288}]","[{'number': 1, 'created': '2016-08-25 11:57:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/ee82589daf54a4f6588065bd8994ac56793ead2a', 'message': 'update constraint for oslo.db to new release 4.13.0\n\noslo.db 4.13.0 release\n\nChange-Id: Icf6e1fd6b1090bdf2a7851e70d2bca0ddb2aef78\nmeta:version: 4.13.0\nmeta:diff-start: -\nmeta:series: newton\nmeta:release-type: release\nmeta:announce: openstack-dev@lists.openstack.org\nmeta:pypi: yes\nmeta:first: no\nmeta:release:Author: Joshua Harlow <jxharlow@godaddy.com>\nmeta:release:Commit: Davanum Srinivas <davanum@gmail.com>\nmeta:release:Change-Id: I3c4738cb6fc0baf1e15c9bc17864a6d79a4a786b\n'}, {'number': 2, 'created': '2016-08-26 03:56:33.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/7b110dbe6f44110159622c3b891c319f0bde2838', 'message': 'update constraint for oslo.db to new release 4.13.0\n\noslo.db 4.13.0 release\n\nChange-Id: Icf6e1fd6b1090bdf2a7851e70d2bca0ddb2aef78\nmeta:version: 4.13.0\nmeta:diff-start: -\nmeta:series: newton\nmeta:release-type: release\nmeta:announce: openstack-dev@lists.openstack.org\nmeta:pypi: yes\nmeta:first: no\nmeta:release:Author: Joshua Harlow <jxharlow@godaddy.com>\nmeta:release:Commit: Davanum Srinivas <davanum@gmail.com>\nmeta:release:Change-Id: I3c4738cb6fc0baf1e15c9bc17864a6d79a4a786b\n'}]",0,360467,7b110dbe6f44110159622c3b891c319f0bde2838,16,3,2,5638,,,0,"update constraint for oslo.db to new release 4.13.0

oslo.db 4.13.0 release

Change-Id: Icf6e1fd6b1090bdf2a7851e70d2bca0ddb2aef78
meta:version: 4.13.0
meta:diff-start: -
meta:series: newton
meta:release-type: release
meta:announce: openstack-dev@lists.openstack.org
meta:pypi: yes
meta:first: no
meta:release:Author: Joshua Harlow <jxharlow@godaddy.com>
meta:release:Commit: Davanum Srinivas <davanum@gmail.com>
meta:release:Change-Id: I3c4738cb6fc0baf1e15c9bc17864a6d79a4a786b
",git fetch https://review.opendev.org/openstack/requirements refs/changes/67/360467/2 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,ee82589daf54a4f6588065bd8994ac56793ead2a,new-release,oslo.db===4.13.0,oslo.db===4.12.0,1,1
openstack%2Fneutron~master~I6eea7d4465cf23df1d8dae26336633052dfab871,openstack/neutron,master,I6eea7d4465cf23df1d8dae26336633052dfab871,Remove deprecated default subnetpools,MERGED,2016-05-26 17:29:17.000000000,2016-08-29 07:29:01.000000000,2016-08-29 07:29:01.000000000,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 5170}, {'_account_id': 6524}, {'_account_id': 6598}, {'_account_id': 6635}, {'_account_id': 6951}, {'_account_id': 7037}, {'_account_id': 7448}, {'_account_id': 7715}, {'_account_id': 9732}, {'_account_id': 9845}, {'_account_id': 10184}, {'_account_id': 10386}, {'_account_id': 10692}, {'_account_id': 14208}, {'_account_id': 14323}, {'_account_id': 14605}, {'_account_id': 14611}, {'_account_id': 15752}, {'_account_id': 16376}, {'_account_id': 17120}, {'_account_id': 19726}, {'_account_id': 20246}, {'_account_id': 22218}, {'_account_id': 22220}]","[{'number': 1, 'created': '2016-05-26 17:29:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e71c8961cc5c552a9a5d1a0b94002910356d28e1', 'message': 'Remove deprecated default subnetpools\n\nRemoves the old deprecated way of doing default subnetpools\nusing config options.\n\nChange-Id: I6eea7d4465cf23df1d8dae26336633052dfab871\n'}, {'number': 2, 'created': '2016-06-21 13:18:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/30e7b18ad4bc9a5a771827881263588e00a0bb70', 'message': 'Remove deprecated default subnetpools\n\nThese config options were deprecated in Mitaka.\nThey can now be removed in Newton.\n\nCloses-Bug: #1594810\nChange-Id: I6eea7d4465cf23df1d8dae26336633052dfab871\n'}, {'number': 3, 'created': '2016-06-27 16:13:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/f8560e7f87544658cf5436f4d008eb03236cf80c', 'message': 'Remove deprecated default subnetpools\n\nThese config options were deprecated in Mitaka.\nThey can now be removed in Newton.\n\nCloses-Bug: #1594810\nRelated-Bug: #1501328\nChange-Id: I6eea7d4465cf23df1d8dae26336633052dfab871\n'}, {'number': 4, 'created': '2016-06-29 10:50:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/ad5b7b8314e034dc3657b6f9c196a38a3928ca1d', 'message': 'Remove deprecated default subnetpools\n\nThese config options were deprecated in Mitaka.\nThey can now be removed in Newton.\n\nCloses-Bug: #1594810\nRelated-Bug: #1501328\nChange-Id: I6eea7d4465cf23df1d8dae26336633052dfab871\n'}, {'number': 5, 'created': '2016-06-29 11:15:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/fbac90eb61e2e82afb75167dcf638bf3799a6466', 'message': 'Remove deprecated default subnetpools\n\nThese config options were deprecated in Mitaka.\nThey can now be removed in Newton.\n\nDocImpact: Remove references to default_ipv4_subnet_pool and\ndefault_ipv6_subnet_pool\n\nUpgradeImpact\n\nCloses-Bug: #1594810\nRelated-Bug: #1501328\nChange-Id: I6eea7d4465cf23df1d8dae26336633052dfab871\n'}, {'number': 6, 'created': '2016-08-02 10:25:32.000000000', 'files': ['neutron/tests/unit/db/test_db_base_plugin_v2.py', 'neutron/db/db_base_plugin_v2.py', 'neutron/conf/common.py', 'releasenotes/notes/remove-subnetpool-config-b15dbe59237aee7e.yaml', 'neutron/tests/unit/extensions/test_default_subnetpools.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/f7cc6a0107bd330150e2136e5a3dac99b6b2c33d', 'message': 'Remove deprecated default subnetpools\n\nThese config options were deprecated in Mitaka.\nThey can now be removed in Newton.\n\nCloses-Bug: #1594810\nRelated-Bug: #1501328\nChange-Id: I6eea7d4465cf23df1d8dae26336633052dfab871\n'}]",3,321769,f7cc6a0107bd330150e2136e5a3dac99b6b2c33d,93,26,6,6635,,,0,"Remove deprecated default subnetpools

These config options were deprecated in Mitaka.
They can now be removed in Newton.

Closes-Bug: #1594810
Related-Bug: #1501328
Change-Id: I6eea7d4465cf23df1d8dae26336633052dfab871
",git fetch https://review.opendev.org/openstack/neutron refs/changes/69/321769/6 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/unit/db/test_db_base_plugin_v2.py', 'neutron/common/config.py', 'neutron/db/db_base_plugin_v2.py', 'neutron/tests/unit/extensions/test_default_subnetpools.py']",4,e71c8961cc5c552a9a5d1a0b94002910356d28e1,bug/1594810,," def test_create_subnet_only_ip_version_v4_old(self): # TODO(john-davidge): Remove after Mitaka release. with self.network() as network: tenant_id = network['network']['tenant_id'] subnetpool_prefix = '10.0.0.0/8' with self.subnetpool(prefixes=[subnetpool_prefix], admin=False, name=""My subnet pool"", tenant_id=tenant_id, min_prefixlen='25') as subnetpool: subnetpool_id = subnetpool['subnetpool']['id'] cfg.CONF.set_override('default_ipv4_subnet_pool', subnetpool_id) data = {'subnet': {'network_id': network['network']['id'], 'ip_version': '4', 'prefixlen': '27', 'tenant_id': tenant_id, 'use_default_subnetpool': True}} subnet_req = self.new_create_request('subnets', data) res = subnet_req.get_response(self.api) subnet = self.deserialize(self.fmt, res)['subnet'] ip_net = netaddr.IPNetwork(subnet['cidr']) self.assertIn(ip_net, netaddr.IPNetwork(subnetpool_prefix)) self.assertEqual(27, ip_net.prefixlen) self.assertEqual(subnetpool_id, subnet['subnetpool_id']) def test_create_subnet_only_ip_version_v6_old(self): # TODO(john-davidge): Remove after Mitaka release. with self.network() as network: tenant_id = network['network']['tenant_id'] subnetpool_prefix = '2000::/56' with self.subnetpool(prefixes=[subnetpool_prefix], admin=False, name=""My ipv6 subnet pool"", tenant_id=tenant_id, min_prefixlen='64') as subnetpool: subnetpool_id = subnetpool['subnetpool']['id'] cfg.CONF.set_override('default_ipv6_subnet_pool', subnetpool_id) cfg.CONF.set_override('ipv6_pd_enabled', False) data = {'subnet': {'network_id': network['network']['id'], 'ip_version': '6', 'tenant_id': tenant_id, 'use_default_subnetpool': True}} subnet_req = self.new_create_request('subnets', data) res = subnet_req.get_response(self.api) subnet = self.deserialize(self.fmt, res)['subnet'] self.assertEqual(subnetpool_id, subnet['subnetpool_id']) ip_net = netaddr.IPNetwork(subnet['cidr']) self.assertIn(ip_net, netaddr.IPNetwork(subnetpool_prefix)) self.assertEqual(64, ip_net.prefixlen) ",0,83
openstack%2Fneutron~master~I893a3b250339006f50aa003686fb95d7f2465edc,openstack/neutron,master,I893a3b250339006f50aa003686fb95d7f2465edc,Wait for ovsdb_monitor to be active before use it,MERGED,2016-05-23 09:11:35.000000000,2016-08-29 07:28:30.000000000,2016-08-29 07:28:30.000000000,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 1653}, {'_account_id': 5170}, {'_account_id': 6524}, {'_account_id': 7448}, {'_account_id': 7787}, {'_account_id': 9732}, {'_account_id': 9845}, {'_account_id': 10692}, {'_account_id': 13717}, {'_account_id': 14208}, {'_account_id': 14323}, {'_account_id': 15752}, {'_account_id': 16376}, {'_account_id': 19726}, {'_account_id': 20037}, {'_account_id': 21273}]","[{'number': 1, 'created': '2016-05-23 09:11:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/32330d55039e166c4d3e16ca9b740f0d4bc64ea7', 'message': 'Wait for ovsdb_monitor to be active before use it\n\nThere is a race between ovsdb_monitor becoming active and using\novsdb_monitor. Sometimes, code [1] will be hit at ovs-agent startup.\n\nThe fix here will block the start of ovsdb_monitor, so that the\nfollowing code to use the ovsdb_monitor will have ovsdb_monitor be\nactive.\n\n[1] https://goo.gl/RJX4I5\nCloses-bug: #1584647\n\nChange-Id: I893a3b250339006f50aa003686fb95d7f2465edc\n'}, {'number': 2, 'created': '2016-08-27 08:17:42.000000000', 'files': ['neutron/tests/unit/agent/linux/test_polling.py', 'neutron/agent/linux/polling.py', 'neutron/tests/unit/plugins/ml2/drivers/openvswitch/agent/test_ovs_neutron_agent.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/95ff46722d195eb894e79b08c5a6eb13082cc799', 'message': 'Wait for ovsdb_monitor to be active before use it\n\nThere is a race between ovsdb_monitor becoming active and using\novsdb_monitor. Sometimes, code [1] will be hit at ovs-agent startup.\n\nThe fix here will block the start of ovsdb_monitor, so that the\nfollowing code to use the ovsdb_monitor will have ovsdb_monitor be\nactive.\n\n[1] https://goo.gl/RJX4I5\nCloses-bug: #1584647\n\nChange-Id: I893a3b250339006f50aa003686fb95d7f2465edc\n'}]",0,319788,95ff46722d195eb894e79b08c5a6eb13082cc799,31,18,2,11159,,,0,"Wait for ovsdb_monitor to be active before use it

There is a race between ovsdb_monitor becoming active and using
ovsdb_monitor. Sometimes, code [1] will be hit at ovs-agent startup.

The fix here will block the start of ovsdb_monitor, so that the
following code to use the ovsdb_monitor will have ovsdb_monitor be
active.

[1] https://goo.gl/RJX4I5
Closes-bug: #1584647

Change-Id: I893a3b250339006f50aa003686fb95d7f2465edc
",git fetch https://review.opendev.org/openstack/neutron refs/changes/88/319788/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/unit/agent/linux/test_polling.py', 'neutron/agent/linux/polling.py', 'neutron/tests/unit/plugins/ml2/drivers/openvswitch/agent/test_ovs_neutron_agent.py']",3,32330d55039e166c4d3e16ca9b740f0d4bc64ea7,bug/1584647," mock.patch.object(async_process.AsyncProcess, ""is_active"", return_value=True),\ mock.patch.object(async_process.AsyncProcess, ""is_active"", return_value=True),\",,6,2
openstack%2Fneutron~master~I3c85731de6b6d07af54ace5f8d835f01a366f5b3,openstack/neutron,master,I3c85731de6b6d07af54ace5f8d835f01a366f5b3,Make addbr safe to bridge add races,MERGED,2016-08-26 23:37:17.000000000,2016-08-29 07:28:19.000000000,2016-08-29 07:28:19.000000000,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 1131}, {'_account_id': 5170}, {'_account_id': 6524}, {'_account_id': 9732}, {'_account_id': 10980}, {'_account_id': 14611}]","[{'number': 1, 'created': '2016-08-26 23:37:17.000000000', 'files': ['neutron/agent/linux/bridge_lib.py', 'neutron/tests/unit/agent/linux/test_bridge_lib.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/ab61970644086de392f12d6d6a054ca85fb6e5d7', 'message': 'Make addbr safe to bridge add races\n\nThis makes the code that constructs a bridge safe to concurrent\nadditions of the same bridge.\n\nChange-Id: I3c85731de6b6d07af54ace5f8d835f01a366f5b3\nCloses-Bug: #1617447\n'}]",0,361526,ab61970644086de392f12d6d6a054ca85fb6e5d7,21,8,1,7787,,,0,"Make addbr safe to bridge add races

This makes the code that constructs a bridge safe to concurrent
additions of the same bridge.

Change-Id: I3c85731de6b6d07af54ace5f8d835f01a366f5b3
Closes-Bug: #1617447
",git fetch https://review.opendev.org/openstack/neutron refs/changes/26/361526/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/agent/linux/bridge_lib.py', 'neutron/tests/unit/agent/linux/test_bridge_lib.py']",2,ab61970644086de392f12d6d6a054ca85fb6e5d7,bug/1617447," def test_addbr_exists(self): self.execute.side_effect = RuntimeError() with mock.patch.object(bridge_lib.BridgeDevice, 'exists', return_value=True): bridge_lib.BridgeDevice.addbr(self._BR_NAME) bridge_lib.BridgeDevice.addbr(self._BR_NAME) ",,14,1
openstack%2Fopenstack-manuals~master~I10395567a7c0b810378837665b9aa282633c9f3e,openstack/openstack-manuals,master,I10395567a7c0b810378837665b9aa282633c9f3e,[config ref] Adding token and federation info,MERGED,2016-07-19 09:58:13.000000000,2016-08-29 07:27:07.000000000,2016-08-29 07:27:07.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 5046}, {'_account_id': 7725}, {'_account_id': 9162}, {'_account_id': 9515}, {'_account_id': 10497}, {'_account_id': 10607}, {'_account_id': 10705}, {'_account_id': 10897}, {'_account_id': 14643}, {'_account_id': 14962}, {'_account_id': 17130}, {'_account_id': 19896}, {'_account_id': 21486}, {'_account_id': 22141}, {'_account_id': 22165}, {'_account_id': 22314}, {'_account_id': 23050}]","[{'number': 1, 'created': '2016-07-19 09:58:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/58df12a1e5d387b5f7ad6d0d53003e85fabb5c78', 'message': '[config ref] Adding token and federation info\n\nWIP: Federated identity section (requires SME)\n\nUpdated patch to include previous accidentally deleted file\n\nChange-Id: I10395567a7c0b810378837665b9aa282633c9f3e\nCloses-bug: #1598686\n'}, {'number': 2, 'created': '2016-07-21 12:00:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/27177e3e35c20c48667f698c2c2540a61edd5b33', 'message': '[config ref] Adding token and federation info\n\nWIP: Federated identity section (requires SME)\n\nUpdated patch to include previous accidentally deleted file\n\nChange-Id: I10395567a7c0b810378837665b9aa282633c9f3e\nCloses-bug: #1598686\n'}, {'number': 3, 'created': '2016-07-21 13:01:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/45502955c915e5869aff759949ad4b512c118bd6', 'message': '[config ref] Adding token and federation info\n\nWIP: Federated identity section (requires SME)\n\nUpdated patch to include previous accidentally deleted file\n\nChange-Id: I10395567a7c0b810378837665b9aa282633c9f3e\nCloses-bug: #1598686\n'}, {'number': 4, 'created': '2016-07-21 13:28:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/d13be3f61faebe7e7e1565074929a64b3303328f', 'message': '[config ref] Adding token and federation info\n\nWIP: Federated identity section (requires SME)\n\nUpdated patch to include previous accidentally deleted file\n\nChange-Id: I10395567a7c0b810378837665b9aa282633c9f3e\nCloses-bug: #1598686\n'}, {'number': 5, 'created': '2016-07-27 14:47:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/56392d1c417b2622d67b53d76a4e6fd8247885b6', 'message': '[config ref] Adding token and federation info\n\nWIP: Federated identity section (requires SME)\n\nUpdated patch to include previous accidentally deleted file\n\nChange-Id: I10395567a7c0b810378837665b9aa282633c9f3e\nCloses-bug: #1598686\n'}, {'number': 6, 'created': '2016-07-27 17:20:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/dc7512334e510565a5bbb1a415cec480360f1cd5', 'message': '[config ref] Adding token and federation info\n\nWIP: Federated identity section (requires SME)\n\nUpdated patch to include previous accidentally deleted file\n\nChange-Id: I10395567a7c0b810378837665b9aa282633c9f3e\nCloses-bug: #1598686\n'}, {'number': 7, 'created': '2016-07-27 19:52:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/fe5b6f45c6476e080167989ea56043f526db738e', 'message': '[config ref] Adding token and federation info\n\nWIP: Federated identity section (requires SME)\n\nUpdated patch to include previous accidentally deleted file\n\nChange-Id: I10395567a7c0b810378837665b9aa282633c9f3e\nCloses-bug: #1598686\n'}, {'number': 8, 'created': '2016-08-08 16:08:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/cbc3bcc446a87d25a21eb0c6996f87d54c3aeb1e', 'message': '[config ref] Adding token and federation info\n\nThe federated identity section (requires SME) is intended as\nbarebones until the federated identity info is updated in the\ndev docs.\n\nUpdated patch to include previous accidentally deleted file\n\nChange-Id: I10395567a7c0b810378837665b9aa282633c9f3e\nCloses-bug: #1598686\n'}, {'number': 9, 'created': '2016-08-08 22:19:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/1d55732f050f6b4e2f17db28b350cffde4a1fa4e', 'message': '[config ref] Adding token and federation info\n\nWIP: The federated identity section (requires SME) is intended as\nbarebones until the federated identity info is updated in the\ndev docs.\n\nUpdated patch to include previous accidentally deleted file\n\nChange-Id: I10395567a7c0b810378837665b9aa282633c9f3e\nCloses-bug: #1598686\n'}, {'number': 10, 'created': '2016-08-09 15:12:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/e10db7ba3b8748d191faabd8ff22b25120225d51', 'message': '[config ref] Adding token and federation info\n\nWIP: The federated identity section (requires SME) is intended as\nbarebones until the federated identity info is updated in the\ndev docs.\n\nUpdated patch to include previous accidentally deleted file\n\nChange-Id: I10395567a7c0b810378837665b9aa282633c9f3e\nCloses-bug: #1598686\n'}, {'number': 11, 'created': '2016-08-09 15:35:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/5aac98b21cc72e952c1a027c9469c3928a091686', 'message': '[config ref] Adding token and federation info\n\nWIP: The federated identity section (requires SME) is intended as\nbarebones until the federated identity info is updated in the\ndev docs.\n\nUpdated patch to include previous accidentally deleted file\n\nChange-Id: I10395567a7c0b810378837665b9aa282633c9f3e\nCloses-bug: #1598686\n'}, {'number': 12, 'created': '2016-08-09 18:48:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/8c4f95765b658170c9a686075359db0cd30a1efa', 'message': '[config ref] Adding token and federation info\n\nWIP: The federated identity section (requires SME) is intended as\nbarebones until the federated identity info is updated in the\ndev docs.\n\nUpdated patch to include previous accidentally deleted file\n\nChange-Id: I10395567a7c0b810378837665b9aa282633c9f3e\nCloses-bug: #1598686\n'}, {'number': 13, 'created': '2016-08-09 18:48:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/4184aaa1606ae96825a194a8cfe5fbb7954bbd61', 'message': '[config ref] Adding token and federation info\n\nWIP: The federated identity section\n\nUpdated patch to include previous accidentally deleted file\n\nChange-Id: I10395567a7c0b810378837665b9aa282633c9f3e\nCloses-bug: #1598686\n'}, {'number': 14, 'created': '2016-08-09 19:10:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/5372e082a94e78ab9663bebc21127ca4a7080e68', 'message': '[config ref] Adding token and federation info\n\nWIP: The federated identity section\n\nUpdated patch to include previous accidentally deleted file\n\nChange-Id: I10395567a7c0b810378837665b9aa282633c9f3e\nCloses-bug: #1598686\n'}, {'number': 15, 'created': '2016-08-09 19:35:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/c059de0b2b2368b8254bbd7e3c19914e758e0876', 'message': '[config ref] Adding token and federation info\n\nWIP: The federated identity section\n\nUpdated patch to include previous accidentally deleted file\n\nChange-Id: I10395567a7c0b810378837665b9aa282633c9f3e\nCloses-bug: #1598686\n'}, {'number': 16, 'created': '2016-08-09 20:24:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/1c2c573801d9025651b5694921969a6a3a0e553a', 'message': '[config ref] Adding token and federation info\n\nAlso updates patch to include previous accidentally deleted file\n\nChange-Id: I10395567a7c0b810378837665b9aa282633c9f3e\nCloses-bug: #1598686\n'}, {'number': 17, 'created': '2016-08-09 20:27:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/69321af4cfc664c92bf877ce4b48c706d44974e9', 'message': '[config ref] Adding token and federation info\n\nAlso updates patch to include previous accidentally deleted file\n\nChange-Id: I10395567a7c0b810378837665b9aa282633c9f3e\nCloses-bug: #1598686\n'}, {'number': 18, 'created': '2016-08-09 20:34:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/0b9dd2d3262103b8fb2cd6894cd9a33d078d0391', 'message': '[config ref] Adding token and federation info\n\nAlso updates patch to include previous accidentally deleted file\n\nChange-Id: I10395567a7c0b810378837665b9aa282633c9f3e\nCloses-bug: #1598686\n'}, {'number': 19, 'created': '2016-08-10 16:46:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/31f8fb1cce78b4804a7e9522ac203e803471735d', 'message': '[config ref] Adding token and federation info\n\nAlso updates patch to include previous accidentally deleted file\n\nChange-Id: I10395567a7c0b810378837665b9aa282633c9f3e\nCloses-bug: #1598686\n'}, {'number': 20, 'created': '2016-08-10 21:01:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/fb3c47b729ad79a2d7ae97b9ab1a5876bd251e93', 'message': '[config ref] Adding token and federation info\n\nAlso updates patch to include previous accidentally deleted file\n\nChange-Id: I10395567a7c0b810378837665b9aa282633c9f3e\nCloses-bug: #1598686\n'}, {'number': 21, 'created': '2016-08-10 22:00:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/9466b8c64f03b7f58505ae3f004ef2f2db5c2fa8', 'message': '[config ref] Adding token and federation info\n\nAlso updates patch to include previous accidentally deleted file\n\nChange-Id: I10395567a7c0b810378837665b9aa282633c9f3e\nCloses-bug: #1598686\n'}, {'number': 22, 'created': '2016-08-11 13:56:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/760133c1bdcbbaa84774a09304cf050235530f5f', 'message': '[config ref] Adding token and federation info\n\nAlso updates patch to include previous accidentally deleted file\n\nChange-Id: I10395567a7c0b810378837665b9aa282633c9f3e\nCloses-bug: #1598686\n'}, {'number': 23, 'created': '2016-08-11 15:47:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/64779f013addc9d87312b5380c143cc131bdc4b6', 'message': '[config ref] Adding token and federation info\n\nAlso updates patch to include previous accidentally deleted file\n\nChange-Id: I10395567a7c0b810378837665b9aa282633c9f3e\nCloses-bug: #1598686\n'}, {'number': 24, 'created': '2016-08-12 00:01:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/ea4b484a58eb98fce35820cf7bb84cee16d385b0', 'message': '[config ref] Adding token and federation info\n\nAlso updates patch to include previous accidentally deleted file\n\nChange-Id: I10395567a7c0b810378837665b9aa282633c9f3e\nCloses-bug: #1598686\n'}, {'number': 25, 'created': '2016-08-18 18:19:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/7dc670be2454a0466d7e55f68d5a3526fbc01ec8', 'message': '[config ref] Adding token and federation info\n\nAlso updates patch to include previous accidentally deleted file\n\nChange-Id: I10395567a7c0b810378837665b9aa282633c9f3e\nCloses-bug: #1598686\n'}, {'number': 26, 'created': '2016-08-19 08:41:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/9cd2e5351bd2f40986b980c98555d6f5c02c74a7', 'message': '[config ref] Adding token and federation info\n\nAlso updates patch to include previous accidentally deleted file\n\nChange-Id: I10395567a7c0b810378837665b9aa282633c9f3e\nCloses-bug: #1598686\n'}, {'number': 27, 'created': '2016-08-19 09:12:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/2558b3339dff5f343d78b2943e638f8cee9ab024', 'message': '[config ref] Adding token and federation info\n\nAlso updates patch to include previous accidentally deleted file\n\nChange-Id: I10395567a7c0b810378837665b9aa282633c9f3e\nCloses-bug: #1598686\n'}, {'number': 28, 'created': '2016-08-23 13:13:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/c4b1feba57e00f92237606c59a37ef3f0401ff74', 'message': '[config ref] Adding token and federation info\n\nAlso updates patch to include previous accidentally deleted file\n\nChange-Id: I10395567a7c0b810378837665b9aa282633c9f3e\nCloses-bug: #1598686\n'}, {'number': 29, 'created': '2016-08-23 13:42:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/036277461d13b21274c87e16b6e423f7c9fc953f', 'message': '[config ref] Adding token and federation info\n\nAlso updates patch to include previous accidentally deleted file\n\nChange-Id: I10395567a7c0b810378837665b9aa282633c9f3e\nCloses-bug: #1598686\n'}, {'number': 30, 'created': '2016-08-24 10:52:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/0eb0cad08bc7a01d1a2972a82ed030655edc49f9', 'message': '[config ref] Adding token and federation info\n\nAlso updates patch to include previous accidentally deleted file\n\nChange-Id: I10395567a7c0b810378837665b9aa282633c9f3e\nCloses-bug: #1598686\n'}, {'number': 31, 'created': '2016-08-25 08:22:10.000000000', 'files': ['doc/config-reference/source/identity/sample-configuration-files.rst', 'doc/config-reference/source/identity.rst', 'doc/config-reference/source/identity/figures/keystone-federation.svg', 'doc/config-reference/source/identity/federated-identity.rst', 'doc/config-reference/source/identity/figures/keystone-federation.png', 'doc/config-reference/source/identity/token-provider.rst'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/7e1ecdeaef858485d447f6e4df5082a04b00f183', 'message': '[config ref] Adding token and federation info\n\nAlso updates patch to include previous accidentally deleted file\n\nChange-Id: I10395567a7c0b810378837665b9aa282633c9f3e\nCloses-bug: #1598686\n'}]",137,344143,7e1ecdeaef858485d447f6e4df5082a04b00f183,99,19,31,10607,,,0,"[config ref] Adding token and federation info

Also updates patch to include previous accidentally deleted file

Change-Id: I10395567a7c0b810378837665b9aa282633c9f3e
Closes-bug: #1598686
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/43/344143/24 && git format-patch -1 --stdout FETCH_HEAD,"['doc/config-reference/source/identity/sample-configuration-files.rst', 'doc/config-reference/source/identity.rst', 'doc/config-reference/source/identity/federated-identity.rst', 'doc/config-reference/source/identity/token-provider.rst']",4,58df12a1e5d387b5f7ad6d0d53003e85fabb5c78,bug/1598686,"============== Token provider ============== OpenStack Identity supports customizable token providers. This is specified in the ``[token]`` section of the configuration file. Identity provides both UUID and PKI token providers. You can register your own token provider by configuring the following property: * ``provider`` - token provider driver. Defaults to ``uuid``. Implemented by :class:`keystone.token.providers.uuid.Provider` Each token format uses different technologies to achieve various performance, scaling, and architectural requirements. Below is the detailed list of the token formats: UUID UUID tokens contain randomly generated UUID4 payloads that are issued and validated by the Identity service. They must be persisted by the Identity service in order to be later validated. PKI and PKIZ PKI and PKIZ tokens contain JSON payloads that represent the entire token validation response that would normally be retrieved from keystone. You can verify PKI and PKIZ offline using the Identity service's public signing key. Both PKI and PKIZ tokens require signing certificates. For non-production environments, create self-signed certificates by using ``keystone-manage pki_setup``. For production environments, use certificates issued by a trusted certificate authority. Fernet Fernet tokens contain a limited amount of identity and authorization data in a `MessagePacked <http://msgpack.org/>`_ payload. Fernet tokens require symmetric encryption keys which can be established using ``keystone-manage fernet_setup`` and periodically rotated using ``keystone-manage fernet_rotate``. .. warning:: UUID, PKI, PKIZ, and Fernet tokens are all bearer tokens. They must be protected from unnecessary disclosure to prevent unauthorized access. ",,107,0
openstack%2Fwatcher~master~I38f2a91d2e6b24b14e1d46fd8e9a5f87ea2f3171,openstack/watcher,master,I38f2a91d2e6b24b14e1d46fd8e9a5f87ea2f3171,Remove unused LOG,MERGED,2016-08-29 01:48:13.000000000,2016-08-29 07:26:32.000000000,2016-08-29 07:26:32.000000000,"[{'_account_id': 3}, {'_account_id': 12394}]","[{'number': 1, 'created': '2016-08-29 01:48:13.000000000', 'files': ['watcher/decision_engine/goal/base.py', 'watcher/applier/rpcapi.py', 'watcher/applier/manager.py'], 'web_link': 'https://opendev.org/openstack/watcher/commit/249cd11533eb60a2955c67cf72c0b92b8acb97a8', 'message': 'Remove unused LOG\n\ndelete unused LOG in some files\n\nChange-Id: I38f2a91d2e6b24b14e1d46fd8e9a5f87ea2f3171\n'}]",0,361789,249cd11533eb60a2955c67cf72c0b92b8acb97a8,6,2,1,21387,,,0,"Remove unused LOG

delete unused LOG in some files

Change-Id: I38f2a91d2e6b24b14e1d46fd8e9a5f87ea2f3171
",git fetch https://review.opendev.org/openstack/watcher refs/changes/89/361789/1 && git format-patch -1 --stdout FETCH_HEAD,"['watcher/decision_engine/goal/base.py', 'watcher/applier/rpcapi.py', 'watcher/applier/manager.py']",3,249cd11533eb60a2955c67cf72c0b92b8acb97a8,bugFix,,from oslo_log import logLOG = log.getLogger(__name__),0,8
openstack%2Fsenlin~master~I3bed44af9b90e317a0d1d76b883182db9338d40d,openstack/senlin,master,I3bed44af9b90e317a0d1d76b883182db9338d40d,Add API tests for profile validation,MERGED,2016-08-29 01:52:07.000000000,2016-08-29 07:25:03.000000000,2016-08-29 07:25:03.000000000,"[{'_account_id': 3}, {'_account_id': 8246}, {'_account_id': 11034}, {'_account_id': 22132}]","[{'number': 1, 'created': '2016-08-29 01:52:07.000000000', 'files': ['senlin/tests/tempest/api/profiles/test_profile_validate.py'], 'web_link': 'https://opendev.org/openstack/senlin/commit/05e2b100512a9c9b06c5d7d2701867f155c5e3f0', 'message': 'Add API tests for profile validation\n\nAdd positive API tests for profile validation, add missing tests.\n\nChange-Id: I3bed44af9b90e317a0d1d76b883182db9338d40d\n'}]",0,361790,05e2b100512a9c9b06c5d7d2701867f155c5e3f0,8,4,1,7404,,,0,"Add API tests for profile validation

Add positive API tests for profile validation, add missing tests.

Change-Id: I3bed44af9b90e317a0d1d76b883182db9338d40d
",git fetch https://review.opendev.org/openstack/senlin refs/changes/90/361790/1 && git format-patch -1 --stdout FETCH_HEAD,['senlin/tests/tempest/api/profiles/test_profile_validate.py'],1,05e2b100512a9c9b06c5d7d2701867f155c5e3f0,profile_validate,"# Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. from tempest.lib import decorators from senlin.tests.tempest.api import base from senlin.tests.tempest.common import constants class TestProfileValidate(base.BaseSenlinAPITest): @decorators.idempotent_id('ff678e2d-60d0-43da-808f-cb70a3926112') def test_profile_validate(self): params = { 'profile': { 'spec': constants.spec_nova_server, } } res = self.client.validate_obj('profiles', params) # Verify resp of validate create API self.assertEqual(200, res['status']) self.assertIsNotNone(res['body']) profile = res['body'] for key in ['created_at', 'domain', 'id', 'metadata', 'name', 'project', 'spec', 'type', 'updated_at', 'user']: self.assertIn(key, profile) self.assertEqual('validated_profile', profile['name']) self.assertEqual('os.nova.server-1.0', profile['type']) self.assertEqual(constants.spec_nova_server, profile['spec']) ",,39,0
openstack%2Fsenlin~master~I0363bfd2165893b713059dc9db5ab9e632522091,openstack/senlin,master,I0363bfd2165893b713059dc9db5ab9e632522091,Add negative API tests for policy validation,MERGED,2016-08-29 03:02:14.000000000,2016-08-29 07:24:45.000000000,2016-08-29 07:24:45.000000000,"[{'_account_id': 3}, {'_account_id': 8246}, {'_account_id': 11034}]","[{'number': 1, 'created': '2016-08-29 03:02:14.000000000', 'files': ['senlin/tests/tempest/api/policies/test_policy_validate_negative.py'], 'web_link': 'https://opendev.org/openstack/senlin/commit/1c81643eaed91b4171a4e68699d930e5ef3688db', 'message': 'Add negative API tests for policy validation\n\nAdd negative API tests for policy validation\n\nChange-Id: I0363bfd2165893b713059dc9db5ab9e632522091\n'}]",0,361809,1c81643eaed91b4171a4e68699d930e5ef3688db,7,3,1,7404,,,0,"Add negative API tests for policy validation

Add negative API tests for policy validation

Change-Id: I0363bfd2165893b713059dc9db5ab9e632522091
",git fetch https://review.opendev.org/openstack/senlin refs/changes/09/361809/1 && git format-patch -1 --stdout FETCH_HEAD,['senlin/tests/tempest/api/policies/test_policy_validate_negative.py'],1,1c81643eaed91b4171a4e68699d930e5ef3688db,policy_validate_negative,"# Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import copy from tempest.lib import decorators from tempest.lib import exceptions from tempest import test from senlin.tests.tempest.api import base from senlin.tests.tempest.common import constants class TestPolicyValidateNegativeBadRequest(base.BaseSenlinAPITest): @test.attr(type=['negative']) @decorators.idempotent_id('4b55bb3e-12d6-4728-9b53-9db5094ac8b5') def test_policy_validate_with_empty_body(self): params = { } # Verify badrequest exception(400) is raised. self.assertRaises(exceptions.BadRequest, self.client.validate_obj, 'policies', params) @test.attr(type=['negative']) @decorators.idempotent_id('a1c35d93-2d19-4a72-919f-cfd70f5cbf06') def test_policy_validate_no_spec(self): params = { 'policy': { } } # Verify badrequest exception(400) is raised. self.assertRaises(exceptions.BadRequest, self.client.validate_obj, 'policies', params) @test.attr(type=['negative']) @decorators.idempotent_id('6073da36-ee3e-4925-bce1-6c9a158e710d') def test_policy_validate_policy_type_incorrect(self): spec = copy.deepcopy(constants.spec_scaling_policy) spec['type'] = 'senlin.policy.bogus' params = { 'policy': { 'spce': spec } } # Verify badrequest exception(400) is raised. self.assertRaises(exceptions.BadRequest, self.client.validate_obj, 'policies', params) @test.attr(type=['negative']) @decorators.idempotent_id('1e1833ea-4a67-4ac1-b6e2-f9afff51c945') def test_policy_validate_spec_validation_failed(self): spec = copy.deepcopy(constants.spec_scaling_policy) spec['properties']['bogus'] = 'foo' params = { 'policy': { 'spce': spec } } # Verify badrequest exception(400) is raised. self.assertRaises(exceptions.BadRequest, self.client.validate_obj, 'policies', params) ",,74,0
openstack%2Fpuppet-tripleo~master~Idaad75238a2884fe82b1e5fce3ed910d866b98a2,openstack/puppet-tripleo,master,Idaad75238a2884fe82b1e5fce3ed910d866b98a2,Add Manila CephFS backend to manila class,MERGED,2016-08-11 12:50:31.000000000,2016-08-29 07:22:32.000000000,2016-08-29 07:22:32.000000000,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 4328}, {'_account_id': 5202}, {'_account_id': 6796}]","[{'number': 1, 'created': '2016-08-11 12:50:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/d208ceb58fc26b1039798d861f81b97985961e68', 'message': 'Add Manila CephFS backend to manila class\n\nMost of the config for the backend is set in the manila base\nclass tht side.\n\nChange-Id: Idaad75238a2884fe82b1e5fce3ed910d866b98a2\n'}, {'number': 2, 'created': '2016-08-19 08:24:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/b5242f8b028555fa054732016f28468405ebaf16', 'message': 'Add Manila CephFS backend to manila class\n\nMost of the config for the backend is set in the manila base\nclass tht side.\n\nChange-Id: Idaad75238a2884fe82b1e5fce3ed910d866b98a2\n'}, {'number': 3, 'created': '2016-08-19 08:28:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/aa6b28590b8f1f2dcfde5135174829197596f7da', 'message': 'Add Manila CephFS backend to manila class\n\nMost of the config for the backend is set in the manila base\nclass tht side.\n\nChange-Id: Idaad75238a2884fe82b1e5fce3ed910d866b98a2\n'}, {'number': 4, 'created': '2016-08-19 10:31:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/800fbe23479503314663fc430c9b63b4b42233dd', 'message': 'Add Manila CephFS backend to manila class\n\nMost of the config for the backend is set in the manila base\nclass tht side.\n\nChange-Id: Idaad75238a2884fe82b1e5fce3ed910d866b98a2\n'}, {'number': 5, 'created': '2016-08-24 10:08:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/5b38fe4e793e792705aec367eb15a89298f6204d', 'message': 'Add Manila CephFS backend to manila class\n\nChange-Id: Idaad75238a2884fe82b1e5fce3ed910d866b98a2\n'}, {'number': 6, 'created': '2016-08-24 12:05:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/85ff9e6d1cc5aac70f1746491a2c4aa5d2ac0106', 'message': 'Add Manila CephFS backend to manila class\n\nChange-Id: Idaad75238a2884fe82b1e5fce3ed910d866b98a2\n'}, {'number': 7, 'created': '2016-08-25 08:27:22.000000000', 'files': ['manifests/profile/pacemaker/manila.pp'], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/4c0b08e99d0f142a5efef62abbe5581a6991a4f8', 'message': 'Add Manila CephFS backend to manila class\n\nChange-Id: Idaad75238a2884fe82b1e5fce3ed910d866b98a2\n'}]",7,354047,4c0b08e99d0f142a5efef62abbe5581a6991a4f8,37,5,7,5202,,,0,"Add Manila CephFS backend to manila class

Change-Id: Idaad75238a2884fe82b1e5fce3ed910d866b98a2
",git fetch https://review.opendev.org/openstack/puppet-tripleo refs/changes/47/354047/5 && git format-patch -1 --stdout FETCH_HEAD,['manifests/profile/pacemaker/manila.pp'],1,d208ceb58fc26b1039798d861f81b97985961e68,manila_cephfs," # manila cephfs: $manila_enable_cephfs = hiera('manila_cephfs_enable_backend', false) if $manila_enable_netapp { $manila_netapp_backend = hiera('manila::backend::cephfs::title') manila::backend::cephfs { $manila_cephfs_backend: } } $manila_enabled_backends = delete_undef_values( [ $manila_generic_backend, $manila_cephfs_backend ] )", $manila_enabled_backends = delete_undef_values([$manila_generic_backend]),13,1
openstack%2Fsenlin~master~Id3c0bc4280f1c76d4fc085ed8c292c99b4db334b,openstack/senlin,master,Id3c0bc4280f1c76d4fc085ed8c292c99b4db334b,Add API tests for policy validation,MERGED,2016-08-29 03:02:14.000000000,2016-08-29 07:21:30.000000000,2016-08-29 07:21:30.000000000,"[{'_account_id': 3}, {'_account_id': 8246}, {'_account_id': 11034}]","[{'number': 1, 'created': '2016-08-29 03:02:14.000000000', 'files': ['senlin/tests/tempest/api/policies/test_policy_validate.py'], 'web_link': 'https://opendev.org/openstack/senlin/commit/400369a4905876bc523631dfd75518a04dab069c', 'message': 'Add API tests for policy validation\n\nAdd API tests for policy validation\n\nChange-Id: Id3c0bc4280f1c76d4fc085ed8c292c99b4db334b\n'}]",0,361808,400369a4905876bc523631dfd75518a04dab069c,7,3,1,7404,,,0,"Add API tests for policy validation

Add API tests for policy validation

Change-Id: Id3c0bc4280f1c76d4fc085ed8c292c99b4db334b
",git fetch https://review.opendev.org/openstack/senlin refs/changes/08/361808/1 && git format-patch -1 --stdout FETCH_HEAD,['senlin/tests/tempest/api/policies/test_policy_validate.py'],1,400369a4905876bc523631dfd75518a04dab069c,policy_validate_negative,"# Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. from tempest.lib import decorators from senlin.tests.tempest.api import base from senlin.tests.tempest.common import constants class TestPolicyValidate(base.BaseSenlinAPITest): def setUp(self): super(TestPolicyValidate, self).setUp() self.policy_id = None @decorators.idempotent_id('a3f5ad0d-4f3d-4b40-b473-1cfc562cfcee') def test_policy_validate(self): params = { 'policy': { 'spec': constants.spec_scaling_policy, } } res = self.client.validate_obj('policies', params) # Verify resp of policy validate API self.assertEqual(200, res['status']) self.assertIsNotNone(res['body']) policy = res['body'] for key in ['created_at', 'data', 'domain', 'id', 'name', 'project', 'spec', 'type', 'updated_at', 'user']: self.assertIn(key, policy) self.assertEqual('validated_policy', policy['name']) self.assertEqual('senlin.policy.scaling-1.0', policy['type']) self.assertEqual(constants.spec_scaling_policy, policy['spec']) ",,44,0
openstack%2Fsenlin~master~Ib993710a663908676e22dd84ab042f269b7c5aa3,openstack/senlin,master,Ib993710a663908676e22dd84ab042f269b7c5aa3,Minor tweak webhook receiver,MERGED,2016-08-24 07:12:59.000000000,2016-08-29 07:12:27.000000000,2016-08-29 07:12:27.000000000,"[{'_account_id': 3}, {'_account_id': 8246}, {'_account_id': 11034}]","[{'number': 1, 'created': '2016-08-24 07:12:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/6f34a191366aedeab47ebdc044ccd3df3990c4b5', 'message': '[WIP]Minor tweak webhook receiver\n\nThis patch minor tweaks webhook receiver by changing\ninitialize_channel logic: webhook host name will first\nbe used to generate webhook url. If it is not provided\nin configuration file, engine will try to query senlin\nendpoint from keystone. If senlin endpoint can not be\nfound as well, local hostname will be used.\n\nChange-Id: Ib993710a663908676e22dd84ab042f269b7c5aa3\n'}, {'number': 2, 'created': '2016-08-24 08:09:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/a8738966b6e065ff9ad7aa99d1f658274b7f2001', 'message': 'Minor tweak webhook receiver\n\nThis patch minor tweaks webhook receiver by changing\ninitialize_channel logic: webhook host name will first\nbe used to generate webhook url. If it is not provided\nin configuration file, engine will try to query senlin\nendpoint from keystone. If senlin endpoint can not be\nfound as well, local hostname will be used.\n\nChange-Id: Ib993710a663908676e22dd84ab042f269b7c5aa3\n'}, {'number': 3, 'created': '2016-08-25 08:04:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/e07cfc7fb341cf71f90ff6663594bfcf07fcae0a', 'message': 'Minor tweak webhook receiver\n\nThis patch minor tweaks webhook receiver by changing\ninitialize_channel logic: webhook host name will first\nbe used to generate webhook url. If it is not provided\nin configuration file, engine will try to query senlin\nendpoint from keystone. If senlin endpoint can not be\nfound as well, local hostname will be used.\n\nChange-Id: Ib993710a663908676e22dd84ab042f269b7c5aa3\n'}, {'number': 4, 'created': '2016-08-26 09:41:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/e8d2780db60cb42859ecbd57780f72176224d9c0', 'message': 'Minor tweak webhook receiver\n\nThis patch minor tweaks webhook receiver by changing\ninitialize_channel logic: webhook host name will first\nbe used to generate webhook url. If it is not provided\nin configuration file, engine will try to query senlin\nendpoint from keystone. If senlin endpoint can not be\nfound as well, local hostname will be used.\n\nChange-Id: Ib993710a663908676e22dd84ab042f269b7c5aa3\n'}, {'number': 5, 'created': '2016-08-29 01:25:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/a55465f3edb41e13924058358f3f72cbcfb4153a', 'message': 'Minor tweak webhook receiver\n\nThis patch minor tweaks webhook receiver by changing\ninitialize_channel logic: webhook host name will first\nbe used to generate webhook url. If it is not provided\nin configuration file, engine will try to query senlin\nendpoint from keystone. If senlin endpoint can not be\nfound as well, local hostname will be used.\n\nChange-Id: Ib993710a663908676e22dd84ab042f269b7c5aa3\n'}, {'number': 6, 'created': '2016-08-29 02:19:24.000000000', 'files': ['senlin/drivers/openstack/keystone_v3.py', 'senlin/tests/unit/drivers/test_keystone_v3.py', 'senlin/engine/receivers/webhook.py', 'senlin/tests/unit/engine/receivers/test_webhook.py', 'senlin/common/config.py', 'senlin/engine/receivers/base.py', 'senlin/tests/unit/engine/receivers/test_receiver.py'], 'web_link': 'https://opendev.org/openstack/senlin/commit/802bb55621736c4236f7ad64a77493de0e19cc96', 'message': 'Minor tweak webhook receiver\n\nThis patch minor tweaks webhook receiver by changing\ninitialize_channel logic: webhook host name will first\nbe used to generate webhook url. If it is not provided\nin configuration file, engine will try to query senlin\nendpoint from keystone. If senlin endpoint can not be\nfound as well, local hostname will be used.\n\nChange-Id: Ib993710a663908676e22dd84ab042f269b7c5aa3\n'}]",22,359636,802bb55621736c4236f7ad64a77493de0e19cc96,29,3,6,11034,,,0,"Minor tweak webhook receiver

This patch minor tweaks webhook receiver by changing
initialize_channel logic: webhook host name will first
be used to generate webhook url. If it is not provided
in configuration file, engine will try to query senlin
endpoint from keystone. If senlin endpoint can not be
found as well, local hostname will be used.

Change-Id: Ib993710a663908676e22dd84ab042f269b7c5aa3
",git fetch https://review.opendev.org/openstack/senlin refs/changes/36/359636/6 && git format-patch -1 --stdout FETCH_HEAD,"['senlin/engine/receivers/webhook.py', 'senlin/tests/unit/engine/receivers/test_webhook.py', 'senlin/common/config.py', 'senlin/tests/unit/engine/receivers/test_receiver.py']",4,6f34a191366aedeab47ebdc044ccd3df3990c4b5,minor-tweak-webhook,"from senlin.engine.receivers import webhook as rw @mock.patch.object(rw.Webhook, 'initialize_channel') def test_receiver_create(self, mock_initialize_channel):", def test_receiver_create(self):,66,6
openstack%2Fheat~master~I143b7d1dfd3dbe1848a2af9c50224bd2934a8c37,openstack/heat,master,I143b7d1dfd3dbe1848a2af9c50224bd2934a8c37,Minor fix for senlin cluster update,MERGED,2016-08-24 09:56:34.000000000,2016-08-29 07:04:20.000000000,2016-08-29 07:04:20.000000000,"[{'_account_id': 3}, {'_account_id': 4571}, {'_account_id': 7404}, {'_account_id': 8246}, {'_account_id': 13009}, {'_account_id': 20559}]","[{'number': 1, 'created': '2016-08-24 09:56:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/a00fbd4b0c8d5b66557aded52944fdbaa58d9581', 'message': 'Minor fix for senlin cluster update\n\nUse check_action_status from senlin plugin to check status.\n\nChange-Id: I143b7d1dfd3dbe1848a2af9c50224bd2934a8c37\n'}, {'number': 2, 'created': '2016-08-26 07:09:27.000000000', 'files': ['heat/engine/resources/openstack/senlin/cluster.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/1e03e621ac040f5ce6d23d35e8096e9800f9045e', 'message': 'Minor fix for senlin cluster update\n\nUse check_action_status from senlin plugin to check status.\n\nChange-Id: I143b7d1dfd3dbe1848a2af9c50224bd2934a8c37\n'}]",0,359756,1e03e621ac040f5ce6d23d35e8096e9800f9045e,19,6,2,7404,,,0,"Minor fix for senlin cluster update

Use check_action_status from senlin plugin to check status.

Change-Id: I143b7d1dfd3dbe1848a2af9c50224bd2934a8c37
",git fetch https://review.opendev.org/openstack/heat refs/changes/56/359756/1 && git format-patch -1 --stdout FETCH_HEAD,['heat/engine/resources/openstack/senlin/cluster.py'],1,a00fbd4b0c8d5b66557aded52944fdbaa58d9581,senlin_fix_5, ret = self.client_plugin().check_action_status( updater['action']) if ret:," _ACTION_STATUS = ( ACTION_SUCCEEDED, ACTION_FAILED, ) = ( 'SUCCEEDED', 'FAILED', ) action = self.client().get_action(updater['action']) if action.status == self.ACTION_SUCCEEDED: elif action.status == self.ACTION_FAILED: raise exception.ResourceInError( status_reason=action.status_reason, resource_status=self.FAILED, )",3,13
openstack%2Ffreezer~master~Ifeaf4a4f73bb951677e4345a1c225cdaf09d61e1,openstack/freezer,master,Ifeaf4a4f73bb951677e4345a1c225cdaf09d61e1,Schedule interval start time work,ABANDONED,2016-06-29 09:12:57.000000000,2016-08-29 06:54:51.000000000,,"[{'_account_id': 3}, {'_account_id': 14101}]","[{'number': 1, 'created': '2016-06-29 09:12:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/freezer/commit/2074576b1a3550acbe64b97c3e8902baf25a048c', 'message': 'Schedule interval start time work\n\nCurrently, freezer schedule does not use schedule start time passed\nby json file.\n\nChange-Id: Ifeaf4a4f73bb951677e4345a1c225cdaf09d61e1\nCloses-Bug: #1597229\n'}, {'number': 2, 'created': '2016-06-29 13:54:18.000000000', 'files': ['freezer/scheduler/scheduler_job.py'], 'web_link': 'https://opendev.org/openstack/freezer/commit/de158c0cc20e8a69b2583ff45969b6032c9897bb', 'message': 'Schedule interval start time work\n\nCurrently, freezer schedule does not use schedule start time passed\nby json file.\n\nChange-Id: Ifeaf4a4f73bb951677e4345a1c225cdaf09d61e1\nCloses-Bug: #1597229\n'}]",0,335389,de158c0cc20e8a69b2583ff45969b6032c9897bb,7,2,2,14084,,,0,"Schedule interval start time work

Currently, freezer schedule does not use schedule start time passed
by json file.

Change-Id: Ifeaf4a4f73bb951677e4345a1c225cdaf09d61e1
Closes-Bug: #1597229
",git fetch https://review.opendev.org/openstack/freezer refs/changes/89/335389/2 && git format-patch -1 --stdout FETCH_HEAD,['freezer/scheduler/scheduler_job.py'],1,2074576b1a3550acbe64b97c3e8902baf25a048c,bug/1597229," def schedule_start_date(self): return self.job_doc['job_schedule'].get('schedule_start_date', '') @property if self.schedule_start_date: start_date = self.schedule_start_date else: start_date = datetime.datetime.now() + datetime.timedelta(0, 2, 0) kwargs.update({'start_date': start_date)"," if not self.schedule_date: kwargs.update({ 'start_date': datetime.datetime.now() + datetime.timedelta(0, 2, 0)})",10,4
openstack%2Fkarbor~master~I4250476933186ba1e02ab2786329a9cf013648d5,openstack/karbor,master,I4250476933186ba1e02ab2786329a9cf013648d5,Support only one time format for time trigger,ABANDONED,2016-08-17 07:31:53.000000000,2016-08-29 06:51:08.000000000,,"[{'_account_id': 3}, {'_account_id': 2023}, {'_account_id': 18266}, {'_account_id': 20883}, {'_account_id': 21648}]","[{'number': 1, 'created': '2016-08-17 07:31:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/karbor/commit/9eb4705754ceeaf8597b1da258137c47455ed1eb', 'message': ""Support only one time format for time trigger\n\nI find there is no need to support multiple kinds of time format\nfor time trigger at the same time, such as 'crontab', 'RFC2445'.\n'RFC2445' meets all use cases at present and we can use it instead\nof 'crontab'. If we find 'RFC2445' can not work some day, we can\nchange to another appropriate one easily by updating 'setup.cfg'.\n\nThe codes regarding to 'crontab' will be deleted in another patch,\n\nChange-Id: I4250476933186ba1e02ab2786329a9cf013648d5\nCloses-Bug: #1613577\n""}, {'number': 2, 'created': '2016-08-19 09:01:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/karbor/commit/8ce63d23825e5e0b37955188fbe32f6d74032433', 'message': ""Support only one time format for time trigger\n\nI find there is no need to support multiple kinds of time format\nfor time trigger at the same time, such as 'crontab', 'RFC2445'.\n'RFC2445' meets all use cases at present and we can use it instead\nof 'crontab'. If we find 'RFC2445' can not work some day, we can\nchange to another appropriate one easily by updating 'setup.cfg'.\n\nThe codes regarding to 'crontab' will be deleted in another patch,\n\nChange-Id: I4250476933186ba1e02ab2786329a9cf013648d5\nCloses-Bug: #1613577\n""}, {'number': 3, 'created': '2016-08-19 09:45:19.000000000', 'files': ['smaug/services/operationengine/engine/triggers/timetrigger/rrule_format.py', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/karbor/commit/96bc8323d734f182eb75b64f9e88a100da778c72', 'message': ""Support only one time format for time trigger\n\nI find there is no need to support multiple kinds of time format\nfor time trigger at the same time, such as 'crontab', 'rrule'.\n'rrule' meets all use cases at present and we can use it instead\nof 'crontab'. If we find 'rrule' can not work some day, we can\nchange to another appropriate one easily by updating 'setup.cfg'.\n\nThe codes regarding to 'crontab' will be deleted in another patch.\n\nChange-Id: I4250476933186ba1e02ab2786329a9cf013648d5\nCloses-Bug: #1613577\n""}]",5,356284,96bc8323d734f182eb75b64f9e88a100da778c72,13,5,3,18266,,,0,"Support only one time format for time trigger

I find there is no need to support multiple kinds of time format
for time trigger at the same time, such as 'crontab', 'rrule'.
'rrule' meets all use cases at present and we can use it instead
of 'crontab'. If we find 'rrule' can not work some day, we can
change to another appropriate one easily by updating 'setup.cfg'.

The codes regarding to 'crontab' will be deleted in another patch.

Change-Id: I4250476933186ba1e02ab2786329a9cf013648d5
Closes-Bug: #1613577
",git fetch https://review.opendev.org/openstack/karbor refs/changes/84/356284/2 && git format-patch -1 --stdout FETCH_HEAD,"['smaug/services/operationengine/engine/triggers/timetrigger/rfc2445.py', 'setup.cfg']",2,9eb4705754ceeaf8597b1da258137c47455ed1eb,bug/1613577,smaug.operationengine.engine.timetrigger.time_format = time_format = smaug.services.operationengine.engine.triggers.timetrigger.rfc2445.RFC2445,,50,0
openstack%2Fpython-senlinclient~master~I6eedc3e6530c471ab786bb7f9ae55149a86cfe44,openstack/python-senlinclient,master,I6eedc3e6530c471ab786bb7f9ae55149a86cfe44,Updated from global requirements,MERGED,2016-08-29 06:17:27.000000000,2016-08-29 06:47:35.000000000,2016-08-29 06:47:35.000000000,"[{'_account_id': 3}, {'_account_id': 8246}]","[{'number': 1, 'created': '2016-08-29 06:17:27.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/python-senlinclient/commit/94e6ec96450e0c75d387f3323a7a96c720d875ba', 'message': 'Updated from global requirements\n\nChange-Id: I6eedc3e6530c471ab786bb7f9ae55149a86cfe44\n'}]",0,361874,94e6ec96450e0c75d387f3323a7a96c720d875ba,6,2,1,11131,,,0,"Updated from global requirements

Change-Id: I6eedc3e6530c471ab786bb7f9ae55149a86cfe44
",git fetch https://review.opendev.org/openstack/python-senlinclient refs/changes/74/361874/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,94e6ec96450e0c75d387f3323a7a96c720d875ba,openstack/requirements,python-heatclient>=1.4.0 # Apache-2.0,python-heatclient>=1.1.0 # Apache-2.0,1,1
openstack%2Fheat~master~I9469c31de5e40334083ef1dd20243f2f6779549e,openstack/heat,master,I9469c31de5e40334083ef1dd20243f2f6779549e,Add interrupt points for convergence check-resource operations,MERGED,2016-07-15 21:03:36.000000000,2016-08-29 06:41:48.000000000,2016-08-29 06:41:48.000000000,"[{'_account_id': 3}, {'_account_id': 4257}, {'_account_id': 4571}, {'_account_id': 8833}, {'_account_id': 12259}]","[{'number': 1, 'created': '2016-07-15 21:03:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/e81d359f5793dd9812e0d2a062a0efef1771670f', 'message': ""Add interrupt points for convergence check-resource operations\n\nThis allows a convergence operation to be cancelled at an appropriate point\n(i.e. between steps in a task) by sending a message to a queue.\n\nNote that there's no code yet to actually cancel any operations\n(specifically, sending a cancel message to the stack will _not_ cause the\ncheck_resource operations to be cancelled under convergence).\n\nChange-Id: I9469c31de5e40334083ef1dd20243f2f6779549e\nRelated-Bug: #1545063\n""}, {'number': 2, 'created': '2016-07-18 20:27:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/af8ed4f95ef339f9d4e57db990fa34e514aedbae', 'message': ""Add interrupt points for convergence check-resource operations\n\nThis allows a convergence operation to be cancelled at an appropriate point\n(i.e. between steps in a task) by sending a message to a queue.\n\nNote that there's no code yet to actually cancel any operations\n(specifically, sending a cancel message to the stack will _not_ cause the\ncheck_resource operations to be cancelled under convergence).\n\nChange-Id: I9469c31de5e40334083ef1dd20243f2f6779549e\nRelated-Bug: #1545063\n""}, {'number': 3, 'created': '2016-07-19 16:34:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/92514565a1c73427beb10371648a358a814be8de', 'message': ""Add interrupt points for convergence check-resource operations\n\nThis allows a convergence operation to be cancelled at an appropriate point\n(i.e. between steps in a task) by sending a message to a queue.\n\nNote that there's no code yet to actually cancel any operations\n(specifically, sending a cancel message to the stack will _not_ cause the\ncheck_resource operations to be cancelled under convergence).\n\nChange-Id: I9469c31de5e40334083ef1dd20243f2f6779549e\nRelated-Bug: #1545063\n""}, {'number': 4, 'created': '2016-07-22 15:47:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/a8977115230d908b2a50c0bed771f650eebb6fc8', 'message': ""Add interrupt points for convergence check-resource operations\n\nThis allows a convergence operation to be cancelled at an appropriate point\n(i.e. between steps in a task) by sending a message to a queue.\n\nNote that there's no code yet to actually cancel any operations\n(specifically, sending a cancel message to the stack will _not_ cause the\ncheck_resource operations to be cancelled under convergence).\n\nChange-Id: I9469c31de5e40334083ef1dd20243f2f6779549e\nRelated-Bug: #1545063\n""}, {'number': 5, 'created': '2016-07-25 13:58:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/b7cf367dbb88aca0b5d435283e5592e9b1e55123', 'message': ""Add interrupt points for convergence check-resource operations\n\nThis allows a convergence operation to be cancelled at an appropriate point\n(i.e. between steps in a task) by sending a message to a queue.\n\nNote that there's no code yet to actually cancel any operations\n(specifically, sending a cancel message to the stack will _not_ cause the\ncheck_resource operations to be cancelled under convergence).\n\nChange-Id: I9469c31de5e40334083ef1dd20243f2f6779549e\nRelated-Bug: #1545063\n""}, {'number': 6, 'created': '2016-08-04 08:31:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/669144010a470c70c63def2ef5d86d29689665c0', 'message': ""Add interrupt points for convergence check-resource operations\n\nThis allows a convergence operation to be cancelled at an appropriate point\n(i.e. between steps in a task) by sending a message to a queue.\n\nNote that there's no code yet to actually cancel any operations\n(specifically, sending a cancel message to the stack will _not_ cause the\ncheck_resource operations to be cancelled under convergence).\n\nChange-Id: I9469c31de5e40334083ef1dd20243f2f6779549e\nRelated-Bug: #1545063\n""}, {'number': 7, 'created': '2016-08-12 11:22:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/4b54f95b024ef47b42de9427eccbebfddfa5e99e', 'message': ""Add interrupt points for convergence check-resource operations\n\nThis allows a convergence operation to be cancelled at an appropriate point\n(i.e. between steps in a task) by sending a message to a queue.\n\nNote that there's no code yet to actually cancel any operations\n(specifically, sending a cancel message to the stack will _not_ cause the\ncheck_resource operations to be cancelled under convergence).\n\nChange-Id: I9469c31de5e40334083ef1dd20243f2f6779549e\nRelated-Bug: #1545063\n""}, {'number': 8, 'created': '2016-08-16 04:44:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/38ae17b1b7d2d294aa905e99f3ca39f41bfc2a20', 'message': ""Add interrupt points for convergence check-resource operations\n\nThis allows a convergence operation to be cancelled at an appropriate point\n(i.e. between steps in a task) by sending a message to a queue.\n\nNote that there's no code yet to actually cancel any operations\n(specifically, sending a cancel message to the stack will _not_ cause the\ncheck_resource operations to be cancelled under convergence).\n\nChange-Id: I9469c31de5e40334083ef1dd20243f2f6779549e\nRelated-Bug: #1545063\n""}, {'number': 9, 'created': '2016-08-16 06:33:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/1e2a86e2b9bdf3ad6a5220739ed35a2716a8e911', 'message': ""Add interrupt points for convergence check-resource operations\n\nThis allows a convergence operation to be cancelled at an appropriate point\n(i.e. between steps in a task) by sending a message to a queue.\n\nNote that there's no code yet to actually cancel any operations\n(specifically, sending a cancel message to the stack will _not_ cause the\ncheck_resource operations to be cancelled under convergence).\n\nChange-Id: I9469c31de5e40334083ef1dd20243f2f6779549e\nRelated-Bug: #1545063\n""}, {'number': 10, 'created': '2016-08-17 04:36:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/2fa2551a75246169c1b1404905f12bfd57b7015f', 'message': ""Add interrupt points for convergence check-resource operations\n\nThis allows a convergence operation to be cancelled at an appropriate point\n(i.e. between steps in a task) by sending a message to a queue.\n\nNote that there's no code yet to actually cancel any operations\n(specifically, sending a cancel message to the stack will _not_ cause the\ncheck_resource operations to be cancelled under convergence).\n\nChange-Id: I9469c31de5e40334083ef1dd20243f2f6779549e\nRelated-Bug: #1545063\n""}, {'number': 11, 'created': '2016-08-17 04:48:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/310c06d36c3e77d03533d443c102b6c337f936d2', 'message': ""Add interrupt points for convergence check-resource operations\n\nThis allows a convergence operation to be cancelled at an appropriate point\n(i.e. between steps in a task) by sending a message to a queue.\n\nNote that there's no code yet to actually cancel any operations\n(specifically, sending a cancel message to the stack will _not_ cause the\ncheck_resource operations to be cancelled under convergence).\n\nChange-Id: I9469c31de5e40334083ef1dd20243f2f6779549e\nRelated-Bug: #1545063\nCo-Authored-By: Anant Patil <anant.patil@hpe.com>\n""}, {'number': 12, 'created': '2016-08-17 04:56:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/f1fc95317f643ee2e43ac08a2e00ac9c18e1340c', 'message': ""Add interrupt points for convergence check-resource operations\n\nThis allows a convergence operation to be cancelled at an appropriate point\n(i.e. between steps in a task) by sending a message to a queue.\n\nNote that there's no code yet to actually cancel any operations\n(specifically, sending a cancel message to the stack will _not_ cause the\ncheck_resource operations to be cancelled under convergence).\n\nChange-Id: I9469c31de5e40334083ef1dd20243f2f6779549e\nRelated-Bug: #1545063\nCo-Authored-By: Anant Patil <anant.patil@hpe.com>\n""}, {'number': 13, 'created': '2016-08-23 08:05:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/a06e4f4dff19d8fb203ed059dd0df677b11bf39f', 'message': ""Add interrupt points for convergence check-resource operations\n\nThis allows a convergence operation to be cancelled at an appropriate point\n(i.e. between steps in a task) by sending a message to a queue.\n\nNote that there's no code yet to actually cancel any operations\n(specifically, sending a cancel message to the stack will _not_ cause the\ncheck_resource operations to be cancelled under convergence).\n\nChange-Id: I9469c31de5e40334083ef1dd20243f2f6779549e\nRelated-Bug: #1545063\nCo-Authored-By: Anant Patil <anant.patil@hpe.com>\n""}, {'number': 14, 'created': '2016-08-26 11:02:45.000000000', 'files': ['heat/tests/engine/test_check_resource.py', 'heat/tests/engine/test_engine_worker.py', 'heat/engine/check_resource.py', 'heat/engine/worker.py', 'heat/engine/resource.py', 'heat/tests/test_resource.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/9c79ee4d69e9a264c90579dcaa798dc725def0c9', 'message': ""Add interrupt points for convergence check-resource operations\n\nThis allows a convergence operation to be cancelled at an appropriate point\n(i.e. between steps in a task) by sending a message to a queue.\n\nNote that there's no code yet to actually cancel any operations\n(specifically, sending a cancel message to the stack will _not_ cause the\ncheck_resource operations to be cancelled under convergence).\n\nChange-Id: I9469c31de5e40334083ef1dd20243f2f6779549e\nRelated-Bug: #1545063\nCo-Authored-By: Anant Patil <anant.patil@hpe.com>\n""}]",19,343076,9c79ee4d69e9a264c90579dcaa798dc725def0c9,61,5,14,4257,,,0,"Add interrupt points for convergence check-resource operations

This allows a convergence operation to be cancelled at an appropriate point
(i.e. between steps in a task) by sending a message to a queue.

Note that there's no code yet to actually cancel any operations
(specifically, sending a cancel message to the stack will _not_ cause the
check_resource operations to be cancelled under convergence).

Change-Id: I9469c31de5e40334083ef1dd20243f2f6779549e
Related-Bug: #1545063
Co-Authored-By: Anant Patil <anant.patil@hpe.com>
",git fetch https://review.opendev.org/openstack/heat refs/changes/76/343076/1 && git format-patch -1 --stdout FETCH_HEAD,"['heat/tests/engine/test_check_resource.py', 'heat/engine/check_resource.py', 'heat/engine/resource.py', 'heat/tests/test_resource.py']",4,e81d359f5793dd9812e0d2a062a0efef1771670f,bug/1545063," pcb = mock.Mock() 60, pcb) mock_call.assert_called_once_with(timeout=60, progress_callback=pcb) pcb = mock.Mock() new_stack, pcb) mock_call.assert_called_once_with(timeout=120, progress_callback=pcb) pcb = mock.Mock() res.delete_convergence(2, {}, 'engine-007', 20, pcb) mock_call.assert_called_once_with(timeout=20, progress_callback=pcb)"," 60) mock_call.assert_called_once_with(timeout=60) new_stack) mock_call.assert_called_once_with(timeout=120) res.delete_convergence(2, {}, 'engine-007', 20) mock_call.assert_called_once_with(timeout=20)",73,29
openstack%2Fmagnum~master~I854fb322debe9464c66a566f3b04392ebed61603,openstack/magnum,master,I854fb322debe9464c66a566f3b04392ebed61603,To use cinder with rexray downgrade to version: 0.3.3,MERGED,2016-08-26 14:29:50.000000000,2016-08-29 06:32:56.000000000,2016-08-29 06:32:56.000000000,"[{'_account_id': 3}, {'_account_id': 668}, {'_account_id': 12385}]","[{'number': 1, 'created': '2016-08-26 14:29:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/4852eb06f9ef838a60497690e0048b8825c317af', 'message': 'To use cinder with rexray downgrade to version: 0.3.3\n\n""openstack"" storageDriver is not supported in latest version of\nrexray. It is supported in stable version: 0.3.3.\nOnce it is supported: http://rexray.readthedocs.io/en/stable,\nthis commit can be reverted.\n\nChange-Id: I854fb322debe9464c66a566f3b04392ebed61603\nCloses-Bug: #1617331\n'}, {'number': 2, 'created': '2016-08-26 20:34:14.000000000', 'files': ['magnum/drivers/mesos_ubuntu_v1/templates/fragments/volume-service.sh'], 'web_link': 'https://opendev.org/openstack/magnum/commit/433eeb8d228229174f457c6bc835144070bb811f', 'message': 'To use cinder with rexray downgrade to version: 0.3.3\n\n""openstack"" storageDriver is not supported in latest version of\nrexray. It is supported in stable version: 0.3.3.\nOnce it is supported: http://rexray.readthedocs.io/en/stable,\nthis commit can be reverted.\n\nChange-Id: I854fb322debe9464c66a566f3b04392ebed61603\nCloses-Bug: #1617331\n'}]",0,361248,433eeb8d228229174f457c6bc835144070bb811f,9,3,2,13861,,,0,"To use cinder with rexray downgrade to version: 0.3.3

""openstack"" storageDriver is not supported in latest version of
rexray. It is supported in stable version: 0.3.3.
Once it is supported: http://rexray.readthedocs.io/en/stable,
this commit can be reverted.

Change-Id: I854fb322debe9464c66a566f3b04392ebed61603
Closes-Bug: #1617331
",git fetch https://review.opendev.org/openstack/magnum refs/changes/48/361248/2 && git format-patch -1 --stdout FETCH_HEAD,['magnum/drivers/mesos_ubuntu_v1/templates/fragments/volume-service.sh'],1,4852eb06f9ef838a60497690e0048b8825c317af,bug/1617331,"# NOTE(yatin): ""openstack"" storageDriver is not supported in latest version # of rexray. So use stable version 0.3.3. Once it is supported by rexray: # http://rexray.readthedocs.io/en/stable/, we can revert this commit. curl -sSL https://dl.bintray.com/emccode/rexray/install | sh - -- stable 0.3.3",curl -sSL https://dl.bintray.com/emccode/rexray/install | sh -,4,1
openstack%2Fneutron-lib~master~I144cada955783e9102e83e03961df2eabea25c7a,openstack/neutron-lib,master,I144cada955783e9102e83e03961df2eabea25c7a,Trivial DevRef Spelling corrections,MERGED,2016-08-25 04:20:09.000000000,2016-08-29 06:23:41.000000000,2016-08-29 06:23:41.000000000,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 5367}, {'_account_id': 5948}, {'_account_id': 6524}, {'_account_id': 6659}, {'_account_id': 14605}, {'_account_id': 16237}]","[{'number': 1, 'created': '2016-08-25 04:20:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-lib/commit/e0a86e511a55e87218b3b1886ceeef7244788521', 'message': 'Trivial DevRef Spelling corrections\n\nSmall nits fixed.\n\nTrivialFix\n\nChange-Id: I144cada955783e9102e83e03961df2eabea25c7a\n'}, {'number': 2, 'created': '2016-08-25 07:06:06.000000000', 'files': ['doc/source/devref/api_validators.rst'], 'web_link': 'https://opendev.org/openstack/neutron-lib/commit/bb397dfddcc1f0e2bec43ce7e521cff858aa2208', 'message': 'Trivial DevRef Spelling corrections\n\nSmall nits fixed.\n\nTrivialFix\n\nChange-Id: I144cada955783e9102e83e03961df2eabea25c7a\n'}]",0,360214,bb397dfddcc1f0e2bec43ce7e521cff858aa2208,15,8,2,17776,,,0,"Trivial DevRef Spelling corrections

Small nits fixed.

TrivialFix

Change-Id: I144cada955783e9102e83e03961df2eabea25c7a
",git fetch https://review.opendev.org/openstack/neutron-lib refs/changes/14/360214/2 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/devref/api_validators.rst'],1,e0a86e511a55e87218b3b1886ceeef7244788521,(detached,"In client code, the validator can be used in a REST API by using theHere, the validate_values() method will take the list of values as the","In client code, the valdiator can be used in a REST API by using theHere, the valdiate_values() method will take the list of values as the",2,2
openstack%2Fpython-neutronclient~master~I76b1846c62747fe7e9c6b0bd1ef40728269ed553,openstack/python-neutronclient,master,I76b1846c62747fe7e9c6b0bd1ef40728269ed553,Improve Help message of VPN Update CLI,MERGED,2016-01-22 09:01:01.000000000,2016-08-29 06:18:58.000000000,2016-08-24 20:22:59.000000000,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 841}, {'_account_id': 6659}, {'_account_id': 14605}, {'_account_id': 17211}, {'_account_id': 17776}]","[{'number': 1, 'created': '2016-01-22 09:01:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/b6a5358961c9cfeddb8d173ebe471804fb04cbc3', 'message': 'Improve Help message of VPN Update CLI\n\nThe vpn-* update CLIs do not show all possible updatable\noptions.\nThe following patch fixes the same.\n\nChange-Id: I76b1846c62747fe7e9c6b0bd1ef40728269ed553\n'}, {'number': 2, 'created': '2016-01-25 02:56:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/804eb3135a9717f151778b33f320368193a315d3', 'message': 'Improve Help message of VPN Update CLI\n\nThe vpn-* and ipsec-connection update CLIs do not\nshow all possible updatable options. With respect to\nthe information in [1], this patch introduces the updatable\noptions in the following CLIs:\n\nneutron ipsec-site-connection-update\nneutron vpn-ipsecpolicy-update\nneutron vpn-service-update\n\n[1]: https://github.com/openstack/neutron-vpnaas/blob/279416b2d8c0e77637c04211514ee55ebde4bbae/neutron_vpnaas/extensions/vpnaas.py\nChange-Id: I76b1846c62747fe7e9c6b0bd1ef40728269ed553\n'}, {'number': 3, 'created': '2016-01-25 03:03:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/80d73f66b66d40330afef6f2b91259458fce5edb', 'message': 'Improve Help message of VPN Update CLI\n\nThe vpn-* and ipsec-connection update CLIs do not\nshow all possible updatable options. With respect to\nthe information in [1], this patch introduces the updatable\noptions in the following CLIs:\n\nneutron ipsec-site-connection-update\nneutron vpn-ipsecpolicy-update\nneutron vpn-service-update\n\n[1]: https://github.com/openstack/neutron-vpnaas/blob/279416b2d8c0e77637c04211514ee55ebde4bbae/neutron_vpnaas/extensions/vpnaas.py\nDepends-On: Ib7b233e082c15d0bd6e16a754b8acad52e413986\nChange-Id: I76b1846c62747fe7e9c6b0bd1ef40728269ed553\n'}, {'number': 4, 'created': '2016-01-25 03:06:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/8a51f001b460e418502a94bc1500b85b51ac62dd', 'message': 'Improve Help message of VPN Update CLI\n\nThe vpn-* and ipsec-connection update CLIs do not\nshow all possible updatable options. With respect to\nthe information in [1], this patch introduces the updatable\noptions in the following CLIs:\n\nneutron ipsec-site-connection-update\nneutron vpn-ipsecpolicy-update\nneutron vpn-service-update\n\n[1]: https://github.com/openstack/neutron-vpnaas/blob/279416b2d8c0e77637c04211514ee55ebde4bbae/neutron_vpnaas/extensions/vpnaas.py\nDepends-On: Ib7b233e082c15d0bd6e16a754b8acad52e413986\nChange-Id: I76b1846c62747fe7e9c6b0bd1ef40728269ed553\n'}, {'number': 5, 'created': '2016-01-25 04:40:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/83b0197ffbc918ab59f492d92ee98969b0df3c04', 'message': 'Improve Help message of VPN Update CLI\n\nThe vpn-* and ipsec-connection update CLIs do not\nshow all possible updatable options. With respect to\nthe information in [1], this patch introduces the updatable\noptions in the following CLIs:\n\nneutron ipsec-site-connection-update\nneutron vpn-ipsecpolicy-update\nneutron vpn-service-update\n\n[1]: https://github.com/openstack/neutron-vpnaas/blob/279416b2d8c0e77637c04211514ee55ebde4bbae/neutron_vpnaas/extensions/vpnaas.py\nChange-Id: I76b1846c62747fe7e9c6b0bd1ef40728269ed553\n'}, {'number': 6, 'created': '2016-01-26 00:34:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/f2443177099609add8aefd1c055035b002f526c9', 'message': 'Improve Help message of VPN Update CLI\n\nThe vpn-* and ipsec-connection update CLIs do not\nshow all possible updatable options. With respect to\nthe information in [1], this patch introduces the updatable\noptions in the following CLIs:\n\nneutron ipsec-site-connection-update\nneutron vpn-ipsecpolicy-update\nneutron vpn-service-update\n\n[1]: https://github.com/openstack/neutron-vpnaas/blob/279416b2d8c0e77637c04211514ee55ebde4bbae/neutron_vpnaas/extensions/vpnaas.py\nChange-Id: I76b1846c62747fe7e9c6b0bd1ef40728269ed553\n'}, {'number': 7, 'created': '2016-01-26 01:32:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/acccad84c7faba3e1c58186523a8789bd1304527', 'message': 'Improve Help message of VPN Update CLI\n\nThe vpn-* and ipsec-connection update CLIs do not\nshow all possible updatable options. With respect to\nthe information in [1], this patch introduces the updatable\noptions in the following CLIs:\n\nneutron ipsec-site-connection-update\nneutron vpn-ipsecpolicy-update\nneutron vpn-service-update\n\n[1]: https://github.com/openstack/neutron-vpnaas/blob/279416b2d8c0e77637c04211514ee55ebde4bbae/neutron_vpnaas/extensions/vpnaas.py\nChange-Id: I76b1846c62747fe7e9c6b0bd1ef40728269ed553\n'}, {'number': 8, 'created': '2016-01-26 02:39:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/ee98b139ac9465150043e579bce3ac73e0d3441f', 'message': 'Improve Help message of VPN Update CLI\n\nThe vpn-* and ipsec-connection update CLIs do not\nshow all possible updatable options. With respect to\nthe information in [1], this patch introduces the updatable\noptions in the following CLIs:\n\nneutron ipsec-site-connection-update\nneutron vpn-ipsecpolicy-update\nneutron vpn-service-update\n\n[1]: https://github.com/openstack/neutron-vpnaas/blob/279416b2d8c0e77637c04211514ee55ebde4bbae/neutron_vpnaas/extensions/vpnaas.py\nChange-Id: I76b1846c62747fe7e9c6b0bd1ef40728269ed553\n'}, {'number': 9, 'created': '2016-02-04 04:45:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/72a543df310a61b26dea733787251805438a9860', 'message': 'Improve Help message of VPN Update CLI\n\nThe vpn-* and ipsec-connection update CLIs do not\nshow all possible updatable options. With respect to\nthe information in [1], this patch introduces the updatable\noptions in the following CLIs:\n\nneutron ipsec-site-connection-update\nneutron vpn-ipsecpolicy-update\nneutron vpn-service-update\n\n[1]: https://github.com/openstack/neutron-vpnaas/blob/279416b2d8c0e77637c04211514ee55ebde4bbae/neutron_vpnaas/extensions/vpnaas.py\nChange-Id: I76b1846c62747fe7e9c6b0bd1ef40728269ed553\n'}, {'number': 10, 'created': '2016-02-12 02:32:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/463fac5d558eaddf01385cbd9ce297aa2cf7e31c', 'message': 'Improve Help message of VPN Update CLI\n\nThe vpn-* and ipsec-connection update CLIs do not\nshow all possible updatable options. With respect to\nthe information in [1], this patch introduces the updatable\noptions in the following CLIs:\n\nneutron ipsec-site-connection-update\nneutron vpn-ipsecpolicy-update\nneutron vpn-service-update\n\n[1]: https://github.com/openstack/neutron-vpnaas/blob/279416b2d8c0e77637c04211514ee55ebde4bbae/neutron_vpnaas/extensions/vpnaas.py\nChange-Id: I76b1846c62747fe7e9c6b0bd1ef40728269ed553\n'}, {'number': 11, 'created': '2016-02-12 02:35:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/9073e88623219fb1ba251ecf1b7cf4c890c5e8b8', 'message': 'Improve Help message of VPN Update CLI\n\nThe vpn-* and ipsec-connection update CLIs do not\nshow all possible updatable options. With respect to\nthe information in [1], this patch introduces the updatable\noptions in the following CLIs:\n\nneutron ipsec-site-connection-update\nneutron vpn-ipsecpolicy-update\nneutron vpn-service-update\nneutron vpn-ikepolicy-update\n\n[1]:https://git.openstack.org/cgit/openstack/neutron-vpnaas/tree/neutron_vpnaas/extensions/vpnaas.py\nChange-Id: I76b1846c62747fe7e9c6b0bd1ef40728269ed553\n'}, {'number': 12, 'created': '2016-02-12 02:36:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/d9f61bce934d00d8436a36eaa659bb2860105bb4', 'message': 'Improve Help message of VPN Update CLI\n\nThe vpn-* and ipsec-connection update CLIs do not\nshow all possible updatable options. With respect to\nthe information in [1], this patch introduces the updatable\noptions in the following CLIs:\n\nneutron ipsec-site-connection-update\nneutron vpn-ipsecpolicy-update\nneutron vpn-service-update\nneutron vpn-ikepolicy-update\n\n[1]:https://git.openstack.org/cgit/openstack/neutron-vpnaas/tree/neutron_vpnaas/extensions/vpnaas.py\nChange-Id: I76b1846c62747fe7e9c6b0bd1ef40728269ed553\n'}, {'number': 13, 'created': '2016-02-15 00:47:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/aefeccd283274a330fc9e442ae24822605fd5d6a', 'message': 'Improve Help message of VPN Update CLI\n\nThe vpn-* and ipsec-connection update CLIs do not\nshow all possible updatable options. With respect to\nthe information in [1], this patch introduces the updatable\noptions in the following CLIs:\n\nneutron ipsec-site-connection-update\nneutron vpn-ipsecpolicy-update\nneutron vpn-service-update\nneutron vpn-ikepolicy-update\n\n[1]:https://git.openstack.org/cgit/openstack/neutron-vpnaas/tree/neutron_vpnaas/extensions/vpnaas.py\nChange-Id: I76b1846c62747fe7e9c6b0bd1ef40728269ed553\n'}, {'number': 14, 'created': '2016-02-22 09:01:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/d8ea33148981d42f7fd89a71c5a4aab946c0db72', 'message': 'Improve Help message of VPN Update CLI\n\nThe vpn-* and ipsec-connection update CLIs do not\nshow all possible updatable options. With respect to\nthe information in [1], this patch introduces the updatable\noptions in the following CLIs:\n\nneutron ipsec-site-connection-update\nneutron vpn-ipsecpolicy-update\nneutron vpn-service-update\nneutron vpn-ikepolicy-update\n\n[1]:https://git.openstack.org/cgit/openstack/neutron-vpnaas/tree/neutron_vpnaas/extensions/vpnaas.py\nChange-Id: I76b1846c62747fe7e9c6b0bd1ef40728269ed553\n'}, {'number': 15, 'created': '2016-03-01 03:17:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/ffc7b882d2fdfa8fe92ee342f8280b5e59b57f56', 'message': 'Improve Help message of VPN Update CLI\n\nThe vpn-* and ipsec-connection update CLIs do not\nshow all possible updatable options. With respect to\nthe information in [1], this patch introduces the updatable\noptions in the following CLIs:\n\nneutron ipsec-site-connection-update\nneutron vpn-ipsecpolicy-update\nneutron vpn-service-update\nneutron vpn-ikepolicy-update\n\n[1]:https://git.openstack.org/cgit/openstack/neutron-vpnaas/tree/neutron_vpnaas/extensions/vpnaas.py\nChange-Id: I76b1846c62747fe7e9c6b0bd1ef40728269ed553\n'}, {'number': 16, 'created': '2016-03-01 04:57:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/071c969c0a09fb41fcd6b9681bb2a262c6a97869', 'message': 'Improve Help message of VPN Update CLI\n\nThe vpn-* and ipsec-connection update CLIs do not\nshow all possible updatable options. With respect to\nthe information in [1], this patch introduces the updatable\noptions in the following CLIs:\n\nneutron ipsec-site-connection-update\nneutron vpn-ipsecpolicy-update\nneutron vpn-service-update\nneutron vpn-ikepolicy-update\n\n[1]:https://git.openstack.org/cgit/openstack/neutron-vpnaas/tree/neutron_vpnaas/extensions/vpnaas.py\nChange-Id: I76b1846c62747fe7e9c6b0bd1ef40728269ed553\n'}, {'number': 17, 'created': '2016-03-01 05:10:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/ce365c3bd29aac5d184952abe8a37eb136b6c9e4', 'message': 'Improve Help message of VPN Update CLI\n\nThe vpn-* and ipsec-connection update CLIs do not\nshow all possible updatable options. With respect to\nthe information in [1], this patch introduces the updatable\noptions in the following CLIs:\n\nneutron ipsec-site-connection-update\nneutron vpn-ipsecpolicy-update\nneutron vpn-service-update\nneutron vpn-ikepolicy-update\n\n[1]:https://git.openstack.org/cgit/openstack/neutron-vpnaas/tree/neutron_vpnaas/extensions/vpnaas.py\nChange-Id: I76b1846c62747fe7e9c6b0bd1ef40728269ed553\n'}, {'number': 18, 'created': '2016-03-08 08:22:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/cc21ac4284799e74e61b456849a62b345a02cded', 'message': 'Improve Help message of VPN Update CLI\n\nThe vpn-* and ipsec-connection update CLIs do not\nshow all possible updatable options. With respect to\nthe information in [1], this patch introduces the updatable\noptions in the following CLIs:\n\nneutron ipsec-site-connection-update\nneutron vpn-ipsecpolicy-update\nneutron vpn-service-update\nneutron vpn-ikepolicy-update\n\n[1]:https://git.openstack.org/cgit/openstack/neutron-vpnaas/tree/neutron_vpnaas/extensions/vpnaas.py\nChange-Id: I76b1846c62747fe7e9c6b0bd1ef40728269ed553\n'}, {'number': 19, 'created': '2016-03-16 22:05:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/4bba350ad4a8dc8e553bcb12a6f4d090b9277c64', 'message': 'Improve Help message of VPN Update CLI\n\nThe vpn-* and ipsec-connection update CLIs do not\nshow all possible updatable options. With respect to\nthe information in [1], this patch introduces the updatable\noptions in the following CLIs:\n\nneutron ipsec-site-connection-update\nneutron vpn-ipsecpolicy-update\nneutron vpn-service-update\nneutron vpn-ikepolicy-update\n\n[1]:https://git.openstack.org/cgit/openstack/neutron-vpnaas/tree/neutron_vpnaas/extensions/vpnaas.py\nChange-Id: I76b1846c62747fe7e9c6b0bd1ef40728269ed553\n'}, {'number': 20, 'created': '2016-03-22 01:21:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/377e99edfb4e0561d536db1930ec87551b06bd45', 'message': 'Improve Help message of VPN Update CLI\n\nThe vpn-* and ipsec-connection update CLIs do not\nshow all possible updatable options. With respect to\nthe information in [1], this patch introduces the updatable\noptions in the following CLIs:\n\nneutron ipsec-site-connection-update\nneutron vpn-ipsecpolicy-update\nneutron vpn-service-update\nneutron vpn-ikepolicy-update\n\n[1]:https://git.openstack.org/cgit/openstack/neutron-vpnaas/tree/neutron_vpnaas/extensions/vpnaas.py\nChange-Id: I76b1846c62747fe7e9c6b0bd1ef40728269ed553\n'}, {'number': 21, 'created': '2016-04-11 07:06:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/bf316a0cb19bb034d55d15fa0d10b4e099e0c9cb', 'message': 'Improve Help message of VPN Update CLI\n\nThe vpn-* and ipsec-connection update CLIs do not\nshow all possible updatable options. With respect to\nthe information in [1], this patch introduces the updatable\noptions in the following CLIs:\n\nneutron ipsec-site-connection-update\nneutron vpn-ipsecpolicy-update\nneutron vpn-service-update\nneutron vpn-ikepolicy-update\n\n[1]:https://git.openstack.org/cgit/openstack/neutron-vpnaas/tree/neutron_vpnaas/extensions/vpnaas.py\nChange-Id: I76b1846c62747fe7e9c6b0bd1ef40728269ed553\n'}, {'number': 22, 'created': '2016-04-18 00:34:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/6de5387db5a3b86084e3f73eb4c76dd24dfdb473', 'message': 'Improve Help message of VPN Update CLI\n\nThe vpn-* and ipsec-connection update CLIs do not\nshow all possible updatable options. With respect to\nthe information in [1], this patch introduces the updatable\noptions in the following CLIs:\n\nneutron ipsec-site-connection-update\nneutron vpn-ipsecpolicy-update\nneutron vpn-service-update\nneutron vpn-ikepolicy-update\n\n[1]:https://git.openstack.org/cgit/openstack/neutron-vpnaas/tree/neutron_vpnaas/extensions/vpnaas.py\nChange-Id: I76b1846c62747fe7e9c6b0bd1ef40728269ed553\n'}, {'number': 23, 'created': '2016-05-13 09:44:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/5680d822cb4ba03f925673f0885310d6f8bf2b74', 'message': 'Improve Help message of VPN Update CLI\n\nThe vpn-* and ipsec-connection update CLIs do not\nshow all possible updatable options. With respect to\nthe information in [1], this patch introduces the updatable\noptions in the following CLIs:\n\nneutron ipsec-site-connection-update\nneutron vpn-ipsecpolicy-update\nneutron vpn-service-update\nneutron vpn-ikepolicy-update\n\n[1]:https://git.openstack.org/cgit/openstack/neutron-vpnaas/tree/neutron_vpnaas/extensions/vpnaas.py\nChange-Id: I76b1846c62747fe7e9c6b0bd1ef40728269ed553\n'}, {'number': 24, 'created': '2016-05-17 06:17:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/50cbdebd759bc6c0f9495981679627c606e0f516', 'message': 'Improve Help message of VPN Update CLI\n\nThe vpn-* and ipsec-connection update CLIs do not\nshow all possible updatable options. With respect to\nthe information in [1], this patch introduces the updatable\noptions in the following CLIs:\n\nneutron ipsec-site-connection-update\nneutron vpn-ipsecpolicy-update\nneutron vpn-service-update\nneutron vpn-ikepolicy-update\n\n[1]:https://git.openstack.org/cgit/openstack/neutron-vpnaas/tree/neutron_vpnaas/extensions/vpnaas.py\nChange-Id: I76b1846c62747fe7e9c6b0bd1ef40728269ed553\n'}, {'number': 25, 'created': '2016-05-18 06:06:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/8a63e1265eb6f9f21cae2be3bc7dce6037d98cd4', 'message': 'Improve Help message of VPN Update CLI\n\nThe vpn-* and ipsec-connection update CLIs do not\nshow all possible updatable options. With respect to\nthe information in [1], this patch introduces the updatable\noptions in the following CLIs:\n\nneutron ipsec-site-connection-update\nneutron vpn-ipsecpolicy-update\nneutron vpn-service-update\nneutron vpn-ikepolicy-update\n\n[1]:https://git.openstack.org/cgit/openstack/neutron-vpnaas/tree/neutron_vpnaas/extensions/vpnaas.py\nChange-Id: I76b1846c62747fe7e9c6b0bd1ef40728269ed553\n'}, {'number': 26, 'created': '2016-06-14 09:39:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/d2166c26766aacb41b6dab711b1bcc92d545b8df', 'message': 'Improve Help message of VPN Update CLI\n\nThe vpn-* and ipsec-connection update CLIs do not\nshow all possible updatable options. With respect to\nthe information in [1], this patch introduces the updatable\noptions in the following CLIs:\n\nneutron ipsec-site-connection-update\nneutron vpn-ipsecpolicy-update\nneutron vpn-service-update\nneutron vpn-ikepolicy-update\n\n[1]:https://git.openstack.org/cgit/openstack/neutron-vpnaas/tree/neutron_vpnaas/extensions/vpnaas.py\nChange-Id: I76b1846c62747fe7e9c6b0bd1ef40728269ed553\n'}, {'number': 27, 'created': '2016-07-01 04:23:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/3cb368edc79a868d43d61556f0d2ce9692657c1f', 'message': 'Improve Help message of VPN Update CLI\n\nThe vpn-* and ipsec-connection update CLIs do not\nshow all possible updatable options. With respect to\nthe information in [1], this patch introduces the updatable\noptions in the following CLIs:\n\nneutron ipsec-site-connection-update\nneutron vpn-ipsecpolicy-update\nneutron vpn-service-update\nneutron vpn-ikepolicy-update\n\n[1]:https://git.openstack.org/cgit/openstack/neutron-vpnaas/tree/neutron_vpnaas/extensions/vpnaas.py\nChange-Id: I76b1846c62747fe7e9c6b0bd1ef40728269ed553\n'}, {'number': 28, 'created': '2016-08-16 06:45:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/8bb1491e9c7ed18c9048b9f84e036db8d1ea34d3', 'message': 'Improve Help message of VPN Update CLI\n\nThe vpn-* and ipsec-connection update CLIs do not\nshow all possible updatable options. With respect to\nthe information in [1], this patch introduces the updatable\noptions in the following CLIs:\n\nneutron ipsec-site-connection-update\nneutron vpn-ipsecpolicy-update\nneutron vpn-service-update\nneutron vpn-ikepolicy-update\n\n[1]:https://git.openstack.org/cgit/openstack/neutron-vpnaas/tree/neutron_vpnaas/extensions/vpnaas.py\nChange-Id: I76b1846c62747fe7e9c6b0bd1ef40728269ed553\n'}, {'number': 29, 'created': '2016-08-16 06:52:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/c8b9682618ee5f956fe8d3464d662f20b6e47853', 'message': 'Improve Help message of VPN Update CLI\n\nThe vpn-* and ipsec-connection update CLIs do not\nshow all possible updatable options. With respect to\nthe information in [1], this patch introduces the updatable\noptions in the following CLIs:\n\nneutron ipsec-site-connection-update\nneutron vpn-ipsecpolicy-update\nneutron vpn-service-update\nneutron vpn-ikepolicy-update\n\n[1]:https://git.openstack.org/cgit/openstack/neutron-vpnaas/tree/neutron_vpnaas/extensions/vpnaas.py\nChange-Id: I76b1846c62747fe7e9c6b0bd1ef40728269ed553\n'}, {'number': 30, 'created': '2016-08-20 07:05:40.000000000', 'files': ['neutronclient/tests/unit/vpn/test_cli20_vpnservice.py', 'neutronclient/tests/unit/vpn/test_cli20_ikepolicy.py', 'neutronclient/neutron/v2_0/vpn/vpnservice.py', 'neutronclient/tests/unit/vpn/test_cli20_ipsec_site_connection.py', 'neutronclient/tests/unit/vpn/test_cli20_ipsecpolicy.py', 'neutronclient/neutron/v2_0/vpn/ipsecpolicy.py', 'neutronclient/neutron/v2_0/vpn/ipsec_site_connection.py', 'neutronclient/neutron/v2_0/vpn/ikepolicy.py'], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/629393090b311ad7878ed3d9c21ed1fc938a71f1', 'message': 'Improve Help message of VPN Update CLI\n\nThe vpn-* and ipsec-connection update CLIs do not\nshow all possible updatable options. With respect to\nthe information in [1], this patch introduces the updatable\noptions in the following CLIs:\n\nneutron ipsec-site-connection-update\nneutron vpn-ipsecpolicy-update\nneutron vpn-service-update\nneutron vpn-ikepolicy-update\n\n[1]:https://git.openstack.org/cgit/openstack/neutron-vpnaas/tree/neutron_vpnaas/extensions/vpnaas.py\nChange-Id: I76b1846c62747fe7e9c6b0bd1ef40728269ed553\n'}]",17,271191,629393090b311ad7878ed3d9c21ed1fc938a71f1,95,7,30,17776,,,0,"Improve Help message of VPN Update CLI

The vpn-* and ipsec-connection update CLIs do not
show all possible updatable options. With respect to
the information in [1], this patch introduces the updatable
options in the following CLIs:

neutron ipsec-site-connection-update
neutron vpn-ipsecpolicy-update
neutron vpn-service-update
neutron vpn-ikepolicy-update

[1]:https://git.openstack.org/cgit/openstack/neutron-vpnaas/tree/neutron_vpnaas/extensions/vpnaas.py
Change-Id: I76b1846c62747fe7e9c6b0bd1ef40728269ed553
",git fetch https://review.opendev.org/openstack/python-neutronclient refs/changes/91/271191/15 && git format-patch -1 --stdout FETCH_HEAD,['neutronclient/neutron/v2_0/vpn/vpnservice.py'],1,b6a5358961c9cfeddb8d173ebe471804fb04cbc3,improve-help-msg,"from neutronclient.common import utilsdef add_common_args(parser): parser.add_argument( '--name', help=_('Set a name for the VPN service.')) parser.add_argument( '--description', help=_('Set a description for the VPN service.')) def common_args2body(parsed_args, body): neutronv20.update_dict(parsed_args, body, ['name', 'description']) add_common_args(parser) ['tenant_id']) common_args2body(parsed_args, body) def add_known_arguments(self, parser): add_common_args(parser) utils.add_boolean_argument( parser, '--admin-state-up', help=_('Update the admin state for the firewall' '(True means UP)')) def args2body(self, parsed_args): body = {} common_args2body(parsed_args, body) neutronv20.update_dict(parsed_args, body, ['admin_state_up']) return {self.resource: body} "," '--name', help=_('Set a name for the VPN service.')) parser.add_argument( '--description', help=_('Set a description for the VPN service.')) parser.add_argument( ['name', 'description', 'tenant_id']) ",32,9
openstack%2Fheat~master~I6a9c89a23160a2cf06c37677871bcfbfab9599be,openstack/heat,master,I6a9c89a23160a2cf06c37677871bcfbfab9599be,Provides 'not' condition function,MERGED,2016-07-27 07:02:31.000000000,2016-08-29 06:18:18.000000000,2016-08-29 06:18:18.000000000,"[{'_account_id': 3}, {'_account_id': 4257}, {'_account_id': 4571}, {'_account_id': 7385}, {'_account_id': 8289}, {'_account_id': 8833}, {'_account_id': 10487}, {'_account_id': 12363}, {'_account_id': 13009}, {'_account_id': 20559}]","[{'number': 1, 'created': '2016-07-27 07:02:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/6f8c372f340c0c0a0d492fca54b48a4285bdd665', 'message': ""Provides 'not' condition function\n\nSupport 'not' and 'Fn::Not' for templates:\nAWSTemplateFormatVersion.2010-09-09\nheat_template_version.2016-10-14\n\nChange-Id: I6a9c89a23160a2cf06c37677871bcfbfab9599be\nBlueprint: support-conditions-function\n""}, {'number': 2, 'created': '2016-07-27 09:50:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/6cd6e21fd55600488ff1f36c0f639d55cc68b734', 'message': ""Provides 'not' condition function\n\nSupport 'not' and 'Fn::Not' for templates:\nAWSTemplateFormatVersion.2010-09-09\nheat_template_version.2016-10-14\n\nChange-Id: I6a9c89a23160a2cf06c37677871bcfbfab9599be\nBlueprint: support-conditions-function\n""}, {'number': 3, 'created': '2016-07-28 02:27:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/8d71d27284a9102408367126b7bcc7995763dc88', 'message': ""Provides 'not' condition function\n\nSupport 'not' and 'Fn::Not' for templates:\nAWSTemplateFormatVersion.2010-09-09\nheat_template_version.2016-10-14\n\nChange-Id: I6a9c89a23160a2cf06c37677871bcfbfab9599be\nBlueprint: support-conditions-function\n""}, {'number': 4, 'created': '2016-07-28 05:22:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/e22a0bd505b3a24a48f5134ebd2e7ef5f4a26c96', 'message': ""Provides 'not' condition function\n\nSupport 'not' and 'Fn::Not' for templates:\nAWSTemplateFormatVersion.2010-09-09\nheat_template_version.2016-10-14\n\nChange-Id: I6a9c89a23160a2cf06c37677871bcfbfab9599be\nBlueprint: support-conditions-function\n""}, {'number': 5, 'created': '2016-08-03 07:18:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/2aad00f650d7f2d135f4e34408e6194505ec0d5b', 'message': ""Provides 'not' condition function\n\nSupport 'not' and 'Fn::Not' for templates:\nAWSTemplateFormatVersion.2010-09-09\nheat_template_version.2016-10-14\n\nChange-Id: I6a9c89a23160a2cf06c37677871bcfbfab9599be\nBlueprint: support-conditions-function\n""}, {'number': 6, 'created': '2016-08-04 03:49:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/b84b4e14159def45d2baff21cfc7f11f096bfc60', 'message': ""Provides 'not' condition function\n\nSupport 'not' and 'Fn::Not' for templates:\nAWSTemplateFormatVersion.2010-09-09\nheat_template_version.2016-10-14\n\nChange-Id: I6a9c89a23160a2cf06c37677871bcfbfab9599be\nBlueprint: support-conditions-function\n""}, {'number': 7, 'created': '2016-08-11 09:16:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/a4d1743e11c695a2a9ba5d64e9ec3b71cbc7c914', 'message': ""Provides 'not' condition function\n\nSupport 'not' and 'Fn::Not' for templates:\nAWSTemplateFormatVersion.2010-09-09\nheat_template_version.2016-10-14\n\nChange-Id: I6a9c89a23160a2cf06c37677871bcfbfab9599be\nBlueprint: support-conditions-function\n""}, {'number': 8, 'created': '2016-08-12 08:36:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/3e9bbf7bc5e3567e2b194b900730ad8743adc88d', 'message': ""Provides 'not' condition function\n\nSupport 'not' and 'Fn::Not' for templates:\nAWSTemplateFormatVersion.2010-09-09\nheat_template_version.2016-10-14\n\nChange-Id: I6a9c89a23160a2cf06c37677871bcfbfab9599be\nBlueprint: support-conditions-function\n""}, {'number': 9, 'created': '2016-08-22 07:24:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/2378b8e0d4fca9613ed02798e256e0f1265102ef', 'message': ""Provides 'not' condition function\n\nSupport 'not' and 'Fn::Not' for templates:\nAWSTemplateFormatVersion.2010-09-09\nheat_template_version.2016-10-14\n\nChange-Id: I6a9c89a23160a2cf06c37677871bcfbfab9599be\nBlueprint: support-conditions-function\n""}, {'number': 10, 'created': '2016-08-22 07:59:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/d3d18f182af7b6458800bc93895308e4c1b82ee8', 'message': ""Provides 'not' condition function\n\nSupport 'not' and 'Fn::Not' for templates:\nAWSTemplateFormatVersion.2010-09-09\nheat_template_version.2016-10-14\n\nChange-Id: I6a9c89a23160a2cf06c37677871bcfbfab9599be\nBlueprint: support-conditions-function\n""}, {'number': 11, 'created': '2016-08-23 04:02:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/61e0eb195bc0983dac0c2fab3321a31b3eb65a9f', 'message': ""Provides 'not' condition function\n\nSupport 'not' and 'Fn::Not' for templates:\nAWSTemplateFormatVersion.2010-09-09\nheat_template_version.2016-10-14\n\nChange-Id: I6a9c89a23160a2cf06c37677871bcfbfab9599be\nBlueprint: support-conditions-function\n""}, {'number': 12, 'created': '2016-08-24 03:06:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/7184cb7153778edec7b3452c60dc69ef32134021', 'message': ""Provides 'not' condition function\n\nSupport 'not' and 'Fn::Not' for templates:\nAWSTemplateFormatVersion.2010-09-09\nheat_template_version.2016-10-14\n\nChange-Id: I6a9c89a23160a2cf06c37677871bcfbfab9599be\nBlueprint: support-conditions-function\n""}, {'number': 13, 'created': '2016-08-25 01:14:34.000000000', 'files': ['heat/engine/hot/functions.py', 'doc/source/template_guide/hot_spec.rst', 'heat/engine/cfn/template.py', 'heat/tests/test_template.py', 'heat/engine/cfn/functions.py', 'heat/engine/hot/template.py', 'doc/source/template_guide/functions.rst', 'heat_integrationtests/functional/test_conditions.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/aeb15bf818cecf6a1a8a2719ea869b67ec8a93ce', 'message': ""Provides 'not' condition function\n\nSupport 'not' and 'Fn::Not' for templates:\nAWSTemplateFormatVersion.2010-09-09\nheat_template_version.2016-10-14\n\nChange-Id: I6a9c89a23160a2cf06c37677871bcfbfab9599be\nBlueprint: support-conditions-function\n""}]",23,347655,aeb15bf818cecf6a1a8a2719ea869b67ec8a93ce,46,10,13,8289,,,0,"Provides 'not' condition function

Support 'not' and 'Fn::Not' for templates:
AWSTemplateFormatVersion.2010-09-09
heat_template_version.2016-10-14

Change-Id: I6a9c89a23160a2cf06c37677871bcfbfab9599be
Blueprint: support-conditions-function
",git fetch https://review.opendev.org/openstack/heat refs/changes/55/347655/13 && git format-patch -1 --stdout FETCH_HEAD,"['heat/engine/hot/functions.py', 'doc/source/template_guide/hot_spec.rst', 'heat/engine/cfn/template.py', 'heat/tests/test_template.py', 'heat/engine/hot/template.py', 'doc/source/template_guide/functions.rst', 'heat_integrationtests/functional/test_conditions.py']",7,6f8c372f340c0c0a0d492fca54b48a4285bdd665,bp/support-conditions-function," Test: {'Fn::Not': [{""Fn::Equals"" : [{Ref: env_type}, ""prod""]}]} test_res: Type: OS::Heat::TestResource Properties: value: just in test env Condition: Test test_res_value: Value: {""Fn::If"": [Test, {""Fn::GetAtt"": [test_res, output]}, 'no_test_res']} test: {not: [{equals : [{get_param: env_type}, ""prod""]}]} test_res: type: OS::Heat::TestResource properties: value: just in test env condition: test test_res_value: value: {if: [test, {get_attr: [test_res, output]}, 'no_test_res']} self.assertEqual(4, len(resources)) self.assertEqual('test_res', res_names) test_res_output = self.client.stacks.output_show( stack_id, 'test_res')['output'] self.assertNotEqual('no_test_res', test_res_output['output_value']) test_res_output = self.client.stacks.output_show( stack_id, 'test_res')['output'] self.assertNotEqual('just in test env', test_res_output['output_value']) "," self.assertEqual(3, len(resources))",174,2
openstack%2Fpython-solumclient~master~I6a0baa61aeb8c4a784f08a2ad7147d85db468d6d,openstack/python-solumclient,master,I6a0baa61aeb8c4a784f08a2ad7147d85db468d6d,Remove white space between print and (),ABANDONED,2016-07-05 07:16:51.000000000,2016-08-29 06:03:46.000000000,,"[{'_account_id': 3}, {'_account_id': 2506}, {'_account_id': 7764}]","[{'number': 1, 'created': '2016-07-05 07:16:51.000000000', 'files': ['solumclient/openstack/common/cliutils.py'], 'web_link': 'https://opendev.org/openstack/python-solumclient/commit/1cd16ba21a172caee2307db75aeecf1ffe268e11', 'message': 'Remove white space between print and ()\n\nTrivialFix\n\nChange-Id: I6a0baa61aeb8c4a784f08a2ad7147d85db468d6d\n'}]",0,337486,1cd16ba21a172caee2307db75aeecf1ffe268e11,5,3,1,20146,,,0,"Remove white space between print and ()

TrivialFix

Change-Id: I6a0baa61aeb8c4a784f08a2ad7147d85db468d6d
",git fetch https://review.opendev.org/openstack/python-solumclient refs/changes/86/337486/1 && git format-patch -1 --stdout FETCH_HEAD,['solumclient/openstack/common/cliutils.py'],1,1cd16ba21a172caee2307db75aeecf1ffe268e11,del_space," print(msg, file=sys.stderr)"," print (msg, file=sys.stderr)",1,1
openstack%2Fcinder~master~I0bc2f73a8b50f2b2247531df200c07b4eeb02bf7,openstack/cinder,master,I0bc2f73a8b50f2b2247531df200c07b4eeb02bf7,VMware: Add volume name in vCenter to conn info,MERGED,2016-07-19 07:25:57.000000000,2016-08-29 05:59:22.000000000,2016-08-27 18:54:23.000000000,"[{'_account_id': 3}, {'_account_id': 6491}, {'_account_id': 9008}, {'_account_id': 9171}, {'_account_id': 9535}, {'_account_id': 9732}, {'_account_id': 10058}, {'_account_id': 10210}, {'_account_id': 10621}, {'_account_id': 12032}, {'_account_id': 12033}, {'_account_id': 12369}, {'_account_id': 12778}, {'_account_id': 12822}, {'_account_id': 13394}, {'_account_id': 13628}, {'_account_id': 14259}, {'_account_id': 14305}, {'_account_id': 14384}, {'_account_id': 14732}, {'_account_id': 14797}, {'_account_id': 15249}, {'_account_id': 15296}, {'_account_id': 15374}, {'_account_id': 15386}, {'_account_id': 15831}, {'_account_id': 15941}, {'_account_id': 16269}, {'_account_id': 16419}, {'_account_id': 16595}, {'_account_id': 16660}, {'_account_id': 16862}, {'_account_id': 16880}, {'_account_id': 16883}, {'_account_id': 16897}, {'_account_id': 16898}, {'_account_id': 16941}, {'_account_id': 17852}, {'_account_id': 18120}, {'_account_id': 18402}, {'_account_id': 19852}, {'_account_id': 19933}, {'_account_id': 21976}, {'_account_id': 22501}, {'_account_id': 22510}, {'_account_id': 22804}]","[{'number': 1, 'created': '2016-07-19 07:25:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/a49d04f4f927eeb82b774b9e3f566a50cc415f30', 'message': 'VMware: Add volume name in vCenter to conn info\n\nThe VMware Nova driver uses the volume reference in vCenter\nwhich is passed in the connection info to identify the volume\nduring attach and detach. If the vCenter inventory is restored\nfrom a backup using backup solutions such as HP data protector,\nthe volume reference in vCenter may change, but the volume name\n(in vCenter) remains the same. This patch adds the volume name\nin vCenter to the connection info so that the VMware Nova driver\ncan use it to identify the volume during detach as a fallback\noption.\n\nChange-Id: I0bc2f73a8b50f2b2247531df200c07b4eeb02bf7\nPartial-bug: #1593742\n'}, {'number': 2, 'created': '2016-07-27 13:40:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/03077406a0cd6b6dad054f30436bbb5c61e642de', 'message': 'VMware: Add volume name in vCenter to conn info\n\nThe VMware Nova driver uses the volume reference in vCenter\nwhich is passed in the connection info to identify the volume\nduring attach and detach. If the vCenter inventory is restored\nfrom a backup using backup solutions such as HP data protector,\nthe volume reference in vCenter may change, but the volume name\n(in vCenter) remains the same. This patch adds the volume name\nin vCenter to the connection info so that the VMware Nova driver\ncan use it to identify the volume during detach as a fallback\noption.\n\nChange-Id: I0bc2f73a8b50f2b2247531df200c07b4eeb02bf7\nPartial-bug: #1593742\n'}, {'number': 3, 'created': '2016-08-23 07:20:37.000000000', 'files': ['cinder/tests/unit/volume/drivers/vmware/test_vmware_vmdk.py', 'cinder/volume/drivers/vmware/vmdk.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/ddabae3ce8ef5dbb3901d5d67b18596c154e7222', 'message': 'VMware: Add volume name in vCenter to conn info\n\nThe VMware Nova driver uses the volume reference in vCenter\nwhich is passed in the connection info to identify the volume\nduring attach and detach. If the vCenter inventory is restored\nfrom a backup using backup solutions such as HP data protector,\nthe volume reference in vCenter may change, but the volume name\n(in vCenter) remains the same. This patch adds the volume name\nin vCenter to the connection info so that the VMware Nova driver\ncan use it to identify the volume during detach as a fallback\noption.\n\nChange-Id: I0bc2f73a8b50f2b2247531df200c07b4eeb02bf7\nPartial-bug: #1593742\n'}]",2,344069,ddabae3ce8ef5dbb3901d5d67b18596c154e7222,134,46,3,9171,,,0,"VMware: Add volume name in vCenter to conn info

The VMware Nova driver uses the volume reference in vCenter
which is passed in the connection info to identify the volume
during attach and detach. If the vCenter inventory is restored
from a backup using backup solutions such as HP data protector,
the volume reference in vCenter may change, but the volume name
(in vCenter) remains the same. This patch adds the volume name
in vCenter to the connection info so that the VMware Nova driver
can use it to identify the volume during detach as a fallback
option.

Change-Id: I0bc2f73a8b50f2b2247531df200c07b4eeb02bf7
Partial-bug: #1593742
",git fetch https://review.opendev.org/openstack/cinder refs/changes/69/344069/3 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/volume/drivers/vmware/vmdk.py', 'cinder/tests/unit/test_vmware_vmdk.py']",2,a49d04f4f927eeb82b774b9e3f566a50cc415f30,bug/1593742," self.assertEqual(volume['name'], conn_info['data']['name'])",,4,2
openstack%2Fmagnum~master~Ifd16bf3f5e80674d0f8d963066374f4ab3823c1f,openstack/magnum,master,Ifd16bf3f5e80674d0f8d963066374f4ab3823c1f,Removed not required style.css file,MERGED,2016-08-28 09:50:21.000000000,2016-08-29 05:58:31.000000000,2016-08-29 05:58:31.000000000,"[{'_account_id': 3}, {'_account_id': 668}, {'_account_id': 12385}]","[{'number': 1, 'created': '2016-08-28 09:50:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/be3659338af0363e4ca21ea804b1004d520cf142', 'message': ""Removed not required style.css file\n\nRemoved style.css from magnum source and it's reference\nfrom test modules.\n\nChange-Id: Ifd16bf3f5e80674d0f8d963066374f4ab3823c1f\nCloses-Bug: #1617722\n""}, {'number': 2, 'created': '2016-08-28 11:58:00.000000000', 'files': ['magnum/tests/unit/api/base.py', 'magnum/public/css/style.css', 'magnum/MANIFEST.in'], 'web_link': 'https://opendev.org/openstack/magnum/commit/08dc69eaf0e7007a924888a902f0aad16e5b3927', 'message': ""Removed not required style.css file\n\nRemoved style.css from magnum source and it's reference\nfrom test modules.\n\nChange-Id: Ifd16bf3f5e80674d0f8d963066374f4ab3823c1f\nCloses-Bug: #1617722\n""}]",0,361704,08dc69eaf0e7007a924888a902f0aad16e5b3927,9,3,2,13861,,,0,"Removed not required style.css file

Removed style.css from magnum source and it's reference
from test modules.

Change-Id: Ifd16bf3f5e80674d0f8d963066374f4ab3823c1f
Closes-Bug: #1617722
",git fetch https://review.opendev.org/openstack/magnum refs/changes/04/361704/1 && git format-patch -1 --stdout FETCH_HEAD,"['magnum/tests/unit/api/base.py', 'magnum/public/css/style.css', 'magnum/MANIFEST.in']",3,be3659338af0363e4ca21ea804b1004d520cf142,bug/1617722,,recursive-include public * ,0,46
openstack%2Frequirements~master~Icb37703f58268d3508aa731a980e4639f22b11b0,openstack/requirements,master,Icb37703f58268d3508aa731a980e4639f22b11b0,Add additional OpenStack-Ansible repositories to projects.txt,MERGED,2016-08-26 13:28:11.000000000,2016-08-29 05:49:57.000000000,2016-08-29 05:49:57.000000000,"[{'_account_id': 3}, {'_account_id': 11105}, {'_account_id': 14288}]","[{'number': 1, 'created': '2016-08-26 13:28:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/1e1ec1a44c3fecf3588469076469ee6e864f81ae', 'message': 'Add additional OpenStack-Ansible repositories to projects.txt\n\nChange-Id: Icb37703f58268d3508aa731a980e4639f22b11b0\n'}, {'number': 2, 'created': '2016-08-26 15:03:49.000000000', 'files': ['projects.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/a46a6b380b7d9eeae4a0fb248b486fd99a7ad41c', 'message': 'Add additional OpenStack-Ansible repositories to projects.txt\n\nChange-Id: Icb37703f58268d3508aa731a980e4639f22b11b0\n'}]",0,361176,a46a6b380b7d9eeae4a0fb248b486fd99a7ad41c,9,3,2,6816,,,0,"Add additional OpenStack-Ansible repositories to projects.txt

Change-Id: Icb37703f58268d3508aa731a980e4639f22b11b0
",git fetch https://review.opendev.org/openstack/requirements refs/changes/76/361176/1 && git format-patch -1 --stdout FETCH_HEAD,['projects.txt'],1,1e1ec1a44c3fecf3588469076469ee6e864f81ae,,openstack/openstack-ansible-ceph_clientopenstack/openstack-ansible-haproxy_serveropenstack/openstack-ansible-os_monascaopenstack/openstack-ansible-os_watcher,,4,0
openstack%2Frequirements~master~Ifd7f61d1d300570f1250a1393d03b9ac2183c1e5,openstack/requirements,master,Ifd7f61d1d300570f1250a1393d03b9ac2183c1e5,update constraint for python-openstackclient to new release 3.1.0,MERGED,2016-08-26 10:41:40.000000000,2016-08-29 05:49:50.000000000,2016-08-29 05:49:50.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 11105}, {'_account_id': 14288}]","[{'number': 1, 'created': '2016-08-26 10:41:40.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/20f444829313136c3a7040ceeead0981272390d7', 'message': 'update constraint for python-openstackclient to new release 3.1.0\n\npython-openstackclient 3.1.0 release\n\nChange-Id: Ifd7f61d1d300570f1250a1393d03b9ac2183c1e5\nmeta:version: 3.1.0\nmeta:diff-start: -\nmeta:series: newton\nmeta:release-type: release\nmeta:announce: openstack-announce@lists.openstack.org\nmeta:pypi: yes\nmeta:first: no\nmeta:release:Author: Steve Martinelli <s.martinelli@gmail.com>\nmeta:release:Commit: Davanum Srinivas <davanum@gmail.com>\nmeta:release:Change-Id: I9c932ecc37c289c7d211e047f5302127f1581d7b\n'}]",0,361070,20f444829313136c3a7040ceeead0981272390d7,10,4,1,5638,,,0,"update constraint for python-openstackclient to new release 3.1.0

python-openstackclient 3.1.0 release

Change-Id: Ifd7f61d1d300570f1250a1393d03b9ac2183c1e5
meta:version: 3.1.0
meta:diff-start: -
meta:series: newton
meta:release-type: release
meta:announce: openstack-announce@lists.openstack.org
meta:pypi: yes
meta:first: no
meta:release:Author: Steve Martinelli <s.martinelli@gmail.com>
meta:release:Commit: Davanum Srinivas <davanum@gmail.com>
meta:release:Change-Id: I9c932ecc37c289c7d211e047f5302127f1581d7b
",git fetch https://review.opendev.org/openstack/requirements refs/changes/70/361070/1 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,20f444829313136c3a7040ceeead0981272390d7,new-release,python-openstackclient===3.1.0,python-openstackclient===2.6.0,1,1
openstack%2Frequirements~master~I4565562c0f5713d567e2a74cb13b17d5ff479a0f,openstack/requirements,master,I4565562c0f5713d567e2a74cb13b17d5ff479a0f,update constraint for python-keystoneclient to new release 3.5.0,MERGED,2016-08-26 10:43:04.000000000,2016-08-29 05:49:44.000000000,2016-08-29 05:49:44.000000000,"[{'_account_id': 3}, {'_account_id': 11105}, {'_account_id': 14288}]","[{'number': 1, 'created': '2016-08-26 10:43:04.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/69724a31246ca792c9ffa81c8919443f3b0e67c1', 'message': 'update constraint for python-keystoneclient to new release 3.5.0\n\npython-keystoneclient 3.5.0 release\n\nChange-Id: I4565562c0f5713d567e2a74cb13b17d5ff479a0f\nmeta:version: 3.5.0\nmeta:diff-start: -\nmeta:series: newton\nmeta:release-type: release\nmeta:announce: openstack-announce@lists.openstack.org\nmeta:pypi: yes\nmeta:first: no\nmeta:release:Author: Steve Martinelli <s.martinelli@gmail.com>\nmeta:release:Commit: Davanum Srinivas <davanum@gmail.com>\nmeta:release:Change-Id: Idf879e0ea6ff9cb8a4a8996d3a600d731a3dcc72\n'}]",0,361073,69724a31246ca792c9ffa81c8919443f3b0e67c1,9,3,1,5638,,,0,"update constraint for python-keystoneclient to new release 3.5.0

python-keystoneclient 3.5.0 release

Change-Id: I4565562c0f5713d567e2a74cb13b17d5ff479a0f
meta:version: 3.5.0
meta:diff-start: -
meta:series: newton
meta:release-type: release
meta:announce: openstack-announce@lists.openstack.org
meta:pypi: yes
meta:first: no
meta:release:Author: Steve Martinelli <s.martinelli@gmail.com>
meta:release:Commit: Davanum Srinivas <davanum@gmail.com>
meta:release:Change-Id: Idf879e0ea6ff9cb8a4a8996d3a600d731a3dcc72
",git fetch https://review.opendev.org/openstack/requirements refs/changes/73/361073/1 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,69724a31246ca792c9ffa81c8919443f3b0e67c1,new-release,python-keystoneclient===3.5.0,python-keystoneclient===3.4.0,1,1
openstack%2Frequirements~master~I2b15ecd41c98c3875c92b37771fecb411b3f0e02,openstack/requirements,master,I2b15ecd41c98c3875c92b37771fecb411b3f0e02,update constraint for pycadf to new release 2.4.0,MERGED,2016-08-26 10:43:51.000000000,2016-08-29 05:49:38.000000000,2016-08-29 05:49:38.000000000,"[{'_account_id': 3}, {'_account_id': 11105}, {'_account_id': 14288}]","[{'number': 1, 'created': '2016-08-26 10:43:51.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/898d71a4b9419403a2303f0c52533385fd6f2b34', 'message': 'update constraint for pycadf to new release 2.4.0\n\npycadf 2.4.0 release\n\nChange-Id: I2b15ecd41c98c3875c92b37771fecb411b3f0e02\nmeta:version: 2.4.0\nmeta:diff-start: -\nmeta:series: newton\nmeta:release-type: release\nmeta:announce: openstack-dev@lists.openstack.org\nmeta:pypi: yes\nmeta:first: no\nmeta:release:Author: Steve Martinelli <s.martinelli@gmail.com>\nmeta:release:Commit: Davanum Srinivas <davanum@gmail.com>\nmeta:release:Change-Id: I111422776892d4245c9348d1dc9d3eec9b15f4e4\n'}]",0,361074,898d71a4b9419403a2303f0c52533385fd6f2b34,9,3,1,5638,,,0,"update constraint for pycadf to new release 2.4.0

pycadf 2.4.0 release

Change-Id: I2b15ecd41c98c3875c92b37771fecb411b3f0e02
meta:version: 2.4.0
meta:diff-start: -
meta:series: newton
meta:release-type: release
meta:announce: openstack-dev@lists.openstack.org
meta:pypi: yes
meta:first: no
meta:release:Author: Steve Martinelli <s.martinelli@gmail.com>
meta:release:Commit: Davanum Srinivas <davanum@gmail.com>
meta:release:Change-Id: I111422776892d4245c9348d1dc9d3eec9b15f4e4
",git fetch https://review.opendev.org/openstack/requirements refs/changes/74/361074/1 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,898d71a4b9419403a2303f0c52533385fd6f2b34,new-release,pycadf===2.4.0,pycadf===2.3.0,1,1
openstack%2Frequirements~master~I0b0d806eacefdf77586250a6fc33ae463ae54138,openstack/requirements,master,I0b0d806eacefdf77586250a6fc33ae463ae54138,update constraint for python-mistralclient to new release 2.1.0,MERGED,2016-08-25 11:36:49.000000000,2016-08-29 05:46:08.000000000,2016-08-29 05:46:08.000000000,"[{'_account_id': 3}, {'_account_id': 11105}, {'_account_id': 12898}, {'_account_id': 14288}]","[{'number': 1, 'created': '2016-08-25 11:36:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/eb91d461616e7641d7a97dc1ef24d4118fc6be8e', 'message': 'update constraint for python-mistralclient to new release 2.1.0\n\npython-mistralclient 2.1.0 release\n\nChange-Id: I0b0d806eacefdf77586250a6fc33ae463ae54138\nmeta:version: 2.1.0\nmeta:diff-start: -\nmeta:series: newton\nmeta:release-type: release\nmeta:announce: openstack-announce@lists.openstack.org\nmeta:pypi: yes\nmeta:first: yes\nmeta:release:Author: Lingxian Kong <anlin.kong@gmail.com>\nmeta:release:Commit: Davanum Srinivas <davanum@gmail.com>\nmeta:release:Change-Id: Idc5b865022d1725d14432cd5df6989c698c486c4\n'}, {'number': 2, 'created': '2016-08-26 04:13:47.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/4a158623ae53866e20e2b85237649359dbb2d2db', 'message': 'update constraint for python-mistralclient to new release 2.1.0\n\npython-mistralclient 2.1.0 release\n\nChange-Id: I0b0d806eacefdf77586250a6fc33ae463ae54138\nmeta:version: 2.1.0\nmeta:diff-start: -\nmeta:series: newton\nmeta:release-type: release\nmeta:announce: openstack-announce@lists.openstack.org\nmeta:pypi: yes\nmeta:first: yes\nmeta:release:Author: Lingxian Kong <anlin.kong@gmail.com>\nmeta:release:Commit: Davanum Srinivas <davanum@gmail.com>\nmeta:release:Change-Id: Idc5b865022d1725d14432cd5df6989c698c486c4\n'}]",0,360454,4a158623ae53866e20e2b85237649359dbb2d2db,9,4,2,5638,,,0,"update constraint for python-mistralclient to new release 2.1.0

python-mistralclient 2.1.0 release

Change-Id: I0b0d806eacefdf77586250a6fc33ae463ae54138
meta:version: 2.1.0
meta:diff-start: -
meta:series: newton
meta:release-type: release
meta:announce: openstack-announce@lists.openstack.org
meta:pypi: yes
meta:first: yes
meta:release:Author: Lingxian Kong <anlin.kong@gmail.com>
meta:release:Commit: Davanum Srinivas <davanum@gmail.com>
meta:release:Change-Id: Idc5b865022d1725d14432cd5df6989c698c486c4
",git fetch https://review.opendev.org/openstack/requirements refs/changes/54/360454/2 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,eb91d461616e7641d7a97dc1ef24d4118fc6be8e,new-release,python-mistralclient===2.1.0,python-mistralclient===2.0.0,1,1
openstack%2Frequirements~master~I750e6a8482525fcc0bc4984a33f65fa2edfc1350,openstack/requirements,master,I750e6a8482525fcc0bc4984a33f65fa2edfc1350,Bump python-heatclient version to 1.4.0,MERGED,2016-08-25 21:05:48.000000000,2016-08-29 05:46:02.000000000,2016-08-29 05:46:02.000000000,"[{'_account_id': 3}, {'_account_id': 4571}, {'_account_id': 11105}, {'_account_id': 14288}, {'_account_id': 23324}]","[{'number': 1, 'created': '2016-08-25 21:05:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/083c70fc9b5aa797a7641b9d4175fa8fe6bfd91c', 'message': 'Bump python-heatclient version to 1.4.0\n\n1.4.0 includes library API required for integration tests\n\nChange-Id: I750e6a8482525fcc0bc4984a33f65fa2edfc1350\n'}, {'number': 2, 'created': '2016-08-26 04:15:14.000000000', 'files': ['global-requirements.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/40f300289f4c062d9dc6e417c6eabe1390579867', 'message': 'Bump python-heatclient version to 1.4.0\n\n1.4.0 includes library API required for integration tests\n\nChange-Id: I750e6a8482525fcc0bc4984a33f65fa2edfc1350\n'}]",0,360791,40f300289f4c062d9dc6e417c6eabe1390579867,12,5,2,4571,,,0,"Bump python-heatclient version to 1.4.0

1.4.0 includes library API required for integration tests

Change-Id: I750e6a8482525fcc0bc4984a33f65fa2edfc1350
",git fetch https://review.opendev.org/openstack/requirements refs/changes/91/360791/2 && git format-patch -1 --stdout FETCH_HEAD,"['global-requirements.txt', 'upper-constraints.txt']",2,083c70fc9b5aa797a7641b9d4175fa8fe6bfd91c,heatclient,python-heatclient===1.4.0,python-heatclient===1.3.0,2,2
openstack%2Frequirements~master~I622b401efd78f3fd20f86b82ef1e6bc418f7cc34,openstack/requirements,master,I622b401efd78f3fd20f86b82ef1e6bc418f7cc34,update constraint for python-heatclient to new release 1.4.0,MERGED,2016-08-25 11:54:32.000000000,2016-08-29 05:45:57.000000000,2016-08-29 05:45:57.000000000,"[{'_account_id': 3}, {'_account_id': 11105}, {'_account_id': 12898}, {'_account_id': 14288}]","[{'number': 1, 'created': '2016-08-25 11:54:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/fd638b1400f2234e1992bfe7570a2308cd856064', 'message': 'update constraint for python-heatclient to new release 1.4.0\n\npython-heatclient 1.4.0 release\n\nChange-Id: I622b401efd78f3fd20f86b82ef1e6bc418f7cc34\nmeta:version: 1.4.0\nmeta:diff-start: -\nmeta:series: newton\nmeta:release-type: release\nmeta:announce: openstack-announce@lists.openstack.org\nmeta:pypi: yes\nmeta:first: no\nmeta:release:Author: Steve Baker <sbaker@redhat.com>\nmeta:release:Commit: Davanum Srinivas <davanum@gmail.com>\nmeta:release:Change-Id: Ib89722b9456a120fbe4aac88ea2e6b09688d2eb2\n'}, {'number': 2, 'created': '2016-08-26 04:13:01.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/dc3497ff3e820f09f1bf60fade106d90195c973c', 'message': 'update constraint for python-heatclient to new release 1.4.0\n\npython-heatclient 1.4.0 release\n\nChange-Id: I622b401efd78f3fd20f86b82ef1e6bc418f7cc34\nmeta:version: 1.4.0\nmeta:diff-start: -\nmeta:series: newton\nmeta:release-type: release\nmeta:announce: openstack-announce@lists.openstack.org\nmeta:pypi: yes\nmeta:first: no\nmeta:release:Author: Steve Baker <sbaker@redhat.com>\nmeta:release:Commit: Davanum Srinivas <davanum@gmail.com>\nmeta:release:Change-Id: Ib89722b9456a120fbe4aac88ea2e6b09688d2eb2\n'}]",0,360462,dc3497ff3e820f09f1bf60fade106d90195c973c,9,4,2,5638,,,0,"update constraint for python-heatclient to new release 1.4.0

python-heatclient 1.4.0 release

Change-Id: I622b401efd78f3fd20f86b82ef1e6bc418f7cc34
meta:version: 1.4.0
meta:diff-start: -
meta:series: newton
meta:release-type: release
meta:announce: openstack-announce@lists.openstack.org
meta:pypi: yes
meta:first: no
meta:release:Author: Steve Baker <sbaker@redhat.com>
meta:release:Commit: Davanum Srinivas <davanum@gmail.com>
meta:release:Change-Id: Ib89722b9456a120fbe4aac88ea2e6b09688d2eb2
",git fetch https://review.opendev.org/openstack/requirements refs/changes/62/360462/1 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,fd638b1400f2234e1992bfe7570a2308cd856064,new-release,python-heatclient===1.4.0,python-heatclient===1.3.0,1,1
openstack%2Frequirements~master~Icc5b1ba275cd7dd93600058eb1a5160aae3fef50,openstack/requirements,master,Icc5b1ba275cd7dd93600058eb1a5160aae3fef50,update constraint for osc-lib to new release 1.1.0,MERGED,2016-08-26 00:21:14.000000000,2016-08-29 05:45:51.000000000,2016-08-29 05:45:51.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 8410}, {'_account_id': 11105}, {'_account_id': 14288}, {'_account_id': 23294}, {'_account_id': 23302}]","[{'number': 1, 'created': '2016-08-26 00:21:14.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/cec8e0b4cbd6dfab76c39c19c83103d33317d5e9', 'message': 'update constraint for osc-lib to new release 1.1.0\n\nosc-lib 1.1.0 release\n\nChange-Id: Icc5b1ba275cd7dd93600058eb1a5160aae3fef50\nmeta:version: 1.1.0\nmeta:diff-start: -\nmeta:series: newton\nmeta:release-type: release\nmeta:announce: openstack-dev@lists.openstack.org\nmeta:pypi: yes\nmeta:first: no\nmeta:release:Author: Steve Martinelli <s.martinelli@gmail.com>\nmeta:release:Commit: Davanum Srinivas <davanum@gmail.com>\nmeta:release:Change-Id: I7dec7a10c5428e357c0aef62843f7ea55b939860\n'}]",0,360830,cec8e0b4cbd6dfab76c39c19c83103d33317d5e9,16,7,1,5638,,,0,"update constraint for osc-lib to new release 1.1.0

osc-lib 1.1.0 release

Change-Id: Icc5b1ba275cd7dd93600058eb1a5160aae3fef50
meta:version: 1.1.0
meta:diff-start: -
meta:series: newton
meta:release-type: release
meta:announce: openstack-dev@lists.openstack.org
meta:pypi: yes
meta:first: no
meta:release:Author: Steve Martinelli <s.martinelli@gmail.com>
meta:release:Commit: Davanum Srinivas <davanum@gmail.com>
meta:release:Change-Id: I7dec7a10c5428e357c0aef62843f7ea55b939860
",git fetch https://review.opendev.org/openstack/requirements refs/changes/30/360830/1 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,cec8e0b4cbd6dfab76c39c19c83103d33317d5e9,new-release,osc-lib===1.1.0,osc-lib===1.0.2,1,1
openstack%2Fkolla~master~I909c56db9080dea6606b647d1d69f19c66c9c0e4,openstack/kolla,master,I909c56db9080dea6606b647d1d69f19c66c9c0e4,Remove RUN macro install from Kibana Dockerfile,ABANDONED,2016-08-29 05:43:04.000000000,2016-08-29 05:45:22.000000000,,[],"[{'number': 1, 'created': '2016-08-29 05:43:04.000000000', 'files': ['docker/kibana/Dockerfile.j2'], 'web_link': 'https://opendev.org/openstack/kolla/commit/eb136e052b39e56bd6fc7eedb1eab78c95d38f29', 'message': 'Remove RUN macro install from Kibana Dockerfile\n\nTrivialFix\nSigned-off-by: Eduardo Gonzalez <dabarren@gmail.com>\n\nChange-Id: I909c56db9080dea6606b647d1d69f19c66c9c0e4\n'}]",0,361846,eb136e052b39e56bd6fc7eedb1eab78c95d38f29,2,0,1,19316,,,0,"Remove RUN macro install from Kibana Dockerfile

TrivialFix
Signed-off-by: Eduardo Gonzalez <dabarren@gmail.com>

Change-Id: I909c56db9080dea6606b647d1d69f19c66c9c0e4
",git fetch https://review.opendev.org/openstack/kolla refs/changes/46/361846/1 && git format-patch -1 --stdout FETCH_HEAD,['docker/kibana/Dockerfile.j2'],1,eb136e052b39e56bd6fc7eedb1eab78c95d38f29,fix_kibana_run,"{{ macros.install_packages(kibana_packages | customizable(""packages"")) }}","RUN {{ macros.install_packages(kibana_packages | customizable(""packages"")) }}",1,1
openstack%2Frequirements~master~I7ccb747335be0774538013b62ea32142d6059d3f,openstack/requirements,master,I7ccb747335be0774538013b62ea32142d6059d3f,Bump tackerclient to 0.6.0 (newton) in global-requirements,MERGED,2016-08-24 03:35:25.000000000,2016-08-29 05:37:20.000000000,2016-08-29 05:37:20.000000000,"[{'_account_id': 3}, {'_account_id': 11105}, {'_account_id': 12898}, {'_account_id': 14288}, {'_account_id': 16237}]","[{'number': 1, 'created': '2016-08-24 03:35:25.000000000', 'files': ['global-requirements.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/badff235c64eb3ad71baec318eee7968452cc87f', 'message': 'Bump tackerclient to 0.6.0 (newton) in global-requirements\n\ntackerclient 0.6.0 introduces client changes for features like\nvnf scaling and audit-event logging\n\nChange-Id: I7ccb747335be0774538013b62ea32142d6059d3f\n'}]",0,359575,badff235c64eb3ad71baec318eee7968452cc87f,12,5,1,13380,,,0,"Bump tackerclient to 0.6.0 (newton) in global-requirements

tackerclient 0.6.0 introduces client changes for features like
vnf scaling and audit-event logging

Change-Id: I7ccb747335be0774538013b62ea32142d6059d3f
",git fetch https://review.opendev.org/openstack/requirements refs/changes/75/359575/1 && git format-patch -1 --stdout FETCH_HEAD,['global-requirements.txt'],1,badff235c64eb3ad71baec318eee7968452cc87f,tackerclient-0.6.0,python-tackerclient>=0.6.0 # Apache-2.0,python-tackerclient>=0.5.0 # Apache-2.0,1,1
openstack%2Fmagnum-ui~master~I0db5472c4f19638cc57116101b552ad21fe34651,openstack/magnum-ui,master,I0db5472c4f19638cc57116101b552ad21fe34651,Rename bay and baymodel for 'Soft StringFreeze' milestone,MERGED,2016-08-26 09:09:04.000000000,2016-08-29 05:31:29.000000000,2016-08-29 05:31:29.000000000,"[{'_account_id': 3}, {'_account_id': 6638}, {'_account_id': 9591}, {'_account_id': 10206}, {'_account_id': 10263}, {'_account_id': 11536}, {'_account_id': 11650}, {'_account_id': 12385}, {'_account_id': 21469}]","[{'number': 1, 'created': '2016-08-26 09:09:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum-ui/commit/4b430eadc80419d30e5cf3171927b971cf4c2305', 'message': 'Rename bay and baymodel for \'Soft StringFreeze\' milestone\n\n""bay"" and ""baymodel"" is not common term.\nThis patch renames ""bay"" to ""cluster"", and ""baymodel"" to\n""cluster template"" for \'Soft StringFreeze\'[1] in Newton\nRelease Schedule[2].\n\n[1] Soft StringFreeze: Aug 29 - Sep 02\n[2] https://releases.openstack.org/newton/schedule.html\n\nFor translation work, this patch should focus to changing\nstrings to be translated and should be merged soon.\n\nSo, until ""cluster"" and ""cluster template"" is implemented\ninto Magnum API, Magnum-UI uses bay and baymodel of magnumclient.\n\nChange-Id: I0db5472c4f19638cc57116101b552ad21fe34651\nImplements: blueprint rename-bay-to-cluster\n'}, {'number': 2, 'created': '2016-08-26 09:23:18.000000000', 'files': ['magnum_ui/static/dashboard/container-infra/clusters/details/overview.controller.js', 'magnum_ui/static/dashboard/container-infra/clusters/details/overview.html', 'magnum_ui/content/cluster_templates/__init__.py', 'magnum_ui/content/clusters/panel.py', 'magnum_ui/static/dashboard/container-infra/cluster-templates/cluster-templates.module.spec.js', 'magnum_ui/static/dashboard/container-infra/bays/create/size/size.help.html', 'magnum_ui/test/api_tests/rest_api_tests.py', 'magnum_ui/enabled/_1372_project_container-infra_baymodels_panel.py', 'magnum_ui/static/dashboard/container-infra/baymodels/create/spec/spec.html', 'magnum_ui/static/dashboard/container-infra/baymodels/details/drawer.controller.js', 'magnum_ui/content/cluster_templates/urls.py', 'magnum_ui/enabled/_1371_project_container_infra_clusters_panel.py', 'magnum_ui/static/dashboard/container-infra/bays/panel.html', 'magnum_ui/static/dashboard/container-infra/cluster-templates/create/info/cluster-template.info.controller.js', 'magnum_ui/content/clusters/urls.py', 'magnum_ui/static/dashboard/container-infra/clusters/create/info/info.html', 'magnum_ui/static/dashboard/container-infra/container-infra.module.js', 'magnum_ui/static/dashboard/container-infra/bays/create/size/size.html', 'magnum_ui/static/dashboard/container-infra/bays/details/details.module.js', 'magnum_ui/static/dashboard/container-infra/baymodels/create/create-workflow.service.js', 'magnum_ui/static/dashboard/container-infra/cluster-templates/create/create.service.js', 'magnum_ui/static/dashboard/container-infra/bays/details/overview.html', 'magnum_ui/static/dashboard/container-infra/clusters/create/size/cluster.size.controller.js', 'magnum_ui/static/dashboard/container-infra/cluster-templates/create/labels/labels.html', 'magnum_ui/static/dashboard/container-infra/clusters/create/size/size.help.html', 'magnum_ui/static/dashboard/container-infra/cluster-templates/create/info/info.help.html', 'magnum_ui/content/clusters/views.py', 'magnum_ui/static/dashboard/container-infra/cluster-templates/create/labels/labels.help.html', 'magnum_ui/content/cluster_templates/views.py', 'magnum_ui/static/dashboard/container-infra/bays/create/info/info.html', 'magnum_ui/static/dashboard/container-infra/clusters/clusters.module.spec.js', 'magnum_ui/static/dashboard/container-infra/cluster-templates/actions.module.js', 'magnum_ui/static/dashboard/container-infra/bays/bays.module.spec.js', 'magnum_ui/static/dashboard/container-infra/clusters/create/misc/misc.html', 'magnum_ui/static/dashboard/container-infra/bays/create/create-workflow.service.js', 'magnum_ui/static/dashboard/container-infra/clusters/create/info/cluster.info.controller.js', 'magnum_ui/static/dashboard/container-infra/cluster-templates/create/info/info.html', 'magnum_ui/static/dashboard/container-infra/cluster-templates/cluster-templates.module.js', 'magnum_ui/static/dashboard/container-infra/cluster-templates/create/spec/spec.html', 'magnum_ui/static/dashboard/container-infra/cluster-templates/details/details.module.js', 'magnum_ui/static/dashboard/container-infra/cluster-templates/panel.html', 'magnum_ui/api/magnum.py', 'magnum_ui/static/dashboard/container-infra/cluster-templates/details/overview.controller.js', 'magnum_ui/static/dashboard/container-infra/cluster-templates/create/labels/cluster-template.labels.controller.js', 'magnum_ui/content/cluster_templates/tests.py', 'magnum_ui/static/dashboard/container-infra/clusters/create/cluster-model.js', 'doc/source/index.rst', 'magnum_ui/static/dashboard/container-infra/clusters/create/misc/misc.help.html', 'magnum_ui/static/dashboard/container-infra/baymodels/details/overview.html', 'magnum_ui/static/dashboard/container-infra/clusters/create/size/size.html', 'magnum_ui/api/rest/magnum.py', 'magnum_ui/content/clusters/__init__.py', 'magnum_ui/static/dashboard/container-infra/bays/create/misc/bay.misc.controller.js', 'magnum_ui/static/dashboard/container-infra/clusters/actions.module.js', 'magnum_ui/static/dashboard/container-infra/clusters/clusters.scss', 'magnum_ui/static/dashboard/container-infra/cluster-templates/delete/delete.service.js', 'magnum_ui/static/dashboard/container-infra/bays/create/info/info.help.html', 'README.rst', 'magnum_ui/static/dashboard/container-infra/baymodels/create/info/info.html', 'magnum_ui/static/dashboard/container-infra/cluster-templates/create/network/network.html', 'magnum_ui/static/dashboard/container-infra/bays/create/misc/misc.help.html', 'magnum_ui/static/dashboard/container-infra/baymodels/actions.module.js', 'magnum_ui/static/dashboard/container-infra/baymodels/create/labels/labels.html', 'magnum_ui/static/dashboard/container-infra/baymodels/panel.html', 'magnum_ui/static/dashboard/container-infra/clusters/create/misc/cluster.misc.controller.js', 'magnum_ui/content/cluster_templates/panel.py', 'magnum_ui/static/dashboard/container-infra/cluster-templates/create/network/network.help.html', 'magnum_ui/static/dashboard/container-infra/clusters/create/create-workflow.service.js', 'magnum_ui/static/dashboard/container-infra/bays/create/info/bay.info.controller.js', 'magnum_ui/static/dashboard/container-infra/container-infra.scss', 'magnum_ui/static/dashboard/container-infra/cluster-templates/cluster-templates.scss', 'magnum_ui/static/dashboard/container-infra/cluster-templates/create/create-workflow.service.js', 'magnum_ui/static/dashboard/container-infra/clusters/details/drawer.html', 'magnum_ui/enabled/_1372_project_container_infra_cluster_templates_panel.py', 'magnum_ui/content/baymodels/tests.py', 'magnum_ui/enabled/_1370_project_container_infra_panel_group.py', 'magnum_ui/static/dashboard/container-infra/clusters/delete/delete.service.js', 'magnum_ui/test/test_data.py', 'magnum_ui/static/dashboard/container-infra/cluster-templates/create/cluster-template-model.js', 'magnum_ui/content/bays/urls.py', 'magnum_ui/content/clusters/tests.py', 'magnum_ui/static/dashboard/container-infra/clusters/details/drawer.controller.js', 'magnum_ui/static/dashboard/container-infra/clusters/clusters.module.js', 'magnum_ui/static/dashboard/container-infra/baymodels/create/info/info.help.html', 'magnum_ui/static/dashboard/container-infra/magnum.service.js', 'magnum_ui/static/dashboard/container-infra/cluster-templates/create/spec/spec.help.html', 'magnum_ui/static/dashboard/container-infra/clusters/create/info/info.help.html', 'magnum_ui/static/dashboard/container-infra/bays/create/misc/misc.html', 'magnum_ui/static/dashboard/container-infra/bays/details/overview.controller.js', 'magnum_ui/static/dashboard/container-infra/cluster-templates/create/spec/cluster-template.spec.controller.js', 'magnum_ui/static/dashboard/container-infra/clusters/create/create.service.js', 'magnum_ui/static/dashboard/container-infra/baymodels/create/network/network.html', 'magnum_ui/static/dashboard/container-infra/cluster-templates/details/drawer.controller.js', 'magnum_ui/static/dashboard/container-infra/bays/actions.module.js', 'magnum_ui/static/dashboard/container-infra/cluster-templates/details/drawer.html', 'magnum_ui/static/dashboard/container-infra/clusters/details/details.module.js', 'magnum_ui/static/dashboard/container-infra/cluster-templates/create/network/cluster-template.network.controller.js', 'magnum_ui/static/dashboard/container-infra/cluster-templates/details/overview.html', 'magnum_ui/static/dashboard/container-infra/clusters/panel.html', 'magnum_ui/static/dashboard/container-infra/baymodels/create/labels/labels.help.html'], 'web_link': 'https://opendev.org/openstack/magnum-ui/commit/04c6e4433a5f70ee343e280bdff58aa152c64d23', 'message': 'Rename bay and baymodel for \'Soft StringFreeze\' milestone\n\n""bay"" and ""baymodel"" is not common term.\nThis patch renames ""bay"" to ""cluster"", and ""baymodel"" to\n""cluster template"" for \'Soft StringFreeze\'[1] in Newton\nRelease Schedule[2].\n\n[1] Soft StringFreeze: Aug 29 - Sep 02\n[2] https://releases.openstack.org/newton/schedule.html\n\nFor translation work, this patch should focus to changing\nstrings to be translated and should be merged soon.\n\nSo, until ""cluster"" and ""cluster template"" is implemented\ninto Magnum API, Magnum-UI uses bay and baymodel of magnumclient.\n\nChange-Id: I0db5472c4f19638cc57116101b552ad21fe34651\nImplements: blueprint rename-bay-to-cluster\n'}]",0,361011,04c6e4433a5f70ee343e280bdff58aa152c64d23,10,9,2,16352,,,0,"Rename bay and baymodel for 'Soft StringFreeze' milestone

""bay"" and ""baymodel"" is not common term.
This patch renames ""bay"" to ""cluster"", and ""baymodel"" to
""cluster template"" for 'Soft StringFreeze'[1] in Newton
Release Schedule[2].

[1] Soft StringFreeze: Aug 29 - Sep 02
[2] https://releases.openstack.org/newton/schedule.html

For translation work, this patch should focus to changing
strings to be translated and should be merged soon.

So, until ""cluster"" and ""cluster template"" is implemented
into Magnum API, Magnum-UI uses bay and baymodel of magnumclient.

Change-Id: I0db5472c4f19638cc57116101b552ad21fe34651
Implements: blueprint rename-bay-to-cluster
",git fetch https://review.opendev.org/openstack/magnum-ui refs/changes/11/361011/2 && git format-patch -1 --stdout FETCH_HEAD,"['magnum_ui/static/dashboard/container-infra/clusters/details/overview.controller.js', 'magnum_ui/static/dashboard/container-infra/clusters/details/overview.html', 'magnum_ui/content/cluster_templates/__init__.py', 'magnum_ui/content/clusters/panel.py', 'magnum_ui/static/dashboard/container-infra/cluster-templates/cluster-templates.module.spec.js', 'magnum_ui/static/dashboard/container-infra/bays/create/size/size.help.html', 'magnum_ui/test/api_tests/rest_api_tests.py', 'magnum_ui/enabled/_1372_project_container-infra_baymodels_panel.py', 'magnum_ui/static/dashboard/container-infra/baymodels/create/spec/spec.html', 'magnum_ui/static/dashboard/container-infra/baymodels/details/drawer.controller.js', 'magnum_ui/content/cluster_templates/urls.py', 'magnum_ui/enabled/_1371_project_container_infra_clusters_panel.py', 'magnum_ui/static/dashboard/container-infra/bays/panel.html', 'magnum_ui/static/dashboard/container-infra/cluster-templates/create/info/cluster-template.info.controller.js', 'magnum_ui/content/clusters/urls.py', 'magnum_ui/static/dashboard/container-infra/clusters/create/info/info.html', 'magnum_ui/static/dashboard/container-infra/container-infra.module.js', 'magnum_ui/static/dashboard/container-infra/bays/create/size/size.html', 'magnum_ui/static/dashboard/container-infra/bays/details/details.module.js', 'magnum_ui/static/dashboard/container-infra/baymodels/create/create-workflow.service.js', 'magnum_ui/static/dashboard/container-infra/cluster-templates/create/create.service.js', 'magnum_ui/static/dashboard/container-infra/bays/details/overview.html', 'magnum_ui/static/dashboard/container-infra/clusters/create/size/cluster.size.controller.js', 'magnum_ui/static/dashboard/container-infra/cluster-templates/create/labels/labels.html', 'magnum_ui/static/dashboard/container-infra/clusters/create/size/size.help.html', 'magnum_ui/static/dashboard/container-infra/cluster-templates/create/info/info.help.html', 'magnum_ui/content/clusters/views.py', 'magnum_ui/static/dashboard/container-infra/cluster-templates/create/labels/labels.help.html', 'magnum_ui/content/cluster_templates/views.py', 'magnum_ui/static/dashboard/container-infra/bays/create/info/info.html', 'magnum_ui/static/dashboard/container-infra/clusters/clusters.module.spec.js', 'magnum_ui/static/dashboard/container-infra/cluster-templates/actions.module.js', 'magnum_ui/static/dashboard/container-infra/bays/bays.module.spec.js', 'magnum_ui/static/dashboard/container-infra/clusters/create/misc/misc.html', 'magnum_ui/static/dashboard/container-infra/bays/create/create-workflow.service.js', 'magnum_ui/static/dashboard/container-infra/clusters/create/info/cluster.info.controller.js', 'magnum_ui/static/dashboard/container-infra/cluster-templates/create/info/info.html', 'magnum_ui/static/dashboard/container-infra/cluster-templates/cluster-templates.module.js', 'magnum_ui/static/dashboard/container-infra/cluster-templates/create/spec/spec.html', 'magnum_ui/static/dashboard/container-infra/cluster-templates/details/details.module.js', 'magnum_ui/static/dashboard/container-infra/cluster-templates/panel.html', 'magnum_ui/api/magnum.py', 'magnum_ui/static/dashboard/container-infra/cluster-templates/details/overview.controller.js', 'magnum_ui/static/dashboard/container-infra/cluster-templates/create/labels/cluster-template.labels.controller.js', 'magnum_ui/content/cluster_templates/tests.py', 'magnum_ui/static/dashboard/container-infra/clusters/create/cluster-model.js', 'doc/source/index.rst', 'magnum_ui/static/dashboard/container-infra/clusters/create/misc/misc.help.html', 'magnum_ui/static/dashboard/container-infra/baymodels/details/overview.html', 'magnum_ui/static/dashboard/container-infra/clusters/create/size/size.html', 'magnum_ui/api/rest/magnum.py', 'magnum_ui/content/clusters/__init__.py', 'magnum_ui/static/dashboard/container-infra/bays/create/misc/bay.misc.controller.js', 'magnum_ui/static/dashboard/container-infra/clusters/actions.module.js', 'magnum_ui/static/dashboard/container-infra/clusters/clusters.scss', 'magnum_ui/static/dashboard/container-infra/cluster-templates/delete/delete.service.js', 'magnum_ui/static/dashboard/container-infra/bays/create/info/info.help.html', 'README.rst', 'magnum_ui/static/dashboard/container-infra/baymodels/create/info/info.html', 'magnum_ui/static/dashboard/container-infra/cluster-templates/create/network/network.html', 'magnum_ui/static/dashboard/container-infra/bays/create/misc/misc.help.html', 'magnum_ui/static/dashboard/container-infra/baymodels/actions.module.js', 'magnum_ui/static/dashboard/container-infra/baymodels/create/labels/labels.html', 'magnum_ui/static/dashboard/container-infra/baymodels/panel.html', 'magnum_ui/static/dashboard/container-infra/clusters/create/misc/cluster.misc.controller.js', 'magnum_ui/content/cluster_templates/panel.py', 'magnum_ui/static/dashboard/container-infra/cluster-templates/create/network/network.help.html', 'magnum_ui/static/dashboard/container-infra/clusters/create/create-workflow.service.js', 'magnum_ui/static/dashboard/container-infra/bays/create/info/bay.info.controller.js', 'magnum_ui/static/dashboard/container-infra/container-infra.scss', 'magnum_ui/static/dashboard/container-infra/cluster-templates/cluster-templates.scss', 'magnum_ui/static/dashboard/container-infra/cluster-templates/create/create-workflow.service.js', 'magnum_ui/static/dashboard/container-infra/clusters/details/drawer.html', 'magnum_ui/enabled/_1372_project_container_infra_cluster_templates_panel.py', 'magnum_ui/content/baymodels/tests.py', 'magnum_ui/enabled/_1370_project_container_infra_panel_group.py', 'magnum_ui/static/dashboard/container-infra/clusters/delete/delete.service.js', 'magnum_ui/test/test_data.py', 'magnum_ui/static/dashboard/container-infra/cluster-templates/create/cluster-template-model.js', 'magnum_ui/content/bays/urls.py', 'magnum_ui/content/clusters/tests.py', 'magnum_ui/static/dashboard/container-infra/clusters/details/drawer.controller.js', 'magnum_ui/static/dashboard/container-infra/clusters/clusters.module.js', 'magnum_ui/static/dashboard/container-infra/baymodels/create/info/info.help.html', 'magnum_ui/static/dashboard/container-infra/magnum.service.js', 'magnum_ui/static/dashboard/container-infra/cluster-templates/create/spec/spec.help.html', 'magnum_ui/static/dashboard/container-infra/clusters/create/info/info.help.html', 'magnum_ui/static/dashboard/container-infra/bays/create/misc/misc.html', 'magnum_ui/static/dashboard/container-infra/bays/details/overview.controller.js', 'magnum_ui/static/dashboard/container-infra/cluster-templates/create/spec/cluster-template.spec.controller.js', 'magnum_ui/static/dashboard/container-infra/clusters/create/create.service.js', 'magnum_ui/static/dashboard/container-infra/baymodels/create/network/network.html', 'magnum_ui/static/dashboard/container-infra/cluster-templates/details/drawer.controller.js', 'magnum_ui/static/dashboard/container-infra/bays/actions.module.js', 'magnum_ui/static/dashboard/container-infra/cluster-templates/details/drawer.html', 'magnum_ui/static/dashboard/container-infra/clusters/details/details.module.js', 'magnum_ui/static/dashboard/container-infra/cluster-templates/create/network/cluster-template.network.controller.js', 'magnum_ui/static/dashboard/container-infra/cluster-templates/details/overview.html', 'magnum_ui/static/dashboard/container-infra/clusters/panel.html', 'magnum_ui/static/dashboard/container-infra/baymodels/create/labels/labels.help.html']",100,4b430eadc80419d30e5cf3171927b971cf4c2305,bp/rename-bay-to-cluster,,<p translate>Arbitrary labels in the form of key=value pairs to associate with a baymodel. May be used multiple times.</p> ,1306,1531
openstack%2Fkeystone~master~Ia012c614b9a5b9af6b8bb447b39a9901caaf1fb5,openstack/keystone,master,Ia012c614b9a5b9af6b8bb447b39a9901caaf1fb5,Modify sql banned operations for each of the new repos,MERGED,2016-08-22 15:42:41.000000000,2016-08-29 05:17:02.000000000,2016-08-29 05:17:02.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 2218}, {'_account_id': 5707}, {'_account_id': 6482}, {'_account_id': 17860}]","[{'number': 1, 'created': '2016-08-22 15:42:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/83474bbed017663f7114d5254ced8e3e87de9465', 'message': 'Modify sql banned opreations for each of the new repos\n\nThis patch covers all the regular table and column operations\nacross the four repos. It does not, however, check for triggers\nand indexes - which will be done in a separate patch.\n\nPartial-Bug: #1615024\nChange-Id: Ia012c614b9a5b9af6b8bb447b39a9901caaf1fb5\n'}, {'number': 2, 'created': '2016-08-23 18:21:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/767a9c31fd1add7cca52a8938639cb81a9fda9b4', 'message': 'Modify sql banned operations for each of the new repos\n\nThis patch covers all the regular table and column operations\nacross the four repos. It does not, however, check for triggers\nand indexes - which will be done in a separate patch.\n\nPartial-Bug: #1615024\nChange-Id: Ia012c614b9a5b9af6b8bb447b39a9901caaf1fb5\n'}, {'number': 3, 'created': '2016-08-23 19:11:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/23d544bcd7d9a16b10d11a10de2c868daad6c67e', 'message': 'Modify sql banned operations for each of the new repos\n\nThis patch covers all the regular table and column operations\nacross the four repos. It does not, however, check for triggers\nand indexes - which will be done in a separate patch.\n\nPartial-Bug: #1615024\nChange-Id: Ia012c614b9a5b9af6b8bb447b39a9901caaf1fb5\n'}, {'number': 4, 'created': '2016-08-24 21:03:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/a0934dbc87ff88554c9673d4e3240aaa9a8caf6c', 'message': 'Modify sql banned operations for each of the new repos\n\nThis patch covers all the regular table and column operations\nacross the four repos. It does not, however, check for triggers\nand indexes - which will be done in a separate patch.\n\nPartial-Bug: #1615024\nChange-Id: Ia012c614b9a5b9af6b8bb447b39a9901caaf1fb5\n'}, {'number': 5, 'created': '2016-08-25 12:37:39.000000000', 'files': ['keystone/tests/unit/test_sql_banned_operations.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/743e1102c83b41953b039ea02aa19534336797d6', 'message': ""Modify sql banned operations for each of the new repos\n\nThis patch covers all the regular table and column operations\nacross the four repos. It does not, however, check for triggers\nand indexes - which will be done in a separate patch.\n\nLimitations: Due to the fact that migrating versions causes an\nimplicit table update (to increase the version number) we don't\nyet include checking agains inappropriate table updates of our\nown tables in the expand and data migration phases.\n\nPartial-Bug: #1615024\nChange-Id: Ia012c614b9a5b9af6b8bb447b39a9901caaf1fb5\n""}]",11,358723,743e1102c83b41953b039ea02aa19534336797d6,22,6,5,5707,,,0,"Modify sql banned operations for each of the new repos

This patch covers all the regular table and column operations
across the four repos. It does not, however, check for triggers
and indexes - which will be done in a separate patch.

Limitations: Due to the fact that migrating versions causes an
implicit table update (to increase the version number) we don't
yet include checking agains inappropriate table updates of our
own tables in the expand and data migration phases.

Partial-Bug: #1615024
Change-Id: Ia012c614b9a5b9af6b8bb447b39a9901caaf1fb5
",git fetch https://review.opendev.org/openstack/keystone refs/changes/23/358723/4 && git format-patch -1 --stdout FETCH_HEAD,['keystone/tests/unit/test_sql_banned_operations.py'],1,83474bbed017663f7114d5254ced8e3e87de9465,bug/1615024,"from migrate.versioning import api as versioning_apifrom keystone.common.sql import contract_repo from keystone.common.sql import data_migration_repo def __init__(self, banned_ops=None, migration_repo=migrate_repo.__file__): self._banned_ops = banned_ops or {} self._migration_repo = migration_repo def _explode(resource_op, repo): # Extract the repo name prior to the trailing '/__init__.py' repo_name = repo.split('/')[-2] 'Operation %s() is not allowed in %s database migrations' % ( resource_op, repo_name)) explode_lambda = { 'Table.create': lambda *a, **k: self._explode( 'Table.create', self._migration_repo), 'Table.alter': lambda *a, **k: self._explode( 'Table.alter', self._migration_repo), 'Table.drop': lambda *a, **k: self._explode( 'Table.drop', self._migration_repo), 'Table.insert': lambda *a, **k: self._explode( 'Table.insert', self._migration_repo), 'Table.update': lambda *a, **k: self._explode( 'Table.update', self._migration_repo), 'Table.delete': lambda *a, **k: self._explode( 'Table.delete', self._migration_repo), 'Column.create': lambda *a, **k: self._explode( 'Column.create', self._migration_repo), 'Column.alter': lambda *a, **k: self._explode( 'Column.alter', self._migration_repo), 'Column.drop': lambda *a, **k: self._explode( 'Column.drop', self._migration_repo) } for resource in self._banned_ops: for op in self._banned_ops[resource]: resource_op = '%(resource)s.%(op)s' % { 'resource': resource, 'op': op} self.useFixture(fixtures.MonkeyPatch( 'sqlalchemy.%s' % resource_op, explode_lambda[resource_op])) """"""Test column operations raise DBOperationNotAllowed."""""" with BannedDBSchemaOperations( banned_ops={'Column': ['create', 'alter', 'drop']}): self.assertRaises(DBOperationNotAllowed, column.create) """"""Test table operations raise DBOperationNotAllowed."""""" with BannedDBSchemaOperations( banned_ops={'Table': ['create', 'alter', 'drop', 'insert', 'update', 'delete']}): self.assertRaises(DBOperationNotAllowed, table.create) self.assertRaises(DBOperationNotAllowed, table.insert) self.assertRaises(DBOperationNotAllowed, table.update) self.assertRaises(DBOperationNotAllowed, table.delete) # NOTE(xek): We start requiring things be additive in Newton, so # ignore all migrations before the first version in Newton. migrate_file = migrate_repo.__file__ first_version = 101 # NOTE(henry-nash): We don't ban data modification in the legacy repo, # since there are already migrations that do this for Newton (and these # do not cause us issues, or are already worked around). banned_ops = {'Table': ['alter', 'drop'], 'Column': ['alter', 'drop']} exceptions = [ # NOTE(xek): Reviewers: DO NOT ALLOW THINGS TO BE ADDED HERE UNLESS # JUSTIFICATION CAN BE PROVIDED AS TO WHY THIS WILL NOT CAUSE # PROBLEMS FOR ROLLING UPGRADES. # Migration 102 drops the domain table in the Newton release. All # code that referenced the domain table was removed in the Mitaka # release, hence this migration will not cause problems when # running a mixture of Mitaka and Newton versions of keystone. 102, # Migration 106 simply allows the password column to be nullable. # This change would not impact a rolling upgrade. 106 ] return migration_helpers.get_init_version( abs_path=os.path.abspath(os.path.dirname(self.migrate_file))) os.path.abspath(os.path.dirname(self.migrate_file)) def migrate_fully(self, repo_name): abs_path = os.path.abspath(os.path.dirname(repo_name)) init_version = migration_helpers.get_init_version(abs_path=abs_path) schema = versioning_api.ControlledSchema.create( self.migrate_engine, abs_path, init_version) max_version = schema.repository.version().version upgrade = True err = '' version = versioning_api._migrate_version( schema, max_version, upgrade, err) schema.upgrade(version) # self.exceptions contains a list of migrations where we allow the # banned operations. Only Migrations which don't cause # incompatibilities are allowed, for example dropping an index or # constraint. if version >= self.first_version and version not in self.exceptions: banned_ops = self.banned_ops else: banned_ops = None with BannedDBSchemaOperations(banned_ops, self.migrate_file):class TestKeystoneExpandSchemaMigrations( KeystoneMigrationsCheckers): migrate_file = expand_repo.__file__ first_version = 1 # NOTE(henry-nash): we should include Table update here as well, but this # causes the update of the migration version to appear as a banned # operation! banned_ops = {'Table': ['alter', 'drop', 'insert', 'delete'], 'Column': ['alter', 'drop']} exceptions = [ # NOTE(xek, henry-nash): Reviewers: DO NOT ALLOW THINGS TO BE ADDED # HERE UNLESS JUSTIFICATION CAN BE PROVIDED AS TO WHY THIS WILL NOT # CAUSE PROBLEMS FOR ROLLING UPGRADES. ] def setUp(self): super(TestKeystoneExpandSchemaMigrations, self).setUp() self.migrate_fully(migrate_repo.__file__) TestKeystoneExpandSchemaMigrations, test_base.MySQLOpportunisticTestCase): pass TestKeystoneExpandSchemaMigrations, test_base.PostgreSQLOpportunisticTestCase): pass class TestKeystoneDataMigrations( KeystoneMigrationsCheckers): migrate_file = data_migration_repo.__file__ first_version = 1 banned_ops = {'Table': ['create', 'alter', 'drop'], 'Column': ['create', 'alter', 'drop']} exceptions = [ # NOTE(xek, henry-nash): Reviewers: DO NOT ALLOW THINGS TO BE ADDED # HERE UNLESS JUSTIFICATION CAN BE PROVIDED AS TO WHY THIS WILL NOT # CAUSE PROBLEMS FOR ROLLING UPGRADES. ] def setUp(self): super(TestKeystoneDataMigrations, self).setUp() self.migrate_fully(migrate_repo.__file__) self.migrate_fully(expand_repo.__file__) class TestKeystoneDataMigrationsMySQL( TestKeystoneDataMigrations, test_base.MySQLOpportunisticTestCase): pass class TestKeystoneDataMigrationsPostgreSQL( TestKeystoneDataMigrations, test_base.PostgreSQLOpportunisticTestCase): pass class TestKeystoneDataMigrationsSQLite( TestKeystoneDataMigrations, test_base.DbTestCase): pass class TestKeystoneContractSchemaMigrations( KeystoneMigrationsCheckers): migrate_file = contract_repo.__file__ first_version = 1 # NOTE(henry-nash): we should include Table update here as well, but this # causes the update of the migration version to appear as a banned # operation! banned_ops = {'Table': ['create', 'insert', 'delete'], 'Column': ['create']} exceptions = [ # NOTE(xek, henry-nash): Reviewers: DO NOT ALLOW THINGS TO BE ADDED # HERE UNLESS JUSTIFICATION CAN BE PROVIDED AS TO WHY THIS WILL NOT # CAUSE PROBLEMS FOR ROLLING UPGRADES. ] def setUp(self): super(TestKeystoneContractSchemaMigrations, self).setUp() self.migrate_fully(migrate_repo.__file__) self.migrate_fully(expand_repo.__file__) self.migrate_fully(data_migration_repo.__file__) class TestKeystoneContractSchemaMigrationsMySQL( TestKeystoneContractSchemaMigrations, test_base.MySQLOpportunisticTestCase): pass class TestKeystoneContractSchemaMigrationsPostgreSQL( TestKeystoneContractSchemaMigrations, test_base.PostgreSQLOpportunisticTestCase): pass class TestKeystoneContractSchemaMigrationsSQLite( TestKeystoneContractSchemaMigrations, test_base.DbTestCase): # In Sqlite an alter will appear as a create, so if we check for creates # we will get false positives. def setUp(self): super(TestKeystoneContractSchemaMigrationsSQLite, self).setUp() self.banned_ops['Table'].remove('create')"," def __init__(self, banned_resources=None): self._banned_resources = banned_resources or [] def _explode(resource, op): 'Operation %s.%s() is not allowed in a database migration' % ( resource, op)) for resource in self._banned_resources: self.useFixture(fixtures.MonkeyPatch( 'sqlalchemy.%s.drop' % resource, lambda *a, **k: self._explode(resource, 'drop'))) self.useFixture(fixtures.MonkeyPatch( 'sqlalchemy.%s.alter' % resource, lambda *a, **k: self._explode(resource, 'alter'))) """"""Test column drops and alters raise DBOperationNotAllowed."""""" with BannedDBSchemaOperations(banned_resources=['Column']): """"""Test table drops and alters raise DBOperationNotAllowed."""""" with BannedDBSchemaOperations(banned_resources=['Table']): return migration_helpers.get_init_version() migrate_file = migrate_repo.__file__ os.path.abspath(os.path.dirname(migrate_file)) # This is a list of migrations where we allow dropping and altering # things. The rules for adding exceptions are very specific: # # 1) Migrations which don't cause incompatibilities are allowed, # for example dropping an index or constraint. # # 2) Migrations removing structures not used in the previous version # are allowed (we keep compatibility between releases), ex.: # # a) feature is deprecated according to the deprecation policies # (release 1), # # b) code supporting the feature is removed the following release # (release 2), # # c) table can be dropped a release after the code has been removed # (i.e. in release 3). # # 3) Any other changes which don't pass this test are disallowed. exceptions = [ # NOTE(xek): Reviewers: DO NOT ALLOW THINGS TO BE ADDED HERE UNLESS # JUSTIFICATION CAN BE PROVIDED AS TO WHY THIS WILL NOT CAUSE # PROBLEMS FOR ROLLING UPGRADES. # Migration 102 drops the domain table in the Newton release. All # code that referenced the domain table was removed in the Mitaka # release, hence this migration will not cause problems when # running a mixture of Mitaka and Newton versions of keystone. 102, # Migration 106 simply allows the password column to be nullable. # This change would not impact a rolling upgrade. 106 ] # NOTE(xek): We start requiring things be additive in Newton, so # ignore all migrations before that point. NEWTON_START = 101 if version >= NEWTON_START and version not in exceptions: banned = ['Table', 'Column'] else: banned = None with BannedDBSchemaOperations(banned): KeystoneMigrationsCheckers, test_base.MySQLOpportunisticTestCase): @property def INIT_VERSION(self): return migration_helpers.get_init_version( abs_path=os.path.abspath(os.path.dirname(expand_repo.__file__))) @property def REPOSITORY(self): migrate_file = expand_repo.__file__ return repository.Repository( os.path.abspath(os.path.dirname(migrate_file)) ) KeystoneMigrationsCheckers, test_base.PostgreSQLOpportunisticTestCase): @property def INIT_VERSION(self): return migration_helpers.get_init_version( abs_path=os.path.abspath(os.path.dirname(expand_repo.__file__))) @property def REPOSITORY(self): migrate_file = expand_repo.__file__ return repository.Repository( os.path.abspath(os.path.dirname(migrate_file)) ) class TestKeystoneExpandSchemaMigrationsSQLite( KeystoneMigrationsCheckers, test_base.DbTestCase): @property def INIT_VERSION(self): return migration_helpers.get_init_version( abs_path=os.path.abspath(os.path.dirname(expand_repo.__file__))) @property def REPOSITORY(self): migrate_file = expand_repo.__file__ return repository.Repository( os.path.abspath(os.path.dirname(migrate_file)) )",202,100
openstack%2Fneutron-lbaas~master~I54d400dea4efdf9ac9b580ff7f0a2bbcceb4df5e,openstack/neutron-lbaas,master,I54d400dea4efdf9ac9b580ff7f0a2bbcceb4df5e,Use temporary directory for neutron install,MERGED,2016-08-28 06:29:35.000000000,2016-08-29 05:10:51.000000000,2016-08-29 05:10:51.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 9008}, {'_account_id': 11628}, {'_account_id': 11685}]","[{'number': 1, 'created': '2016-08-28 06:29:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-lbaas/commit/0df9be24e0b752000cbe18fbfb182a7be21dd343', 'message': ""Use temporary directory for neutron install\n\nDo not install in /tmp/openstack/neutron and leave the git repository\nthere after the script is run - if zuul-cloner is used.\n\nWe run jobs on long lived workers and also on developers machines, let's\ncleanup afterwards.\n\nInstall into a temporary directory and remove the created afterwards.\n\nChange-Id: I54d400dea4efdf9ac9b580ff7f0a2bbcceb4df5e\n""}, {'number': 2, 'created': '2016-08-28 09:22:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-lbaas/commit/658a2eb31aa4736aef168e0103c56cf2c2afd830', 'message': ""Use temporary directory for neutron install\n\nDo not install in /tmp/openstack/neutron and leave the git repository\nthere after the script is run - if zuul-cloner is used.\n\nWe run jobs on long lived workers and also on developers machines, let's\ncleanup afterwards.\n\nInstall into a temporary directory and remove the created afterwards.\n\nChange-Id: I54d400dea4efdf9ac9b580ff7f0a2bbcceb4df5e\n""}, {'number': 3, 'created': '2016-08-28 09:23:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-lbaas/commit/35d575361ef15bd153fdfc2d245caa50d06aeec0', 'message': ""Use temporary directory for neutron install\n\nDo not install in /tmp/openstack/neutron and leave the git repository\nthere after the script is run - if zuul-cloner is used.\n\nWe run jobs on long lived workers and also on developers machines, let's\ncleanup afterwards.\n\nInstall into a temporary directory and remove the created afterwards.\n\nAlso, remove setup of ZUUL_BRANCH, this is not needed with current zuul\nanymore.\n\nChange-Id: I54d400dea4efdf9ac9b580ff7f0a2bbcceb4df5e\n""}, {'number': 4, 'created': '2016-08-28 09:34:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-lbaas/commit/fa0120c9d4ba94b1e68027b81e353ba6a0944c6d', 'message': ""Use temporary directory for neutron install\n\nDo not install in /tmp/openstack/neutron and leave the git repository\nthere after the script is run - if zuul-cloner is used.\n\nWe run jobs on long lived workers and also on developers machines, let's\ncleanup afterwards.\n\nInstall into a temporary directory and remove the created afterwards.\nSimplify with using pushd/popd which are bash features, so change\nshe-bang.\n\nAlso, remove setup of ZUUL_BRANCH, this is not needed with current zuul\nanymore.\n\nChange-Id: I54d400dea4efdf9ac9b580ff7f0a2bbcceb4df5e\n""}, {'number': 5, 'created': '2016-08-28 09:46:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-lbaas/commit/c31356453ef7aa1ba562c9b1b34e5a490b9bcd3f', 'message': ""Use temporary directory for neutron install\n\nDo not install in /tmp/openstack/neutron and leave the git repository\nthere after the script is run - if zuul-cloner is used.\n\nWe run jobs on long lived workers and also on developers machines, let's\ncleanup afterwards.\n\nInstall into a temporary directory and remove the created afterwards.\nSimplify with using pushd/popd which are bash features, so change\nshe-bang.\n\nAlso, remove setup of ZUUL_BRANCH, this is not needed with current zuul\nanymore.\n\nChange-Id: I54d400dea4efdf9ac9b580ff7f0a2bbcceb4df5e\n""}, {'number': 6, 'created': '2016-08-28 10:12:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-lbaas/commit/71fcc0807643b72e4743cab2f554512a6023c1d9', 'message': 'Use temporary directory for neutron install\n\nDo not install in /tmp/openstack/neutron and leave the git repository\nthere after the script is run - if zuul-cloner is used.\n\nWe run jobs on long lived workers and also on developers machines, let\'s\ncleanup afterwards.\n\nInstall into a temporary directory that can be removed with ""git clean""\nafterwards.\nSimplify with using pushd/popd which are bash features, so change\nshe-bang.\n\nAlso, remove setup of ZUUL_BRANCH, this is not needed with current zuul\nanymore.\n\nChange-Id: I54d400dea4efdf9ac9b580ff7f0a2bbcceb4df5e\n'}, {'number': 7, 'created': '2016-08-28 10:38:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-lbaas/commit/cf6b096670ee6425d8a6d8add6abfa08fa78e9e0', 'message': 'Use temporary directory for neutron install\n\nDo not install in /tmp/openstack/neutron and leave the git repository\nthere after the script is run - if zuul-cloner is used.\n\nWe run jobs on long lived workers and also on developers machines, let\'s\ncleanup afterwards.\n\nInstall into a temporary directory that can be removed with ""git clean""\nafterwards.\nSimplify with using pushd/popd which are bash features, so change\nshe-bang.\n\nAlso, remove setup of ZUUL_BRANCH, this is not needed with current zuul\nanymore.\n\nChange-Id: I54d400dea4efdf9ac9b580ff7f0a2bbcceb4df5e\n'}, {'number': 8, 'created': '2016-08-28 12:26:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-lbaas/commit/475d2c24e58d65dda6a6b77b43944844a41a64f8', 'message': 'Use temporary directory for neutron install\n\nDo not install in /tmp/openstack/neutron and leave the git repository\nthere after the script is run - if zuul-cloner is used.\n\nWe run jobs on long lived workers and also on developers machines, let\'s\ncleanup afterwards.\n\nInstall into a temporary directory that can be removed with ""git clean""\nafterwards.\nSimplify with using pushd/popd which are bash features, so change\nshe-bang.\n\nAlso, remove setup of ZUUL_BRANCH, this is not needed with current zuul\nanymore.\n\nChange-Id: I54d400dea4efdf9ac9b580ff7f0a2bbcceb4df5e\n'}, {'number': 9, 'created': '2016-08-28 12:39:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-lbaas/commit/602a538a209fcb29cfc6a886dc05a94b82c834a4', 'message': 'Use temporary directory for neutron install\n\nDo not install in /tmp/openstack/neutron and leave the git repository\nthere after the script is run - if zuul-cloner is used.\n\nWe run jobs on long lived workers and also on developers machines, let\'s\ncleanup afterwards.\n\nInstall into a temporary directory that can be removed with ""git clean""\nafterwards. Add this directory to ignore list of pep8.\n\nSimplify with using pushd/popd which are bash features, so change\nshe-bang.\n\nAlso, remove setup of ZUUL_BRANCH, this is not needed with current zuul\nanymore.\n\nChange-Id: I54d400dea4efdf9ac9b580ff7f0a2bbcceb4df5e\n'}, {'number': 10, 'created': '2016-08-28 17:11:05.000000000', 'files': ['tools/tox_install.sh', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/neutron-lbaas/commit/30ea768a8f83c76494b0c51caa948d1e68b3675d', 'message': 'Use temporary directory for neutron install\n\nDo not install in /tmp/openstack/neutron and leave the git repository\nthere after the script is run - if zuul-cloner is used.\n\nWe run jobs on long lived workers and also on developers machines, let\'s\ncleanup afterwards.\n\nInstall into a temporary directory that can be removed with ""git clean""\nafterwards. Add this directory to ignore list of pep8.\n\nSimplify with using pushd/popd which are bash features, so change\nshe-bang.\n\nAlso, remove setup of ZUUL_BRANCH, this is not needed with current zuul\nanymore.\n\nChange-Id: I54d400dea4efdf9ac9b580ff7f0a2bbcceb4df5e\n'}]",0,361695,30ea768a8f83c76494b0c51caa948d1e68b3675d,27,5,10,6547,,,0,"Use temporary directory for neutron install

Do not install in /tmp/openstack/neutron and leave the git repository
there after the script is run - if zuul-cloner is used.

We run jobs on long lived workers and also on developers machines, let's
cleanup afterwards.

Install into a temporary directory that can be removed with ""git clean""
afterwards. Add this directory to ignore list of pep8.

Simplify with using pushd/popd which are bash features, so change
she-bang.

Also, remove setup of ZUUL_BRANCH, this is not needed with current zuul
anymore.

Change-Id: I54d400dea4efdf9ac9b580ff7f0a2bbcceb4df5e
",git fetch https://review.opendev.org/openstack/neutron-lbaas refs/changes/95/361695/9 && git format-patch -1 --stdout FETCH_HEAD,['tools/tox_install.sh'],1,0df9be24e0b752000cbe18fbfb182a7be21dd343,tox_install," export NEUTRON_DIR=$(/bin/mktemp -d) trap ""rm -rf $NEUTRON_DIR"" EXIT pushdir $NEUTRON_DIR popd"," cwd=$(/bin/pwd) cd /tmp cd ""$cwd""",4,3
openstack%2Fheat~master~I7f3ba21507ab7f72ce8434106aa6bed1d8647f2f,openstack/heat,master,I7f3ba21507ab7f72ce8434106aa6bed1d8647f2f,Correct mistaken parameters of test_hacking.py in tests,MERGED,2016-08-05 08:55:27.000000000,2016-08-29 04:47:19.000000000,2016-08-29 04:47:19.000000000,"[{'_account_id': 3}, {'_account_id': 8833}, {'_account_id': 12404}, {'_account_id': 16237}, {'_account_id': 22863}]","[{'number': 1, 'created': '2016-08-05 08:55:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/b3c8c4ff78498d79f5e533dcf354e02ef0a0af9c', 'message': ""Remove  openstack/common from the exclude list of flake8 in tox\n\nThe Oslo team has moved all previously incubated code from the\n'openstack/oslo-incubator' repository into separate library\nrepositories and released those libraries to the Python Package\nIndex, so the directory should be removed.\n\nChange-Id: I7f3ba21507ab7f72ce8434106aa6bed1d8647f2f\n""}, {'number': 2, 'created': '2016-08-05 08:59:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/d036c40606916554b9f66ca78d878ffba72d13c2', 'message': ""Remove  openstack/common from the exclude list of flake8 in tox\n\nThe Oslo team has moved all previously incubated code from the\n'openstack/oslo-incubator' repository into separate library\nrepositories and released those libraries to the Python Package\nIndex, so the directory should be removed.\n\nChange-Id: I7f3ba21507ab7f72ce8434106aa6bed1d8647f2f\n""}, {'number': 3, 'created': '2016-08-05 10:50:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/df01131eb5959b9e342540b6b53c0edf84a3f69a', 'message': ""Remove  openstack/common from the exclude list of flake8 in tox\n\nThe Oslo team has moved all previously incubated code from the\n'openstack/oslo-incubator' repository into separate library\nrepositories and released those libraries to the Python Package\nIndex, so the directory should be removed.Then modify some small\ncases relating to formation in heat/openstack/common.\n\nChange-Id: I7f3ba21507ab7f72ce8434106aa6bed1d8647f2f\n""}, {'number': 4, 'created': '2016-08-17 06:41:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/ff1a0fcd22e43e5607f4bce0cf601fac68a8d8fe', 'message': 'qModify some mistaken parameters in test_hacking.py\n\nChange-Id: I7f3ba21507ab7f72ce8434106aa6bed1d8647f2f\n'}, {'number': 5, 'created': '2016-08-17 06:53:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/a20eea8607625eca1560e68a0b79b4895cc98817', 'message': 'Modify some mistaken parameters in test_hacking.py\n\nChange-Id: I7f3ba21507ab7f72ce8434106aa6bed1d8647f2f\n'}, {'number': 6, 'created': '2016-08-17 10:38:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/96129cbf92b0504465f747065fe5fbe0b5423953', 'message': 'Modify three mistaken parameters in test_hacking.py\n\nChange-Id: I7f3ba21507ab7f72ce8434106aa6bed1d8647f2f\n'}, {'number': 7, 'created': '2016-08-19 02:09:28.000000000', 'files': ['heat/tests/test_hacking.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/9a768ce5c9d9dcd80ea38773ac240b28188bf7d2', 'message': 'Correct mistaken parameters of test_hacking.py in tests\n\nChange-Id: I7f3ba21507ab7f72ce8434106aa6bed1d8647f2f\n'}]",0,351584,9a768ce5c9d9dcd80ea38773ac240b28188bf7d2,20,5,7,22863,,,0,"Correct mistaken parameters of test_hacking.py in tests

Change-Id: I7f3ba21507ab7f72ce8434106aa6bed1d8647f2f
",git fetch https://review.opendev.org/openstack/heat refs/changes/84/351584/2 && git format-patch -1 --stdout FETCH_HEAD,"['heat_key.priv', 'tox.ini']",2,b3c8c4ff78498d79f5e533dcf354e02ef0a0af9c,del-olso,"exclude=.*,dist,*lib/python*,*egg,build,*convergence/scenarios/*","exclude=.*,dist,*openstack/common*,*lib/python*,*egg,build,*convergence/scenarios/*",29,1
openstack%2Fkeystone~master~I8a83dd91d0cde7af2a10e02b75659704baad5496,openstack/keystone,master,I8a83dd91d0cde7af2a10e02b75659704baad5496,Remove mapping schema from the doc,MERGED,2016-08-26 14:33:29.000000000,2016-08-29 04:46:54.000000000,2016-08-29 04:46:54.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 1916}, {'_account_id': 2218}, {'_account_id': 2903}, {'_account_id': 5046}, {'_account_id': 5707}, {'_account_id': 6482}, {'_account_id': 6486}, {'_account_id': 7191}, {'_account_id': 7725}, {'_account_id': 8119}, {'_account_id': 8571}, {'_account_id': 11022}, {'_account_id': 13063}, {'_account_id': 17860}, {'_account_id': 23058}]","[{'number': 1, 'created': '2016-08-26 14:33:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/b2e24c45b4b3f780725272392201fb021da592ea', 'message': 'Update mapping schema in the docs.\n\nMapping schema in documentation should reflect schema in the codebase.\n\nChange-Id: I8a83dd91d0cde7af2a10e02b75659704baad5496\n'}, {'number': 2, 'created': '2016-08-26 14:43:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/a670d36e8e45296cae272056cab5f6d709928597', 'message': 'Update mapping schema in the docs.\n\nMapping schema in documentation should reflect schema in the codebase.\nCloses-bug: #1617361\nChange-Id: I8a83dd91d0cde7af2a10e02b75659704baad5496\n'}, {'number': 3, 'created': '2016-08-28 10:12:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/0dabbc524c73e1498d6e2273b25887b2ef598cf4', 'message': 'Update mapping schema in the docs.\n\nMapping schema in documentation should reflect schema in the codebase.\nCloses-bug: #1617361\nChange-Id: I8a83dd91d0cde7af2a10e02b75659704baad5496\n'}, {'number': 4, 'created': '2016-08-28 16:35:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/addd65ab3f9f5ef0e420d09085dd15b835b6c2c1', 'message': 'Update mapping schema in the docs.\n\nMapping schema in documentation should reflect schema in the codebase.\nCloses-bug: #1617361\nChange-Id: I8a83dd91d0cde7af2a10e02b75659704baad5496\n'}, {'number': 5, 'created': '2016-08-28 16:47:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/ac002d9230411f5b011efed157a7dd786e8b0f5d', 'message': 'Update mapping schema in the docs.\n\nMapping schema in documentation should reflect schema in the codebase.\nCloses-bug: #1617361\nChange-Id: I8a83dd91d0cde7af2a10e02b75659704baad5496\n'}, {'number': 6, 'created': '2016-08-29 02:22:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/0dbb1b2b0676e6e6e9085caab0a593318c4ad48e', 'message': 'Update mapping schema in the docs.\n\nMapping schema in documentation should reflect schema in the codebase.\nCloses-bug: #1617361\nChange-Id: I8a83dd91d0cde7af2a10e02b75659704baad5496\n'}, {'number': 7, 'created': '2016-08-29 02:30:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/2bb3f9a5fa3bf5bd0dba0d509fafa4e15b9e8907', 'message': 'The mapping schema is now super long and complex, and anyone interested\nin it can go to our code base and read about it, no need to track in\nthe doc.\n\nMapping schema in documentation should reflect schema in the codebase.\nCloses-bug: #1617361\nChange-Id: I8a83dd91d0cde7af2a10e02b75659704baad5496\n'}, {'number': 8, 'created': '2016-08-29 02:31:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/457834faa2a206285ae1c0b09dd3ee8c4f687fcd', 'message': 'Remove mapping schema from the doc\n\nThe mapping schema is now super long and complex, and anyone interested\nin it can go to our code base and read about it, no need to track in\nthe doc.\n\nMapping schema in documentation should reflect schema in the codebase.\nCloses-bug: #1617361\nChange-Id: I8a83dd91d0cde7af2a10e02b75659704baad5496\n'}, {'number': 9, 'created': '2016-08-29 02:33:04.000000000', 'files': ['doc/source/federation/mapping_combinations.rst', 'doc/source/federation/federated_identity.rst', 'doc/source/federation/mapping_schema.rst'], 'web_link': 'https://opendev.org/openstack/keystone/commit/c613dd3a6cad8f5c328b7f1ef3ecf449464e7356', 'message': 'Remove mapping schema from the doc\n\nThe mapping schema is now super long and complex, and anyone interested\nin it can go to our code base and read about it, no need to track in\nthe doc.\n\nCloses-bug: #1617361\nChange-Id: I8a83dd91d0cde7af2a10e02b75659704baad5496\n'}]",2,361252,c613dd3a6cad8f5c328b7f1ef3ecf449464e7356,34,17,9,8978,,,0,"Remove mapping schema from the doc

The mapping schema is now super long and complex, and anyone interested
in it can go to our code base and read about it, no need to track in
the doc.

Closes-bug: #1617361
Change-Id: I8a83dd91d0cde7af2a10e02b75659704baad5496
",git fetch https://review.opendev.org/openstack/keystone refs/changes/52/361252/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/federation/mapping_schema.rst'],1,b2e24c45b4b3f780725272392201fb021da592ea,bug/1617361," ""type"": ""array"", ""items"": { ""type"": ""object"", ""additionalProperties"": False, ""properties"": { ""user"": { ""type"": ""object"", ""properties"": { ""id"": {""type"": ""string""}, ""name"": {""type"": ""string""}, ""email"": {""type"": ""string""}, ""domain"": { ""$ref"": ""#/definitions/domain"" }, ""type"": { ""type"": ""string"", ""enum"": [""local"", ""remote""] } }, ""additionalProperties"": False }, ""group"": { ""type"": ""object"", ""oneOf"": [ {""$ref"": ""#/definitions/group_by_id""}, {""$ref"": ""#/definitions/group_by_name""} ] }, ""groups"": { ""type"": ""string"" }, ""group_ids"": { ""type"": ""string"" }, ""domain"": {""$ref"": ""#/definitions/domain""}, } } }, ""domain"": { ""type"": ""object"", ""properties"": { ""id"": {""type"": ""string""}, ""name"": {""type"": ""string""} }, ""additionalProperties"": False }, ""group_by_id"": { ""type"": ""object"", ""properties"": { ""id"": {""type"": ""string""} }, ""additionalProperties"": False, ""required"": [""id""] }, ""group_by_name"": { ""type"": ""object"", ""properties"": { ""name"": {""type"": ""string""}, ""domain"": {""$ref"": ""#/definitions/domain""} }, ""additionalProperties"": False, ""required"": [""name"", ""domain""]"," ""type"": ""array""",63,1
openstack%2Fkolla~master~I7556d6cd473516c7ceb4aba7c1ba1130af2544ee,openstack/kolla,master,I7556d6cd473516c7ceb4aba7c1ba1130af2544ee,Customizations for Nova,MERGED,2016-08-05 11:53:10.000000000,2016-08-29 04:44:50.000000000,2016-08-29 04:44:50.000000000,"[{'_account_id': 3}, {'_account_id': 979}, {'_account_id': 1390}, {'_account_id': 7488}, {'_account_id': 10787}, {'_account_id': 11105}, {'_account_id': 16482}, {'_account_id': 19316}, {'_account_id': 22165}]","[{'number': 1, 'created': '2016-08-05 11:53:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/a0847169ad9f713a1c7fb95ae607277fc1042e92', 'message': 'Customizations for Nova\n\nChange-Id: I7556d6cd473516c7ceb4aba7c1ba1130af2544ee\nPartially-implements: blueprint third-party-plugin-support\n'}, {'number': 2, 'created': '2016-08-05 14:07:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/0ebb4b1992f0c917ebb01f7d07f6c0f248c7222a', 'message': 'Customizations for Nova\n\nChange-Id: I7556d6cd473516c7ceb4aba7c1ba1130af2544ee\nPartially-implements: blueprint third-party-plugin-support\n'}, {'number': 3, 'created': '2016-08-05 14:13:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/ded7d0ed6920dbe502b4634a4dc891abb59a371e', 'message': 'Customizations for Nova\n\nChange-Id: I7556d6cd473516c7ceb4aba7c1ba1130af2544ee\nPartially-implements: blueprint third-party-plugin-support\n'}, {'number': 4, 'created': '2016-08-05 16:26:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/871d0dd1087c69ab9431bbfb390252560abbdc04', 'message': 'Customizations for Nova\n\nChange-Id: I7556d6cd473516c7ceb4aba7c1ba1130af2544ee\nPartially-implements: blueprint third-party-plugin-support\n'}, {'number': 5, 'created': '2016-08-08 10:10:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/9ec30b32815d22a7a941f4586d408b7540b824a3', 'message': 'Customizations for Nova\n\nChange-Id: I7556d6cd473516c7ceb4aba7c1ba1130af2544ee\nPartially-implements: blueprint third-party-plugin-support\n'}, {'number': 6, 'created': '2016-08-09 09:46:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/9d43c496f690b7f58567eff0948959c0592a59e6', 'message': 'Customizations for Nova\n\nChange-Id: I7556d6cd473516c7ceb4aba7c1ba1130af2544ee\nPartially-implements: blueprint third-party-plugin-support\n'}, {'number': 7, 'created': '2016-08-09 13:20:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/37f1e805cb234de289602352e7379186d920f7be', 'message': 'Customizations for Nova\n\nChange-Id: I7556d6cd473516c7ceb4aba7c1ba1130af2544ee\nPartially-implements: blueprint third-party-plugin-support\n'}, {'number': 8, 'created': '2016-08-10 11:51:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/031b8deaacb9ed4d6cdf687927777f603b8855b0', 'message': 'Customizations for Nova\n\nChange-Id: I7556d6cd473516c7ceb4aba7c1ba1130af2544ee\nPartially-implements: blueprint third-party-plugin-support\n'}, {'number': 9, 'created': '2016-08-19 14:17:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/76646dcc7e8b77c3bde8f53d25532227c17649b6', 'message': 'Customizations for Nova\n\nChange-Id: I7556d6cd473516c7ceb4aba7c1ba1130af2544ee\nPartially-implements: blueprint third-party-plugin-support\n'}, {'number': 10, 'created': '2016-08-23 11:46:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/ed986eb9946a8c4d349749600322023df6421d1e', 'message': 'Customizations for Nova\n\nChange-Id: I7556d6cd473516c7ceb4aba7c1ba1130af2544ee\nPartially-implements: blueprint third-party-plugin-support\n'}, {'number': 11, 'created': '2016-08-24 11:18:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/e8a3bd197bad0b943806e5eea6b6cf258e47d8b9', 'message': 'Customizations for Nova\n\nChange-Id: I7556d6cd473516c7ceb4aba7c1ba1130af2544ee\nPartially-implements: blueprint third-party-plugin-support\n'}, {'number': 12, 'created': '2016-08-24 15:05:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/267c25ace9ef442313e49f130fdca3feb573c1b5', 'message': 'Customizations for Nova\n\nChange-Id: I7556d6cd473516c7ceb4aba7c1ba1130af2544ee\nPartially-implements: blueprint third-party-plugin-support\n'}, {'number': 13, 'created': '2016-08-25 12:02:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/f3b98c1937e8a6c157c74d6c589ed554371a84e7', 'message': 'Customizations for Nova\n\nChange-Id: I7556d6cd473516c7ceb4aba7c1ba1130af2544ee\nPartially-implements: blueprint third-party-plugin-support\n'}, {'number': 14, 'created': '2016-08-25 13:07:07.000000000', 'files': ['docker/nova/nova-base/Dockerfile.j2', 'docker/nova/nova-scheduler/Dockerfile.j2', 'docker/nova/nova-libvirt/Dockerfile.j2', 'docker/nova/nova-novncproxy/Dockerfile.j2', 'docker/nova/nova-ssh/Dockerfile.j2', 'docker/nova/nova-consoleauth/Dockerfile.j2', 'docker/nova/nova-conductor/Dockerfile.j2', 'docker/nova/nova-spicehtml5proxy/Dockerfile.j2', 'docker/nova/nova-compute-ironic/Dockerfile.j2', 'docker/nova/nova-api/Dockerfile.j2', 'docker/nova/nova-compute/Dockerfile.j2', 'docker/nova/nova-network/Dockerfile.j2'], 'web_link': 'https://opendev.org/openstack/kolla/commit/d3c60d0035d62ece4277f59c40aabe570539face', 'message': 'Customizations for Nova\n\nChange-Id: I7556d6cd473516c7ceb4aba7c1ba1130af2544ee\nPartially-implements: blueprint third-party-plugin-support\n'}]",24,351676,d3c60d0035d62ece4277f59c40aabe570539face,66,9,14,1390,,,0,"Customizations for Nova

Change-Id: I7556d6cd473516c7ceb4aba7c1ba1130af2544ee
Partially-implements: blueprint third-party-plugin-support
",git fetch https://review.opendev.org/openstack/kolla refs/changes/76/351676/2 && git format-patch -1 --stdout FETCH_HEAD,"['docker/nova/nova-base/Dockerfile.j2', 'docker/nova/nova-scheduler/Dockerfile.j2', 'docker/nova/nova-libvirt/Dockerfile.j2', 'docker/nova/nova-novncproxy/Dockerfile.j2', 'docker/nova/nova-ssh/Dockerfile.j2', 'docker/nova/nova-consoleauth/Dockerfile.j2', 'docker/nova/nova-conductor/Dockerfile.j2', 'docker/nova/nova-spicehtml5proxy/Dockerfile.j2', 'docker/nova/nova-compute-ironic/Dockerfile.j2', 'docker/nova/nova-api/Dockerfile.j2', 'docker/nova/nova-compute/Dockerfile.j2', 'docker/nova/nova-network/Dockerfile.j2']",12,a0847169ad9f713a1c7fb95ae607277fc1042e92,bp/third-party-plugin-support,"{% import ""macros.j2"" as macros with context %} {% set nova_network_packages = [ 'openstack-nova-network', 'bridge-utils', 'initscripts' ] %} {% set nova_network_packages = [ 'nova-network' ] %} {% set nova_network_packages = [ 'initscripts' ] %} RUN {{ macros.install_packages(nova_network_packages | customizable(""packages"")) }} {% block nova_network_footer %}{% endblock %} {% block footer %}{% endblock %}",RUN yum -y install \ openstack-nova-network \ bridge-utils \ initscripts \ && yum clean allRUN apt-get -y install --no-install-recommends \ nova-network \ && apt-get cleanRUN yum -y install \ initscripts \ && yum clean all,264,170
openstack%2Fsecurity-analysis~master~I5792ebeea31b845ad732822ea1c8e8d9030d65c0,openstack/security-analysis,master,I5792ebeea31b845ad732822ea1c8e8d9030d65c0,Update requirements,MERGED,2016-08-26 13:13:05.000000000,2016-08-29 04:40:18.000000000,2016-08-29 04:40:18.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 10497}]","[{'number': 1, 'created': '2016-08-26 13:13:05.000000000', 'files': ['bindep.txt', 'test-requirements.txt', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/security-analysis/commit/ab0e341aa0b7699796b47f74a410be9f1e56daa6', 'message': 'Update requirements\n\nRemove all unneeded requirements, also remove some extra tox targets.\nMake docs environment the default tox environment.\n\nAdd bindep.txt file so that only required packages get installed. Add\nbindep environment for tox.ini.\n\nChange-Id: I5792ebeea31b845ad732822ea1c8e8d9030d65c0\n'}]",0,361167,ab0e341aa0b7699796b47f74a410be9f1e56daa6,7,3,1,6547,,,0,"Update requirements

Remove all unneeded requirements, also remove some extra tox targets.
Make docs environment the default tox environment.

Add bindep.txt file so that only required packages get installed. Add
bindep environment for tox.ini.

Change-Id: I5792ebeea31b845ad732822ea1c8e8d9030d65c0
",git fetch https://review.opendev.org/openstack/security-analysis refs/changes/67/361167/1 && git format-patch -1 --stdout FETCH_HEAD,"['bindep.txt', 'test-requirements.txt', 'tox.ini']",3,ab0e341aa0b7699796b47f74a410be9f1e56daa6,constraints,"envlist = docsinstall_command = pip install -U {opts} {packages}[testenv:bindep] # Do not install any requirements. We want this to be fast and work even if # system dependencies are missing, since it's used to tell you what system # dependencies are missing! This also means that bindep must be installed # separately, outside of the requirements files. deps = bindep commands = bindep test ","envlist = py34,py27,pypy,pep8install_command = pip install -U {opts} {packages}commands = python setup.py test --slowest --testr-args='{posargs}' [testenv:pep8] commands = flake8 {posargs}[testenv:cover] commands = python setup.py test --coverage --testr-args='{posargs}' ",23,18
openstack%2Fsecurity-analysis~master~Ibf5b56cf2b802bdb28ba282875078640c57c82af,openstack/security-analysis,master,Ibf5b56cf2b802bdb28ba282875078640c57c82af,Cleanup tox.ini,MERGED,2016-08-26 08:52:18.000000000,2016-08-29 04:40:11.000000000,2016-08-29 04:40:11.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 9162}, {'_account_id': 10497}]","[{'number': 1, 'created': '2016-08-26 08:52:18.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/security-analysis/commit/9db40c78d630eb130e54eb556b17a7104a355543', 'message': ""Cleanup tox.ini\n\nRemove old constraints environments, those are not used anymore.\n\nNote also that this repo has not used constraints - and does not need them,\nsince it's not installed on actual systems.\n\nChange-Id: Ibf5b56cf2b802bdb28ba282875078640c57c82af\n""}]",0,360991,9db40c78d630eb130e54eb556b17a7104a355543,10,4,1,6547,,,0,"Cleanup tox.ini

Remove old constraints environments, those are not used anymore.

Note also that this repo has not used constraints - and does not need them,
since it's not installed on actual systems.

Change-Id: Ibf5b56cf2b802bdb28ba282875078640c57c82af
",git fetch https://review.opendev.org/openstack/security-analysis refs/changes/91/360991/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,9db40c78d630eb130e54eb556b17a7104a355543,constraints,"envlist = py34,py27,pypy,pep8","envlist = py34-constraints,py27-constraints,pypy-constraints,pep8-constraints constraints: {[testenv:common-constraints]install_command}[testenv:common-constraints] install_command = pip install -c{env:UPPER_CONSTRAINTS_FILE:https://git.openstack.org/cgit/openstack/requirements/plain/upper-constraints.txt} {opts} {packages} [testenv:pep8-constraints] install_command = {[testenv:common-constraints]install_command} commands = flake8 {posargs} [testenv:venv-constraints] install_command = {[testenv:common-constraints]install_command} commands = {posargs} [testenv:cover-constraints] install_command = {[testenv:common-constraints]install_command} commands = python setup.py test --coverage --testr-args='{posargs}' [testenv:docs-constraints] install_command = {[testenv:common-constraints]install_command} commands = python setup.py build_sphinx [testenv:debug] commands = oslo_debug_helper {posargs} [testenv:debug-constraints] install_command = {[testenv:common-constraints]install_command} commands = oslo_debug_helper {posargs} ",1,28
openstack%2Fopenstack-manuals~master~I8cb09eb4f8c7e7d549fb62336eb45a9ace77a8ba,openstack/openstack-manuals,master,I8cb09eb4f8c7e7d549fb62336eb45a9ace77a8ba,"[user-guide] Use ""project"" to replace ""tenant"" term in use-guide",MERGED,2016-08-18 00:45:18.000000000,2016-08-29 04:37:23.000000000,2016-08-29 04:37:23.000000000,"[{'_account_id': 3}, {'_account_id': 9162}, {'_account_id': 10497}, {'_account_id': 10607}, {'_account_id': 10897}, {'_account_id': 14643}, {'_account_id': 21486}, {'_account_id': 22165}]","[{'number': 1, 'created': '2016-08-18 00:45:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/9e077e7c76f9f440b37a8b982470b9034b7cf0d9', 'message': '[user-guide] Use ""project"" to replace ""tenant"" term in use-guide\n\nThis patch use ""project"" to replace ""tenant"" term in use-guide for cleanup.\n\nChange-Id: I8cb09eb4f8c7e7d549fb62336eb45a9ace77a8ba\n'}, {'number': 2, 'created': '2016-08-18 01:13:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/649bcb869058c6d1c3a649cff6b97ea4ad10aefa', 'message': '[user-guide] Use ""project"" to replace ""tenant"" term in use-guide\n\nThis patch use ""project"" to replace ""tenant"" term in use-guide for cleanup.\n\nPartial-Bug: #1475005\nChange-Id: I8cb09eb4f8c7e7d549fb62336eb45a9ace77a8ba\n'}, {'number': 3, 'created': '2016-08-26 13:57:33.000000000', 'files': ['doc/user-guide/source/cli-manage-bare-metal-nodes.rst', 'doc/user-guide/source/cli-launch-instances.rst', 'doc/user-guide/source/dashboard-create-networks.rst'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/51a78d9f7f6412dcf61d8ef664ed469f3091ff47', 'message': '[user-guide] Use ""project"" to replace ""tenant"" term in use-guide\n\nThis patch use ""project"" to replace ""tenant"" term in use-guide for\ncleanup.\n\nPartial-Bug: #1475005\nChange-Id: I8cb09eb4f8c7e7d549fb62336eb45a9ace77a8ba\n'}]",0,356816,51a78d9f7f6412dcf61d8ef664ed469f3091ff47,20,8,3,14151,,,0,"[user-guide] Use ""project"" to replace ""tenant"" term in use-guide

This patch use ""project"" to replace ""tenant"" term in use-guide for
cleanup.

Partial-Bug: #1475005
Change-Id: I8cb09eb4f8c7e7d549fb62336eb45a9ace77a8ba
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/16/356816/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/user-guide/source/cli-manage-bare-metal-nodes.rst', 'doc/user-guide/source/cli-launch-instances.rst', 'doc/user-guide/source/dashboard-create-networks.rst']",3,9e077e7c76f9f440b37a8b982470b9034b7cf0d9,, :guilabel:`Shared`: Share the network with other projects. Non admin users, :guilabel:`Shared`: Share the network with other tenants. Non admin users,3,3
openstack%2Fsenlin~master~I696d696914fb2d5fbead34f5c404942e6f82f741,openstack/senlin,master,I696d696914fb2d5fbead34f5c404942e6f82f741,api-ref doc for policy validation,MERGED,2016-08-29 01:56:17.000000000,2016-08-29 04:33:45.000000000,2016-08-29 04:33:45.000000000,"[{'_account_id': 3}, {'_account_id': 7404}, {'_account_id': 8246}]","[{'number': 1, 'created': '2016-08-29 01:56:17.000000000', 'files': ['api-ref/source/policies.inc'], 'web_link': 'https://opendev.org/openstack/senlin/commit/3bcc293ac8042a9a6c146a40ccc444841de51a0e', 'message': 'api-ref doc for policy validation\n\nThis adds policy-validate documentation in the api reference.\n\nChange-Id: I696d696914fb2d5fbead34f5c404942e6f82f741\n'}]",0,361791,3bcc293ac8042a9a6c146a40ccc444841de51a0e,7,3,1,8246,,,0,"api-ref doc for policy validation

This adds policy-validate documentation in the api reference.

Change-Id: I696d696914fb2d5fbead34f5c404942e6f82f741
",git fetch https://review.opendev.org/openstack/senlin refs/changes/91/361791/1 && git format-patch -1 --stdout FETCH_HEAD,['api-ref/source/policies.inc'],1,3bcc293ac8042a9a6c146a40ccc444841de51a0e,api-ref-policy-validate, Validate policy =============== .. rest_method:: POST /v1/policies/validate Validates a policy. Response Codes -------------- .. rest_status_code:: success status.yaml - 200 .. rest_status_code:: error status.yaml - 400 - 401 - 503 Request Parameters ------------------ .. rest_parameters:: parameters.yaml - OpenStack-API-Version: microversion - policy: policy - spec: policy_spec Response Parameters ------------------- The response contains properties as if the policy has been created. .. rest_parameters:: parameters.yaml - X-OpenStack-Request-Id: request_id - policy: policy - created_at: created_at - data: policy_data - domain: domain - id: policy_id - name: name - project: project - spec: policy_spec - type: policy_type_name - updated_at: updated_at - user: user,,50,0
openstack%2Fneutron~master~I6da92cb8b9fcbb603e120eababcf4ce711da3e30,openstack/neutron,master,I6da92cb8b9fcbb603e120eababcf4ce711da3e30,Implement L3 Agent Extension Manager,MERGED,2016-07-07 21:35:50.000000000,2016-08-29 04:31:58.000000000,2016-08-17 10:05:29.000000000,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 1131}, {'_account_id': 5109}, {'_account_id': 5170}, {'_account_id': 7448}, {'_account_id': 8788}, {'_account_id': 9382}, {'_account_id': 9656}, {'_account_id': 9732}, {'_account_id': 9845}, {'_account_id': 10385}, {'_account_id': 10692}, {'_account_id': 11447}, {'_account_id': 13995}, {'_account_id': 14208}, {'_account_id': 14323}, {'_account_id': 15752}, {'_account_id': 16376}, {'_account_id': 17292}, {'_account_id': 17711}, {'_account_id': 18051}, {'_account_id': 23061}]","[{'number': 1, 'created': '2016-07-07 21:35:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/2209455dd45d601ecf8bc4db0bca3faf7d938642', 'message': '[WIP] Implement L3 Agent Extension Manager\n\nUsing the generalized agent extension mechanism, create an agent extension\nmanager in the L3 agent, so that the L3 agent can load agent extensions.\n\nChange-Id: I6da92cb8b9fcbb603e120eababcf4ce711da3e30\nDepends-On: I9380343c09d28eec67077c9e6d77c33a195e516b\nNeeded-By: Iff506bd11b83d396305e631f3dd95d44cf38fd63\n'}, {'number': 2, 'created': '2016-07-07 21:38:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/7a9343fcbd5c08c85256eed54312b54bbad3b66a', 'message': '[WIP] Implement L3 Agent Extension Manager\n\nUsing the generalized agent extension mechanism, create an agent extension\nmanager in the L3 agent, so that the L3 agent can load agent extensions.\n\nCo-Authored-By: Margaret Frances <margaret_frances@cable.comcast.com>\nDepends-On: I9380343c09d28eec67077c9e6d77c33a195e516b\nNeeded-By: Iff506bd11b83d396305e631f3dd95d44cf38fd63\n\nChange-Id: I6da92cb8b9fcbb603e120eababcf4ce711da3e30\n'}, {'number': 3, 'created': '2016-07-08 15:00:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b9ba38e4cc1777f44c339f4b45fb036c222166fb', 'message': '[WIP] Implement L3 Agent Extension Manager\n\nUsing the generalized agent extension mechanism, create an agent extension\nmanager in the L3 agent, so that the L3 agent can load agent extensions.\n\nCo-Authored-By: Margaret Frances <margaret_frances@cable.comcast.com>\nImplements: blueprint l3-agent-extensions\nDepends-On: I9380343c09d28eec67077c9e6d77c33a195e516b\nNeeded-By: Iff506bd11b83d396305e631f3dd95d44cf38fd63\n\nChange-Id: I6da92cb8b9fcbb603e120eababcf4ce711da3e30\n'}, {'number': 4, 'created': '2016-07-15 14:31:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/7c5741871cfcc9b0b526e6c902864365c5d0a544', 'message': '[WIP] Implement L3 Agent Extension Manager\n\nUsing the generalized agent extension mechanism, create an agent extension\nmanager in the L3 agent, so that the L3 agent can load agent extensions.\n\nCo-Authored-By: Margaret Frances <margaret_frances@cable.comcast.com>\nImplements: blueprint l3-agent-extensions\nDepends-On: I9380343c09d28eec67077c9e6d77c33a195e516b\nNeeded-By: Iff506bd11b83d396305e631f3dd95d44cf38fd63\n\nChange-Id: I6da92cb8b9fcbb603e120eababcf4ce711da3e30\n'}, {'number': 5, 'created': '2016-07-15 14:48:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/93adf88a6776f6951f6f8b7582b0e1aede28b3fb', 'message': '[WIP] Implement L3 Agent Extension Manager\n\nUsing the generalized agent extension mechanism, create an agent extension\nmanager in the L3 agent, so that the L3 agent can load agent extensions.\n\nCo-Authored-By: Margaret Frances <margaret_frances@cable.comcast.com>\nImplements: blueprint l3-agent-extensions\nDepends-On: I9380343c09d28eec67077c9e6d77c33a195e516b\nNeeded-By: Iff506bd11b83d396305e631f3dd95d44cf38fd63\n\nChange-Id: I6da92cb8b9fcbb603e120eababcf4ce711da3e30\n'}, {'number': 6, 'created': '2016-07-15 15:11:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/08a85ba2896d16a6f334a2638124670c262c5550', 'message': '[WIP] Implement L3 Agent Extension Manager\n\nUsing the generalized agent extension mechanism, create an agent extension\nmanager in the L3 agent, so that the L3 agent can load agent extensions.\n\nCo-Authored-By: Margaret Frances <margaret_frances@cable.comcast.com>\nImplements: blueprint l3-agent-extensions\nDepends-On: I9380343c09d28eec67077c9e6d77c33a195e516b\nNeeded-By: Iff506bd11b83d396305e631f3dd95d44cf38fd63\n\nChange-Id: I6da92cb8b9fcbb603e120eababcf4ce711da3e30\n'}, {'number': 7, 'created': '2016-07-15 15:11:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/78ee0f5e656b82c5b8048d7896fe8e2abb522e81', 'message': '[WIP] Implement L3 Agent Extension Manager\n\nUsing the generalized agent extension mechanism, create an agent extension\nmanager in the L3 agent, so that the L3 agent can load agent extensions.\n\nCo-Authored-By: Margaret Frances <margaret_frances@cable.comcast.com>\nImplements: blueprint l3-agent-extensions\nDepends-On: I9380343c09d28eec67077c9e6d77c33a195e516b\nNeeded-By: Iff506bd11b83d396305e631f3dd95d44cf38fd63\n\nChange-Id: I6da92cb8b9fcbb603e120eababcf4ce711da3e30\n'}, {'number': 8, 'created': '2016-07-19 15:34:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/10add1adea83d2800e084b8d3a670ae84881d857', 'message': '[WIP] Implement L3 Agent Extension Manager\n\nUsing the generalized agent extension mechanism, create an agent extension\nmanager in the L3 agent, so that the L3 agent can load agent extensions.\n\nCo-Authored-By: Margaret Frances <margaret_frances@cable.comcast.com>\nImplements: blueprint l3-agent-extensions\nDepends-On: I9380343c09d28eec67077c9e6d77c33a195e516b\nNeeded-By: Iff506bd11b83d396305e631f3dd95d44cf38fd63\n\nChange-Id: I6da92cb8b9fcbb603e120eababcf4ce711da3e30\n'}, {'number': 9, 'created': '2016-07-21 15:17:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/0d5eb7a2ca83d0c5549894544dc2ed4ffd735273', 'message': 'Implement L3 Agent Extension Manager\n\nUsing the generalized agent extension mechanism, create an agent extension\nmanager in the L3 agent, so that the L3 agent can load agent extensions.\n\nCo-Authored-By: Margaret Frances <margaret_frances@cable.comcast.com>\nImplements: blueprint l3-agent-extensions\nDepends-On: I9380343c09d28eec67077c9e6d77c33a195e516b\nNeeded-By: Iff506bd11b83d396305e631f3dd95d44cf38fd63\n\nChange-Id: I6da92cb8b9fcbb603e120eababcf4ce711da3e30\n'}, {'number': 10, 'created': '2016-07-21 19:06:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/44de1d6f7eae3f1659a0de1be805ee52eb084e9f', 'message': 'Implement L3 Agent Extension Manager\n\nUsing the generalized agent extension mechanism, create an agent extension\nmanager in the L3 agent, so that the L3 agent can load agent extensions.\n\nCo-Authored-By: Margaret Frances <margaret_frances@cable.comcast.com>\nImplements: blueprint l3-agent-extensions\nNeeded-By: Iff506bd11b83d396305e631f3dd95d44cf38fd63\n\nChange-Id: I6da92cb8b9fcbb603e120eababcf4ce711da3e30\n'}, {'number': 11, 'created': '2016-08-01 18:42:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/af955d205234c3f80d95060e061b594be0f45f9e', 'message': 'Implement L3 Agent Extension Manager\n\nUsing the generalized agent extension mechanism, create an agent extension\nmanager in the L3 agent, so that the L3 agent can load agent extensions.\n\nCo-Authored-By: Margaret Frances <margaret_frances@cable.comcast.com>\nImplements: blueprint l3-agent-extensions\nNeeded-By: Iff506bd11b83d396305e631f3dd95d44cf38fd63\n\nChange-Id: I6da92cb8b9fcbb603e120eababcf4ce711da3e30\n'}, {'number': 12, 'created': '2016-08-03 04:39:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/9102147b3666038aedf089b90885af3a2f40919c', 'message': 'Implement L3 Agent Extension Manager\n\nUsing the generalized agent extension mechanism, create an agent extension\nmanager in the L3 agent, so that the L3 agent can load agent extensions.\n\nCo-Authored-By: Margaret Frances <margaret_frances@cable.comcast.com>\nImplements: blueprint l3-agent-extensions\nNeeded-By: Iff506bd11b83d396305e631f3dd95d44cf38fd63\n\nChange-Id: I6da92cb8b9fcbb603e120eababcf4ce711da3e30\n'}, {'number': 13, 'created': '2016-08-11 18:32:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/f61acda56924868bd2f7adee12be7cd0342457ae', 'message': 'Implement L2 Agent Extension Manager\n\nUsing the generalized agent extension mechanism, create an agent extension\nmanager in the L3 agent, so that the L3 agent can load agent extensions.\n\nCo-Authored-By: Margaret Frances <margaret_frances@cable.comcast.com>\nImplements: blueprint l3-agent-extensions\nNeeded-By: Iff506bd11b83d396305e631f3dd95d44cf38fd63\n\nChange-Id: I6da92cb8b9fcbb603e120eababcf4ce711da3e30\n'}, {'number': 14, 'created': '2016-08-11 18:58:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b5755c8172c5189108943e35f69691824b1abaca', 'message': 'Implement L2 Agent Extension Manager\n\nUsing the generalized agent extension mechanism, create an agent extension\nmanager in the L3 agent, so that the L3 agent can load agent extensions.\n\nCo-Authored-By: Margaret Frances <margaret_frances@cable.comcast.com>\nImplements: blueprint l3-agent-extensions\nNeeded-By: Iff506bd11b83d396305e631f3dd95d44cf38fd63\n\nChange-Id: I6da92cb8b9fcbb603e120eababcf4ce711da3e30\n'}, {'number': 15, 'created': '2016-08-11 19:01:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/22471fdeb94bd9863e5b426164aeea7555cbdd1c', 'message': 'Implement L3 Agent Extension Manager\n\nUsing the generalized agent extension mechanism, create an agent extension\nmanager in the L3 agent, so that the L3 agent can load agent extensions.\n\nCo-Authored-By: Margaret Frances <margaret_frances@cable.comcast.com>\nImplements: blueprint l3-agent-extensions\nNeeded-By: Iff506bd11b83d396305e631f3dd95d44cf38fd63\n\nChange-Id: I6da92cb8b9fcbb603e120eababcf4ce711da3e30\n'}, {'number': 16, 'created': '2016-08-14 03:31:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/29d20955ce6bbcdb7738db4a1fd4367a7ead819e', 'message': 'Implement L3 Agent Extension Manager\n\nUsing the generalized agent extension mechanism, create an agent extension\nmanager in the L3 agent, so that the L3 agent can load agent extensions.\n\nCo-Authored-By: Margaret Frances <margaret_frances@cable.comcast.com>\nImplements: blueprint l3-agent-extensions\nNeeded-By: Iff506bd11b83d396305e631f3dd95d44cf38fd63\n\nChange-Id: I6da92cb8b9fcbb603e120eababcf4ce711da3e30\n'}, {'number': 17, 'created': '2016-08-14 03:43:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/1529ec12c243a4d60084cbbd8384321fd851c863', 'message': 'Implement L3 Agent Extension Manager\n\nUsing the generalized agent extension mechanism, create an agent extension\nmanager in the L3 agent, so that the L3 agent can load agent extensions.\n\nCo-Authored-By: Margaret Frances <margaret_frances@cable.comcast.com>\nImplements: blueprint l3-agent-extensions\nNeeded-By: Iff506bd11b83d396305e631f3dd95d44cf38fd63\n\nChange-Id: I6da92cb8b9fcbb603e120eababcf4ce711da3e30\n'}, {'number': 18, 'created': '2016-08-14 14:22:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/8f1abffe6b865725ed5af951356d7af3734b5415', 'message': 'Implement L3 Agent Extension Manager\n\nUsing the generalized agent extension mechanism, create an agent extension\nmanager in the L3 agent, so that the L3 agent can load agent extensions.\n\nCo-Authored-By: Margaret Frances <margaret_frances@cable.comcast.com>\nImplements: blueprint l3-agent-extensions\nNeeded-By: Iff506bd11b83d396305e631f3dd95d44cf38fd63\n\nChange-Id: I6da92cb8b9fcbb603e120eababcf4ce711da3e30\n'}, {'number': 19, 'created': '2016-08-14 16:18:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/493b850e4d8639388f4e6884b1fa8f9683c2f88c', 'message': 'Implement L3 Agent Extension Manager\n\nUsing the generalized agent extension mechanism, create an agent extension\nmanager in the L3 agent, so that the L3 agent can load agent extensions.\n\nCo-Authored-By: Margaret Frances <margaret_frances@cable.comcast.com>\nImplements: blueprint l3-agent-extensions\nNeeded-By: Iff506bd11b83d396305e631f3dd95d44cf38fd63\n\nChange-Id: I6da92cb8b9fcbb603e120eababcf4ce711da3e30\n'}, {'number': 20, 'created': '2016-08-15 13:37:10.000000000', 'files': ['neutron/agent/l3/agent.py', 'neutron/agent/l3/l3_agent_extension.py', 'releasenotes/notes/l3-agent-extensions-b348ff26aec0fe88.yaml', 'neutron/agent/l3/l3_agent_extensions_manager.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/93a8dc3dbe4faae6efd017105fb407d7dfca1d32', 'message': 'Implement L3 Agent Extension Manager\n\nUsing the generalized agent extension mechanism, create an agent extension\nmanager in the L3 agent, so that the L3 agent can load agent extensions.\n\nCo-Authored-By: Margaret Frances <margaret_frances@cable.comcast.com>\nImplements: blueprint l3-agent-extensions\nNeeded-By: Iff506bd11b83d396305e631f3dd95d44cf38fd63\n\nChange-Id: I6da92cb8b9fcbb603e120eababcf4ce711da3e30\n'}]",41,339246,93a8dc3dbe4faae6efd017105fb407d7dfca1d32,203,23,20,13995,,,0,"Implement L3 Agent Extension Manager

Using the generalized agent extension mechanism, create an agent extension
manager in the L3 agent, so that the L3 agent can load agent extensions.

Co-Authored-By: Margaret Frances <margaret_frances@cable.comcast.com>
Implements: blueprint l3-agent-extensions
Needed-By: Iff506bd11b83d396305e631f3dd95d44cf38fd63

Change-Id: I6da92cb8b9fcbb603e120eababcf4ce711da3e30
",git fetch https://review.opendev.org/openstack/neutron refs/changes/46/339246/16 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/agent/l3/agent.py', 'neutron/agent/l3/l3_agent_extension.py', 'neutron/agent/l3/l3_agent_extensions_manager.py']",3,2209455dd45d601ecf8bc4db0bca3faf7d938642,bp/l3-agent-extensions,"# Copyright (c) 2015 Mellanox Technologies, Ltd # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. from oslo_log import log from neutron._i18n import _LE from neutron.agent import agent_extensions_manager as agent_ext_manager LOG = log.getLogger(__name__) L3_AGENT_EXT_MANAGER_NAMESPACE = 'neutron.agent.l2.extensions' def register_opts(conf): agent_ext_manager.register_opts(conf) class L3AgentExtensionsManager(agent_ext_manager.AgentExtensionsManager): """"""Manage l2 agent extensions."""""" def __init__(self, conf): super(L3AgentExtensionsManager, self).__init__(conf, L3_AGENT_EXT_MANAGER_NAMESPACE) def handle_router(self, context, data): """"""Notify all agent extensions to handle router."""""" for extension in self: try: extension.obj.handle_router(context, data) except AttributeError: LOG.exception( _LE(""Agent Extension '%(name)s' failed "" ""while handling router update""), {'name': extension.name} ) def delete_router(self, context, data): """"""Notify all agent extensions to delete router."""""" for extension in self: try: extension.obj.delete_router(context, data) except AttributeError: LOG.exception( _LE(""Agent Extension '%(name)s' failed "" ""while handling router deletion""), {'name': extension.name} ) ",,118,0
openstack%2Fneutron-lib~master~Ie52f672fde5bb2840524843bd0f79c2844487e6b,openstack/neutron-lib,master,Ie52f672fde5bb2840524843bd0f79c2844487e6b,Add __init__ methods in model_base for debtcollector,ABANDONED,2016-08-20 10:54:02.000000000,2016-08-29 04:30:21.000000000,,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 5367}, {'_account_id': 6524}]","[{'number': 1, 'created': '2016-08-20 10:54:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-lib/commit/a05e846047903a6eda84cca294b5e6aadf70470b', 'message': 'Add __init__ methods in model_base for debtcollector\n\nThe use of debtcollector in model_base.py in core neutron to\ndeprecate the Has* mixins requires that they have __init__\nmethods here in neutron-lib.\n\nRelated Blueprint: neutron-lib\n\nChange-Id: Ie52f672fde5bb2840524843bd0f79c2844487e6b\n'}, {'number': 2, 'created': '2016-08-20 19:40:50.000000000', 'files': ['neutron_lib/db/model_base.py', 'neutron_lib/tests/unit/db/test_model_base.py'], 'web_link': 'https://opendev.org/openstack/neutron-lib/commit/eb2242a66850e2e188fac315793d8a92a5d4bd51', 'message': 'Add __init__ methods in model_base for debtcollector\n\nThe use of debtcollector in model_base.py in core neutron to\ndeprecate the Has* mixins requires that they have __init__\nmethods here in neutron-lib.\n\nRelated Blueprint: neutron-lib\n\nChange-Id: Ie52f672fde5bb2840524843bd0f79c2844487e6b\n'}]",2,358178,eb2242a66850e2e188fac315793d8a92a5d4bd51,8,4,2,6524,,,0,"Add __init__ methods in model_base for debtcollector

The use of debtcollector in model_base.py in core neutron to
deprecate the Has* mixins requires that they have __init__
methods here in neutron-lib.

Related Blueprint: neutron-lib

Change-Id: Ie52f672fde5bb2840524843bd0f79c2844487e6b
",git fetch https://review.opendev.org/openstack/neutron-lib refs/changes/78/358178/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron_lib/db/model_base.py'],1,a05e846047903a6eda84cca294b5e6aadf70470b,bp/neutron-lib," # Use of debtcollector in neutron model_base requires __init__ here def __init__(self, *args, **kwargs): super(HasProject, self).__init__(*args, **kwargs) # Use of debtcollector in neutron model_base requires __init__ here def __init__(self, *args, **kwargs): super(HasId, self).__init__(*args, **kwargs) # Use of debtcollector in neutron model_base requires __init__ here def __init__(self, *args, **kwargs): super(HasStatusDescription, self).__init__(*args, **kwargs) ",,12,0
openstack%2Fopenstack-manuals~master~I193642e0a1e212b06352e514fda818283c4a238e,openstack/openstack-manuals,master,I193642e0a1e212b06352e514fda818283c4a238e,Build for more languages,MERGED,2016-08-28 09:31:51.000000000,2016-08-29 04:29:48.000000000,2016-08-29 04:29:48.000000000,"[{'_account_id': 3}, {'_account_id': 9162}, {'_account_id': 10497}, {'_account_id': 17130}, {'_account_id': 21486}, {'_account_id': 23327}]","[{'number': 1, 'created': '2016-08-28 09:31:51.000000000', 'files': ['doc-tools-check-languages.conf'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/2a815fd15f46dd607bb51ba60797956f35e219a6', 'message': 'Build for more languages\n\nBuild guides for all languages that have translations.\n\nChange-Id: I193642e0a1e212b06352e514fda818283c4a238e\n'}]",0,361703,2a815fd15f46dd607bb51ba60797956f35e219a6,10,6,1,6547,,,0,"Build for more languages

Build guides for all languages that have translations.

Change-Id: I193642e0a1e212b06352e514fda818283c4a238e
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/03/361703/1 && git format-patch -1 --stdout FETCH_HEAD,['doc-tools-check-languages.conf'],1,2a815fd15f46dd607bb51ba60797956f35e219a6,languages," [""de""]=""install-guide"" [""id""]=""install-guide"" [""zh_CN""]=""install-guide"" [""de""]=""install-guide"" [""id""]=""install-guide"" [""zh_CN""]=""install-guide""",,6,0
openstack%2Fossa~master~I6d822623652caf1721a8132d03ed4530d080a378,openstack/ossa,master,I6d822623652caf1721a8132d03ed4530d080a378,Make Git ignore files generated by doc builds,MERGED,2016-08-26 16:40:21.000000000,2016-08-29 04:10:33.000000000,2016-08-29 04:10:33.000000000,"[{'_account_id': 3}, {'_account_id': 9311}]","[{'number': 1, 'created': '2016-08-26 16:40:21.000000000', 'files': ['.gitignore'], 'web_link': 'https://opendev.org/openstack/ossa/commit/028048235c213a42e6c49aeb3c9ed399a6306245', 'message': 'Make Git ignore files generated by doc builds\n\nMake Git ignore the AUTHORS and ChangeLog files generated by\nsetup.py build_sphinx invocations.\n\nChange-Id: I6d822623652caf1721a8132d03ed4530d080a378\n'}]",0,361357,028048235c213a42e6c49aeb3c9ed399a6306245,6,2,1,5263,,,0,"Make Git ignore files generated by doc builds

Make Git ignore the AUTHORS and ChangeLog files generated by
setup.py build_sphinx invocations.

Change-Id: I6d822623652caf1721a8132d03ed4530d080a378
",git fetch https://review.opendev.org/openstack/ossa refs/changes/57/361357/1 && git format-patch -1 --stdout FETCH_HEAD,['.gitignore'],1,028048235c213a42e6c49aeb3c9ed399a6306245,gitignore,AUTHORS ChangeLog,,2,0
openstack%2Fpython-senlinclient~master~Ia020226bb20522d7eb03af02bd69dfa5845876ce,openstack/python-senlinclient,master,Ia020226bb20522d7eb03af02bd69dfa5845876ce,Fix cluster-policy-list,MERGED,2016-08-27 13:49:43.000000000,2016-08-29 04:02:20.000000000,2016-08-29 04:02:20.000000000,"[{'_account_id': 3}, {'_account_id': 7404}, {'_account_id': 8246}]","[{'number': 1, 'created': '2016-08-27 13:49:43.000000000', 'files': ['senlinclient/tests/unit/v1/test_shell.py', 'senlinclient/v1/shell.py', 'senlinclient/tests/unit/v1/test_cluster_policy.py', 'senlinclient/v1/cluster_policy.py'], 'web_link': 'https://opendev.org/openstack/python-senlinclient/commit/951f7ee5195fa8a6b63355e1d155533ae3e95b41', 'message': ""Fix cluster-policy-list\n\nThe 'enabled' field has been renamed to 'is_enabled' by the sdk, this\npatch changes the field name for listing.\n\nChange-Id: Ia020226bb20522d7eb03af02bd69dfa5845876ce\n""}]",0,361601,951f7ee5195fa8a6b63355e1d155533ae3e95b41,9,3,1,8246,,,0,"Fix cluster-policy-list

The 'enabled' field has been renamed to 'is_enabled' by the sdk, this
patch changes the field name for listing.

Change-Id: Ia020226bb20522d7eb03af02bd69dfa5845876ce
",git fetch https://review.opendev.org/openstack/python-senlinclient refs/changes/01/361601/1 && git format-patch -1 --stdout FETCH_HEAD,"['senlinclient/tests/unit/v1/test_shell.py', 'senlinclient/v1/shell.py', 'senlinclient/tests/unit/v1/test_cluster_policy.py', 'senlinclient/v1/cluster_policy.py']",4,951f7ee5195fa8a6b63355e1d155533ae3e95b41,," columns = ['policy_id', 'policy_name', 'policy_type', 'is_enabled']"," columns = ['policy_id', 'policy_name', 'policy_type', 'enabled']",4,4
openstack%2Fkeystone~master~Ie2e71c45c85f33d3cff49d06dcdbd76f0cf1ac2e,openstack/keystone,master,Ie2e71c45c85f33d3cff49d06dcdbd76f0cf1ac2e,[api] add relationship links to v3-ext,MERGED,2016-08-17 14:00:19.000000000,2016-08-29 03:52:03.000000000,2016-08-29 03:52:03.000000000,"[{'_account_id': 3}, {'_account_id': 6482}, {'_account_id': 8119}, {'_account_id': 13063}, {'_account_id': 13478}, {'_account_id': 19985}]","[{'number': 1, 'created': '2016-08-17 14:00:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/167268fb0236c29d406bcca12e8ad2a7771c68de', 'message': '[api] add relationship links to v3-ext\n\nNearly all the ""relationship"" links are missing in v3 APIs\n\nAdded relationship links to v3-ext API pages.\n\nChange-Id: Ie2e71c45c85f33d3cff49d06dcdbd76f0cf1ac2e\nPartial-Bug: #1609159\n'}, {'number': 2, 'created': '2016-08-17 14:01:23.000000000', 'files': ['api-ref/source/v3-ext/revoke.inc', 'api-ref/source/v3-ext/federation/projects-domains/projects-domains.inc', 'api-ref/source/v3-ext/federation/auth/auth.inc', 'api-ref/source/v3-ext/federation/service-provider/sp.inc', 'api-ref/source/v3-ext/trust.inc', 'api-ref/source/v3-ext/federation/mapping/mapping.inc', 'api-ref/source/v3-ext/federation/identity-provider/idp.inc', 'api-ref/source/v3-ext/federation/assertion/assertion.inc'], 'web_link': 'https://opendev.org/openstack/keystone/commit/cb51cb40372a5b1f5fba0e27178c4ee745e67e75', 'message': '[api] add relationship links to v3-ext\n\nNearly all the ""relationship"" links are missing in v3 APIs\n\nAdded relationship links to v3-ext API pages.\n\nChange-Id: Ie2e71c45c85f33d3cff49d06dcdbd76f0cf1ac2e\nCloses-Bug: #1609159\n'}]",0,356485,cb51cb40372a5b1f5fba0e27178c4ee745e67e75,11,6,2,21420,,,0,"[api] add relationship links to v3-ext

Nearly all the ""relationship"" links are missing in v3 APIs

Added relationship links to v3-ext API pages.

Change-Id: Ie2e71c45c85f33d3cff49d06dcdbd76f0cf1ac2e
Closes-Bug: #1609159
",git fetch https://review.opendev.org/openstack/keystone refs/changes/85/356485/2 && git format-patch -1 --stdout FETCH_HEAD,"['api-ref/source/v3-ext/revoke.inc', 'api-ref/source/v3-ext/federation/projects-domains/projects-domains.inc', 'api-ref/source/v3-ext/federation/auth/auth.inc', 'api-ref/source/v3-ext/federation/service-provider/sp.inc', 'api-ref/source/v3-ext/trust.inc', 'api-ref/source/v3-ext/federation/identity-provider/idp.inc', 'api-ref/source/v3-ext/federation/mapping/mapping.inc', 'api-ref/source/v3-ext/federation/assertion/assertion.inc']",8,167268fb0236c29d406bcca12e8ad2a7771c68de,bug/1609159,Relationship: ``http://docs.openstack.org/api/openstack-identity/3/ext/OS-FEDERATION/1.0/rel/saml2`` Relationship: ``http://docs.openstack.org/api/openstack-identity/3/ext/OS-FEDERATION/1.0/rel/saml2/ecp`` Relationship: ``http://docs.openstack.org/api/openstack-identity/3/ext/OS-FEDERATION/1.0/rel/metadata`` ,,70,12
openstack%2Fdevstack~master~Ia2b2e106975be4c1f59308ca40c3dd4e7a793bbe,openstack/devstack,master,Ia2b2e106975be4c1f59308ca40c3dd4e7a793bbe,Add VMware configuration,ABANDONED,2016-07-27 02:20:50.000000000,2016-08-29 03:15:15.000000000,,"[{'_account_id': 3}, {'_account_id': 4656}, {'_account_id': 7882}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 16376}]","[{'number': 1, 'created': '2016-07-27 02:20:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/0e14104faf21bdf714c71c6dca73062abbb3d489', 'message': 'Add VMware configuration\n\nIn nova, there is a configuration [vmware]insecure,\nbut we cannot set it in devstack.\nThis patch set adds VMware configuration ""insecure"".\n\nChange-Id: Ia2b2e106975be4c1f59308ca40c3dd4e7a793bbe\n'}, {'number': 2, 'created': '2016-07-27 23:55:15.000000000', 'files': ['lib/nova_plugins/hypervisor-vsphere'], 'web_link': 'https://opendev.org/openstack/devstack/commit/3be2e5ee1f44ed3704daeb0dcb90a4830184ef11', 'message': 'Add VMware configuration\n\nIn nova, there is a configuration [vmware]insecure,\nbut we cannot set it in devstack.\nThis patch set adds VMware configuration ""insecure"".\n\nChange-Id: Ia2b2e106975be4c1f59308ca40c3dd4e7a793bbe\n'}]",2,347596,3be2e5ee1f44ed3704daeb0dcb90a4830184ef11,15,6,2,7882,,,0,"Add VMware configuration

In nova, there is a configuration [vmware]insecure,
but we cannot set it in devstack.
This patch set adds VMware configuration ""insecure"".

Change-Id: Ia2b2e106975be4c1f59308ca40c3dd4e7a793bbe
",git fetch https://review.opendev.org/openstack/devstack refs/changes/96/347596/1 && git format-patch -1 --stdout FETCH_HEAD,['lib/nova_plugins/hypervisor-vsphere'],1,0e14104faf21bdf714c71c6dca73062abbb3d489,add_vmware_insecure," iniset $NOVA_CONF vmware insecure ""$VMWAREAPI_INSECURE""",,1,0
openstack%2Fmagnum~master~I775caa66fc62ed79d6c7838770eb12540a03c355,openstack/magnum,master,I775caa66fc62ed79d6c7838770eb12540a03c355,LBaaS API v2,ABANDONED,2016-07-11 03:11:15.000000000,2016-08-29 03:11:00.000000000,,"[{'_account_id': 3}, {'_account_id': 10068}, {'_account_id': 13861}, {'_account_id': 20498}]","[{'number': 1, 'created': '2016-07-11 03:11:15.000000000', 'files': ['magnum/drivers/swarm_fedora_atomic_v1/templates/cluster.yaml', 'magnum/drivers/swarm_fedora_atomic_v1/templates/swarmmaster.yaml'], 'web_link': 'https://opendev.org/openstack/magnum/commit/096f775acec8a1e9cf64e30cb587df3e7aac63d3', 'message': 'LBaaS API v2\n\nLBaaS v2 Implementation for Swarm\n\nChange-Id: I775caa66fc62ed79d6c7838770eb12540a03c355\nImplements: blueprint magnum-lbaasv2-support\n'}]",0,340208,096f775acec8a1e9cf64e30cb587df3e7aac63d3,6,4,1,22685,,,0,"LBaaS API v2

LBaaS v2 Implementation for Swarm

Change-Id: I775caa66fc62ed79d6c7838770eb12540a03c355
Implements: blueprint magnum-lbaasv2-support
",git fetch https://review.opendev.org/openstack/magnum refs/changes/08/340208/1 && git format-patch -1 --stdout FETCH_HEAD,"['magnum/drivers/swarm_fedora_atomic_v1/templates/cluster.yaml', 'magnum/drivers/swarm_fedora_atomic_v1/templates/swarmmaster.yaml']",2,096f775acec8a1e9cf64e30cb587df3e7aac63d3,bp/magnum-lbaasv2-support, type: OS::Neutron::LBaaS::PoolMember properties: pool: {get_param: api_pool_id} subnet: {get_param: fixed_subnet_id} type: OS::Neutron::LBaaS::PoolMember properties: pool: {get_param: etcd_pool_id} subnet: {get_param: fixed_subnet_id}, type: OS::Neutron::PoolMember properties: pool_id: {get_param: api_pool_id} type: OS::Neutron::PoolMember properties: pool_id: {get_param: etcd_pool_id},61,28
openstack%2Fdesignate-tempest-plugin~master~I1d4c8eb70c8429cc3902a608fe8bbf466e727726,openstack/designate-tempest-plugin,master,I1d4c8eb70c8429cc3902a608fe8bbf466e727726,Add testcases for RecordsetOwnership,ABANDONED,2016-06-20 10:44:51.000000000,2016-08-29 03:07:29.000000000,,"[{'_account_id': 3}, {'_account_id': 8099}, {'_account_id': 15699}]","[{'number': 1, 'created': '2016-06-20 10:44:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate-tempest-plugin/commit/8c5dfb6e6ac8952033f02171d247bed30a7b5121', 'message': 'Add testcases for RecordsetOwnership\n\nThis patch also adds client method to get a recordset using\n/v2/recordsets API and the corresponding test case.\n\nChange-Id: I1d4c8eb70c8429cc3902a608fe8bbf466e727726\n'}, {'number': 2, 'created': '2016-06-20 10:55:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate-tempest-plugin/commit/ce4d647b03bfd3ed68722451336a1751e373c67f', 'message': 'Add testcases for RecordsetOwnership\n\nThis patch also adds client method to get a recordset using\n/v2/recordsets API and the corresponding test case.\n\nChange-Id: I1d4c8eb70c8429cc3902a608fe8bbf466e727726\n'}, {'number': 3, 'created': '2016-06-20 11:35:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate-tempest-plugin/commit/c385c707218b2a80d3693c3cc4cb7fd53dedd021', 'message': 'Add testcases for RecordsetOwnership\n\nThis patch also adds client method to get a recordset using\n/v2/recordsets API and the corresponding test case.\n\nChange-Id: I1d4c8eb70c8429cc3902a608fe8bbf466e727726\n'}, {'number': 4, 'created': '2016-07-15 05:46:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate-tempest-plugin/commit/36b19525dc77e1e6c9a427f0d0d6d3d785d04ee8', 'message': 'Add testcases for RecordsetOwnership\n\nThis patch also adds client method to get a recordset using\n/v2/recordsets API and the corresponding test case.\n\nChange-Id: I1d4c8eb70c8429cc3902a608fe8bbf466e727726\n'}, {'number': 5, 'created': '2016-08-26 05:46:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate-tempest-plugin/commit/defe0f58ac8d387deb554125b18a69cad3a7db1d', 'message': 'Add testcases for RecordsetOwnership\n\nChange-Id: I1d4c8eb70c8429cc3902a608fe8bbf466e727726\n'}, {'number': 6, 'created': '2016-08-26 07:28:05.000000000', 'files': ['designate_tempest_plugin/tests/api/v2/test_recordset.py'], 'web_link': 'https://opendev.org/openstack/designate-tempest-plugin/commit/cdd5f104a485172a3f8940390151dd95cce55622', 'message': 'Add testcases for RecordsetOwnership\n\nChange-Id: I1d4c8eb70c8429cc3902a608fe8bbf466e727726\n'}]",0,331611,cdd5f104a485172a3f8940390151dd95cce55622,23,3,6,15699,,,0,"Add testcases for RecordsetOwnership

Change-Id: I1d4c8eb70c8429cc3902a608fe8bbf466e727726
",git fetch https://review.opendev.org/openstack/designate-tempest-plugin refs/changes/11/331611/4 && git format-patch -1 --stdout FETCH_HEAD,"['designate_tempest_plugin/services/dns/v2/json/recordset_client.py', 'designate_tempest_plugin/tests/api/v2/test_recordset.py']",2,8c5dfb6e6ac8952033f02171d247bed30a7b5121,(detached," def test_show_zone_recordset(self): LOG.info('Create a zone') _, zone = self.zone_client.create_zone() self.addCleanup(self.zone_client.delete_zone, zone['id']) recordset_data = data_utils.rand_a_recordset(zone_name=zone['name']) LOG.info('Create a recordset') resp, recordset = self.client.create_recordset(zone['id'], recordset_data) resp, body = self.client.show_zone_recordset(recordset['id']) self.assertEqual('200', resp['status']) @test.attr(type='smoke') class RecordsetOwnershipTest(BaseRecordsetsTest): credentials = ['primary', 'alt'] def setUp(cls): super(RecordsetOwnershipTest, cls).setUp() cls.client = cls.os.recordset_client cls.zone_client = cls.os.zones_client cls.alt_zone_client = cls.os_alt.zones_client cls.alt_client = cls.os_alt.recordset_client @test.attr(type='smoke') def test_no_create_recordset_by_alt_tenant(self): LOG.info('Create a zone') _, zone = self.zone_client.create_zone() self.addCleanup(self.zone_client.delete_zone, zone['id']) recordset_data = data_utils.random_a_recordset(zone_name=zone['name']) self.assertRaises(lib_exc.RestClientException, self.alt_client.create_recordset, zone_uuid=zone['id'], recordset_data=recordset_data) recordset_data = { ""name"": zone['name'], ""description"": ""This is an example record set."", ""type"": ""A"", ""ttl"": 3600, ""records"": [ ""10.1.0.2"" ] } LOG.info('Create a zone as an alt user with existing subdomain') self.assertRaises(lib_exc.RestClientException, self.alt_client.create_recordset, zone_uuid=zone['id'], recordset_data=recordset_data) @test.attr(type='smoke') def test_no_create_super_recordsets(self): LOG.info('Create a zone') zone_name = data_utils.rand_zone_name() LOG.info('Create a zone as a default user') _, zone = self.zone_client.create_zone(name='a.b.c.' + zone_name) self.addCleanup(self.zone_client.delete_zone, zone['id']) recordset = data_utils.rand_a_recordset(zone_name=zone['name']) recordset['name'] = 'b.c.' + zone_name LOG.info('Create a recordset as an alt user') self.assertRaises(lib_exc.RestClientException, self.alt_client.create_recordset, zone_uuid=zone['id'], recordset_data=recordset) @test.attr(type='smoke') def test_no_create_recordset_via_alt_domain(self): LOG.info('Create a zone as primary user') _, zone = self.zone_client.create_zone() self.addCleanup(self.zone_client.delete_zone, zone['id']) LOG.info('Create a zone as alt user') _, alt_zone = self.alt_zone_client.create_zone() self.addCleanup(self.alt_zone_client.delete_zone, alt_zone['id']) recordset_data = data_utils.rand_recordset_data( record_type='A', zone_name=zone['name']) self.assertRaises(lib_exc.RestClientException, self.alt_client.create_recordset, zone_uuid=zone['id'], recordset_data=recordset_data) self.assertRaises(lib_exc.RestClientException, self.alt_client.create_recordset, zone_uuid=alt_zone['id'], recordset_data=recordset_data)",,104,0
openstack%2Fnova~master~I11db343f96c7ce187e3c8bf32784ca06e089cfdc,openstack/nova,master,I11db343f96c7ce187e3c8bf32784ca06e089cfdc,Imported Translations from Zanata,MERGED,2016-08-24 07:12:48.000000000,2016-08-29 03:06:26.000000000,2016-08-25 13:49:03.000000000,"[{'_account_id': 3}, {'_account_id': 2271}, {'_account_id': 5170}, {'_account_id': 6547}, {'_account_id': 9008}, {'_account_id': 9732}, {'_account_id': 10385}, {'_account_id': 15286}, {'_account_id': 15751}, {'_account_id': 16376}, {'_account_id': 16897}, {'_account_id': 16898}]","[{'number': 1, 'created': '2016-08-24 07:12:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4ec5eae5bf66db0bbe6ee0a1330ba8f4b62fc2e2', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I11db343f96c7ce187e3c8bf32784ca06e089cfdc\n'}, {'number': 2, 'created': '2016-08-25 07:57:35.000000000', 'files': ['nova/locale/zh_CN/LC_MESSAGES/nova-log-warning.po', 'nova/locale/tr_TR/LC_MESSAGES/nova-log-warning.po', 'nova/locale/ko_KR/LC_MESSAGES/nova-log-error.po', 'nova/locale/fr/LC_MESSAGES/nova-log-warning.po', 'nova/locale/pt_BR/LC_MESSAGES/nova.po', 'nova/locale/zh_CN/LC_MESSAGES/nova.po', 'nova/locale/cs/LC_MESSAGES/nova-log-warning.po', 'nova/locale/es/LC_MESSAGES/nova-log-warning.po', 'nova/locale/zh_CN/LC_MESSAGES/nova-log-error.po', 'nova/locale/fr/LC_MESSAGES/nova.po', 'nova/locale/tr_TR/LC_MESSAGES/nova-log-error.po', 'nova/locale/ko_KR/LC_MESSAGES/nova.po', 'nova/locale/zh_TW/LC_MESSAGES/nova.po', 'nova/locale/de/LC_MESSAGES/nova-log-error.po', 'nova/locale/ru/LC_MESSAGES/nova.po', 'nova/locale/cs/LC_MESSAGES/nova-log-error.po', 'nova/locale/it/LC_MESSAGES/nova-log-error.po', 'nova/locale/fr/LC_MESSAGES/nova-log-error.po', 'nova/locale/pt_BR/LC_MESSAGES/nova-log-error.po', 'nova/locale/es/LC_MESSAGES/nova.po', 'nova/locale/ja/LC_MESSAGES/nova.po', 'nova/locale/cs/LC_MESSAGES/nova.po', 'nova/locale/ko_KR/LC_MESSAGES/nova-log-warning.po', 'nova/locale/tr_TR/LC_MESSAGES/nova.po', 'nova/locale/it/LC_MESSAGES/nova.po', 'nova/locale/de/LC_MESSAGES/nova.po', 'nova/locale/es/LC_MESSAGES/nova-log-error.po'], 'web_link': 'https://opendev.org/openstack/nova/commit/4885d59a92b97e8498472b376c69995119b0e788', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I11db343f96c7ce187e3c8bf32784ca06e089cfdc\n'}]",0,359635,4885d59a92b97e8498472b376c69995119b0e788,27,12,2,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
https://wiki.openstack.org/wiki/Translations/Infrastructure

Change-Id: I11db343f96c7ce187e3c8bf32784ca06e089cfdc
",git fetch https://review.opendev.org/openstack/nova refs/changes/35/359635/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/locale/zh_CN/LC_MESSAGES/nova-log-warning.po', 'nova/locale/tr_TR/LC_MESSAGES/nova-log-warning.po', 'nova/locale/ko_KR/LC_MESSAGES/nova-log-error.po', 'nova/locale/fr/LC_MESSAGES/nova-log-warning.po', 'nova/locale/pt_BR/LC_MESSAGES/nova.po', 'nova/locale/zh_CN/LC_MESSAGES/nova.po', 'nova/locale/cs/LC_MESSAGES/nova-log-warning.po', 'nova/locale/es/LC_MESSAGES/nova-log-warning.po', 'nova/locale/zh_CN/LC_MESSAGES/nova-log-error.po', 'nova/locale/fr/LC_MESSAGES/nova.po', 'nova/locale/tr_TR/LC_MESSAGES/nova-log-error.po', 'nova/locale/ko_KR/LC_MESSAGES/nova.po', 'nova/locale/zh_TW/LC_MESSAGES/nova.po', 'nova/locale/de/LC_MESSAGES/nova-log-error.po', 'nova/locale/ru/LC_MESSAGES/nova.po', 'nova/locale/cs/LC_MESSAGES/nova-log-error.po', 'nova/locale/it/LC_MESSAGES/nova-log-error.po', 'nova/locale/fr/LC_MESSAGES/nova-log-error.po', 'nova/locale/pt_BR/LC_MESSAGES/nova-log-error.po', 'nova/locale/es/LC_MESSAGES/nova.po', 'nova/locale/ja/LC_MESSAGES/nova.po', 'nova/locale/cs/LC_MESSAGES/nova.po', 'nova/locale/ko_KR/LC_MESSAGES/nova-log-warning.po', 'nova/locale/tr_TR/LC_MESSAGES/nova.po', 'nova/locale/it/LC_MESSAGES/nova.po', 'nova/locale/de/LC_MESSAGES/nova.po', 'nova/locale/es/LC_MESSAGES/nova-log-error.po']",27,4ec5eae5bf66db0bbe6ee0a1330ba8f4b62fc2e2,zanata/translations,"""Project-Id-Version: nova 14.0.0.0b3.dev713\n""""POT-Creation-Date: 2016-08-24 02:17+0000\n""","""Project-Id-Version: nova 14.0.0.0b3.dev274\n""""POT-Creation-Date: 2016-08-02 00:03+0000\n""msgid ""No db access allowed in nova-compute: %s"" msgstr ""No se permite acceso a la base de datos en nova-compute: %s"" #, python-format msgid ""No db access allowed in nova-dhcpbridge: %s"" msgstr ""No se permite acceso a la base de datos en nova-dhcpbridge: %s"" #, python-format msgid ""No db access allowed in nova-network: %s"" msgstr ""No se permite acceso a base de datos en nova-network: %s"" #, python-formatmsgid ""Unable to update host of port %s"" msgstr ""Incapaz de actualizar el anfitrin del puerto %s"" #, python-format",67,1184
openstack%2Fpython-karborclient~master~I1761237c252707411f5e7b4548ce7d5e89d57079,openstack/python-karborclient,master,I1761237c252707411f5e7b4548ce7d5e89d57079,fix .coveragerc,MERGED,2016-08-26 09:51:37.000000000,2016-08-29 02:53:45.000000000,2016-08-29 02:53:45.000000000,"[{'_account_id': 3}, {'_account_id': 2023}, {'_account_id': 17151}, {'_account_id': 20883}]","[{'number': 1, 'created': '2016-08-26 09:51:37.000000000', 'files': ['.coveragerc'], 'web_link': 'https://opendev.org/openstack/python-karborclient/commit/ef4f89da066f31a57a09037b96c0f094c0ad85bd', 'message': 'fix .coveragerc\n\nReplace karbor as karborclient in .coveragerc,\n\nChange-Id: I1761237c252707411f5e7b4548ce7d5e89d57079\n'}]",0,361047,ef4f89da066f31a57a09037b96c0f094c0ad85bd,7,4,1,21648,,,0,"fix .coveragerc

Replace karbor as karborclient in .coveragerc,

Change-Id: I1761237c252707411f5e7b4548ce7d5e89d57079
",git fetch https://review.opendev.org/openstack/python-karborclient refs/changes/47/361047/1 && git format-patch -1 --stdout FETCH_HEAD,['.coveragerc'],1,ef4f89da066f31a57a09037b96c0f094c0ad85bd,fix-coveragerc,"omit = karborclient/tests/*,karborclient/openstack/*","omit = karborclient/tests/*,karbor/openstack/*",1,1
openstack%2Fzaqar~master~I7febfcca600e08b5b0f7e58ddb17e83f30f35f34,openstack/zaqar,master,I7febfcca600e08b5b0f7e58ddb17e83f30f35f34,Clean the auth app after authentication failure,MERGED,2016-06-07 07:31:22.000000000,2016-08-29 02:50:30.000000000,2016-08-29 02:50:30.000000000,"[{'_account_id': 3}, {'_account_id': 6484}, {'_account_id': 8846}]","[{'number': 1, 'created': '2016-06-07 07:31:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/1b86838c4896884d2c23e35c269f850da92eb84a', 'message': ""Clean the auth app after authentication failure\n\nNow with websocket deployment, if we authenticate again after\nonce authentication failure. zaqar doesn't authenticate and\nalways return 403.\nThe reason is that we didn't clean the _auth_app after the\nfailure.\n\nChange-Id: I7febfcca600e08b5b0f7e58ddb17e83f30f35f34\nCloses-bug: #1589825\n""}, {'number': 2, 'created': '2016-06-12 08:50:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/edf4a0a9136c1125bf36a9396486bc36af3b577d', 'message': ""Clean the auth app after authentication failure\n\nNow with websocket deployment, if we authenticate again after\nonce authentication failure. zaqar doesn't authenticate and\nalways return 403.\nThe reason is that we didn't clean the _auth_app after the\nfailure.\n\nChange-Id: I7febfcca600e08b5b0f7e58ddb17e83f30f35f34\nCloses-bug: #1589825\n""}, {'number': 3, 'created': '2016-06-17 07:55:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/54142233d9dbd8783c73d2c60a5324e2a305eaa3', 'message': ""Clean the auth app after authentication failure\n\nNow with websocket deployment, if we authenticate again after\nonce authentication failure. zaqar doesn't authenticate and\nalways return 403.\nThe reason is that we didn't clean the _auth_app after the\nfailure.\n\nChange-Id: I7febfcca600e08b5b0f7e58ddb17e83f30f35f34\nCloses-bug: #1589825\n""}, {'number': 4, 'created': '2016-06-23 08:32:11.000000000', 'files': ['zaqar/transport/websocket/protocol.py', 'zaqar/tests/unit/transport/websocket/v2/test_auth.py'], 'web_link': 'https://opendev.org/openstack/zaqar/commit/228f4a69209b1549c79fd6631a1cfa35b306d94b', 'message': ""Clean the auth app after authentication failure\n\nNow with websocket deployment, if we authenticate again after\nonce authentication failure. zaqar doesn't authenticate and\nalways return 403.\nThe reason is that we didn't clean the _auth_app after the\nfailure.\n\nChange-Id: I7febfcca600e08b5b0f7e58ddb17e83f30f35f34\nCloses-bug: #1589825\n""}]",2,326272,228f4a69209b1549c79fd6631a1cfa35b306d94b,19,3,4,15054,,,0,"Clean the auth app after authentication failure

Now with websocket deployment, if we authenticate again after
once authentication failure. zaqar doesn't authenticate and
always return 403.
The reason is that we didn't clean the _auth_app after the
failure.

Change-Id: I7febfcca600e08b5b0f7e58ddb17e83f30f35f34
Closes-bug: #1589825
",git fetch https://review.opendev.org/openstack/zaqar refs/changes/72/326272/2 && git format-patch -1 --stdout FETCH_HEAD,['zaqar/transport/websocket/protocol.py'],1,1b86838c4896884d2c23e35c269f850da92eb84a,bug/1589825, # we should clean up the _auth_app after the authentication # failure. So that we could authenticate again. self._auth_app = None,,3,0
openstack%2Fsenlin~master~Ia6d6e3d05e4f672093b75164d8f661d1755d430e,openstack/senlin,master,Ia6d6e3d05e4f672093b75164d8f661d1755d430e,Add eval_status operation to cluster,MERGED,2016-08-23 12:48:50.000000000,2016-08-29 02:27:27.000000000,2016-08-29 02:27:27.000000000,"[{'_account_id': 3}, {'_account_id': 8246}, {'_account_id': 11034}, {'_account_id': 17645}]","[{'number': 1, 'created': '2016-08-23 12:48:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/2d695d2fc514c45404d11148508e4a54c0db61ba', 'message': ""Add eval_status operation to cluster\n\nThis adds an 'eval_status' operation to cluster class. It can be invoked\nto refresh the status of a cluster based on the status of its nodes.\n\nChange-Id: Ia6d6e3d05e4f672093b75164d8f661d1755d430e\n""}, {'number': 2, 'created': '2016-08-24 03:28:14.000000000', 'files': ['senlin/tests/unit/engine/test_cluster.py', 'senlin/engine/cluster.py'], 'web_link': 'https://opendev.org/openstack/senlin/commit/c2884f13c363f5be52a593162f59cafb1d61d61d', 'message': ""Add eval_status operation to cluster\n\nThis adds an 'eval_status' operation to cluster class. It can be invoked\nto refresh the status of a cluster based on the status of its nodes.\n\nChange-Id: Ia6d6e3d05e4f672093b75164d8f661d1755d430e\n""}]",5,359177,c2884f13c363f5be52a593162f59cafb1d61d61d,14,4,2,8246,,,0,"Add eval_status operation to cluster

This adds an 'eval_status' operation to cluster class. It can be invoked
to refresh the status of a cluster based on the status of its nodes.

Change-Id: Ia6d6e3d05e4f672093b75164d8f661d1755d430e
",git fetch https://review.opendev.org/openstack/senlin refs/changes/77/359177/1 && git format-patch -1 --stdout FETCH_HEAD,"['senlin/tests/unit/engine/test_cluster.py', 'senlin/engine/cluster.py']",2,2d695d2fc514c45404d11148508e4a54c0db61ba,eval-status," def eval_status(self, ctx, operation): """"""Re-evaluate cluster health status. :param ctx: The requesting context. :param operation: The operation that triggers this status evaluation. :returns: ``None``. """""" self.rt['nodes'] = node_mod.Node.load_all(ctx, cluster_id=self.id) active_count = 0 for node in self.nodes: if node.status == 'ACTIVE': active_count += 1 values = {} if active_count < self.min_size: status = self.ERROR reason = _(""%(o)s: number of active nodes is below min_size "" ""(%(n)d)."") % {'o': operation, 'n': self.min_size} elif active_count < self.desired_capacity: status = self.WARNING reason = _(""%(o)s: number of active nodes is below "" ""desired_capacity "" ""(%(n)d)."") % {'o': operation, 'n': self.desired_capacity} elif self.max_size < 0 or active_count < self.max_size: status = self.ACTIVE reason = _(""%(o)s: number of active nodes is above "" ""desired_capacity "" ""(%(n)d)."") % {'o': operation, 'n': self.desired_capacity} else: status = self.WARNING reason = _(""%(o)s: number of active nodes is above max_size "" ""(%(n)d)."") % {'o': operation, 'n': self.max_size} values = {'status': status, 'status_reason': reason} co.Cluster.update(ctx, self.id, values)",,114,0
openstack%2Fpython-neutronclient~master~Icbdd0634517bc5c9993b5d9198ec3dd0cdabf30c,openstack/python-neutronclient,master,Icbdd0634517bc5c9993b5d9198ec3dd0cdabf30c,Enable -F support for bandwidth rule show and dscp rule show,ABANDONED,2016-08-25 01:49:46.000000000,2016-08-29 02:25:49.000000000,,"[{'_account_id': 3}, {'_account_id': 841}, {'_account_id': 17776}, {'_account_id': 20076}]","[{'number': 1, 'created': '2016-08-25 01:49:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/df5a412dcdddfb9cd7020d2f2eb535a268745795', 'message': 'Enable -F support for bandwidth rule show and dscp rule show\n\nIn qos-bandwidth-limit-rule-show and qos-dscp-marking-rule-show help\ninformation, the -F is valid, but the fact is not that.\n\nChange-Id: Icbdd0634517bc5c9993b5d9198ec3dd0cdabf30c\nCloses-Bug: #1616416\n'}, {'number': 2, 'created': '2016-08-26 00:34:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/3a7c96f5bb4a5cd329a8ec39018f3bce0082f020', 'message': 'Enable -F support for bandwidth rule show and dscp rule show\n\nIn qos-bandwidth-limit-rule-show and qos-dscp-marking-rule-show help\ninformation, the -F is valid, but the fact is not that.\n\nChange-Id: Icbdd0634517bc5c9993b5d9198ec3dd0cdabf30c\nCloses-Bug: #1616416\n'}, {'number': 3, 'created': '2016-08-27 05:54:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/d192f54a0c991f4b902e35539a7e63178c862254', 'message': 'Enable -F support for bandwidth rule show and dscp rule show\n\nIn qos-bandwidth-limit-rule-show and qos-dscp-marking-rule-show help\ninformation, the -F is valid, but the fact is not that.\n\nChange-Id: Icbdd0634517bc5c9993b5d9198ec3dd0cdabf30c\nCloses-Bug: #1616416\n'}, {'number': 4, 'created': '2016-08-28 06:34:33.000000000', 'files': ['neutronclient/v2_0/client.py'], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/f898bbb22ea69bd53d640280d7767218f0b37f59', 'message': 'Enable -F support for bandwidth rule show and dscp rule show\n\nIn qos-bandwidth-limit-rule-show and qos-dscp-marking-rule-show help\ninformation, the -F is valid, but the fact is not that.\n\nChange-Id: Icbdd0634517bc5c9993b5d9198ec3dd0cdabf30c\nCloses-Bug: #1616416\n'}]",0,360173,f898bbb22ea69bd53d640280d7767218f0b37f59,15,4,4,20076,,,0,"Enable -F support for bandwidth rule show and dscp rule show

In qos-bandwidth-limit-rule-show and qos-dscp-marking-rule-show help
information, the -F is valid, but the fact is not that.

Change-Id: Icbdd0634517bc5c9993b5d9198ec3dd0cdabf30c
Closes-Bug: #1616416
",git fetch https://review.opendev.org/openstack/python-neutronclient refs/changes/73/360173/3 && git format-patch -1 --stdout FETCH_HEAD,['neutronclient/v2_0/client.py'],1,df5a412dcdddfb9cd7020d2f2eb535a268745795,bug/1616416," def show_bandwidth_limit_rule(self, rule, policy, **_params): (policy, rule), params=_params) def show_dscp_marking_rule(self, rule, policy, **_params): (policy, rule), params=_params)"," def show_bandwidth_limit_rule(self, rule, policy, body=None): (policy, rule), body=body) def show_dscp_marking_rule(self, rule, policy, body=None): (policy, rule), body=body)",4,4
openstack%2Fhorizon~master~If73584c040846dc82aa482e75f5e5d95dfb6525e,openstack/horizon,master,If73584c040846dc82aa482e75f5e5d95dfb6525e,Fix the issue workflow filter do not show all users,MERGED,2016-05-19 07:58:53.000000000,2016-08-29 02:14:28.000000000,2016-08-29 02:14:28.000000000,"[{'_account_id': 3}, {'_account_id': 6763}, {'_account_id': 9155}, {'_account_id': 9531}, {'_account_id': 12071}, {'_account_id': 12826}, {'_account_id': 13325}, {'_account_id': 14124}, {'_account_id': 14151}, {'_account_id': 17172}, {'_account_id': 20509}, {'_account_id': 21728}, {'_account_id': 22587}]","[{'number': 1, 'created': '2016-05-19 07:58:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/2be4e85582ac1861037b1c2726763f68f664b4cc', 'message': ""Fix the issue workflow filter do not show all users\n\nReproduce\n1) Go to /identityu\n2) Press 'create project' button, go to 'Project Groups' tab\n3) For example, you have there two default groups: 'admins'\n   and 'nonadmins'. Type 'non' in the left filter field\n4) Filter works correct and now 'all groups' panel has only\n   'nonadmins' group. Press '+' to add 'nonadmins' to project groups\n5) Note that All groups panel is now empty and filter input is empty too.\n   Group admins will not be shown until you type 'admin' in that field.\n\nAfter being pressed '+', update of user list, and remove of filter\ninput are performed as internal process. This issue is caused by\nincorrect order of these processes. This patch will fix it.\n\nChange-Id: If73584c040846dc82aa482e75f5e5d95dfb6525e\nCloses-Bug: #1543620\n""}, {'number': 2, 'created': '2016-05-23 05:59:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/f269917f2a5852e49ddbab23eb6057f5cd73e749', 'message': ""Fix the issue workflow filter do not show all users\n\nReproduce\n1) Go to /identity\n2) Press 'create project' button, go to 'Project Groups' tab\n3) For example, you have there two default groups: 'admins'\n   and 'nonadmins'. Type 'non' in the left filter field\n4) Filter works correct and now 'all groups' panel has only\n   'nonadmins' group. Press '+' to add 'nonadmins' to project groups\n5) Note that All groups panel is now empty and filter input is empty too.\n   Group admins will not be shown until you type 'admin' in that field.\n\nAfter being pressed '+', update of user list, and remove of filter\ninput are performed as internal process. This issue is caused by\nincorrect order of these processes. This patch will fix it.\n\nChange-Id: If73584c040846dc82aa482e75f5e5d95dfb6525e\nCloses-Bug: #1543620\n""}, {'number': 3, 'created': '2016-06-03 11:37:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/bf2becaf9d9d29c52fd9eca1cfab1c954a2e56b7', 'message': ""Fix the issue workflow filter do not show all users\n\nWhen user add any group in Project Group Tab, layout will be incorrect\nin case below.\n\nReproduce\n1) Go to /identity\n2) Press 'create project' button, go to 'Project Groups' tab\n3) For example, you have there two default groups: 'admins'\n   and 'nonadmins'. Type 'non' in the left filter field\n4) Filter works correct and now 'all groups' panel has only\n   'nonadmins' group. Press '+' to add 'nonadmins' to project groups\n5) Note that All groups panel is now empty and filter input is empty too.\n   Group admins will not be shown until you type 'admin' in that field.\n\nAfter being pressed '+', update of user list and remove of filter\ninput are performed as internal process. This issue is caused by\nincorrect order of these processes. This patch will fix it.\n\nChange-Id: If73584c040846dc82aa482e75f5e5d95dfb6525e\nCloses-Bug: #1543620\n""}, {'number': 4, 'created': '2016-06-15 06:45:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/be629b20bc9b0871e2ee731400163cc1ddd6de70', 'message': ""Fix the issue workflow filter do not show all users\n\nWhen user add any group in Project Group Tab, layout will be incorrect\nin case below.\n\nReproduce\n1) Go to /identity\n2) Press 'create project' button, go to 'Project Groups' tab\n3) For example, you have there two default groups: 'admins'\n   and 'nonadmins'. Type 'non' in the left filter field\n4) Filter works correct and now 'all groups' panel has only\n   'nonadmins' group. Press '+' to add 'nonadmins' to project groups\n5) Note that All groups panel is now empty and filter input is empty too.\n   Group admins will not be shown until you type 'admin' in that field.\n\nAfter being pressed '+', update of user list and remove of filter\ninput are performed as internal process. This issue is caused by\nincorrect order of these processes. This patch will fix it.\n\nChange-Id: If73584c040846dc82aa482e75f5e5d95dfb6525e\nCloses-Bug: #1543620\n""}, {'number': 5, 'created': '2016-06-20 06:33:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/6eb07ee54e5de04d6f3ebaee6724bde15f6392c5', 'message': ""Fix the issue workflow filter do not show all users\n\nWhen user add any group in Project Group Tab, layout will be incorrect\nin case below.\n\nReproduce\n1) Go to /identity\n2) Press 'create project' button, go to 'Project Groups' tab\n3) For example, you have there two default groups: 'admins'\n   and 'nonadmins'. Type 'non' in the left filter field\n4) Filter works correct and now 'all groups' panel has only\n   'nonadmins' group. Press '+' to add 'nonadmins' to project groups\n5) Note that All groups panel is now empty and filter input is empty too.\n   Group admins will not be shown until you type 'admin' in that field.\n\nAfter being pressed '+', update of user list and remove of filter\ninput are performed as internal process. This issue is caused by\nincorrect order of these processes. This patch will fix it.\n\nChange-Id: If73584c040846dc82aa482e75f5e5d95dfb6525e\nCloses-Bug: #1543620\n""}, {'number': 6, 'created': '2016-06-28 05:39:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/915f08f6c30921e95e3ce390908403d75220171f', 'message': ""Fix the issue workflow filter do not show all users\n\nWhen user add any group in Project Group Tab, layout will be incorrect\nin case below.\n\nReproduce\n1) Go to /identity\n2) Press 'create project' button, go to 'Project Groups' tab\n3) For example, you have there two default groups: 'admins'\n   and 'nonadmins'. Type 'non' in the left filter field\n4) Filter works correct and now 'all groups' panel has only\n   'nonadmins' group. Press '+' to add 'nonadmins' to project groups\n5) Note that All groups panel is now empty and filter input is empty too.\n   Group admins will not be shown until you type 'admin' in that field.\n\nAfter being pressed '+', update of user list and remove of filter\ninput are performed as internal process. This issue is caused by\nincorrect order of these processes. This patch will fix it.\n\nChange-Id: If73584c040846dc82aa482e75f5e5d95dfb6525e\nCloses-Bug: #1543620\n""}, {'number': 7, 'created': '2016-07-07 07:15:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/03c136d1d96ca3e872e24356b8a9c4ccf8cdfcd7', 'message': ""Fix the issue workflow filter do not show all users\n\nWhen user add any group in Project Group Tab, layout will be incorrect\nin case below.\n\nReproduce\n1) Go to /identity\n2) Press 'create project' button, go to 'Project Groups' tab\n3) For example, you have there two default groups: 'admins'\n   and 'nonadmins'. Type 'non' in the left filter field\n4) Filter works correct and now 'all groups' panel has only\n   'nonadmins' group. Press '+' to add 'nonadmins' to project groups\n5) Note that All groups panel is now empty and filter input is empty too.\n   Group admins will not be shown until you type 'admin' in that field.\n\nAfter being pressed '+', update of user list and remove of filter\ninput are performed as internal process. This issue is caused by\nincorrect order of these processes. This patch will fix it.\n\nChange-Id: If73584c040846dc82aa482e75f5e5d95dfb6525e\nCloses-Bug: #1543620\n""}, {'number': 8, 'created': '2016-07-29 01:36:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/da88604d95b708c6abedbdf8ea9ccb4f259ef9b3', 'message': ""Fix the issue workflow filter do not show all users\n\nWhen user add any group in Project Group Tab, layout will be incorrect\nin case below.\n\nReproduce\n1) Go to /identity\n2) Press 'create project' button, go to 'Project Groups' tab\n3) For example, you have there two default groups: 'admins'\n   and 'nonadmins'. Type 'non' in the left filter field\n4) Filter works correct and now 'all groups' panel has only\n   'nonadmins' group. Press '+' to add 'nonadmins' to project groups\n5) Note that All groups panel is now empty and filter input is empty too.\n   Group admins will not be shown until you type 'admin' in that field.\n\nAfter being pressed '+', update of user list and remove of filter\ninput are performed as internal process. This issue is caused by\nincorrect order of these processes. This patch will fix it.\n\nChange-Id: If73584c040846dc82aa482e75f5e5d95dfb6525e\nCloses-Bug: #1543620\n""}, {'number': 9, 'created': '2016-08-08 05:11:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/d28b783375a9c6f1d3c38c7875ebaafaa6a28627', 'message': ""Fix the issue workflow filter do not show all users\n\nWhen user add any group in Project Group Tab, layout will be incorrect\nin case below.\n\nReproduce\n1) Go to /identity\n2) Press 'create project' button, go to 'Project Groups' tab\n3) For example, you have there two default groups: 'admins'\n   and 'nonadmins'. Type 'non' in the left filter field\n4) Filter works correct and now 'all groups' panel has only\n   'nonadmins' group. Press '+' to add 'nonadmins' to project groups\n5) Note that All groups panel is now empty and filter input is empty too.\n   Group admins will not be shown until you type 'admin' in that field.\n\nAfter being pressed '+', update of user list and remove of filter\ninput are performed as internal process. This issue is caused by\nincorrect order of these processes. This patch will fix it.\n\nChange-Id: If73584c040846dc82aa482e75f5e5d95dfb6525e\nCloses-Bug: #1543620\n""}, {'number': 10, 'created': '2016-08-25 23:35:50.000000000', 'files': ['horizon/static/horizon/js/horizon.membership.js'], 'web_link': 'https://opendev.org/openstack/horizon/commit/8ec0ce07f233b3980e00a22fecfc4a6babd7f1b2', 'message': ""Fix the issue workflow filter do not show all users\n\nWhen user add any group in Project Group Tab, layout will be incorrect\nin case below.\n\nReproduce\n1) Go to /identity\n2) Press 'create project' button, go to 'Project Groups' tab\n3) For example, you have there two default groups: 'admins'\n   and 'nonadmins'. Type 'non' in the left filter field\n4) Filter works correct and now 'all groups' panel has only\n   'nonadmins' group. Press '+' to add 'nonadmins' to project groups\n5) Note that All groups panel is now empty and filter input is empty too.\n   Group admins will not be shown until you type 'admin' in that field.\n\nAfter being pressed '+', update of user list and remove of filter\ninput are performed as internal process. This issue is caused by\nincorrect order of these processes. This patch will fix it.\n\nChange-Id: If73584c040846dc82aa482e75f5e5d95dfb6525e\nCloses-Bug: #1543620\n""}]",3,318485,8ec0ce07f233b3980e00a22fecfc4a6babd7f1b2,63,13,10,17172,,,0,"Fix the issue workflow filter do not show all users

When user add any group in Project Group Tab, layout will be incorrect
in case below.

Reproduce
1) Go to /identity
2) Press 'create project' button, go to 'Project Groups' tab
3) For example, you have there two default groups: 'admins'
   and 'nonadmins'. Type 'non' in the left filter field
4) Filter works correct and now 'all groups' panel has only
   'nonadmins' group. Press '+' to add 'nonadmins' to project groups
5) Note that All groups panel is now empty and filter input is empty too.
   Group admins will not be shown until you type 'admin' in that field.

After being pressed '+', update of user list and remove of filter
input are performed as internal process. This issue is caused by
incorrect order of these processes. This patch will fix it.

Change-Id: If73584c040846dc82aa482e75f5e5d95dfb6525e
Closes-Bug: #1543620
",git fetch https://review.opendev.org/openstack/horizon refs/changes/85/318485/1 && git format-patch -1 --stdout FETCH_HEAD,['horizon/static/horizon/js/horizon.membership.js'],1,2be4e85582ac1861037b1c2726763f68f664b4cc,bug/1543620," // remove input filters $(""input."" + step_slug + ""_filter"").val(""""); "," // remove input filters $(""input."" + step_slug + ""_filter"").val("""");",3,3
openstack%2Fzun~master~I678b108bbd9ca2527b4f9090bb8ef1e84977dee2,openstack/zun,master,I678b108bbd9ca2527b4f9090bb8ef1e84977dee2,"Cleanup tox.ini, enable constraints",MERGED,2016-08-26 14:43:52.000000000,2016-08-29 02:12:52.000000000,2016-08-29 02:12:52.000000000,"[{'_account_id': 3}, {'_account_id': 11536}, {'_account_id': 13248}, {'_account_id': 23058}]","[{'number': 1, 'created': '2016-08-26 14:43:52.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/zun/commit/4b389bc03b54953ddd523fa5b44a4acb34d1c299', 'message': 'Cleanup tox.ini, enable constraints\n\nRemove old and unused constraints environments from tox.ini. Those\nhave never been used. Use standard environments as default list.\n\nEnable use of constraints for all tox based jobs.\n\nFor more information about constraints see:\nhttp://lists.openstack.org/pipermail/openstack-dev/2016-August/101474.html\n\nChange-Id: I678b108bbd9ca2527b4f9090bb8ef1e84977dee2\n'}]",0,361260,4b389bc03b54953ddd523fa5b44a4acb34d1c299,8,4,1,6547,,,0,"Cleanup tox.ini, enable constraints

Remove old and unused constraints environments from tox.ini. Those
have never been used. Use standard environments as default list.

Enable use of constraints for all tox based jobs.

For more information about constraints see:
http://lists.openstack.org/pipermail/openstack-dev/2016-August/101474.html

Change-Id: I678b108bbd9ca2527b4f9090bb8ef1e84977dee2
",git fetch https://review.opendev.org/openstack/zun refs/changes/60/361260/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,4b389bc03b54953ddd523fa5b44a4acb34d1c299,constraints,install_command = pip install -c{env:UPPER_CONSTRAINTS_FILE:https://git.openstack.org/cgit/openstack/requirements/plain/upper-constraints.txt} {opts} {packages},install_command = constraints: {[testenv:common-constraints]install_command} pip install -U {opts} {packages}[testenv:common-constraints] install_command = pip install -c{env:UPPER_CONSTRAINTS_FILE:https://git.openstack.org/cgit/openstack/requirements/plain/upper-constraints.txt} {opts} {packages} [testenv:pep8-constraints] commands = flake8 {posargs} [testenv:venv-constraints] commands = {posargs} [testenv:cover-constraints] commands = python setup.py test --coverage --testr-args='{posargs}' [testenv:docs-constraints] commands = python setup.py build_sphinx [testenv:debug-constraints] commands = oslo_debug_helper {posargs} ,1,21
openstack%2Fsenlin~master~Ia5cdba076ddd518e24ad745ee15bb537ec70ae4d,openstack/senlin,master,Ia5cdba076ddd518e24ad745ee15bb537ec70ae4d,Add version support to schema and spec,MERGED,2016-07-29 03:32:32.000000000,2016-08-29 02:12:17.000000000,2016-08-29 02:12:17.000000000,"[{'_account_id': 3}, {'_account_id': 7404}, {'_account_id': 8246}, {'_account_id': 11034}, {'_account_id': 15857}]","[{'number': 1, 'created': '2016-07-29 03:32:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/6158e681cec38d8c051e7e93df142d02afbef963', 'message': ""[WIP]Add version support to schema and spec\n\nThis patch adds version support to schema and spec. The\nfowlloing changes are made:\n  - Two new property 'min_version' and 'max_version' are\n    added to schema class to identify the supportive version\n    scope;\n  - New method validate_version is added to schema class to\n    verify given version number;\n  - New class VersioningSpec is added. This class derives from\n    Spec class and its __init__ and resolve_value methods are\n    overriden to support version validation. This new class is\n    now used for profile/policy spec.\n\nPartial-bp: schema-spec-version-support\nChange-Id: Ia5cdba076ddd518e24ad745ee15bb537ec70ae4d\n""}, {'number': 2, 'created': '2016-07-29 03:33:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/cbb48c6aba95a7fa8a274505c20a1541ae1fb266', 'message': ""[WIP]Add version support to schema and spec\n\nThis patch adds version support to schema and spec. The\nfollowing changes are made:\n  - Two new property 'min_version' and 'max_version' are\n    added to schema class to identify the supportive version\n    scope;\n  - New method validate_version is added to schema class to\n    verify given version number;\n  - New class VersioningSpec is added. This class derives from\n    Spec class and its __init__ and resolve_value methods are\n    overriden to support version validation. This new class is\n    now used for profile/policy spec.\n\nPartial-bp: schema-spec-version-support\nChange-Id: Ia5cdba076ddd518e24ad745ee15bb537ec70ae4d\n""}, {'number': 3, 'created': '2016-07-29 03:36:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/6b275396ac1e5542569181000dcbf6f57195528c', 'message': ""[WIP]Add version support to schema and spec\n\nThis patch adds version support to schema and spec. The\nfollowing changes are made:\n  - Two new property 'min_version' and 'max_version' are\n    added to schema class to identify the supportive version\n    scope;\n  - New method validate_version is added to schema class to\n    verify given version number;\n  - New class VersioningSpec is added. This class derives from\n    Spec class and its __init__ and resolve_value methods are\n    overriden to support version validation. This new class is\n    now used for profile/policy spec.\n\nPartial-bp: schema-spec-version-support\nChange-Id: Ia5cdba076ddd518e24ad745ee15bb537ec70ae4d\n""}, {'number': 4, 'created': '2016-07-29 03:38:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/46321817cbca2076b822256faaf7bc76f076a4bd', 'message': ""[WIP]Add version support to schema and spec\n\nThis patch adds version support to schema and spec. The\nfollowing changes are made:\n  - Two new property 'min_version' and 'max_version' are\n    added to schema class to identify the supportive version\n    scope;\n  - New method validate_version is added to schema class to\n    verify given version number;\n  - New class VersioningSpec is added. This class derives from\n    Spec class and its __init__ and resolve_value methods are\n    overriden to support version validation. This new class is\n    now used for profile/policy spec.\n\nPartial-bp: schema-spec-version-support\nChange-Id: Ia5cdba076ddd518e24ad745ee15bb537ec70ae4d\n""}, {'number': 5, 'created': '2016-07-29 05:58:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/ce842fff566a3e601266d5136b93b8c235a4c9bb', 'message': ""Add version support to schema and spec\n\nThis patch adds version support to schema and spec. The\nfollowing changes are made:\n  - Two new property 'min_version' and 'max_version' are\n    added to schema class to identify the supportive version\n    scope;\n  - New method validate_version is added to schema class to\n    verify given version number;\n  - New class VersioningSpec is added. This class derives from\n    Spec class and its __init__ and resolve_value methods are\n    overriden to support version validation. This new class is\n    now used for profile/policy spec.\n\nPartial-bp: schema-spec-version-support\nChange-Id: Ia5cdba076ddd518e24ad745ee15bb537ec70ae4d\n""}, {'number': 6, 'created': '2016-07-29 06:57:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/833e7e0c566124968a367a8faa37fbb7bceb3a59', 'message': ""Add version support to schema and spec\n\nThis patch adds version support to schema and spec. The\nfollowing changes are made:\n  - Two new property 'min_version' and 'max_version' are\n    added to schema class to identify the supportive version\n    scope;\n  - New method validate_version is added to schema class to\n    verify given version number;\n  - New class VersioningSpec is added. This class derives from\n    Spec class and its __init__ and resolve_value methods are\n    overriden to support version validation. This new class is\n    now used for profile/policy spec.\n\nPartial-bp: schema-spec-version-support\nChange-Id: Ia5cdba076ddd518e24ad745ee15bb537ec70ae4d\n""}, {'number': 7, 'created': '2016-07-29 08:50:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/39d58cc633ad4c25c446765f1d9d50b144a1ebfe', 'message': ""Add version support to schema and spec\n\nThis patch adds version support to schema and spec. The\nfollowing changes are made:\n  - Two new property 'min_version' and 'max_version' are\n    added to schema class to identify the supportive version\n    scope;\n  - New method validate_version is added to schema class to\n    verify given version number;\n  - New class VersioningSpec is added. This class derives from\n    Spec class and its __init__ and resolve_value methods are\n    overriden to support version validation. This new class is\n    now used for profile/policy spec.\n\nPartial-bp: schema-spec-version-support\nChange-Id: Ia5cdba076ddd518e24ad745ee15bb537ec70ae4d\n""}, {'number': 8, 'created': '2016-08-22 03:56:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/38054c2e317508687dafc626a3afa027d1b24a40', 'message': ""Add version support to schema and spec\n\nThis patch adds version support to schema and spec. The\nfollowing changes are made:\n  - Two new property 'min_version' and 'max_version' are\n    added to schema class to identify the supportive version\n    scope;\n  - New method _validate_version is added to schema class to\n    verify given version number;\n  - Spec class is revised to support version validation.\n\nPartial-bp: schema-spec-version-support\nChange-Id: Ia5cdba076ddd518e24ad745ee15bb537ec70ae4d\n""}, {'number': 9, 'created': '2016-08-22 09:17:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/9b7f0baf4c8552ee2fc96e14a6aeb33e2111916f', 'message': ""Add version support to schema and spec\n\nThis patch adds version support to schema and spec. The\nfollowing changes are made:\n  - Two new property 'min_version' and 'max_version' are\n    added to schema class to identify the supportive version\n    scope;\n  - New method _validate_version is added to schema class to\n    verify given version number;\n  - Spec class is revised to support version validation.\n\nPartial-bp: schema-spec-version-support\nChange-Id: Ia5cdba076ddd518e24ad745ee15bb537ec70ae4d\n""}, {'number': 10, 'created': '2016-08-26 09:50:47.000000000', 'files': ['senlin/tests/unit/test_common_constraints.py', 'senlin/policies/base.py', 'senlin/profiles/base.py', 'senlin/common/schema.py'], 'web_link': 'https://opendev.org/openstack/senlin/commit/7bc5c3c76249482dc1c2b4365419e34f2bc18672', 'message': ""Add version support to schema and spec\n\nThis patch adds version support to schema and spec. The\nfollowing changes are made:\n  - Two new property 'min_version' and 'max_version' are\n    added to schema class to identify the supportive version\n    scope;\n  - New method _validate_version is added to schema class to\n    verify given version number;\n  - Spec class is revised to support version validation.\n\nPartial-bp: schema-spec-version-support\nChange-Id: Ia5cdba076ddd518e24ad745ee15bb537ec70ae4d\n""}]",25,348709,7bc5c3c76249482dc1c2b4365419e34f2bc18672,35,5,10,11034,,,0,"Add version support to schema and spec

This patch adds version support to schema and spec. The
following changes are made:
  - Two new property 'min_version' and 'max_version' are
    added to schema class to identify the supportive version
    scope;
  - New method _validate_version is added to schema class to
    verify given version number;
  - Spec class is revised to support version validation.

Partial-bp: schema-spec-version-support
Change-Id: Ia5cdba076ddd518e24ad745ee15bb537ec70ae4d
",git fetch https://review.opendev.org/openstack/senlin refs/changes/09/348709/2 && git format-patch -1 --stdout FETCH_HEAD,"['senlin/policies/base.py', 'senlin/profiles/base.py', 'senlin/common/schema.py']",3,6158e681cec38d8c051e7e93df142d02afbef963,bp/schema-spec-version-support,"from oslo_log import log as loggingLOG = logging.getLogger(__name__) MIN_VERSION, MAX_VERSION, 'min_version', 'max_version', schema=None, constraints=None, min_version=None, max_version=None): self.min_version = min_version self.max_version = max_version def validate_version(self, version, key): if self.min_version and cmp(self.min_version, version) > 0: msg = _('%(key)s is not supported in version %(version)s.' ) % {'key': key, 'version': version} raise exception.SpecValidationFailed(message=msg) if self.max_version and cmp(self.max_version, version) == 0: msg = _('Warning: %(key)s will be deprecated after version ' '%(version)s!') % {'key': key, 'version': version} LOG.warning(msg) CONSTRAINTS, MIN_VERSION, MAX_VERSION, 'constraints', 'min_version', 'max_version', schema=None, updatable=False, constraints=None, min_version=None, max_version=None): constraints=constraints, min_version=min_version, max_version=max_version) value = None value = schema_item.resolve(raw_value) elif schema_item.has_default(): value = schema_item.get_default() return value class VersioningSpec(Spec): """"""A spec class with version specified."""""" def __init__(self, schema, data, version=None): super(VersioningSpec, self).__init__(schema, data) if not version: # Try to extract version information from spec # directly if it is not provided explicitly. self._version = get_spec_version(data)[1] else: # Version can also be specified explicitly when # versioning spec being initialized. This is useful for # case that sub spec inherit version from parent spec, # e.g. property spec of profile/policy will inherit # version from parent data spec. self._version = version def resolve_value(self, key): """"""Override Spec.resolve_value to add version validation."""""" value = super(VersioningSpec, self).resolve_value(key) self._schema[key].validate_version(self._version, key) return value "," schema=None, constraints=None): CONSTRAINTS, 'constraints', schema=None, updatable=False, constraints=None): constraints=constraints) return schema_item.resolve(raw_value) elif schema_item.has_default(): return schema_item.get_default()",66,13
openstack%2Fsenlin~master~I5b67c4df2395c302b6453a2cd7bf424fec538908,openstack/senlin,master,I5b67c4df2395c302b6453a2cd7bf424fec538908,Fix reraise issue,MERGED,2016-08-26 09:55:56.000000000,2016-08-29 01:58:10.000000000,2016-08-29 01:58:10.000000000,"[{'_account_id': 3}, {'_account_id': 7404}, {'_account_id': 8246}, {'_account_id': 11034}, {'_account_id': 19902}]","[{'number': 1, 'created': '2016-08-26 09:55:56.000000000', 'files': ['senlin/api/middleware/trust.py', 'senlin/common/schema.py'], 'web_link': 'https://opendev.org/openstack/senlin/commit/f69d6594b8a1779378ebf1f7faab10431dd0d024', 'message': ""Fix reraise issue\n\nWhen an exception was caught and rethrown, it should call 'raise'\nwithout any arguments because it shows the place where an exception\noccured initially instead of place where the exception re-raised.\n\nChange-Id: I5b67c4df2395c302b6453a2cd7bf424fec538908\n""}]",0,361048,f69d6594b8a1779378ebf1f7faab10431dd0d024,8,5,1,9323,,,0,"Fix reraise issue

When an exception was caught and rethrown, it should call 'raise'
without any arguments because it shows the place where an exception
occured initially instead of place where the exception re-raised.

Change-Id: I5b67c4df2395c302b6453a2cd7bf424fec538908
",git fetch https://review.opendev.org/openstack/senlin refs/changes/48/361048/1 && git format-patch -1 --stdout FETCH_HEAD,"['senlin/api/middleware/trust.py', 'senlin/common/schema.py']",2,f69d6594b8a1779378ebf1f7faab10431dd0d024,fix_reraise," except (TypeError, ValueError): raise"," except (TypeError, ValueError) as ex: raise ex",3,3
openstack%2Fneutron-fwaas~master~Id99133b2391a4cc3756b8e62f6a2fcc3c5de3d9b,openstack/neutron-fwaas,master,Id99133b2391a4cc3756b8e62f6a2fcc3c5de3d9b,Updated from global requirements,MERGED,2016-08-26 22:09:01.000000000,2016-08-29 01:47:10.000000000,2016-08-29 01:47:10.000000000,"[{'_account_id': 3}, {'_account_id': 10980}, {'_account_id': 13995}]","[{'number': 1, 'created': '2016-08-26 22:09:01.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/neutron-fwaas/commit/35797ac53f2713841e95248c5016c00cd86dbb35', 'message': 'Updated from global requirements\n\nChange-Id: Id99133b2391a4cc3756b8e62f6a2fcc3c5de3d9b\n'}]",0,361495,35797ac53f2713841e95248c5016c00cd86dbb35,7,3,1,11131,,,0,"Updated from global requirements

Change-Id: Id99133b2391a4cc3756b8e62f6a2fcc3c5de3d9b
",git fetch https://review.opendev.org/openstack/neutron-fwaas refs/changes/95/361495/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,35797ac53f2713841e95248c5016c00cd86dbb35,openstack/requirements,neutron-lib>=0.4.0 # Apache-2.0,neutron-lib>=0.3.0 # Apache-2.0,1,1
openstack%2Fdragonflow~master~I33b16c844eb1cfd347249790046aa905e1fedabc,openstack/dragonflow,master,I33b16c844eb1cfd347249790046aa905e1fedabc,Fix metadata environment error in fullstack,ABANDONED,2016-08-25 07:53:52.000000000,2016-08-29 01:47:09.000000000,,"[{'_account_id': 3}, {'_account_id': 11159}, {'_account_id': 20336}]","[{'number': 1, 'created': '2016-08-25 07:53:52.000000000', 'files': ['dragonflow/tests/fullstack/test_metadata_service.py'], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/5826ddc7c38b949b2c13f01f8cef06bd4b03c031', 'message': 'Fix metadata environment error in fullstack\n\nThe metadata process will initialize the tap device at boot time.\nAs a result, the fullstack test will raise error when it starts\nand re-creates the same tap device.\n\nHere I just change the logic of the initialization in fullstack test.\n\nChange-Id: I33b16c844eb1cfd347249790046aa905e1fedabc\nCloses-Bug: #1616744\n'}]",1,360309,5826ddc7c38b949b2c13f01f8cef06bd4b03c031,7,3,1,7805,,,0,"Fix metadata environment error in fullstack

The metadata process will initialize the tap device at boot time.
As a result, the fullstack test will raise error when it starts
and re-creates the same tap device.

Here I just change the logic of the initialization in fullstack test.

Change-Id: I33b16c844eb1cfd347249790046aa905e1fedabc
Closes-Bug: #1616744
",git fetch https://review.opendev.org/openstack/dragonflow refs/changes/09/360309/1 && git format-patch -1 --stdout FETCH_HEAD,['dragonflow/tests/fullstack/test_metadata_service.py'],1,5826ddc7c38b949b2c13f01f8cef06bd4b03c031,bug/1616744, # Rebuild the metadata environment df_metadata_service.environment_setup(), df_metadata_service.environment_setup(),3,1
openstack%2Fdragonflow~master~Idd035c8f812e23b0ec748175c5180f822144b04b,openstack/dragonflow,master,Idd035c8f812e23b0ec748175c5180f822144b04b,Use revision plugin rather than version_db for routers,MERGED,2016-08-24 12:28:08.000000000,2016-08-29 01:37:08.000000000,2016-08-29 01:37:08.000000000,"[{'_account_id': 3}, {'_account_id': 7805}, {'_account_id': 11343}, {'_account_id': 20297}]","[{'number': 1, 'created': '2016-08-24 12:28:08.000000000', 'files': ['dragonflow/neutron/services/l3_router_plugin.py'], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/e9eceb7a1a1148287c6fbc119959ffd3b92fcdcc', 'message': ""Use revision plugin rather than version_db for routers\n\nIn order to use version_db for routers, a database session has to exist\naround the router modification as well as the version creation action.\nThis behaviour is no longer supported by Neutron.\n\nHowever, Neutron have a 'revisions' plugin with the same functionality.\nSo we move routers to use that plugin for its versioning.\n\nNote that this is done for ML2 only.\n\nChange-Id: Idd035c8f812e23b0ec748175c5180f822144b04b\nRelated-Bug: 1613551\nRelated-Bug: 1611533\n""}]",2,359845,e9eceb7a1a1148287c6fbc119959ffd3b92fcdcc,15,4,1,20229,,,0,"Use revision plugin rather than version_db for routers

In order to use version_db for routers, a database session has to exist
around the router modification as well as the version creation action.
This behaviour is no longer supported by Neutron.

However, Neutron have a 'revisions' plugin with the same functionality.
So we move routers to use that plugin for its versioning.

Note that this is done for ML2 only.

Change-Id: Idd035c8f812e23b0ec748175c5180f822144b04b
Related-Bug: 1613551
Related-Bug: 1611533
",git fetch https://review.opendev.org/openstack/dragonflow refs/changes/45/359845/1 && git format-patch -1 --stdout FETCH_HEAD,['dragonflow/neutron/services/l3_router_plugin.py'],1,e9eceb7a1a1148287c6fbc119959ffd3b92fcdcc,bug/1613551," router = super(DFL3RouterPlugin, self).create_router(context, router) router_version = router['revision'] router = super(DFL3RouterPlugin, self).update_router( context, router_id, router) router_version = router['revision'] ret_val = super(DFL3RouterPlugin, self).delete_router(context, router_id) result = super(DFL3RouterPlugin, self).add_router_interface( context, router_id, interface_info) router = self.get_router(context, router_id) router_version = router['revision'] new_router = super(DFL3RouterPlugin, self).remove_router_interface( router = self.get_router(context, router_id) router_version = router['revision']"," with context.session.begin(subtransactions=True): router = super(DFL3RouterPlugin, self).create_router( context, router) router_version = version_db._create_db_version_row( context.session, router['id'] ) with context.session.begin(subtransactions=True): router = super(DFL3RouterPlugin, self).update_router( context, router_id, router) router_version = version_db._update_db_version_row( context.session, router['id']) with context.session.begin(subtransactions=True): ret_val = super(DFL3RouterPlugin, self).delete_router(context, router_id) version_db._delete_db_version_row(context.session, router_id) with context.session.begin(subtransactions=True): result = super(DFL3RouterPlugin, self).add_router_interface( context, router_id, interface_info) router_version = version_db._update_db_version_row( context.session, router_id) with context.session.begin(subtransactions=True): new_router = super(DFL3RouterPlugin, self).remove_router_interface( router_version = version_db._update_db_version_row( context.session, router_id)",14,25
openstack%2Fopenstack-manuals~master~I8b6ea24340f0e9eea500000d01ab65fa2ea45b03,openstack/openstack-manuals,master,I8b6ea24340f0e9eea500000d01ab65fa2ea45b03,"[ha-guide] Use ""project"" to replace ""tenant"" term in use-guide",MERGED,2016-08-18 00:50:51.000000000,2016-08-29 01:34:27.000000000,2016-08-29 01:34:27.000000000,"[{'_account_id': 3}, {'_account_id': 6804}, {'_account_id': 10497}, {'_account_id': 10607}, {'_account_id': 16237}, {'_account_id': 17130}]","[{'number': 1, 'created': '2016-08-18 00:50:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/e8466b0d7aaa3f9d4dfdd74ef4ad65f1f1cce9fb', 'message': '[ha-guide] Use ""project"" to replace ""tenant"" term in use-guide\n\nThis patch use ""project"" to replace ""tenant"" term in ha-guide for cleanup.\n\nChange-Id: I8b6ea24340f0e9eea500000d01ab65fa2ea45b03\n'}, {'number': 2, 'created': '2016-08-18 01:15:32.000000000', 'files': ['doc/ha-guide/source/intro-ha-arch-keepalived.rst'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/0265a3914004d20b3cfc49322349a1a14fc3d6ac', 'message': '[ha-guide] Use ""project"" to replace ""tenant"" term in use-guide\n\nThis patch use ""project"" to replace ""tenant"" term in ha-guide for cleanup.\n\nPartial-Bug: #1475005\nChange-Id: I8b6ea24340f0e9eea500000d01ab65fa2ea45b03\n'}]",0,356819,0265a3914004d20b3cfc49322349a1a14fc3d6ac,12,6,2,14151,,,0,"[ha-guide] Use ""project"" to replace ""tenant"" term in use-guide

This patch use ""project"" to replace ""tenant"" term in ha-guide for cleanup.

Partial-Bug: #1475005
Change-Id: I8b6ea24340f0e9eea500000d01ab65fa2ea45b03
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/19/356819/2 && git format-patch -1 --stdout FETCH_HEAD,['doc/ha-guide/source/intro-ha-arch-keepalived.rst'],1,e8466b0d7aaa3f9d4dfdd74ef4ad65f1f1cce9fb,, driver does not allow high availability for the project load, driver does not allow high availability for the tenant load,1,1
openstack%2Fopenstack-manuals~master~I4ef7db5634968da6b8eed14a4b650a43228a18f1,openstack/openstack-manuals,master,I4ef7db5634968da6b8eed14a4b650a43228a18f1,"[image-guide] Use ""project"" to replace ""tenant"" term in use-guide",MERGED,2016-08-18 00:48:38.000000000,2016-08-29 01:34:11.000000000,2016-08-29 01:34:11.000000000,"[{'_account_id': 3}, {'_account_id': 6804}, {'_account_id': 10497}, {'_account_id': 10607}, {'_account_id': 16237}, {'_account_id': 17130}]","[{'number': 1, 'created': '2016-08-18 00:48:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/fab60f21637de21a5f35ab4fd914b9ba7ca12b7e', 'message': '[image-guide] Use ""project"" to replace ""tenant"" term in use-guide\n\nThis patch use ""project"" to replace ""tenant"" term in image-guide for cleanup.\n\nChange-Id: I4ef7db5634968da6b8eed14a4b650a43228a18f1\n'}, {'number': 2, 'created': '2016-08-18 01:15:14.000000000', 'files': ['doc/image-guide/source/share-images.rst'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/47a8a6a2d01e8a6910956b59343cc393e47977cc', 'message': '[image-guide] Use ""project"" to replace ""tenant"" term in use-guide\n\nThis patch use ""project"" to replace ""tenant"" term in image-guide for cleanup.\n\nPartial-Bug: #1475005\nChange-Id: I4ef7db5634968da6b8eed14a4b650a43228a18f1\n'}]",0,356817,47a8a6a2d01e8a6910956b59343cc393e47977cc,12,6,2,14151,,,0,"[image-guide] Use ""project"" to replace ""tenant"" term in use-guide

This patch use ""project"" to replace ""tenant"" term in image-guide for cleanup.

Partial-Bug: #1475005
Change-Id: I4ef7db5634968da6b8eed14a4b650a43228a18f1
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/17/356817/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/image-guide/source/share-images.rst'],1,fab60f21637de21a5f35ab4fd914b9ba7ca12b7e,,#. A potential consumer provides the producer with the consumer's project,#. A potential consumer provides the producer with the consumer's tenant,1,1
openstack%2Fsenlin~master~Ib84fb476ca10065c2ceb899d9e2e698bfa9ba425,openstack/senlin,master,Ib84fb476ca10065c2ceb899d9e2e698bfa9ba425,Remove 'description' from Action class,MERGED,2016-08-23 09:05:25.000000000,2016-08-29 01:32:44.000000000,2016-08-29 01:32:44.000000000,"[{'_account_id': 3}, {'_account_id': 7404}, {'_account_id': 8246}]","[{'number': 1, 'created': '2016-08-23 09:05:25.000000000', 'files': ['senlin/tests/unit/engine/actions/test_action_base.py', 'senlin/engine/actions/base.py'], 'web_link': 'https://opendev.org/openstack/senlin/commit/ff2fbd541fe0b72a12f32d7fd85b5f7fab87a8ce', 'message': ""Remove 'description' from Action class\n\nWe were not using this column/field at all. This patch proposes a\ncomplete removal.\n\nChange-Id: Ib84fb476ca10065c2ceb899d9e2e698bfa9ba425\n""}]",0,359055,ff2fbd541fe0b72a12f32d7fd85b5f7fab87a8ce,8,3,1,8246,,,0,"Remove 'description' from Action class

We were not using this column/field at all. This patch proposes a
complete removal.

Change-Id: Ib84fb476ca10065c2ceb899d9e2e698bfa9ba425
",git fetch https://review.opendev.org/openstack/senlin refs/changes/55/359055/1 && git format-patch -1 --stdout FETCH_HEAD,"['senlin/tests/unit/engine/actions/test_action_base.py', 'senlin/engine/actions/base.py']",2,ff2fbd541fe0b72a12f32d7fd85b5f7fab87a8ce,action-description,," # TODO(Qiming): make description a db column self.description = kwargs.get('description', '') ",0,6
openstack%2Fsahara~master~I155f03b08e967947fe0d073b25d7d37b589f70ca,openstack/sahara,master,I155f03b08e967947fe0d073b25d7d37b589f70ca,Clean imports in code,ABANDONED,2016-08-25 06:43:13.000000000,2016-08-29 01:32:38.000000000,,"[{'_account_id': 3}, {'_account_id': 8932}, {'_account_id': 12038}, {'_account_id': 15905}, {'_account_id': 19554}]","[{'number': 1, 'created': '2016-08-25 06:43:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/ef21606c8aed7a0eac028e606296ed33628148cc', 'message': 'Clean imports in code\n\nThis patch merges all lines importing i18n into 1 line:\n\nhttp://docs.openstack.org/developer/hacking/#imports\n\nChange-Id: I155f03b08e967947fe0d073b25d7d37b589f70ca\n'}, {'number': 2, 'created': '2016-08-25 07:51:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/5cc764929f7179ae1731130ff601ba9b8c79e50c', 'message': 'Clean imports in code\n\nThis patch merges all lines importing i18n into 1 line:\n\nhttp://docs.openstack.org/developer/hacking/#imports\n\nChange-Id: I155f03b08e967947fe0d073b25d7d37b589f70ca\n'}, {'number': 3, 'created': '2016-08-25 09:02:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/d2efeeb0d15e65b586360c3657ff3607dd19f786', 'message': 'Clean imports in code\n\nThis patch merges all lines importing i18n into 1 line:\n\nhttp://docs.openstack.org/developer/hacking/#imports\n\nChange-Id: I155f03b08e967947fe0d073b25d7d37b589f70ca\n'}, {'number': 4, 'created': '2016-08-25 09:06:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/429d7c2b95943c8277d164dda481c0bf8a3a586e', 'message': 'Clean imports in code\n\nThis patch merges all lines importing i18n into 1 line:\n\nhttp://docs.openstack.org/developer/hacking/#imports\n\nChange-Id: I155f03b08e967947fe0d073b25d7d37b589f70ca\n'}, {'number': 5, 'created': '2016-08-25 09:25:41.000000000', 'files': ['sahara/service/volumes.py', 'sahara/service/coordinator.py', 'sahara/plugins/mapr/base/base_cluster_configurer.py', 'sahara/service/ntp_service.py', 'sahara/service/edp/job_manager.py', 'sahara/service/engine.py', 'sahara/plugins/cdh/client/cms.py', 'sahara/plugins/labels.py'], 'web_link': 'https://opendev.org/openstack/sahara/commit/4ba7e620c43d069e1146769c56c7da9a6964e783', 'message': 'Clean imports in code\n\nThis patch merges all lines importing i18n into 1 line:\nThis will become beautiful.\n\nChange-Id: I155f03b08e967947fe0d073b25d7d37b589f70ca\n'}]",1,360275,4ba7e620c43d069e1146769c56c7da9a6964e783,13,5,5,19554,,,0,"Clean imports in code

This patch merges all lines importing i18n into 1 line:
This will become beautiful.

Change-Id: I155f03b08e967947fe0d073b25d7d37b589f70ca
",git fetch https://review.opendev.org/openstack/sahara refs/changes/75/360275/1 && git format-patch -1 --stdout FETCH_HEAD,"['sahara/service/coordinator.py', 'sahara/service/volumes.py', 'sahara/plugins/mapr/base/base_cluster_configurer.py', 'sahara/service/ntp_service.py', 'sahara/service/edp/job_manager.py', 'sahara/plugins/labels.py', 'sahara/service/engine.py']",7,ef21606c8aed7a0eac028e606296ed33628148cc,clean_import,"from sahara.i18n import _, _LI, _LW",from sahara.i18n import _ from sahara.i18n import _LI from sahara.i18n import _LW,7,20
openstack%2Fsenlin~master~Ia6245d502fde38cd4d63aa4a786b6296b22a37a1,openstack/senlin,master,Ia6245d502fde38cd4d63aa4a786b6296b22a37a1,Update api-ref configuration,MERGED,2016-08-26 13:03:20.000000000,2016-08-29 01:29:23.000000000,2016-08-29 01:29:23.000000000,"[{'_account_id': 3}, {'_account_id': 8246}]","[{'number': 1, 'created': '2016-08-26 13:03:20.000000000', 'files': ['api-ref/source/conf.py'], 'web_link': 'https://opendev.org/openstack/senlin/commit/6d41feb58dd836d426c9b6f025846dbbf7295097', 'message': 'Update api-ref configuration\n\nThe os-api-ref 1.0.0 is out. We can remove the support to older version\nnow.\n\nChange-Id: Ia6245d502fde38cd4d63aa4a786b6296b22a37a1\n'}]",0,361160,6d41feb58dd836d426c9b6f025846dbbf7295097,6,2,1,8246,,,0,"Update api-ref configuration

The os-api-ref 1.0.0 is out. We can remove the support to older version
now.

Change-Id: Ia6245d502fde38cd4d63aa4a786b6296b22a37a1
",git fetch https://review.opendev.org/openstack/senlin refs/changes/60/361160/1 && git format-patch -1 --stdout FETCH_HEAD,['api-ref/source/conf.py'],1,6d41feb58dd836d426c9b6f025846dbbf7295097,update-api-ref,"import openstackdocstheme # noqa extensions = [ 'os_api_ref', ] html_theme = 'openstackdocs' html_theme_path = [openstackdocstheme.get_html_theme_path()] html_theme_options = { ""sidebar_mode"": ""toc"", }"," if getattr(os_api_ref, 'THEME', 'olsosphinx') == 'openstackdocstheme': # We are on the new version with openstackdocstheme support extensions = [ 'os_api_ref', ] import openstackdocstheme # noqa html_theme = 'openstackdocs' html_theme_path = [openstackdocstheme.get_html_theme_path()] html_theme_options = { ""sidebar_mode"": ""toc"", } else: # We are on the old version without openstackdocstheme support extensions = [ 'os_api_ref', 'oslosphinx', ] # End temporary block",9,23
openstack%2Fzaqar~master~Id86adcc7aa500d7bf92b77205bbf44adee0996b3,openstack/zaqar,master,Id86adcc7aa500d7bf92b77205bbf44adee0996b3,Let v2 tempest base on the base tests,MERGED,2016-06-02 01:32:55.000000000,2016-08-29 01:29:13.000000000,2016-08-29 01:29:13.000000000,"[{'_account_id': 3}, {'_account_id': 6484}, {'_account_id': 8846}]","[{'number': 1, 'created': '2016-06-02 01:32:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/81a806cd3a970bdcbdb15db4e4ebee718c1f4122', 'message': 'Let v2 tempest tests base on the base tests.\n\nNow v2 tempest tests base on v1.1. We should not rely on v1.1 since\nv1.1 will be deprecated soon.\n\nChange-Id: Id86adcc7aa500d7bf92b77205bbf44adee0996b3\n'}, {'number': 2, 'created': '2016-06-06 22:30:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/f6f551eaf405f7bfcd42d8f84cffa048c215fd31', 'message': 'Let v2 tempest tests base on the base tests.\n\nNow v2 tempest tests base on v1.1. We should not rely on v1.1 since\nv1.1 will be deprecated soon.\n\nChange-Id: Id86adcc7aa500d7bf92b77205bbf44adee0996b3\n'}, {'number': 3, 'created': '2016-06-12 06:09:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/af722dff6f61267b88e18f3215241f6a28401257', 'message': 'Let v2 tempest tests base on the base tests.\n\nNow v2 tempest tests base on v1.1. We should not rely on v1.1 since\nv1.1 will be deprecated soon.\n\nDepends-on: #328670\nChange-Id: Id86adcc7aa500d7bf92b77205bbf44adee0996b3\n'}, {'number': 4, 'created': '2016-06-12 06:11:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/05248614b37cc8554f56ef6df66a053944c1aaff', 'message': 'Let v2 tempest tests base on the base tests.\n\nNow v2 tempest tests base on v1.1. We should not rely on v1.1 since\nv1.1 will be deprecated soon.\n\nDepends-on: Ica1ff5ac5ceaf675993122243830a5cae0cd8d09\nChange-Id: Id86adcc7aa500d7bf92b77205bbf44adee0996b3\n'}, {'number': 5, 'created': '2016-06-19 19:33:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/5f25e0a05e84a20b6f3eec2d7da3d8689d267990', 'message': 'Let v2 tempest tests base on the base tests.\n\nNow v2 tempest tests base on v1.1. We should not rely on v1.1 since\nv1.1 will be deprecated soon.\n\nDepends-on: Ica1ff5ac5ceaf675993122243830a5cae0cd8d09\nChange-Id: Id86adcc7aa500d7bf92b77205bbf44adee0996b3\n'}, {'number': 6, 'created': '2016-06-20 01:10:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/77c77b08d1798fd396b7792b368014bee2c2c4de', 'message': 'Let v2 tempest base on the base tests.\n\nNow v2 tempest tests base on v1.1. We should not rely on v1.1 since\nv1.1 will be deprecated soon.\n\nDepends-on: Ica1ff5ac5ceaf675993122243830a5cae0cd8d09\nChange-Id: Id86adcc7aa500d7bf92b77205bbf44adee0996b3\n'}, {'number': 7, 'created': '2016-06-22 17:25:59.000000000', 'files': ['zaqar/tests/tempest_plugin/tests/v2/test_queues.py', 'zaqar/tests/tempest_plugin/tests/base.py'], 'web_link': 'https://opendev.org/openstack/zaqar/commit/53b595451589bd3b4a64669e9be143e4f2157e7b', 'message': 'Let v2 tempest base on the base tests\n\nNow v2 tempest tests base on v1.1. We should not rely on v1.1 since\nv1.1 will be deprecated soon.\n\nDepends-on: Ica1ff5ac5ceaf675993122243830a5cae0cd8d09\nChange-Id: Id86adcc7aa500d7bf92b77205bbf44adee0996b3\n'}]",1,324161,53b595451589bd3b4a64669e9be143e4f2157e7b,20,3,7,15054,,,0,"Let v2 tempest base on the base tests

Now v2 tempest tests base on v1.1. We should not rely on v1.1 since
v1.1 will be deprecated soon.

Depends-on: Ica1ff5ac5ceaf675993122243830a5cae0cd8d09
Change-Id: Id86adcc7aa500d7bf92b77205bbf44adee0996b3
",git fetch https://review.opendev.org/openstack/zaqar refs/changes/61/324161/4 && git format-patch -1 --stdout FETCH_HEAD,"['zaqar/tests/tempest_plugin/tests/v2/test_queues.py', 'zaqar/tests/tempest_plugin/tests/base.py']",2,81a806cd3a970bdcbdb15db4e4ebee718c1f4122,v2_tempest_test,"class BaseV2MessagingTest(BaseMessagingTest): """"""Base class for the Messaging (Zaqar) v2 tests."""""" @classmethod def generate_message_body(cls, repeat=1): """"""Wrapper utility that sets the metadata of a queue."""""" message_ttl = data_utils.\ rand_int_id(start=60, end=CONF.messaging.max_message_ttl) key = data_utils.arbitrary_string(size=20, base_text='MessagingKey') value = data_utils.arbitrary_string(size=20, base_text='MessagingValue') message_body = {key: value} body = ([{'body': message_body, 'ttl': message_ttl}] * repeat) rbody = {'messages': body} return rbody","class BaseV2MessagingTest(BaseV11MessagingTest): """"""Base class for the Messaging (Zaqar) v1.1 tests.""""""",18,3
openstack%2Fcinder~master~Ib17d7f4fe8a5829ae6fd37f50b7cee68e7199886,openstack/cinder,master,Ib17d7f4fe8a5829ae6fd37f50b7cee68e7199886,Get ready for os-api-ref sphinx theme change,ABANDONED,2016-08-26 07:44:38.000000000,2016-08-29 01:26:35.000000000,,"[{'_account_id': 3}, {'_account_id': 8846}, {'_account_id': 9732}, {'_account_id': 10621}, {'_account_id': 10622}, {'_account_id': 11904}, {'_account_id': 12016}, {'_account_id': 12017}, {'_account_id': 12032}, {'_account_id': 12176}, {'_account_id': 12369}, {'_account_id': 12822}, {'_account_id': 13394}, {'_account_id': 14384}, {'_account_id': 14797}, {'_account_id': 15249}, {'_account_id': 15296}, {'_account_id': 15386}, {'_account_id': 15905}, {'_account_id': 15941}, {'_account_id': 16160}, {'_account_id': 16422}, {'_account_id': 16595}, {'_account_id': 16862}, {'_account_id': 16897}, {'_account_id': 16898}, {'_account_id': 17852}, {'_account_id': 18120}, {'_account_id': 18444}, {'_account_id': 21976}, {'_account_id': 22126}, {'_account_id': 22248}, {'_account_id': 22450}]","[{'number': 1, 'created': '2016-08-26 07:44:38.000000000', 'files': ['api-ref/v2/source/conf.py', 'api-ref/v1/source/conf.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/e90344d2e81db9fac895898d392fa37235b90404', 'message': 'Get ready for os-api-ref sphinx theme change\n\nWe need some magic to keep the build working as we move away from\noslosphinx and towards openstackdocstheme, the theme we are going\nto use for all the docs.\n\nFor more details see:\nhttp://lists.openstack.org/pipermail/openstack-dev/2016-August/101996.html\n\nChange-Id: Ib17d7f4fe8a5829ae6fd37f50b7cee68e7199886\n'}]",0,360949,e90344d2e81db9fac895898d392fa37235b90404,35,33,1,20079,,,0,"Get ready for os-api-ref sphinx theme change

We need some magic to keep the build working as we move away from
oslosphinx and towards openstackdocstheme, the theme we are going
to use for all the docs.

For more details see:
http://lists.openstack.org/pipermail/openstack-dev/2016-August/101996.html

Change-Id: Ib17d7f4fe8a5829ae6fd37f50b7cee68e7199886
",git fetch https://review.opendev.org/openstack/cinder refs/changes/49/360949/1 && git format-patch -1 --stdout FETCH_HEAD,"['api-ref/v2/source/conf.py', 'api-ref/v1/source/conf.py']",2,e90344d2e81db9fac895898d392fa37235b90404,os-api-ref-1.0.0-prep,"import os_api_ref if getattr(os_api_ref, 'THEME', 'olsosphinx') == 'openstackdocstheme': # We are on the new version with openstackdocstheme support extensions = [ 'os_api_ref', ] import openstackdocstheme # noqa html_theme = 'openstackdocs' html_theme_path = [openstackdocstheme.get_html_theme_path()] html_theme_options = { ""sidebar_mode"": ""toc"", } else: # We are on the old version without openstackdocstheme support extensions = [ 'os_api_ref', 'oslosphinx', ] # End temporary block","extensions = [ 'os_api_ref', 'oslosphinx', ]",52,8
openstack%2Fsenlin~master~I3ad3c9d891c857d9c6cfc08dcee2e3762d566115,openstack/senlin,master,I3ad3c9d891c857d9c6cfc08dcee2e3762d566115,Add negative API tests for profile validation,MERGED,2016-08-28 13:19:12.000000000,2016-08-29 01:22:19.000000000,2016-08-29 01:22:19.000000000,"[{'_account_id': 3}, {'_account_id': 8246}]","[{'number': 1, 'created': '2016-08-28 13:19:12.000000000', 'files': ['senlin/tests/tempest/api/profiles/test_profile_validate_negative.py'], 'web_link': 'https://opendev.org/openstack/senlin/commit/1260f2dfd29b007a3fd1954b869a19e631c3c66c', 'message': 'Add negative API tests for profile validation\n\nAdd negative API tests for profile validation\n\nChange-Id: I3ad3c9d891c857d9c6cfc08dcee2e3762d566115\n'}]",0,361740,1260f2dfd29b007a3fd1954b869a19e631c3c66c,6,2,1,7404,,,0,"Add negative API tests for profile validation

Add negative API tests for profile validation

Change-Id: I3ad3c9d891c857d9c6cfc08dcee2e3762d566115
",git fetch https://review.opendev.org/openstack/senlin refs/changes/40/361740/1 && git format-patch -1 --stdout FETCH_HEAD,['senlin/tests/tempest/api/profiles/test_profile_validate_negative.py'],1,1260f2dfd29b007a3fd1954b869a19e631c3c66c,profile_validate_negative,"# Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import copy from tempest.lib import decorators from tempest.lib import exceptions from tempest import test from senlin.tests.tempest.api import base from senlin.tests.tempest.common import constants class TestProfileValidateNegativeBadRequest(base.BaseSenlinAPITest): @test.attr(type=['negative']) @decorators.idempotent_id('d128781c-808f-4dee-b8b6-abe4def40eb1') def test_profile_validate_empty_body(self): params = { } # Verify badrequest exception(400) is raised. self.assertRaises(exceptions.BadRequest, self.client.validate_obj, 'profiles', params) @test.attr(type=['negative']) @decorators.idempotent_id('7c66eaa1-a78c-4b60-9b0f-c6fa91f28778') def test_profile_validate_no_spec(self): params = { 'profile': { } } # Verify badrequest exception(400) is raised. self.assertRaises(exceptions.BadRequest, self.client.validate_obj, 'profiles', params) @test.attr(type=['negative']) @decorators.idempotent_id('d661c452-3752-4196-9649-4b44ac9c55a6') def test_profile_validate_profile_type_incorrect(self): spec = copy.deepcopy(constants.spec_nova_server) spec['type'] = 'senlin.profile.bogus' params = { 'profile': { 'name': 'test-profile', 'spec': spec } } # Verify badrequest exception(400) is raised. self.assertRaises(exceptions.BadRequest, self.client.validate_obj, 'profiles', params) @test.attr(type=['negative']) @decorators.idempotent_id('c0fe55cf-608c-4e89-bf85-4561805fc867') def test_profile_validate_spec_validation_failed(self): spec = copy.deepcopy(constants.spec_nova_server) spec['properties']['bogus'] = 'foo' params = { 'profile': { 'name': 'test-profile', 'spec': spec } } # Verify badrequest exception(400) is raised. self.assertRaises(exceptions.BadRequest, self.client.validate_obj, 'profiles', params) ",,76,0
openstack%2Fsenlin~master~If00b38b67656b460c9f438833fa408921ae90449,openstack/senlin,master,If00b38b67656b460c9f438833fa408921ae90449,Add API tests for profile validation,MERGED,2016-08-28 13:19:12.000000000,2016-08-29 01:22:13.000000000,2016-08-29 01:22:13.000000000,"[{'_account_id': 3}, {'_account_id': 8246}]","[{'number': 1, 'created': '2016-08-28 13:19:12.000000000', 'files': ['senlin/tests/tempest/common/clustering_client.py'], 'web_link': 'https://opendev.org/openstack/senlin/commit/5021d026e9250212b5e2a91c8bb706abfaaa4bbb', 'message': 'Add API tests for profile validation\n\nAdd positive API tests for profile validation\n\nChange-Id: If00b38b67656b460c9f438833fa408921ae90449\n'}]",0,361739,5021d026e9250212b5e2a91c8bb706abfaaa4bbb,6,2,1,7404,,,0,"Add API tests for profile validation

Add positive API tests for profile validation

Change-Id: If00b38b67656b460c9f438833fa408921ae90449
",git fetch https://review.opendev.org/openstack/senlin refs/changes/39/361739/1 && git format-patch -1 --stdout FETCH_HEAD,['senlin/tests/tempest/common/clustering_client.py'],1,5021d026e9250212b5e2a91c8bb706abfaaa4bbb,profile_validate_negative," def validate_obj(self, obj_type, attrs): uri = '{0}/{1}/validate'.format(self.version, obj_type) headers = {'openstack-api-version': 'clustering 1.2'} resp, body = self.post(uri, body=jsonutils.dumps(attrs), headers=headers) return self._parsed_resp(resp, body) ",,8,0
openstack%2Fopenstack-manuals~master~Ida4a728ff2420e4e9540b87ea4ba1afa2b5a8e3c,openstack/openstack-manuals,master,Ida4a728ff2420e4e9540b87ea4ba1afa2b5a8e3c,Remove ratelimit in nova api configuration guide,MERGED,2016-08-17 14:05:20.000000000,2016-08-29 01:12:06.000000000,2016-08-29 01:12:06.000000000,"[{'_account_id': 3}, {'_account_id': 6804}, {'_account_id': 10497}, {'_account_id': 10607}, {'_account_id': 14643}, {'_account_id': 17130}, {'_account_id': 22165}]","[{'number': 1, 'created': '2016-08-17 14:05:20.000000000', 'files': ['doc/config-reference/source/compute/api.rst'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/debafd7975938b9d985d16bdf1c156a8ffeb609d', 'message': 'Remove ratelimit in nova api configuration guide\n\nIn this patch https://review.openstack.org/#/c/311653/  , the\nratelimit filter had been removed, delete.\n\nChange-Id: Ida4a728ff2420e4e9540b87ea4ba1afa2b5a8e3c\n'}]",0,356487,debafd7975938b9d985d16bdf1c156a8ffeb609d,13,7,1,18777,,,0,"Remove ratelimit in nova api configuration guide

In this patch https://review.openstack.org/#/c/311653/  , the
ratelimit filter had been removed, delete.

Change-Id: Ida4a728ff2420e4e9540b87ea4ba1afa2b5a8e3c
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/87/356487/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/config-reference/source/compute/api.rst'],1,debafd7975938b9d985d16bdf1c156a8ffeb609d,remove_ratelimit_config,,"Configure Compute API rate limiting ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ OpenStack Compute supports API rate limiting for the OpenStack API. The rate limiting allows an administrator to configure limits on the type and number of API calls that can be made in a specific time interval. When API rate limits are exceeded, HTTP requests return an error with a status code of ``403 Forbidden``. Rate limiting is not available for the EC2 API. Define limits ~~~~~~~~~~~~~ To define limits, set these values: * The **HTTP method** used in the API call, typically one of GET, PUT, POST, or DELETE. * A **human readable URI** that is used as a friendly description of where the limit is applied. * A **regular expression**. The limit is applied to all URIs that match the regular expression and HTTP method. * A **limit value** that specifies the maximum count of units before the limit takes effect. * An **interval** that specifies time frame to which the limit is applied. The interval can be SECOND, MINUTE, HOUR, or DAY. Rate limits are applied in relative order to the HTTP method, going from least to most specific. Default limits ~~~~~~~~~~~~~~ Normally, you install OpenStack Compute with the following limits enabled: .. list-table:: Default API rate limits :header-rows: 1 * - HTTP method - API URI - API regular expression - Limit * - POST - any URI (\*) - .\* - 120 per minute * - POST - /servers - ^/servers - 120 per minute * - PUT - any URI (\*) - .\* - 120 per minute * - GET - \*changes-since\* - .\*changes-since.\* - 120 per minute * - DELETE - any URI (\*) - .\* - 120 per minute * - GET - \*/os-fping - ^/os-fping - 12 per minute Configure and change limits ~~~~~~~~~~~~~~~~~~~~~~~~~~~ As part of the WSGI pipeline, the ``etc/nova/api-paste.ini`` file defines the actual limits. To enable limits, include the ``ratelimit`` filter in the API pipeline specification. If the ``ratelimit`` filter is removed from the pipeline, limiting is disabled. You must also define the rate limit filter. The lines appear as follows: .. code-block:: ini [pipeline:openstack_compute_api_v2] pipeline = faultwrap authtoken keystonecontext ratelimit osapi_compute_app_v2 [pipeline:openstack_volume_api_v1] pipeline = faultwrap authtoken keystonecontext ratelimit osapi_volume_app_v1 [filter:ratelimit] paste.filter_factory = nova.api.openstack.compute.limits:RateLimitingMiddleware.factory To modify the limits, add a ``limits`` specification to the ``[filter:ratelimit]`` section of the file. Specify the limits in this order: #. HTTP method #. friendly URI #. regex #. limit #. interval The following example shows the default rate-limiting values: .. code-block:: ini [filter:ratelimit] paste.filter_factory = nova.api.openstack.compute.limits:RateLimitingMiddleware.factory limits =(POST, ""*"", .*, 120, MINUTE);(POST, ""*/servers"", ^/servers, 120, MINUTE);(PUT, ""*"", .*, 120, MINUTE);(GET, ""*changes-since*"", .*changes-since.*, 120, MINUTE);(DELETE, ""*"", .*, 120, MINUTE);(GET, ""*/os-fping"", ^/os-fping, 12, MINUTE) ",0,107
openstack%2Fcinder~master~I5c4169fa6a31d2951851bd3eb44d849f2c7eeed5,openstack/cinder,master,I5c4169fa6a31d2951851bd3eb44d849f2c7eeed5,Unmanaging vol/snap reduces quota incorrectly,ABANDONED,2015-10-08 09:26:54.000000000,2016-08-29 01:11:50.000000000,,"[{'_account_id': 3}, {'_account_id': 1207}, {'_account_id': 2243}, {'_account_id': 2759}, {'_account_id': 8846}, {'_account_id': 8871}, {'_account_id': 8912}, {'_account_id': 9003}, {'_account_id': 9008}, {'_account_id': 9535}, {'_account_id': 9732}, {'_account_id': 10115}, {'_account_id': 10621}, {'_account_id': 10622}, {'_account_id': 11600}, {'_account_id': 11611}, {'_account_id': 11904}, {'_account_id': 12017}, {'_account_id': 12032}, {'_account_id': 12033}, {'_account_id': 12176}, {'_account_id': 12249}, {'_account_id': 12369}, {'_account_id': 12491}, {'_account_id': 12540}, {'_account_id': 12778}, {'_account_id': 12822}, {'_account_id': 13144}, {'_account_id': 13203}, {'_account_id': 13394}, {'_account_id': 13628}, {'_account_id': 14206}, {'_account_id': 14242}, {'_account_id': 14259}, {'_account_id': 14274}, {'_account_id': 14305}, {'_account_id': 14384}, {'_account_id': 14587}, {'_account_id': 14797}, {'_account_id': 14969}, {'_account_id': 15054}, {'_account_id': 15249}, {'_account_id': 15296}, {'_account_id': 15374}, {'_account_id': 15386}, {'_account_id': 15764}, {'_account_id': 15831}, {'_account_id': 15941}, {'_account_id': 16160}, {'_account_id': 16269}, {'_account_id': 16422}, {'_account_id': 16595}, {'_account_id': 16660}, {'_account_id': 16834}, {'_account_id': 16862}, {'_account_id': 16880}, {'_account_id': 16897}, {'_account_id': 16898}, {'_account_id': 16941}, {'_account_id': 16952}, {'_account_id': 17103}, {'_account_id': 17405}, {'_account_id': 17492}, {'_account_id': 17852}, {'_account_id': 18120}, {'_account_id': 18402}, {'_account_id': 18444}, {'_account_id': 18752}, {'_account_id': 19146}, {'_account_id': 19852}, {'_account_id': 19917}, {'_account_id': 19933}, {'_account_id': 20105}, {'_account_id': 20442}, {'_account_id': 20629}, {'_account_id': 21193}, {'_account_id': 22126}]","[{'number': 1, 'created': '2015-10-08 09:26:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/df96a8707ce1627dc06ff7ee41f705da5db7e887', 'message': ""Unmanage volume/snapshot reduce quota incorrectly\n\nWhen managing volume/snapshot get error, the quota\nusage will roll back and set the new volume/snapshot\nstatus to error, but then delete/unmanage this resource,\nquota usage will be reduced again, it's incorrect.\n\nFix: When managing volume/snapshot get error, commit the quota\nreservations in revert process, so when delete/unmanage this resource,\nit will reduce quota usage correctly.\n\nChange-Id: I5c4169fa6a31d2951851bd3eb44d849f2c7eeed5\nCloses-Bug: #1504007\n""}, {'number': 2, 'created': '2015-10-08 09:37:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/ab4575e9819e077fa75cb7dc0fc276e66a796230', 'message': ""Unmanage volume/snapshot reduce quota incorrectly\n\nWhen managing volume/snapshot get error, the quota\nusage will roll back and set the new volume/snapshot\nstatus to error, but then delete/unmanage this resource,\nquota usage will be reduced again, it's incorrect.\n\nFix: When managing volume/snapshot get error, commit\nthe quota reservations in revert process, so when\ndeleting/unmanaging this resource, it will reduce quota\nusage correctly.\n\nChange-Id: I5c4169fa6a31d2951851bd3eb44d849f2c7eeed5\nCloses-Bug: #1504007\n""}, {'number': 3, 'created': '2015-10-10 02:18:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/6d4a270247f0f2a688e1579b16fc07045d384855', 'message': 'Unmanaging vol/snap reduces quota incorrectly\n\nWhen managing volume/snapshot taskflow get driver exception,\nthe quota reservation will roll back in revert routine\nand set the new volume/snapshot status to error,\nBut after that, when attempting to delete/unmanage this\nresource, quota usage will be reduced again.\nThis is incorrect.\n\nFix: When managing volume/snapshot taskflow get driver exception,\ncommit the quota reservations in revert process, so when\nattempting to delete/unmanage this resource, it will reduce\nquota usage correctly.\n\nChange-Id: I5c4169fa6a31d2951851bd3eb44d849f2c7eeed5\nCloses-Bug: #1504007\n'}, {'number': 4, 'created': '2015-11-06 07:14:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/e6ef8dd52cb9397327e5416cdc6fac5d2c428bf6', 'message': 'Unmanaging vol/snap reduces quota incorrectly\n\nWhen managing volume/snapshot taskflow get driver exception,\nthe quota reservation will roll back in revert routine\nand set the new volume/snapshot status to error,\nBut after that, when attempting to delete/unmanage this\nresource, quota usage will be reduced again.\nThis is incorrect.\n\nFix: When managing volume/snapshot taskflow get driver exception,\ncommit the quota reservations in revert process, so when\nattempting to delete/unmanage this resource, it will reduce\nquota usage correctly.\n\nChange-Id: I5c4169fa6a31d2951851bd3eb44d849f2c7eeed5\nCloses-Bug: #1504007\n'}, {'number': 5, 'created': '2015-11-09 07:17:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/0d1ce177d3b5a1425278e284eb91c60622b2c790', 'message': 'Unmanaging vol/snap reduces quota incorrectly\n\nWhen managing volume/snapshot taskflow get driver exception,\nthe quota reservation will roll back in revert routine\nand set the new volume/snapshot status to error,\nBut after that, when attempting to delete/unmanage this\nresource, quota usage will be reduced again.\nThis is incorrect.\n\nFix: When managing volume/snapshot taskflow get driver\nexception, commit the quota reservations in revert process,\nso when attempting to delete/unmanage this resource, it\nwill reduce quota usage correctly.\n\nChange-Id: I5c4169fa6a31d2951851bd3eb44d849f2c7eeed5\nCloses-Bug: #1504007\n'}, {'number': 6, 'created': '2015-11-10 08:08:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/e38ec787f7ba58359678a071dd69e4a99bf087f5', 'message': 'Unmanaging vol/snap reduces quota incorrectly\n\nWhen managing volume/snapshot taskflow get driver exception,\nthe quota reservation will roll back in revert routine\nand set the new volume/snapshot status to error,\nBut after that, when attempting to delete/unmanage this\nresource, quota usage will be reduced again.\nThis is incorrect.\n\nFix: When managing volume/snapshot taskflow get driver\nexception, commit the quota reservations in revert process,\nso when attempting to delete/unmanage this resource, it\nwill reduce quota usage correctly.\n\nChange-Id: I5c4169fa6a31d2951851bd3eb44d849f2c7eeed5\nCloses-Bug: #1504007\n'}, {'number': 7, 'created': '2015-11-10 09:24:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/88d3d07abd98e6b119e206deae994ac7b0455343', 'message': 'Unmanaging vol/snap reduces quota incorrectly\n\nWhen managing volume/snapshot taskflow get driver exception,\nthe quota reservation will roll back in revert routine\nand set the new volume/snapshot status to error,\nBut after that, when attempting to delete/unmanage this\nresource, quota usage will be reduced again.\nThis is incorrect.\n\nFix: When managing volume/snapshot taskflow get driver\nexception, commit the quota reservations in revert process,\nso when attempting to delete/unmanage this resource, it\nwill reduce quota usage correctly.\n\nChange-Id: I5c4169fa6a31d2951851bd3eb44d849f2c7eeed5\nCloses-Bug: #1504007\n'}, {'number': 8, 'created': '2015-11-10 11:54:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/edc0d8ca6f7227cb8bf27406871f0dbe1cc2d7df', 'message': 'Unmanaging vol/snap reduces quota incorrectly\n\nWhen managing volume/snapshot taskflow get driver exception,\nthe quota reservation will roll back in revert routine\nand set the new volume/snapshot status to error,\nBut after that, when attempting to delete/unmanage this\nresource, quota usage will be reduced again.\nThis is incorrect.\n\nFix: When managing volume/snapshot taskflow get driver\nexception, commit the quota reservations in revert process,\nso when attempting to delete/unmanage this resource, it\nwill reduce quota usage correctly.\n\nChange-Id: I5c4169fa6a31d2951851bd3eb44d849f2c7eeed5\nCloses-Bug: #1504007\n'}, {'number': 9, 'created': '2015-11-11 03:03:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/77ad6ae690076469d7d64b4a82c962525849c6af', 'message': 'Unmanaging vol/snap reduces quota incorrectly\n\nWhen managing volume/snapshot taskflow get driver exception,\nthe quota reservation will roll back in revert routine\nand set the new volume/snapshot status to error,\nBut after that, when attempting to delete/unmanage this\nresource, quota usage will be reduced again.\nThis is incorrect.\n\nFix: When managing volume/snapshot taskflow get driver\nexception, commit the quota reservations in revert process,\nso when attempting to delete/unmanage this resource, it\nwill reduce quota usage correctly.\n\nChange-Id: I5c4169fa6a31d2951851bd3eb44d849f2c7eeed5\nCloses-Bug: #1504007\n'}, {'number': 10, 'created': '2015-11-12 08:31:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/b401a3e720c9618bbe85fadc6a0741582ccf3dc0', 'message': 'Unmanaging vol/snap reduces quota incorrectly\n\nWhen managing volume/snapshot taskflow get driver exception,\nthe quota reservation will roll back in revert routine\nand set the new volume/snapshot status to error.\nBut after that, when attempting to delete/unmanage this\nresource, quota usage will be reduced again.\nThis is incorrect.\n\nFix: When managing volume/snapshot taskflow get driver\nexception, commit the quota reservations in revert process,\nso when attempting to delete/unmanage this resource, it\nwill reduce quota usage correctly.\n\nChange-Id: I5c4169fa6a31d2951851bd3eb44d849f2c7eeed5\nCloses-Bug: #1504007\n'}, {'number': 11, 'created': '2015-11-13 08:27:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/dbb7a7ffdaef41cfbcd8c94d38957581f8bc4dac', 'message': 'Unmanaging vol/snap reduces quota incorrectly\n\nWhen managing volume/snapshot taskflow get driver exception,\nthe quota reservation will roll back in revert routine\nand set the new volume/snapshot status to error.\nBut after that, when attempting to delete/unmanage this\nresource, quota usage will be reduced again.\nThis is incorrect.\n\nFix: When managing volume/snapshot taskflow get driver\nexception, commit the quota reservations in revert process,\nso when attempting to delete/unmanage this resource, it\nwill reduce quota usage correctly.\n\nChange-Id: I5c4169fa6a31d2951851bd3eb44d849f2c7eeed5\nCloses-Bug: #1504007\n'}, {'number': 12, 'created': '2015-11-13 08:29:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/461761151685d56014129171e1a381aca3eb7db7', 'message': 'Unmanaging vol/snap reduces quota incorrectly\n\nWhen managing volume/snapshot taskflow get driver exception,\nthe quota reservation will roll back in revert routine\nand set the new volume/snapshot status to error.\nBut after that, when attempting to delete/unmanage this\nresource, quota usage will be reduced again.\nThis is incorrect.\n\nFix: When managing volume/snapshot taskflow get driver\nexception, commit the quota reservations in revert process,\nso when attempting to delete/unmanage this resource, it\nwill reduce quota usage correctly.\n\nChange-Id: I5c4169fa6a31d2951851bd3eb44d849f2c7eeed5\nCloses-Bug: #1504007\n'}, {'number': 13, 'created': '2015-11-16 02:09:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/9a1e7ba451617c1ff6ee36f570e374fd58fd8636', 'message': 'Unmanaging vol/snap reduces quota incorrectly\n\nWhen managing volume/snapshot taskflow get driver exception,\nthe quota reservation will roll back in revert routine\nand set the new volume/snapshot status to error.\nBut after that, when attempting to delete/unmanage this\nresource, quota usage will be reduced again.\nThis is incorrect.\n\nFix: When managing volume/snapshot taskflow get driver\nexception, commit the quota reservations in revert process,\nso when attempting to delete/unmanage this resource, it\nwill reduce quota usage correctly.\n\nChange-Id: I5c4169fa6a31d2951851bd3eb44d849f2c7eeed5\nCloses-Bug: #1504007\n'}, {'number': 14, 'created': '2016-01-12 07:32:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/336a3619bb1c779a08569b129d89b5b2272fbba2', 'message': 'Unmanaging vol/snap reduces quota incorrectly\n\nWhen managing volume/snapshot taskflow get driver exception,\nthe quota reservation will roll back in revert routine\nand set the new volume/snapshot status to error.\nBut after that, when attempting to delete/unmanage this\nresource, quota usage will be reduced again.\nThis is incorrect.\n\nFix: When managing volume/snapshot taskflow get driver\nexception, commit the quota reservations in revert process,\nso when attempting to delete/unmanage this resource, it\nwill reduce quota usage correctly.\n\nChange-Id: I5c4169fa6a31d2951851bd3eb44d849f2c7eeed5\nCloses-Bug: #1504007\n'}, {'number': 15, 'created': '2016-01-12 08:07:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/996d98baf6d6182e1676f157f520ea4cdd9a8aef', 'message': 'Unmanaging vol/snap reduces quota incorrectly\n\nWhen managing volume/snapshot taskflow get driver exception,\nthe quota reservation will roll back in revert routine\nand set the new volume/snapshot status to error.\nBut after that, when attempting to delete/unmanage this\nresource, quota usage will be reduced again.\nThis is incorrect.\n\nFix: When managing volume/snapshot taskflow get driver\nexception, commit the quota reservations in revert process,\nso when attempting to delete/unmanage this resource, it\nwill reduce quota usage correctly.\n\nChange-Id: I5c4169fa6a31d2951851bd3eb44d849f2c7eeed5\nCloses-Bug: #1504007\n'}, {'number': 16, 'created': '2016-01-13 08:33:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/cc639589ddbe791f11f4c582014c35cb4475647a', 'message': 'Unmanaging vol/snap reduces quota incorrectly\n\nWhen managing volume/snapshot taskflow get driver exception,\nthe quota reservation will roll back in revert routine\nand set the new volume/snapshot status to error.\nBut after that, when attempting to delete/unmanage this\nresource, quota usage will be reduced again.\nThis is incorrect.\n\nFix: When managing volume/snapshot taskflow get driver\nexception, commit the quota reservations in revert process,\nso when attempting to delete/unmanage this resource, it\nwill reduce quota usage correctly.\n\nChange-Id: I5c4169fa6a31d2951851bd3eb44d849f2c7eeed5\nCloses-Bug: #1504007\n'}, {'number': 17, 'created': '2016-01-13 23:58:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/f37a3b9a42e2896192656b0e4de9c1e83fe8c703', 'message': 'Unmanaging vol/snap reduces quota incorrectly\n\nWhen managing volume/snapshot taskflow get driver exception,\nthe quota reservation will roll back in revert routine\nand set the new volume/snapshot status to error.\nBut after that, when attempting to delete/unmanage this\nresource, quota usage will be reduced again.\nThis is incorrect.\n\nFix: When managing volume/snapshot taskflow get driver\nexception, commit the quota reservations in revert process,\nso when attempting to delete/unmanage this resource, it\nwill reduce quota usage correctly.\n\nChange-Id: I5c4169fa6a31d2951851bd3eb44d849f2c7eeed5\nCloses-Bug: #1504007\n'}, {'number': 18, 'created': '2016-01-18 06:58:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/44c350276ecc066daa705c379343cfaa97c08252', 'message': 'Unmanaging vol/snap reduces quota incorrectly\n\nWhen managing volume/snapshot taskflow get driver exception,\nthe quota reservation will roll back in revert routine\nand set the new volume/snapshot status to error.\nBut after that, when attempting to delete/unmanage this\nresource, quota usage will be reduced again.\nThis is incorrect.\n\nFix: When managing volume/snapshot taskflow get driver\nexception, commit the quota reservations in revert process,\nso when attempting to delete/unmanage this resource, it\nwill reduce quota usage correctly.\n\nChange-Id: I5c4169fa6a31d2951851bd3eb44d849f2c7eeed5\nCloses-Bug: #1504007\n'}, {'number': 19, 'created': '2016-01-18 07:02:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/1e5706c9a3469917bcb83580180a9263904ff4ed', 'message': 'Unmanaging vol/snap reduces quota incorrectly\n\nWhen managing volume/snapshot taskflow get driver exception,\nthe quota reservation will roll back in revert routine\nand set the new volume/snapshot status to error.\nBut after that, when attempting to delete/unmanage this\nresource, quota usage will be reduced again.\nThis is incorrect.\n\nFix: When managing volume/snapshot taskflow get driver\nexception, commit the quota reservations in revert process,\nso when attempting to delete/unmanage this resource, it\nwill reduce quota usage correctly.\n\nChange-Id: I5c4169fa6a31d2951851bd3eb44d849f2c7eeed5\nCloses-Bug: #1504007\n'}, {'number': 20, 'created': '2016-02-29 12:27:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/51c99f571ebd5fa9edb075f571b47c3168a1ad80', 'message': 'Unmanaging vol/snap reduces quota incorrectly\n\nWhen managing volume/snapshot taskflow get driver exception,\nthe quota reservation will roll back in revert routine\nand set the new volume/snapshot status to error.\nBut after that, when attempting to delete/unmanage this\nresource, quota usage will be reduced again.\nThis is incorrect.\n\nFix: When managing volume/snapshot taskflow get driver\nexception, commit the quota reservations in revert process,\nso when attempting to delete/unmanage this resource, it\nwill reduce quota usage correctly.\n\nChange-Id: I5c4169fa6a31d2951851bd3eb44d849f2c7eeed5\nCloses-Bug: #1504007\n'}, {'number': 21, 'created': '2016-02-29 12:29:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/2e1f7c56351c0b6524797dabd8b77f821bb32fcf', 'message': 'Unmanaging vol/snap reduces quota incorrectly\n\nWhen managing volume/snapshot taskflow get driver exception,\nthe quota reservation will roll back in revert routine\nand set the new volume/snapshot status to error.\nBut after that, when attempting to delete/unmanage this\nresource, quota usage will be reduced again.\nThis is incorrect.\n\nFix: When managing volume/snapshot taskflow get driver\nexception, commit the quota reservations in revert process,\nso when attempting to delete/unmanage this resource, it\nwill reduce quota usage correctly.\n\nChange-Id: I5c4169fa6a31d2951851bd3eb44d849f2c7eeed5\nCloses-Bug: #1504007\n'}, {'number': 22, 'created': '2016-03-07 06:36:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/006de132d8ce72d3ff9f9aa09c24a240db06bde7', 'message': 'Unmanaging vol/snap reduces quota incorrectly\n\nWhen managing volume/snapshot taskflow get driver exception,\nthe quota reservation will roll back in revert routine\nand set the new volume/snapshot status to error.\nBut after that, when attempting to delete/unmanage this\nresource, quota usage will be reduced again.\nThis is incorrect.\n\nFix: When managing volume/snapshot taskflow get driver\nexception, commit the quota reservations in revert process,\nso when attempting to delete/unmanage this resource, it\nwill reduce quota usage correctly.\n\nChange-Id: I5c4169fa6a31d2951851bd3eb44d849f2c7eeed5\nCloses-Bug: #1504007\n'}, {'number': 23, 'created': '2016-03-07 14:35:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/211b299d951e7f245f22b3f30b0f337a4b9c9095', 'message': 'Unmanaging vol/snap reduces quota incorrectly\n\nWhen managing volume/snapshot taskflow get driver exception,\nthe quota reservation will roll back in revert routine\nand set the new volume/snapshot status to error.\nBut after that, when attempting to delete/unmanage this\nresource, quota usage will be reduced again.\nThis is incorrect.\n\nFix: When managing volume/snapshot taskflow get driver\nexception, commit the quota reservations in revert process,\nso when attempting to delete/unmanage this resource, it\nwill reduce quota usage correctly.\n\nChange-Id: I5c4169fa6a31d2951851bd3eb44d849f2c7eeed5\nCloses-Bug: #1504007\n'}, {'number': 24, 'created': '2016-03-16 08:53:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/777f9d885c0c8ee79e3298cf5fc0414eee733537', 'message': 'Unmanaging vol/snap reduces quota incorrectly\n\nWhen managing volume/snapshot taskflow get driver exception,\nthe quota reservation will roll back in revert routine\nand set the new volume/snapshot status to error.\nBut after that, when attempting to delete/unmanage this\nresource, quota usage will be reduced again.\nThis is incorrect.\n\nFix: When managing volume/snapshot taskflow get driver\nexception, commit the quota reservations in revert process,\nso when attempting to delete/unmanage this resource, it\nwill reduce quota usage correctly.\n\nChange-Id: I5c4169fa6a31d2951851bd3eb44d849f2c7eeed5\nCloses-Bug: #1504007\n'}, {'number': 25, 'created': '2016-03-21 09:13:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/521aaa6056194c31aaa7b75bddf589f21101ed89', 'message': 'Unmanaging vol/snap reduces quota incorrectly\n\nWhen managing volume/snapshot taskflow get driver exception,\nthe quota reservation will roll back in revert routine\nand set the new volume/snapshot status to error.\nBut after that, when attempting to delete/unmanage this\nresource, quota usage will be reduced again.\nThis is incorrect.\n\nFix: When managing volume/snapshot taskflow get driver\nexception, commit the quota reservations in revert process,\nso when attempting to delete/unmanage this resource, it\nwill reduce quota usage correctly.\n\nChange-Id: I5c4169fa6a31d2951851bd3eb44d849f2c7eeed5\nCloses-Bug: #1504007\n'}, {'number': 26, 'created': '2016-03-22 03:45:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/e599ef53db785fd9c2e2b572929c1c4b7d6b6070', 'message': 'Unmanaging vol/snap reduces quota incorrectly\n\nWhen managing volume/snapshot taskflow get driver exception,\nthe quota reservation will roll back in revert routine\nand set the new volume/snapshot status to error.\nBut after that, when attempting to delete/unmanage this\nresource, quota usage will be reduced again.\nThis is incorrect.\n\nFix: When managing volume/snapshot taskflow get driver\nexception, commit the quota reservations in revert process,\nso when attempting to delete/unmanage this resource, it\nwill reduce quota usage correctly.\n\nChange-Id: I5c4169fa6a31d2951851bd3eb44d849f2c7eeed5\nCloses-Bug: #1504007\n'}, {'number': 27, 'created': '2016-03-26 09:53:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/ca5ec412636749074c7ac7b65a2a2d38874b3c11', 'message': 'Unmanaging vol/snap reduces quota incorrectly\n\nWhen managing volume/snapshot taskflow get driver exception,\nthe quota reservation will roll back in revert routine\nand set the new volume/snapshot status to error.\nBut after that, when attempting to delete/unmanage this\nresource, quota usage will be reduced again.\nThis is incorrect.\n\nFix: When managing volume/snapshot taskflow get driver\nexception, commit the quota reservations in revert process,\nso when attempting to delete/unmanage this resource, it\nwill reduce quota usage correctly.\n\nChange-Id: I5c4169fa6a31d2951851bd3eb44d849f2c7eeed5\nCloses-Bug: #1504007\n'}, {'number': 28, 'created': '2016-05-20 01:46:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/82a19c7e655b7c81fcc3df8a673f4646642535ed', 'message': 'Unmanaging vol/snap reduces quota incorrectly\n\nWhen managing volume/snapshot taskflow get driver exception,\nthe quota reservation will roll back in revert routine\nand set the new volume/snapshot status to error.\nBut after that, when attempting to delete/unmanage this\nresource, quota usage will be reduced again.\nThis is incorrect.\n\nFix: When managing volume/snapshot taskflow get driver\nexception, commit the quota reservations in revert process,\nso when attempting to delete/unmanage this resource, it\nwill reduce quota usage correctly.\n\nChange-Id: I5c4169fa6a31d2951851bd3eb44d849f2c7eeed5\nCloses-Bug: #1504007\n'}, {'number': 29, 'created': '2016-05-20 12:25:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/35bc8045b398ebd18d49efe64d8f6ec544441925', 'message': 'Unmanaging vol/snap reduces quota incorrectly\n\nWhen managing volume/snapshot taskflow get driver exception,\nthe quota reservation will roll back in revert routine\nand set the new volume/snapshot status to error.\nBut after that, when attempting to delete/unmanage this\nresource, quota usage will be reduced again.\nThis is incorrect.\n\nFix: When managing volume/snapshot taskflow get driver\nexception, commit the quota reservations in revert process,\nso when attempting to delete/unmanage this resource, it\nwill reduce quota usage correctly.\n\nChange-Id: I5c4169fa6a31d2951851bd3eb44d849f2c7eeed5\nCloses-Bug: #1504007\n'}, {'number': 30, 'created': '2016-06-17 06:49:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/f5438f756fcddef23f4ac8ca6a9caf4561d62215', 'message': 'Unmanaging vol/snap reduces quota incorrectly\n\nWhen managing volume/snapshot taskflow get driver exception,\nthe quota reservation will roll back in revert routine\nand set the new volume/snapshot status to error.\nBut after that, when attempting to delete/unmanage this\nresource, quota usage will be reduced again.\nThis is incorrect.\n\nFix: When managing volume/snapshot taskflow get driver\nexception, commit the quota reservations in revert process,\nso when attempting to delete/unmanage this resource, it\nwill reduce quota usage correctly.\n\nChange-Id: I5c4169fa6a31d2951851bd3eb44d849f2c7eeed5\nCloses-Bug: #1504007\n'}, {'number': 31, 'created': '2016-06-21 01:25:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/7f8c8750b43ce27fd315bc1d70fe04481c1d820d', 'message': 'Unmanaging vol/snap reduces quota incorrectly\n\nWhen managing volume/snapshot taskflow get driver exception,\nthe quota reservation will roll back in revert routine\nand set the new volume/snapshot status to error.\nBut after that, when attempting to delete/unmanage this\nresource, quota usage will be reduced again.\nThis is incorrect.\n\nFix: When managing volume/snapshot taskflow get driver\nexception, commit the quota reservations in revert process,\nso when attempting to delete/unmanage this resource, it\nwill reduce quota usage correctly.\n\nChange-Id: I5c4169fa6a31d2951851bd3eb44d849f2c7eeed5\nCloses-Bug: #1504007\n'}, {'number': 32, 'created': '2016-06-21 06:44:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/a2473d5bc1a87b7b43115393ab0006cf86e03d14', 'message': 'Unmanaging vol/snap reduces quota incorrectly\n\nWhen managing volume/snapshot taskflow get driver exception,\nthe quota reservation will roll back in revert routine\nand set the new volume/snapshot status to error.\nBut after that, when attempting to delete/unmanage this\nresource, quota usage will be reduced again.\nThis is incorrect.\n\nFix: When managing volume/snapshot taskflow get driver\nexception, commit the quota reservations in revert process,\nso when attempting to delete/unmanage this resource, it\nwill reduce quota usage correctly.\n\nChange-Id: I5c4169fa6a31d2951851bd3eb44d849f2c7eeed5\nCloses-Bug: #1504007\n'}, {'number': 33, 'created': '2016-06-21 09:16:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/5401ef9921a2d75f913d1f6f777b9044aa214bdd', 'message': 'Unmanaging vol/snap reduces quota incorrectly\n\nWhen managing volume/snapshot taskflow get driver exception,\nthe quota reservation will roll back in revert routine\nand set the new volume/snapshot status to error.\nBut after that, when attempting to delete/unmanage this\nresource, quota usage will be reduced again.\nThis is incorrect.\n\nFix: When managing volume/snapshot taskflow get driver\nexception, commit the quota reservations in revert process,\nso when attempting to delete/unmanage this resource, it\nwill reduce quota usage correctly.\n\nChange-Id: I5c4169fa6a31d2951851bd3eb44d849f2c7eeed5\nCloses-Bug: #1504007\n'}, {'number': 34, 'created': '2016-06-23 07:16:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/1f5f299720fd33bcbe496d491fd16590c1166f5e', 'message': 'Unmanaging vol/snap reduces quota incorrectly\n\nWhen managing volume/snapshot taskflow get driver exception,\nthe quota reservation will roll back in revert routine\nand set the new volume/snapshot status to error.\nBut after that, when attempting to delete/unmanage this\nresource, quota usage will be reduced again.\nThis is incorrect.\n\nFix: When managing volume/snapshot taskflow get driver\nexception, commit the quota reservations in revert process,\nso when attempting to delete/unmanage this resource, it\nwill reduce quota usage correctly.\n\nChange-Id: I5c4169fa6a31d2951851bd3eb44d849f2c7eeed5\nCloses-Bug: #1504007\n'}, {'number': 35, 'created': '2016-06-23 08:19:48.000000000', 'files': ['cinder/volume/manager.py', 'cinder/volume/flows/manager/manage_existing.py', 'cinder/tests/unit/test_volume.py', 'cinder/volume/flows/manager/manage_existing_snapshot.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/132c0890b8b9e6fd5228c2417c5f6b5ab8de9222', 'message': ""Unmanaging vol/snap reduces quota incorrectly\n\nWhen managing volume/snapshot taskflow get driver exception,\nthe quota reservation will roll back in revert routine\nand set the new volume/snapshot status to error.\nBut after that, when attempting to delete/unmanage this\nresource, quota usage will be reduced again.\nThis is incorrect.\n\nFix: When managing volume/snapshot taskflow get driver\nexception, commit the quota reservations in revert process,\nso when attempting to delete/unmanage this resource, it\nwill reduce quota usage correctly.\n\nThere is another way to fix this issue according discussion in\nIRC meeting, that will introduce 'manage_starting' and 'error_manaing'\nto fix it.\nhttps://review.openstack.org/#/c/333164/\n\nChange-Id: I5c4169fa6a31d2951851bd3eb44d849f2c7eeed5\nCloses-Bug: #1504007\n""}]",63,232436,132c0890b8b9e6fd5228c2417c5f6b5ab8de9222,794,77,35,8846,,,0,"Unmanaging vol/snap reduces quota incorrectly

When managing volume/snapshot taskflow get driver exception,
the quota reservation will roll back in revert routine
and set the new volume/snapshot status to error.
But after that, when attempting to delete/unmanage this
resource, quota usage will be reduced again.
This is incorrect.

Fix: When managing volume/snapshot taskflow get driver
exception, commit the quota reservations in revert process,
so when attempting to delete/unmanage this resource, it
will reduce quota usage correctly.

There is another way to fix this issue according discussion in
IRC meeting, that will introduce 'manage_starting' and 'error_manaing'
to fix it.
https://review.openstack.org/#/c/333164/

Change-Id: I5c4169fa6a31d2951851bd3eb44d849f2c7eeed5
Closes-Bug: #1504007
",git fetch https://review.opendev.org/openstack/cinder refs/changes/36/232436/18 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/tests/unit/volume/flows/test_manage_volume_flow.py', 'cinder/volume/flows/manager/manage_existing.py', 'cinder/volume/flows/manager/manage_existing_snapshot.py', 'cinder/tests/unit/volume/flows/test_manage_snapshot_flow.py']",4,df96a8707ce1627dc06ff7ee41f705da5db7e887,bug/1504007,"# Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. """""" Tests for manage_existing_snapshot TaskFlow """""" import mock from cinder import context from cinder import quota from cinder import test from cinder.volume.flows.manager import manage_existing_snapshot QUOTAS = quota.QUOTAS class ManageSnapshotFlowTestCase(test.TestCase): def setUp(self): super(ManageSnapshotFlowTestCase, self).setUp() self.ctxt = context.get_admin_context() self.counter = float(0) def test_manage_existing_snapshot_revert(self): db = mock.MagicMock(return_value=None) driver = mock.MagicMock(return_value=None) task = manage_existing_snapshot.ManageExistingTask(db, driver) result = {} reserve_opts = {'snapshots': 1, 'gigabytes': 1} reservations = QUOTAS.reserve(context, **reserve_opts) result['reservations'] = reservations optional_args = {'is_quota_committed': False} task.revert(context, result, optional_args) ",,92,0
openstack%2Fmurano-apps~master~I62482bce9ad4f45b7ea2d1d4db77d009c7191f7b,openstack/murano-apps,master,I62482bce9ad4f45b7ea2d1d4db77d009c7191f7b,Fixing docker DIB element for setting correct MTU,MERGED,2016-08-26 11:51:05.000000000,2016-08-29 00:55:04.000000000,2016-08-29 00:55:04.000000000,"[{'_account_id': 3}, {'_account_id': 6577}, {'_account_id': 7700}, {'_account_id': 13149}, {'_account_id': 15168}]","[{'number': 1, 'created': '2016-08-26 11:51:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-apps/commit/712c2d7f42de036bfddb373b3e18a1790efc4236', 'message': ""Fixing docker DIB element for setting correct MTU\n\n * docker0 interface in ubuntu had incorrect MTU value\n * Older docker (< v1.1) automatically infer MTU value based\n on host. But since 1.1 docker doesn't do this. It\n sets MTU value 1500 which causes some network problems\n (especially with SSL/TLS/HTTPS) and apps like\n HTTPdSite and NginXSite couldn't clone the repo.\n\nCloses-Bug: 1608836\n\nChange-Id: I62482bce9ad4f45b7ea2d1d4db77d009c7191f7b\n""}, {'number': 2, 'created': '2016-08-26 12:17:51.000000000', 'files': ['Docker/Kubernetes/KubernetesCluster/elements/docker/install.d/56-docker', 'Docker/DockerStandaloneHost/elements/docker/install.d/56-docker'], 'web_link': 'https://opendev.org/openstack/murano-apps/commit/a6032decbadbf46aeed36b41c71eeaee47b4e54f', 'message': ""Fixing docker DIB element for setting correct MTU\n\n * docker0 interface in ubuntu had incorrect MTU value\n * Older docker (< v1.1) automatically infer MTU value based\n on host. But since 1.1 docker doesn't do this. It\n sets MTU value 1500 which causes some network problems\n (especially with SSL/TLS/HTTPS) and apps like\n HTTPdSite and NginXSite couldn't clone the repo.\n\nCloses-Bug: 1608836\n\nChange-Id: I62482bce9ad4f45b7ea2d1d4db77d009c7191f7b\n""}]",0,361115,a6032decbadbf46aeed36b41c71eeaee47b4e54f,12,5,2,7700,,,0,"Fixing docker DIB element for setting correct MTU

 * docker0 interface in ubuntu had incorrect MTU value
 * Older docker (< v1.1) automatically infer MTU value based
 on host. But since 1.1 docker doesn't do this. It
 sets MTU value 1500 which causes some network problems
 (especially with SSL/TLS/HTTPS) and apps like
 HTTPdSite and NginXSite couldn't clone the repo.

Closes-Bug: 1608836

Change-Id: I62482bce9ad4f45b7ea2d1d4db77d009c7191f7b
",git fetch https://review.opendev.org/openstack/murano-apps refs/changes/15/361115/2 && git format-patch -1 --stdout FETCH_HEAD,['Docker/DockerStandaloneHost/elements/docker/install.d/56-docker'],1,712c2d7f42de036bfddb373b3e18a1790efc4236,bug/1608836,"echo 'DOCKER_OPTS=""--bip=172.31.0.1/16 --fixed-cidr=172.31.0.0/16 --mtu=1450""' >> /etc/default/docker","echo 'DOCKER_OPTS=""--bip=172.31.0.1/16 --fixed-cidr=172.31.0.0/16""' >> /etc/default/docker",1,1
openstack%2Fheat~master~Iaf82d6c8054e3215adf1d2189c69d19386a71059,openstack/heat,master,Iaf82d6c8054e3215adf1d2189c69d19386a71059,Improve efficiency of SoftwareDeployment updates,MERGED,2016-08-25 00:19:13.000000000,2016-08-29 00:04:22.000000000,2016-08-29 00:04:22.000000000,"[{'_account_id': 3}, {'_account_id': 4571}, {'_account_id': 12404}, {'_account_id': 20559}]","[{'number': 1, 'created': '2016-08-25 00:19:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/5ac1f785492e66afba70a7f087306e6f5fda2e4b', 'message': 'Improve efficiency of SoftwareDeployment updates\n\nAvoid having to get the existing derived config ID (which involves\nmaking two RPC calls) twice.\n\nAlso rename _get_derived_config to _create_derived_config to cut down on\nconfusion.\n\nChange-Id: Iaf82d6c8054e3215adf1d2189c69d19386a71059\n'}, {'number': 2, 'created': '2016-08-26 00:24:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/04acc9dc0dbe1792074d1a479c343659044934ed', 'message': 'Improve efficiency of SoftwareDeployment updates\n\nAvoid having to get the existing derived config ID (which involves\nmaking two RPC calls) twice.\n\nAlso rename _get_derived_config to _create_derived_config to cut down on\nconfusion.\n\nChange-Id: Iaf82d6c8054e3215adf1d2189c69d19386a71059\n'}, {'number': 3, 'created': '2016-08-26 00:33:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/3a41117fe19d5637e02bdff75effbaa135606029', 'message': 'Improve efficiency of SoftwareDeployment updates\n\nAvoid having to get the existing derived config ID (which involves\nmaking two RPC calls) twice.\n\nAlso rename _get_derived_config to _create_derived_config to cut down on\nconfusion.\n\nChange-Id: Iaf82d6c8054e3215adf1d2189c69d19386a71059\n'}, {'number': 4, 'created': '2016-08-26 15:47:44.000000000', 'files': ['heat/engine/resources/openstack/heat/software_deployment.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/d446b2f5044bcbd8a968a35597c9416a303550c0', 'message': 'Improve efficiency of SoftwareDeployment updates\n\nAvoid having to get the existing derived config ID (which involves\nmaking two RPC calls) twice.\n\nAlso rename _get_derived_config to _create_derived_config to cut down on\nconfusion.\n\nChange-Id: Iaf82d6c8054e3215adf1d2189c69d19386a71059\n'}]",1,360131,d446b2f5044bcbd8a968a35597c9416a303550c0,14,4,4,4257,,,0,"Improve efficiency of SoftwareDeployment updates

Avoid having to get the existing derived config ID (which involves
making two RPC calls) twice.

Also rename _get_derived_config to _create_derived_config to cut down on
confusion.

Change-Id: Iaf82d6c8054e3215adf1d2189c69d19386a71059
",git fetch https://review.opendev.org/openstack/heat refs/changes/31/360131/2 && git format-patch -1 --stdout FETCH_HEAD,['heat/engine/resources/openstack/heat/software_deployment.py'],1,5ac1f785492e66afba70a7f087306e6f5fda2e4b,bug1616550," def _create_derived_config(self, action, source_config): def _handle_action(self, action, config=None, prev_derived_config=None): self._create_derived_config(action, config), if prev_derived_config is None: prev_derived_config = self._get_derived_config_id() prev_derived_config = self._get_derived_config_id() old_config = self._load_config(prev_derived_config) return self._handle_action(self.UPDATE, config=config, prev_derived_config=prev_derived_config)"," def _get_derived_config(self, action, source_config): def _handle_action(self, action, config=None): self._get_derived_config(action, config), sd = self.rpc_client().show_software_deployment( self.context, self.resource_id) prev_derived_config = sd[rpc_api.SOFTWARE_DEPLOYMENT_CONFIG_ID] old_config = self._load_config(self._get_derived_config_id()) return self._handle_action(self.UPDATE, config=config)",9,8
openstack%2Fmurano~master~I151a4255beb12fde73ec42f1dbe8b4877ed4d9d9,openstack/murano,master,I151a4255beb12fde73ec42f1dbe8b4877ed4d9d9,Update Readme with correct Doc URL,MERGED,2016-08-26 16:52:30.000000000,2016-08-28 23:38:45.000000000,2016-08-28 23:38:45.000000000,"[{'_account_id': 3}, {'_account_id': 7225}, {'_account_id': 7226}, {'_account_id': 7535}, {'_account_id': 7549}, {'_account_id': 7821}, {'_account_id': 8127}, {'_account_id': 13323}, {'_account_id': 13962}, {'_account_id': 14107}, {'_account_id': 14265}, {'_account_id': 15168}, {'_account_id': 16237}]","[{'number': 1, 'created': '2016-08-26 16:52:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/dc15fe1e84147a4f151079b12f881b4f2d2b6d51', 'message': 'Update Readme with correct Doc URL\n\nChange-Id: I151a4255beb12fde73ec42f1dbe8b4877ed4d9d9\n'}, {'number': 2, 'created': '2016-08-26 16:54:08.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/murano/commit/d331a4fbd5d306d9f6ec16b565b41362ab5aa693', 'message': 'Update Readme with correct Doc URL\n\nChange-Id: I151a4255beb12fde73ec42f1dbe8b4877ed4d9d9\n'}]",0,361365,d331a4fbd5d306d9f6ec16b565b41362ab5aa693,14,13,2,19290,,,0,"Update Readme with correct Doc URL

Change-Id: I151a4255beb12fde73ec42f1dbe8b4877ed4d9d9
",git fetch https://review.opendev.org/openstack/murano refs/changes/65/361365/2 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,dc15fe1e84147a4f151079b12f881b4f2d2b6d51,,* `Murano Official Documentation <http://http://docs.openstack.org/developer/murano/>`_,* `Murano Official Documentation <http://murano.readthedocs.org>`_,1,1
openstack%2Fmurano-dashboard~master~Iea1439f2a23804c653fc60eb72e3c4b4e50c7498,openstack/murano-dashboard,master,Iea1439f2a23804c653fc60eb72e3c4b4e50c7498,[WIP] Move muranodashboard's panels to Applications dashboard,ABANDONED,2016-06-30 00:26:27.000000000,2016-08-28 23:19:25.000000000,,"[{'_account_id': 3}, {'_account_id': 7821}, {'_account_id': 15168}]","[{'number': 1, 'created': '2016-06-30 00:26:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/f203888faeb4f07365a7eb546076e7954572306f', 'message': ""[WIP] Move muranodashboard's panels to Applications dashboard\n\nThis commit moves panels of muranodashboard to 'Applications'\ndashboard, allowing to share single dashboard between\nmuranodashboard and app-catalog-ui\n\nThis is a WIP, yet it is working and can be tested\nin conjunction with I433bf09387dbfaf023b7b89be01b1daf504feaf4\n\nChange-Id: Iea1439f2a23804c653fc60eb72e3c4b4e50c7498\n""}, {'number': 2, 'created': '2016-06-30 11:33:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/6fcc2bcd417daa9a6d387a374c9f69a24d63487e', 'message': ""[WIP] Move muranodashboard's panels to Applications dashboard\n\nThis commit moves panels of muranodashboard to 'Applications'\ndashboard, allowing to share single dashboard between\nmuranodashboard and app-catalog-ui\n\nThis is a WIP, yet it is working and can be tested\nin conjunction with I433bf09387dbfaf023b7b89be01b1daf504feaf4\n\nChange-Id: Iea1439f2a23804c653fc60eb72e3c4b4e50c7498\n""}, {'number': 3, 'created': '2016-08-17 16:32:09.000000000', 'files': ['muranodashboard/catalog/panel.py', 'muranodashboard/packages/panel.py', 'muranodashboard/environments/panel.py', 'muranodashboard/local/enabled/_61_panel_murano_environments.py', 'muranodashboard/local/enabled/_72_panel_murano_images.py', 'muranodashboard/categories/panel.py', 'muranodashboard/images/panel.py', 'muranodashboard/local/enabled/_51_muranodashboard.py', 'muranodashboard/local/enabled/_60_panel_group_murano_deploy.py', 'muranodashboard/views.py', 'muranodashboard/local/enabled/_50_dashboard_applications.py', 'muranodashboard/local/enabled/_71_panel_murano_packages.py', 'muranodashboard/environments/tables.py', 'muranodashboard/local/enabled/_70_panel_group_murano_manage.py', 'muranodashboard/dashboard.py', 'muranodashboard/local/enabled/_62_panel_murano_catalog.py', 'muranodashboard/local/enabled/_73_panel_murano_categories.py'], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/b6f5c496b7470532da2f9bbc42182edc5f717beb', 'message': ""[WIP] Move muranodashboard's panels to Applications dashboard\n\nThis commit moves panels of muranodashboard to 'Applications'\ndashboard, allowing to share single dashboard between\nmuranodashboard and app-catalog-ui\n\nThis is a WIP, yet it is working and can be tested\nin conjunction with I433bf09387dbfaf023b7b89be01b1daf504feaf4\n\nChange-Id: Iea1439f2a23804c653fc60eb72e3c4b4e50c7498\n""}]",0,335730,b6f5c496b7470532da2f9bbc42182edc5f717beb,19,3,3,15168,,,0,"[WIP] Move muranodashboard's panels to Applications dashboard

This commit moves panels of muranodashboard to 'Applications'
dashboard, allowing to share single dashboard between
muranodashboard and app-catalog-ui

This is a WIP, yet it is working and can be tested
in conjunction with I433bf09387dbfaf023b7b89be01b1daf504feaf4

Change-Id: Iea1439f2a23804c653fc60eb72e3c4b4e50c7498
",git fetch https://review.opendev.org/openstack/murano-dashboard refs/changes/30/335730/2 && git format-patch -1 --stdout FETCH_HEAD,"['muranodashboard/catalog/panel.py', 'muranodashboard/packages/panel.py', 'muranodashboard/environments/panel.py', 'muranodashboard/local/enabled/_61_panel_murano_environments.py', 'muranodashboard/local/enabled/_72_panel_murano_images.py', 'muranodashboard/categories/panel.py', 'muranodashboard/images/panel.py', 'muranodashboard/local/enabled/_51_muranodashboard.py', 'muranodashboard/local/enabled/_60_panel_group_murano_deploy.py', 'muranodashboard/views.py', 'muranodashboard/local/enabled/_71_panel_murano_packages.py', 'muranodashboard/environments/tables.py', 'muranodashboard/local/enabled/_70_panel_group_murano_manage.py', 'muranodashboard/dashboard.py', 'muranodashboard/local/enabled/_62_panel_murano_catalog.py', 'muranodashboard/local/enabled/_73_panel_murano_categories.py']",16,f203888faeb4f07365a7eb546076e7954572306f,applications-dashboard,# The name of the panel to be added to HORIZON_CONFIG. Required. PANEL = 'categories' # The name of the dashboard the PANEL associated with. Required. PANEL_DASHBOARD = 'applications' # The name of the panel group the PANEL is associated with. PANEL_GROUP = 'murano_manage_group' # Python panel class of the PANEL to be added. ADD_PANEL = 'muranodashboard.categories.panel.Categories' ,,74,56
openstack%2Fmurano-dashboard~master~I8089e33388cc3f9476fa6fa0546d346fba192568,openstack/murano-dashboard,master,I8089e33388cc3f9476fa6fa0546d346fba192568,Update Readme with correct Doc URL,MERGED,2016-08-26 16:58:27.000000000,2016-08-28 23:05:19.000000000,2016-08-28 23:05:19.000000000,"[{'_account_id': 3}, {'_account_id': 7225}, {'_account_id': 7226}, {'_account_id': 7535}, {'_account_id': 7549}, {'_account_id': 7821}, {'_account_id': 8127}, {'_account_id': 13323}, {'_account_id': 13962}, {'_account_id': 14107}, {'_account_id': 14265}, {'_account_id': 15168}, {'_account_id': 16237}]","[{'number': 1, 'created': '2016-08-26 16:58:27.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/c2e06ac47a31e086d93d19eddf4129ee2276962c', 'message': 'Update Readme with correct Doc URL\n\nChange-Id: I8089e33388cc3f9476fa6fa0546d346fba192568\n'}]",0,361368,c2e06ac47a31e086d93d19eddf4129ee2276962c,11,13,1,19290,,,0,"Update Readme with correct Doc URL

Change-Id: I8089e33388cc3f9476fa6fa0546d346fba192568
",git fetch https://review.opendev.org/openstack/murano-dashboard refs/changes/68/361368/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,c2e06ac47a31e086d93d19eddf4129ee2276962c,,* `Documentation <http://docs.openstack.org/developer/murano/>`_,* `Documentation <http://murano.readthedocs.org/>`_,1,1
openstack%2Fmurano-agent~master~I4d4f5cfe01c17e70117ef09752e5b5023ac09937,openstack/murano-agent,master,I4d4f5cfe01c17e70117ef09752e5b5023ac09937,[docs] Update Readme with correct Doc URL,MERGED,2016-08-26 17:03:08.000000000,2016-08-28 23:04:49.000000000,2016-08-28 23:04:49.000000000,"[{'_account_id': 3}, {'_account_id': 7225}, {'_account_id': 7226}, {'_account_id': 7535}, {'_account_id': 7549}, {'_account_id': 7821}, {'_account_id': 8127}, {'_account_id': 13962}, {'_account_id': 14107}, {'_account_id': 14265}, {'_account_id': 15168}, {'_account_id': 16237}]","[{'number': 1, 'created': '2016-08-26 17:03:08.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/murano-agent/commit/a58d8ae7c122fa7b78b4c0d4d1b7b12c432f7f08', 'message': '[docs] Update Readme with correct Doc URL\n\nChange-Id: I4d4f5cfe01c17e70117ef09752e5b5023ac09937\n'}]",0,361370,a58d8ae7c122fa7b78b4c0d4d1b7b12c432f7f08,10,12,1,19290,,,0,"[docs] Update Readme with correct Doc URL

Change-Id: I4d4f5cfe01c17e70117ef09752e5b5023ac09937
",git fetch https://review.opendev.org/openstack/murano-agent refs/changes/70/361370/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,a58d8ae7c122fa7b78b4c0d4d1b7b12c432f7f08,, http://docs.openstack.org/developer/murano/, https://murano.readthedocs.org,1,1
openstack%2Fheat~master~Ia42ea3fd6cacf429a205c64d06e0db53dde32684,openstack/heat,master,Ia42ea3fd6cacf429a205c64d06e0db53dde32684,Fix senlin profile/policy type constraint check,MERGED,2016-08-28 10:25:35.000000000,2016-08-28 22:54:25.000000000,2016-08-28 22:54:25.000000000,"[{'_account_id': 3}, {'_account_id': 4571}, {'_account_id': 6577}, {'_account_id': 8246}]","[{'number': 1, 'created': '2016-08-28 10:25:35.000000000', 'files': ['heat/engine/clients/os/senlin.py', 'heat/tests/clients/test_senlin_client.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/c00e776bed897fdca79461f23c655240ffca5a4c', 'message': 'Fix senlin profile/policy type constraint check\n\nGet profile/policy type name from attribute.\n\nCloses-Bug: #1617723\nChange-Id: Ia42ea3fd6cacf429a205c64d06e0db53dde32684\n'}]",0,361706,c00e776bed897fdca79461f23c655240ffca5a4c,7,4,1,7404,,,0,"Fix senlin profile/policy type constraint check

Get profile/policy type name from attribute.

Closes-Bug: #1617723
Change-Id: Ia42ea3fd6cacf429a205c64d06e0db53dde32684
",git fetch https://review.opendev.org/openstack/heat refs/changes/06/361706/1 && git format-patch -1 --stdout FETCH_HEAD,"['heat/engine/clients/os/senlin.py', 'heat/tests/clients/test_senlin_client.py']",2,c00e776bed897fdca79461f23c655240ffca5a4c,bug/1617723," heat_profile_type = mock.MagicMock() heat_profile_type.name = 'os.heat.stack-1.0' nova_profile_type = mock.MagicMock() nova_profile_type.name = 'os.nova.server-1.0' return_value=[heat_profile_type, nova_profile_type]) deletion_policy_type = mock.MagicMock() deletion_policy_type.name = 'senlin.policy.deletion-1.0' lb_policy_type = mock.MagicMock() lb_policy_type.name = 'senlin.policy.loadbalance-1.0' return_value=[deletion_policy_type, lb_policy_type])"," return_value=[{'name': 'os.heat.stack-1.0'}, {'name': 'os.nova.server-1.0'}]) return_value=[{'name': 'senlin.policy.deletion-1.0'}, {'name': 'senlin.policy.loadbalance-1.0'}])",12,6
openstack%2Ftripleo-heat-templates~master~Idfb772567d5711083b82ae8cb4bce2c4498b4d64,openstack/tripleo-heat-templates,master,Idfb772567d5711083b82ae8cb4bce2c4498b4d64,Fix debug parameter in gnocchi-base.yaml,MERGED,2016-08-26 20:14:01.000000000,2016-08-28 22:27:33.000000000,2016-08-28 22:27:33.000000000,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 3153}, {'_account_id': 6924}, {'_account_id': 6928}]","[{'number': 1, 'created': '2016-08-26 20:14:01.000000000', 'files': ['puppet/services/gnocchi-base.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/38bbf112078f2817d7a1192858ec32b826690a4b', 'message': ""Fix debug parameter in gnocchi-base.yaml\n\nThis gnocchi-base service was using get_input to obtain\nthe debug setting which won't work here. This patch adds in\nthe standard Debug heat parameter to the service and sets\nit via get_param.\n\nChange-Id: Idfb772567d5711083b82ae8cb4bce2c4498b4d64\n""}]",1,361450,38bbf112078f2817d7a1192858ec32b826690a4b,10,5,1,360,,,0,"Fix debug parameter in gnocchi-base.yaml

This gnocchi-base service was using get_input to obtain
the debug setting which won't work here. This patch adds in
the standard Debug heat parameter to the service and sets
it via get_param.

Change-Id: Idfb772567d5711083b82ae8cb4bce2c4498b4d64
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/50/361450/1 && git format-patch -1 --stdout FETCH_HEAD,['puppet/services/gnocchi-base.yaml'],1,38bbf112078f2817d7a1192858ec32b826690a4b,gnocchi_debug_fix, Debug: type: string default: '' description: Set to True to enable debugging on all services. gnocchi::debug: {get_param: Debug}, gnocchi::debug: {get_input: debug},5,1
