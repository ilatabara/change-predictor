{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import  precision_score, recall_score, roc_auc_score, brier_score_loss\n",
    "from sklearn.base import clone\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "from utils import helpers as hpr\n",
    "from utils import constants\n",
    "from utils import classifier_util as clas_util\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram\n",
    "from scipy.spatial.distance import squareform\n",
    "from scipy.stats import mannwhitneyu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = constants.get_metrics()[:-3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependent changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dependencies = pd.read_csv(osp.join('.', 'Files', \"Preliminary\", 'deps_ident.csv'))\n",
    "df_dependencies = df_dependencies[(df_dependencies['Source_status']!=\"NEW\")&(df_dependencies['Target_status']!=\"NEW\")]\n",
    "dependent_changes = set(hpr.flatten_list(df_dependencies[['Source', 'Target']].values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading OpenStack changes...\n",
      "OpenStack changes loaded successfully...\n"
     ]
    }
   ],
   "source": [
    "df_changes = hpr.combine_openstack_data()\n",
    "df_changes = df_changes[df_changes[\"status\"]!=\"NEW\"]\n",
    "df_changes['is_dependent'] = df_changes['number'].map(lambda nbr: 1 if nbr in dependent_changes else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_developer_exp = pd.read_csv(osp.join(\".\", \"Files\", \"Metrics\", \"project_changes_owner.csv\"))\n",
    "df_developer_exp['is_dependent'] = df_developer_exp['number'].map(lambda nbr: 1 if nbr in dependent_changes else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>added_lines</th>\n",
       "      <th>insertions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>21225</td>\n",
       "      <td>import json from tempest.common.rest_client im...</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378616</th>\n",
       "      <td>489219</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382320</th>\n",
       "      <td>493712</td>\n",
       "      <td>\"\"\"A decorator for verifying policy enforceme...</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382771</th>\n",
       "      <td>494247</td>\n",
       "      <td># Licensed under the Apache License, Version 2...</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384375</th>\n",
       "      <td>496203</td>\n",
       "      <td># # Licensed under the Apache License, Version...</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176807</th>\n",
       "      <td>242556</td>\n",
       "      <td>@mock.patch('ceilometer.pipeline.LOG') def te...</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176853</th>\n",
       "      <td>242615</td>\n",
       "      <td>new_domain = unit.new_domain_ref() domain = u...</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177316</th>\n",
       "      <td>243221</td>\n",
       "      <td>with _utils.shade_exceptions(\"Error authentic...</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173985</th>\n",
       "      <td>238965</td>\n",
       "      <td>import json def get_property_value(self, obj, ...</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>721284</th>\n",
       "      <td>917116</td>\n",
       "      <td># verify_contents(catalogue, '/etc/nova/provid...</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>625 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        number                                        added_lines  insertions\n",
       "116      21225  import json from tempest.common.rest_client im...         100\n",
       "378616  489219                                                NaN         100\n",
       "382320  493712   \"\"\"A decorator for verifying policy enforceme...         100\n",
       "382771  494247  # Licensed under the Apache License, Version 2...         100\n",
       "384375  496203  # # Licensed under the Apache License, Version...         100\n",
       "...        ...                                                ...         ...\n",
       "176807  242556   @mock.patch('ceilometer.pipeline.LOG') def te...         100\n",
       "176853  242615   new_domain = unit.new_domain_ref() domain = u...         100\n",
       "177316  243221   with _utils.shade_exceptions(\"Error authentic...         100\n",
       "173985  238965  import json def get_property_value(self, obj, ...         100\n",
       "721284  917116  # verify_contents(catalogue, '/etc/nova/provid...         100\n",
       "\n",
       "[625 rows x 3 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_changes.loc[(df_changes[\"insertions\"]==100)&(df_changes[\"is_dependent\"]==0), [\"number\", \"added_lines\", \"insertions\"]].sort_values(\"insertions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_output = pd.read_csv(osp.join(\".\", \"combined_output.csv\"))\n",
    "combined_output.drop(columns=[\"owner_account_id\", 'status'], inplace=True)\n",
    "# combined_output[\"changed_files\"] = combined_output[\"changed_files\"].map(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_path = osp.join('.', 'Files', 'Metrics')\n",
    "metric_list = [f for f in hpr.list_file(metric_path) if f[:-4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_mod_file_dep_cha(row):\n",
    "    changed_files = row[\"changed_files\"]\n",
    "    if type(changed_files) is not list:\n",
    "        changed_files = []\n",
    "    return round(100*row['num_mod_file_dep_cha']/len(changed_files), 2) if len(changed_files) != 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = clas_util.combine_features()\n",
    "df = pd.merge(\n",
    "    left=df, \n",
    "    right=combined_output, \n",
    "    left_on='number', \n",
    "    right_on='number', \n",
    "    how='left',\n",
    "    suffixes=('_source', '_target')\n",
    ")\n",
    "df['pctg_mod_file_dep_cha'] = df.apply(calc_mod_file_dep_cha, axis=1)\n",
    "df['is_dependent'] = df['number'].map(lambda nbr: 1 if nbr in dependent_changes else 0)\n",
    "df = df.drop(columns=[\n",
    "    \"number\", \"changed_files\", \"num_mod_file_dep_cha\", 'num_build_failures'\n",
    "    ])\n",
    "df.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>description_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>90292</th>\n",
       "      <td>137514</td>\n",
       "      <td>325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132768</th>\n",
       "      <td>189241</td>\n",
       "      <td>325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164234</th>\n",
       "      <td>227312</td>\n",
       "      <td>325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164725</th>\n",
       "      <td>227875</td>\n",
       "      <td>325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168060</th>\n",
       "      <td>231778</td>\n",
       "      <td>325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689764</th>\n",
       "      <td>886851</td>\n",
       "      <td>325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>692661</th>\n",
       "      <td>891651</td>\n",
       "      <td>325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699515</th>\n",
       "      <td>902009</td>\n",
       "      <td>325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>706804</th>\n",
       "      <td>912768</td>\n",
       "      <td>325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>710979</th>\n",
       "      <td>919376</td>\n",
       "      <td>325</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>87 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        number  description_length\n",
       "90292   137514                 325\n",
       "132768  189241                 325\n",
       "164234  227312                 325\n",
       "164725  227875                 325\n",
       "168060  231778                 325\n",
       "...        ...                 ...\n",
       "689764  886851                 325\n",
       "692661  891651                 325\n",
       "699515  902009                 325\n",
       "706804  912768                 325\n",
       "710979  919376                 325\n",
       "\n",
       "[87 rows x 2 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[(df[\"description_length\"]==325)&(df[\"is_dependent\"]==1), [\"number\", \"description_length\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "dep_per_project = df.groupby(['project', 'is_dependent']).count().reset_index()[['project', 'is_dependent', 'number']]\n",
    "dep_per_project.rename(columns={'number': 'count'}, inplace=True)\n",
    "# dep_per_project[(dep_per_project['is_dependent']==1)&(dep_per_project['count']==0)]\n",
    "projects_sample = dep_per_project.sort_values(['is_dependent', 'count'], ascending=False)\n",
    "projects_sample = projects_sample[(projects_sample['is_dependent']==1)&(projects_sample['count']>=300)].iloc[:, 0].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build dataset for the 1st model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['is_dependent']\n",
    "X = df.drop(columns=['is_dependent'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_classifiers = clas_util.load_classifiers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features = pd.read_csv(osp.join(\".\", \"Results\", \"Correlation\", \"first_model.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training ad evaluation of the first and second model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training with ET classifier...\n",
      "['pctg_mod_file_dep_cha']\n",
      "ET, Fold: 1, Precision: 0.02854927714689652, Recall: 0.753309265944645, AUC: 0.710021864964312, Brier: 0.332154385531376\n",
      "['pctg_mod_file_dep_cha']\n",
      "ET, Fold: 2, Precision: 0.06601873976427632, Recall: 0.8318673883626523, AUC: 0.6344363887484961, Brier: 0.5449673343938716\n",
      "['pctg_mod_file_dep_cha']\n",
      "ET, Fold: 3, Precision: 0.08985742060920285, Recall: 0.8282556750298686, AUC: 0.6854026139770917, Brier: 0.4426768807821212\n",
      "['pctg_mod_file_dep_cha']\n",
      "ET, Fold: 4, Precision: 0.11677319814855631, Recall: 0.7536273115220483, AUC: 0.7132063915854298, Brier: 0.32282576798925045\n",
      "['pctg_mod_file_dep_cha']\n",
      "ET, Fold: 5, Precision: 0.11885742814349903, Recall: 0.7251958224543081, AUC: 0.6572064796632566, Brier: 0.40113055431139666\n",
      "['pctg_mod_file_dep_cha']\n",
      "ET, Fold: 6, Precision: 0.17895816710361337, Recall: 0.668749112594065, AUC: 0.6471345036143762, Brier: 0.36977775032047816\n",
      "['pctg_mod_file_dep_cha']\n",
      "ET, Fold: 7, Precision: 0.12772329555464207, Recall: 0.7336819025130713, AUC: 0.6142992123330768, Brier: 0.4832192997358951\n",
      "['pctg_mod_file_dep_cha']\n",
      "ET, Fold: 8, Precision: 0.14646187602852442, Recall: 0.700327868852459, AUC: 0.6379109632597589, Brier: 0.41274499204596354\n",
      "['num_file_changes', 'pctg_mod_file_dep_cha']\n",
      "ET, Fold: 9, Precision: 0.12854899908412926, Recall: 0.6856245638520586, AUC: 0.6170900079278934, Brier: 0.4393099294175792\n",
      "['pctg_mod_file_dep_cha']\n",
      "ET, Fold: 10, Precision: 0.10514791121033876, Recall: 0.5945617868414663, AUC: 0.6253966155293298, Brier: 0.34769178494756514\n",
      "ET, Precision: 0.1106896312793679, Recall: 0.7275200697966644, AUC: 0.6542105041603021, Brier: 0.40964986794754965\n",
      "Start training with RF classifier...\n",
      "['pctg_mod_file_dep_cha']\n",
      "RF, Fold: 1, Precision: 0.15200931857891672, Recall: 0.9422382671480144, AUC: 0.936949285648605, Brier: 0.06820393222852024\n",
      "['pctg_mod_file_dep_cha']\n",
      "RF, Fold: 2, Precision: 0.15061287027579162, Recall: 0.9976319350473613, AUC: 0.8642413530976315, Brier: 0.2569694348772916\n",
      "['pctg_mod_file_dep_cha']\n",
      "RF, Fold: 3, Precision: 0.1408582486284183, Recall: 0.989247311827957, AUC: 0.8301177193352067, Brier: 0.3125550218542944\n",
      "['pctg_mod_file_dep_cha']\n",
      "RF, Fold: 4, Precision: 0.1704608271772451, Recall: 0.9650071123755334, AUC: 0.8477129238386683, Brier: 0.25684587702905154\n",
      "['pctg_mod_file_dep_cha']\n",
      "RF, Fold: 5, Precision: 0.17791729984803648, Recall: 0.9680156657963447, AUC: 0.8131295432604274, Brier: 0.3197677112453087\n",
      "['pctg_mod_file_dep_cha']\n",
      "RF, Fold: 6, Precision: 0.2494118539880094, Recall: 0.9332670736901888, AUC: 0.7952329406992467, Brier: 0.31277124808871454\n",
      "['pctg_mod_file_dep_cha']\n",
      "RF, Fold: 7, Precision: 0.2177120375274268, Recall: 0.9706527238994771, AUC: 0.8095383378754756, Brier: 0.32206897616878\n",
      "['pctg_mod_file_dep_cha']\n",
      "RF, Fold: 8, Precision: 0.2143945163747144, Recall: 0.9229508196721311, AUC: 0.7855925854801735, Brier: 0.3258838247331923\n",
      "['num_file_changes', 'pctg_mod_file_dep_cha']\n",
      "RF, Fold: 9, Precision: 0.19797677306259587, Recall: 0.9457431960921144, AUC: 0.786808732672847, Brier: 0.34398504950036296\n",
      "['pctg_mod_file_dep_cha']\n",
      "RF, Fold: 10, Precision: 0.18164157357940747, Recall: 0.9079873755765963, AUC: 0.8150314921031362, Brier: 0.266097270916027\n",
      "RF, Precision: 0.18529953190405624, Recall: 0.9542741481125718, AUC: 0.8284354914011418, Brier: 0.27851483466415433\n",
      "Start training with XGBoost classifier...\n",
      "['pctg_mod_file_dep_cha']\n",
      "XGBoost, Fold: 1, Precision: 0.1648912561029738, Recall: 0.8941034897713598, AUC: 0.9176146712265022, Brier: 0.05947765919656509\n",
      "['pctg_mod_file_dep_cha']\n",
      "XGBoost, Fold: 2, Precision: 0.1572093023255814, Recall: 0.9719215155615697, AUC: 0.8613309573244077, Brier: 0.2391616599996911\n",
      "['pctg_mod_file_dep_cha']\n",
      "XGBoost, Fold: 3, Precision: 0.15146541617819462, Recall: 0.9647550776583035, AUC: 0.8350217187017881, Brier: 0.28129488624955595\n",
      "['pctg_mod_file_dep_cha']\n",
      "XGBoost, Fold: 4, Precision: 0.1950522732798444, Recall: 0.9129445234708392, AUC: 0.848334359984701, Brier: 0.20926066072559346\n",
      "['pctg_mod_file_dep_cha']\n",
      "XGBoost, Fold: 5, Precision: 0.18202883625128732, Recall: 0.922976501305483, AUC: 0.8030370195842639, Brier: 0.29987489767865694\n",
      "['pctg_mod_file_dep_cha']\n",
      "XGBoost, Fold: 6, Precision: 0.2503992210321324, Recall: 0.9128212409484595, AUC: 0.7896457514876776, Brier: 0.306732358255981\n",
      "['pctg_mod_file_dep_cha']\n",
      "XGBoost, Fold: 7, Precision: 0.22334392470739653, Recall: 0.9365828976218586, AUC: 0.8041410186704961, Brier: 0.30404497505675937\n",
      "['pctg_mod_file_dep_cha']\n",
      "XGBoost, Fold: 8, Precision: 0.2167171556122449, Recall: 0.891311475409836, AUC: 0.7781194613395455, Brier: 0.3137442661436051\n",
      "['num_file_changes', 'pctg_mod_file_dep_cha']\n",
      "XGBoost, Fold: 9, Precision: 0.20590315988052194, Recall: 0.9139916259595254, AUC: 0.7858105211048156, Brier: 0.3196750428591286\n",
      "['pctg_mod_file_dep_cha']\n",
      "XGBoost, Fold: 10, Precision: 0.18767258896472672, Recall: 0.8744840980820587, AUC: 0.808662844712996, Brier: 0.24878372743138677\n",
      "XGBoost, Precision: 0.1934683134334904, Recall: 0.9195892445789294, AUC: 0.8231718324137194, Brier: 0.25820501335969237\n",
      "Start training with AdaBoost classifier...\n",
      "['pctg_mod_file_dep_cha']\n",
      "AdaBoost, Fold: 1, Precision: 0.16511824324324326, Recall: 0.941034897713598, AUC: 0.9395862266276234, Brier: 0.06182525831312648\n",
      "['pctg_mod_file_dep_cha']\n",
      "AdaBoost, Fold: 2, Precision: 0.1984907893763409, Recall: 0.9076454668470907, AUC: 0.8661562447763315, Brier: 0.17154462755031122\n",
      "['pctg_mod_file_dep_cha']\n",
      "AdaBoost, Fold: 3, Precision: 0.16076173604960142, Recall: 0.9758064516129032, AUC: 0.8490165989884253, Brier: 0.26466091093023614\n",
      "['pctg_mod_file_dep_cha']\n",
      "AdaBoost, Fold: 4, Precision: 0.16509045055531307, Recall: 0.968421052631579, AUC: 0.8436386031383658, Brier: 0.2675954098259379\n",
      "['pctg_mod_file_dep_cha']\n",
      "AdaBoost, Fold: 5, Precision: 0.21269493558650185, Recall: 0.8872932985204526, AUC: 0.8181707635725404, Brier: 0.24113858557153228\n",
      "['pctg_mod_file_dep_cha']\n",
      "AdaBoost, Fold: 6, Precision: 0.2396997145173228, Recall: 0.965639642197927, AUC: 0.7959003701076978, Brier: 0.33691136268861877\n",
      "['pctg_mod_file_dep_cha']\n",
      "AdaBoost, Fold: 7, Precision: 0.20496388613510835, Recall: 0.9763872491145218, AUC: 0.7973081813255971, Brier: 0.3489736976230559\n",
      "['pctg_mod_file_dep_cha']\n",
      "AdaBoost, Fold: 8, Precision: 0.19204858460823682, Recall: 0.948688524590164, AUC: 0.7667803630333978, Brier: 0.3808516224689947\n",
      "['num_file_changes', 'pctg_mod_file_dep_cha']\n",
      "AdaBoost, Fold: 9, Precision: 0.19309998925231972, Recall: 0.9403349616189811, AUC: 0.7793431141230549, Brier: 0.35314377500115834\n",
      "['pctg_mod_file_dep_cha']\n",
      "AdaBoost, Fold: 10, Precision: 0.16628279817549566, Recall: 0.8939062879339645, AUC: 0.7947050077922775, Brier: 0.2918745270051122\n",
      "AdaBoost, Precision: 0.1898251127499484, Recall: 0.9405157832781181, AUC: 0.8250605473485312, Brier: 0.27185197769780844\n",
      "Start training with MLP classifier...\n",
      "['pctg_mod_file_dep_cha']\n",
      "MLP, Fold: 1, Precision: 0.025108483222365762, Recall: 0.9121540312876053, AUC: 0.7258451488185945, Brier: 0.45568134430938884\n",
      "['pctg_mod_file_dep_cha']\n",
      "MLP, Fold: 2, Precision: 0.11529411764705882, Recall: 0.38125845737483083, AUC: 0.6206514002010662, Brier: 0.16181444700140546\n",
      "['pctg_mod_file_dep_cha']\n",
      "MLP, Fold: 3, Precision: 0.13549501931286848, Recall: 0.7962962962962963, AUC: 0.7596279768098527, Brier: 0.27324818138292123\n",
      "['pctg_mod_file_dep_cha']\n",
      "MLP, Fold: 4, Precision: 0.10082020997375328, Recall: 0.87425320056899, AUC: 0.7133302193072282, Brier: 0.43012031445472376\n",
      "['pctg_mod_file_dep_cha']\n",
      "MLP, Fold: 5, Precision: 0.14976403253338688, Recall: 0.6490426457789382, AUC: 0.6837505958857619, Brier: 0.286468871144609\n",
      "['pctg_mod_file_dep_cha']\n",
      "MLP, Fold: 6, Precision: 0.23780267437658115, Recall: 0.5605565810024138, AUC: 0.6706325120456406, Brier: 0.24323906899161352\n",
      "['pctg_mod_file_dep_cha']\n",
      "MLP, Fold: 7, Precision: 0.09946134456683126, Recall: 0.9716646989374262, AUC: 0.5424221689117408, Brier: 0.8082073300693469\n",
      "['pctg_mod_file_dep_cha']\n",
      "MLP, Fold: 8, Precision: 0.14205933682373473, Recall: 0.7339344262295082, AUC: 0.6364524382754614, Brier: 0.44266143605109115\n",
      "['num_file_changes', 'pctg_mod_file_dep_cha']\n",
      "MLP, Fold: 9, Precision: 0.10995784908510586, Recall: 0.787334263782275, AUC: 0.5841695465314832, Brier: 0.583023151651814\n",
      "['pctg_mod_file_dep_cha']\n",
      "MLP, Fold: 10, Precision: 0.081006645778035, Recall: 0.9854333576110706, AUC: 0.6129581513924589, Brier: 0.7121256583316602\n",
      "MLP, Precision: 0.11967697133197212, Recall: 0.7651927958869355, AUC: 0.654984015817929, Brier: 0.4396589803388574\n"
     ]
    }
   ],
   "source": [
    "training_results = {key: None for key in ensemble_classifiers.keys()}\n",
    "tscv = TimeSeriesSplit(n_splits = 10)\n",
    "\n",
    "clf_path = osp.join('.', 'Results')\n",
    "if not os.path.exists(clf_path):\n",
    "    os.makedirs(clf_path)\n",
    "\n",
    "df_feat_impo = pd.DataFrame()\n",
    "# df_feat_impact = pd.DataFrame()\n",
    "\n",
    "for label, ens_clf in ensemble_classifiers.items():\n",
    "    print(f'Start training with {label} classifier...')\n",
    "\n",
    "    # if label not in ['RF']:\n",
    "    #     continue\n",
    "\n",
    "    auc_scores = []\n",
    "    precision_scores = []\n",
    "    recall_scores = []\n",
    "    brier_scores = []\n",
    "    # feature_importances = np.zeros(len(METRICS))\n",
    "    feature_importances = []\n",
    "    corr_features = []\n",
    "    redundant_features = []\n",
    "    # df_features = pd.DataFrame({\"Feat\":X_train.columns.tolist()})\n",
    "    # for f in range(0, 10):\n",
    "    #     df_features[f\"Fold{f}\"] = [1]*len(df_features)\n",
    "    # df_features.to_csv(osp.join(\".\", \"Results\", \"Correlation\", \"first_model.csv\"), index=None)\n",
    "\n",
    "    for fold, (train_idx, test_idx) in enumerate(tscv.split(X)):\n",
    "        # if fold < 7:\n",
    "        #     continue\n",
    "        clone_clf = clone(ens_clf)\n",
    "\n",
    "        # Filter training set\n",
    "        X_train = X.iloc[train_idx]\n",
    "        y_train = y.iloc[train_idx]\n",
    "        \n",
    "        # corr_path = osp.join('.', 'Results', 'Correlation', f'first_model')\n",
    "        # if not os.path.exists(corr_path):\n",
    "        #     os.makedirs(corr_path)\n",
    "            \n",
    "        corr_features = df_features.loc[df_features[f'Fold{fold}']==0, 'Feat'].tolist()\n",
    "        # plt.figure(figsize=(6,12))\n",
    "        # dissimilarity = 1 - abs(X_train.corr())\n",
    "        # Z = linkage(squareform(dissimilarity), 'complete')\n",
    "\n",
    "        # dendrogram(Z, labels=X_train.columns, orientation='left')\n",
    "\n",
    "        # threshold = 0.3 * max(Z[:, 2])  # Scale threshold based on the maximum distance in the dendrogram\n",
    "        # plt.axvline(x=threshold, color='r', linestyle='--')\n",
    "\n",
    "        # # Adjust the layout to make sure labels fit\n",
    "        # plt.tight_layout()\n",
    "        # plt.savefig(f'{corr_path}/{fold}.pdf')\n",
    "\n",
    "        # Remove highly correlated features from the training sets\n",
    "        if len(corr_features) > 0:\n",
    "            X_train = X_train.drop(columns=corr_features)\n",
    "\n",
    "        # Conduct redundancy analysis\n",
    "        redundant_features = clas_util.redundancy_analysis(X_train)\n",
    "        print(redundant_features)\n",
    "        # Remove indepandent variables explained by others\n",
    "        X_train = X_train.drop(columns=redundant_features)\n",
    "\n",
    "        # Instantiate the UnderSampler class then fit it on the each fold training dataset\n",
    "        ros = RandomUnderSampler(random_state=0)\n",
    "        \n",
    "        # Perform under-sampling of the majority class(es)\n",
    "        X_train, y_train = ros.fit_resample(X_train, y_train)\n",
    "    \n",
    "        # Train the Random Forest Classifier on the training fold set \n",
    "        clone_clf.fit(X_train, y_train)\n",
    "\n",
    "        # Columns to exclude in the test set\n",
    "        cols_exluded = corr_features + redundant_features\n",
    "        \n",
    "        # print(highly_correlated_features, independent_features)\n",
    "\n",
    "        # Filter training set\n",
    "        X_test = X.iloc[test_idx]\n",
    "        X_test = X_test.drop(columns=cols_exluded)\n",
    "        y_test = y.iloc[test_idx]\n",
    "\n",
    "        # Test the Random Forest Classifier on the test fold set \n",
    "        y_pred = clone_clf.predict(X_test)\n",
    "        \n",
    "        precision_scores.append(precision_score(y_test, y_pred))\n",
    "        recall_scores.append(recall_score(y_test, y_pred))\n",
    "        auc_scores.append(roc_auc_score(y_test, y_pred))\n",
    "        brier_scores.append(brier_score_loss(y_test, y_pred))\n",
    "\n",
    "        if label == 'RF':\n",
    "            df_feat_imp_item = pd.DataFrame({name: [val] for name, val in zip(X_train.columns.to_list(), clone_clf.feature_importances_)})\n",
    "            # if 'pctg_mod_file_dep_cha' in X_train.columns:\n",
    "            # print(X_train.columns.sort_values())\n",
    "            df_feat_impo = pd.concat((df_feat_impo, df_feat_imp_item))\n",
    "        if label not in ['MLP']:\n",
    "\n",
    "            binary_cols = list(constants.DESCRIPTION.keys())\n",
    "\n",
    "            # Step 1: Calculate the median of each column\n",
    "            medians = X_train.median()\n",
    "\n",
    "            # Step 2: Calculate the standard deviation of each column\n",
    "            std_devs = X_train.std()\n",
    "\n",
    "            # Step 3: Create a new dataframe starting with the median row\n",
    "            df_feat_impact_item = pd.DataFrame([medians])\n",
    "            for col in binary_cols:\n",
    "                if col in X_train.columns.tolist():\n",
    "                    df_feat_impact_item[col] = 0\n",
    "        \n",
    "            df_feat_impact_item = pd.concat([df_feat_impact_item] * (len(X_train.columns.to_list()) + 1), ignore_index=True)\n",
    "\n",
    "            # Step 4: Double the number of rows according to the number of features and add standard deviation to each column\n",
    "            for idx, col in zip(range(1, len(df_feat_impact_item.columns)+1), df_feat_impact_item.columns):\n",
    "                if col in binary_cols:\n",
    "                    df_feat_impact_item.iloc[idx, idx-1] = 1\n",
    "                else:\n",
    "                    df_feat_impact_item.iloc[idx, idx-1] += std_devs[col]\n",
    "\n",
    "            df_feat_impact_item['pred'] = clone_clf.predict_proba(df_feat_impact_item)[:,1]\n",
    "            proba1 = df_feat_impact_item.iloc[0, -1]\n",
    "            df_feat_impact_item['impact'] = None\n",
    "\n",
    "            df_feat_impact_item.iloc[1:, -1] = 0 if proba1 == 0 else (df_feat_impact_item.iloc[1:, -2] - proba1) / proba1\n",
    "\n",
    "            df_feat_impact_item['fold'] = fold\n",
    "            df_feat_impact_item['Classifier'] = label\n",
    "\n",
    "            df_feat_impact = pd.concat((df_feat_impact, df_feat_impact_item))\n",
    "\n",
    "        print(f\"{label}, Fold: {fold+1}, Precision: {precision_scores[-1]}, Recall: {recall_scores[-1]}, AUC: {auc_scores[-1]}, Brier: {brier_scores[-1]}\")\n",
    "\n",
    "    prec_avg = np.average(precision_scores)\n",
    "    recall_avg = np.average(recall_scores)\n",
    "    auc_avg = np.average(auc_scores)\n",
    "    brier_avg = np.average(brier_scores)\n",
    "\n",
    "    print(f\"{label}, Precision: {prec_avg}, Recall: {recall_avg}, AUC: {auc_avg}, Brier: {brier_avg}\")\n",
    "\n",
    "    training_results[label] = {\n",
    "        'Classifier': label,\n",
    "        'Precision': prec_avg,\n",
    "        'Recall': recall_avg,\n",
    "        'AUC': auc_avg,\n",
    "        'Brier': brier_avg,\n",
    "        'AUC Scores': auc_scores,\n",
    "        'Precision Scores': precision_scores,\n",
    "        'Recall Scores': recall_scores,\n",
    "        'Brier Scores': brier_scores,\n",
    "        # 'feature_importances': feature_importances,\n",
    "        # 'features': X_train.columns.tolist()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training_results = pd.DataFrame(list(training_results.values()))\n",
    "df_training_results.sort_values(by=['AUC', 'Brier'], ascending=[0, 1], inplace=True)\n",
    "df_training_results.to_csv(osp.join('.', 'Results', 'first_model_perf.csv'), index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training_results = pd.read_csv(osp.join('.', 'Results', 'first_model_perf.csv'))\n",
    "# df_training_results.sort_values(by=['AUC', 'Brier'], ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def latex_float(f):\n",
    "    float_str = \"{0:.2g}\".format(f)\n",
    "    if \"e\" in float_str:\n",
    "        base, exponent = float_str.split(\"e\")\n",
    "        return r\"{0} \\times 10^{{{1}}}\".format(base, int(exponent))\n",
    "    else:\n",
    "        return float_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training_results_m2 = pd.read_csv(osp.join(\".\", \"Results\", \"second_model_perf.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\multirow{2}{*}{RF} & AUC & $82.86\\%$ & $80.84\\%$\\\\\n",
      "& Brier & $0.28$ & $0.072$\\\\\n",
      "\\noalign{\\smallskip}\n",
      "\\hhline{~----}\n",
      "\\noalign{\\smallskip}\n",
      "\\multirow{2}{*}{AdaBoost} & AUC & $82.72\\%$ & $77.16\\%$\\\\\n",
      "& Brier & $0.27$ & $0.16$\\\\\n",
      "\\noalign{\\smallskip}\n",
      "\\hhline{~----}\n",
      "\\noalign{\\smallskip}\n",
      "\\multirow{2}{*}{XGBoost} & AUC & $82.35\\%$ & $84.49\\%$\\\\\n",
      "& Brier & $0.26$ & $0.099$\\\\\n",
      "\\noalign{\\smallskip}\n",
      "\\hhline{~----}\n",
      "\\noalign{\\smallskip}\n",
      "\\multirow{2}{*}{ET} & AUC & $70.74\\%$ & $64.49\\%$\\\\\n",
      "& Brier & $0.35$ & $0.3$\\\\\n",
      "\\noalign{\\smallskip}\n",
      "\\hhline{~----}\n",
      "\\noalign{\\smallskip}\n",
      "\\multirow{2}{*}{MLP} & AUC & $60.02\\%$ & $69.58\\%$\\\\\n",
      "& Brier & $0.61$ & $0.17$\\\\\n",
      "\\noalign{\\smallskip}\n",
      "\\hhline{~----}\n",
      "\\noalign{\\smallskip}\n"
     ]
    }
   ],
   "source": [
    "for idx, row in df_training_results.iterrows():\n",
    "    m2_perf = df_training_results_m2[df_training_results_m2['Classifier']==row['Classifier']]\n",
    "    print(\"\\multirow{2}{*}\"+\"{\"+row['Classifier']+\"} & AUC & $\"+str(round(row['AUC']*100, 2))+\"\\%$ & $\"+str(round(m2_perf['AUC'].values[0]*100, 2))+\"\\%$\\\\\" + \"\\\\\")\n",
    "    print(\"& Brier & $\"+latex_float(row['Brier'])+\"$ & $\"+latex_float(m2_perf['Brier'].values[0])+\"$\\\\\"+ \"\\\\\")\n",
    "    print(\"\\\\noalign{\\smallskip}\")\n",
    "    print(\"\\hhline{~----}\")\n",
    "\n",
    "    print(\"\\\\noalign{\\smallskip}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>has_feature_addition</th>\n",
       "      <th>deletions</th>\n",
       "      <th>insertions</th>\n",
       "      <th>num_file_types</th>\n",
       "      <th>is_preventive</th>\n",
       "      <th>project_changes_owner</th>\n",
       "      <th>is_refactoring</th>\n",
       "      <th>whole_within_project_changes</th>\n",
       "      <th>is_merge</th>\n",
       "      <th>num_directory_files</th>\n",
       "      <th>...</th>\n",
       "      <th>pctg_mod_file_dep_cha</th>\n",
       "      <th>pred</th>\n",
       "      <th>impact</th>\n",
       "      <th>fold</th>\n",
       "      <th>max_num_mod_file_dep_cha</th>\n",
       "      <th>cross_project_changes_owner</th>\n",
       "      <th>min_num_mod_file_dep_cha</th>\n",
       "      <th>cross_project_changes</th>\n",
       "      <th>whole_changes_owner</th>\n",
       "      <th>num_dev_modified_files</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.5</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.12</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.5</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>12.89036</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.5</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.09</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>239.808907</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.5</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>1.637287</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.5</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>0</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>15357.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42.0</td>\n",
       "      <td>389.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>0</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>15357.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.018519</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42.0</td>\n",
       "      <td>389.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>0</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>15357.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.12963</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42.0</td>\n",
       "      <td>389.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>0</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>15357.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.148148</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>74.604505</td>\n",
       "      <td>42.0</td>\n",
       "      <td>389.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>0</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>15357.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>105.949923</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42.0</td>\n",
       "      <td>389.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>240 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     has_feature_addition  deletions  insertions  num_file_types  \\\n",
       "0                       0    2.00000   13.000000        1.000000   \n",
       "1                       1    2.00000   13.000000        1.000000   \n",
       "2                       0   12.89036   13.000000        1.000000   \n",
       "3                       0    2.00000  239.808907        1.000000   \n",
       "4                       0    2.00000   13.000000        1.637287   \n",
       "..                    ...        ...         ...             ...   \n",
       "235                     0    2.00000    7.000000        1.000000   \n",
       "236                     0    2.00000    7.000000        1.000000   \n",
       "237                     0    2.00000    7.000000        1.000000   \n",
       "238                     0    2.00000    7.000000        1.000000   \n",
       "239                     0    2.00000    7.000000        1.000000   \n",
       "\n",
       "     is_preventive  project_changes_owner  is_refactoring  \\\n",
       "0                0                    5.0               0   \n",
       "1                0                    5.0               0   \n",
       "2                0                    5.0               0   \n",
       "3                0                    5.0               0   \n",
       "4                0                    5.0               0   \n",
       "..             ...                    ...             ...   \n",
       "235              0                    NaN               0   \n",
       "236              0                    NaN               0   \n",
       "237              0                    NaN               0   \n",
       "238              0                    NaN               0   \n",
       "239              0                    NaN               0   \n",
       "\n",
       "     whole_within_project_changes  is_merge  num_directory_files  ...  \\\n",
       "0                             7.5         0                  1.0  ...   \n",
       "1                             7.5         0                  1.0  ...   \n",
       "2                             7.5         0                  1.0  ...   \n",
       "3                             7.5         0                  1.0  ...   \n",
       "4                             7.5         0                  1.0  ...   \n",
       "..                            ...       ...                  ...  ...   \n",
       "235                       15357.0         0                  1.0  ...   \n",
       "236                       15357.0         0                  1.0  ...   \n",
       "237                       15357.0         0                  1.0  ...   \n",
       "238                       15357.0         0                  1.0  ...   \n",
       "239                       15357.0         0                  1.0  ...   \n",
       "\n",
       "     pctg_mod_file_dep_cha  pred    impact  fold  max_num_mod_file_dep_cha  \\\n",
       "0                 0.000000  0.12      None     1                       NaN   \n",
       "1                 0.000000  0.13  0.083333     1                       NaN   \n",
       "2                 0.000000  0.09     -0.25     1                       NaN   \n",
       "3                 0.000000  0.18       0.5     1                       NaN   \n",
       "4                 0.000000  0.12       0.0     1                       NaN   \n",
       "..                     ...   ...       ...   ...                       ...   \n",
       "235              60.000000  0.58  0.074074    10                       NaN   \n",
       "236              60.000000  0.55  0.018519    10                       NaN   \n",
       "237              60.000000  0.61   0.12963    10                       NaN   \n",
       "238              60.000000  0.62  0.148148    10                       NaN   \n",
       "239             105.949923  0.60  0.111111    10                       NaN   \n",
       "\n",
       "     cross_project_changes_owner  min_num_mod_file_dep_cha  \\\n",
       "0                            NaN                       NaN   \n",
       "1                            NaN                       NaN   \n",
       "2                            NaN                       NaN   \n",
       "3                            NaN                       NaN   \n",
       "4                            NaN                       NaN   \n",
       "..                           ...                       ...   \n",
       "235                          1.0                  0.000000   \n",
       "236                          1.0                  0.000000   \n",
       "237                          1.0                  0.000000   \n",
       "238                          1.0                 74.604505   \n",
       "239                          1.0                  0.000000   \n",
       "\n",
       "     cross_project_changes  whole_changes_owner  num_dev_modified_files  \n",
       "0                      NaN                  NaN                     NaN  \n",
       "1                      NaN                  NaN                     NaN  \n",
       "2                      NaN                  NaN                     NaN  \n",
       "3                      NaN                  NaN                     NaN  \n",
       "4                      NaN                  NaN                     NaN  \n",
       "..                     ...                  ...                     ...  \n",
       "235                   42.0                389.0                     NaN  \n",
       "236                   42.0                389.0                     NaN  \n",
       "237                   42.0                389.0                     NaN  \n",
       "238                   42.0                389.0                     NaN  \n",
       "239                   42.0                389.0                     NaN  \n",
       "\n",
       "[240 rows x 31 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_feat_impact = df_feat_impact.reset_index(drop=True)\n",
    "# df_feat_impact.to_csv(osp.join('.', 'Results', 'Impact', 'first_model_feat_impact.csv'), index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feat_impo.fillna(0, inplace=True)\n",
    "# df_feat_impo\n",
    "df_feat_impo.to_csv(osp.join('.', 'Results', 'Feature_importance', 'first_feat_impo.csv'), index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimension importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimensions = {\n",
    "    'Change': constants.CHANGE_METRICS,\n",
    "    'Text': constants.TEXT_METRICS,\n",
    "    'Developer': constants.DEVELOPER_METRICS,\n",
    "    'Project': constants.PROJECT_METRICS,\n",
    "    'File': constants.FILE_METRICS\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training with Change dimension...\n",
      "Dimension: Change, Fold: 1, Precision: 0.015423621381787449, Recall: 0.35138387484957884, AUC: 0.5298755534207842, Brier: 0.2962144964245448\n",
      "Dimension: Change, Fold: 2, Precision: 0.05910109708623334, Recall: 0.5084573748308525, AUC: 0.5606082572556943, Brier: 0.39200271827266125\n",
      "Dimension: Change, Fold: 3, Precision: 0.06943020916372471, Recall: 0.5462962962962963, AUC: 0.5735194897009421, Brier: 0.4020726829042272\n",
      "Dimension: Change, Fold: 4, Precision: 0.07304228362082126, Recall: 0.5445234708392603, AUC: 0.5739177322840148, Brier: 0.3998795310979659\n",
      "Dimension: Change, Fold: 5, Precision: 0.0955488938640762, Recall: 0.5478677110530896, AUC: 0.5758074735877574, Brier: 0.40021931518062615\n",
      "Dimension: Change, Fold: 6, Precision: 0.1363697388735987, Recall: 0.5768848502058782, AUC: 0.5654856110172605, Brier: 0.44343367260259164\n",
      "Dimension: Change, Fold: 7, Precision: 0.11440801990340992, Recall: 0.5274076572777872, AUC: 0.5579419870257819, Brier: 0.4171158509274561\n",
      "Dimension: Change, Fold: 8, Precision: 0.11243826403726925, Recall: 0.5262295081967213, AUC: 0.5470849486522168, Brier: 0.43598931224612725\n",
      "Dimension: Change, Fold: 9, Precision: 0.11693564067664787, Recall: 0.5245987438939288, AUC: 0.5699076071414064, Brier: 0.39280584428622173\n",
      "Dimension: Change, Fold: 10, Precision: 0.0873059866962306, Recall: 0.5353241077931536, AUC: 0.5775601207963591, Brier: 0.38557771016417747\n",
      "Change, Precision: 0.08800037553037993, Recall: 0.5188973595236547, AUC: 0.5631708780882216\n",
      "Start training with Text dimension...\n",
      "Dimension: Text, Fold: 1, Precision: 0.014331845724030333, Recall: 0.4753309265944645, AUC: 0.5251521645926825, Brier: 0.42630546589031154\n",
      "Dimension: Text, Fold: 2, Precision: 0.059796588705528515, Recall: 0.5111637347767253, AUC: 0.5633370420901801, Brier: 0.38925355614931967\n",
      "Dimension: Text, Fold: 3, Precision: 0.07263809412589046, Recall: 0.557347670250896, AUC: 0.5846723041558883, Brier: 0.3908289187143806\n",
      "Dimension: Text, Fold: 4, Precision: 0.07982815057283142, Recall: 0.5550497866287339, AUC: 0.5938872528649288, Brier: 0.3714921154648092\n",
      "Dimension: Text, Fold: 5, Precision: 0.10417749350389766, Recall: 0.5670147954743255, AUC: 0.5972345178182918, Brier: 0.3768359924011923\n",
      "Dimension: Text, Fold: 6, Precision: 0.14939333608805078, Recall: 0.5646741445406787, AUC: 0.5861288371393258, Brier: 0.39708403478153426\n",
      "Dimension: Text, Fold: 7, Precision: 0.12211854092132925, Recall: 0.5584415584415584, AUC: 0.5768847596349382, Brier: 0.40804979381284073\n",
      "Dimension: Text, Fold: 8, Precision: 0.12108932939072026, Recall: 0.5437704918032787, AUC: 0.5666232546659411, Brier: 0.41483003073501473\n",
      "Dimension: Text, Fold: 9, Precision: 0.10817125970723662, Recall: 0.5491974877878576, AUC: 0.5547054964144744, Brier: 0.44076173413440006\n",
      "Dimension: Text, Fold: 10, Precision: 0.08553299492385787, Recall: 0.5727118232580724, AUC: 0.5783579568886522, Brier: 0.4167142879206759\n",
      "Text, Precision: 0.09170776336633732, Recall: 0.5454702419556592, AUC: 0.5726983586265304\n",
      "Start training with Developer dimension...\n",
      "Dimension: Developer, Fold: 1, Precision: 0.16494192185850054, Recall: 0.9398315282791817, AUC: 0.9389845419104151, Brier: 0.06184070304415649\n",
      "Dimension: Developer, Fold: 2, Precision: 0.15852524478967234, Recall: 0.9803788903924222, AUC: 0.8657133888125953, Brier: 0.2384820918343707\n",
      "Dimension: Developer, Fold: 3, Precision: 0.14283827220289727, Recall: 0.9689366786140979, AUC: 0.8259396987754443, Brier: 0.3022688309883083\n",
      "Dimension: Developer, Fold: 4, Precision: 0.1609031432928329, Recall: 0.9305832147937411, AUC: 0.8260016936262929, Brier: 0.2672247362812177\n",
      "Dimension: Developer, Fold: 5, Precision: 0.16187008105250794, Recall: 0.8994778067885117, AUC: 0.7718116868891272, Brier: 0.3377299334332093\n",
      "Dimension: Developer, Fold: 6, Precision: 0.23289742232973012, Recall: 0.8749112594065029, AUC: 0.7615926046096705, Brier: 0.327073069022503\n",
      "Dimension: Developer, Fold: 7, Precision: 0.20258894833327099, Recall: 0.9133074717490302, AUC: 0.7754677043875553, Brier: 0.3371275889230389\n",
      "Dimension: Developer, Fold: 8, Precision: 0.17627906976744187, Recall: 0.8698360655737705, AUC: 0.7235346713191205, Brier: 0.39519977759587316\n",
      "Dimension: Developer, Fold: 9, Precision: 0.16958477508650519, Recall: 0.8550244242847174, AUC: 0.724182550192007, Brier: 0.3834926714751263\n",
      "Dimension: Developer, Fold: 10, Precision: 0.12769689528152955, Recall: 0.883709638261714, AUC: 0.73679280158121, Brier: 0.39143126322455096\n",
      "Developer, Precision: 0.16981257739948888, Recall: 0.911599697814369, AUC: 0.7950021342103437\n",
      "Start training with Project dimension...\n",
      "Dimension: Project, Fold: 1, Precision: 0.012834571485937573, Recall: 1.0, AUC: 0.5, Brier: 0.9871654285140624\n",
      "Dimension: Project, Fold: 2, Precision: 0.04752591433600626, Recall: 0.9042625169147497, AUC: 0.5186538912032439, Brier: 0.8317451001590808\n",
      "Dimension: Project, Fold: 3, Precision: 0.06377679265115854, Recall: 0.8336320191158901, AUC: 0.5831705104455817, Brier: 0.6413887902142185\n",
      "Dimension: Project, Fold: 4, Precision: 0.06826466654428155, Recall: 0.7405405405405405, AUC: 0.5801605237325123, Brier: 0.5628059987335321\n",
      "Dimension: Project, Fold: 5, Precision: 0.08781168862979474, Recall: 0.7800261096605744, AUC: 0.5804504540422704, Brier: 0.5907918513599085\n",
      "Dimension: Project, Fold: 6, Precision: 0.11113618413629696, Recall: 0.8391310521084765, AUC: 0.5099925328475281, Brier: 0.7475404265834711\n",
      "Dimension: Project, Fold: 7, Precision: 0.09998340524394292, Recall: 0.812953280485748, AUC: 0.5376439699718685, Brier: 0.6872441966423155\n",
      "Dimension: Project, Fold: 8, Precision: 0.1065891472868217, Recall: 0.55, AUC: 0.5352520163009191, Brier: 0.47671706797226127\n",
      "Dimension: Project, Fold: 9, Precision: 0.0925953241389483, Recall: 0.8761339846475925, AUC: 0.5211052029482138, Brier: 0.7710627519421749\n",
      "Dimension: Project, Fold: 10, Precision: 0.07656025868566288, Recall: 0.7645059480456421, AUC: 0.5690148662178465, Brier: 0.601603163080915\n",
      "Project, Precision: 0.07670779531388514, Recall: 0.8101185451519214, AUC: 0.5435443967709984\n",
      "Start training with File dimension...\n",
      "Dimension: File, Fold: 1, Precision: 0.015484842532573822, Recall: 0.5691937424789411, AUC: 0.5493427877548971, Brier: 0.4699986099742073\n",
      "Dimension: File, Fold: 2, Precision: 0.059037621638188646, Recall: 0.5213125845737483, AUC: 0.5619137569661964, Brier: 0.40119233323551673\n",
      "Dimension: File, Fold: 3, Precision: 0.06765880562951693, Recall: 0.4250298685782557, AUC: 0.5528299231325944, Brier: 0.3325868380002162\n",
      "Dimension: File, Fold: 4, Precision: 0.07265589440145653, Recall: 0.36330014224751067, AUC: 0.5485578970971026, Brier: 0.2862989791032789\n",
      "Dimension: File, Fold: 5, Precision: 0.08994515539305302, Recall: 0.32114882506527415, AUC: 0.536436825460103, Brier: 0.2788391740157845\n",
      "Dimension: File, Fold: 6, Precision: 0.13462425080682341, Recall: 0.331676842254721, AUC: 0.5357261238862681, Brier: 0.3046164301048697\n",
      "Dimension: File, Fold: 7, Precision: 0.1181812565639093, Recall: 0.32265137459942655, AUC: 0.5399852813015494, Brier: 0.2824841305388667\n",
      "Dimension: File, Fold: 8, Precision: 0.11205352935632834, Recall: 0.3898360655737705, AUC: 0.5342619037436265, Brier: 0.34852580042318565\n",
      "Dimension: File, Fold: 9, Precision: 0.10508567619495746, Recall: 0.4675505931612003, AUC: 0.5404092032145068, Brier: 0.3996324154014858\n",
      "Dimension: File, Fold: 10, Precision: 0.07687088405507883, Recall: 0.4675892206846322, AUC: 0.543049410104802, Brier: 0.39109147914189074\n",
      "File, Precision: 0.08515979165718862, Recall: 0.417928925921748, AUC: 0.5442513112661646\n"
     ]
    }
   ],
   "source": [
    "dimension_results = {key: [] for key in dimensions.keys()}\n",
    "# Change variable to 'keep' or 'discard\n",
    "dimension_type = 'keep'\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits = 10)\n",
    "\n",
    "clf_path = osp.join('.', 'Results')\n",
    "if not os.path.exists(clf_path):\n",
    "    os.makedirs(clf_path)\n",
    "\n",
    "for label, dimension in dimensions.items():\n",
    "    print(f'Start training with {label} dimension...')\n",
    "\n",
    "    features = []\n",
    "    if dimension_type == 'keep':\n",
    "        features = dimension\n",
    "    else:\n",
    "        for lab, dim in dimensions.items():\n",
    "            if lab != label:\n",
    "                features += dim\n",
    "\n",
    "    features = [f for f in features if f in X.columns.tolist()]\n",
    "\n",
    "    auc_scores = []\n",
    "    precision_scores = []\n",
    "    recall_scores = []\n",
    "    brier_scores = []\n",
    "    \n",
    "    feature_importances = []\n",
    "\n",
    "    kept_feat = []\n",
    "    corr_features = []\n",
    "    redundant_features = []\n",
    "\n",
    "    for fold, (train_idx, test_idx) in enumerate(tscv.split(X)):\n",
    "\n",
    "        forest_clf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "        # Filter training set\n",
    "        X_train = X.iloc[train_idx]\n",
    "        X_train = X_train[features]\n",
    "        y_train = y.iloc[train_idx]\n",
    "\n",
    "        # conduct the correlation analysis\n",
    "\n",
    "        # if fold == 0:\n",
    "        # corr_path = osp.join('.', 'Results', 'Correlation', f'{model}_model')\n",
    "            \n",
    "        corr_features = df_features.loc[df_features[f'Fold{fold}']==0, 'Feat'].tolist()\n",
    "        # corr_features = clas_util.correlation_analysis(X_train, metric_imp)\n",
    "\n",
    "        features = [f for f in features if f not in corr_features]\n",
    "        # # Remove highly correlated features from the training set\n",
    "        X_train = X_train[features]\n",
    "\n",
    "        # Conduct redundancy analysis\n",
    "        # if fold == 0 and len(features) > 1:\n",
    "        redundant_features = clas_util.redundancy_analysis(X_train)\n",
    "            # features = [f for f in features if f not in corr_features]\n",
    "\n",
    "        # Remove indepandent variables explained by others\n",
    "        if len(redundant_features) != 0:\n",
    "            X_train = X_train.drop(columns=redundant_features)\n",
    "\n",
    "        # Instantiate the UnderSampler class then fit it on the each fold training dataset\n",
    "        ros = RandomUnderSampler(random_state=0)\n",
    "\n",
    "        # Perform under-sampling of the majority class(es)\n",
    "        X_train, y_train = ros.fit_resample(X_train, y_train)\n",
    "    \n",
    "        # Train the Random Forest Classifier on the training fold set \n",
    "        forest_clf.fit(X_train, y_train)\n",
    "\n",
    "        # Filter training set\n",
    "        X_test = X.iloc[test_idx]\n",
    "        X_test = X_test[X_train.columns.tolist()]\n",
    "        y_test = y.iloc[test_idx]\n",
    "\n",
    "        # Test the Random Forest Classifier on the test fold set \n",
    "        y_pred = forest_clf.predict(X_test)\n",
    "\n",
    "        precision = precision_score(y_test, y_pred)\n",
    "        recall = recall_score(y_test, y_pred)\n",
    "        auc = roc_auc_score(y_test, y_pred)\n",
    "        brier = brier_score_loss(y_test, y_pred)\n",
    "\n",
    "        precision_scores.append(precision)\n",
    "        recall_scores.append(recall)\n",
    "        auc_scores.append(auc)\n",
    "        brier_scores.append(brier)\n",
    "\n",
    "        # feature_importances.app\n",
    "\n",
    "        print(f\"Dimension: {label}, Fold: {fold+1}, Precision: {precision}, Recall: {recall}, AUC: {auc}, Brier: {brier}\")\n",
    "\n",
    "        kept_feat = X_train.columns.tolist()\n",
    "\n",
    "    prec_avg = np.average(precision_scores)\n",
    "    recall_avg = np.average(recall_scores)\n",
    "    auc_avg = np.average(auc_scores)\n",
    "    brier_avg = np.average(brier_scores)\n",
    "\n",
    "    print(f\"{label}, Precision: {prec_avg}, Recall: {recall_avg}, AUC: {auc_avg}\")\n",
    "    dimension_results[label] += [{\n",
    "        'Dimension': label,\n",
    "        'Precision': prec_avg,\n",
    "        'Recall': recall_avg,\n",
    "        'AUC': auc_avg,\n",
    "        'Brier': brier_avg\n",
    "    }]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_imp = pd.DataFrame([item[0] for item in list(dimension_results.values())])\n",
    "dim_imp.to_csv(osp.join('.', 'Results', 'Feature_importance', f'first_model_{dimension_type}_dim.csv'), index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dimension</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Brier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Change</td>\n",
       "      <td>0.184608</td>\n",
       "      <td>0.931897</td>\n",
       "      <td>0.819432</td>\n",
       "      <td>0.276269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Text</td>\n",
       "      <td>0.171462</td>\n",
       "      <td>0.941881</td>\n",
       "      <td>0.811367</td>\n",
       "      <td>0.299549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Developer</td>\n",
       "      <td>0.104390</td>\n",
       "      <td>0.860847</td>\n",
       "      <td>0.646060</td>\n",
       "      <td>0.541653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Project</td>\n",
       "      <td>0.176986</td>\n",
       "      <td>0.955364</td>\n",
       "      <td>0.817475</td>\n",
       "      <td>0.299555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>File</td>\n",
       "      <td>0.180999</td>\n",
       "      <td>0.946864</td>\n",
       "      <td>0.821739</td>\n",
       "      <td>0.284503</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Dimension  Precision    Recall       AUC     Brier\n",
       "0     Change   0.184608  0.931897  0.819432  0.276269\n",
       "1       Text   0.171462  0.941881  0.811367  0.299549\n",
       "2  Developer   0.104390  0.860847  0.646060  0.541653\n",
       "3    Project   0.176986  0.955364  0.817475  0.299555\n",
       "4       File   0.180999  0.946864  0.821739  0.284503"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def round_number(nbr):\n",
    "    return round(100 * nbr, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_model_keep_dim = pd.read_csv(osp.join(\".\", \"Results\", \"Feature_importance\", \"first_model_keep_dim.csv\"))\n",
    "first_model_discard_dim = pd.read_csv(osp.join(\".\", \"Results\", \"Feature_importance\", \"first_model_discard_dim.csv\"))\n",
    "second_model_keep_dim = pd.read_csv(osp.join(\".\", \"Results\", \"Feature_importance\", \"second_model_keep_dim.csv\"))\n",
    "second_model_discard_dim = pd.read_csv(osp.join(\".\", \"Results\", \"Feature_importance\", \"second_model_discard_dim.csv\"))\n",
    "\n",
    "first_model_perf = pd.read_csv(osp.join(\".\", \"Results\", \"first_model_perf.csv\"))\n",
    "second_model_perf = pd.read_csv(osp.join(\".\", \"Results\", \"second_model_perf.csv\")).sort_values(by='AUC', ascending=False)\n",
    "first_model_auc = round_number(first_model_perf['AUC'].values[0])\n",
    "second_model_auc = round_number(second_model_perf['AUC'].values[0])\n",
    "only_pair_auc = round_number(second_model_keep_dim.loc[second_model_keep_dim['Dimension']==\"Pairs\", 'AUC'].values[0])\n",
    "without_pair_auc = round_number(second_model_discard_dim.loc[second_model_discard_dim['Dimension']==\"Pairs\", 'AUC'].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\multirow{2}{*}{\\textbf{Change}} & Only & 56.32\\% & 62.58\\% \\\\\n",
      "& Without & 81.94\\% &83.1\\%\\\\\n",
      "\\noalign{\\smallskip}\n",
      "\\hhline{~----}\n",
      "\\noalign{\\smallskip}\n",
      "\\multirow{2}{*}{\\textbf{Text}} & Only & 57.27\\% & 58.7\\% \\\\\n",
      "& Without & 81.14\\% &82.53\\%\\\\\n",
      "\\noalign{\\smallskip}\n",
      "\\hhline{~----}\n",
      "\\noalign{\\smallskip}\n",
      "\\multirow{2}{*}{\\textbf{Developer}} & Only & 79.5\\% & 79.8\\% \\\\\n",
      "& Without & 64.61\\% &80.9\\%\\\\\n",
      "\\noalign{\\smallskip}\n",
      "\\hhline{~----}\n",
      "\\noalign{\\smallskip}\n",
      "\\multirow{2}{*}{\\textbf{Project}} & Only & 54.35\\% & 61.68\\% \\\\\n",
      "& Without & 81.75\\% &83.64\\%\\\\\n",
      "\\noalign{\\smallskip}\n",
      "\\hhline{~----}\n",
      "\\noalign{\\smallskip}\n",
      "\\multirow{2}{*}{\\textbf{File}} & Only & 54.43\\% & 52.6\\% \\\\\n",
      "& Without & 82.17\\% &83.1\\%\\\\\n",
      "\\noalign{\\smallskip}\n",
      "\\hhline{~----}\n",
      "\\noalign{\\smallskip}\n",
      "\\multirow{2}{*}{\\textbf{Pair}} & Only & N/A &76.4\\%\\\\\n",
      "\\noalign{\\smallskip}\n",
      "& Without & N/A & 77.11\\%\\\\\n",
      "\\noalign{\\smallskip}\n",
      "\\hline\n",
      "\\noalign{\\smallskip}\n",
      "\\textbf{All} & All & 82.86\\% & 84.49\\%\\\\\n",
      "\\noalign{\\smallskip}\n"
     ]
    }
   ],
   "source": [
    "for idx, row in first_model_keep_dim.iterrows():\n",
    "    auc_m2_keep = round_number(second_model_keep_dim.loc[second_model_keep_dim['Dimension']==row['Dimension'], \"AUC\"].values[0])\n",
    "    auc_m1_discard = round_number(first_model_discard_dim.loc[first_model_discard_dim['Dimension']==row['Dimension'], \"AUC\"].values[0])\n",
    "    auc_m2_discard = round_number(second_model_discard_dim.loc[second_model_discard_dim['Dimension']==row['Dimension'], \"AUC\"].values[0])\n",
    "    print(\"\\\\multirow{2}{*}{\\\\textbf{\"+row['Dimension']+\"}} & Only & \"+str(round_number(row['AUC']))+\"\\\\% & \"+str(auc_m2_keep)+\"\\\\% \\\\\" + \"\\\\\")\n",
    "    print(\"& Without & \"+str(auc_m1_discard)+\"\\% &\"+ str(auc_m2_discard)+\"\\%\\\\\"+ \"\\\\\")\n",
    "    print(\"\\\\noalign{\\smallskip}\")\n",
    "    print(\"\\hhline{~----}\")\n",
    "    print(\"\\\\noalign{\\smallskip}\")\n",
    "print(\"\\\\multirow{2}{*}{\\\\textbf{Pair}} & Only & N/A &\"+ str(only_pair_auc)+\"\\\\%\\\\\\\\\")\n",
    "print(\"\\\\noalign{\\smallskip}\")\n",
    "print(\"& Without & N/A & \"+str(without_pair_auc)+\"\\\\%\\\\\\\\\")\n",
    "print(\"\\\\noalign{\\smallskip}\")\n",
    "print(\"\\\\hline\")\n",
    "print(\"\\\\noalign{\\smallskip}\")\n",
    "print(\"\\\\textbf{All} & All & \"+str(first_model_auc)+\"\\\\% & \"+str(second_model_auc)+\"\\\\%\\\\\\\\\")\n",
    "print(\"\\\\noalign{\\smallskip}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feat_impact = df_feat_impact[df_feat_impact['impact'].notnull()]\n",
    "df_feat_impact = df_feat_impact.reset_index(drop=True)\n",
    "# df_feat_impact.to_csv(osp.join('.', 'Results', 'Impact', 'first_model_feat_impact.csv'), index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feat_impact_2 = pd.read_csv(osp.join('.', 'Results', 'Impact', 'first_model_feat_impact.csv'))\n",
    "# df_feat_impact = df_feat_impact[df_feat_impact['impact'].notnull()]\n",
    "# attr = \"insertions\"\n",
    "# test = df_feat_impact.loc[(df_feat_impact[attr].duplicated()==False)&(df_feat_impact['fold']!=0), [attr, \"fold\", \"impact\"]].sort_values(\"impact\")\n",
    "# test = test[test['impact'].notnull()==True].iloc[:-1, -1]\n",
    "# test = f\" & {round(test.min(), 2)} & {round(test.median(), 2)} & {round(test.max(), 2)}\"\n",
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a DataFrame from the new set of data\n",
    "data = {\n",
    "    'Feature': [\n",
    "        'ratio_dep_chan_owner', 'project_changes_owner', 'pctg_cross_project_changes',\n",
    "        'description_length', 'whole_within_project_changes', 'project_age',\n",
    "        'projects_contributed_owner', 'pctg_cross_project_changes_owner', 'subject_length',\n",
    "        'cross_project_changes_owner', 'num_file_changes', 'insertions',\n",
    "        'last_mth_dep_proj_nbr', 'deletions', 'max_num_mod_file_dep_cha',\n",
    "        'num_directory_files', 'cross_project_changes', 'whole_changes_owner',\n",
    "        'num_file_types', 'has_feature_addition', 'is_corrective',\n",
    "        'avg_num_dev_modified_files', 'is_refactoring', 'min_num_mod_file_dep_cha',\n",
    "        'is_preventive', 'is_non_functional', 'num_dev_modified_files',\n",
    "        'is_merge'\n",
    "    ],\n",
    "    'Ranking': [\n",
    "        1, 2, 2, 3, 4, 5, 6, 6, 7, 7, 7, 8, 9, 9, 9, 10, 11, 11, 12, 13, 14, 14, 15, 16, 16, 17, 17, 18\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Creating the dataframe\n",
    "df_most_impo_feat = pd.DataFrame(data)\n",
    "classifiers = df_feat_impact['Classifier'].unique().tolist()\n",
    "df_most_impo_feat['Classifier'] = [classifiers for _ in range(len(df_most_impo_feat))]\n",
    "df_most_impo_feat = df_most_impo_feat.explode(\"Classifier\")\n",
    "df_most_impo_feat.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_impact_to_fold(row):\n",
    "    # print(row)\n",
    "    for i in range(10):\n",
    "        row[f'fold{i}'] = df_feat_impact.loc[(df_feat_impact['Classifier']==row['Classifier'])&(df_feat_impact['fold']==i), [row['Feature'],  'fold', 'impact']].sort_values(by=row['Feature']).iloc[-1, -1]\n",
    "    # print(row)\n",
    "    return row\n",
    "\n",
    "def retrieve_impact(row, func):\n",
    "    df_sub = [row[f'fold{i}'] for i in range(10)]\n",
    "    return func(df_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_most_impo_feat = df_most_impo_feat.apply(map_impact_to_fold, axis=1)\n",
    "df_most_impo_feat['mean'] = df_most_impo_feat.apply(retrieve_impact, args=(np.mean,), axis=1) \n",
    "# df_most_impo_feat['median'] = df_most_impo_feat.apply(retrieve_impact, args=(np.median,), axis=1) \n",
    "# df_most_impo_feat['max'] = df_most_impo_feat.apply(retrieve_impact, args=(max,), axis=1) \n",
    "# df_most_impo_feat['max'] = df_most_impo_feat.apply(retrieve_impact, args=(max,), axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_most_impo_feat.to_csv(osp.join('.', 'Results', 'first_feat_impact_import.csv'), index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, row in df_most_impo_feat[:10].iterrows():\n",
    "    print(row[\"Feature\"].replace(\"_\", \"\\\\_\")+\" & \"+str(row['Ranking'])+\" & \"+str(round(row['min'], 2))+\" & \"+str(round(row['median'], 2))+\" & \"+str(round(row['max'], 2))+\" \\\\\\\\\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
