{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "from datetime import timedelta\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import  precision_score, recall_score, roc_auc_score, brier_score_loss\n",
    "from sklearn.base import clone\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# %matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from alibi.explainers import ALE, plot_ale\n",
    "\n",
    "from utils import helpers as hpr\n",
    "from utils import constants\n",
    "import utils.classifier_util as clas_util\n",
    "\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram\n",
    "from scipy.spatial.distance import squareform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = constants.get_metrics()\n",
    "# metric_imp = pd.read_csv(osp.join('.', 'Files', 'third_metric_importances.csv'))\n",
    "# metric_imp = metric_imp.set_index('m')['imp'].to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependent changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dependent_changes = pd.read_csv(osp.join('.', 'Files', 'all_dependencies.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dependent_changes = set(hpr.flatten_list(df_dependent_changes[['Source', 'Target']].values))\n",
    "# cross_pro_changes = set(hpr.flatten_list(df_dependent_changes.loc[df_dependent_changes['is_cross']==True, ['Source', 'Target']].values))\n",
    "# within_pro_changes = dependent_changes.difference(cross_pro_changes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading OpenStack changes...\n",
      "OpenStack changes loaded successfully...\n"
     ]
    }
   ],
   "source": [
    "df_changes = hpr.combine_openstack_data()\n",
    "df_changes['changed_files'] = df_changes['changed_files'].map(hpr.combine_changed_file_names)\n",
    "df_changes['commit_message'] = df_changes['commit_message'].map(hpr.preprocess_change_description)\n",
    "# df_changes = df_changes[df_changes['number'].isin(dependent_changes)]\n",
    "# all_change_ids = df_changes['number'].unique()\n",
    "# df_changes['reviewers'] = df_changes['reviewers'].map(ast.literal_eval)\n",
    "# df_changes['reviewers'] = df_changes['reviewers'].map(lambda x: [rev['_account_id'] for rev in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_date = datetime(2014, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_changes = df_changes[(df_changes['status']!='NEW')&(df_changes['created']>=min_date)]\n",
    "df_changes = df_changes.drop_duplicates(subset=['change_id'], keep='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "changed_files = dict(zip(df_changes['number'], df_changes['changed_files']))\n",
    "changes_description = dict(zip(df_changes['number'], df_changes['commit_message']))\n",
    "added_lines = dict(zip(df_changes['number'], df_changes['added_lines']))\n",
    "deleted_lines = dict(zip(df_changes['number'], df_changes['deleted_lines']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import pairs of changes with depends-on and needed-by tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dependencies = pd.read_csv(osp.join(\".\", \"Files\", \"Preliminary\", \"deps_ident.csv\"))\n",
    "df_dependencies = df_dependencies.loc[(df_dependencies['Source_status']!='NEW')&(df_dependencies['Target_status']!='NEW')]\n",
    "df_dependencies['related'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_deps_red = df_dependencies[['when_identified']]\n",
    "\n",
    "# Calculate Z-scores\n",
    "z_scores = np.abs((df_deps_red - df_deps_red.mean()) / df_deps_red.std())\n",
    "\n",
    "# Set a threshold for identifying outliers\n",
    "threshold = 3\n",
    "\n",
    "# Filter out the outliers\n",
    "df_clean = df_deps_red[(z_scores < threshold).all(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dependencies = df_dependencies[df_dependencies.index.isin(df_clean.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_changes[df_changes['status']==\"MERGED\"]\n",
    "df_dependencies[(df_dependencies['Source_status']==\"MERGED\")&(df_dependencies['Target_status']==\"MERGED\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_pctg_cross_project_changes(row):\n",
    "    dominator = row['cross_project_changes'] + row['within_project_changes']\n",
    "    if dominator == 0:\n",
    "        return 0\n",
    "    return row['cross_project_changes'] / dominator\n",
    "\n",
    "def compute_pctg_whole_cross_project_changes(row):\n",
    "    dominator = row['whole_cross_project_changes'] + row['whole_within_project_changes']\n",
    "    if dominator == 0:\n",
    "        return 0\n",
    "    return row['whole_cross_project_changes'] / dominator\n",
    "\n",
    "def compute_ptg_cross_project_changes_owner(row):\n",
    "    dominator = row['cross_project_changes_owner'] + row['within_project_changes_owner']\n",
    "    if dominator == 0:\n",
    "        return 0\n",
    "    return row['cross_project_changes_owner'] / dominator\n",
    "\n",
    "def combine_features():\n",
    "    metric_path = osp.join('.', 'Files', 'Metrics')\n",
    "    metric_list = hpr.list_file(metric_path)\n",
    "    df = pd.read_csv(f'{metric_path}/{metric_list[0]}')\n",
    "    for metric_file in metric_list[1:]:\n",
    "        df_metric = pd.read_csv(f'{metric_path}/{metric_file}') \n",
    "        # Join source and target changes with features of changes\n",
    "        df = pd.merge(\n",
    "            left=df, \n",
    "            right=df_metric, \n",
    "            left_on='number', \n",
    "            right_on='number', \n",
    "            how='inner',\n",
    "            suffixes=('_target', '_source')\n",
    "        )\n",
    "\n",
    "    df['project_age'] /= (60 * 60 * 24)\n",
    "\n",
    "    df['pctg_cross_project_changes'] = df.apply(compute_pctg_cross_project_changes, axis=1)\n",
    "    # df['pctg_whole_cross_project_changes'] = df.apply(compute_pctg_whole_cross_project_changes, axis=1)\n",
    "    df['ptg_cross_project_changes_owner'] = df.apply(compute_ptg_cross_project_changes_owner, axis=1)\n",
    "\n",
    "    df.drop(columns=['num_build_failures'], inplace=None)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def is_cross_project(number):\n",
    "    if number in cross_pro_changes:\n",
    "        return 1\n",
    "    elif number in within_pro_changes:\n",
    "        return 0\n",
    "    else:\n",
    "        return 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = clas_util.combine_features()\n",
    "df = df.drop(columns=['num_build_failures'])\n",
    "# df = pd.merge(\n",
    "#     left=df, \n",
    "#     right=df_changes[['number', 'created', 'project', 'owner_account_id']], \n",
    "#     left_on='number', \n",
    "#     right_on='number', \n",
    "#     how='inner',\n",
    "#     suffixes=('_source', '_target')\n",
    "# )\n",
    "# df['is_dependent'] = df['number'].map(lambda nbr: 1 if nbr in dependent_changes else 0)\n",
    "# df['is_cross'] = df['number'].map(is_cross_project)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build dataset for the 3rd model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_past_changes(row, sampling=True):\n",
    "    days_offset = row['created'] - timedelta(days=38.06)\n",
    "    source_changes = df_changes.loc[\n",
    "        (df_changes['status'] == 'MERGED') &\n",
    "        (df_changes['created'] < row['created']) &\n",
    "        (df_changes['created'] >= days_offset),\n",
    "        ['number']\n",
    "    ]\n",
    "    if (len(source_changes) > 0) and (sampling == True):\n",
    "        source_changes = source_changes.sample(n=30, replace=True, random_state=42)\n",
    "\n",
    "    source_changes = source_changes['number'].tolist()\n",
    "\n",
    "    # if len(source_changes) >= 60:\n",
    "    #     source_changes = random.sample(source_changes, 60)\n",
    "    \n",
    "    source_changes += df_dependencies.loc[\n",
    "        (df_dependencies['Target']==row['Target']), \n",
    "        'Source'].tolist()\n",
    "    return set(source_changes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_common_dev_pctg(row):\n",
    "    dev_source = df.loc[\n",
    "        (df['project'] == row['project_source']) &\n",
    "        (df['created'] < row['created_target']),\n",
    "        'owner_account_id'\n",
    "    ].unique()\n",
    "    dev_target = df.loc[\n",
    "        (df['project'] == row['project_target']) &\n",
    "        (df['created'] < row['created_target']),\n",
    "        'owner_account_id'\n",
    "    ].unique()\n",
    "\n",
    "    union = len(set(dev_source).union(dev_target))\n",
    "    intersect = len(set(dev_source).intersection(dev_target))\n",
    "    return intersect/union if union != 0 else 0\n",
    "\n",
    "def count_dev_in_src_change(row):\n",
    "    changes_nbr = df.loc[\n",
    "        (df['project'] == row['project_source']) &\n",
    "        (df['created'] < row['created_target']) &\n",
    "        (df['owner_account_id'] == row['owner_account_id_target']),\n",
    "        'number'\n",
    "    ].nunique()\n",
    "\n",
    "    return changes_nbr\n",
    "\n",
    "def count_rev_in_src_change(row):\n",
    "    account_id = row['owner_account_id_target']\n",
    "    reviewers = df.loc[\n",
    "        (df['project'] == row['project_source']) &\n",
    "        (df['created'] < row['created_target']) & \n",
    "        (df['owner_account_id'] != account_id), 'reviewers'].values\n",
    "    rev_exists = [account_id in reviewers_list for reviewers_list in reviewers]\n",
    "    return sum(rev_exists)\n",
    "\n",
    "def count_src_trgt_co_changed(row):\n",
    "    return len(df_dependent_changes[\n",
    "        (df_dependent_changes['project_source'] == row['project_source']) &\n",
    "        (df_dependent_changes['project_target'] == row['project_target']) &\n",
    "        (df_dependent_changes['created_target'] < row['created_target'])\n",
    "    ])\n",
    "\n",
    "def get_features_labels():\n",
    "    X = pd.DataFrame({})\n",
    "    X_path = osp.join('.', 'Files', 'Data', 'Model3')\n",
    "    for f in hpr.list_file(X_path):\n",
    "        X_item = pd.read_csv(f'{X_path}/{f}')\n",
    "        X = pd.concat((X, X_item))\n",
    "    X.sort_values(by=['Target', 'Source'], inplace=True)\n",
    "    \n",
    "    y = X['related']\n",
    "\n",
    "    # X.drop(columns=['Source', 'Target', 'project', 'owner_account_id', 'number_target', 'number_source', 'number', 'created_target', 'created_source', 'related'], inplace=True)\n",
    "    X.drop(columns=['Source', 'Target', 'related'], inplace=True)\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_features(X, fold):\n",
    "    print(f'******** Started assigning pairs of changes for Fold {fold}')\n",
    "    X = pd.merge(\n",
    "        left=X, \n",
    "        right=df, \n",
    "        left_on='Source', \n",
    "        right_on='number', \n",
    "        how='inner',\n",
    "        suffixes=('_target', '_source')\n",
    "    )\n",
    "    X = pd.merge(\n",
    "        left=X, \n",
    "        right=df, \n",
    "        left_on='Target', \n",
    "        right_on='number', \n",
    "        how='inner',\n",
    "        suffixes=('_target', '_source')\n",
    "    )\n",
    "    # y = X['related'].values\n",
    "    # X.drop(columns=['related', 'number_source', 'number_target'], axis=1, inplace=True)\n",
    "    X.drop(columns=['number_source', 'number_target'], inplace=True)\n",
    "\n",
    "    # if X.empty == False:\n",
    "    #     X.to_csv(osp.join('.', 'Files', 'Data', 'Pairs', f'{target}.csv'), index=None)\n",
    "\n",
    "    return X\n",
    "\n",
    "    \n",
    "def assign_pair_features(X):\n",
    "    # print(f'******** Assigning pairs\\'s features')\n",
    "    X = pd.merge(\n",
    "        left=X, \n",
    "        right=df[['number', 'owner_account_id', 'project']], \n",
    "        left_on='Source', \n",
    "        right_on='number', \n",
    "        how='left',\n",
    "        suffixes=('_target', '_source')\n",
    "    )\n",
    "\n",
    "    X.drop(columns=['owner_account_id_source', 'project_source', 'owner_account_id_target', 'project_target'], axis=1, inplace=True)\n",
    "\n",
    "    # print(f'******** Pairs\\'s features were assigned successfully...')\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******** Started assigning pairs of changes for Fold 6.csv\n",
      "./Files/Data/Test/6.csv processed successfully...\n",
      "******** Started assigning pairs of changes for Fold 7.csv\n",
      "./Files/Data/Test/7.csv processed successfully...\n",
      "******** Started assigning pairs of changes for Fold 5.csv\n",
      "./Files/Data/Test/5.csv processed successfully...\n",
      "******** Started assigning pairs of changes for Fold 4.csv\n",
      "./Files/Data/Test/4.csv processed successfully...\n",
      "******** Started assigning pairs of changes for Fold 0.csv\n",
      "./Files/Data/Test/0.csv processed successfully...\n",
      "******** Started assigning pairs of changes for Fold 1.csv\n",
      "./Files/Data/Test/1.csv processed successfully...\n",
      "******** Started assigning pairs of changes for Fold 3.csv\n",
      "./Files/Data/Test/3.csv processed successfully...\n",
      "******** Started assigning pairs of changes for Fold 2.csv\n",
      "./Files/Data/Test/2.csv processed successfully...\n",
      "******** Started assigning pairs of changes for Fold 9.csv\n",
      "./Files/Data/Test/9.csv processed successfully...\n",
      "******** Started assigning pairs of changes for Fold 8.csv\n",
      "./Files/Data/Test/8.csv processed successfully...\n"
     ]
    }
   ],
   "source": [
    "test_path = osp.join('.', 'Files', 'Data', 'Test')\n",
    "test_files = hpr.list_file(test_path)\n",
    "\n",
    "for fn in test_files:\n",
    "    file_path = f'{test_path}/{fn}'\n",
    "    # print(f'Processing {file_path}')\n",
    "    df_test = pd.read_csv(file_path)\n",
    "    df_test = df_test[['Source', 'Target', 'related']+constants.PAIR_METRICS]\n",
    "    df_test = assign_features(df_test, fn)\n",
    "    df_test.to_csv(file_path, index=None)\n",
    "    print(f'{file_path} processed successfully...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = osp.join('.', 'Files', 'Data', 'Pipeline')\n",
    "test_files = hpr.list_file(test_path)\n",
    "\n",
    "for fn in test_files:\n",
    "    file_path = f'{test_path}/{fn}'\n",
    "    print(f'Processing {file_path}')\n",
    "    df_test = pd.read_csv(file_path)\n",
    "    df_test['num_shrd_file_tkns'] = df_test[['Source', 'Target']].apply(clas_util.compute_filenames_shared_tokens, args=(changed_files,), axis=1)\n",
    "    df_test['num_shrd_desc_tkns'] = df_test[['Source', 'Target']].apply(clas_util.compute_shared_desc_tokens, args=(changes_description,), axis=1)\n",
    "    df_test['related'] = df_test['related'].fillna(False)\n",
    "    df_test.to_csv(file_path, index=None)\n",
    "    print(f'{file_path} processed successfully...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_classifiers = clas_util.load_classifiers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features = pd.read_csv(osp.join(\".\", \"Results\", \"Correlation\", \"second_model.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_remai_feat = X_train.columns.tolist()\n",
    "df_remai_feat = [f for f in df_remai_feat if f not in df_features['Feat'].tolist()]\n",
    "df_remai_feat = [{\"Feat\": f}|{f\"Fold{i}\": 1 for i in range(10)} for f in df_remai_feat]\n",
    "df_remai_feat = pd.DataFrame(df_remai_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training with ET classifier...\n",
      "ET, Fold: 10, Precision: 0.00729877677907684, Recall: 0.7346938775510204, AUC: 0.7002898011174263, Brier: 0.3338849720024484\n",
      "ET, Precision: 0.00729877677907684, Recall: 0.7346938775510204, AUC: 0.7002898011174263, Brier: 0.3338849720024484\n",
      "Start training with RF classifier...\n",
      "RF, Fold: 10, Precision: 0.01635124905374716, Recall: 0.7346938775510204, AUC: 0.7934569378656748, Brier: 0.14817165786311803\n",
      "RF, Precision: 0.01635124905374716, Recall: 0.7346938775510204, AUC: 0.7934569378656748, Brier: 0.14817165786311803\n",
      "Start training with XGBoost classifier...\n",
      "XGBoost, Fold: 10, Precision: 0.018187025633681797, Recall: 0.8639455782312925, AUC: 0.8539999022081765, Brier: 0.1558794858425336\n",
      "XGBoost, Precision: 0.018187025633681797, Recall: 0.8639455782312925, AUC: 0.8539999022081765, Brier: 0.1558794858425336\n",
      "Start training with AdaBoost classifier...\n",
      "AdaBoost, Fold: 10, Precision: 0.009922534598311428, Recall: 0.7755102040816326, AUC: 0.7583878925057421, Brier: 0.25862029879168463\n",
      "AdaBoost, Precision: 0.009922534598311428, Recall: 0.7755102040816326, AUC: 0.7583878925057421, Brier: 0.25862029879168463\n",
      "Start training with MLP classifier...\n",
      "MLP, Fold: 10, Precision: 0.015710503089143867, Recall: 0.6054421768707483, AUC: 0.7393055666448183, Brier: 0.1277232436353744\n",
      "MLP, Precision: 0.015710503089143867, Recall: 0.6054421768707483, AUC: 0.7393055666448183, Brier: 0.1277232436353744\n"
     ]
    }
   ],
   "source": [
    "training_results = {key: None for key in ensemble_classifiers.keys()}\n",
    "tscv = TimeSeriesSplit(n_splits = 10)\n",
    "clf_path = osp.join('.', 'Results')\n",
    "\n",
    "# df_feat_impo = pd.DataFrame()\n",
    "# df_feat_impact = pd.DataFrame()\n",
    "\n",
    "if not os.path.exists(clf_path):\n",
    "    os.makedirs(clf_path)\n",
    "    \n",
    "for label, ens_clf in ensemble_classifiers.items():\n",
    "    print(f'Start training with {label} classifier...')\n",
    "\n",
    "    # if label != 'RF':\n",
    "    #     continue\n",
    "\n",
    "    auc_scores = []\n",
    "    precision_scores = []\n",
    "    recall_scores = []\n",
    "    brier_scores = []\n",
    "    feature_importances = []\n",
    "    features = []\n",
    "    corr_features = []\n",
    "    redundant_features = []\n",
    "\n",
    "\n",
    "    for fold in range(0, 10):\n",
    "\n",
    "        if fold not in [9]:\n",
    "            continue\n",
    "\n",
    "        clone_clf = clone(ens_clf)\n",
    "        \n",
    "        # Split training data into features and labels\n",
    "        X_train = pd.read_csv(osp.join(\".\", \"Files\", \"Data\", \"Train\", f\"{fold}.csv\"))\n",
    "        y_train = X_train['related']\n",
    "        # X_train = X_train.drop(columns=[\"related\"])\n",
    "        # pd.DataFrame({'col': X_train.columns.tolist()}).to_csv(\"test.csv\", index=None)\n",
    "        # df_test = pd.concat((df_test, X_train.iloc[:1]))\n",
    "        # desc_model = clas_util.doc2vec_model(df_changes, X_train[['Source', 'Target']].values, fold)\n",
    "        # subject_model = clas_util.doc2vec_model(df_changes, X_train[['Source', 'Target']].values, fold, \"subject\")\n",
    "        # add_lines_model = clas_util.doc2vec_model(df_changes, X_train[['Source', 'Target']].values, fold, 'added_lines')\n",
    "        # del_lines_model = clas_util.doc2vec_model(df_changes, X_train[['Source', 'Target']].values, fold, 'deleted_lines')\n",
    "\n",
    "        # X_train = clas_util.compute_embdedding_similarity(df_changes, desc_model, X_train, 'commit_message', 'desc')\n",
    "        # X_train = clas_util.compute_embdedding_similarity(df_changes, subject_model, X_train, 'subject', 'subject')\n",
    "        # X_train = clas_util.compute_embdedding_similarity(df_changes, add_lines_model, X_train, 'added_lines', 'add_lines')\n",
    "        # X_train = clas_util.compute_embdedding_similarity(df_changes, del_lines_model, X_train, 'deleted_lines', 'del_lines')\n",
    "\n",
    "        X_train = X_train.drop(columns=['Source', 'Target', 'related'])\n",
    "        # X_train.to_csv(osp.join(\".\", \"Files\", \"Data\", \"Train\", f\"{fold}.csv\"), index=None)\n",
    "\n",
    "        # corr_path = osp.join('.', 'Results', 'Correlation')\n",
    "        # if fold == 0:\n",
    "        #     df_features = pd.DataFrame({'Feat': X_train.columns.tolist()})\n",
    "        #     for f in range(0, 10):\n",
    "        #         df_features[f\"Fold{f}\"] = [1]*len(df_features)\n",
    "        #     df_features.to_csv(f\"{corr_path}/second_model.csv\", index=None)\n",
    "        \n",
    "\n",
    "        # conduct the correlation analysis\n",
    "        # if fold == 0:\n",
    "        \n",
    "\n",
    "       \n",
    "        # if not os.path.exists(corr_path):\n",
    "        #     os.makedirs(corr_path)\n",
    "            \n",
    "        # pd.DataFrame({'Features': corr_features}).to_csv(f'{corr_path}/{fold+1}.csv', index=None)\n",
    "        # plt.figure(figsize=(6,12))\n",
    "        # dissimilarity = 1 - abs(X_train.corr())\n",
    "        # Z = linkage(squareform(dissimilarity), 'complete')\n",
    "\n",
    "        # dendrogram(Z, labels=X_train.columns, orientation='left')\n",
    "\n",
    "        # threshold = 0.3 * max(Z[:, 2])  # Scale threshold based on the maximum distance in the dendrogram\n",
    "        # plt.axvline(x=threshold, color='r', linestyle='--')\n",
    "\n",
    "        # # # Adjust the layout to make sure labels fit\n",
    "        # plt.tight_layout()\n",
    "        # plt.savefig(f'{corr_path}/second_model/{fold}.pdf')\n",
    "\n",
    "        corr_features = df_features.loc[df_features[f'Fold{fold}']==0, 'Feat'].tolist()\n",
    "        # Remove highly correlated features from the training set\n",
    "        X_train = X_train.drop(columns=corr_features)\n",
    "\n",
    "        # Conduct redundancy analysis\n",
    "        redundant_features = clas_util.redundancy_analysis(X_train)\n",
    "\n",
    "        # Remove indepandent variables explained by others\n",
    "        X_train = X_train.drop(columns=redundant_features)\n",
    "\n",
    "        # if fold == 0:\n",
    "        #     break\n",
    "\n",
    "        # Instantiate the OverSampler class then fit it on the each fold training dataset\n",
    "        # features = X_train.columns.tolist()\n",
    "        # print(f'len(X_train) {len(X_train)}')\n",
    "\n",
    "        # Columns to exclude in the test set\n",
    "        # cols_exluded = corr_features + redundant_features \n",
    "\n",
    "        # Train the Random Forest Classifier on the training fold set \n",
    "        clone_clf.fit(X_train, y_train)\n",
    "\n",
    "        # rf_ale = ALE(clone_clf.predict, feature_names=X_train.columns.tolist())\n",
    "        # rf_exp = rf_ale.explain(X_train.to_numpy())\n",
    "        # plot_ale(rf_exp, features=ale_features, n_cols=4, fig_kw={'figwidth':14, 'figheight': 7})\n",
    "        # plt.tight_layout()\n",
    "        # plt.savefig(f'./Results/ALE/third_model/ale_{fold+1}_model.pdf', format='pdf')\n",
    "        # continue\n",
    "\n",
    "        X_test = pd.read_csv(osp.join(\".\", \"Files\", \"Data\", \"Test\", f\"{fold}.csv\"))\n",
    "        y_test = X_test['related']\n",
    "        # X_test = X_test.drop(columns=[\"related\"])\n",
    "        # X_test_pairs = X_test[['Source', 'Target', 'related']]\n",
    "\n",
    "        # X_test = clas_util.compute_embdedding_similarity(df_changes, desc_model, X_test, 'commit_message', 'desc')\n",
    "        # X_test = clas_util.compute_embdedding_similarity(df_changes, desc_model, X_test, 'subject', 'subject')\n",
    "        # X_test = clas_util.compute_embdedding_similarity(df_changes, add_lines_model, X_test, 'added_lines', 'add_lines')\n",
    "        # X_test = clas_util.compute_embdedding_similarity(df_changes, del_lines_model, X_test, 'deleted_lines', 'del_lines')\n",
    "        \n",
    "        # X_test = X_test.drop(columns=cols_dropped+corr_features+redundant_features)\n",
    "        # X_test = X_test.drop(columns=['Source', 'Target'])\n",
    "        X_test = X_test[X_train.columns.tolist()]\n",
    "        # X_test.to_csv(osp.join(\".\", \"Files\", \"Data\", \"Test\", f\"{fold}.csv\"), index=None)\n",
    "\n",
    "        # print(X_train.columns, )\n",
    "        # Test the Random Forest Classifier on the test fold set \n",
    "        y_pred = clone_clf.predict(X_test)\n",
    "\n",
    "        # y_pred_prob = clone_clf.predict_proba(X_test)[:, 1]\n",
    "        # X_test_pairs['pred'] = y_pred_prob\n",
    "        # compute_top_k_prec_recal(X_test_pairs, label, fold+1)\n",
    "\n",
    "        precision_scores.append(precision_score(y_test, y_pred))\n",
    "        recall_scores.append(recall_score(y_test, y_pred))\n",
    "        auc_scores.append(roc_auc_score(y_test, y_pred))\n",
    "        brier_scores.append(brier_score_loss(y_test, y_pred))\n",
    "\n",
    "        print(f\"{label}, Fold: {fold+1}, Precision: {precision_scores[-1]}, Recall: {recall_scores[-1]}, AUC: {auc_scores[-1]}, Brier: {brier_scores[-1]}\")\n",
    "\n",
    "        # logging.debug(msg=f\"{label}, Fold: {fold+1}, Precision: {precision_scores[-1]}, Recall: {recall_scores[-1]}, AUC: {auc_scores[-1]}\")\n",
    "        if label == 'XGBoost': \n",
    "            df_feat_imp_item = pd.DataFrame({name: [val] for name, val in zip(X_train.columns.to_list(), clone_clf.feature_importances_)})\n",
    "            df_feat_impo = pd.concat((df_feat_impo, df_feat_imp_item))\n",
    "\n",
    "        if label not in ['MLP']:\n",
    "\n",
    "            binary_cols = list(constants.DESCRIPTION_METRICS.keys())\n",
    "            binary_cols = hpr.flatten_list([[f'{c}_source', f'{c}_target'] for c in binary_cols])\n",
    "\n",
    "            # Step 1: Calculate the median of each column\n",
    "            medians = X_train.median()\n",
    "\n",
    "            # Step 2: Calculate the standard deviation of each column\n",
    "            std_devs = X_train.std()\n",
    "\n",
    "            # Step 3: Create a new dataframe starting with the median row\n",
    "            df_feat_impact_item = pd.DataFrame([medians])\n",
    "            for col in binary_cols:\n",
    "                if col in X_train.columns.tolist():\n",
    "                    df_feat_impact_item[col] = 0\n",
    "            df_feat_impact_item = pd.concat([df_feat_impact_item] * (len(X_train.columns.to_list()) + 1), ignore_index=True)\n",
    "\n",
    "\n",
    "            # Step 4: Double the number of rows according to the number of features and add standard deviation to each column\n",
    "            for idx, col in zip(range(1, len(df_feat_impact_item.columns)+1), df_feat_impact_item.columns):\n",
    "                # df_feat_impact_item.iloc[idx, idx-1] += std_devs[col]\n",
    "\n",
    "                if col in binary_cols:\n",
    "                    df_feat_impact_item.iloc[idx, idx-1] = 1\n",
    "                else:\n",
    "                    df_feat_impact_item.iloc[idx, idx-1] += std_devs[col]\n",
    "\n",
    "            df_feat_impact_item['pred'] = clone_clf.predict_proba(df_feat_impact_item)[:,1]\n",
    "            proba1 = df_feat_impact_item.iloc[0, -1]\n",
    "            df_feat_impact_item['impact'] = None\n",
    "\n",
    "            df_feat_impact_item.iloc[1:, -1] = 0 if proba1 == 0 else (df_feat_impact_item.iloc[1:, -2] - proba1) / proba1\n",
    "\n",
    "            df_feat_impact_item['fold'] = fold\n",
    "            df_feat_impact_item['Classifier'] = label\n",
    "\n",
    "            df_feat_impact = pd.concat((df_feat_impact, df_feat_impact_item))\n",
    "\n",
    "    # feature_importances /= (fold+1)\n",
    "    prec_avg = np.average(precision_scores)\n",
    "    recall_avg = np.average(recall_scores)\n",
    "    auc_avg = np.average(auc_scores)\n",
    "    brier_avg = np.average(brier_scores)\n",
    "\n",
    "    print(f\"{label}, Precision: {prec_avg}, Recall: {recall_avg}, AUC: {auc_avg}, Brier: {brier_avg}\")\n",
    "\n",
    "    training_results[label] = {\n",
    "        'Classifier': label,\n",
    "        'Precision': prec_avg,\n",
    "        'Recall': recall_avg,\n",
    "        'AUC': auc_avg,\n",
    "        'Brier': brier_avg,\n",
    "        'AUC Scores': auc_scores,\n",
    "        'Precision Scores': precision_scores,\n",
    "        'Recall Scores': recall_scores,\n",
    "        'Brier Scores': brier_scores\n",
    "    }\n",
    "    # training_results[label]['Precision Scores'] += precision_scores\n",
    "    # training_results[label]['AUC Scores'] += auc_scores\n",
    "    # training_results[label]['Recall Scores'] += recall_scores\n",
    "    # training_results[label]['Brier Scores'] += brier_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_results['RF']#['AUC Scores']\n",
    "for met in ['Precision', 'Recall', 'Brier', 'AUC']:\n",
    "    df_result[met] = df_result[f'{met} Scores'].map(np.mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result = pd.DataFrame(training_results.values())\n",
    "df_result.to_csv(osp.join('.', 'Results', 'second_model_perf.csv'), index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feat_impo.fillna(0, inplace=True)\n",
    "df_feat_impo.to_csv(osp.join('.', 'Results', 'Feature_importance', f'second_feat_impo.csv'), index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Impact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feat_impact = df_feat_impact.reset_index(drop=True)\n",
    "df_feat_impact = df_feat_impact[df_feat_impact['impact'].notnull()]\n",
    "df_feat_impact.to_csv(osp.join('.', 'Results', 'Impact', 'second_model_feat_impact.csv'), index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feat_impact = pd.read_csv(osp.join('.', 'Results', 'Impact', 'second_model_feat_impact.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a DataFrame from the additional data\n",
    "data = {\n",
    "    'Feature': [\n",
    "        'num_shrd_desc_tkns', 'num_shrd_file_tkns', 'desc_sim',\n",
    "        'subject_sim', 'description_length_source', 'whole_within_project_changes_source',\n",
    "        'description_length_target', 'projects_contributed_owner_target', 'projects_contributed_owner_source',\n",
    "        'project_age_target', 'ratio_dep_chan_owner_source', 'project_age_source',\n",
    "        'whole_changes_owner_source', 'whole_changes_owner_target', 'ratio_dep_chan_owner_target',\n",
    "        'num_file_changes_source', 'insertions_source', 'num_file_changes_target',\n",
    "        'insertions_target', 'pctg_cross_project_changes_source', 'add_lines_sim',\n",
    "        'pctg_cross_project_changes_target', 'last_mth_dep_proj_nbr_target', 'last_mth_cro_proj_nbr_target',\n",
    "        'last_mth_dep_proj_nbr_source', 'cross_project_changes_target', 'src_trgt_co_changed_nbr',\n",
    "        'pctg_inter_dep_cha', 'deletions_target', 'deletions_source',\n",
    "        'cross_project_changes_owner_source', 'project_changes_owner_target', 'dev_in_src_change_nbr',\n",
    "        'del_lines_sim', 'last_mth_cro_proj_nbr_source', 'cross_project_changes_source',\n",
    "        'rev_in_src_change_nbr', 'pctg_cross_project_changes_owner_source', 'is_preventive_source',\n",
    "        'pctg_cross_project_changes_owner_target', 'project_changes_owner_source', 'num_file_types_target',\n",
    "        'is_corrective_target', 'num_directory_files_target', 'num_file_types_source',\n",
    "        'has_feature_addition_source', 'is_preventive_target', 'is_corrective_source',\n",
    "        'is_refactoring_source', 'is_refactoring_target', 'has_feature_addition_target',\n",
    "        'num_directory_files_source', 'is_merge_source', 'is_non_functional_target',\n",
    "        'is_non_functional_source', 'is_merge_target'\n",
    "    ],\n",
    "    'Ranking': [\n",
    "        1, 2, 3, 4, 5, 6, 7, 8, 8, 9, 10, 10, 10, 10, 11, 11, 12, 13, 13, 14, 15, 15, 16, 16, 17, 17, 18, 18, 19, 19, 20, 21, 21, 22, 22, 23, 23, 24, 25, 25, 26, 26, 27, 27, 28, 29, 30, 30, 31, 31, 32, 33, 33, 34, 34, 35\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Creating the dataframe\n",
    "# Creating the dataframe\n",
    "df_most_impo_feat = pd.DataFrame(data)\n",
    "classifiers = df_feat_impact['Classifier'].unique().tolist()\n",
    "df_most_impo_feat['Classifier'] = [classifiers for _ in range(len(df_most_impo_feat))]\n",
    "df_most_impo_feat = df_most_impo_feat.explode(\"Classifier\")\n",
    "df_most_impo_feat.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_impact_to_fold(row):\n",
    "    # print(row)\n",
    "    for i in range(10):\n",
    "        row[f'fold{i}'] = df_feat_impact.loc[(df_feat_impact['Classifier']==row['Classifier'])&(df_feat_impact['fold']==i), [row['Feature'],  'fold', 'impact']].sort_values(by=row['Feature']).iloc[-1, -1]\n",
    "    return row\n",
    "\n",
    "def retrieve_impact(row, func):\n",
    "    df_sub = [row[f'fold{i}'] for i in range(10)]\n",
    "    return func(df_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_feat_impact.loc[(df_feat_impact['Classifier']=='ET')&(df_feat_impact['fold']==0), ['num_shrd_desc_tkns',  'fold', 'impact']].sort_values(by='num_shrd_desc_tkns').iloc[-1, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_most_impo_feat = df_most_impo_feat.apply(map_impact_to_fold, axis=1)\n",
    "# df_most_impo_feat['mean'] = df_most_impo_feat.apply(retrieve_impact, args=(np.mean,), axis=1) \n",
    "# df_most_impo_feat['median'] = df_most_impo_feat.apply(retrieve_impact, args=(np.median,), axis=1) \n",
    "# df_most_impo_feat['max'] = df_most_impo_feat.apply(retrieve_impact, args=(max,), axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num\\_shrd\\_desc\\_tkns & 1 & 2.06 & 2.5 & 3.48 \\\\\n",
      "num\\_shrd\\_file\\_tkns & 2 & 1.0 & 1.33 & 2.24 \\\\\n",
      "desc\\_sim & 3 & -0.1 & 0.0 & 0.15 \\\\\n",
      "subject\\_sim & 4 & -0.03 & 0.16 & 0.43 \\\\\n",
      "description\\_length\\_source & 5 & -0.07 & 0.16 & 0.42 \\\\\n",
      "whole\\_within\\_project\\_changes\\_source & 6 & -0.21 & -0.06 & 0.37 \\\\\n",
      "description\\_length\\_target & 7 & -0.17 & 0.15 & 0.33 \\\\\n",
      "projects\\_contributed\\_owner\\_target & 8 & -0.21 & -0.12 & 0.0 \\\\\n",
      "projects\\_contributed\\_owner\\_source & 8 & -0.33 & -0.12 & 0.08 \\\\\n",
      "project\\_age\\_target & 9 & -0.12 & -0.02 & 0.1 \\\\\n"
     ]
    }
   ],
   "source": [
    "for idx, row in df_most_impo_feat[:10].iterrows():\n",
    "    print(row[\"Feature\"].replace(\"_\", \"\\\\_\")+\" & \"+str(row[\"Ranking\"])+\" & \"+str(round(row['min'], 2))+\" & \"+str(round(row['median'], 2))+\" & \"+str(round(row['max'], 2))+\" \\\\\\\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_most_impo_feat.to_csv(osp.join('.', 'Results', 'second_feat_impact_import.csv'), index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimension importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "M1_METRICS = df.columns.tolist()\n",
    "CHANGE_METRICS = [col for col in constants.CHANGE_METRICS if col in M1_METRICS]\n",
    "TEXT_METRICS = [col for col in constants.TEXT_METRICS if col in M1_METRICS]\n",
    "DEVELOPER_METRICS = [col for col in constants.DEVELOPER_METRICS if col in M1_METRICS]\n",
    "PROJECT_METRICS = [col for col in constants.PROJECT_METRICS if col in M1_METRICS]\n",
    "FILE_METRICS = [col for col in constants.FILE_METRICS if col in M1_METRICS]\n",
    "CHANGE_METRICS = [f'{cm}_source' for cm in CHANGE_METRICS] + [f'{cm}_target' for cm in CHANGE_METRICS]\n",
    "TEXT_METRICS = [f'{cm}_source' for cm in TEXT_METRICS] + [f'{cm}_target' for cm in TEXT_METRICS]\n",
    "DEVELOPER_METRICS = [f'{cm}_source' for cm in DEVELOPER_METRICS] + [f'{cm}_target' for cm in DEVELOPER_METRICS]\n",
    "PROJECT_METRICS = [f'{cm}_source' for cm in PROJECT_METRICS] + [f'{cm}_target' for cm in PROJECT_METRICS]\n",
    "FILE_METRICS = [f'{cm}_source' for cm in FILE_METRICS] + [f'{cm}_target' for cm in FILE_METRICS]\n",
    "\n",
    "dimensions = {\n",
    "    'Change': CHANGE_METRICS,\n",
    "    'Text': TEXT_METRICS,\n",
    "    'Developer': DEVELOPER_METRICS,\n",
    "    'Project': PROJECT_METRICS,\n",
    "    'File': FILE_METRICS,\n",
    "    'Pairs': constants.PAIR_METRICS\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training with Change dimension...\n",
      "Change, Fold: 1, Precision: 0.009780246317314658, Recall: 0.6230769230769231, AUC: 0.7802770258224332, Brier: 0.06283416350591783\n",
      "Change, Fold: 2, Precision: 0.008028352379574714, Recall: 0.7872340425531915, AUC: 0.847103421602174, Brier: 0.09314160641318416\n",
      "Change, Fold: 3, Precision: 0.011615989067304407, Recall: 0.6538461538461539, AUC: 0.7964330013917226, Brier: 0.061292382844028326\n",
      "Change, Fold: 4, Precision: 0.010235870048954161, Recall: 0.7379679144385026, AUC: 0.8346911940613565, Brier: 0.06877127760633027\n",
      "Change, Fold: 5, Precision: 0.01065552808797204, Recall: 0.8223684210526315, AUC: 0.8790119896285096, Brier: 0.06443982827863177\n",
      "Change, Fold: 6, Precision: 0.007017133500964856, Recall: 0.7547169811320755, AUC: 0.8112238299438321, Brier: 0.13240911460156682\n",
      "Change, Fold: 7, Precision: 0.01100784986014617, Recall: 0.782051282051282, AUC: 0.8379847800613145, Brier: 0.10625036238186351\n",
      "Change, Fold: 8, Precision: 0.009901738473167044, Recall: 0.8562091503267973, AUC: 0.870650300853122, Brier: 0.11494726145004731\n",
      "Change, Fold: 9, Precision: 0.008902691511387164, Recall: 0.8431372549019608, AUC: 0.8169454196178997, Brier: 0.20912989750672384\n",
      "Change, Fold: 10, Precision: 0.02001696352841391, Recall: 0.8027210884353742, AUC: 0.8356590611861157, Brier: 0.13162249778966698\n",
      "Change, Precision: 0.01071623627751991, Recall: 0.7663329211814892, AUC: 0.830998002416848, Brier: 0.1044838392377961\n",
      "Start training with Text dimension...\n",
      "Text, Fold: 1, Precision: 0.011662260923651064, Recall: 0.5769230769230769, AUC: 0.7642330681029144, Brier: 0.048827857240780516\n",
      "Text, Fold: 2, Precision: 0.007203876067831187, Recall: 0.8014184397163121, AUC: 0.8478943246536523, Brier: 0.10571860324860576\n",
      "Text, Fold: 3, Precision: 0.011402280456091218, Recall: 0.7307692307692307, AUC: 0.830661270926509, Brier: 0.06966542907475383\n",
      "Text, Fold: 4, Precision: 0.011432229742088898, Recall: 0.6684491978609626, AUC: 0.8064465356081129, Brier: 0.05582114230257719\n",
      "Text, Fold: 5, Precision: 0.010621594162741294, Recall: 0.756578947368421, AUC: 0.8485954507428611, Brier: 0.05954299958454508\n",
      "Text, Fold: 6, Precision: 0.006466844590433176, Recall: 0.7924528301886793, AUC: 0.820834226158196, Brier: 0.15085459114212585\n",
      "Text, Fold: 7, Precision: 0.012314493211240922, Recall: 0.75, AUC: 0.8295903257650543, Brier: 0.09105931466341972\n",
      "Text, Fold: 8, Precision: 0.00886963696369637, Recall: 0.8431372549019608, AUC: 0.8583421701502216, Brier: 0.12649367487822827\n",
      "Text, Fold: 9, Precision: 0.009816045756685732, Recall: 0.8300653594771242, AUC: 0.8217015805428516, Brier: 0.18662499091371665\n",
      "Text, Fold: 10, Precision: 0.014718200311116428, Recall: 0.8367346938775511, AUC: 0.8247225466476282, Brier: 0.18720953957062864\n",
      "Text, Precision: 0.010450746218557629, Recall: 0.7586529031083319, AUC: 0.8253021499298001, Brier: 0.10818181426193815\n",
      "Start training with Developer dimension...\n",
      "Developer, Fold: 1, Precision: 0.009072580645161291, Recall: 0.5538461538461539, AUC: 0.746946253307561, Brier: 0.060336029490167406\n",
      "Developer, Fold: 2, Precision: 0.007102803738317757, Recall: 0.8085106382978723, AUC: 0.8502093312224626, Brier: 0.10817165974344553\n",
      "Developer, Fold: 3, Precision: 0.010580497569345154, Recall: 0.7115384615384616, AUC: 0.8193033955329758, Brier: 0.07316765042356525\n",
      "Developer, Fold: 4, Precision: 0.0091636551368095, Recall: 0.7593582887700535, AUC: 0.8402208795823951, Brier: 0.0790718213887762\n",
      "Developer, Fold: 5, Precision: 0.008599707934447509, Recall: 0.6973684210526315, AUC: 0.8148099610543881, Brier: 0.06794626782994045\n",
      "Developer, Fold: 6, Precision: 0.005563282336578581, Recall: 0.7295597484276729, AUC: 0.7840247839363832, Brier: 0.1616449226316895\n",
      "Developer, Fold: 7, Precision: 0.010265024262784622, Recall: 0.7051282051282052, AUC: 0.8012411054481783, Brier: 0.10293577627026923\n",
      "Developer, Fold: 8, Precision: 0.008428292090890702, Recall: 0.8169934640522876, AUC: 0.8439939029546932, Brier: 0.12907803903703963\n",
      "Developer, Fold: 9, Precision: 0.008715501141315626, Recall: 0.8235294117647058, AUC: 0.8073600549906406, Brier: 0.20873737006614815\n",
      "Developer, Fold: 10, Precision: 0.011359223300970873, Recall: 0.7959183673469388, AUC: 0.7821485204035212, Brier: 0.23152955045226814\n",
      "Developer, Precision: 0.008885056815662162, Recall: 0.7401751160224983, AUC: 0.8090258188433198, Brier: 0.12226190873333094\n",
      "Start training with Project dimension...\n",
      "Project, Fold: 1, Precision: 0.008652430044182622, Recall: 0.7230769230769231, AUC: 0.8204842409968661, Brier: 0.08230132979938765\n",
      "Project, Fold: 2, Precision: 0.008513743614692289, Recall: 0.7446808510638298, AUC: 0.830869897145562, Brier: 0.08310575926164354\n",
      "Project, Fold: 3, Precision: 0.010672451193058569, Recall: 0.7884615384615384, AUC: 0.8541745598508289, Brier: 0.08025631487707133\n",
      "Project, Fold: 4, Precision: 0.007401235173022253, Recall: 0.8074866310160428, AUC: 0.8517002439619688, Brier: 0.104171052699143\n",
      "Project, Fold: 5, Precision: 0.008028098344204716, Recall: 0.7368421052631579, AUC: 0.8300588809096472, Brier: 0.0768813183769561\n",
      "Project, Fold: 6, Precision: 0.009615384615384616, Recall: 0.7232704402515723, AUC: 0.8155033636350008, Brier: 0.09249188974724018\n",
      "Project, Fold: 7, Precision: 0.012780222082547664, Recall: 0.782051282051282, AUC: 0.8454224046669316, Brier: 0.09139753773603139\n",
      "Project, Fold: 8, Precision: 0.01170631204345383, Recall: 0.8169934640522876, AUC: 0.8622096141700974, Brier: 0.0926954480148579\n",
      "Project, Fold: 9, Precision: 0.017690728163007423, Recall: 0.7320261437908496, AUC: 0.8207062179497436, Brier: 0.09100821400014537\n",
      "Project, Fold: 10, Precision: 0.022017997319548153, Recall: 0.782312925170068, AUC: 0.8330634774153497, Brier: 0.11652422298292943\n",
      "Project, Precision: 0.011707860259310213, Recall: 0.7637202304197552, AUC: 0.8364192900701998, Brier: 0.09108330874954058\n",
      "Start training with File dimension...\n",
      "File, Fold: 1, Precision: 0.011501120238984317, Recall: 0.5923076923076923, AUC: 0.7709266565954173, Brier: 0.05080808542399732\n",
      "File, Fold: 2, Precision: 0.007937643020594966, Recall: 0.7872340425531915, AUC: 0.8465675740813167, Brier: 0.09421227747999268\n",
      "File, Fold: 3, Precision: 0.01145629063886882, Recall: 0.7115384615384616, AUC: 0.8221208907024822, Brier: 0.067538829738702\n",
      "File, Fold: 4, Precision: 0.011213615396850644, Recall: 0.7540106951871658, AUC: 0.8450537645343723, Brier: 0.06407800890385988\n",
      "File, Fold: 5, Precision: 0.009907697518841562, Recall: 0.7697368421052632, AUC: 0.8524578052731081, Brier: 0.06496053178230161\n",
      "File, Fold: 6, Precision: 0.006951045627376425, Recall: 0.7358490566037735, AUC: 0.8028258384544004, Brier: 0.13036307481659548\n",
      "File, Fold: 7, Precision: 0.013107344632768362, Recall: 0.7435897435897436, AUC: 0.8295305820710851, Brier: 0.08478769254556348\n",
      "File, Fold: 8, Precision: 0.009954058192955589, Recall: 0.8496732026143791, AUC: 0.8681235875785173, Brier: 0.1134754879629954\n",
      "File, Fold: 9, Precision: 0.01125719687204606, Recall: 0.8562091503267973, AUC: 0.8442807029172161, Brier: 0.1675946790724722\n",
      "File, Fold: 10, Precision: 0.015669149755972257, Recall: 0.8299319727891157, AUC: 0.8278037627570363, Brier: 0.17431026274625377\n",
      "File, Precision: 0.0108955161895259, Recall: 0.7630080859615583, AUC: 0.8309691164964953, Brier: 0.10121289304727339\n",
      "Start training with Pairs dimension...\n",
      "Pairs, Fold: 1, Precision: 0.002667775352527457, Recall: 0.5923076923076923, AUC: 0.6864243389569689, Brier: 0.21964538682995932\n",
      "Pairs, Fold: 2, Precision: 0.0034434520606908426, Recall: 0.6808510638297872, AUC: 0.7462011542441347, Brier: 0.1885736357414397\n",
      "Pairs, Fold: 3, Precision: 0.004577556892492807, Recall: 0.6730769230769231, AUC: 0.7563241632774392, Brier: 0.16061088846933977\n",
      "Pairs, Fold: 4, Precision: 0.0056259503294475415, Recall: 0.5935828877005348, AUC: 0.7463725499357938, Brier: 0.10113121126384489\n",
      "Pairs, Fold: 5, Precision: 0.004493142046350308, Recall: 0.75, AUC: 0.8049839776463218, Brier: 0.14012463647694226\n",
      "Pairs, Fold: 6, Precision: 0.005157904262057732, Recall: 0.7169811320754716, AUC: 0.772855508163579, Brier: 0.17140834441929034\n",
      "Pairs, Fold: 7, Precision: 0.006261351687219195, Recall: 0.8397435897435898, AUC: 0.8192630419925583, Brier: 0.20115575655669585\n",
      "Pairs, Fold: 8, Precision: 0.005654632448890822, Recall: 0.8496732026143791, AUC: 0.824569045712646, Brier: 0.20046781371552722\n",
      "Pairs, Fold: 9, Precision: 0.006633418873771365, Recall: 0.8954248366013072, AUC: 0.7982486113301442, Brier: 0.2984953114777931\n",
      "Pairs, Fold: 10, Precision: 0.010229471938070224, Recall: 0.7551020408163265, AUC: 0.755405628724058, Brier: 0.24429280678288862\n",
      "Pairs, Precision: 0.005474465589151829, Recall: 0.7346743368766011, AUC: 0.7710648019983644, Brier: 0.1925905791733721\n"
     ]
    }
   ],
   "source": [
    "dimension_results = {key: [] for key in dimensions.keys()}\n",
    "tscv = TimeSeriesSplit(n_splits = 10)\n",
    "clf_path = osp.join('.', 'Results')\n",
    "dimension_type = 'discard'\n",
    "\n",
    "if not os.path.exists(clf_path):\n",
    "    os.makedirs(clf_path)\n",
    "    \n",
    "for dim_label, dim_feats in dimensions.items():\n",
    "    print(f'Start training with {dim_label} dimension...')\n",
    "\n",
    "    # if dim == 'Pairs':\n",
    "    #     continue\n",
    "\n",
    "    features = []\n",
    "    if dimension_type == 'keep':\n",
    "        features = dim_feats\n",
    "    else:\n",
    "        for lab, dim in dimensions.items():\n",
    "            if lab != dim_label:\n",
    "                features += dim\n",
    "\n",
    "    auc_scores = []\n",
    "    precision_scores = []\n",
    "    recall_scores = []\n",
    "    brier_scores = []\n",
    "    feature_importances = []\n",
    "    corr_features = []\n",
    "    redundant_features = []\n",
    "\n",
    "    for fold in range(0, 10):\n",
    "\n",
    "        # if fold in [3, 4]:\n",
    "        #     continue\n",
    "\n",
    "        clone_clf = XGBClassifier(random_state=42)\n",
    "        \n",
    "        # Split training data into features and dims\n",
    "        X_train = pd.read_csv(osp.join(\".\", \"Files\", \"Data\", \"Train\", f\"{fold}.csv\"))\n",
    "        y_train = X_train['related']\n",
    "\n",
    "        # df_test = pd.concat((df_test, X_train.iloc[:1]))\n",
    "        # if (dimension_type == 'keep' and dim_label == 'Pairs') or (dimension_type == 'discard' and dim_label != 'Pairs'):\n",
    "        #     desc_model = clas_util.doc2vec_model(df_changes, X_train[['Source', 'Target']].values, fold)\n",
    "        #     subject_model = clas_util.doc2vec_model(df_changes, X_train[['Source', 'Target']].values, fold, \"subject\")\n",
    "        #     add_lines_model = clas_util.doc2vec_model(df_changes, X_train[['Source', 'Target']].values, fold, 'added_lines')\n",
    "        #     del_lines_model = clas_util.doc2vec_model(df_changes, X_train[['Source', 'Target']].values, fold, 'deleted_lines')\n",
    "\n",
    "        #     X_train = clas_util.compute_embdedding_similarity(df_changes, desc_model, X_train, 'commit_message', 'desc')\n",
    "        #     X_train = clas_util.compute_embdedding_similarity(df_changes, subject_model, X_train, 'subject', 'subject')\n",
    "        #     X_train = clas_util.compute_embdedding_similarity(df_changes, add_lines_model, X_train, 'added_lines', 'add_lines')\n",
    "        #     X_train = clas_util.compute_embdedding_similarity(df_changes, del_lines_model, X_train, 'deleted_lines', 'del_lines')\n",
    "\n",
    "        corr_features = df_features.loc[df_features[f'Fold{fold}']==0, 'Feat'].tolist()\n",
    "        features = [c for c in features if c not in corr_features]\n",
    "\n",
    "        X_train = X_train[features]\n",
    "\n",
    "        # X_train = X_train.drop(columns=cols_dropped)\n",
    "\n",
    "        # ros = RandomUnderSampler(random_state=0)\n",
    "        \n",
    "        # Perform under-sampling of the majority class(es)\n",
    "        # X_train, y_train = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "        # conduct the correlation analysis\n",
    "        # if fold == 0:\n",
    "        \n",
    "\n",
    "        # # Remove highly correlated features from the training set\n",
    "        # X_train = X_train.drop(columns=corr_features)\n",
    "\n",
    "        # Conduct redundancy analysis\n",
    "        # if len(X_train.columns) > 1:\n",
    "        #     redundant_features = clas_util.redundancy_analysis(X_train)\n",
    "\n",
    "        # Remove indepandent variables explained by others\n",
    "        # if len(redundant_features) != 0:\n",
    "        #     X_train = X_train.drop(columns=redundant_features)\n",
    "\n",
    "        # Instantiate the OverSampler class then fit it on the each fold training dataset\n",
    "        # features = X_train.columns.tolist()\n",
    "        # print(f'len(X_train) {len(X_train)}')\n",
    "\n",
    "        # Columns to exclude in the test set\n",
    "        # cols_exluded = corr_features + redundant_features \n",
    "\n",
    "        X_test = pd.read_csv(osp.join(\".\", \"Files\", \"Data\", \"Test\", f\"{fold}.csv\"))\n",
    "        # X_test_pairs = X_test[['Source', 'Target', 'related']]\n",
    "        y_test = X_test['related']\n",
    "\n",
    "        # if (dimension_type == 'keep' and dim_label == 'Pairs') or (dimension_type == 'discard' and dim_label != 'Pairs'):\n",
    "        #     X_test = clas_util.compute_embdedding_similarity(df_changes, desc_model, X_test, 'commit_message', 'desc')\n",
    "        #     X_test = clas_util.compute_embdedding_similarity(df_changes, subject_model, X_test, 'subject', 'subject')\n",
    "        #     X_test = clas_util.compute_embdedding_similarity(df_changes, add_lines_model, X_test, 'added_lines', 'add_lines')\n",
    "        #     X_test = clas_util.compute_embdedding_similarity(df_changes, del_lines_model, X_test, 'deleted_lines', 'del_lines')\n",
    "        \n",
    "        X_test = X_test[X_train.columns.tolist()]\n",
    "\n",
    "        # Train the Random Forest Classifier on the training fold set \n",
    "        clone_clf.fit(X_train, y_train)\n",
    "\n",
    "        # Test the Random Forest Classifier on the test fold set \n",
    "        y_pred = clone_clf.predict(X_test)\n",
    "\n",
    "        # y_pred_prob = clone_clf.predict_proba(X_test)[:, 1]\n",
    "        # X_test_pairs['pred'] = y_pred_prob\n",
    "        # compute_top_k_prec_recal(X_test_pairs, dim, fold+1)\n",
    "\n",
    "        precision_scores.append(precision_score(y_test, y_pred))\n",
    "        recall_scores.append(recall_score(y_test, y_pred))\n",
    "        auc_scores.append(roc_auc_score(y_test, y_pred))\n",
    "        brier_scores.append(brier_score_loss(y_test, y_pred))\n",
    "\n",
    "        print(f\"{dim_label}, Fold: {fold+1}, Precision: {precision_scores[-1]}, Recall: {recall_scores[-1]}, AUC: {auc_scores[-1]}, Brier: {brier_scores[-1]}\")\n",
    "\n",
    "    # feature_importances /= (fold+1)\n",
    "    prec_avg = np.average(precision_scores)\n",
    "    recall_avg = np.average(recall_scores)\n",
    "    auc_avg = np.average(auc_scores)\n",
    "    brier_avg = np.average(brier_scores)\n",
    "\n",
    "    print(f\"{dim_label}, Precision: {prec_avg}, Recall: {recall_avg}, AUC: {auc_avg}, Brier: {brier_avg}\")\n",
    "\n",
    "    dimension_results[dim_label] += [{\n",
    "        'Dimension': dim_label,\n",
    "        'Precision': prec_avg,\n",
    "        'Recall': recall_avg,\n",
    "        'AUC': auc_avg,\n",
    "        'Brier': brier_avg\n",
    "    }]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_imp = pd.DataFrame([item[0] for item in list(dimension_results.values())])\n",
    "dim_imp.to_csv(osp.join('.', 'Results', 'Feature_importance', f'second_model_{dimension_type}_dim.csv'), index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feat_impact = pd.read_csv(osp.join('.', 'Results', 'Impact', f'third_model_feat_impact.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attr = \"last_mth_mod_uniq_proj_nbr_target\"\n",
    "# test = df_feat_impact#.loc[(df_feat_impact['fold']!=0)&(df_feat_impact[attr].duplicated()==False), [attr, \"fold\", \"impact\"]].sort_values(\"impact\")\n",
    "# test = test[test['impact'].notnull()==True].iloc[:-1, -1]\n",
    "# test = f\" & {round(test.min(), 2)} & {round(test.median(), 2)} & {round(test.max(), 2)}\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
